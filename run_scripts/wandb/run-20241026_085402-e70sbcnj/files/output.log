Not using distributed mode
[08:54:04.652975] job dir: /root/seg_framework/MS-Mamba/run_scripts
[08:54:04.653120] Namespace(accum_iter=1,
model='SegFormer3D',
in_channels=1,
lr=None,
blr=0.001,
min_lr=0,
dist_on_itp=False,
warmup_epochs=20,
device='cuda:0',
seed=42,
layer_decay=0.75,
clip_grad=None,
num_workers=1,
pin_mem=True,
resume='',
mask_mode='concatenate to image',
world_size=1,
embed_dim=1,
local_rank=-1,
dist_url='env://',
nb_classes=2,
data_dir='/root/MSLesSeg24/data',
datalist=None,
preprocess=False,
dim=2,
loss='mask tp1 tp2',
distributed=False)
[08:54:04.653245] device  cuda:0
[08:54:04.653950] Random seed set as 42
[08:54:04.654322] Starting for fold 0
[08:54:04.844714] Elements in data_dir_paths: 11052
[08:54:04.879493] Elements in data_dir_paths: 1803
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
[08:54:06.657269] number of params: 47335447
[08:54:06.657517] model: Vivim2D(
  (encoder): mamba_block(
    (downsample_layers): SegformerEncoder(
      (patch_embeddings): ModuleList(
        (0): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(2, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (1): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (2): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (3): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (block): ModuleList(
        (0): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): Identity()
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.003703703870996833)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.007407407741993666)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.011111111380159855)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.014814815483987331)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.018518518656492233)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.02222222276031971)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (2): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.025925926864147186)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.029629630967974663)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03333333507180214)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03703703731298447)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04074074327945709)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04444444552063942)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.048148151487112045)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.051851850003004074)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0555555559694767)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.05925925821065903)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06296296417713165)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06666667014360428)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07037036865949631)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07407407462596893)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07777778059244156)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08148147910833359)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08518518507480621)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08888889104127884)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (3): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.09259259700775146)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0962962955236435)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.10000000149011612)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (layer_norm): ModuleList(
        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): SegformerDecodeHead(
    (linear_c): ModuleList(
      (0): SegformerMLP(
        (proj): Linear(in_features=64, out_features=768, bias=True)
      )
      (1): SegformerMLP(
        (proj): Linear(in_features=128, out_features=768, bias=True)
      )
      (2): SegformerMLP(
        (proj): Linear(in_features=320, out_features=768, bias=True)
      )
      (3): SegformerMLP(
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
    )
    (linear_fuse): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (batch_norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): ReLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Conv2d(768, 150, kernel_size=(1, 1), stride=(1, 1))
  )
  (out): Conv2d(768, 1, kernel_size=(1, 1), stride=(1, 1))
)
[08:54:06.659852] base lr: 1.00e-03
[08:54:06.659911] actual lr: 1.25e-04
[08:54:06.659959] accumulate grad iterations: 1
[08:54:06.660011] effective batch size: 32
[08:54:06.661188] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.000125
    maximize: False
    weight_decay: 0.01
)
[08:54:06.663189] Start training for 50 epochs
[08:54:06.664634] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[08:54:07.742460] Epoch: [0]  [  0/345]  eta: 0:06:11  lr: 0.000000  loss: 1.6960 (1.6960)  time: 1.0767  data: 0.1991  max mem: 10551
[08:54:12.612126] Epoch: [0]  [ 20/345]  eta: 0:01:32  lr: 0.000000  loss: 1.6900 (1.6908)  time: 0.2434  data: 0.0001  max mem: 10917
[08:54:17.471115] Epoch: [0]  [ 40/345]  eta: 0:01:20  lr: 0.000001  loss: 1.6888 (1.6902)  time: 0.2429  data: 0.0001  max mem: 10917
[08:54:22.346694] Epoch: [0]  [ 60/345]  eta: 0:01:13  lr: 0.000001  loss: 1.6859 (1.6889)  time: 0.2437  data: 0.0001  max mem: 10917
[08:54:27.243618] Epoch: [0]  [ 80/345]  eta: 0:01:07  lr: 0.000001  loss: 1.6809 (1.6870)  time: 0.2448  data: 0.0001  max mem: 10917
[08:54:32.136360] Epoch: [0]  [100/345]  eta: 0:01:01  lr: 0.000002  loss: 1.6779 (1.6852)  time: 0.2446  data: 0.0001  max mem: 10917
[08:54:37.018761] Epoch: [0]  [120/345]  eta: 0:00:56  lr: 0.000002  loss: 1.6719 (1.6830)  time: 0.2441  data: 0.0001  max mem: 10917
[08:54:41.945350] Epoch: [0]  [140/345]  eta: 0:00:51  lr: 0.000003  loss: 1.6633 (1.6804)  time: 0.2463  data: 0.0001  max mem: 10917
[08:54:46.869619] Epoch: [0]  [160/345]  eta: 0:00:46  lr: 0.000003  loss: 1.6554 (1.6773)  time: 0.2462  data: 0.0001  max mem: 10917
[08:54:51.791071] Epoch: [0]  [180/345]  eta: 0:00:41  lr: 0.000003  loss: 1.6421 (1.6736)  time: 0.2460  data: 0.0001  max mem: 10917
[08:54:56.724846] Epoch: [0]  [200/345]  eta: 0:00:36  lr: 0.000004  loss: 1.6268 (1.6690)  time: 0.2466  data: 0.0001  max mem: 10917
[08:55:01.668830] Epoch: [0]  [220/345]  eta: 0:00:31  lr: 0.000004  loss: 1.6131 (1.6640)  time: 0.2472  data: 0.0000  max mem: 10917
[08:55:06.613419] Epoch: [0]  [240/345]  eta: 0:00:26  lr: 0.000004  loss: 1.5986 (1.6588)  time: 0.2472  data: 0.0000  max mem: 10917
[08:55:11.574605] Epoch: [0]  [260/345]  eta: 0:00:21  lr: 0.000005  loss: 1.5842 (1.6531)  time: 0.2480  data: 0.0001  max mem: 10917
[08:55:16.540695] Epoch: [0]  [280/345]  eta: 0:00:16  lr: 0.000005  loss: 1.5702 (1.6472)  time: 0.2483  data: 0.0001  max mem: 10917
[08:55:21.507756] Epoch: [0]  [300/345]  eta: 0:00:11  lr: 0.000005  loss: 1.5530 (1.6409)  time: 0.2483  data: 0.0001  max mem: 10917
[08:55:26.479692] Epoch: [0]  [320/345]  eta: 0:00:06  lr: 0.000006  loss: 1.5361 (1.6344)  time: 0.2486  data: 0.0000  max mem: 10917
[08:55:31.451533] Epoch: [0]  [340/345]  eta: 0:00:01  lr: 0.000006  loss: 1.5210 (1.6278)  time: 0.2486  data: 0.0001  max mem: 10917
[08:55:32.446658] Epoch: [0]  [344/345]  eta: 0:00:00  lr: 0.000006  loss: 1.5196 (1.6265)  time: 0.2486  data: 0.0001  max mem: 10917
[08:55:32.500571] Epoch: [0] Total time: 0:01:25 (0.2488 s / it)
[08:55:32.501071] Averaged stats: lr: 0.000006  loss: 1.5196 (1.6265)
[08:55:32.735335] Test:  [  0/345]  eta: 0:01:19  loss: 1.5056 (1.5056)  time: 0.2317  data: 0.1519  max mem: 10917
[08:55:33.643844] Test:  [ 10/345]  eta: 0:00:34  loss: 1.5062 (1.5065)  time: 0.1036  data: 0.0229  max mem: 10917
[08:55:34.461150] Test:  [ 20/345]  eta: 0:00:30  loss: 1.5062 (1.5065)  time: 0.0862  data: 0.0050  max mem: 10917
[08:55:35.282277] Test:  [ 30/345]  eta: 0:00:28  loss: 1.5065 (1.5066)  time: 0.0819  data: 0.0001  max mem: 10917
[08:55:36.106636] Test:  [ 40/345]  eta: 0:00:26  loss: 1.5064 (1.5065)  time: 0.0822  data: 0.0001  max mem: 10917
[08:55:36.934799] Test:  [ 50/345]  eta: 0:00:25  loss: 1.5070 (1.5067)  time: 0.0826  data: 0.0001  max mem: 10917
[08:55:37.766766] Test:  [ 60/345]  eta: 0:00:24  loss: 1.5067 (1.5066)  time: 0.0830  data: 0.0001  max mem: 10917
[08:55:38.602008] Test:  [ 70/345]  eta: 0:00:23  loss: 1.5055 (1.5064)  time: 0.0833  data: 0.0001  max mem: 10917
[08:55:39.442052] Test:  [ 80/345]  eta: 0:00:22  loss: 1.5048 (1.5064)  time: 0.0837  data: 0.0001  max mem: 10917
[08:55:40.284847] Test:  [ 90/345]  eta: 0:00:21  loss: 1.5062 (1.5064)  time: 0.0841  data: 0.0001  max mem: 10917
[08:55:41.131669] Test:  [100/345]  eta: 0:00:20  loss: 1.5066 (1.5064)  time: 0.0844  data: 0.0001  max mem: 10917
[08:55:41.981252] Test:  [110/345]  eta: 0:00:20  loss: 1.5057 (1.5064)  time: 0.0848  data: 0.0001  max mem: 10917
[08:55:42.834206] Test:  [120/345]  eta: 0:00:19  loss: 1.5058 (1.5064)  time: 0.0851  data: 0.0001  max mem: 10917
[08:55:43.690429] Test:  [130/345]  eta: 0:00:18  loss: 1.5059 (1.5064)  time: 0.0854  data: 0.0001  max mem: 10917
[08:55:44.550546] Test:  [140/345]  eta: 0:00:17  loss: 1.5059 (1.5063)  time: 0.0858  data: 0.0001  max mem: 10917
[08:55:45.413699] Test:  [150/345]  eta: 0:00:16  loss: 1.5058 (1.5063)  time: 0.0861  data: 0.0001  max mem: 10917
[08:55:46.280806] Test:  [160/345]  eta: 0:00:15  loss: 1.5061 (1.5063)  time: 0.0865  data: 0.0001  max mem: 10917
[08:55:47.151707] Test:  [170/345]  eta: 0:00:14  loss: 1.5067 (1.5064)  time: 0.0869  data: 0.0001  max mem: 10917
[08:55:48.026771] Test:  [180/345]  eta: 0:00:14  loss: 1.5062 (1.5063)  time: 0.0872  data: 0.0001  max mem: 10917
[08:55:48.905119] Test:  [190/345]  eta: 0:00:13  loss: 1.5061 (1.5064)  time: 0.0876  data: 0.0001  max mem: 10917
[08:55:49.787603] Test:  [200/345]  eta: 0:00:12  loss: 1.5061 (1.5064)  time: 0.0880  data: 0.0001  max mem: 10917
[08:55:51.009219] Test:  [210/345]  eta: 0:00:11  loss: 1.5056 (1.5063)  time: 0.1052  data: 0.0001  max mem: 10917
[08:55:51.932594] Test:  [220/345]  eta: 0:00:10  loss: 1.5056 (1.5063)  time: 0.1072  data: 0.0001  max mem: 10917
[08:55:52.988227] Test:  [230/345]  eta: 0:00:10  loss: 1.5070 (1.5063)  time: 0.0989  data: 0.0001  max mem: 10917
[08:55:53.912846] Test:  [240/345]  eta: 0:00:09  loss: 1.5075 (1.5064)  time: 0.0990  data: 0.0001  max mem: 10917
[08:55:55.056235] Test:  [250/345]  eta: 0:00:08  loss: 1.5057 (1.5063)  time: 0.1034  data: 0.0001  max mem: 10917
[08:55:56.202817] Test:  [260/345]  eta: 0:00:07  loss: 1.5057 (1.5063)  time: 0.1145  data: 0.0001  max mem: 10917
[08:55:57.138379] Test:  [270/345]  eta: 0:00:06  loss: 1.5058 (1.5063)  time: 0.1041  data: 0.0001  max mem: 10917
[08:55:58.347299] Test:  [280/345]  eta: 0:00:05  loss: 1.5051 (1.5063)  time: 0.1072  data: 0.0001  max mem: 10917
[08:55:59.533292] Test:  [290/345]  eta: 0:00:05  loss: 1.5071 (1.5063)  time: 0.1197  data: 0.0001  max mem: 10917
[08:56:00.779937] Test:  [300/345]  eta: 0:00:04  loss: 1.5060 (1.5063)  time: 0.1216  data: 0.0001  max mem: 10917
[08:56:01.981989] Test:  [310/345]  eta: 0:00:03  loss: 1.5059 (1.5063)  time: 0.1224  data: 0.0001  max mem: 10917
[08:56:03.068610] Test:  [320/345]  eta: 0:00:02  loss: 1.5060 (1.5062)  time: 0.1144  data: 0.0001  max mem: 10917
[08:56:04.191894] Test:  [330/345]  eta: 0:00:01  loss: 1.5052 (1.5062)  time: 0.1104  data: 0.0001  max mem: 10917
[08:56:05.557691] Test:  [340/345]  eta: 0:00:00  loss: 1.5057 (1.5062)  time: 0.1244  data: 0.0001  max mem: 10917
[08:56:06.250436] Test:  [344/345]  eta: 0:00:00  loss: 1.5061 (1.5062)  time: 0.1324  data: 0.0001  max mem: 10917
[08:56:06.307471] Test: Total time: 0:00:33 (0.0980 s / it)
[08:56:16.897533] Test:  [ 0/57]  eta: 0:00:12  loss: 1.5115 (1.5115)  time: 0.2172  data: 0.1378  max mem: 10917
[08:56:17.704830] Test:  [10/57]  eta: 0:00:04  loss: 1.5087 (1.5089)  time: 0.0930  data: 0.0126  max mem: 10917
[08:56:18.517098] Test:  [20/57]  eta: 0:00:03  loss: 1.5093 (1.5080)  time: 0.0809  data: 0.0001  max mem: 10917
[08:56:19.333291] Test:  [30/57]  eta: 0:00:02  loss: 1.5080 (1.5048)  time: 0.0814  data: 0.0001  max mem: 10917
[08:56:20.153100] Test:  [40/57]  eta: 0:00:01  loss: 1.4966 (1.5025)  time: 0.0817  data: 0.0001  max mem: 10917
[08:56:20.976843] Test:  [50/57]  eta: 0:00:00  loss: 1.4966 (1.5016)  time: 0.0821  data: 0.0001  max mem: 10917
[08:56:21.450776] Test:  [56/57]  eta: 0:00:00  loss: 1.4989 (1.5016)  time: 0.0813  data: 0.0001  max mem: 10917
[08:56:21.503269] Test: Total time: 0:00:04 (0.0846 s / it)
[08:56:23.304915] Dice score of the network on the train images: 0.000000, val images: 0.000000
[08:56:23.305150] saving best_dice_model_0 @ epoch 0
[08:56:23.974758] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[08:56:24.365046] Epoch: [1]  [  0/345]  eta: 0:02:14  lr: 0.000006  loss: 1.5158 (1.5158)  time: 0.3891  data: 0.1376  max mem: 10917
[08:56:29.330137] Epoch: [1]  [ 20/345]  eta: 0:01:22  lr: 0.000007  loss: 1.5031 (1.5047)  time: 0.2482  data: 0.0001  max mem: 10917
[08:56:34.302634] Epoch: [1]  [ 40/345]  eta: 0:01:16  lr: 0.000007  loss: 1.4936 (1.4991)  time: 0.2486  data: 0.0001  max mem: 10917
[08:56:39.279664] Epoch: [1]  [ 60/345]  eta: 0:01:11  lr: 0.000007  loss: 1.4792 (1.4928)  time: 0.2488  data: 0.0001  max mem: 10917
[08:56:44.262902] Epoch: [1]  [ 80/345]  eta: 0:01:06  lr: 0.000008  loss: 1.4672 (1.4869)  time: 0.2491  data: 0.0001  max mem: 10917
[08:56:49.252164] Epoch: [1]  [100/345]  eta: 0:01:01  lr: 0.000008  loss: 1.4561 (1.4809)  time: 0.2494  data: 0.0001  max mem: 10917
[08:56:54.241720] Epoch: [1]  [120/345]  eta: 0:00:56  lr: 0.000008  loss: 1.4482 (1.4756)  time: 0.2494  data: 0.0000  max mem: 10917
[08:56:59.236417] Epoch: [1]  [140/345]  eta: 0:00:51  lr: 0.000009  loss: 1.4378 (1.4703)  time: 0.2497  data: 0.0001  max mem: 10917
[08:57:04.238453] Epoch: [1]  [160/345]  eta: 0:00:46  lr: 0.000009  loss: 1.4295 (1.4651)  time: 0.2501  data: 0.0001  max mem: 10917
[08:57:09.242683] Epoch: [1]  [180/345]  eta: 0:00:41  lr: 0.000010  loss: 1.4227 (1.4604)  time: 0.2502  data: 0.0001  max mem: 10917
[08:57:14.255200] Epoch: [1]  [200/345]  eta: 0:00:36  lr: 0.000010  loss: 1.4117 (1.4556)  time: 0.2506  data: 0.0001  max mem: 10917
[08:57:19.267604] Epoch: [1]  [220/345]  eta: 0:00:31  lr: 0.000010  loss: 1.4049 (1.4510)  time: 0.2506  data: 0.0000  max mem: 10917
[08:57:24.285187] Epoch: [1]  [240/345]  eta: 0:00:26  lr: 0.000011  loss: 1.3984 (1.4467)  time: 0.2508  data: 0.0001  max mem: 10917
[08:57:29.313638] Epoch: [1]  [260/345]  eta: 0:00:21  lr: 0.000011  loss: 1.3906 (1.4424)  time: 0.2514  data: 0.0001  max mem: 10917
[08:57:34.347995] Epoch: [1]  [280/345]  eta: 0:00:16  lr: 0.000011  loss: 1.3855 (1.4384)  time: 0.2517  data: 0.0001  max mem: 10917
[08:57:39.377672] Epoch: [1]  [300/345]  eta: 0:00:11  lr: 0.000012  loss: 1.3786 (1.4345)  time: 0.2514  data: 0.0000  max mem: 10917
[08:57:44.413040] Epoch: [1]  [320/345]  eta: 0:00:06  lr: 0.000012  loss: 1.3731 (1.4307)  time: 0.2517  data: 0.0000  max mem: 10917
[08:57:49.436621] Epoch: [1]  [340/345]  eta: 0:00:01  lr: 0.000012  loss: 1.3677 (1.4270)  time: 0.2511  data: 0.0001  max mem: 10917
[08:57:50.442038] Epoch: [1]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 1.3673 (1.4263)  time: 0.2511  data: 0.0001  max mem: 10917
[08:57:50.494340] Epoch: [1] Total time: 0:01:26 (0.2508 s / it)
[08:57:50.494577] Averaged stats: lr: 0.000012  loss: 1.3673 (1.4263)
[08:57:50.732927] Test:  [  0/345]  eta: 0:01:21  loss: 1.3687 (1.3687)  time: 0.2356  data: 0.1553  max mem: 10917
[08:57:51.552784] Test:  [ 10/345]  eta: 0:00:32  loss: 1.3653 (1.3652)  time: 0.0959  data: 0.0142  max mem: 10917
[08:57:52.375457] Test:  [ 20/345]  eta: 0:00:29  loss: 1.3651 (1.3654)  time: 0.0821  data: 0.0001  max mem: 10917
[08:57:53.200797] Test:  [ 30/345]  eta: 0:00:27  loss: 1.3651 (1.3652)  time: 0.0823  data: 0.0001  max mem: 10917
[08:57:54.030906] Test:  [ 40/345]  eta: 0:00:26  loss: 1.3648 (1.3651)  time: 0.0827  data: 0.0001  max mem: 10917
[08:57:54.863905] Test:  [ 50/345]  eta: 0:00:25  loss: 1.3648 (1.3649)  time: 0.0831  data: 0.0001  max mem: 10917
[08:57:55.700420] Test:  [ 60/345]  eta: 0:00:24  loss: 1.3645 (1.3648)  time: 0.0834  data: 0.0001  max mem: 10917
[08:57:56.540489] Test:  [ 70/345]  eta: 0:00:23  loss: 1.3645 (1.3649)  time: 0.0838  data: 0.0001  max mem: 10917
[08:57:57.384416] Test:  [ 80/345]  eta: 0:00:22  loss: 1.3641 (1.3647)  time: 0.0842  data: 0.0001  max mem: 10917
[08:57:58.231805] Test:  [ 90/345]  eta: 0:00:21  loss: 1.3639 (1.3648)  time: 0.0845  data: 0.0001  max mem: 10917
[08:57:59.081935] Test:  [100/345]  eta: 0:00:20  loss: 1.3647 (1.3648)  time: 0.0848  data: 0.0001  max mem: 10917
[08:57:59.936927] Test:  [110/345]  eta: 0:00:19  loss: 1.3640 (1.3648)  time: 0.0852  data: 0.0001  max mem: 10917
[08:58:00.794507] Test:  [120/345]  eta: 0:00:19  loss: 1.3640 (1.3648)  time: 0.0856  data: 0.0001  max mem: 10917
[08:58:01.655579] Test:  [130/345]  eta: 0:00:18  loss: 1.3647 (1.3648)  time: 0.0859  data: 0.0001  max mem: 10917
[08:58:02.520745] Test:  [140/345]  eta: 0:00:17  loss: 1.3648 (1.3648)  time: 0.0863  data: 0.0001  max mem: 10917
[08:58:03.388963] Test:  [150/345]  eta: 0:00:16  loss: 1.3648 (1.3648)  time: 0.0866  data: 0.0001  max mem: 10917
[08:58:04.260759] Test:  [160/345]  eta: 0:00:15  loss: 1.3650 (1.3648)  time: 0.0870  data: 0.0001  max mem: 10917
[08:58:05.135629] Test:  [170/345]  eta: 0:00:14  loss: 1.3644 (1.3647)  time: 0.0873  data: 0.0001  max mem: 10917
[08:58:06.015047] Test:  [180/345]  eta: 0:00:14  loss: 1.3636 (1.3646)  time: 0.0877  data: 0.0001  max mem: 10917
[08:58:06.896922] Test:  [190/345]  eta: 0:00:13  loss: 1.3638 (1.3646)  time: 0.0880  data: 0.0001  max mem: 10917
[08:58:07.783003] Test:  [200/345]  eta: 0:00:12  loss: 1.3652 (1.3647)  time: 0.0884  data: 0.0001  max mem: 10917
[08:58:08.672927] Test:  [210/345]  eta: 0:00:11  loss: 1.3655 (1.3647)  time: 0.0888  data: 0.0001  max mem: 10917
[08:58:09.566074] Test:  [220/345]  eta: 0:00:10  loss: 1.3653 (1.3647)  time: 0.0891  data: 0.0001  max mem: 10917
[08:58:10.462913] Test:  [230/345]  eta: 0:00:09  loss: 1.3647 (1.3647)  time: 0.0895  data: 0.0001  max mem: 10917
[08:58:11.362976] Test:  [240/345]  eta: 0:00:09  loss: 1.3646 (1.3647)  time: 0.0898  data: 0.0001  max mem: 10917
[08:58:12.265545] Test:  [250/345]  eta: 0:00:08  loss: 1.3650 (1.3647)  time: 0.0901  data: 0.0001  max mem: 10917
[08:58:13.172791] Test:  [260/345]  eta: 0:00:07  loss: 1.3652 (1.3647)  time: 0.0904  data: 0.0001  max mem: 10917
[08:58:14.083402] Test:  [270/345]  eta: 0:00:06  loss: 1.3647 (1.3647)  time: 0.0908  data: 0.0001  max mem: 10917
[08:58:14.996711] Test:  [280/345]  eta: 0:00:05  loss: 1.3643 (1.3647)  time: 0.0911  data: 0.0001  max mem: 10917
[08:58:15.913836] Test:  [290/345]  eta: 0:00:04  loss: 1.3647 (1.3647)  time: 0.0915  data: 0.0001  max mem: 10917
[08:58:16.835601] Test:  [300/345]  eta: 0:00:03  loss: 1.3646 (1.3647)  time: 0.0919  data: 0.0001  max mem: 10917
[08:58:17.760165] Test:  [310/345]  eta: 0:00:03  loss: 1.3640 (1.3647)  time: 0.0923  data: 0.0001  max mem: 10917
[08:58:18.687908] Test:  [320/345]  eta: 0:00:02  loss: 1.3633 (1.3646)  time: 0.0926  data: 0.0001  max mem: 10917
[08:58:19.618940] Test:  [330/345]  eta: 0:00:01  loss: 1.3638 (1.3646)  time: 0.0929  data: 0.0001  max mem: 10917
[08:58:20.553953] Test:  [340/345]  eta: 0:00:00  loss: 1.3640 (1.3646)  time: 0.0933  data: 0.0001  max mem: 10917
[08:58:20.929269] Test:  [344/345]  eta: 0:00:00  loss: 1.3640 (1.3646)  time: 0.0934  data: 0.0001  max mem: 10917
[08:58:20.987236] Test: Total time: 0:00:30 (0.0884 s / it)
[08:58:31.543449] Test:  [ 0/57]  eta: 0:00:12  loss: 1.3699 (1.3699)  time: 0.2211  data: 0.1416  max mem: 10917
[08:58:32.356222] Test:  [10/57]  eta: 0:00:04  loss: 1.3685 (1.3671)  time: 0.0939  data: 0.0129  max mem: 10917
[08:58:33.173048] Test:  [20/57]  eta: 0:00:03  loss: 1.3685 (1.3664)  time: 0.0814  data: 0.0001  max mem: 10917
[08:58:33.993883] Test:  [30/57]  eta: 0:00:02  loss: 1.3639 (1.3637)  time: 0.0818  data: 0.0001  max mem: 10917
[08:58:34.817622] Test:  [40/57]  eta: 0:00:01  loss: 1.3588 (1.3618)  time: 0.0822  data: 0.0001  max mem: 10917
[08:58:35.645899] Test:  [50/57]  eta: 0:00:00  loss: 1.3585 (1.3608)  time: 0.0826  data: 0.0001  max mem: 10917
[08:58:36.095591] Test:  [56/57]  eta: 0:00:00  loss: 1.3585 (1.3606)  time: 0.0804  data: 0.0001  max mem: 10917
[08:58:36.135825] Test: Total time: 0:00:04 (0.0845 s / it)
[08:58:37.975535] Dice score of the network on the train images: 0.000000, val images: 0.000000
[08:58:37.979138] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[08:58:38.378180] Epoch: [2]  [  0/345]  eta: 0:02:17  lr: 0.000013  loss: 1.3689 (1.3689)  time: 0.3980  data: 0.1466  max mem: 10917
[08:58:43.364496] Epoch: [2]  [ 20/345]  eta: 0:01:23  lr: 0.000013  loss: 1.3616 (1.3635)  time: 0.2493  data: 0.0001  max mem: 10917
[08:58:48.353943] Epoch: [2]  [ 40/345]  eta: 0:01:17  lr: 0.000013  loss: 1.3551 (1.3600)  time: 0.2494  data: 0.0000  max mem: 10917
[08:58:53.348098] Epoch: [2]  [ 60/345]  eta: 0:01:11  lr: 0.000014  loss: 1.3536 (1.3578)  time: 0.2497  data: 0.0000  max mem: 10917
[08:58:58.351589] Epoch: [2]  [ 80/345]  eta: 0:01:06  lr: 0.000014  loss: 1.3473 (1.3553)  time: 0.2501  data: 0.0001  max mem: 10917
[08:59:03.363120] Epoch: [2]  [100/345]  eta: 0:01:01  lr: 0.000014  loss: 1.3437 (1.3529)  time: 0.2505  data: 0.0000  max mem: 10917
[08:59:08.374299] Epoch: [2]  [120/345]  eta: 0:00:56  lr: 0.000015  loss: 1.3398 (1.3508)  time: 0.2505  data: 0.0001  max mem: 10917
[08:59:13.382007] Epoch: [2]  [140/345]  eta: 0:00:51  lr: 0.000015  loss: 1.3362 (1.3487)  time: 0.2503  data: 0.0001  max mem: 10917
[08:59:18.396589] Epoch: [2]  [160/345]  eta: 0:00:46  lr: 0.000015  loss: 1.3335 (1.3469)  time: 0.2507  data: 0.0001  max mem: 10917
[08:59:23.415552] Epoch: [2]  [180/345]  eta: 0:00:41  lr: 0.000016  loss: 1.3299 (1.3451)  time: 0.2509  data: 0.0000  max mem: 10917
[08:59:28.435053] Epoch: [2]  [200/345]  eta: 0:00:36  lr: 0.000016  loss: 1.3257 (1.3431)  time: 0.2509  data: 0.0000  max mem: 10917
[08:59:33.455940] Epoch: [2]  [220/345]  eta: 0:00:31  lr: 0.000016  loss: 1.3236 (1.3414)  time: 0.2510  data: 0.0000  max mem: 10917
[08:59:38.481284] Epoch: [2]  [240/345]  eta: 0:00:26  lr: 0.000017  loss: 1.3210 (1.3397)  time: 0.2512  data: 0.0000  max mem: 10917
[08:59:43.506488] Epoch: [2]  [260/345]  eta: 0:00:21  lr: 0.000017  loss: 1.3170 (1.3380)  time: 0.2512  data: 0.0000  max mem: 10917
[08:59:48.536308] Epoch: [2]  [280/345]  eta: 0:00:16  lr: 0.000018  loss: 1.3161 (1.3365)  time: 0.2514  data: 0.0000  max mem: 10917
[08:59:53.566409] Epoch: [2]  [300/345]  eta: 0:00:11  lr: 0.000018  loss: 1.3120 (1.3348)  time: 0.2515  data: 0.0000  max mem: 10917
[08:59:58.596324] Epoch: [2]  [320/345]  eta: 0:00:06  lr: 0.000018  loss: 1.3093 (1.3333)  time: 0.2515  data: 0.0000  max mem: 10917
[09:00:03.630790] Epoch: [2]  [340/345]  eta: 0:00:01  lr: 0.000019  loss: 1.3071 (1.3317)  time: 0.2517  data: 0.0000  max mem: 10917
[09:00:04.637903] Epoch: [2]  [344/345]  eta: 0:00:00  lr: 0.000019  loss: 1.3062 (1.3314)  time: 0.2517  data: 0.0001  max mem: 10917
[09:00:04.693536] Epoch: [2] Total time: 0:01:26 (0.2513 s / it)
[09:00:04.694025] Averaged stats: lr: 0.000019  loss: 1.3062 (1.3314)
[09:00:04.933732] Test:  [  0/345]  eta: 0:01:21  loss: 1.3038 (1.3038)  time: 0.2365  data: 0.1564  max mem: 10917
[09:00:05.785762] Test:  [ 10/345]  eta: 0:00:33  loss: 1.3029 (1.3017)  time: 0.0989  data: 0.0173  max mem: 10917
[09:00:06.608961] Test:  [ 20/345]  eta: 0:00:29  loss: 1.3012 (1.3006)  time: 0.0837  data: 0.0017  max mem: 10917
[09:00:07.436224] Test:  [ 30/345]  eta: 0:00:27  loss: 1.2996 (1.3004)  time: 0.0825  data: 0.0001  max mem: 10917
[09:00:08.267014] Test:  [ 40/345]  eta: 0:00:26  loss: 1.2996 (1.3004)  time: 0.0828  data: 0.0001  max mem: 10917
[09:00:09.100438] Test:  [ 50/345]  eta: 0:00:25  loss: 1.2996 (1.3003)  time: 0.0832  data: 0.0001  max mem: 10917
[09:00:09.937102] Test:  [ 60/345]  eta: 0:00:24  loss: 1.3003 (1.3004)  time: 0.0835  data: 0.0001  max mem: 10917
[09:00:10.777732] Test:  [ 70/345]  eta: 0:00:23  loss: 1.2991 (1.3001)  time: 0.0838  data: 0.0001  max mem: 10917
[09:00:11.622877] Test:  [ 80/345]  eta: 0:00:22  loss: 1.2986 (1.3000)  time: 0.0842  data: 0.0001  max mem: 10917
[09:00:12.470323] Test:  [ 90/345]  eta: 0:00:21  loss: 1.2995 (1.3001)  time: 0.0846  data: 0.0001  max mem: 10917
[09:00:13.321626] Test:  [100/345]  eta: 0:00:20  loss: 1.2997 (1.3000)  time: 0.0849  data: 0.0001  max mem: 10917
[09:00:14.175638] Test:  [110/345]  eta: 0:00:20  loss: 1.2995 (1.3001)  time: 0.0852  data: 0.0001  max mem: 10917
[09:00:15.034097] Test:  [120/345]  eta: 0:00:19  loss: 1.3002 (1.3001)  time: 0.0856  data: 0.0001  max mem: 10917
[09:00:15.895621] Test:  [130/345]  eta: 0:00:18  loss: 1.3012 (1.3002)  time: 0.0859  data: 0.0001  max mem: 10917
[09:00:16.761006] Test:  [140/345]  eta: 0:00:17  loss: 1.3011 (1.3003)  time: 0.0863  data: 0.0001  max mem: 10917
[09:00:17.630294] Test:  [150/345]  eta: 0:00:16  loss: 1.3010 (1.3003)  time: 0.0867  data: 0.0001  max mem: 10917
[09:00:18.502844] Test:  [160/345]  eta: 0:00:15  loss: 1.3012 (1.3004)  time: 0.0870  data: 0.0001  max mem: 10917
[09:00:19.378827] Test:  [170/345]  eta: 0:00:15  loss: 1.3012 (1.3004)  time: 0.0874  data: 0.0001  max mem: 10917
[09:00:20.258198] Test:  [180/345]  eta: 0:00:14  loss: 1.3012 (1.3004)  time: 0.0877  data: 0.0001  max mem: 10917
[09:00:21.140792] Test:  [190/345]  eta: 0:00:13  loss: 1.3015 (1.3005)  time: 0.0881  data: 0.0001  max mem: 10917
[09:00:22.027725] Test:  [200/345]  eta: 0:00:12  loss: 1.3016 (1.3005)  time: 0.0884  data: 0.0001  max mem: 10917
[09:00:22.917732] Test:  [210/345]  eta: 0:00:11  loss: 1.3007 (1.3005)  time: 0.0888  data: 0.0001  max mem: 10917
[09:00:23.810852] Test:  [220/345]  eta: 0:00:10  loss: 1.3008 (1.3005)  time: 0.0891  data: 0.0001  max mem: 10917
[09:00:24.707792] Test:  [230/345]  eta: 0:00:09  loss: 1.3018 (1.3006)  time: 0.0895  data: 0.0001  max mem: 10917
[09:00:25.607896] Test:  [240/345]  eta: 0:00:09  loss: 1.3010 (1.3006)  time: 0.0898  data: 0.0001  max mem: 10917
[09:00:26.511045] Test:  [250/345]  eta: 0:00:08  loss: 1.3005 (1.3006)  time: 0.0901  data: 0.0001  max mem: 10917
[09:00:27.417905] Test:  [260/345]  eta: 0:00:07  loss: 1.2996 (1.3006)  time: 0.0905  data: 0.0001  max mem: 10917
[09:00:28.329207] Test:  [270/345]  eta: 0:00:06  loss: 1.2995 (1.3006)  time: 0.0909  data: 0.0001  max mem: 10917
[09:00:29.243526] Test:  [280/345]  eta: 0:00:05  loss: 1.3012 (1.3006)  time: 0.0912  data: 0.0001  max mem: 10917
[09:00:30.161933] Test:  [290/345]  eta: 0:00:04  loss: 1.3003 (1.3006)  time: 0.0916  data: 0.0001  max mem: 10917
[09:00:31.083463] Test:  [300/345]  eta: 0:00:03  loss: 1.2998 (1.3006)  time: 0.0919  data: 0.0001  max mem: 10917
[09:00:32.008611] Test:  [310/345]  eta: 0:00:03  loss: 1.2998 (1.3006)  time: 0.0923  data: 0.0001  max mem: 10917
[09:00:32.936134] Test:  [320/345]  eta: 0:00:02  loss: 1.3015 (1.3006)  time: 0.0926  data: 0.0001  max mem: 10917
[09:00:33.867877] Test:  [330/345]  eta: 0:00:01  loss: 1.3010 (1.3006)  time: 0.0929  data: 0.0001  max mem: 10917
[09:00:34.802587] Test:  [340/345]  eta: 0:00:00  loss: 1.3010 (1.3006)  time: 0.0933  data: 0.0001  max mem: 10917
[09:00:35.178338] Test:  [344/345]  eta: 0:00:00  loss: 1.3006 (1.3006)  time: 0.0934  data: 0.0001  max mem: 10917
[09:00:35.235683] Test: Total time: 0:00:30 (0.0885 s / it)
[09:00:45.779971] Test:  [ 0/57]  eta: 0:00:12  loss: 1.3069 (1.3069)  time: 0.2223  data: 0.1425  max mem: 10917
[09:00:46.598259] Test:  [10/57]  eta: 0:00:04  loss: 1.3043 (1.3037)  time: 0.0945  data: 0.0136  max mem: 10917
[09:00:47.415118] Test:  [20/57]  eta: 0:00:03  loss: 1.3048 (1.3035)  time: 0.0817  data: 0.0004  max mem: 10917
[09:00:48.235441] Test:  [30/57]  eta: 0:00:02  loss: 1.2963 (1.2995)  time: 0.0818  data: 0.0001  max mem: 10917
[09:00:49.058961] Test:  [40/57]  eta: 0:00:01  loss: 1.2907 (1.2968)  time: 0.0821  data: 0.0001  max mem: 10917
[09:00:49.886821] Test:  [50/57]  eta: 0:00:00  loss: 1.2900 (1.2957)  time: 0.0825  data: 0.0001  max mem: 10917
[09:00:50.336956] Test:  [56/57]  eta: 0:00:00  loss: 1.2933 (1.2955)  time: 0.0803  data: 0.0001  max mem: 10917
[09:00:50.395580] Test: Total time: 0:00:04 (0.0849 s / it)
[09:00:52.168968] Dice score of the network on the train images: 0.000000, val images: 0.000000
[09:00:52.172389] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:00:52.567402] Epoch: [3]  [  0/345]  eta: 0:02:15  lr: 0.000019  loss: 1.3071 (1.3071)  time: 0.3942  data: 0.1430  max mem: 10917
[09:00:57.552866] Epoch: [3]  [ 20/345]  eta: 0:01:23  lr: 0.000019  loss: 1.3039 (1.3047)  time: 0.2492  data: 0.0001  max mem: 10917
[09:01:02.542539] Epoch: [3]  [ 40/345]  eta: 0:01:17  lr: 0.000019  loss: 1.3022 (1.3035)  time: 0.2494  data: 0.0000  max mem: 10917
[09:01:07.533372] Epoch: [3]  [ 60/345]  eta: 0:01:11  lr: 0.000020  loss: 1.3002 (1.3025)  time: 0.2495  data: 0.0000  max mem: 10917
[09:01:12.528672] Epoch: [3]  [ 80/345]  eta: 0:01:06  lr: 0.000020  loss: 1.2985 (1.3011)  time: 0.2497  data: 0.0000  max mem: 10917
[09:01:17.532687] Epoch: [3]  [100/345]  eta: 0:01:01  lr: 0.000021  loss: 1.2964 (1.3002)  time: 0.2502  data: 0.0001  max mem: 10917
[09:01:22.533206] Epoch: [3]  [120/345]  eta: 0:00:56  lr: 0.000021  loss: 1.2953 (1.2994)  time: 0.2500  data: 0.0000  max mem: 10917
[09:01:27.538112] Epoch: [3]  [140/345]  eta: 0:00:51  lr: 0.000021  loss: 1.2902 (1.2981)  time: 0.2502  data: 0.0000  max mem: 10917
[09:01:32.551788] Epoch: [3]  [160/345]  eta: 0:00:46  lr: 0.000022  loss: 1.2891 (1.2970)  time: 0.2506  data: 0.0001  max mem: 10917
[09:01:37.566305] Epoch: [3]  [180/345]  eta: 0:00:41  lr: 0.000022  loss: 1.2878 (1.2960)  time: 0.2507  data: 0.0001  max mem: 10917
[09:01:42.581477] Epoch: [3]  [200/345]  eta: 0:00:36  lr: 0.000022  loss: 1.2856 (1.2950)  time: 0.2507  data: 0.0000  max mem: 10917
[09:01:47.614660] Epoch: [3]  [220/345]  eta: 0:00:31  lr: 0.000023  loss: 1.2823 (1.2939)  time: 0.2516  data: 0.0001  max mem: 10917
[09:01:52.650929] Epoch: [3]  [240/345]  eta: 0:00:26  lr: 0.000023  loss: 1.2811 (1.2929)  time: 0.2518  data: 0.0000  max mem: 10917
[09:01:57.683716] Epoch: [3]  [260/345]  eta: 0:00:21  lr: 0.000023  loss: 1.2748 (1.2916)  time: 0.2516  data: 0.0000  max mem: 10917
[09:02:02.708628] Epoch: [3]  [280/345]  eta: 0:00:16  lr: 0.000024  loss: 1.2729 (1.2902)  time: 0.2512  data: 0.0000  max mem: 10917
[09:02:07.733893] Epoch: [3]  [300/345]  eta: 0:00:11  lr: 0.000024  loss: 1.2641 (1.2886)  time: 0.2512  data: 0.0000  max mem: 10917
[09:02:12.761684] Epoch: [3]  [320/345]  eta: 0:00:06  lr: 0.000025  loss: 1.2621 (1.2870)  time: 0.2513  data: 0.0001  max mem: 10917
[09:02:17.790904] Epoch: [3]  [340/345]  eta: 0:00:01  lr: 0.000025  loss: 1.2587 (1.2853)  time: 0.2514  data: 0.0001  max mem: 10917
[09:02:18.796919] Epoch: [3]  [344/345]  eta: 0:00:00  lr: 0.000025  loss: 1.2557 (1.2849)  time: 0.2514  data: 0.0001  max mem: 10917
[09:02:18.854161] Epoch: [3] Total time: 0:01:26 (0.2513 s / it)
[09:02:18.854549] Averaged stats: lr: 0.000025  loss: 1.2557 (1.2849)
[09:02:19.086726] Test:  [  0/345]  eta: 0:01:19  loss: 1.2441 (1.2441)  time: 0.2292  data: 0.1487  max mem: 10917
[09:02:19.942381] Test:  [ 10/345]  eta: 0:00:33  loss: 1.2385 (1.2379)  time: 0.0985  data: 0.0170  max mem: 10917
[09:02:20.765185] Test:  [ 20/345]  eta: 0:00:29  loss: 1.2385 (1.2406)  time: 0.0839  data: 0.0020  max mem: 10917
[09:02:21.590858] Test:  [ 30/345]  eta: 0:00:27  loss: 1.2444 (1.2407)  time: 0.0824  data: 0.0001  max mem: 10917
[09:02:22.420676] Test:  [ 40/345]  eta: 0:00:26  loss: 1.2367 (1.2399)  time: 0.0827  data: 0.0001  max mem: 10917
[09:02:23.253941] Test:  [ 50/345]  eta: 0:00:25  loss: 1.2383 (1.2407)  time: 0.0831  data: 0.0001  max mem: 10917
[09:02:24.090620] Test:  [ 60/345]  eta: 0:00:24  loss: 1.2463 (1.2417)  time: 0.0834  data: 0.0001  max mem: 10917
[09:02:24.931401] Test:  [ 70/345]  eta: 0:00:23  loss: 1.2446 (1.2418)  time: 0.0838  data: 0.0001  max mem: 10917
[09:02:25.775891] Test:  [ 80/345]  eta: 0:00:22  loss: 1.2417 (1.2416)  time: 0.0842  data: 0.0001  max mem: 10917
[09:02:26.624021] Test:  [ 90/345]  eta: 0:00:21  loss: 1.2388 (1.2412)  time: 0.0846  data: 0.0001  max mem: 10917
[09:02:27.475102] Test:  [100/345]  eta: 0:00:20  loss: 1.2417 (1.2416)  time: 0.0849  data: 0.0001  max mem: 10917
[09:02:28.329978] Test:  [110/345]  eta: 0:00:20  loss: 1.2438 (1.2419)  time: 0.0852  data: 0.0001  max mem: 10917
[09:02:29.188698] Test:  [120/345]  eta: 0:00:19  loss: 1.2393 (1.2416)  time: 0.0856  data: 0.0001  max mem: 10917
[09:02:30.050997] Test:  [130/345]  eta: 0:00:18  loss: 1.2384 (1.2414)  time: 0.0860  data: 0.0001  max mem: 10917
[09:02:30.916588] Test:  [140/345]  eta: 0:00:17  loss: 1.2418 (1.2414)  time: 0.0863  data: 0.0001  max mem: 10917
[09:02:31.785159] Test:  [150/345]  eta: 0:00:16  loss: 1.2408 (1.2414)  time: 0.0867  data: 0.0001  max mem: 10917
[09:02:32.657280] Test:  [160/345]  eta: 0:00:15  loss: 1.2387 (1.2413)  time: 0.0870  data: 0.0001  max mem: 10917
[09:02:33.533758] Test:  [170/345]  eta: 0:00:15  loss: 1.2378 (1.2411)  time: 0.0874  data: 0.0001  max mem: 10917
[09:02:34.413793] Test:  [180/345]  eta: 0:00:14  loss: 1.2378 (1.2410)  time: 0.0877  data: 0.0001  max mem: 10917
[09:02:35.296415] Test:  [190/345]  eta: 0:00:13  loss: 1.2375 (1.2408)  time: 0.0881  data: 0.0001  max mem: 10917
[09:02:36.183257] Test:  [200/345]  eta: 0:00:12  loss: 1.2377 (1.2408)  time: 0.0884  data: 0.0001  max mem: 10917
[09:02:37.072922] Test:  [210/345]  eta: 0:00:11  loss: 1.2391 (1.2409)  time: 0.0888  data: 0.0001  max mem: 10917
[09:02:37.966660] Test:  [220/345]  eta: 0:00:10  loss: 1.2399 (1.2408)  time: 0.0891  data: 0.0001  max mem: 10917
[09:02:38.863410] Test:  [230/345]  eta: 0:00:09  loss: 1.2356 (1.2407)  time: 0.0895  data: 0.0001  max mem: 10917
[09:02:39.764357] Test:  [240/345]  eta: 0:00:09  loss: 1.2389 (1.2407)  time: 0.0898  data: 0.0001  max mem: 10917
[09:02:40.668202] Test:  [250/345]  eta: 0:00:08  loss: 1.2404 (1.2408)  time: 0.0902  data: 0.0001  max mem: 10917
[09:02:41.575353] Test:  [260/345]  eta: 0:00:07  loss: 1.2430 (1.2407)  time: 0.0905  data: 0.0001  max mem: 10917
[09:02:42.486618] Test:  [270/345]  eta: 0:00:06  loss: 1.2440 (1.2409)  time: 0.0909  data: 0.0001  max mem: 10917
[09:02:43.400515] Test:  [280/345]  eta: 0:00:05  loss: 1.2449 (1.2410)  time: 0.0912  data: 0.0001  max mem: 10917
[09:02:44.318814] Test:  [290/345]  eta: 0:00:04  loss: 1.2378 (1.2409)  time: 0.0916  data: 0.0001  max mem: 10917
[09:02:45.239964] Test:  [300/345]  eta: 0:00:03  loss: 1.2378 (1.2409)  time: 0.0919  data: 0.0001  max mem: 10917
[09:02:46.164926] Test:  [310/345]  eta: 0:00:03  loss: 1.2392 (1.2408)  time: 0.0923  data: 0.0001  max mem: 10917
[09:02:47.093847] Test:  [320/345]  eta: 0:00:02  loss: 1.2419 (1.2409)  time: 0.0926  data: 0.0001  max mem: 10917
[09:02:48.026314] Test:  [330/345]  eta: 0:00:01  loss: 1.2430 (1.2410)  time: 0.0930  data: 0.0001  max mem: 10917
[09:02:48.961410] Test:  [340/345]  eta: 0:00:00  loss: 1.2415 (1.2409)  time: 0.0933  data: 0.0001  max mem: 10917
[09:02:49.336680] Test:  [344/345]  eta: 0:00:00  loss: 1.2383 (1.2408)  time: 0.0935  data: 0.0001  max mem: 10917
[09:02:49.394001] Test: Total time: 0:00:30 (0.0885 s / it)
[09:03:00.010026] Test:  [ 0/57]  eta: 0:00:12  loss: 1.2613 (1.2613)  time: 0.2220  data: 0.1421  max mem: 10917
[09:03:00.823918] Test:  [10/57]  eta: 0:00:04  loss: 1.2597 (1.2550)  time: 0.0941  data: 0.0130  max mem: 10917
[09:03:01.639890] Test:  [20/57]  eta: 0:00:03  loss: 1.2599 (1.2536)  time: 0.0814  data: 0.0001  max mem: 10917
[09:03:02.460361] Test:  [30/57]  eta: 0:00:02  loss: 1.2243 (1.2366)  time: 0.0818  data: 0.0001  max mem: 10917
[09:03:03.284700] Test:  [40/57]  eta: 0:00:01  loss: 1.1917 (1.2256)  time: 0.0822  data: 0.0001  max mem: 10917
[09:03:04.112258] Test:  [50/57]  eta: 0:00:00  loss: 1.2010 (1.2217)  time: 0.0825  data: 0.0001  max mem: 10917
[09:03:04.561751] Test:  [56/57]  eta: 0:00:00  loss: 1.2167 (1.2220)  time: 0.0803  data: 0.0001  max mem: 10917
[09:03:04.616385] Test: Total time: 0:00:04 (0.0847 s / it)
[09:03:06.445494] Dice score of the network on the train images: 0.102478, val images: 0.100649
[09:03:06.445725] saving best_prec_model_0 @ epoch 3
[09:03:07.107071] saving best_rec_model_0 @ epoch 3
[09:03:07.642470] saving best_dice_model_0 @ epoch 3
[09:03:08.439332] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:03:08.835505] Epoch: [4]  [  0/345]  eta: 0:02:16  lr: 0.000025  loss: 1.2609 (1.2609)  time: 0.3952  data: 0.1426  max mem: 10917
[09:03:13.825286] Epoch: [4]  [ 20/345]  eta: 0:01:23  lr: 0.000025  loss: 1.2531 (1.2519)  time: 0.2494  data: 0.0000  max mem: 10917
[09:03:18.821284] Epoch: [4]  [ 40/345]  eta: 0:01:17  lr: 0.000026  loss: 1.2374 (1.2449)  time: 0.2498  data: 0.0001  max mem: 10917
[09:03:23.810217] Epoch: [4]  [ 60/345]  eta: 0:01:11  lr: 0.000026  loss: 1.2333 (1.2419)  time: 0.2494  data: 0.0000  max mem: 10917
[09:03:28.805096] Epoch: [4]  [ 80/345]  eta: 0:01:06  lr: 0.000026  loss: 1.2296 (1.2385)  time: 0.2497  data: 0.0001  max mem: 10917
[09:03:33.804665] Epoch: [4]  [100/345]  eta: 0:01:01  lr: 0.000027  loss: 1.2181 (1.2343)  time: 0.2499  data: 0.0000  max mem: 10917
[09:03:38.813906] Epoch: [4]  [120/345]  eta: 0:00:56  lr: 0.000027  loss: 1.2098 (1.2301)  time: 0.2504  data: 0.0001  max mem: 10917
[09:03:43.826303] Epoch: [4]  [140/345]  eta: 0:00:51  lr: 0.000028  loss: 1.1993 (1.2262)  time: 0.2506  data: 0.0001  max mem: 10917
[09:03:48.841475] Epoch: [4]  [160/345]  eta: 0:00:46  lr: 0.000028  loss: 1.2001 (1.2228)  time: 0.2507  data: 0.0000  max mem: 10917
[09:03:53.858933] Epoch: [4]  [180/345]  eta: 0:00:41  lr: 0.000028  loss: 1.1943 (1.2195)  time: 0.2508  data: 0.0001  max mem: 10917
[09:03:58.878431] Epoch: [4]  [200/345]  eta: 0:00:36  lr: 0.000029  loss: 1.1852 (1.2160)  time: 0.2509  data: 0.0000  max mem: 10917
[09:04:03.906703] Epoch: [4]  [220/345]  eta: 0:00:31  lr: 0.000029  loss: 1.1761 (1.2125)  time: 0.2514  data: 0.0000  max mem: 10917
[09:04:08.942829] Epoch: [4]  [240/345]  eta: 0:00:26  lr: 0.000029  loss: 1.1759 (1.2097)  time: 0.2518  data: 0.0000  max mem: 10917
[09:04:13.982986] Epoch: [4]  [260/345]  eta: 0:00:21  lr: 0.000030  loss: 1.1680 (1.2065)  time: 0.2520  data: 0.0000  max mem: 10917
[09:04:19.027719] Epoch: [4]  [280/345]  eta: 0:00:16  lr: 0.000030  loss: 1.1555 (1.2032)  time: 0.2522  data: 0.0000  max mem: 10917
[09:04:24.073958] Epoch: [4]  [300/345]  eta: 0:00:11  lr: 0.000030  loss: 1.1573 (1.2001)  time: 0.2523  data: 0.0000  max mem: 10917
[09:04:29.115868] Epoch: [4]  [320/345]  eta: 0:00:06  lr: 0.000031  loss: 1.1413 (1.1968)  time: 0.2521  data: 0.0000  max mem: 10917
[09:04:34.162900] Epoch: [4]  [340/345]  eta: 0:00:01  lr: 0.000031  loss: 1.1321 (1.1932)  time: 0.2523  data: 0.0000  max mem: 10917
[09:04:35.172316] Epoch: [4]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 1.1321 (1.1925)  time: 0.2522  data: 0.0001  max mem: 10917
[09:04:35.227590] Epoch: [4] Total time: 0:01:26 (0.2516 s / it)
[09:04:35.228083] Averaged stats: lr: 0.000031  loss: 1.1321 (1.1925)
[09:04:35.459712] Test:  [  0/345]  eta: 0:01:18  loss: 1.1236 (1.1236)  time: 0.2278  data: 0.1486  max mem: 10917
[09:04:36.302176] Test:  [ 10/345]  eta: 0:00:32  loss: 1.1189 (1.1222)  time: 0.0972  data: 0.0157  max mem: 10917
[09:04:37.125377] Test:  [ 20/345]  eta: 0:00:29  loss: 1.1243 (1.1241)  time: 0.0832  data: 0.0012  max mem: 10917
[09:04:37.952328] Test:  [ 30/345]  eta: 0:00:27  loss: 1.1278 (1.1232)  time: 0.0824  data: 0.0001  max mem: 10917
[09:04:38.782684] Test:  [ 40/345]  eta: 0:00:26  loss: 1.1192 (1.1202)  time: 0.0828  data: 0.0001  max mem: 10917
[09:04:39.616868] Test:  [ 50/345]  eta: 0:00:25  loss: 1.1192 (1.1207)  time: 0.0832  data: 0.0001  max mem: 10917
[09:04:40.454215] Test:  [ 60/345]  eta: 0:00:24  loss: 1.1213 (1.1218)  time: 0.0835  data: 0.0001  max mem: 10917
[09:04:41.295173] Test:  [ 70/345]  eta: 0:00:23  loss: 1.1213 (1.1219)  time: 0.0839  data: 0.0001  max mem: 10917
[09:04:42.139984] Test:  [ 80/345]  eta: 0:00:22  loss: 1.1142 (1.1212)  time: 0.0842  data: 0.0001  max mem: 10917
[09:04:42.988015] Test:  [ 90/345]  eta: 0:00:21  loss: 1.1167 (1.1223)  time: 0.0846  data: 0.0001  max mem: 10917
[09:04:43.839926] Test:  [100/345]  eta: 0:00:20  loss: 1.1207 (1.1215)  time: 0.0850  data: 0.0001  max mem: 10917
[09:04:44.695835] Test:  [110/345]  eta: 0:00:20  loss: 1.1185 (1.1215)  time: 0.0853  data: 0.0001  max mem: 10917
[09:04:45.554053] Test:  [120/345]  eta: 0:00:19  loss: 1.1227 (1.1214)  time: 0.0857  data: 0.0001  max mem: 10917
[09:04:46.416148] Test:  [130/345]  eta: 0:00:18  loss: 1.1157 (1.1214)  time: 0.0860  data: 0.0001  max mem: 10917
[09:04:47.282252] Test:  [140/345]  eta: 0:00:17  loss: 1.1178 (1.1218)  time: 0.0864  data: 0.0001  max mem: 10917
[09:04:48.151355] Test:  [150/345]  eta: 0:00:16  loss: 1.1196 (1.1218)  time: 0.0867  data: 0.0001  max mem: 10917
[09:04:49.024463] Test:  [160/345]  eta: 0:00:15  loss: 1.1178 (1.1214)  time: 0.0871  data: 0.0001  max mem: 10917
[09:04:49.900842] Test:  [170/345]  eta: 0:00:15  loss: 1.1178 (1.1214)  time: 0.0874  data: 0.0001  max mem: 10917
[09:04:50.781703] Test:  [180/345]  eta: 0:00:14  loss: 1.1222 (1.1216)  time: 0.0878  data: 0.0001  max mem: 10917
[09:04:51.665000] Test:  [190/345]  eta: 0:00:13  loss: 1.1144 (1.1211)  time: 0.0882  data: 0.0001  max mem: 10917
[09:04:52.553012] Test:  [200/345]  eta: 0:00:12  loss: 1.1188 (1.1212)  time: 0.0885  data: 0.0001  max mem: 10917
[09:04:53.443940] Test:  [210/345]  eta: 0:00:11  loss: 1.1229 (1.1215)  time: 0.0889  data: 0.0001  max mem: 10917
[09:04:54.337887] Test:  [220/345]  eta: 0:00:10  loss: 1.1229 (1.1214)  time: 0.0892  data: 0.0001  max mem: 10917
[09:04:55.235889] Test:  [230/345]  eta: 0:00:09  loss: 1.1229 (1.1216)  time: 0.0895  data: 0.0001  max mem: 10917
[09:04:56.137941] Test:  [240/345]  eta: 0:00:09  loss: 1.1179 (1.1216)  time: 0.0900  data: 0.0001  max mem: 10917
[09:04:57.042178] Test:  [250/345]  eta: 0:00:08  loss: 1.1307 (1.1221)  time: 0.0903  data: 0.0001  max mem: 10917
[09:04:57.950777] Test:  [260/345]  eta: 0:00:07  loss: 1.1308 (1.1220)  time: 0.0906  data: 0.0001  max mem: 10917
[09:04:58.863326] Test:  [270/345]  eta: 0:00:06  loss: 1.1190 (1.1219)  time: 0.0910  data: 0.0001  max mem: 10917
[09:04:59.778312] Test:  [280/345]  eta: 0:00:05  loss: 1.1190 (1.1217)  time: 0.0913  data: 0.0001  max mem: 10917
[09:05:00.697454] Test:  [290/345]  eta: 0:00:04  loss: 1.1221 (1.1216)  time: 0.0917  data: 0.0001  max mem: 10917
[09:05:01.619762] Test:  [300/345]  eta: 0:00:03  loss: 1.1302 (1.1217)  time: 0.0920  data: 0.0001  max mem: 10917
[09:05:02.545373] Test:  [310/345]  eta: 0:00:03  loss: 1.1321 (1.1219)  time: 0.0923  data: 0.0001  max mem: 10917
[09:05:03.474270] Test:  [320/345]  eta: 0:00:02  loss: 1.1236 (1.1217)  time: 0.0927  data: 0.0001  max mem: 10917
[09:05:04.407142] Test:  [330/345]  eta: 0:00:01  loss: 1.1203 (1.1218)  time: 0.0930  data: 0.0001  max mem: 10917
[09:05:05.342360] Test:  [340/345]  eta: 0:00:00  loss: 1.1193 (1.1218)  time: 0.0934  data: 0.0001  max mem: 10917
[09:05:05.718164] Test:  [344/345]  eta: 0:00:00  loss: 1.1126 (1.1218)  time: 0.0935  data: 0.0001  max mem: 10917
[09:05:05.755753] Test: Total time: 0:00:30 (0.0885 s / it)
[09:05:16.221673] Test:  [ 0/57]  eta: 0:00:12  loss: 1.1866 (1.1866)  time: 0.2254  data: 0.1454  max mem: 10917
[09:05:17.033235] Test:  [10/57]  eta: 0:00:04  loss: 1.1843 (1.1616)  time: 0.0942  data: 0.0133  max mem: 10917
[09:05:17.849595] Test:  [20/57]  eta: 0:00:03  loss: 1.1786 (1.1601)  time: 0.0813  data: 0.0001  max mem: 10917
[09:05:18.669446] Test:  [30/57]  eta: 0:00:02  loss: 1.1009 (1.1212)  time: 0.0818  data: 0.0001  max mem: 10917
[09:05:19.492842] Test:  [40/57]  eta: 0:00:01  loss: 1.0149 (1.0959)  time: 0.0821  data: 0.0001  max mem: 10917
[09:05:20.321079] Test:  [50/57]  eta: 0:00:00  loss: 1.0269 (1.0872)  time: 0.0825  data: 0.0001  max mem: 10917
[09:05:20.770737] Test:  [56/57]  eta: 0:00:00  loss: 1.0604 (1.0898)  time: 0.0803  data: 0.0001  max mem: 10917
[09:05:20.830429] Test: Total time: 0:00:04 (0.0848 s / it)
[09:05:22.608223] Dice score of the network on the train images: 0.618383, val images: 0.679092
[09:05:22.608438] saving best_rec_model_0 @ epoch 4
[09:05:23.441417] saving best_dice_model_0 @ epoch 4
[09:05:24.232038] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:05:24.631312] Epoch: [5]  [  0/345]  eta: 0:02:17  lr: 0.000031  loss: 1.1239 (1.1239)  time: 0.3981  data: 0.1447  max mem: 10917
[09:05:29.631718] Epoch: [5]  [ 20/345]  eta: 0:01:23  lr: 0.000032  loss: 1.1284 (1.1335)  time: 0.2500  data: 0.0000  max mem: 10917
[09:05:34.634450] Epoch: [5]  [ 40/345]  eta: 0:01:17  lr: 0.000032  loss: 1.1288 (1.1291)  time: 0.2501  data: 0.0000  max mem: 10917
[09:05:39.642939] Epoch: [5]  [ 60/345]  eta: 0:01:11  lr: 0.000032  loss: 1.1181 (1.1261)  time: 0.2504  data: 0.0000  max mem: 10917
[09:05:44.654775] Epoch: [5]  [ 80/345]  eta: 0:01:06  lr: 0.000033  loss: 1.1181 (1.1239)  time: 0.2505  data: 0.0000  max mem: 10917
[09:05:49.672453] Epoch: [5]  [100/345]  eta: 0:01:01  lr: 0.000033  loss: 1.0945 (1.1183)  time: 0.2508  data: 0.0000  max mem: 10917
[09:05:54.699141] Epoch: [5]  [120/345]  eta: 0:00:56  lr: 0.000033  loss: 1.1090 (1.1159)  time: 0.2513  data: 0.0001  max mem: 10917
[09:05:59.727495] Epoch: [5]  [140/345]  eta: 0:00:51  lr: 0.000034  loss: 1.0901 (1.1129)  time: 0.2514  data: 0.0000  max mem: 10917
[09:06:04.744808] Epoch: [5]  [160/345]  eta: 0:00:46  lr: 0.000034  loss: 1.0965 (1.1111)  time: 0.2508  data: 0.0001  max mem: 10917
[09:06:09.765844] Epoch: [5]  [180/345]  eta: 0:00:41  lr: 0.000035  loss: 1.0752 (1.1072)  time: 0.2510  data: 0.0001  max mem: 10917
[09:06:14.798494] Epoch: [5]  [200/345]  eta: 0:00:36  lr: 0.000035  loss: 1.0716 (1.1039)  time: 0.2516  data: 0.0001  max mem: 10917
[09:06:19.833803] Epoch: [5]  [220/345]  eta: 0:00:31  lr: 0.000035  loss: 1.0843 (1.1017)  time: 0.2517  data: 0.0001  max mem: 10917
[09:06:24.872875] Epoch: [5]  [240/345]  eta: 0:00:26  lr: 0.000036  loss: 1.0584 (1.0985)  time: 0.2519  data: 0.0000  max mem: 10917
[09:06:29.913562] Epoch: [5]  [260/345]  eta: 0:00:21  lr: 0.000036  loss: 1.0508 (1.0947)  time: 0.2520  data: 0.0000  max mem: 10917
[09:06:34.961869] Epoch: [5]  [280/345]  eta: 0:00:16  lr: 0.000036  loss: 1.0350 (1.0903)  time: 0.2524  data: 0.0000  max mem: 10917
[09:06:40.010731] Epoch: [5]  [300/345]  eta: 0:00:11  lr: 0.000037  loss: 1.0282 (1.0866)  time: 0.2524  data: 0.0001  max mem: 10917
[09:06:45.058909] Epoch: [5]  [320/345]  eta: 0:00:06  lr: 0.000037  loss: 1.0281 (1.0831)  time: 0.2524  data: 0.0000  max mem: 10917
[09:06:50.108909] Epoch: [5]  [340/345]  eta: 0:00:01  lr: 0.000037  loss: 1.0256 (1.0798)  time: 0.2525  data: 0.0000  max mem: 10917
[09:06:51.118731] Epoch: [5]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 1.0266 (1.0792)  time: 0.2524  data: 0.0001  max mem: 10917
[09:06:51.174416] Epoch: [5] Total time: 0:01:26 (0.2520 s / it)
[09:06:51.174825] Averaged stats: lr: 0.000037  loss: 1.0266 (1.0792)
[09:06:51.406567] Test:  [  0/345]  eta: 0:01:18  loss: 1.0214 (1.0214)  time: 0.2281  data: 0.1481  max mem: 10917
[09:06:52.240750] Test:  [ 10/345]  eta: 0:00:32  loss: 1.0114 (1.0135)  time: 0.0965  data: 0.0149  max mem: 10917
[09:06:53.071090] Test:  [ 20/345]  eta: 0:00:29  loss: 1.0164 (1.0179)  time: 0.0832  data: 0.0011  max mem: 10917
[09:06:53.897449] Test:  [ 30/345]  eta: 0:00:27  loss: 1.0164 (1.0188)  time: 0.0828  data: 0.0004  max mem: 10917
[09:06:54.728232] Test:  [ 40/345]  eta: 0:00:26  loss: 1.0085 (1.0163)  time: 0.0828  data: 0.0001  max mem: 10917
[09:06:55.561784] Test:  [ 50/345]  eta: 0:00:25  loss: 1.0149 (1.0183)  time: 0.0832  data: 0.0001  max mem: 10917
[09:06:56.399677] Test:  [ 60/345]  eta: 0:00:24  loss: 1.0282 (1.0171)  time: 0.0835  data: 0.0001  max mem: 10917
[09:06:57.240421] Test:  [ 70/345]  eta: 0:00:23  loss: 1.0193 (1.0165)  time: 0.0839  data: 0.0001  max mem: 10917
[09:06:58.084864] Test:  [ 80/345]  eta: 0:00:22  loss: 1.0095 (1.0157)  time: 0.0842  data: 0.0001  max mem: 10917
[09:06:58.932781] Test:  [ 90/345]  eta: 0:00:21  loss: 1.0165 (1.0157)  time: 0.0846  data: 0.0001  max mem: 10917
[09:06:59.783359] Test:  [100/345]  eta: 0:00:20  loss: 1.0165 (1.0160)  time: 0.0849  data: 0.0001  max mem: 10917
[09:07:00.638464] Test:  [110/345]  eta: 0:00:20  loss: 1.0119 (1.0163)  time: 0.0852  data: 0.0001  max mem: 10917
[09:07:01.497322] Test:  [120/345]  eta: 0:00:19  loss: 1.0121 (1.0159)  time: 0.0856  data: 0.0001  max mem: 10917
[09:07:02.358900] Test:  [130/345]  eta: 0:00:18  loss: 1.0078 (1.0144)  time: 0.0860  data: 0.0001  max mem: 10917
[09:07:03.224613] Test:  [140/345]  eta: 0:00:17  loss: 0.9958 (1.0126)  time: 0.0863  data: 0.0001  max mem: 10917
[09:07:04.094306] Test:  [150/345]  eta: 0:00:16  loss: 1.0090 (1.0136)  time: 0.0867  data: 0.0001  max mem: 10917
[09:07:04.966517] Test:  [160/345]  eta: 0:00:15  loss: 1.0102 (1.0133)  time: 0.0870  data: 0.0001  max mem: 10917
[09:07:05.842405] Test:  [170/345]  eta: 0:00:14  loss: 1.0043 (1.0129)  time: 0.0874  data: 0.0001  max mem: 10917
[09:07:06.722132] Test:  [180/345]  eta: 0:00:14  loss: 1.0060 (1.0132)  time: 0.0877  data: 0.0001  max mem: 10917
[09:07:07.604966] Test:  [190/345]  eta: 0:00:13  loss: 1.0062 (1.0129)  time: 0.0881  data: 0.0001  max mem: 10917
[09:07:08.491909] Test:  [200/345]  eta: 0:00:12  loss: 1.0092 (1.0129)  time: 0.0884  data: 0.0001  max mem: 10917
[09:07:09.382487] Test:  [210/345]  eta: 0:00:11  loss: 1.0092 (1.0126)  time: 0.0888  data: 0.0001  max mem: 10917
[09:07:10.276862] Test:  [220/345]  eta: 0:00:10  loss: 1.0074 (1.0126)  time: 0.0892  data: 0.0001  max mem: 10917
[09:07:11.174129] Test:  [230/345]  eta: 0:00:09  loss: 1.0062 (1.0119)  time: 0.0895  data: 0.0001  max mem: 10917
[09:07:12.074701] Test:  [240/345]  eta: 0:00:09  loss: 1.0096 (1.0120)  time: 0.0898  data: 0.0001  max mem: 10917
[09:07:12.978819] Test:  [250/345]  eta: 0:00:08  loss: 1.0136 (1.0124)  time: 0.0902  data: 0.0001  max mem: 10917
[09:07:13.886634] Test:  [260/345]  eta: 0:00:07  loss: 1.0017 (1.0118)  time: 0.0906  data: 0.0001  max mem: 10917
[09:07:14.798842] Test:  [270/345]  eta: 0:00:06  loss: 1.0067 (1.0121)  time: 0.0910  data: 0.0001  max mem: 10917
[09:07:15.714086] Test:  [280/345]  eta: 0:00:05  loss: 1.0174 (1.0123)  time: 0.0913  data: 0.0001  max mem: 10917
[09:07:16.632114] Test:  [290/345]  eta: 0:00:04  loss: 1.0202 (1.0119)  time: 0.0916  data: 0.0001  max mem: 10917
[09:07:17.554519] Test:  [300/345]  eta: 0:00:03  loss: 0.9914 (1.0112)  time: 0.0920  data: 0.0001  max mem: 10917
[09:07:18.479622] Test:  [310/345]  eta: 0:00:03  loss: 1.0052 (1.0115)  time: 0.0923  data: 0.0001  max mem: 10917
[09:07:19.408281] Test:  [320/345]  eta: 0:00:02  loss: 1.0121 (1.0110)  time: 0.0926  data: 0.0001  max mem: 10917
[09:07:20.340644] Test:  [330/345]  eta: 0:00:01  loss: 1.0000 (1.0109)  time: 0.0930  data: 0.0001  max mem: 10917
[09:07:21.275991] Test:  [340/345]  eta: 0:00:00  loss: 1.0150 (1.0111)  time: 0.0933  data: 0.0001  max mem: 10917
[09:07:21.651098] Test:  [344/345]  eta: 0:00:00  loss: 1.0134 (1.0110)  time: 0.0935  data: 0.0001  max mem: 10917
[09:07:21.706462] Test: Total time: 0:00:30 (0.0885 s / it)
[09:07:32.203181] Test:  [ 0/57]  eta: 0:00:12  loss: 1.0801 (1.0801)  time: 0.2189  data: 0.1387  max mem: 10917
[09:07:33.016966] Test:  [10/57]  eta: 0:00:04  loss: 1.0729 (1.0545)  time: 0.0938  data: 0.0127  max mem: 10917
[09:07:33.833101] Test:  [20/57]  eta: 0:00:03  loss: 1.0579 (1.0535)  time: 0.0814  data: 0.0001  max mem: 10917
[09:07:34.653808] Test:  [30/57]  eta: 0:00:02  loss: 0.9946 (1.0092)  time: 0.0818  data: 0.0001  max mem: 10917
[09:07:35.478536] Test:  [40/57]  eta: 0:00:01  loss: 0.8961 (0.9809)  time: 0.0822  data: 0.0001  max mem: 10917
[09:07:36.305913] Test:  [50/57]  eta: 0:00:00  loss: 0.9164 (0.9706)  time: 0.0826  data: 0.0001  max mem: 10917
[09:07:36.755377] Test:  [56/57]  eta: 0:00:00  loss: 0.9330 (0.9732)  time: 0.0803  data: 0.0001  max mem: 10917
[09:07:36.809557] Test: Total time: 0:00:04 (0.0847 s / it)
[09:07:38.605881] Dice score of the network on the train images: 0.658783, val images: 0.733092
[09:07:38.606086] saving best_rec_model_0 @ epoch 5
[09:07:39.543349] saving best_dice_model_0 @ epoch 5
[09:07:40.338904] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:07:40.733399] Epoch: [6]  [  0/345]  eta: 0:02:15  lr: 0.000038  loss: 1.0135 (1.0135)  time: 0.3932  data: 0.1402  max mem: 10917
[09:07:45.729330] Epoch: [6]  [ 20/345]  eta: 0:01:23  lr: 0.000038  loss: 1.0197 (1.0161)  time: 0.2497  data: 0.0001  max mem: 10917
[09:07:50.723664] Epoch: [6]  [ 40/345]  eta: 0:01:17  lr: 0.000038  loss: 1.0107 (1.0140)  time: 0.2497  data: 0.0001  max mem: 10917
[09:07:55.720287] Epoch: [6]  [ 60/345]  eta: 0:01:11  lr: 0.000039  loss: 1.0020 (1.0127)  time: 0.2498  data: 0.0001  max mem: 10917
[09:08:00.728873] Epoch: [6]  [ 80/345]  eta: 0:01:06  lr: 0.000039  loss: 0.9902 (1.0075)  time: 0.2504  data: 0.0001  max mem: 10917
[09:08:05.748553] Epoch: [6]  [100/345]  eta: 0:01:01  lr: 0.000039  loss: 0.9886 (1.0040)  time: 0.2509  data: 0.0000  max mem: 10917
[09:08:10.774153] Epoch: [6]  [120/345]  eta: 0:00:56  lr: 0.000040  loss: 0.9802 (1.0013)  time: 0.2512  data: 0.0001  max mem: 10917
[09:08:15.802346] Epoch: [6]  [140/345]  eta: 0:00:51  lr: 0.000040  loss: 0.9783 (0.9984)  time: 0.2514  data: 0.0001  max mem: 10917
[09:08:20.830914] Epoch: [6]  [160/345]  eta: 0:00:46  lr: 0.000040  loss: 0.9762 (0.9963)  time: 0.2514  data: 0.0001  max mem: 10917
[09:08:25.859244] Epoch: [6]  [180/345]  eta: 0:00:41  lr: 0.000041  loss: 0.9713 (0.9941)  time: 0.2514  data: 0.0000  max mem: 10917
[09:08:30.896689] Epoch: [6]  [200/345]  eta: 0:00:36  lr: 0.000041  loss: 0.9584 (0.9909)  time: 0.2518  data: 0.0001  max mem: 10917
[09:08:35.935564] Epoch: [6]  [220/345]  eta: 0:00:31  lr: 0.000041  loss: 0.9586 (0.9883)  time: 0.2519  data: 0.0001  max mem: 10917
[09:08:40.980456] Epoch: [6]  [240/345]  eta: 0:00:26  lr: 0.000042  loss: 0.9441 (0.9848)  time: 0.2522  data: 0.0001  max mem: 10917
[09:08:46.028507] Epoch: [6]  [260/345]  eta: 0:00:21  lr: 0.000042  loss: 0.9584 (0.9826)  time: 0.2524  data: 0.0001  max mem: 10917
[09:08:51.077375] Epoch: [6]  [280/345]  eta: 0:00:16  lr: 0.000043  loss: 0.9445 (0.9800)  time: 0.2524  data: 0.0001  max mem: 10917
[09:08:56.125843] Epoch: [6]  [300/345]  eta: 0:00:11  lr: 0.000043  loss: 0.9473 (0.9778)  time: 0.2524  data: 0.0001  max mem: 10917
[09:09:01.171536] Epoch: [6]  [320/345]  eta: 0:00:06  lr: 0.000043  loss: 0.9363 (0.9750)  time: 0.2522  data: 0.0001  max mem: 10917
[09:09:06.219270] Epoch: [6]  [340/345]  eta: 0:00:01  lr: 0.000044  loss: 0.9212 (0.9723)  time: 0.2523  data: 0.0001  max mem: 10917
[09:09:07.229281] Epoch: [6]  [344/345]  eta: 0:00:00  lr: 0.000044  loss: 0.9197 (0.9719)  time: 0.2524  data: 0.0001  max mem: 10917
[09:09:07.284691] Epoch: [6] Total time: 0:01:26 (0.2520 s / it)
[09:09:07.284885] Averaged stats: lr: 0.000044  loss: 0.9197 (0.9719)
[09:09:07.519976] Test:  [  0/345]  eta: 0:01:19  loss: 0.9166 (0.9166)  time: 0.2313  data: 0.1513  max mem: 10917
[09:09:08.365194] Test:  [ 10/345]  eta: 0:00:32  loss: 0.9111 (0.9105)  time: 0.0978  data: 0.0162  max mem: 10917
[09:09:09.188947] Test:  [ 20/345]  eta: 0:00:29  loss: 0.9064 (0.9063)  time: 0.0834  data: 0.0014  max mem: 10917
[09:09:10.015397] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8986 (0.9062)  time: 0.0825  data: 0.0001  max mem: 10917
[09:09:10.846402] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8979 (0.9056)  time: 0.0828  data: 0.0001  max mem: 10917
[09:09:11.679734] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8988 (0.9080)  time: 0.0831  data: 0.0001  max mem: 10917
[09:09:12.518934] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8993 (0.9084)  time: 0.0835  data: 0.0001  max mem: 10917
[09:09:13.359372] Test:  [ 70/345]  eta: 0:00:23  loss: 0.9018 (0.9072)  time: 0.0838  data: 0.0001  max mem: 10917
[09:09:14.203914] Test:  [ 80/345]  eta: 0:00:22  loss: 0.9049 (0.9075)  time: 0.0842  data: 0.0001  max mem: 10917
[09:09:15.051698] Test:  [ 90/345]  eta: 0:00:21  loss: 0.9170 (0.9099)  time: 0.0846  data: 0.0001  max mem: 10917
[09:09:15.903642] Test:  [100/345]  eta: 0:00:20  loss: 0.9170 (0.9098)  time: 0.0849  data: 0.0001  max mem: 10917
[09:09:16.758822] Test:  [110/345]  eta: 0:00:20  loss: 0.9060 (0.9099)  time: 0.0853  data: 0.0001  max mem: 10917
[09:09:17.618075] Test:  [120/345]  eta: 0:00:19  loss: 0.9118 (0.9103)  time: 0.0856  data: 0.0001  max mem: 10917
[09:09:18.480627] Test:  [130/345]  eta: 0:00:18  loss: 0.9080 (0.9103)  time: 0.0860  data: 0.0001  max mem: 10917
[09:09:19.348069] Test:  [140/345]  eta: 0:00:17  loss: 0.9042 (0.9094)  time: 0.0864  data: 0.0001  max mem: 10917
[09:09:20.217141] Test:  [150/345]  eta: 0:00:16  loss: 0.9151 (0.9111)  time: 0.0868  data: 0.0001  max mem: 10917
[09:09:21.089788] Test:  [160/345]  eta: 0:00:15  loss: 0.9183 (0.9108)  time: 0.0870  data: 0.0001  max mem: 10917
[09:09:21.965518] Test:  [170/345]  eta: 0:00:15  loss: 0.9106 (0.9110)  time: 0.0874  data: 0.0001  max mem: 10917
[09:09:22.846534] Test:  [180/345]  eta: 0:00:14  loss: 0.9147 (0.9115)  time: 0.0878  data: 0.0001  max mem: 10917
[09:09:23.729452] Test:  [190/345]  eta: 0:00:13  loss: 0.9147 (0.9117)  time: 0.0881  data: 0.0001  max mem: 10917
[09:09:24.616242] Test:  [200/345]  eta: 0:00:12  loss: 0.9149 (0.9118)  time: 0.0884  data: 0.0001  max mem: 10917
[09:09:25.507646] Test:  [210/345]  eta: 0:00:11  loss: 0.9082 (0.9114)  time: 0.0889  data: 0.0001  max mem: 10917
[09:09:26.402557] Test:  [220/345]  eta: 0:00:10  loss: 0.8987 (0.9113)  time: 0.0893  data: 0.0001  max mem: 10917
[09:09:27.299434] Test:  [230/345]  eta: 0:00:09  loss: 0.9100 (0.9113)  time: 0.0895  data: 0.0001  max mem: 10917
[09:09:28.200335] Test:  [240/345]  eta: 0:00:09  loss: 0.9137 (0.9114)  time: 0.0898  data: 0.0001  max mem: 10917
[09:09:29.103885] Test:  [250/345]  eta: 0:00:08  loss: 0.9089 (0.9112)  time: 0.0902  data: 0.0001  max mem: 10917
[09:09:30.012231] Test:  [260/345]  eta: 0:00:07  loss: 0.9089 (0.9115)  time: 0.0905  data: 0.0001  max mem: 10917
[09:09:30.924858] Test:  [270/345]  eta: 0:00:06  loss: 0.9198 (0.9116)  time: 0.0910  data: 0.0001  max mem: 10917
[09:09:31.838616] Test:  [280/345]  eta: 0:00:05  loss: 0.9072 (0.9116)  time: 0.0913  data: 0.0001  max mem: 10917
[09:09:32.756957] Test:  [290/345]  eta: 0:00:04  loss: 0.8995 (0.9115)  time: 0.0916  data: 0.0001  max mem: 10917
[09:09:33.679464] Test:  [300/345]  eta: 0:00:03  loss: 0.8998 (0.9113)  time: 0.0920  data: 0.0001  max mem: 10917
[09:09:34.604204] Test:  [310/345]  eta: 0:00:03  loss: 0.9108 (0.9114)  time: 0.0923  data: 0.0001  max mem: 10917
[09:09:35.533378] Test:  [320/345]  eta: 0:00:02  loss: 0.9108 (0.9114)  time: 0.0926  data: 0.0001  max mem: 10917
[09:09:36.465586] Test:  [330/345]  eta: 0:00:01  loss: 0.8998 (0.9114)  time: 0.0930  data: 0.0001  max mem: 10917
[09:09:37.401501] Test:  [340/345]  eta: 0:00:00  loss: 0.9045 (0.9115)  time: 0.0934  data: 0.0001  max mem: 10917
[09:09:37.777608] Test:  [344/345]  eta: 0:00:00  loss: 0.9045 (0.9115)  time: 0.0935  data: 0.0001  max mem: 10917
[09:09:37.835706] Test: Total time: 0:00:30 (0.0885 s / it)
[09:09:48.214471] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9801 (0.9801)  time: 0.2195  data: 0.1396  max mem: 10917
[09:09:49.026795] Test:  [10/57]  eta: 0:00:04  loss: 0.9727 (0.9665)  time: 0.0937  data: 0.0128  max mem: 10917
[09:09:49.843124] Test:  [20/57]  eta: 0:00:03  loss: 0.9578 (0.9643)  time: 0.0814  data: 0.0001  max mem: 10917
[09:09:50.664154] Test:  [30/57]  eta: 0:00:02  loss: 0.8941 (0.9284)  time: 0.0818  data: 0.0001  max mem: 10917
[09:09:51.487840] Test:  [40/57]  eta: 0:00:01  loss: 0.8381 (0.9071)  time: 0.0822  data: 0.0001  max mem: 10917
[09:09:52.315927] Test:  [50/57]  eta: 0:00:00  loss: 0.8351 (0.8997)  time: 0.0825  data: 0.0001  max mem: 10917
[09:09:52.765772] Test:  [56/57]  eta: 0:00:00  loss: 0.8668 (0.9026)  time: 0.0803  data: 0.0001  max mem: 10917
[09:09:52.806471] Test: Total time: 0:00:04 (0.0844 s / it)
[09:09:54.588647] Dice score of the network on the train images: 0.730074, val images: 0.736258
[09:09:54.588867] saving best_dice_model_0 @ epoch 6
[09:09:55.441547] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:09:55.834505] Epoch: [7]  [  0/345]  eta: 0:02:15  lr: 0.000044  loss: 0.8901 (0.8901)  time: 0.3918  data: 0.1399  max mem: 10917
[09:10:00.823598] Epoch: [7]  [ 20/345]  eta: 0:01:23  lr: 0.000044  loss: 0.9366 (0.9354)  time: 0.2494  data: 0.0001  max mem: 10917
[09:10:05.820252] Epoch: [7]  [ 40/345]  eta: 0:01:17  lr: 0.000044  loss: 0.9320 (0.9348)  time: 0.2498  data: 0.0001  max mem: 10917
[09:10:10.822258] Epoch: [7]  [ 60/345]  eta: 0:01:11  lr: 0.000045  loss: 0.9185 (0.9329)  time: 0.2501  data: 0.0001  max mem: 10917
[09:10:15.824267] Epoch: [7]  [ 80/345]  eta: 0:01:06  lr: 0.000045  loss: 0.9145 (0.9291)  time: 0.2501  data: 0.0001  max mem: 10917
[09:10:20.842481] Epoch: [7]  [100/345]  eta: 0:01:01  lr: 0.000046  loss: 0.9051 (0.9250)  time: 0.2509  data: 0.0001  max mem: 10917
[09:10:25.855304] Epoch: [7]  [120/345]  eta: 0:00:56  lr: 0.000046  loss: 0.9014 (0.9222)  time: 0.2506  data: 0.0000  max mem: 10917
[09:10:30.867629] Epoch: [7]  [140/345]  eta: 0:00:51  lr: 0.000046  loss: 0.9111 (0.9209)  time: 0.2506  data: 0.0000  max mem: 10917
[09:10:35.888963] Epoch: [7]  [160/345]  eta: 0:00:46  lr: 0.000047  loss: 0.9126 (0.9196)  time: 0.2510  data: 0.0000  max mem: 10917
[09:10:40.907561] Epoch: [7]  [180/345]  eta: 0:00:41  lr: 0.000047  loss: 0.9127 (0.9194)  time: 0.2509  data: 0.0001  max mem: 10917
[09:10:45.924752] Epoch: [7]  [200/345]  eta: 0:00:36  lr: 0.000047  loss: 0.9096 (0.9185)  time: 0.2508  data: 0.0000  max mem: 10917
[09:10:50.947056] Epoch: [7]  [220/345]  eta: 0:00:31  lr: 0.000048  loss: 0.9100 (0.9180)  time: 0.2511  data: 0.0000  max mem: 10917
[09:10:55.985807] Epoch: [7]  [240/345]  eta: 0:00:26  lr: 0.000048  loss: 0.8986 (0.9168)  time: 0.2519  data: 0.0000  max mem: 10917
[09:11:01.031764] Epoch: [7]  [260/345]  eta: 0:00:21  lr: 0.000048  loss: 0.8944 (0.9155)  time: 0.2523  data: 0.0000  max mem: 10917
[09:11:06.078588] Epoch: [7]  [280/345]  eta: 0:00:16  lr: 0.000049  loss: 0.8844 (0.9136)  time: 0.2523  data: 0.0000  max mem: 10917
[09:11:11.124765] Epoch: [7]  [300/345]  eta: 0:00:11  lr: 0.000049  loss: 0.8991 (0.9128)  time: 0.2523  data: 0.0001  max mem: 10917
[09:11:16.162137] Epoch: [7]  [320/345]  eta: 0:00:06  lr: 0.000050  loss: 0.8979 (0.9116)  time: 0.2518  data: 0.0001  max mem: 10917
[09:11:21.205658] Epoch: [7]  [340/345]  eta: 0:00:01  lr: 0.000050  loss: 0.8930 (0.9106)  time: 0.2521  data: 0.0001  max mem: 10917
[09:11:22.214718] Epoch: [7]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.8945 (0.9103)  time: 0.2522  data: 0.0001  max mem: 10917
[09:11:22.271759] Epoch: [7] Total time: 0:01:26 (0.2517 s / it)
[09:11:22.272248] Averaged stats: lr: 0.000050  loss: 0.8945 (0.9103)
[09:11:22.506182] Test:  [  0/345]  eta: 0:01:19  loss: 0.8550 (0.8550)  time: 0.2297  data: 0.1497  max mem: 10917
[09:11:23.399116] Test:  [ 10/345]  eta: 0:00:34  loss: 0.8550 (0.8600)  time: 0.1020  data: 0.0206  max mem: 10917
[09:11:24.266819] Test:  [ 20/345]  eta: 0:00:30  loss: 0.8586 (0.8568)  time: 0.0880  data: 0.0062  max mem: 10917
[09:11:25.093508] Test:  [ 30/345]  eta: 0:00:28  loss: 0.8516 (0.8569)  time: 0.0847  data: 0.0024  max mem: 10917
[09:11:25.924773] Test:  [ 40/345]  eta: 0:00:27  loss: 0.8516 (0.8599)  time: 0.0828  data: 0.0001  max mem: 10917
[09:11:26.758663] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8541 (0.8580)  time: 0.0832  data: 0.0001  max mem: 10917
[09:11:27.596762] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8626 (0.8595)  time: 0.0835  data: 0.0001  max mem: 10917
[09:11:28.437750] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8653 (0.8606)  time: 0.0839  data: 0.0001  max mem: 10917
[09:11:29.282070] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8547 (0.8607)  time: 0.0842  data: 0.0001  max mem: 10917
[09:11:30.130130] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8616 (0.8622)  time: 0.0846  data: 0.0001  max mem: 10917
[09:11:30.981312] Test:  [100/345]  eta: 0:00:21  loss: 0.8672 (0.8626)  time: 0.0849  data: 0.0001  max mem: 10917
[09:11:31.836655] Test:  [110/345]  eta: 0:00:20  loss: 0.8649 (0.8632)  time: 0.0853  data: 0.0001  max mem: 10917
[09:11:32.696087] Test:  [120/345]  eta: 0:00:19  loss: 0.8663 (0.8630)  time: 0.0857  data: 0.0001  max mem: 10917
[09:11:33.558292] Test:  [130/345]  eta: 0:00:18  loss: 0.8702 (0.8636)  time: 0.0860  data: 0.0001  max mem: 10917
[09:11:34.424738] Test:  [140/345]  eta: 0:00:17  loss: 0.8615 (0.8639)  time: 0.0864  data: 0.0001  max mem: 10917
[09:11:35.293535] Test:  [150/345]  eta: 0:00:16  loss: 0.8605 (0.8641)  time: 0.0867  data: 0.0001  max mem: 10917
[09:11:36.165750] Test:  [160/345]  eta: 0:00:15  loss: 0.8576 (0.8635)  time: 0.0870  data: 0.0001  max mem: 10917
[09:11:37.043226] Test:  [170/345]  eta: 0:00:15  loss: 0.8592 (0.8637)  time: 0.0874  data: 0.0001  max mem: 10917
[09:11:37.923360] Test:  [180/345]  eta: 0:00:14  loss: 0.8574 (0.8635)  time: 0.0878  data: 0.0001  max mem: 10917
[09:11:38.805941] Test:  [190/345]  eta: 0:00:13  loss: 0.8644 (0.8639)  time: 0.0881  data: 0.0001  max mem: 10917
[09:11:39.692425] Test:  [200/345]  eta: 0:00:12  loss: 0.8690 (0.8640)  time: 0.0884  data: 0.0001  max mem: 10917
[09:11:40.583422] Test:  [210/345]  eta: 0:00:11  loss: 0.8644 (0.8633)  time: 0.0888  data: 0.0001  max mem: 10917
[09:11:41.476224] Test:  [220/345]  eta: 0:00:10  loss: 0.8554 (0.8637)  time: 0.0891  data: 0.0001  max mem: 10917
[09:11:42.373814] Test:  [230/345]  eta: 0:00:09  loss: 0.8712 (0.8640)  time: 0.0895  data: 0.0001  max mem: 10917
[09:11:43.275615] Test:  [240/345]  eta: 0:00:09  loss: 0.8620 (0.8637)  time: 0.0899  data: 0.0001  max mem: 10917
[09:11:44.179770] Test:  [250/345]  eta: 0:00:08  loss: 0.8627 (0.8642)  time: 0.0903  data: 0.0001  max mem: 10917
[09:11:45.087610] Test:  [260/345]  eta: 0:00:07  loss: 0.8725 (0.8646)  time: 0.0906  data: 0.0001  max mem: 10917
[09:11:45.999775] Test:  [270/345]  eta: 0:00:06  loss: 0.8768 (0.8647)  time: 0.0910  data: 0.0001  max mem: 10917
[09:11:46.914868] Test:  [280/345]  eta: 0:00:05  loss: 0.8609 (0.8642)  time: 0.0913  data: 0.0001  max mem: 10917
[09:11:47.835665] Test:  [290/345]  eta: 0:00:04  loss: 0.8564 (0.8640)  time: 0.0917  data: 0.0001  max mem: 10917
[09:11:48.757113] Test:  [300/345]  eta: 0:00:03  loss: 0.8627 (0.8643)  time: 0.0920  data: 0.0001  max mem: 10917
[09:11:49.683659] Test:  [310/345]  eta: 0:00:03  loss: 0.8710 (0.8645)  time: 0.0924  data: 0.0001  max mem: 10917
[09:11:50.612249] Test:  [320/345]  eta: 0:00:02  loss: 0.8811 (0.8650)  time: 0.0927  data: 0.0001  max mem: 10917
[09:11:51.545263] Test:  [330/345]  eta: 0:00:01  loss: 0.8597 (0.8644)  time: 0.0930  data: 0.0001  max mem: 10917
[09:11:52.480624] Test:  [340/345]  eta: 0:00:00  loss: 0.8597 (0.8649)  time: 0.0934  data: 0.0001  max mem: 10917
[09:11:52.856576] Test:  [344/345]  eta: 0:00:00  loss: 0.8597 (0.8650)  time: 0.0935  data: 0.0001  max mem: 10917
[09:11:52.908647] Test: Total time: 0:00:30 (0.0888 s / it)
[09:12:03.284012] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9282 (0.9282)  time: 0.2196  data: 0.1400  max mem: 10917
[09:12:04.096348] Test:  [10/57]  eta: 0:00:04  loss: 0.8990 (0.9202)  time: 0.0937  data: 0.0128  max mem: 10917
[09:12:04.913876] Test:  [20/57]  eta: 0:00:03  loss: 0.9131 (0.9175)  time: 0.0814  data: 0.0001  max mem: 10917
[09:12:05.735061] Test:  [30/57]  eta: 0:00:02  loss: 0.8354 (0.8783)  time: 0.0819  data: 0.0001  max mem: 10917
[09:12:06.559259] Test:  [40/57]  eta: 0:00:01  loss: 0.7892 (0.8538)  time: 0.0822  data: 0.0001  max mem: 10917
[09:12:07.388168] Test:  [50/57]  eta: 0:00:00  loss: 0.7911 (0.8459)  time: 0.0826  data: 0.0001  max mem: 10917
[09:12:07.838010] Test:  [56/57]  eta: 0:00:00  loss: 0.8287 (0.8499)  time: 0.0804  data: 0.0001  max mem: 10917
[09:12:07.892502] Test: Total time: 0:00:04 (0.0847 s / it)
[09:12:09.622694] Dice score of the network on the train images: 0.722955, val images: 0.794163
[09:12:09.622904] saving best_rec_model_0 @ epoch 7
[09:12:10.482070] saving best_dice_model_0 @ epoch 7
[09:12:11.395657] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:12:11.789696] Epoch: [8]  [  0/345]  eta: 0:02:15  lr: 0.000050  loss: 0.8725 (0.8725)  time: 0.3928  data: 0.1418  max mem: 10917
[09:12:16.776852] Epoch: [8]  [ 20/345]  eta: 0:01:23  lr: 0.000050  loss: 0.8885 (0.8894)  time: 0.2493  data: 0.0001  max mem: 10917
[09:12:21.786790] Epoch: [8]  [ 40/345]  eta: 0:01:17  lr: 0.000051  loss: 0.8950 (0.8932)  time: 0.2504  data: 0.0001  max mem: 10917
[09:12:26.802240] Epoch: [8]  [ 60/345]  eta: 0:01:11  lr: 0.000051  loss: 0.8956 (0.8919)  time: 0.2507  data: 0.0001  max mem: 10917
[09:12:31.820993] Epoch: [8]  [ 80/345]  eta: 0:01:06  lr: 0.000051  loss: 0.8808 (0.8903)  time: 0.2509  data: 0.0001  max mem: 10917
[09:12:36.843864] Epoch: [8]  [100/345]  eta: 0:01:01  lr: 0.000052  loss: 0.8811 (0.8887)  time: 0.2511  data: 0.0001  max mem: 10917
[09:12:41.873138] Epoch: [8]  [120/345]  eta: 0:00:56  lr: 0.000052  loss: 0.8922 (0.8887)  time: 0.2514  data: 0.0001  max mem: 10917
[09:12:46.904857] Epoch: [8]  [140/345]  eta: 0:00:51  lr: 0.000053  loss: 0.8758 (0.8878)  time: 0.2515  data: 0.0001  max mem: 10917

[09:12:51.934720] Epoch: [8]  [160/345]  eta: 0:00:46  lr: 0.000053  loss: 0.8908 (0.8874)  time: 0.2514  data: 0.0000  max mem: 10917
[09:12:56.965854] Epoch: [8]  [180/345]  eta: 0:00:41  lr: 0.000053  loss: 0.8671 (0.8857)  time: 0.2515  data: 0.0001  max mem: 10917
[09:13:01.998838] Epoch: [8]  [200/345]  eta: 0:00:36  lr: 0.000054  loss: 0.8771 (0.8853)  time: 0.2516  data: 0.0001  max mem: 10917
[09:13:07.041344] Epoch: [8]  [220/345]  eta: 0:00:31  lr: 0.000054  loss: 0.8911 (0.8858)  time: 0.2521  data: 0.0001  max mem: 10917
[09:13:12.088908] Epoch: [8]  [240/345]  eta: 0:00:26  lr: 0.000054  loss: 0.8666 (0.8843)  time: 0.2523  data: 0.0001  max mem: 10917
[09:13:17.133027] Epoch: [8]  [260/345]  eta: 0:00:21  lr: 0.000055  loss: 0.8703 (0.8835)  time: 0.2522  data: 0.0001  max mem: 10917
[09:13:22.182031] Epoch: [8]  [280/345]  eta: 0:00:16  lr: 0.000055  loss: 0.8668 (0.8826)  time: 0.2524  data: 0.0001  max mem: 10917
[09:13:27.233027] Epoch: [8]  [300/345]  eta: 0:00:11  lr: 0.000055  loss: 0.8672 (0.8820)  time: 0.2525  data: 0.0001  max mem: 10917
[09:13:32.283284] Epoch: [8]  [320/345]  eta: 0:00:06  lr: 0.000056  loss: 0.8891 (0.8820)  time: 0.2525  data: 0.0001  max mem: 10917
[09:13:37.333157] Epoch: [8]  [340/345]  eta: 0:00:01  lr: 0.000056  loss: 0.8707 (0.8812)  time: 0.2524  data: 0.0001  max mem: 10917
[09:13:38.344491] Epoch: [8]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.8698 (0.8811)  time: 0.2525  data: 0.0001  max mem: 10917
[09:13:38.399110] Epoch: [8] Total time: 0:01:27 (0.2522 s / it)
[09:13:38.399540] Averaged stats: lr: 0.000056  loss: 0.8698 (0.8811)
[09:13:38.636030] Test:  [  0/345]  eta: 0:01:20  loss: 0.8978 (0.8978)  time: 0.2329  data: 0.1529  max mem: 10917
[09:13:39.456369] Test:  [ 10/345]  eta: 0:00:32  loss: 0.8451 (0.8444)  time: 0.0957  data: 0.0140  max mem: 10917
[09:13:40.279839] Test:  [ 20/345]  eta: 0:00:29  loss: 0.8383 (0.8399)  time: 0.0821  data: 0.0001  max mem: 10917
[09:13:41.106518] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8286 (0.8366)  time: 0.0825  data: 0.0001  max mem: 10917
[09:13:41.937850] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8302 (0.8372)  time: 0.0828  data: 0.0001  max mem: 10917
[09:13:42.771787] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8316 (0.8375)  time: 0.0832  data: 0.0001  max mem: 10917
[09:13:43.609921] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8307 (0.8357)  time: 0.0836  data: 0.0001  max mem: 10917
[09:13:44.451063] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8296 (0.8362)  time: 0.0839  data: 0.0001  max mem: 10917
[09:13:45.295597] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8318 (0.8374)  time: 0.0842  data: 0.0001  max mem: 10917
[09:13:46.143970] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8326 (0.8380)  time: 0.0846  data: 0.0001  max mem: 10917
[09:13:46.996464] Test:  [100/345]  eta: 0:00:20  loss: 0.8381 (0.8390)  time: 0.0850  data: 0.0001  max mem: 10917
[09:13:47.851185] Test:  [110/345]  eta: 0:00:19  loss: 0.8501 (0.8399)  time: 0.0853  data: 0.0001  max mem: 10917
[09:13:48.710632] Test:  [120/345]  eta: 0:00:19  loss: 0.8526 (0.8410)  time: 0.0857  data: 0.0001  max mem: 10917
[09:13:49.573175] Test:  [130/345]  eta: 0:00:18  loss: 0.8526 (0.8412)  time: 0.0860  data: 0.0001  max mem: 10917
[09:13:50.439594] Test:  [140/345]  eta: 0:00:17  loss: 0.8431 (0.8420)  time: 0.0864  data: 0.0001  max mem: 10917
[09:13:51.308825] Test:  [150/345]  eta: 0:00:16  loss: 0.8431 (0.8423)  time: 0.0867  data: 0.0001  max mem: 10917
[09:13:52.181441] Test:  [160/345]  eta: 0:00:15  loss: 0.8314 (0.8411)  time: 0.0870  data: 0.0001  max mem: 10917
[09:13:53.058022] Test:  [170/345]  eta: 0:00:14  loss: 0.8284 (0.8414)  time: 0.0874  data: 0.0001  max mem: 10917
[09:13:53.938053] Test:  [180/345]  eta: 0:00:14  loss: 0.8444 (0.8414)  time: 0.0878  data: 0.0001  max mem: 10917
[09:13:54.820656] Test:  [190/345]  eta: 0:00:13  loss: 0.8357 (0.8411)  time: 0.0881  data: 0.0001  max mem: 10917
[09:13:55.707691] Test:  [200/345]  eta: 0:00:12  loss: 0.8371 (0.8413)  time: 0.0884  data: 0.0001  max mem: 10917
[09:13:56.598138] Test:  [210/345]  eta: 0:00:11  loss: 0.8420 (0.8414)  time: 0.0888  data: 0.0001  max mem: 10917
[09:13:57.491853] Test:  [220/345]  eta: 0:00:10  loss: 0.8326 (0.8412)  time: 0.0892  data: 0.0001  max mem: 10917
[09:13:58.390575] Test:  [230/345]  eta: 0:00:09  loss: 0.8326 (0.8410)  time: 0.0896  data: 0.0001  max mem: 10917
[09:13:59.292008] Test:  [240/345]  eta: 0:00:09  loss: 0.8425 (0.8412)  time: 0.0900  data: 0.0001  max mem: 10917
[09:14:00.196192] Test:  [250/345]  eta: 0:00:08  loss: 0.8428 (0.8415)  time: 0.0902  data: 0.0001  max mem: 10917
[09:14:01.104911] Test:  [260/345]  eta: 0:00:07  loss: 0.8486 (0.8416)  time: 0.0906  data: 0.0001  max mem: 10917
[09:14:02.016679] Test:  [270/345]  eta: 0:00:06  loss: 0.8497 (0.8421)  time: 0.0910  data: 0.0001  max mem: 10917
[09:14:02.932331] Test:  [280/345]  eta: 0:00:05  loss: 0.8385 (0.8419)  time: 0.0913  data: 0.0001  max mem: 10917
[09:14:03.851204] Test:  [290/345]  eta: 0:00:04  loss: 0.8377 (0.8418)  time: 0.0917  data: 0.0001  max mem: 10917
[09:14:04.773783] Test:  [300/345]  eta: 0:00:03  loss: 0.8430 (0.8418)  time: 0.0920  data: 0.0001  max mem: 10917
[09:14:05.700144] Test:  [310/345]  eta: 0:00:03  loss: 0.8469 (0.8418)  time: 0.0924  data: 0.0001  max mem: 10917
[09:14:06.628870] Test:  [320/345]  eta: 0:00:02  loss: 0.8469 (0.8419)  time: 0.0927  data: 0.0001  max mem: 10917
[09:14:07.561523] Test:  [330/345]  eta: 0:00:01  loss: 0.8365 (0.8416)  time: 0.0930  data: 0.0001  max mem: 10917
[09:14:08.496375] Test:  [340/345]  eta: 0:00:00  loss: 0.8291 (0.8416)  time: 0.0933  data: 0.0001  max mem: 10917
[09:14:08.872371] Test:  [344/345]  eta: 0:00:00  loss: 0.8364 (0.8418)  time: 0.0935  data: 0.0001  max mem: 10917
[09:14:08.928239] Test: Total time: 0:00:30 (0.0885 s / it)
[09:14:19.400728] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9206 (0.9206)  time: 0.2220  data: 0.1421  max mem: 10917
[09:14:20.213266] Test:  [10/57]  eta: 0:00:04  loss: 0.8926 (0.9099)  time: 0.0940  data: 0.0130  max mem: 10917
[09:14:21.029747] Test:  [20/57]  eta: 0:00:03  loss: 0.9003 (0.9060)  time: 0.0814  data: 0.0001  max mem: 10917
[09:14:21.850669] Test:  [30/57]  eta: 0:00:02  loss: 0.8169 (0.8694)  time: 0.0818  data: 0.0001  max mem: 10917
[09:14:22.675097] Test:  [40/57]  eta: 0:00:01  loss: 0.7888 (0.8470)  time: 0.0822  data: 0.0001  max mem: 10917
[09:14:23.503834] Test:  [50/57]  eta: 0:00:00  loss: 0.7926 (0.8392)  time: 0.0826  data: 0.0001  max mem: 10917
[09:14:23.953409] Test:  [56/57]  eta: 0:00:00  loss: 0.8182 (0.8425)  time: 0.0803  data: 0.0001  max mem: 10917
[09:14:24.008655] Test: Total time: 0:00:04 (0.0847 s / it)
[09:14:25.796410] Dice score of the network on the train images: 0.747257, val images: 0.795689
[09:14:25.796639] saving best_dice_model_0 @ epoch 8
[09:14:26.623259] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:14:27.017733] Epoch: [9]  [  0/345]  eta: 0:02:15  lr: 0.000056  loss: 0.8390 (0.8390)  time: 0.3920  data: 0.1388  max mem: 10917
[09:14:32.050441] Epoch: [9]  [ 20/345]  eta: 0:01:23  lr: 0.000057  loss: 0.8662 (0.8673)  time: 0.2516  data: 0.0001  max mem: 10917
[09:14:37.072261] Epoch: [9]  [ 40/345]  eta: 0:01:17  lr: 0.000057  loss: 0.8775 (0.8731)  time: 0.2510  data: 0.0001  max mem: 10917
[09:14:42.063368] Epoch: [9]  [ 60/345]  eta: 0:01:12  lr: 0.000057  loss: 0.8683 (0.8734)  time: 0.2495  data: 0.0001  max mem: 10917
[09:14:47.063662] Epoch: [9]  [ 80/345]  eta: 0:01:06  lr: 0.000058  loss: 0.8604 (0.8719)  time: 0.2500  data: 0.0001  max mem: 10917
[09:14:52.071495] Epoch: [9]  [100/345]  eta: 0:01:01  lr: 0.000058  loss: 0.8572 (0.8697)  time: 0.2503  data: 0.0001  max mem: 10917
[09:14:57.079649] Epoch: [9]  [120/345]  eta: 0:00:56  lr: 0.000058  loss: 0.8566 (0.8684)  time: 0.2504  data: 0.0001  max mem: 10917

[09:15:02.094619] Epoch: [9]  [140/345]  eta: 0:00:51  lr: 0.000059  loss: 0.8550 (0.8666)  time: 0.2507  data: 0.0001  max mem: 10917
[09:15:07.115476] Epoch: [9]  [160/345]  eta: 0:00:46  lr: 0.000059  loss: 0.8759 (0.8678)  time: 0.2510  data: 0.0001  max mem: 10917
[09:15:12.148903] Epoch: [9]  [180/345]  eta: 0:00:41  lr: 0.000060  loss: 0.8631 (0.8676)  time: 0.2516  data: 0.0001  max mem: 10917
[09:15:17.182146] Epoch: [9]  [200/345]  eta: 0:00:36  lr: 0.000060  loss: 0.8439 (0.8655)  time: 0.2516  data: 0.0001  max mem: 10917
[09:15:22.217889] Epoch: [9]  [220/345]  eta: 0:00:31  lr: 0.000060  loss: 0.8518 (0.8643)  time: 0.2517  data: 0.0001  max mem: 10917
[09:15:27.257729] Epoch: [9]  [240/345]  eta: 0:00:26  lr: 0.000061  loss: 0.8527 (0.8638)  time: 0.2519  data: 0.0001  max mem: 10917
[09:15:32.302526] Epoch: [9]  [260/345]  eta: 0:00:21  lr: 0.000061  loss: 0.8758 (0.8649)  time: 0.2522  data: 0.0001  max mem: 10917
[09:15:37.342378] Epoch: [9]  [280/345]  eta: 0:00:16  lr: 0.000061  loss: 0.8580 (0.8644)  time: 0.2519  data: 0.0001  max mem: 10917
[09:15:42.387811] Epoch: [9]  [300/345]  eta: 0:00:11  lr: 0.000062  loss: 0.8525 (0.8641)  time: 0.2522  data: 0.0001  max mem: 10917
[09:15:47.422087] Epoch: [9]  [320/345]  eta: 0:00:06  lr: 0.000062  loss: 0.8498 (0.8641)  time: 0.2517  data: 0.0001  max mem: 10917
[09:15:52.455918] Epoch: [9]  [340/345]  eta: 0:00:01  lr: 0.000062  loss: 0.8501 (0.8635)  time: 0.2516  data: 0.0001  max mem: 10917
[09:15:53.464216] Epoch: [9]  [344/345]  eta: 0:00:00  lr: 0.000062  loss: 0.8474 (0.8633)  time: 0.2517  data: 0.0001  max mem: 10917
[09:15:53.522285] Epoch: [9] Total time: 0:01:26 (0.2519 s / it)
[09:15:53.522622] Averaged stats: lr: 0.000062  loss: 0.8474 (0.8633)
[09:15:53.756558] Test:  [  0/345]  eta: 0:01:19  loss: 0.8406 (0.8406)  time: 0.2312  data: 0.1511  max mem: 10917
[09:15:54.576106] Test:  [ 10/345]  eta: 0:00:31  loss: 0.8221 (0.8228)  time: 0.0954  data: 0.0138  max mem: 10917
[09:15:55.400480] Test:  [ 20/345]  eta: 0:00:28  loss: 0.8222 (0.8261)  time: 0.0821  data: 0.0001  max mem: 10917
[09:15:56.228453] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8287 (0.8256)  time: 0.0826  data: 0.0001  max mem: 10917
[09:15:57.059447] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8292 (0.8273)  time: 0.0829  data: 0.0001  max mem: 10917
[09:15:57.893696] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8290 (0.8268)  time: 0.0832  data: 0.0001  max mem: 10917
[09:15:58.732314] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8151 (0.8243)  time: 0.0836  data: 0.0001  max mem: 10917
[09:15:59.573464] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8111 (0.8237)  time: 0.0839  data: 0.0001  max mem: 10917
[09:16:00.418707] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8182 (0.8239)  time: 0.0843  data: 0.0001  max mem: 10917
[09:16:01.267075] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8354 (0.8248)  time: 0.0846  data: 0.0001  max mem: 10917
[09:16:02.119320] Test:  [100/345]  eta: 0:00:20  loss: 0.8298 (0.8248)  time: 0.0850  data: 0.0001  max mem: 10917
[09:16:02.975207] Test:  [110/345]  eta: 0:00:19  loss: 0.8298 (0.8260)  time: 0.0854  data: 0.0001  max mem: 10917
[09:16:03.835146] Test:  [120/345]  eta: 0:00:19  loss: 0.8255 (0.8253)  time: 0.0857  data: 0.0001  max mem: 10917
[09:16:04.697566] Test:  [130/345]  eta: 0:00:18  loss: 0.8149 (0.8247)  time: 0.0861  data: 0.0001  max mem: 10917
[09:16:05.563736] Test:  [140/345]  eta: 0:00:17  loss: 0.8233 (0.8249)  time: 0.0864  data: 0.0001  max mem: 10917
[09:16:06.435190] Test:  [150/345]  eta: 0:00:16  loss: 0.8321 (0.8253)  time: 0.0868  data: 0.0001  max mem: 10917
[09:16:07.308611] Test:  [160/345]  eta: 0:00:15  loss: 0.8349 (0.8265)  time: 0.0872  data: 0.0001  max mem: 10917
[09:16:08.186540] Test:  [170/345]  eta: 0:00:14  loss: 0.8377 (0.8266)  time: 0.0875  data: 0.0001  max mem: 10917
[09:16:09.067775] Test:  [180/345]  eta: 0:00:14  loss: 0.8242 (0.8264)  time: 0.0879  data: 0.0001  max mem: 10917
[09:16:09.951416] Test:  [190/345]  eta: 0:00:13  loss: 0.8288 (0.8266)  time: 0.0882  data: 0.0001  max mem: 10917
[09:16:10.839216] Test:  [200/345]  eta: 0:00:12  loss: 0.8315 (0.8275)  time: 0.0885  data: 0.0001  max mem: 10917
[09:16:11.729979] Test:  [210/345]  eta: 0:00:11  loss: 0.8165 (0.8264)  time: 0.0889  data: 0.0001  max mem: 10917
[09:16:12.624035] Test:  [220/345]  eta: 0:00:10  loss: 0.8115 (0.8259)  time: 0.0892  data: 0.0001  max mem: 10917
[09:16:13.522351] Test:  [230/345]  eta: 0:00:09  loss: 0.8085 (0.8255)  time: 0.0896  data: 0.0001  max mem: 10917
[09:16:14.424385] Test:  [240/345]  eta: 0:00:09  loss: 0.8175 (0.8256)  time: 0.0900  data: 0.0001  max mem: 10917
[09:16:15.330410] Test:  [250/345]  eta: 0:00:08  loss: 0.8192 (0.8256)  time: 0.0904  data: 0.0001  max mem: 10917
[09:16:16.238856] Test:  [260/345]  eta: 0:00:07  loss: 0.8192 (0.8255)  time: 0.0907  data: 0.0001  max mem: 10917
[09:16:17.150553] Test:  [270/345]  eta: 0:00:06  loss: 0.8265 (0.8257)  time: 0.0910  data: 0.0001  max mem: 10917
[09:16:18.066511] Test:  [280/345]  eta: 0:00:05  loss: 0.8254 (0.8256)  time: 0.0913  data: 0.0001  max mem: 10917
[09:16:18.985549] Test:  [290/345]  eta: 0:00:04  loss: 0.8187 (0.8257)  time: 0.0917  data: 0.0001  max mem: 10917
[09:16:19.907923] Test:  [300/345]  eta: 0:00:03  loss: 0.8381 (0.8263)  time: 0.0920  data: 0.0001  max mem: 10917
[09:16:20.833470] Test:  [310/345]  eta: 0:00:03  loss: 0.8343 (0.8261)  time: 0.0923  data: 0.0001  max mem: 10917
[09:16:21.762997] Test:  [320/345]  eta: 0:00:02  loss: 0.8109 (0.8258)  time: 0.0927  data: 0.0001  max mem: 10917
[09:16:22.695946] Test:  [330/345]  eta: 0:00:01  loss: 0.8216 (0.8260)  time: 0.0931  data: 0.0001  max mem: 10917
[09:16:23.632125] Test:  [340/345]  eta: 0:00:00  loss: 0.8240 (0.8259)  time: 0.0934  data: 0.0001  max mem: 10917
[09:16:24.008081] Test:  [344/345]  eta: 0:00:00  loss: 0.8243 (0.8259)  time: 0.0936  data: 0.0001  max mem: 10917
[09:16:24.046754] Test: Total time: 0:00:30 (0.0885 s / it)
[09:16:34.457295] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9223 (0.9223)  time: 0.2201  data: 0.1403  max mem: 10917
[09:16:35.270060] Test:  [10/57]  eta: 0:00:04  loss: 0.9034 (0.9086)  time: 0.0938  data: 0.0128  max mem: 10917
[09:16:36.087025] Test:  [20/57]  eta: 0:00:03  loss: 0.9018 (0.9003)  time: 0.0814  data: 0.0001  max mem: 10917
[09:16:36.908837] Test:  [30/57]  eta: 0:00:02  loss: 0.7971 (0.8599)  time: 0.0819  data: 0.0001  max mem: 10917
[09:16:37.732023] Test:  [40/57]  eta: 0:00:01  loss: 0.7791 (0.8357)  time: 0.0822  data: 0.0001  max mem: 10917
[09:16:38.560944] Test:  [50/57]  eta: 0:00:00  loss: 0.7807 (0.8279)  time: 0.0826  data: 0.0001  max mem: 10917
[09:16:39.010563] Test:  [56/57]  eta: 0:00:00  loss: 0.7989 (0.8314)  time: 0.0803  data: 0.0001  max mem: 10917
[09:16:39.069170] Test: Total time: 0:00:04 (0.0848 s / it)
[09:16:40.833603] Dice score of the network on the train images: 0.749729, val images: 0.808190
[09:16:40.833822] saving best_rec_model_0 @ epoch 9
[09:16:41.706660] saving best_dice_model_0 @ epoch 9
[09:16:42.614609] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:16:43.015369] Epoch: [10]  [  0/345]  eta: 0:02:17  lr: 0.000063  loss: 0.7973 (0.7973)  time: 0.3996  data: 0.1471  max mem: 10917
[09:16:48.000956] Epoch: [10]  [ 20/345]  eta: 0:01:23  lr: 0.000063  loss: 0.8560 (0.8499)  time: 0.2492  data: 0.0001  max mem: 10917
[09:16:52.992755] Epoch: [10]  [ 40/345]  eta: 0:01:17  lr: 0.000063  loss: 0.8568 (0.8546)  time: 0.2495  data: 0.0001  max mem: 10917
[09:16:57.985082] Epoch: [10]  [ 60/345]  eta: 0:01:11  lr: 0.000064  loss: 0.8586 (0.8557)  time: 0.2496  data: 0.0001  max mem: 10917
[09:17:02.981996] Epoch: [10]  [ 80/345]  eta: 0:01:06  lr: 0.000064  loss: 0.8621 (0.8567)  time: 0.2498  data: 0.0001  max mem: 10917
[09:17:07.983959] Epoch: [10]  [100/345]  eta: 0:01:01  lr: 0.000064  loss: 0.8518 (0.8556)  time: 0.2501  data: 0.0001  max mem: 10917
[09:17:12.994181] Epoch: [10]  [120/345]  eta: 0:00:56  lr: 0.000065  loss: 0.8451 (0.8551)  time: 0.2505  data: 0.0000  max mem: 10917
[09:17:18.017886] Epoch: [10]  [140/345]  eta: 0:00:51  lr: 0.000065  loss: 0.8369 (0.8535)  time: 0.2511  data: 0.0000  max mem: 10917
[09:17:23.043011] Epoch: [10]  [160/345]  eta: 0:00:46  lr: 0.000065  loss: 0.8568 (0.8532)  time: 0.2512  data: 0.0001  max mem: 10917
[09:17:28.073465] Epoch: [10]  [180/345]  eta: 0:00:41  lr: 0.000066  loss: 0.8527 (0.8525)  time: 0.2515  data: 0.0000  max mem: 10917
[09:17:33.107256] Epoch: [10]  [200/345]  eta: 0:00:36  lr: 0.000066  loss: 0.8531 (0.8528)  time: 0.2516  data: 0.0000  max mem: 10917
[09:17:38.141283] Epoch: [10]  [220/345]  eta: 0:00:31  lr: 0.000066  loss: 0.8477 (0.8522)  time: 0.2517  data: 0.0000  max mem: 10917
[09:17:43.179859] Epoch: [10]  [240/345]  eta: 0:00:26  lr: 0.000067  loss: 0.8395 (0.8516)  time: 0.2519  data: 0.0000  max mem: 10917
[09:17:48.220703] Epoch: [10]  [260/345]  eta: 0:00:21  lr: 0.000067  loss: 0.8554 (0.8519)  time: 0.2520  data: 0.0000  max mem: 10917
[09:17:53.263603] Epoch: [10]  [280/345]  eta: 0:00:16  lr: 0.000068  loss: 0.8515 (0.8519)  time: 0.2521  data: 0.0001  max mem: 10917
[09:17:58.309502] Epoch: [10]  [300/345]  eta: 0:00:11  lr: 0.000068  loss: 0.8438 (0.8516)  time: 0.2522  data: 0.0001  max mem: 10917
[09:18:03.353694] Epoch: [10]  [320/345]  eta: 0:00:06  lr: 0.000068  loss: 0.8551 (0.8516)  time: 0.2522  data: 0.0000  max mem: 10917
[09:18:08.392898] Epoch: [10]  [340/345]  eta: 0:00:01  lr: 0.000069  loss: 0.8481 (0.8515)  time: 0.2519  data: 0.0001  max mem: 10917
[09:18:09.401099] Epoch: [10]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.8354 (0.8511)  time: 0.2518  data: 0.0001  max mem: 10917
[09:18:09.455300] Epoch: [10] Total time: 0:01:26 (0.2517 s / it)
[09:18:09.455693] Averaged stats: lr: 0.000069  loss: 0.8354 (0.8511)
[09:18:09.686435] Test:  [  0/345]  eta: 0:01:18  loss: 0.8075 (0.8075)  time: 0.2271  data: 0.1472  max mem: 10917
[09:18:10.516542] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7985 (0.8093)  time: 0.0960  data: 0.0144  max mem: 10917
[09:18:11.339975] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7985 (0.8081)  time: 0.0826  data: 0.0006  max mem: 10917
[09:18:12.167939] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8011 (0.8074)  time: 0.0825  data: 0.0001  max mem: 10917
[09:18:12.998683] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8011 (0.8063)  time: 0.0829  data: 0.0001  max mem: 10917
[09:18:13.833081] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8046 (0.8098)  time: 0.0832  data: 0.0001  max mem: 10917
[09:18:14.671968] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8163 (0.8114)  time: 0.0836  data: 0.0001  max mem: 10917
[09:18:15.513830] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8122 (0.8108)  time: 0.0840  data: 0.0001  max mem: 10917
[09:18:16.359054] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8076 (0.8103)  time: 0.0843  data: 0.0001  max mem: 10917
[09:18:17.208782] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8034 (0.8103)  time: 0.0847  data: 0.0001  max mem: 10917
[09:18:18.060597] Test:  [100/345]  eta: 0:00:20  loss: 0.8127 (0.8113)  time: 0.0850  data: 0.0001  max mem: 10917
[09:18:18.915855] Test:  [110/345]  eta: 0:00:20  loss: 0.8128 (0.8106)  time: 0.0853  data: 0.0001  max mem: 10917
[09:18:19.775532] Test:  [120/345]  eta: 0:00:19  loss: 0.8015 (0.8096)  time: 0.0857  data: 0.0001  max mem: 10917
[09:18:20.638105] Test:  [130/345]  eta: 0:00:18  loss: 0.8060 (0.8101)  time: 0.0861  data: 0.0001  max mem: 10917
[09:18:21.504545] Test:  [140/345]  eta: 0:00:17  loss: 0.8017 (0.8092)  time: 0.0864  data: 0.0001  max mem: 10917
[09:18:22.374723] Test:  [150/345]  eta: 0:00:16  loss: 0.7989 (0.8089)  time: 0.0868  data: 0.0001  max mem: 10917
[09:18:23.248423] Test:  [160/345]  eta: 0:00:15  loss: 0.7960 (0.8089)  time: 0.0871  data: 0.0001  max mem: 10917
[09:18:24.125112] Test:  [170/345]  eta: 0:00:14  loss: 0.8026 (0.8088)  time: 0.0875  data: 0.0001  max mem: 10917
[09:18:25.005502] Test:  [180/345]  eta: 0:00:14  loss: 0.8019 (0.8084)  time: 0.0878  data: 0.0001  max mem: 10917
[09:18:25.888580] Test:  [190/345]  eta: 0:00:13  loss: 0.7944 (0.8081)  time: 0.0881  data: 0.0001  max mem: 10917
[09:18:26.775533] Test:  [200/345]  eta: 0:00:12  loss: 0.8051 (0.8085)  time: 0.0885  data: 0.0001  max mem: 10917
[09:18:27.666584] Test:  [210/345]  eta: 0:00:11  loss: 0.8051 (0.8084)  time: 0.0888  data: 0.0001  max mem: 10917
[09:18:28.561230] Test:  [220/345]  eta: 0:00:10  loss: 0.7966 (0.8085)  time: 0.0892  data: 0.0001  max mem: 10917
[09:18:29.459473] Test:  [230/345]  eta: 0:00:09  loss: 0.7917 (0.8076)  time: 0.0896  data: 0.0001  max mem: 10917
[09:18:30.361972] Test:  [240/345]  eta: 0:00:09  loss: 0.7969 (0.8079)  time: 0.0900  data: 0.0001  max mem: 10917
[09:18:31.267415] Test:  [250/345]  eta: 0:00:08  loss: 0.8156 (0.8082)  time: 0.0903  data: 0.0001  max mem: 10917
[09:18:32.176106] Test:  [260/345]  eta: 0:00:07  loss: 0.8142 (0.8084)  time: 0.0907  data: 0.0001  max mem: 10917
[09:18:33.087985] Test:  [270/345]  eta: 0:00:06  loss: 0.8066 (0.8081)  time: 0.0910  data: 0.0001  max mem: 10917
[09:18:34.003978] Test:  [280/345]  eta: 0:00:05  loss: 0.7962 (0.8079)  time: 0.0913  data: 0.0001  max mem: 10917
[09:18:34.923864] Test:  [290/345]  eta: 0:00:04  loss: 0.8003 (0.8080)  time: 0.0917  data: 0.0001  max mem: 10917
[09:18:35.845250] Test:  [300/345]  eta: 0:00:03  loss: 0.8085 (0.8081)  time: 0.0920  data: 0.0001  max mem: 10917
[09:18:36.771350] Test:  [310/345]  eta: 0:00:03  loss: 0.8113 (0.8083)  time: 0.0923  data: 0.0001  max mem: 10917
[09:18:37.701174] Test:  [320/345]  eta: 0:00:02  loss: 0.8142 (0.8085)  time: 0.0927  data: 0.0001  max mem: 10917
[09:18:38.634756] Test:  [330/345]  eta: 0:00:01  loss: 0.8123 (0.8086)  time: 0.0931  data: 0.0001  max mem: 10917
[09:18:39.571371] Test:  [340/345]  eta: 0:00:00  loss: 0.8083 (0.8085)  time: 0.0935  data: 0.0001  max mem: 10917
[09:18:39.947293] Test:  [344/345]  eta: 0:00:00  loss: 0.8099 (0.8089)  time: 0.0936  data: 0.0001  max mem: 10917
[09:18:40.003060] Test: Total time: 0:00:30 (0.0885 s / it)
[09:18:50.359449] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8975 (0.8975)  time: 0.2119  data: 0.1322  max mem: 10917
[09:18:51.171827] Test:  [10/57]  eta: 0:00:04  loss: 0.8975 (0.9033)  time: 0.0930  data: 0.0121  max mem: 10917
[09:18:51.987428] Test:  [20/57]  eta: 0:00:03  loss: 0.8924 (0.8940)  time: 0.0813  data: 0.0001  max mem: 10917
[09:18:52.807835] Test:  [30/57]  eta: 0:00:02  loss: 0.7850 (0.8550)  time: 0.0818  data: 0.0001  max mem: 10917
[09:18:53.632014] Test:  [40/57]  eta: 0:00:01  loss: 0.7766 (0.8315)  time: 0.0822  data: 0.0001  max mem: 10917
[09:18:54.459712] Test:  [50/57]  eta: 0:00:00  loss: 0.7755 (0.8239)  time: 0.0825  data: 0.0001  max mem: 10917
[09:18:54.909327] Test:  [56/57]  eta: 0:00:00  loss: 0.7873 (0.8277)  time: 0.0803  data: 0.0001  max mem: 10917
[09:18:54.967394] Test: Total time: 0:00:04 (0.0846 s / it)
[09:18:56.726094] Dice score of the network on the train images: 0.763257, val images: 0.805936
[09:18:56.729797] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:18:57.128763] Epoch: [11]  [  0/345]  eta: 0:02:17  lr: 0.000069  loss: 0.8292 (0.8292)  time: 0.3979  data: 0.1448  max mem: 10917
[09:19:02.134338] Epoch: [11]  [ 20/345]  eta: 0:01:23  lr: 0.000069  loss: 0.8279 (0.8283)  time: 0.2502  data: 0.0000  max mem: 10917
[09:19:07.145219] Epoch: [11]  [ 40/345]  eta: 0:01:17  lr: 0.000069  loss: 0.8379 (0.8361)  time: 0.2505  data: 0.0000  max mem: 10917
[09:19:12.158541] Epoch: [11]  [ 60/345]  eta: 0:01:12  lr: 0.000070  loss: 0.8343 (0.8398)  time: 0.2506  data: 0.0000  max mem: 10917
[09:19:17.177455] Epoch: [11]  [ 80/345]  eta: 0:01:06  lr: 0.000070  loss: 0.8462 (0.8420)  time: 0.2509  data: 0.0000  max mem: 10917
[09:19:22.197560] Epoch: [11]  [100/345]  eta: 0:01:01  lr: 0.000071  loss: 0.8456 (0.8425)  time: 0.2510  data: 0.0001  max mem: 10917
[09:19:27.221845] Epoch: [11]  [120/345]  eta: 0:00:56  lr: 0.000071  loss: 0.8394 (0.8430)  time: 0.2512  data: 0.0000  max mem: 10917
[09:19:32.248311] Epoch: [11]  [140/345]  eta: 0:00:51  lr: 0.000071  loss: 0.8507 (0.8443)  time: 0.2513  data: 0.0000  max mem: 10917
[09:19:37.277373] Epoch: [11]  [160/345]  eta: 0:00:46  lr: 0.000072  loss: 0.8478 (0.8453)  time: 0.2514  data: 0.0000  max mem: 10917
[09:19:42.311527] Epoch: [11]  [180/345]  eta: 0:00:41  lr: 0.000072  loss: 0.8346 (0.8449)  time: 0.2517  data: 0.0000  max mem: 10917
[09:19:47.346093] Epoch: [11]  [200/345]  eta: 0:00:36  lr: 0.000072  loss: 0.8376 (0.8445)  time: 0.2517  data: 0.0000  max mem: 10917
[09:19:52.384692] Epoch: [11]  [220/345]  eta: 0:00:31  lr: 0.000073  loss: 0.8285 (0.8441)  time: 0.2519  data: 0.0000  max mem: 10917
[09:19:57.426376] Epoch: [11]  [240/345]  eta: 0:00:26  lr: 0.000073  loss: 0.8297 (0.8433)  time: 0.2520  data: 0.0000  max mem: 10917
[09:20:02.467705] Epoch: [11]  [260/345]  eta: 0:00:21  lr: 0.000073  loss: 0.8444 (0.8433)  time: 0.2520  data: 0.0000  max mem: 10917
[09:20:07.509632] Epoch: [11]  [280/345]  eta: 0:00:16  lr: 0.000074  loss: 0.8291 (0.8431)  time: 0.2521  data: 0.0000  max mem: 10917
[09:20:12.556186] Epoch: [11]  [300/345]  eta: 0:00:11  lr: 0.000074  loss: 0.8418 (0.8432)  time: 0.2523  data: 0.0001  max mem: 10917
[09:20:17.597684] Epoch: [11]  [320/345]  eta: 0:00:06  lr: 0.000075  loss: 0.8432 (0.8431)  time: 0.2520  data: 0.0000  max mem: 10917
[09:20:22.644996] Epoch: [11]  [340/345]  eta: 0:00:01  lr: 0.000075  loss: 0.8425 (0.8431)  time: 0.2523  data: 0.0000  max mem: 10917
[09:20:23.655319] Epoch: [11]  [344/345]  eta: 0:00:00  lr: 0.000075  loss: 0.8335 (0.8428)  time: 0.2523  data: 0.0001  max mem: 10917
[09:20:23.709921] Epoch: [11] Total time: 0:01:26 (0.2521 s / it)
[09:20:23.710110] Averaged stats: lr: 0.000075  loss: 0.8335 (0.8428)
[09:20:23.943424] Test:  [  0/345]  eta: 0:01:19  loss: 0.8136 (0.8136)  time: 0.2295  data: 0.1498  max mem: 10917
[09:20:24.779011] Test:  [ 10/345]  eta: 0:00:32  loss: 0.8136 (0.8130)  time: 0.0967  data: 0.0152  max mem: 10917
[09:20:25.602726] Test:  [ 20/345]  eta: 0:00:29  loss: 0.8073 (0.8083)  time: 0.0829  data: 0.0009  max mem: 10917
[09:20:26.429132] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8073 (0.8089)  time: 0.0825  data: 0.0001  max mem: 10917
[09:20:27.258905] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8131 (0.8086)  time: 0.0828  data: 0.0001  max mem: 10917
[09:20:28.092629] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7958 (0.8058)  time: 0.0831  data: 0.0001  max mem: 10917
[09:20:28.930292] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7982 (0.8046)  time: 0.0835  data: 0.0001  max mem: 10917
[09:20:29.770845] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8005 (0.8036)  time: 0.0839  data: 0.0001  max mem: 10917
[09:20:30.615308] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8005 (0.8031)  time: 0.0842  data: 0.0001  max mem: 10917
[09:20:31.463466] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8012 (0.8038)  time: 0.0846  data: 0.0001  max mem: 10917
[09:20:32.314280] Test:  [100/345]  eta: 0:00:20  loss: 0.8019 (0.8037)  time: 0.0849  data: 0.0001  max mem: 10917
[09:20:33.169464] Test:  [110/345]  eta: 0:00:20  loss: 0.8071 (0.8045)  time: 0.0852  data: 0.0001  max mem: 10917
[09:20:34.027645] Test:  [120/345]  eta: 0:00:19  loss: 0.8071 (0.8044)  time: 0.0856  data: 0.0001  max mem: 10917
[09:20:34.889645] Test:  [130/345]  eta: 0:00:18  loss: 0.8052 (0.8046)  time: 0.0860  data: 0.0001  max mem: 10917
[09:20:35.755016] Test:  [140/345]  eta: 0:00:17  loss: 0.8052 (0.8048)  time: 0.0863  data: 0.0001  max mem: 10917
[09:20:36.624722] Test:  [150/345]  eta: 0:00:16  loss: 0.7965 (0.8040)  time: 0.0867  data: 0.0001  max mem: 10917
[09:20:37.497164] Test:  [160/345]  eta: 0:00:15  loss: 0.7958 (0.8041)  time: 0.0871  data: 0.0001  max mem: 10917
[09:20:38.373783] Test:  [170/345]  eta: 0:00:14  loss: 0.8074 (0.8045)  time: 0.0874  data: 0.0001  max mem: 10917
[09:20:39.253234] Test:  [180/345]  eta: 0:00:14  loss: 0.8115 (0.8045)  time: 0.0877  data: 0.0001  max mem: 10917
[09:20:40.136228] Test:  [190/345]  eta: 0:00:13  loss: 0.8170 (0.8050)  time: 0.0881  data: 0.0001  max mem: 10917
[09:20:41.022606] Test:  [200/345]  eta: 0:00:12  loss: 0.8047 (0.8049)  time: 0.0884  data: 0.0001  max mem: 10917
[09:20:41.912543] Test:  [210/345]  eta: 0:00:11  loss: 0.7998 (0.8051)  time: 0.0888  data: 0.0001  max mem: 10917
[09:20:42.805419] Test:  [220/345]  eta: 0:00:10  loss: 0.8047 (0.8051)  time: 0.0891  data: 0.0001  max mem: 10917
[09:20:43.703199] Test:  [230/345]  eta: 0:00:09  loss: 0.8088 (0.8056)  time: 0.0895  data: 0.0001  max mem: 10917
[09:20:44.604549] Test:  [240/345]  eta: 0:00:09  loss: 0.8036 (0.8050)  time: 0.0899  data: 0.0001  max mem: 10917
[09:20:45.508456] Test:  [250/345]  eta: 0:00:08  loss: 0.7996 (0.8051)  time: 0.0902  data: 0.0001  max mem: 10917
[09:20:46.416417] Test:  [260/345]  eta: 0:00:07  loss: 0.8036 (0.8050)  time: 0.0905  data: 0.0001  max mem: 10917
[09:20:47.327947] Test:  [270/345]  eta: 0:00:06  loss: 0.8086 (0.8051)  time: 0.0909  data: 0.0001  max mem: 10917
[09:20:48.242345] Test:  [280/345]  eta: 0:00:05  loss: 0.8095 (0.8050)  time: 0.0913  data: 0.0001  max mem: 10917
[09:20:49.160637] Test:  [290/345]  eta: 0:00:04  loss: 0.8052 (0.8050)  time: 0.0916  data: 0.0001  max mem: 10917
[09:20:50.082919] Test:  [300/345]  eta: 0:00:03  loss: 0.8042 (0.8048)  time: 0.0920  data: 0.0001  max mem: 10917
[09:20:51.007785] Test:  [310/345]  eta: 0:00:03  loss: 0.8042 (0.8048)  time: 0.0923  data: 0.0001  max mem: 10917
[09:20:51.936817] Test:  [320/345]  eta: 0:00:02  loss: 0.8012 (0.8049)  time: 0.0926  data: 0.0001  max mem: 10917
[09:20:52.869634] Test:  [330/345]  eta: 0:00:01  loss: 0.8110 (0.8051)  time: 0.0930  data: 0.0001  max mem: 10917
[09:20:53.805244] Test:  [340/345]  eta: 0:00:00  loss: 0.8105 (0.8052)  time: 0.0934  data: 0.0001  max mem: 10917
[09:20:54.180573] Test:  [344/345]  eta: 0:00:00  loss: 0.8048 (0.8051)  time: 0.0935  data: 0.0001  max mem: 10917
[09:20:54.237398] Test: Total time: 0:00:30 (0.0885 s / it)
[09:21:04.660294] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8876 (0.8876)  time: 0.2182  data: 0.1384  max mem: 10917
[09:21:05.473722] Test:  [10/57]  eta: 0:00:04  loss: 0.8953 (0.9159)  time: 0.0937  data: 0.0126  max mem: 10917
[09:21:06.289539] Test:  [20/57]  eta: 0:00:03  loss: 0.9020 (0.9053)  time: 0.0814  data: 0.0001  max mem: 10917
[09:21:07.110394] Test:  [30/57]  eta: 0:00:02  loss: 0.7982 (0.8655)  time: 0.0818  data: 0.0001  max mem: 10917
[09:21:07.934457] Test:  [40/57]  eta: 0:00:01  loss: 0.7849 (0.8430)  time: 0.0822  data: 0.0001  max mem: 10917
[09:21:08.763154] Test:  [50/57]  eta: 0:00:00  loss: 0.7853 (0.8370)  time: 0.0826  data: 0.0001  max mem: 10917
[09:21:09.212705] Test:  [56/57]  eta: 0:00:00  loss: 0.7967 (0.8405)  time: 0.0804  data: 0.0001  max mem: 10917
[09:21:09.269682] Test: Total time: 0:00:04 (0.0847 s / it)
[09:21:11.044379] Dice score of the network on the train images: 0.768527, val images: 0.789277
[09:21:11.047976] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:21:11.441505] Epoch: [12]  [  0/345]  eta: 0:02:15  lr: 0.000075  loss: 0.7994 (0.7994)  time: 0.3924  data: 0.1396  max mem: 10917
[09:21:16.451466] Epoch: [12]  [ 20/345]  eta: 0:01:23  lr: 0.000075  loss: 0.8172 (0.8268)  time: 0.2504  data: 0.0001  max mem: 10917
[09:21:21.464744] Epoch: [12]  [ 40/345]  eta: 0:01:17  lr: 0.000076  loss: 0.8326 (0.8287)  time: 0.2506  data: 0.0001  max mem: 10917
[09:21:26.481164] Epoch: [12]  [ 60/345]  eta: 0:01:12  lr: 0.000076  loss: 0.8345 (0.8319)  time: 0.2508  data: 0.0001  max mem: 10917
[09:21:31.507388] Epoch: [12]  [ 80/345]  eta: 0:01:06  lr: 0.000076  loss: 0.8299 (0.8309)  time: 0.2513  data: 0.0001  max mem: 10917
[09:21:36.537649] Epoch: [12]  [100/345]  eta: 0:01:01  lr: 0.000077  loss: 0.8292 (0.8309)  time: 0.2515  data: 0.0001  max mem: 10917
[09:21:41.568872] Epoch: [12]  [120/345]  eta: 0:00:56  lr: 0.000077  loss: 0.8354 (0.8314)  time: 0.2515  data: 0.0001  max mem: 10917
[09:21:46.605134] Epoch: [12]  [140/345]  eta: 0:00:51  lr: 0.000078  loss: 0.8374 (0.8325)  time: 0.2518  data: 0.0001  max mem: 10917
[09:21:51.638429] Epoch: [12]  [160/345]  eta: 0:00:46  lr: 0.000078  loss: 0.8347 (0.8325)  time: 0.2516  data: 0.0001  max mem: 10917

[09:21:56.671949] Epoch: [12]  [180/345]  eta: 0:00:41  lr: 0.000078  loss: 0.8281 (0.8322)  time: 0.2516  data: 0.0001  max mem: 10917
[09:22:01.710127] Epoch: [12]  [200/345]  eta: 0:00:36  lr: 0.000079  loss: 0.8224 (0.8317)  time: 0.2519  data: 0.0001  max mem: 10917
[09:22:06.750577] Epoch: [12]  [220/345]  eta: 0:00:31  lr: 0.000079  loss: 0.8436 (0.8323)  time: 0.2520  data: 0.0001  max mem: 10917
[09:22:11.800036] Epoch: [12]  [240/345]  eta: 0:00:26  lr: 0.000079  loss: 0.8343 (0.8326)  time: 0.2524  data: 0.0001  max mem: 10917
[09:22:16.836331] Epoch: [12]  [260/345]  eta: 0:00:21  lr: 0.000080  loss: 0.8321 (0.8328)  time: 0.2518  data: 0.0001  max mem: 10917
[09:22:21.865360] Epoch: [12]  [280/345]  eta: 0:00:16  lr: 0.000080  loss: 0.8225 (0.8322)  time: 0.2514  data: 0.0001  max mem: 10917
[09:22:26.897009] Epoch: [12]  [300/345]  eta: 0:00:11  lr: 0.000080  loss: 0.8264 (0.8323)  time: 0.2515  data: 0.0001  max mem: 10917
[09:22:31.945207] Epoch: [12]  [320/345]  eta: 0:00:06  lr: 0.000081  loss: 0.8401 (0.8329)  time: 0.2524  data: 0.0001  max mem: 10917
[09:22:36.998323] Epoch: [12]  [340/345]  eta: 0:00:01  lr: 0.000081  loss: 0.8267 (0.8326)  time: 0.2526  data: 0.0001  max mem: 10917
[09:22:38.008185] Epoch: [12]  [344/345]  eta: 0:00:00  lr: 0.000081  loss: 0.8260 (0.8325)  time: 0.2525  data: 0.0001  max mem: 10917
[09:22:38.064294] Epoch: [12] Total time: 0:01:27 (0.2522 s / it)
[09:22:38.064839] Averaged stats: lr: 0.000081  loss: 0.8260 (0.8325)
[09:22:38.302646] Test:  [  0/345]  eta: 0:01:20  loss: 0.7629 (0.7629)  time: 0.2328  data: 0.1527  max mem: 10917
[09:22:39.149423] Test:  [ 10/345]  eta: 0:00:32  loss: 0.8153 (0.8051)  time: 0.0980  data: 0.0165  max mem: 10917
[09:22:39.977982] Test:  [ 20/345]  eta: 0:00:29  loss: 0.8090 (0.8030)  time: 0.0837  data: 0.0017  max mem: 10917
[09:22:40.805587] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7977 (0.8026)  time: 0.0828  data: 0.0003  max mem: 10917
[09:22:41.634935] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8017 (0.8019)  time: 0.0828  data: 0.0001  max mem: 10917
[09:22:42.468875] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8017 (0.8019)  time: 0.0831  data: 0.0001  max mem: 10917
[09:22:43.306496] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7933 (0.8009)  time: 0.0835  data: 0.0001  max mem: 10917
[09:22:44.147480] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7920 (0.8007)  time: 0.0839  data: 0.0001  max mem: 10917
[09:22:44.991773] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7905 (0.8003)  time: 0.0842  data: 0.0001  max mem: 10917
[09:22:45.839733] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8006 (0.8008)  time: 0.0846  data: 0.0001  max mem: 10917
[09:22:46.691313] Test:  [100/345]  eta: 0:00:20  loss: 0.8073 (0.8018)  time: 0.0849  data: 0.0001  max mem: 10917
[09:22:47.545965] Test:  [110/345]  eta: 0:00:20  loss: 0.7988 (0.8014)  time: 0.0853  data: 0.0001  max mem: 10917
[09:22:48.404788] Test:  [120/345]  eta: 0:00:19  loss: 0.7940 (0.8010)  time: 0.0856  data: 0.0001  max mem: 10917
[09:22:49.266966] Test:  [130/345]  eta: 0:00:18  loss: 0.7979 (0.8009)  time: 0.0860  data: 0.0001  max mem: 10917
[09:22:50.132416] Test:  [140/345]  eta: 0:00:17  loss: 0.7983 (0.8011)  time: 0.0863  data: 0.0001  max mem: 10917
[09:22:51.002550] Test:  [150/345]  eta: 0:00:16  loss: 0.7980 (0.8011)  time: 0.0867  data: 0.0001  max mem: 10917
[09:22:51.874514] Test:  [160/345]  eta: 0:00:15  loss: 0.7932 (0.8007)  time: 0.0871  data: 0.0001  max mem: 10917
[09:22:52.750960] Test:  [170/345]  eta: 0:00:15  loss: 0.7902 (0.8008)  time: 0.0873  data: 0.0001  max mem: 10917
[09:22:53.630372] Test:  [180/345]  eta: 0:00:14  loss: 0.8042 (0.8010)  time: 0.0877  data: 0.0001  max mem: 10917
[09:22:54.513112] Test:  [190/345]  eta: 0:00:13  loss: 0.8002 (0.8008)  time: 0.0881  data: 0.0001  max mem: 10917
[09:22:55.399625] Test:  [200/345]  eta: 0:00:12  loss: 0.8023 (0.8007)  time: 0.0884  data: 0.0001  max mem: 10917
[09:22:56.290705] Test:  [210/345]  eta: 0:00:11  loss: 0.7931 (0.8005)  time: 0.0888  data: 0.0001  max mem: 10917
[09:22:57.183917] Test:  [220/345]  eta: 0:00:10  loss: 0.7931 (0.8005)  time: 0.0892  data: 0.0001  max mem: 10917
[09:22:58.081599] Test:  [230/345]  eta: 0:00:09  loss: 0.7996 (0.8007)  time: 0.0895  data: 0.0001  max mem: 10917
[09:22:58.982794] Test:  [240/345]  eta: 0:00:09  loss: 0.7984 (0.8006)  time: 0.0899  data: 0.0001  max mem: 10917
[09:22:59.886928] Test:  [250/345]  eta: 0:00:08  loss: 0.7953 (0.8005)  time: 0.0902  data: 0.0001  max mem: 10917
[09:23:00.794858] Test:  [260/345]  eta: 0:00:07  loss: 0.7929 (0.8002)  time: 0.0906  data: 0.0001  max mem: 10917
[09:23:01.706205] Test:  [270/345]  eta: 0:00:06  loss: 0.8013 (0.8005)  time: 0.0909  data: 0.0001  max mem: 10917
[09:23:02.620660] Test:  [280/345]  eta: 0:00:05  loss: 0.8036 (0.8006)  time: 0.0912  data: 0.0001  max mem: 10917
[09:23:03.539986] Test:  [290/345]  eta: 0:00:04  loss: 0.8114 (0.8009)  time: 0.0916  data: 0.0001  max mem: 10917
[09:23:04.461434] Test:  [300/345]  eta: 0:00:03  loss: 0.8162 (0.8012)  time: 0.0920  data: 0.0001  max mem: 10917
[09:23:05.387420] Test:  [310/345]  eta: 0:00:03  loss: 0.8045 (0.8011)  time: 0.0923  data: 0.0001  max mem: 10917
[09:23:06.316185] Test:  [320/345]  eta: 0:00:02  loss: 0.7977 (0.8011)  time: 0.0927  data: 0.0001  max mem: 10917
[09:23:07.248728] Test:  [330/345]  eta: 0:00:01  loss: 0.7941 (0.8010)  time: 0.0930  data: 0.0001  max mem: 10917
[09:23:08.184054] Test:  [340/345]  eta: 0:00:00  loss: 0.7995 (0.8012)  time: 0.0933  data: 0.0001  max mem: 10917
[09:23:08.559823] Test:  [344/345]  eta: 0:00:00  loss: 0.8097 (0.8011)  time: 0.0935  data: 0.0001  max mem: 10917
[09:23:08.616457] Test: Total time: 0:00:30 (0.0885 s / it)
[09:23:19.012255] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8928 (0.8928)  time: 0.2191  data: 0.1391  max mem: 10917
[09:23:19.825471] Test:  [10/57]  eta: 0:00:04  loss: 0.8891 (0.8968)  time: 0.0938  data: 0.0127  max mem: 10917
[09:23:20.641693] Test:  [20/57]  eta: 0:00:03  loss: 0.8785 (0.8843)  time: 0.0814  data: 0.0001  max mem: 10917
[09:23:21.462203] Test:  [30/57]  eta: 0:00:02  loss: 0.7782 (0.8476)  time: 0.0818  data: 0.0001  max mem: 10917
[09:23:22.286694] Test:  [40/57]  eta: 0:00:01  loss: 0.7629 (0.8242)  time: 0.0822  data: 0.0001  max mem: 10917
[09:23:23.114192] Test:  [50/57]  eta: 0:00:00  loss: 0.7521 (0.8154)  time: 0.0826  data: 0.0001  max mem: 10917
[09:23:23.564467] Test:  [56/57]  eta: 0:00:00  loss: 0.7868 (0.8196)  time: 0.0804  data: 0.0001  max mem: 10917
[09:23:23.618964] Test: Total time: 0:00:04 (0.0847 s / it)
[09:23:25.382864] Dice score of the network on the train images: 0.747816, val images: 0.807343
[09:23:25.383077] saving best_rec_model_0 @ epoch 12
[09:23:26.236256] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:23:26.629118] Epoch: [13]  [  0/345]  eta: 0:02:15  lr: 0.000081  loss: 0.8546 (0.8546)  time: 0.3917  data: 0.1394  max mem: 10917
[09:23:31.635236] Epoch: [13]  [ 20/345]  eta: 0:01:23  lr: 0.000082  loss: 0.8401 (0.8380)  time: 0.2502  data: 0.0001  max mem: 10917
[09:23:36.645164] Epoch: [13]  [ 40/345]  eta: 0:01:17  lr: 0.000082  loss: 0.8166 (0.8305)  time: 0.2505  data: 0.0001  max mem: 10917
[09:23:41.662983] Epoch: [13]  [ 60/345]  eta: 0:01:12  lr: 0.000082  loss: 0.8330 (0.8326)  time: 0.2508  data: 0.0001  max mem: 10917
[09:23:46.678029] Epoch: [13]  [ 80/345]  eta: 0:01:06  lr: 0.000083  loss: 0.8330 (0.8326)  time: 0.2507  data: 0.0001  max mem: 10917
[09:23:51.785282] Epoch: [13]  [100/345]  eta: 0:01:01  lr: 0.000083  loss: 0.8183 (0.8319)  time: 0.2553  data: 0.0001  max mem: 10917

[09:23:56.809467] Epoch: [13]  [120/345]  eta: 0:00:56  lr: 0.000083  loss: 0.8293 (0.8317)  time: 0.2512  data: 0.0000  max mem: 10917
[09:24:01.837120] Epoch: [13]  [140/345]  eta: 0:00:51  lr: 0.000084  loss: 0.8344 (0.8319)  time: 0.2513  data: 0.0001  max mem: 10917
[09:24:06.870024] Epoch: [13]  [160/345]  eta: 0:00:46  lr: 0.000084  loss: 0.8191 (0.8310)  time: 0.2516  data: 0.0000  max mem: 10917
[09:24:11.915067] Epoch: [13]  [180/345]  eta: 0:00:41  lr: 0.000085  loss: 0.8246 (0.8311)  time: 0.2522  data: 0.0001  max mem: 10917
[09:24:16.959991] Epoch: [13]  [200/345]  eta: 0:00:36  lr: 0.000085  loss: 0.8304 (0.8304)  time: 0.2522  data: 0.0001  max mem: 10917
[09:24:21.999732] Epoch: [13]  [220/345]  eta: 0:00:31  lr: 0.000085  loss: 0.8209 (0.8300)  time: 0.2519  data: 0.0001  max mem: 10917
[09:24:27.041898] Epoch: [13]  [240/345]  eta: 0:00:26  lr: 0.000086  loss: 0.8211 (0.8294)  time: 0.2521  data: 0.0001  max mem: 10917
[09:24:32.084667] Epoch: [13]  [260/345]  eta: 0:00:21  lr: 0.000086  loss: 0.8229 (0.8288)  time: 0.2521  data: 0.0001  max mem: 10917
[09:24:37.131246] Epoch: [13]  [280/345]  eta: 0:00:16  lr: 0.000086  loss: 0.8354 (0.8292)  time: 0.2523  data: 0.0001  max mem: 10917
[09:24:42.173798] Epoch: [13]  [300/345]  eta: 0:00:11  lr: 0.000087  loss: 0.8371 (0.8300)  time: 0.2521  data: 0.0001  max mem: 10917
[09:24:47.205804] Epoch: [13]  [320/345]  eta: 0:00:06  lr: 0.000087  loss: 0.8279 (0.8303)  time: 0.2516  data: 0.0001  max mem: 10917
[09:24:52.256189] Epoch: [13]  [340/345]  eta: 0:00:01  lr: 0.000087  loss: 0.8382 (0.8307)  time: 0.2525  data: 0.0001  max mem: 10917
[09:24:53.267556] Epoch: [13]  [344/345]  eta: 0:00:00  lr: 0.000087  loss: 0.8341 (0.8306)  time: 0.2525  data: 0.0001  max mem: 10917
[09:24:53.329045] Epoch: [13] Total time: 0:01:27 (0.2524 s / it)
[09:24:53.329534] Averaged stats: lr: 0.000087  loss: 0.8341 (0.8306)
[09:24:53.564896] Test:  [  0/345]  eta: 0:01:19  loss: 0.7910 (0.7910)  time: 0.2313  data: 0.1509  max mem: 10917
[09:24:54.456869] Test:  [ 10/345]  eta: 0:00:34  loss: 0.7966 (0.7957)  time: 0.1020  data: 0.0207  max mem: 10917
[09:24:55.288969] Test:  [ 20/345]  eta: 0:00:30  loss: 0.7953 (0.7961)  time: 0.0861  data: 0.0043  max mem: 10917
[09:24:56.117101] Test:  [ 30/345]  eta: 0:00:28  loss: 0.7989 (0.8012)  time: 0.0830  data: 0.0006  max mem: 10917
[09:24:56.947471] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8001 (0.7986)  time: 0.0829  data: 0.0001  max mem: 10917
[09:24:57.781233] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7949 (0.7981)  time: 0.0832  data: 0.0001  max mem: 10917
[09:24:58.619164] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8090 (0.8013)  time: 0.0835  data: 0.0001  max mem: 10917
[09:24:59.460044] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8129 (0.8012)  time: 0.0839  data: 0.0001  max mem: 10917
[09:25:00.304617] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7953 (0.8011)  time: 0.0842  data: 0.0001  max mem: 10917
[09:25:01.152523] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7923 (0.8006)  time: 0.0846  data: 0.0001  max mem: 10917
[09:25:02.004734] Test:  [100/345]  eta: 0:00:21  loss: 0.7935 (0.8000)  time: 0.0850  data: 0.0001  max mem: 10917
[09:25:02.860562] Test:  [110/345]  eta: 0:00:20  loss: 0.8040 (0.8009)  time: 0.0854  data: 0.0001  max mem: 10917
[09:25:03.719927] Test:  [120/345]  eta: 0:00:19  loss: 0.7933 (0.7996)  time: 0.0857  data: 0.0001  max mem: 10917
[09:25:04.581959] Test:  [130/345]  eta: 0:00:18  loss: 0.7881 (0.7993)  time: 0.0860  data: 0.0001  max mem: 10917
[09:25:05.447494] Test:  [140/345]  eta: 0:00:17  loss: 0.7894 (0.7986)  time: 0.0863  data: 0.0001  max mem: 10917
[09:25:06.316994] Test:  [150/345]  eta: 0:00:16  loss: 0.7918 (0.7981)  time: 0.0867  data: 0.0001  max mem: 10917
[09:25:07.189583] Test:  [160/345]  eta: 0:00:15  loss: 0.7868 (0.7975)  time: 0.0871  data: 0.0001  max mem: 10917
[09:25:08.065308] Test:  [170/345]  eta: 0:00:15  loss: 0.7910 (0.7973)  time: 0.0874  data: 0.0001  max mem: 10917
[09:25:08.945497] Test:  [180/345]  eta: 0:00:14  loss: 0.7925 (0.7974)  time: 0.0878  data: 0.0001  max mem: 10917
[09:25:09.828534] Test:  [190/345]  eta: 0:00:13  loss: 0.7836 (0.7967)  time: 0.0881  data: 0.0001  max mem: 10917
[09:25:10.715918] Test:  [200/345]  eta: 0:00:12  loss: 0.7812 (0.7963)  time: 0.0885  data: 0.0001  max mem: 10917
[09:25:11.606614] Test:  [210/345]  eta: 0:00:11  loss: 0.7826 (0.7959)  time: 0.0889  data: 0.0001  max mem: 10917
[09:25:12.500314] Test:  [220/345]  eta: 0:00:10  loss: 0.7914 (0.7957)  time: 0.0892  data: 0.0001  max mem: 10917
[09:25:13.397805] Test:  [230/345]  eta: 0:00:09  loss: 0.7914 (0.7952)  time: 0.0895  data: 0.0001  max mem: 10917
[09:25:14.300136] Test:  [240/345]  eta: 0:00:09  loss: 0.7905 (0.7952)  time: 0.0899  data: 0.0001  max mem: 10917
[09:25:15.204345] Test:  [250/345]  eta: 0:00:08  loss: 0.7976 (0.7955)  time: 0.0903  data: 0.0001  max mem: 10917
[09:25:16.111783] Test:  [260/345]  eta: 0:00:07  loss: 0.7915 (0.7951)  time: 0.0905  data: 0.0001  max mem: 10917
[09:25:17.024247] Test:  [270/345]  eta: 0:00:06  loss: 0.7886 (0.7949)  time: 0.0909  data: 0.0001  max mem: 10917
[09:25:17.939109] Test:  [280/345]  eta: 0:00:05  loss: 0.7948 (0.7950)  time: 0.0913  data: 0.0001  max mem: 10917
[09:25:18.857452] Test:  [290/345]  eta: 0:00:04  loss: 0.7935 (0.7947)  time: 0.0916  data: 0.0001  max mem: 10917
[09:25:19.780142] Test:  [300/345]  eta: 0:00:03  loss: 0.7866 (0.7946)  time: 0.0920  data: 0.0001  max mem: 10917
[09:25:20.705305] Test:  [310/345]  eta: 0:00:03  loss: 0.7866 (0.7943)  time: 0.0923  data: 0.0001  max mem: 10917
[09:25:21.634294] Test:  [320/345]  eta: 0:00:02  loss: 0.7955 (0.7947)  time: 0.0927  data: 0.0001  max mem: 10917
[09:25:22.566884] Test:  [330/345]  eta: 0:00:01  loss: 0.7988 (0.7946)  time: 0.0930  data: 0.0001  max mem: 10917
[09:25:23.502786] Test:  [340/345]  eta: 0:00:00  loss: 0.7893 (0.7944)  time: 0.0934  data: 0.0001  max mem: 10917
[09:25:23.878468] Test:  [344/345]  eta: 0:00:00  loss: 0.7843 (0.7942)  time: 0.0935  data: 0.0001  max mem: 10917
[09:25:23.933883] Test: Total time: 0:00:30 (0.0887 s / it)
[09:25:34.464194] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9268 (0.9268)  time: 0.2210  data: 0.1412  max mem: 10917
[09:25:35.277007] Test:  [10/57]  eta: 0:00:04  loss: 0.9268 (0.9085)  time: 0.0939  data: 0.0129  max mem: 10917
[09:25:36.093504] Test:  [20/57]  eta: 0:00:03  loss: 0.8958 (0.8996)  time: 0.0814  data: 0.0001  max mem: 10917
[09:25:36.914718] Test:  [30/57]  eta: 0:00:02  loss: 0.7966 (0.8602)  time: 0.0818  data: 0.0001  max mem: 10917
[09:25:37.739230] Test:  [40/57]  eta: 0:00:01  loss: 0.7758 (0.8368)  time: 0.0822  data: 0.0001  max mem: 10917
[09:25:38.567336] Test:  [50/57]  eta: 0:00:00  loss: 0.7726 (0.8275)  time: 0.0826  data: 0.0001  max mem: 10917
[09:25:39.017010] Test:  [56/57]  eta: 0:00:00  loss: 0.8043 (0.8311)  time: 0.0803  data: 0.0001  max mem: 10917
[09:25:39.070996] Test: Total time: 0:00:04 (0.0847 s / it)
[09:25:40.845634] Dice score of the network on the train images: 0.771172, val images: 0.801080
[09:25:40.849135] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:25:41.243308] Epoch: [14]  [  0/345]  eta: 0:02:15  lr: 0.000087  loss: 0.7959 (0.7959)  time: 0.3933  data: 0.1420  max mem: 10917
[09:25:46.231480] Epoch: [14]  [ 20/345]  eta: 0:01:23  lr: 0.000088  loss: 0.8285 (0.8239)  time: 0.2494  data: 0.0001  max mem: 10917
[09:25:51.224127] Epoch: [14]  [ 40/345]  eta: 0:01:17  lr: 0.000088  loss: 0.8478 (0.8338)  time: 0.2496  data: 0.0001  max mem: 10917
[09:25:56.222409] Epoch: [14]  [ 60/345]  eta: 0:01:11  lr: 0.000089  loss: 0.8250 (0.8330)  time: 0.2499  data: 0.0001  max mem: 10917
[09:26:01.225037] Epoch: [14]  [ 80/345]  eta: 0:01:06  lr: 0.000089  loss: 0.8287 (0.8321)  time: 0.2501  data: 0.0001  max mem: 10917
[09:26:06.230735] Epoch: [14]  [100/345]  eta: 0:01:01  lr: 0.000089  loss: 0.8227 (0.8315)  time: 0.2502  data: 0.0001  max mem: 10917
[09:26:11.245743] Epoch: [14]  [120/345]  eta: 0:00:56  lr: 0.000090  loss: 0.8217 (0.8299)  time: 0.2507  data: 0.0001  max mem: 10917
[09:26:16.266456] Epoch: [14]  [140/345]  eta: 0:00:51  lr: 0.000090  loss: 0.8356 (0.8303)  time: 0.2510  data: 0.0001  max mem: 10917
[09:26:21.305121] Epoch: [14]  [160/345]  eta: 0:00:46  lr: 0.000090  loss: 0.8392 (0.8320)  time: 0.2519  data: 0.0001  max mem: 10917
[09:26:26.330160] Epoch: [14]  [180/345]  eta: 0:00:41  lr: 0.000091  loss: 0.8446 (0.8330)  time: 0.2512  data: 0.0001  max mem: 10917
[09:26:31.384005] Epoch: [14]  [200/345]  eta: 0:00:36  lr: 0.000091  loss: 0.8284 (0.8328)  time: 0.2526  data: 0.0001  max mem: 10917
[09:26:36.425702] Epoch: [14]  [220/345]  eta: 0:00:31  lr: 0.000091  loss: 0.8419 (0.8336)  time: 0.2520  data: 0.0001  max mem: 10917
[09:26:41.471232] Epoch: [14]  [240/345]  eta: 0:00:26  lr: 0.000092  loss: 0.8395 (0.8339)  time: 0.2522  data: 0.0001  max mem: 10917
[09:26:46.503350] Epoch: [14]  [260/345]  eta: 0:00:21  lr: 0.000092  loss: 0.8371 (0.8343)  time: 0.2516  data: 0.0001  max mem: 10917
[09:26:51.550466] Epoch: [14]  [280/345]  eta: 0:00:16  lr: 0.000093  loss: 0.8208 (0.8334)  time: 0.2523  data: 0.0001  max mem: 10917
[09:26:56.595879] Epoch: [14]  [300/345]  eta: 0:00:11  lr: 0.000093  loss: 0.8278 (0.8329)  time: 0.2522  data: 0.0000  max mem: 10917
[09:27:01.641197] Epoch: [14]  [320/345]  eta: 0:00:06  lr: 0.000093  loss: 0.8163 (0.8320)  time: 0.2522  data: 0.0001  max mem: 10917
[09:27:06.675266] Epoch: [14]  [340/345]  eta: 0:00:01  lr: 0.000094  loss: 0.8094 (0.8311)  time: 0.2517  data: 0.0001  max mem: 10917
[09:27:07.673502] Epoch: [14]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.8094 (0.8311)  time: 0.2512  data: 0.0001  max mem: 10917
[09:27:07.730723] Epoch: [14] Total time: 0:01:26 (0.2518 s / it)
[09:27:07.731181] Averaged stats: lr: 0.000094  loss: 0.8094 (0.8311)
[09:27:07.968932] Test:  [  0/345]  eta: 0:01:21  loss: 0.7820 (0.7820)  time: 0.2348  data: 0.1547  max mem: 10917
[09:27:08.791692] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7803 (0.7817)  time: 0.0961  data: 0.0144  max mem: 10917
[09:27:09.615555] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7780 (0.7812)  time: 0.0823  data: 0.0002  max mem: 10917
[09:27:10.441937] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7721 (0.7782)  time: 0.0825  data: 0.0001  max mem: 10917
[09:27:11.272370] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7662 (0.7787)  time: 0.0828  data: 0.0001  max mem: 10917
[09:27:12.106200] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7799 (0.7793)  time: 0.0832  data: 0.0001  max mem: 10917
[09:27:12.944206] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7816 (0.7809)  time: 0.0835  data: 0.0001  max mem: 10917
[09:27:13.784785] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7787 (0.7799)  time: 0.0839  data: 0.0001  max mem: 10917
[09:27:14.629904] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7779 (0.7812)  time: 0.0842  data: 0.0001  max mem: 10917
[09:27:15.478753] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7760 (0.7804)  time: 0.0846  data: 0.0001  max mem: 10917
[09:27:16.331146] Test:  [100/345]  eta: 0:00:20  loss: 0.7760 (0.7806)  time: 0.0850  data: 0.0001  max mem: 10917
[09:27:17.185795] Test:  [110/345]  eta: 0:00:19  loss: 0.7810 (0.7811)  time: 0.0853  data: 0.0001  max mem: 10917
[09:27:18.044528] Test:  [120/345]  eta: 0:00:19  loss: 0.7872 (0.7820)  time: 0.0856  data: 0.0001  max mem: 10917
[09:27:18.906750] Test:  [130/345]  eta: 0:00:18  loss: 0.7915 (0.7825)  time: 0.0860  data: 0.0001  max mem: 10917
[09:27:19.773203] Test:  [140/345]  eta: 0:00:17  loss: 0.7760 (0.7819)  time: 0.0864  data: 0.0001  max mem: 10917
[09:27:20.642597] Test:  [150/345]  eta: 0:00:16  loss: 0.7767 (0.7825)  time: 0.0867  data: 0.0001  max mem: 10917
[09:27:21.516085] Test:  [160/345]  eta: 0:00:15  loss: 0.7812 (0.7824)  time: 0.0871  data: 0.0001  max mem: 10917
[09:27:22.392181] Test:  [170/345]  eta: 0:00:14  loss: 0.7815 (0.7822)  time: 0.0874  data: 0.0001  max mem: 10917
[09:27:23.271838] Test:  [180/345]  eta: 0:00:14  loss: 0.7818 (0.7822)  time: 0.0877  data: 0.0001  max mem: 10917
[09:27:24.155117] Test:  [190/345]  eta: 0:00:13  loss: 0.7769 (0.7820)  time: 0.0881  data: 0.0001  max mem: 10917
[09:27:25.042560] Test:  [200/345]  eta: 0:00:12  loss: 0.7783 (0.7818)  time: 0.0885  data: 0.0001  max mem: 10917
[09:27:25.934042] Test:  [210/345]  eta: 0:00:11  loss: 0.7783 (0.7816)  time: 0.0889  data: 0.0001  max mem: 10917
[09:27:26.828744] Test:  [220/345]  eta: 0:00:10  loss: 0.7748 (0.7817)  time: 0.0893  data: 0.0001  max mem: 10917
[09:27:27.725783] Test:  [230/345]  eta: 0:00:09  loss: 0.7758 (0.7817)  time: 0.0895  data: 0.0001  max mem: 10917
[09:27:28.627017] Test:  [240/345]  eta: 0:00:09  loss: 0.7830 (0.7823)  time: 0.0899  data: 0.0001  max mem: 10917
[09:27:29.532412] Test:  [250/345]  eta: 0:00:08  loss: 0.7854 (0.7824)  time: 0.0903  data: 0.0001  max mem: 10917
[09:27:30.440113] Test:  [260/345]  eta: 0:00:07  loss: 0.7877 (0.7826)  time: 0.0906  data: 0.0001  max mem: 10917
[09:27:31.352128] Test:  [270/345]  eta: 0:00:06  loss: 0.7877 (0.7827)  time: 0.0909  data: 0.0001  max mem: 10917
[09:27:32.267091] Test:  [280/345]  eta: 0:00:05  loss: 0.7749 (0.7824)  time: 0.0913  data: 0.0001  max mem: 10917
[09:27:33.186298] Test:  [290/345]  eta: 0:00:04  loss: 0.7755 (0.7823)  time: 0.0917  data: 0.0001  max mem: 10917
[09:27:34.108529] Test:  [300/345]  eta: 0:00:03  loss: 0.7836 (0.7826)  time: 0.0920  data: 0.0001  max mem: 10917
[09:27:35.034619] Test:  [310/345]  eta: 0:00:03  loss: 0.7865 (0.7825)  time: 0.0924  data: 0.0001  max mem: 10917
[09:27:35.963539] Test:  [320/345]  eta: 0:00:02  loss: 0.7815 (0.7824)  time: 0.0927  data: 0.0001  max mem: 10917
[09:27:36.896711] Test:  [330/345]  eta: 0:00:01  loss: 0.7748 (0.7824)  time: 0.0931  data: 0.0001  max mem: 10917
[09:27:37.832560] Test:  [340/345]  eta: 0:00:00  loss: 0.7714 (0.7823)  time: 0.0934  data: 0.0001  max mem: 10917
[09:27:38.208927] Test:  [344/345]  eta: 0:00:00  loss: 0.7830 (0.7825)  time: 0.0936  data: 0.0001  max mem: 10917
[09:27:38.266132] Test: Total time: 0:00:30 (0.0885 s / it)
[09:27:48.735528] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8758 (0.8758)  time: 0.2190  data: 0.1395  max mem: 10917
[09:27:49.547813] Test:  [10/57]  eta: 0:00:04  loss: 0.8915 (0.9015)  time: 0.0937  data: 0.0127  max mem: 10917
[09:27:50.365290] Test:  [20/57]  eta: 0:00:03  loss: 0.8839 (0.8899)  time: 0.0814  data: 0.0001  max mem: 10917
[09:27:51.186383] Test:  [30/57]  eta: 0:00:02  loss: 0.7898 (0.8500)  time: 0.0819  data: 0.0001  max mem: 10917
[09:27:52.009801] Test:  [40/57]  eta: 0:00:01  loss: 0.7687 (0.8278)  time: 0.0822  data: 0.0001  max mem: 10917
[09:27:52.837970] Test:  [50/57]  eta: 0:00:00  loss: 0.7544 (0.8180)  time: 0.0825  data: 0.0001  max mem: 10917
[09:27:53.288084] Test:  [56/57]  eta: 0:00:00  loss: 0.7824 (0.8227)  time: 0.0803  data: 0.0001  max mem: 10917
[09:27:53.344434] Test: Total time: 0:00:04 (0.0847 s / it)
[09:27:55.122972] Dice score of the network on the train images: 0.775907, val images: 0.812762
[09:27:55.123195] saving best_dice_model_0 @ epoch 14
[09:27:55.976978] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:27:56.373985] Epoch: [15]  [  0/345]  eta: 0:02:16  lr: 0.000094  loss: 0.7870 (0.7870)  time: 0.3958  data: 0.1433  max mem: 10917
[09:28:01.363329] Epoch: [15]  [ 20/345]  eta: 0:01:23  lr: 0.000094  loss: 0.8165 (0.8199)  time: 0.2494  data: 0.0001  max mem: 10917
[09:28:06.367457] Epoch: [15]  [ 40/345]  eta: 0:01:17  lr: 0.000094  loss: 0.8135 (0.8169)  time: 0.2502  data: 0.0000  max mem: 10917
[09:28:11.374943] Epoch: [15]  [ 60/345]  eta: 0:01:11  lr: 0.000095  loss: 0.8000 (0.8138)  time: 0.2503  data: 0.0000  max mem: 10917
[09:28:16.390711] Epoch: [15]  [ 80/345]  eta: 0:01:06  lr: 0.000095  loss: 0.8101 (0.8135)  time: 0.2507  data: 0.0000  max mem: 10917
[09:28:21.413256] Epoch: [15]  [100/345]  eta: 0:01:01  lr: 0.000096  loss: 0.8256 (0.8158)  time: 0.2511  data: 0.0000  max mem: 10917
[09:28:26.437459] Epoch: [15]  [120/345]  eta: 0:00:56  lr: 0.000096  loss: 0.8338 (0.8186)  time: 0.2512  data: 0.0000  max mem: 10917
[09:28:31.467631] Epoch: [15]  [140/345]  eta: 0:00:51  lr: 0.000096  loss: 0.8387 (0.8214)  time: 0.2515  data: 0.0001  max mem: 10917
[09:28:36.497636] Epoch: [15]  [160/345]  eta: 0:00:46  lr: 0.000097  loss: 0.8123 (0.8205)  time: 0.2515  data: 0.0000  max mem: 10917
[09:28:41.534810] Epoch: [15]  [180/345]  eta: 0:00:41  lr: 0.000097  loss: 0.8147 (0.8199)  time: 0.2518  data: 0.0000  max mem: 10917
[09:28:46.567755] Epoch: [15]  [200/345]  eta: 0:00:36  lr: 0.000097  loss: 0.8197 (0.8200)  time: 0.2516  data: 0.0000  max mem: 10917
[09:28:51.609589] Epoch: [15]  [220/345]  eta: 0:00:31  lr: 0.000098  loss: 0.8154 (0.8196)  time: 0.2520  data: 0.0001  max mem: 10917
[09:28:56.651989] Epoch: [15]  [240/345]  eta: 0:00:26  lr: 0.000098  loss: 0.8098 (0.8188)  time: 0.2521  data: 0.0000  max mem: 10917
[09:29:01.692832] Epoch: [15]  [260/345]  eta: 0:00:21  lr: 0.000098  loss: 0.8042 (0.8179)  time: 0.2520  data: 0.0000  max mem: 10917
[09:29:06.736862] Epoch: [15]  [280/345]  eta: 0:00:16  lr: 0.000099  loss: 0.8204 (0.8178)  time: 0.2522  data: 0.0000  max mem: 10917
[09:29:11.788141] Epoch: [15]  [300/345]  eta: 0:00:11  lr: 0.000099  loss: 0.8296 (0.8185)  time: 0.2525  data: 0.0001  max mem: 10917
[09:29:16.836298] Epoch: [15]  [320/345]  eta: 0:00:06  lr: 0.000100  loss: 0.8307 (0.8193)  time: 0.2524  data: 0.0000  max mem: 10917
[09:29:21.885897] Epoch: [15]  [340/345]  eta: 0:00:01  lr: 0.000100  loss: 0.8183 (0.8194)  time: 0.2524  data: 0.0000  max mem: 10917
[09:29:22.897442] Epoch: [15]  [344/345]  eta: 0:00:00  lr: 0.000100  loss: 0.8183 (0.8195)  time: 0.2525  data: 0.0001  max mem: 10917
[09:29:22.951409] Epoch: [15] Total time: 0:01:26 (0.2521 s / it)
[09:29:22.951761] Averaged stats: lr: 0.000100  loss: 0.8183 (0.8195)
[09:29:23.185439] Test:  [  0/345]  eta: 0:01:19  loss: 0.7800 (0.7800)  time: 0.2301  data: 0.1499  max mem: 10917
[09:29:24.005702] Test:  [ 10/345]  eta: 0:00:31  loss: 0.7808 (0.7835)  time: 0.0954  data: 0.0137  max mem: 10917
[09:29:24.829605] Test:  [ 20/345]  eta: 0:00:28  loss: 0.7832 (0.7837)  time: 0.0822  data: 0.0001  max mem: 10917
[09:29:25.656008] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7859 (0.7864)  time: 0.0825  data: 0.0001  max mem: 10917
[09:29:26.486363] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7804 (0.7829)  time: 0.0828  data: 0.0001  max mem: 10917
[09:29:27.320993] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7775 (0.7833)  time: 0.0832  data: 0.0001  max mem: 10917
[09:29:28.159286] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7765 (0.7825)  time: 0.0836  data: 0.0001  max mem: 10917
[09:29:28.999832] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7765 (0.7821)  time: 0.0839  data: 0.0001  max mem: 10917
[09:29:29.845101] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7819 (0.7820)  time: 0.0842  data: 0.0001  max mem: 10917
[09:29:30.693984] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7811 (0.7820)  time: 0.0847  data: 0.0001  max mem: 10917
[09:29:31.546059] Test:  [100/345]  eta: 0:00:20  loss: 0.7783 (0.7820)  time: 0.0850  data: 0.0001  max mem: 10917
[09:29:32.401459] Test:  [110/345]  eta: 0:00:19  loss: 0.7853 (0.7838)  time: 0.0853  data: 0.0001  max mem: 10917
[09:29:33.260411] Test:  [120/345]  eta: 0:00:19  loss: 0.7849 (0.7833)  time: 0.0857  data: 0.0001  max mem: 10917
[09:29:34.122974] Test:  [130/345]  eta: 0:00:18  loss: 0.7742 (0.7828)  time: 0.0860  data: 0.0001  max mem: 10917
[09:29:34.989031] Test:  [140/345]  eta: 0:00:17  loss: 0.7814 (0.7832)  time: 0.0864  data: 0.0001  max mem: 10917
[09:29:35.858513] Test:  [150/345]  eta: 0:00:16  loss: 0.7916 (0.7843)  time: 0.0867  data: 0.0001  max mem: 10917
[09:29:36.731292] Test:  [160/345]  eta: 0:00:15  loss: 0.7897 (0.7844)  time: 0.0871  data: 0.0001  max mem: 10917
[09:29:37.608545] Test:  [170/345]  eta: 0:00:14  loss: 0.7801 (0.7839)  time: 0.0875  data: 0.0001  max mem: 10917
[09:29:38.488730] Test:  [180/345]  eta: 0:00:14  loss: 0.7812 (0.7836)  time: 0.0878  data: 0.0001  max mem: 10917
[09:29:39.372147] Test:  [190/345]  eta: 0:00:13  loss: 0.7846 (0.7839)  time: 0.0881  data: 0.0001  max mem: 10917
[09:29:40.258851] Test:  [200/345]  eta: 0:00:12  loss: 0.7836 (0.7842)  time: 0.0885  data: 0.0001  max mem: 10917
[09:29:41.149873] Test:  [210/345]  eta: 0:00:11  loss: 0.7863 (0.7846)  time: 0.0888  data: 0.0001  max mem: 10917
[09:29:42.042894] Test:  [220/345]  eta: 0:00:10  loss: 0.7878 (0.7849)  time: 0.0892  data: 0.0001  max mem: 10917
[09:29:42.941595] Test:  [230/345]  eta: 0:00:09  loss: 0.7922 (0.7852)  time: 0.0895  data: 0.0001  max mem: 10917
[09:29:43.842868] Test:  [240/345]  eta: 0:00:09  loss: 0.7854 (0.7851)  time: 0.0899  data: 0.0001  max mem: 10917
[09:29:44.746965] Test:  [250/345]  eta: 0:00:08  loss: 0.7808 (0.7848)  time: 0.0902  data: 0.0001  max mem: 10917
[09:29:45.655412] Test:  [260/345]  eta: 0:00:07  loss: 0.7780 (0.7850)  time: 0.0906  data: 0.0001  max mem: 10917
[09:29:46.567135] Test:  [270/345]  eta: 0:00:06  loss: 0.7811 (0.7848)  time: 0.0910  data: 0.0001  max mem: 10917
[09:29:47.482058] Test:  [280/345]  eta: 0:00:05  loss: 0.7862 (0.7849)  time: 0.0913  data: 0.0001  max mem: 10917
[09:29:48.402040] Test:  [290/345]  eta: 0:00:04  loss: 0.7916 (0.7852)  time: 0.0917  data: 0.0001  max mem: 10917
[09:29:49.324406] Test:  [300/345]  eta: 0:00:03  loss: 0.7867 (0.7852)  time: 0.0921  data: 0.0001  max mem: 10917
[09:29:50.250169] Test:  [310/345]  eta: 0:00:03  loss: 0.7827 (0.7852)  time: 0.0924  data: 0.0001  max mem: 10917
[09:29:51.180073] Test:  [320/345]  eta: 0:00:02  loss: 0.7698 (0.7847)  time: 0.0927  data: 0.0001  max mem: 10917
[09:29:52.113118] Test:  [330/345]  eta: 0:00:01  loss: 0.7682 (0.7848)  time: 0.0931  data: 0.0001  max mem: 10917
[09:29:53.049508] Test:  [340/345]  eta: 0:00:00  loss: 0.7722 (0.7846)  time: 0.0934  data: 0.0001  max mem: 10917
[09:29:53.425583] Test:  [344/345]  eta: 0:00:00  loss: 0.7722 (0.7844)  time: 0.0936  data: 0.0001  max mem: 10917
[09:29:53.483152] Test: Total time: 0:00:30 (0.0885 s / it)
[09:30:03.994080] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8938 (0.8938)  time: 0.2183  data: 0.1386  max mem: 10917
[09:30:04.806899] Test:  [10/57]  eta: 0:00:04  loss: 0.9019 (0.9134)  time: 0.0937  data: 0.0127  max mem: 10917
[09:30:05.624515] Test:  [20/57]  eta: 0:00:03  loss: 0.9019 (0.8963)  time: 0.0815  data: 0.0001  max mem: 10917
[09:30:06.446528] Test:  [30/57]  eta: 0:00:02  loss: 0.7880 (0.8555)  time: 0.0819  data: 0.0001  max mem: 10917
[09:30:07.272012] Test:  [40/57]  eta: 0:00:01  loss: 0.7716 (0.8335)  time: 0.0823  data: 0.0001  max mem: 10917
[09:30:08.101221] Test:  [50/57]  eta: 0:00:00  loss: 0.7768 (0.8256)  time: 0.0827  data: 0.0001  max mem: 10917
[09:30:08.551177] Test:  [56/57]  eta: 0:00:00  loss: 0.7856 (0.8299)  time: 0.0804  data: 0.0001  max mem: 10917
[09:30:08.603180] Test: Total time: 0:00:04 (0.0847 s / it)
[09:30:10.374826] Dice score of the network on the train images: 0.779409, val images: 0.797380
[09:30:10.378504] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:30:10.774109] Epoch: [16]  [  0/345]  eta: 0:02:16  lr: 0.000100  loss: 0.8104 (0.8104)  time: 0.3946  data: 0.1416  max mem: 10917
[09:30:15.780695] Epoch: [16]  [ 20/345]  eta: 0:01:23  lr: 0.000100  loss: 0.8257 (0.8255)  time: 0.2503  data: 0.0001  max mem: 10917
[09:30:20.790859] Epoch: [16]  [ 40/345]  eta: 0:01:17  lr: 0.000101  loss: 0.8074 (0.8205)  time: 0.2505  data: 0.0001  max mem: 10917
[09:30:25.790955] Epoch: [16]  [ 60/345]  eta: 0:01:11  lr: 0.000101  loss: 0.8126 (0.8192)  time: 0.2500  data: 0.0001  max mem: 10917
[09:30:30.800610] Epoch: [16]  [ 80/345]  eta: 0:01:06  lr: 0.000101  loss: 0.8061 (0.8181)  time: 0.2504  data: 0.0000  max mem: 10917
[09:30:35.822464] Epoch: [16]  [100/345]  eta: 0:01:01  lr: 0.000102  loss: 0.8589 (0.8266)  time: 0.2510  data: 0.0001  max mem: 10917
[09:30:40.845001] Epoch: [16]  [120/345]  eta: 0:00:56  lr: 0.000102  loss: 0.8145 (0.8255)  time: 0.2511  data: 0.0000  max mem: 10917
[09:30:45.869542] Epoch: [16]  [140/345]  eta: 0:00:51  lr: 0.000103  loss: 0.8282 (0.8252)  time: 0.2512  data: 0.0001  max mem: 10917
[09:30:50.892224] Epoch: [16]  [160/345]  eta: 0:00:46  lr: 0.000103  loss: 0.8112 (0.8240)  time: 0.2511  data: 0.0000  max mem: 10917
[09:30:55.996097] Epoch: [16]  [180/345]  eta: 0:00:41  lr: 0.000103  loss: 0.8089 (0.8227)  time: 0.2552  data: 0.0001  max mem: 10917
[09:31:01.027554] Epoch: [16]  [200/345]  eta: 0:00:36  lr: 0.000104  loss: 0.8127 (0.8218)  time: 0.2515  data: 0.0001  max mem: 10917
[09:31:06.061820] Epoch: [16]  [220/345]  eta: 0:00:31  lr: 0.000104  loss: 0.8131 (0.8212)  time: 0.2517  data: 0.0000  max mem: 10917
[09:31:11.096271] Epoch: [16]  [240/345]  eta: 0:00:26  lr: 0.000104  loss: 0.8102 (0.8207)  time: 0.2517  data: 0.0000  max mem: 10917
[09:31:16.139858] Epoch: [16]  [260/345]  eta: 0:00:21  lr: 0.000105  loss: 0.8087 (0.8201)  time: 0.2521  data: 0.0001  max mem: 10917
[09:31:21.179199] Epoch: [16]  [280/345]  eta: 0:00:16  lr: 0.000105  loss: 0.8199 (0.8200)  time: 0.2519  data: 0.0001  max mem: 10917
[09:31:26.221062] Epoch: [16]  [300/345]  eta: 0:00:11  lr: 0.000105  loss: 0.8044 (0.8191)  time: 0.2521  data: 0.0000  max mem: 10917
[09:31:31.262480] Epoch: [16]  [320/345]  eta: 0:00:06  lr: 0.000106  loss: 0.8115 (0.8186)  time: 0.2520  data: 0.0000  max mem: 10917
[09:31:36.308284] Epoch: [16]  [340/345]  eta: 0:00:01  lr: 0.000106  loss: 0.8264 (0.8189)  time: 0.2523  data: 0.0000  max mem: 10917
[09:31:37.317095] Epoch: [16]  [344/345]  eta: 0:00:00  lr: 0.000106  loss: 0.8265 (0.8190)  time: 0.2522  data: 0.0001  max mem: 10917
[09:31:37.378538] Epoch: [16] Total time: 0:01:26 (0.2522 s / it)
[09:31:37.378675] Averaged stats: lr: 0.000106  loss: 0.8265 (0.8190)
[09:31:37.609688] Test:  [  0/345]  eta: 0:01:18  loss: 0.7762 (0.7762)  time: 0.2276  data: 0.1473  max mem: 10917
[09:31:38.467623] Test:  [ 10/345]  eta: 0:00:33  loss: 0.7944 (0.7915)  time: 0.0986  data: 0.0171  max mem: 10917
[09:31:39.304083] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7822 (0.7900)  time: 0.0847  data: 0.0028  max mem: 10917
[09:31:40.131126] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7790 (0.7852)  time: 0.0831  data: 0.0008  max mem: 10917
[09:31:40.961686] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7775 (0.7855)  time: 0.0828  data: 0.0001  max mem: 10917
[09:31:41.795545] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7846 (0.7863)  time: 0.0832  data: 0.0001  max mem: 10917
[09:31:42.633410] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7945 (0.7885)  time: 0.0835  data: 0.0001  max mem: 10917
[09:31:43.474300] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7925 (0.7879)  time: 0.0839  data: 0.0001  max mem: 10917
[09:31:44.318388] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7861 (0.7886)  time: 0.0842  data: 0.0001  max mem: 10917
[09:31:45.166524] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7872 (0.7888)  time: 0.0846  data: 0.0001  max mem: 10917
[09:31:46.017085] Test:  [100/345]  eta: 0:00:20  loss: 0.7960 (0.7890)  time: 0.0849  data: 0.0001  max mem: 10917
[09:31:46.872962] Test:  [110/345]  eta: 0:00:20  loss: 0.7967 (0.7893)  time: 0.0853  data: 0.0001  max mem: 10917
[09:31:47.731298] Test:  [120/345]  eta: 0:00:19  loss: 0.7930 (0.7893)  time: 0.0857  data: 0.0001  max mem: 10917
[09:31:48.593281] Test:  [130/345]  eta: 0:00:18  loss: 0.7845 (0.7900)  time: 0.0860  data: 0.0001  max mem: 10917
[09:31:49.459584] Test:  [140/345]  eta: 0:00:17  loss: 0.7932 (0.7902)  time: 0.0864  data: 0.0001  max mem: 10917
[09:31:50.329059] Test:  [150/345]  eta: 0:00:16  loss: 0.7932 (0.7905)  time: 0.0867  data: 0.0001  max mem: 10917
[09:31:51.201961] Test:  [160/345]  eta: 0:00:15  loss: 0.7820 (0.7903)  time: 0.0871  data: 0.0001  max mem: 10917
[09:31:52.078105] Test:  [170/345]  eta: 0:00:15  loss: 0.7764 (0.7897)  time: 0.0874  data: 0.0001  max mem: 10917
[09:31:52.957953] Test:  [180/345]  eta: 0:00:14  loss: 0.7829 (0.7898)  time: 0.0878  data: 0.0001  max mem: 10917
[09:31:53.841179] Test:  [190/345]  eta: 0:00:13  loss: 0.7833 (0.7892)  time: 0.0881  data: 0.0001  max mem: 10917
[09:31:54.728689] Test:  [200/345]  eta: 0:00:12  loss: 0.7805 (0.7888)  time: 0.0885  data: 0.0001  max mem: 10917
[09:31:55.619031] Test:  [210/345]  eta: 0:00:11  loss: 0.7866 (0.7891)  time: 0.0888  data: 0.0001  max mem: 10917
[09:31:56.512627] Test:  [220/345]  eta: 0:00:10  loss: 0.7915 (0.7890)  time: 0.0892  data: 0.0001  max mem: 10917
[09:31:57.410341] Test:  [230/345]  eta: 0:00:09  loss: 0.7897 (0.7891)  time: 0.0895  data: 0.0001  max mem: 10917
[09:31:58.311541] Test:  [240/345]  eta: 0:00:09  loss: 0.7873 (0.7886)  time: 0.0899  data: 0.0001  max mem: 10917
[09:31:59.215050] Test:  [250/345]  eta: 0:00:08  loss: 0.7879 (0.7890)  time: 0.0902  data: 0.0001  max mem: 10917
[09:32:00.122294] Test:  [260/345]  eta: 0:00:07  loss: 0.8032 (0.7897)  time: 0.0905  data: 0.0001  max mem: 10917
[09:32:01.033833] Test:  [270/345]  eta: 0:00:06  loss: 0.7900 (0.7895)  time: 0.0909  data: 0.0001  max mem: 10917
[09:32:01.949077] Test:  [280/345]  eta: 0:00:05  loss: 0.7886 (0.7898)  time: 0.0913  data: 0.0001  max mem: 10917
[09:32:02.867240] Test:  [290/345]  eta: 0:00:04  loss: 0.7856 (0.7894)  time: 0.0916  data: 0.0001  max mem: 10917
[09:32:03.789111] Test:  [300/345]  eta: 0:00:03  loss: 0.7820 (0.7895)  time: 0.0920  data: 0.0001  max mem: 10917
[09:32:04.714119] Test:  [310/345]  eta: 0:00:03  loss: 0.7911 (0.7894)  time: 0.0923  data: 0.0001  max mem: 10917
[09:32:05.643039] Test:  [320/345]  eta: 0:00:02  loss: 0.7781 (0.7892)  time: 0.0926  data: 0.0001  max mem: 10917
[09:32:06.575460] Test:  [330/345]  eta: 0:00:01  loss: 0.7845 (0.7891)  time: 0.0930  data: 0.0001  max mem: 10917
[09:32:07.511611] Test:  [340/345]  eta: 0:00:00  loss: 0.7848 (0.7888)  time: 0.0934  data: 0.0001  max mem: 10917
[09:32:07.887063] Test:  [344/345]  eta: 0:00:00  loss: 0.7899 (0.7890)  time: 0.0935  data: 0.0001  max mem: 10917
[09:32:07.924121] Test: Total time: 0:00:30 (0.0885 s / it)
[09:32:18.321295] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8626 (0.8626)  time: 0.2206  data: 0.1407  max mem: 10917
[09:32:19.135670] Test:  [10/57]  eta: 0:00:04  loss: 0.8785 (0.8823)  time: 0.0940  data: 0.0129  max mem: 10917
[09:32:19.952618] Test:  [20/57]  eta: 0:00:03  loss: 0.8785 (0.8749)  time: 0.0815  data: 0.0001  max mem: 10917
[09:32:20.773344] Test:  [30/57]  eta: 0:00:02  loss: 0.7755 (0.8379)  time: 0.0818  data: 0.0001  max mem: 10917
[09:32:21.597637] Test:  [40/57]  eta: 0:00:01  loss: 0.7615 (0.8174)  time: 0.0822  data: 0.0001  max mem: 10917
[09:32:22.425967] Test:  [50/57]  eta: 0:00:00  loss: 0.7550 (0.8111)  time: 0.0826  data: 0.0001  max mem: 10917
[09:32:22.875380] Test:  [56/57]  eta: 0:00:00  loss: 0.7921 (0.8158)  time: 0.0803  data: 0.0001  max mem: 10917
[09:32:22.914528] Test: Total time: 0:00:04 (0.0845 s / it)
[09:32:24.676008] Dice score of the network on the train images: 0.748844, val images: 0.793703
[09:32:24.679500] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:32:25.072620] Epoch: [17]  [  0/345]  eta: 0:02:15  lr: 0.000106  loss: 0.8216 (0.8216)  time: 0.3923  data: 0.1407  max mem: 10917
[09:32:30.076224] Epoch: [17]  [ 20/345]  eta: 0:01:23  lr: 0.000107  loss: 0.8074 (0.8135)  time: 0.2501  data: 0.0001  max mem: 10917
[09:32:35.091887] Epoch: [17]  [ 40/345]  eta: 0:01:17  lr: 0.000107  loss: 0.8317 (0.8213)  time: 0.2507  data: 0.0000  max mem: 10917
[09:32:40.106310] Epoch: [17]  [ 60/345]  eta: 0:01:12  lr: 0.000107  loss: 0.8128 (0.8187)  time: 0.2507  data: 0.0000  max mem: 10917
[09:32:45.120320] Epoch: [17]  [ 80/345]  eta: 0:01:06  lr: 0.000108  loss: 0.8002 (0.8156)  time: 0.2507  data: 0.0000  max mem: 10917
[09:32:50.140842] Epoch: [17]  [100/345]  eta: 0:01:01  lr: 0.000108  loss: 0.8092 (0.8151)  time: 0.2510  data: 0.0000  max mem: 10917
[09:32:55.165685] Epoch: [17]  [120/345]  eta: 0:00:56  lr: 0.000108  loss: 0.8277 (0.8179)  time: 0.2512  data: 0.0000  max mem: 10917
[09:33:00.194772] Epoch: [17]  [140/345]  eta: 0:00:51  lr: 0.000109  loss: 0.8343 (0.8202)  time: 0.2514  data: 0.0000  max mem: 10917
[09:33:05.223295] Epoch: [17]  [160/345]  eta: 0:00:46  lr: 0.000109  loss: 0.8321 (0.8216)  time: 0.2514  data: 0.0000  max mem: 10917
[09:33:10.256511] Epoch: [17]  [180/345]  eta: 0:00:41  lr: 0.000110  loss: 0.8140 (0.8213)  time: 0.2516  data: 0.0001  max mem: 10917
[09:33:15.290646] Epoch: [17]  [200/345]  eta: 0:00:36  lr: 0.000110  loss: 0.8004 (0.8195)  time: 0.2517  data: 0.0000  max mem: 10917
[09:33:20.325192] Epoch: [17]  [220/345]  eta: 0:00:31  lr: 0.000110  loss: 0.8102 (0.8190)  time: 0.2517  data: 0.0000  max mem: 10917
[09:33:25.361492] Epoch: [17]  [240/345]  eta: 0:00:26  lr: 0.000111  loss: 0.8152 (0.8189)  time: 0.2518  data: 0.0001  max mem: 10917
[09:33:30.398141] Epoch: [17]  [260/345]  eta: 0:00:21  lr: 0.000111  loss: 0.7976 (0.8177)  time: 0.2518  data: 0.0000  max mem: 10917
[09:33:35.436804] Epoch: [17]  [280/345]  eta: 0:00:16  lr: 0.000111  loss: 0.8072 (0.8169)  time: 0.2519  data: 0.0000  max mem: 10917
[09:33:40.480405] Epoch: [17]  [300/345]  eta: 0:00:11  lr: 0.000112  loss: 0.8018 (0.8160)  time: 0.2521  data: 0.0000  max mem: 10917
[09:33:45.523192] Epoch: [17]  [320/345]  eta: 0:00:06  lr: 0.000112  loss: 0.8015 (0.8153)  time: 0.2521  data: 0.0000  max mem: 10917
[09:33:50.567840] Epoch: [17]  [340/345]  eta: 0:00:01  lr: 0.000112  loss: 0.7998 (0.8145)  time: 0.2522  data: 0.0000  max mem: 10917
[09:33:51.576401] Epoch: [17]  [344/345]  eta: 0:00:00  lr: 0.000112  loss: 0.8003 (0.8143)  time: 0.2522  data: 0.0001  max mem: 10917
[09:33:51.633099] Epoch: [17] Total time: 0:01:26 (0.2520 s / it)
[09:33:51.633610] Averaged stats: lr: 0.000112  loss: 0.8003 (0.8143)
[09:33:51.872349] Test:  [  0/345]  eta: 0:01:21  loss: 0.7986 (0.7986)  time: 0.2353  data: 0.1549  max mem: 10917
[09:33:52.692178] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7781 (0.7823)  time: 0.0959  data: 0.0141  max mem: 10917
[09:33:53.516142] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7768 (0.7766)  time: 0.0821  data: 0.0001  max mem: 10917
[09:33:54.343745] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7684 (0.7744)  time: 0.0825  data: 0.0001  max mem: 10917
[09:33:55.174383] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7763 (0.7749)  time: 0.0829  data: 0.0001  max mem: 10917
[09:33:56.009413] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7661 (0.7724)  time: 0.0832  data: 0.0001  max mem: 10917
[09:33:56.848077] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7593 (0.7699)  time: 0.0836  data: 0.0001  max mem: 10917
[09:33:57.689375] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7613 (0.7698)  time: 0.0839  data: 0.0001  max mem: 10917
[09:33:58.533405] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7709 (0.7693)  time: 0.0842  data: 0.0001  max mem: 10917
[09:33:59.380977] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7675 (0.7692)  time: 0.0845  data: 0.0001  max mem: 10917
[09:34:00.232159] Test:  [100/345]  eta: 0:00:20  loss: 0.7682 (0.7689)  time: 0.0849  data: 0.0001  max mem: 10917
[09:34:01.087318] Test:  [110/345]  eta: 0:00:19  loss: 0.7682 (0.7688)  time: 0.0853  data: 0.0001  max mem: 10917
[09:34:01.946666] Test:  [120/345]  eta: 0:00:19  loss: 0.7611 (0.7682)  time: 0.0857  data: 0.0001  max mem: 10917
[09:34:02.808740] Test:  [130/345]  eta: 0:00:18  loss: 0.7627 (0.7679)  time: 0.0860  data: 0.0001  max mem: 10917
[09:34:03.674191] Test:  [140/345]  eta: 0:00:17  loss: 0.7692 (0.7688)  time: 0.0863  data: 0.0001  max mem: 10917
[09:34:04.544164] Test:  [150/345]  eta: 0:00:16  loss: 0.7797 (0.7693)  time: 0.0867  data: 0.0001  max mem: 10917
[09:34:05.416347] Test:  [160/345]  eta: 0:00:15  loss: 0.7695 (0.7696)  time: 0.0871  data: 0.0001  max mem: 10917
[09:34:06.292693] Test:  [170/345]  eta: 0:00:14  loss: 0.7685 (0.7696)  time: 0.0874  data: 0.0001  max mem: 10917
[09:34:07.173071] Test:  [180/345]  eta: 0:00:14  loss: 0.7679 (0.7695)  time: 0.0878  data: 0.0001  max mem: 10917
[09:34:08.055797] Test:  [190/345]  eta: 0:00:13  loss: 0.7679 (0.7696)  time: 0.0881  data: 0.0001  max mem: 10917
[09:34:08.942775] Test:  [200/345]  eta: 0:00:12  loss: 0.7612 (0.7691)  time: 0.0884  data: 0.0001  max mem: 10917
[09:34:09.832488] Test:  [210/345]  eta: 0:00:11  loss: 0.7621 (0.7691)  time: 0.0888  data: 0.0001  max mem: 10917
[09:34:10.726877] Test:  [220/345]  eta: 0:00:10  loss: 0.7658 (0.7688)  time: 0.0892  data: 0.0001  max mem: 10917
[09:34:11.624060] Test:  [230/345]  eta: 0:00:09  loss: 0.7616 (0.7684)  time: 0.0895  data: 0.0001  max mem: 10917
[09:34:12.525644] Test:  [240/345]  eta: 0:00:09  loss: 0.7695 (0.7687)  time: 0.0899  data: 0.0001  max mem: 10917
[09:34:13.428974] Test:  [250/345]  eta: 0:00:08  loss: 0.7721 (0.7685)  time: 0.0902  data: 0.0001  max mem: 10917
[09:34:14.336644] Test:  [260/345]  eta: 0:00:07  loss: 0.7613 (0.7682)  time: 0.0905  data: 0.0001  max mem: 10917
[09:34:15.248862] Test:  [270/345]  eta: 0:00:06  loss: 0.7599 (0.7679)  time: 0.0909  data: 0.0001  max mem: 10917
[09:34:16.163920] Test:  [280/345]  eta: 0:00:05  loss: 0.7622 (0.7678)  time: 0.0913  data: 0.0001  max mem: 10917
[09:34:17.082872] Test:  [290/345]  eta: 0:00:04  loss: 0.7675 (0.7678)  time: 0.0917  data: 0.0001  max mem: 10917
[09:34:18.005401] Test:  [300/345]  eta: 0:00:03  loss: 0.7675 (0.7679)  time: 0.0920  data: 0.0001  max mem: 10917
[09:34:18.930480] Test:  [310/345]  eta: 0:00:03  loss: 0.7661 (0.7676)  time: 0.0923  data: 0.0001  max mem: 10917
[09:34:19.859939] Test:  [320/345]  eta: 0:00:02  loss: 0.7514 (0.7672)  time: 0.0927  data: 0.0001  max mem: 10917
[09:34:20.792403] Test:  [330/345]  eta: 0:00:01  loss: 0.7656 (0.7674)  time: 0.0930  data: 0.0001  max mem: 10917
[09:34:21.727867] Test:  [340/345]  eta: 0:00:00  loss: 0.7691 (0.7674)  time: 0.0933  data: 0.0001  max mem: 10917
[09:34:22.104176] Test:  [344/345]  eta: 0:00:00  loss: 0.7691 (0.7674)  time: 0.0935  data: 0.0001  max mem: 10917
[09:34:22.161502] Test: Total time: 0:00:30 (0.0885 s / it)
[09:34:32.501259] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9129 (0.9129)  time: 0.2169  data: 0.1373  max mem: 10917
[09:34:33.314101] Test:  [10/57]  eta: 0:00:04  loss: 0.9084 (0.8966)  time: 0.0935  data: 0.0125  max mem: 10917
[09:34:34.131153] Test:  [20/57]  eta: 0:00:03  loss: 0.8939 (0.8907)  time: 0.0814  data: 0.0001  max mem: 10917
[09:34:34.951030] Test:  [30/57]  eta: 0:00:02  loss: 0.7885 (0.8512)  time: 0.0818  data: 0.0001  max mem: 10917
[09:34:35.774668] Test:  [40/57]  eta: 0:00:01  loss: 0.7698 (0.8292)  time: 0.0821  data: 0.0001  max mem: 10917
[09:34:36.602231] Test:  [50/57]  eta: 0:00:00  loss: 0.7740 (0.8235)  time: 0.0825  data: 0.0001  max mem: 10917
[09:34:37.052381] Test:  [56/57]  eta: 0:00:00  loss: 0.7880 (0.8277)  time: 0.0803  data: 0.0001  max mem: 10917
[09:34:37.110605] Test: Total time: 0:00:04 (0.0847 s / it)
[09:34:38.879767] Dice score of the network on the train images: 0.788248, val images: 0.799963
[09:34:38.883300] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:34:39.283637] Epoch: [18]  [  0/345]  eta: 0:02:17  lr: 0.000113  loss: 0.7930 (0.7930)  time: 0.3994  data: 0.1466  max mem: 10917
[09:34:44.286645] Epoch: [18]  [ 20/345]  eta: 0:01:23  lr: 0.000113  loss: 0.8099 (0.8080)  time: 0.2501  data: 0.0000  max mem: 10917
[09:34:49.294492] Epoch: [18]  [ 40/345]  eta: 0:01:17  lr: 0.000113  loss: 0.8059 (0.8071)  time: 0.2504  data: 0.0000  max mem: 10917
[09:34:54.304528] Epoch: [18]  [ 60/345]  eta: 0:01:12  lr: 0.000114  loss: 0.8055 (0.8066)  time: 0.2505  data: 0.0000  max mem: 10917
[09:34:59.321437] Epoch: [18]  [ 80/345]  eta: 0:01:06  lr: 0.000114  loss: 0.8097 (0.8089)  time: 0.2508  data: 0.0000  max mem: 10917
[09:35:04.340730] Epoch: [18]  [100/345]  eta: 0:01:01  lr: 0.000114  loss: 0.8139 (0.8092)  time: 0.2509  data: 0.0000  max mem: 10917
[09:35:09.362517] Epoch: [18]  [120/345]  eta: 0:00:56  lr: 0.000115  loss: 0.7943 (0.8069)  time: 0.2510  data: 0.0000  max mem: 10917
[09:35:14.386529] Epoch: [18]  [140/345]  eta: 0:00:51  lr: 0.000115  loss: 0.8029 (0.8068)  time: 0.2512  data: 0.0000  max mem: 10917
[09:35:19.418751] Epoch: [18]  [160/345]  eta: 0:00:46  lr: 0.000115  loss: 0.8015 (0.8062)  time: 0.2516  data: 0.0001  max mem: 10917
[09:35:24.447280] Epoch: [18]  [180/345]  eta: 0:00:41  lr: 0.000116  loss: 0.8041 (0.8060)  time: 0.2514  data: 0.0001  max mem: 10917
[09:35:29.478162] Epoch: [18]  [200/345]  eta: 0:00:36  lr: 0.000116  loss: 0.8014 (0.8055)  time: 0.2515  data: 0.0001  max mem: 10917
[09:35:34.513247] Epoch: [18]  [220/345]  eta: 0:00:31  lr: 0.000116  loss: 0.7951 (0.8050)  time: 0.2517  data: 0.0001  max mem: 10917
[09:35:39.551579] Epoch: [18]  [240/345]  eta: 0:00:26  lr: 0.000117  loss: 0.7930 (0.8043)  time: 0.2519  data: 0.0001  max mem: 10917
[09:35:44.590082] Epoch: [18]  [260/345]  eta: 0:00:21  lr: 0.000117  loss: 0.7937 (0.8035)  time: 0.2519  data: 0.0000  max mem: 10917
[09:35:49.632725] Epoch: [18]  [280/345]  eta: 0:00:16  lr: 0.000118  loss: 0.8144 (0.8041)  time: 0.2521  data: 0.0000  max mem: 10917
[09:35:54.676268] Epoch: [18]  [300/345]  eta: 0:00:11  lr: 0.000118  loss: 0.8143 (0.8046)  time: 0.2521  data: 0.0001  max mem: 10917
[09:35:59.719483] Epoch: [18]  [320/345]  eta: 0:00:06  lr: 0.000118  loss: 0.8178 (0.8051)  time: 0.2521  data: 0.0001  max mem: 10917
[09:36:04.766504] Epoch: [18]  [340/345]  eta: 0:00:01  lr: 0.000119  loss: 0.7976 (0.8050)  time: 0.2523  data: 0.0001  max mem: 10917
[09:36:05.775312] Epoch: [18]  [344/345]  eta: 0:00:00  lr: 0.000119  loss: 0.8004 (0.8049)  time: 0.2523  data: 0.0001  max mem: 10917
[09:36:05.833017] Epoch: [18] Total time: 0:01:26 (0.2520 s / it)
[09:36:05.833530] Averaged stats: lr: 0.000119  loss: 0.8004 (0.8049)
[09:36:06.069587] Test:  [  0/345]  eta: 0:01:20  loss: 0.7643 (0.7643)  time: 0.2323  data: 0.1520  max mem: 10917
[09:36:06.898146] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7638 (0.7643)  time: 0.0964  data: 0.0147  max mem: 10917
[09:36:07.721165] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7585 (0.7607)  time: 0.0825  data: 0.0005  max mem: 10917
[09:36:08.547357] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7589 (0.7612)  time: 0.0824  data: 0.0001  max mem: 10917
[09:36:09.378170] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7567 (0.7602)  time: 0.0828  data: 0.0001  max mem: 10917
[09:36:10.211995] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7537 (0.7598)  time: 0.0832  data: 0.0001  max mem: 10917
[09:36:11.049202] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7627 (0.7625)  time: 0.0835  data: 0.0001  max mem: 10917
[09:36:11.890467] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7693 (0.7622)  time: 0.0839  data: 0.0001  max mem: 10917
[09:36:12.734960] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7566 (0.7622)  time: 0.0842  data: 0.0001  max mem: 10917
[09:36:13.583472] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7617 (0.7626)  time: 0.0846  data: 0.0001  max mem: 10917
[09:36:14.434718] Test:  [100/345]  eta: 0:00:20  loss: 0.7693 (0.7632)  time: 0.0849  data: 0.0001  max mem: 10917
[09:36:15.289491] Test:  [110/345]  eta: 0:00:19  loss: 0.7614 (0.7628)  time: 0.0853  data: 0.0001  max mem: 10917
[09:36:16.148122] Test:  [120/345]  eta: 0:00:19  loss: 0.7642 (0.7640)  time: 0.0856  data: 0.0001  max mem: 10917
[09:36:17.010336] Test:  [130/345]  eta: 0:00:18  loss: 0.7660 (0.7637)  time: 0.0860  data: 0.0001  max mem: 10917
[09:36:17.876385] Test:  [140/345]  eta: 0:00:17  loss: 0.7594 (0.7631)  time: 0.0864  data: 0.0001  max mem: 10917
[09:36:18.745443] Test:  [150/345]  eta: 0:00:16  loss: 0.7621 (0.7634)  time: 0.0867  data: 0.0001  max mem: 10917
[09:36:19.618569] Test:  [160/345]  eta: 0:00:15  loss: 0.7637 (0.7634)  time: 0.0871  data: 0.0001  max mem: 10917
[09:36:20.494563] Test:  [170/345]  eta: 0:00:14  loss: 0.7582 (0.7628)  time: 0.0874  data: 0.0001  max mem: 10917
[09:36:21.374229] Test:  [180/345]  eta: 0:00:14  loss: 0.7601 (0.7634)  time: 0.0877  data: 0.0001  max mem: 10917
[09:36:22.257296] Test:  [190/345]  eta: 0:00:13  loss: 0.7679 (0.7634)  time: 0.0881  data: 0.0001  max mem: 10917
[09:36:23.144449] Test:  [200/345]  eta: 0:00:12  loss: 0.7669 (0.7638)  time: 0.0885  data: 0.0001  max mem: 10917
[09:36:24.034347] Test:  [210/345]  eta: 0:00:11  loss: 0.7644 (0.7640)  time: 0.0888  data: 0.0001  max mem: 10917
[09:36:24.927602] Test:  [220/345]  eta: 0:00:10  loss: 0.7621 (0.7640)  time: 0.0891  data: 0.0001  max mem: 10917
[09:36:25.824647] Test:  [230/345]  eta: 0:00:09  loss: 0.7609 (0.7641)  time: 0.0895  data: 0.0001  max mem: 10917
[09:36:26.726623] Test:  [240/345]  eta: 0:00:09  loss: 0.7667 (0.7645)  time: 0.0899  data: 0.0001  max mem: 10917
[09:36:27.630545] Test:  [250/345]  eta: 0:00:08  loss: 0.7694 (0.7649)  time: 0.0902  data: 0.0001  max mem: 10917
[09:36:28.537658] Test:  [260/345]  eta: 0:00:07  loss: 0.7694 (0.7649)  time: 0.0905  data: 0.0001  max mem: 10917
[09:36:29.449857] Test:  [270/345]  eta: 0:00:06  loss: 0.7633 (0.7648)  time: 0.0909  data: 0.0001  max mem: 10917
[09:36:30.365069] Test:  [280/345]  eta: 0:00:05  loss: 0.7615 (0.7644)  time: 0.0913  data: 0.0001  max mem: 10917
[09:36:31.283338] Test:  [290/345]  eta: 0:00:04  loss: 0.7600 (0.7646)  time: 0.0916  data: 0.0001  max mem: 10917
[09:36:32.205174] Test:  [300/345]  eta: 0:00:03  loss: 0.7635 (0.7648)  time: 0.0920  data: 0.0001  max mem: 10917
[09:36:33.131038] Test:  [310/345]  eta: 0:00:03  loss: 0.7786 (0.7652)  time: 0.0923  data: 0.0001  max mem: 10917
[09:36:34.061024] Test:  [320/345]  eta: 0:00:02  loss: 0.7646 (0.7646)  time: 0.0927  data: 0.0001  max mem: 10917
[09:36:34.993214] Test:  [330/345]  eta: 0:00:01  loss: 0.7593 (0.7650)  time: 0.0931  data: 0.0001  max mem: 10917
[09:36:35.928990] Test:  [340/345]  eta: 0:00:00  loss: 0.7717 (0.7649)  time: 0.0933  data: 0.0001  max mem: 10917
[09:36:36.305155] Test:  [344/345]  eta: 0:00:00  loss: 0.7702 (0.7648)  time: 0.0935  data: 0.0001  max mem: 10917
[09:36:36.362913] Test: Total time: 0:00:30 (0.0885 s / it)
[09:36:46.772579] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8598 (0.8598)  time: 0.2203  data: 0.1405  max mem: 10917
[09:36:47.587452] Test:  [10/57]  eta: 0:00:04  loss: 0.8620 (0.8837)  time: 0.0940  data: 0.0130  max mem: 10917
[09:36:48.404515] Test:  [20/57]  eta: 0:00:03  loss: 0.8738 (0.8739)  time: 0.0815  data: 0.0002  max mem: 10917
[09:36:49.225510] Test:  [30/57]  eta: 0:00:02  loss: 0.7792 (0.8373)  time: 0.0819  data: 0.0001  max mem: 10917
[09:36:50.049231] Test:  [40/57]  eta: 0:00:01  loss: 0.7707 (0.8165)  time: 0.0822  data: 0.0001  max mem: 10917
[09:36:50.877052] Test:  [50/57]  eta: 0:00:00  loss: 0.7587 (0.8100)  time: 0.0825  data: 0.0001  max mem: 10917
[09:36:51.326993] Test:  [56/57]  eta: 0:00:00  loss: 0.7836 (0.8141)  time: 0.0803  data: 0.0001  max mem: 10917
[09:36:51.383492] Test: Total time: 0:00:04 (0.0848 s / it)
[09:36:53.177826] Dice score of the network on the train images: 0.775842, val images: 0.807457
[09:36:53.181295] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:36:53.579824] Epoch: [19]  [  0/345]  eta: 0:02:17  lr: 0.000119  loss: 0.8158 (0.8158)  time: 0.3977  data: 0.1454  max mem: 10917
[09:36:58.581369] Epoch: [19]  [ 20/345]  eta: 0:01:23  lr: 0.000119  loss: 0.7985 (0.7989)  time: 0.2500  data: 0.0000  max mem: 10917
[09:37:03.582724] Epoch: [19]  [ 40/345]  eta: 0:01:17  lr: 0.000119  loss: 0.8138 (0.8073)  time: 0.2500  data: 0.0001  max mem: 10917
[09:37:08.576854] Epoch: [19]  [ 60/345]  eta: 0:01:11  lr: 0.000120  loss: 0.8292 (0.8151)  time: 0.2497  data: 0.0001  max mem: 10917
[09:37:13.576759] Epoch: [19]  [ 80/345]  eta: 0:01:06  lr: 0.000120  loss: 0.8033 (0.8120)  time: 0.2500  data: 0.0001  max mem: 10917
[09:37:18.582487] Epoch: [19]  [100/345]  eta: 0:01:01  lr: 0.000121  loss: 0.7993 (0.8099)  time: 0.2502  data: 0.0000  max mem: 10917
[09:37:23.586446] Epoch: [19]  [120/345]  eta: 0:00:56  lr: 0.000121  loss: 0.7984 (0.8080)  time: 0.2502  data: 0.0001  max mem: 10917
[09:37:28.595442] Epoch: [19]  [140/345]  eta: 0:00:51  lr: 0.000121  loss: 0.8032 (0.8079)  time: 0.2504  data: 0.0001  max mem: 10917
[09:37:33.605863] Epoch: [19]  [160/345]  eta: 0:00:46  lr: 0.000122  loss: 0.8061 (0.8077)  time: 0.2505  data: 0.0000  max mem: 10917
[09:37:38.620335] Epoch: [19]  [180/345]  eta: 0:00:41  lr: 0.000122  loss: 0.8028 (0.8074)  time: 0.2507  data: 0.0001  max mem: 10917
[09:37:43.634778] Epoch: [19]  [200/345]  eta: 0:00:36  lr: 0.000122  loss: 0.8207 (0.8088)  time: 0.2507  data: 0.0001  max mem: 10917
[09:37:48.656687] Epoch: [19]  [220/345]  eta: 0:00:31  lr: 0.000123  loss: 0.8113 (0.8093)  time: 0.2511  data: 0.0000  max mem: 10917
[09:37:53.676663] Epoch: [19]  [240/345]  eta: 0:00:26  lr: 0.000123  loss: 0.8494 (0.8123)  time: 0.2510  data: 0.0000  max mem: 10917
[09:37:58.700771] Epoch: [19]  [260/345]  eta: 0:00:21  lr: 0.000123  loss: 0.8199 (0.8133)  time: 0.2512  data: 0.0001  max mem: 10917
[09:38:03.723067] Epoch: [19]  [280/345]  eta: 0:00:16  lr: 0.000124  loss: 0.8078 (0.8133)  time: 0.2511  data: 0.0001  max mem: 10917
[09:38:08.749085] Epoch: [19]  [300/345]  eta: 0:00:11  lr: 0.000124  loss: 0.7961 (0.8122)  time: 0.2513  data: 0.0001  max mem: 10917
[09:38:13.776299] Epoch: [19]  [320/345]  eta: 0:00:06  lr: 0.000125  loss: 0.8034 (0.8117)  time: 0.2513  data: 0.0001  max mem: 10917
[09:38:18.806039] Epoch: [19]  [340/345]  eta: 0:00:01  lr: 0.000125  loss: 0.8062 (0.8121)  time: 0.2514  data: 0.0000  max mem: 10917
[09:38:19.812202] Epoch: [19]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.8138 (0.8127)  time: 0.2514  data: 0.0001  max mem: 10917
[09:38:19.869569] Epoch: [19] Total time: 0:01:26 (0.2513 s / it)
[09:38:19.870092] Averaged stats: lr: 0.000125  loss: 0.8138 (0.8127)
[09:38:20.108679] Test:  [  0/345]  eta: 0:01:21  loss: 0.8926 (0.8926)  time: 0.2356  data: 0.1557  max mem: 10917
[09:38:20.998365] Test:  [ 10/345]  eta: 0:00:34  loss: 0.8834 (0.8860)  time: 0.1022  data: 0.0209  max mem: 10917
[09:38:21.821627] Test:  [ 20/345]  eta: 0:00:30  loss: 0.8795 (0.8890)  time: 0.0856  data: 0.0037  max mem: 10917
[09:38:22.648908] Test:  [ 30/345]  eta: 0:00:28  loss: 0.8766 (0.8874)  time: 0.0825  data: 0.0001  max mem: 10917
[09:38:23.479480] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8962 (0.8903)  time: 0.0828  data: 0.0001  max mem: 10917
[09:38:24.314000] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8975 (0.8901)  time: 0.0832  data: 0.0001  max mem: 10917
[09:38:25.151855] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8835 (0.8875)  time: 0.0836  data: 0.0001  max mem: 10917
[09:38:25.994021] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8849 (0.8881)  time: 0.0840  data: 0.0001  max mem: 10917
[09:38:26.838511] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8754 (0.8856)  time: 0.0843  data: 0.0001  max mem: 10917
[09:38:27.686999] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8754 (0.8862)  time: 0.0846  data: 0.0001  max mem: 10917
[09:38:28.539589] Test:  [100/345]  eta: 0:00:21  loss: 0.8877 (0.8857)  time: 0.0850  data: 0.0001  max mem: 10917
[09:38:29.395613] Test:  [110/345]  eta: 0:00:20  loss: 0.8705 (0.8852)  time: 0.0854  data: 0.0001  max mem: 10917
[09:38:30.254361] Test:  [120/345]  eta: 0:00:19  loss: 0.8738 (0.8854)  time: 0.0857  data: 0.0001  max mem: 10917
[09:38:31.116675] Test:  [130/345]  eta: 0:00:18  loss: 0.8886 (0.8852)  time: 0.0860  data: 0.0001  max mem: 10917
[09:38:31.982540] Test:  [140/345]  eta: 0:00:17  loss: 0.8820 (0.8844)  time: 0.0864  data: 0.0001  max mem: 10917
[09:38:32.852240] Test:  [150/345]  eta: 0:00:16  loss: 0.8777 (0.8838)  time: 0.0867  data: 0.0001  max mem: 10917
[09:38:33.724699] Test:  [160/345]  eta: 0:00:15  loss: 0.8767 (0.8833)  time: 0.0871  data: 0.0001  max mem: 10917
[09:38:34.601397] Test:  [170/345]  eta: 0:00:15  loss: 0.8698 (0.8826)  time: 0.0874  data: 0.0001  max mem: 10917
[09:38:35.482130] Test:  [180/345]  eta: 0:00:14  loss: 0.8698 (0.8822)  time: 0.0878  data: 0.0001  max mem: 10917
[09:38:36.364847] Test:  [190/345]  eta: 0:00:13  loss: 0.8883 (0.8831)  time: 0.0881  data: 0.0001  max mem: 10917
[09:38:37.251667] Test:  [200/345]  eta: 0:00:12  loss: 0.8883 (0.8826)  time: 0.0884  data: 0.0001  max mem: 10917
[09:38:38.142202] Test:  [210/345]  eta: 0:00:11  loss: 0.8735 (0.8821)  time: 0.0888  data: 0.0001  max mem: 10917
[09:38:39.035791] Test:  [220/345]  eta: 0:00:10  loss: 0.8834 (0.8824)  time: 0.0892  data: 0.0001  max mem: 10917
[09:38:39.933383] Test:  [230/345]  eta: 0:00:09  loss: 0.8868 (0.8821)  time: 0.0895  data: 0.0001  max mem: 10917
[09:38:40.835587] Test:  [240/345]  eta: 0:00:09  loss: 0.8758 (0.8825)  time: 0.0899  data: 0.0001  max mem: 10917
[09:38:41.739667] Test:  [250/345]  eta: 0:00:08  loss: 0.8927 (0.8827)  time: 0.0903  data: 0.0001  max mem: 10917
[09:38:42.647492] Test:  [260/345]  eta: 0:00:07  loss: 0.8847 (0.8829)  time: 0.0905  data: 0.0001  max mem: 10917
[09:38:43.559923] Test:  [270/345]  eta: 0:00:06  loss: 0.8847 (0.8833)  time: 0.0910  data: 0.0001  max mem: 10917
[09:38:44.474629] Test:  [280/345]  eta: 0:00:05  loss: 0.8890 (0.8835)  time: 0.0913  data: 0.0001  max mem: 10917
[09:38:45.392882] Test:  [290/345]  eta: 0:00:04  loss: 0.8863 (0.8833)  time: 0.0916  data: 0.0001  max mem: 10917
[09:38:46.315097] Test:  [300/345]  eta: 0:00:03  loss: 0.8789 (0.8832)  time: 0.0920  data: 0.0001  max mem: 10917
[09:38:47.240685] Test:  [310/345]  eta: 0:00:03  loss: 0.8822 (0.8831)  time: 0.0923  data: 0.0001  max mem: 10917
[09:38:48.170033] Test:  [320/345]  eta: 0:00:02  loss: 0.8693 (0.8827)  time: 0.0927  data: 0.0001  max mem: 10917
[09:38:49.102518] Test:  [330/345]  eta: 0:00:01  loss: 0.8693 (0.8829)  time: 0.0930  data: 0.0001  max mem: 10917
[09:38:50.038417] Test:  [340/345]  eta: 0:00:00  loss: 0.8907 (0.8830)  time: 0.0934  data: 0.0001  max mem: 10917
[09:38:50.413974] Test:  [344/345]  eta: 0:00:00  loss: 0.8892 (0.8829)  time: 0.0935  data: 0.0001  max mem: 10917
[09:38:50.470069] Test: Total time: 0:00:30 (0.0887 s / it)
[09:39:00.912073] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9572 (0.9572)  time: 0.2219  data: 0.1420  max mem: 10917
[09:39:01.728262] Test:  [10/57]  eta: 0:00:04  loss: 0.9542 (0.9369)  time: 0.0943  data: 0.0133  max mem: 10917
[09:39:02.545745] Test:  [20/57]  eta: 0:00:03  loss: 0.9095 (0.9163)  time: 0.0816  data: 0.0002  max mem: 10917
[09:39:03.366917] Test:  [30/57]  eta: 0:00:02  loss: 0.8150 (0.8749)  time: 0.0819  data: 0.0001  max mem: 10917
[09:39:04.191352] Test:  [40/57]  eta: 0:00:01  loss: 0.7914 (0.8500)  time: 0.0822  data: 0.0001  max mem: 10917
[09:39:05.019310] Test:  [50/57]  eta: 0:00:00  loss: 0.7946 (0.8433)  time: 0.0826  data: 0.0001  max mem: 10917
[09:39:05.469455] Test:  [56/57]  eta: 0:00:00  loss: 0.8173 (0.8489)  time: 0.0803  data: 0.0001  max mem: 10917
[09:39:05.523670] Test: Total time: 0:00:04 (0.0848 s / it)
[09:39:07.344660] Dice score of the network on the train images: 0.607045, val images: 0.739926
[09:39:07.344897] saving best_rec_model_0 @ epoch 19
[09:39:08.292068] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:39:08.689627] Epoch: [20]  [  0/345]  eta: 0:02:16  lr: 0.000125  loss: 0.8400 (0.8400)  time: 0.3963  data: 0.1441  max mem: 10917
[09:39:13.691077] Epoch: [20]  [ 20/345]  eta: 0:01:23  lr: 0.000125  loss: 0.8362 (0.8371)  time: 0.2500  data: 0.0001  max mem: 10917
[09:39:18.691350] Epoch: [20]  [ 40/345]  eta: 0:01:17  lr: 0.000125  loss: 0.8010 (0.8223)  time: 0.2500  data: 0.0000  max mem: 10917
[09:39:23.697054] Epoch: [20]  [ 60/345]  eta: 0:01:11  lr: 0.000125  loss: 0.8064 (0.8178)  time: 0.2502  data: 0.0000  max mem: 10917
[09:39:28.708487] Epoch: [20]  [ 80/345]  eta: 0:01:06  lr: 0.000125  loss: 0.8123 (0.8175)  time: 0.2505  data: 0.0000  max mem: 10917
[09:39:33.731181] Epoch: [20]  [100/345]  eta: 0:01:01  lr: 0.000125  loss: 0.7974 (0.8143)  time: 0.2511  data: 0.0000  max mem: 10917
[09:39:38.757961] Epoch: [20]  [120/345]  eta: 0:00:56  lr: 0.000125  loss: 0.7910 (0.8112)  time: 0.2513  data: 0.0001  max mem: 10917
[09:39:43.782855] Epoch: [20]  [140/345]  eta: 0:00:51  lr: 0.000125  loss: 0.7952 (0.8092)  time: 0.2512  data: 0.0000  max mem: 10917
[09:39:48.830251] Epoch: [20]  [160/345]  eta: 0:00:46  lr: 0.000125  loss: 0.7948 (0.8079)  time: 0.2523  data: 0.0001  max mem: 10917
[09:39:53.864054] Epoch: [20]  [180/345]  eta: 0:00:41  lr: 0.000125  loss: 0.8205 (0.8090)  time: 0.2516  data: 0.0001  max mem: 10917
[09:39:58.898080] Epoch: [20]  [200/345]  eta: 0:00:36  lr: 0.000125  loss: 0.8124 (0.8101)  time: 0.2517  data: 0.0000  max mem: 10917
[09:40:03.934083] Epoch: [20]  [220/345]  eta: 0:00:31  lr: 0.000125  loss: 0.8032 (0.8101)  time: 0.2518  data: 0.0000  max mem: 10917
[09:40:08.973232] Epoch: [20]  [240/345]  eta: 0:00:26  lr: 0.000125  loss: 0.8050 (0.8096)  time: 0.2519  data: 0.0000  max mem: 10917
[09:40:14.013526] Epoch: [20]  [260/345]  eta: 0:00:21  lr: 0.000125  loss: 0.7860 (0.8080)  time: 0.2520  data: 0.0000  max mem: 10917
[09:40:19.054309] Epoch: [20]  [280/345]  eta: 0:00:16  lr: 0.000125  loss: 0.7998 (0.8074)  time: 0.2520  data: 0.0000  max mem: 10917
[09:40:24.094745] Epoch: [20]  [300/345]  eta: 0:00:11  lr: 0.000125  loss: 0.7936 (0.8067)  time: 0.2520  data: 0.0000  max mem: 10917
[09:40:29.138390] Epoch: [20]  [320/345]  eta: 0:00:06  lr: 0.000125  loss: 0.7886 (0.8058)  time: 0.2521  data: 0.0000  max mem: 10917
[09:40:34.184486] Epoch: [20]  [340/345]  eta: 0:00:01  lr: 0.000125  loss: 0.7880 (0.8050)  time: 0.2523  data: 0.0000  max mem: 10917
[09:40:35.195838] Epoch: [20]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.7960 (0.8051)  time: 0.2524  data: 0.0001  max mem: 10917
[09:40:35.252363] Epoch: [20] Total time: 0:01:26 (0.2521 s / it)
[09:40:35.252843] Averaged stats: lr: 0.000125  loss: 0.7960 (0.8051)
[09:40:35.487061] Test:  [  0/345]  eta: 0:01:19  loss: 0.7519 (0.7519)  time: 0.2303  data: 0.1502  max mem: 10917
[09:40:36.313787] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7519 (0.7554)  time: 0.0960  data: 0.0143  max mem: 10917
[09:40:37.137084] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7541 (0.7574)  time: 0.0824  data: 0.0004  max mem: 10917
[09:40:37.964905] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7598 (0.7620)  time: 0.0825  data: 0.0001  max mem: 10917
[09:40:38.794946] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7650 (0.7623)  time: 0.0828  data: 0.0001  max mem: 10917
[09:40:39.628733] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7638 (0.7625)  time: 0.0831  data: 0.0001  max mem: 10917
[09:40:40.466008] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7584 (0.7609)  time: 0.0835  data: 0.0001  max mem: 10917
[09:40:41.306768] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7533 (0.7603)  time: 0.0839  data: 0.0001  max mem: 10917
[09:40:42.151754] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7581 (0.7609)  time: 0.0842  data: 0.0001  max mem: 10917
[09:40:43.000118] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7581 (0.7606)  time: 0.0846  data: 0.0001  max mem: 10917
[09:40:43.852939] Test:  [100/345]  eta: 0:00:20  loss: 0.7508 (0.7600)  time: 0.0850  data: 0.0001  max mem: 10917
[09:40:44.709026] Test:  [110/345]  eta: 0:00:19  loss: 0.7521 (0.7598)  time: 0.0854  data: 0.0001  max mem: 10917
[09:40:45.568393] Test:  [120/345]  eta: 0:00:19  loss: 0.7549 (0.7596)  time: 0.0857  data: 0.0001  max mem: 10917
[09:40:46.430932] Test:  [130/345]  eta: 0:00:18  loss: 0.7591 (0.7596)  time: 0.0860  data: 0.0001  max mem: 10917
[09:40:47.296369] Test:  [140/345]  eta: 0:00:17  loss: 0.7653 (0.7603)  time: 0.0864  data: 0.0001  max mem: 10917
[09:40:48.165453] Test:  [150/345]  eta: 0:00:16  loss: 0.7657 (0.7602)  time: 0.0867  data: 0.0001  max mem: 10917
[09:40:49.037669] Test:  [160/345]  eta: 0:00:15  loss: 0.7570 (0.7599)  time: 0.0870  data: 0.0001  max mem: 10917
[09:40:49.914635] Test:  [170/345]  eta: 0:00:14  loss: 0.7624 (0.7604)  time: 0.0874  data: 0.0001  max mem: 10917
[09:40:50.795443] Test:  [180/345]  eta: 0:00:14  loss: 0.7659 (0.7604)  time: 0.0878  data: 0.0001  max mem: 10917
[09:40:51.679190] Test:  [190/345]  eta: 0:00:13  loss: 0.7557 (0.7601)  time: 0.0882  data: 0.0001  max mem: 10917
[09:40:52.566273] Test:  [200/345]  eta: 0:00:12  loss: 0.7605 (0.7604)  time: 0.0885  data: 0.0001  max mem: 10917
[09:40:53.457631] Test:  [210/345]  eta: 0:00:11  loss: 0.7639 (0.7602)  time: 0.0889  data: 0.0001  max mem: 10917
[09:40:54.351937] Test:  [220/345]  eta: 0:00:10  loss: 0.7485 (0.7597)  time: 0.0892  data: 0.0001  max mem: 10917
[09:40:55.250066] Test:  [230/345]  eta: 0:00:09  loss: 0.7508 (0.7598)  time: 0.0896  data: 0.0001  max mem: 10917
[09:40:56.151836] Test:  [240/345]  eta: 0:00:09  loss: 0.7546 (0.7595)  time: 0.0899  data: 0.0001  max mem: 10917
[09:40:57.057050] Test:  [250/345]  eta: 0:00:08  loss: 0.7546 (0.7595)  time: 0.0903  data: 0.0001  max mem: 10917
[09:40:57.965380] Test:  [260/345]  eta: 0:00:07  loss: 0.7626 (0.7596)  time: 0.0906  data: 0.0001  max mem: 10917
[09:40:58.877155] Test:  [270/345]  eta: 0:00:06  loss: 0.7626 (0.7595)  time: 0.0910  data: 0.0001  max mem: 10917
[09:40:59.792527] Test:  [280/345]  eta: 0:00:05  loss: 0.7474 (0.7594)  time: 0.0913  data: 0.0001  max mem: 10917
[09:41:00.710969] Test:  [290/345]  eta: 0:00:04  loss: 0.7472 (0.7591)  time: 0.0916  data: 0.0001  max mem: 10917
[09:41:01.633447] Test:  [300/345]  eta: 0:00:03  loss: 0.7525 (0.7592)  time: 0.0920  data: 0.0001  max mem: 10917
[09:41:02.558523] Test:  [310/345]  eta: 0:00:03  loss: 0.7621 (0.7596)  time: 0.0923  data: 0.0001  max mem: 10917
[09:41:03.487246] Test:  [320/345]  eta: 0:00:02  loss: 0.7654 (0.7595)  time: 0.0926  data: 0.0001  max mem: 10917
[09:41:04.419691] Test:  [330/345]  eta: 0:00:01  loss: 0.7587 (0.7595)  time: 0.0930  data: 0.0001  max mem: 10917
[09:41:05.356681] Test:  [340/345]  eta: 0:00:00  loss: 0.7498 (0.7593)  time: 0.0934  data: 0.0001  max mem: 10917
[09:41:05.733655] Test:  [344/345]  eta: 0:00:00  loss: 0.7453 (0.7592)  time: 0.0936  data: 0.0001  max mem: 10917
[09:41:05.787571] Test: Total time: 0:00:30 (0.0885 s / it)
[09:41:16.283690] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9132 (0.9132)  time: 0.2184  data: 0.1382  max mem: 10917
[09:41:17.097482] Test:  [10/57]  eta: 0:00:04  loss: 0.9014 (0.9080)  time: 0.0938  data: 0.0126  max mem: 10917
[09:41:17.914605] Test:  [20/57]  eta: 0:00:03  loss: 0.9014 (0.8939)  time: 0.0815  data: 0.0001  max mem: 10917
[09:41:18.735933] Test:  [30/57]  eta: 0:00:02  loss: 0.7902 (0.8529)  time: 0.0819  data: 0.0001  max mem: 10917
[09:41:19.560372] Test:  [40/57]  eta: 0:00:01  loss: 0.7829 (0.8313)  time: 0.0822  data: 0.0001  max mem: 10917
[09:41:20.389271] Test:  [50/57]  eta: 0:00:00  loss: 0.7685 (0.8227)  time: 0.0826  data: 0.0001  max mem: 10917
[09:41:20.839329] Test:  [56/57]  eta: 0:00:00  loss: 0.7829 (0.8268)  time: 0.0804  data: 0.0001  max mem: 10917
[09:41:20.896152] Test: Total time: 0:00:04 (0.0848 s / it)
[09:41:22.644520] Dice score of the network on the train images: 0.795893, val images: 0.808468
[09:41:22.647833] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:41:23.044407] Epoch: [21]  [  0/345]  eta: 0:02:16  lr: 0.000125  loss: 0.8136 (0.8136)  time: 0.3954  data: 0.1430  max mem: 10917
[09:41:28.046841] Epoch: [21]  [ 20/345]  eta: 0:01:23  lr: 0.000125  loss: 0.7855 (0.7875)  time: 0.2501  data: 0.0001  max mem: 10917
[09:41:33.057688] Epoch: [21]  [ 40/345]  eta: 0:01:17  lr: 0.000125  loss: 0.7878 (0.7885)  time: 0.2505  data: 0.0001  max mem: 10917
[09:41:38.073063] Epoch: [21]  [ 60/345]  eta: 0:01:12  lr: 0.000125  loss: 0.7965 (0.7934)  time: 0.2507  data: 0.0001  max mem: 10917
[09:41:43.084822] Epoch: [21]  [ 80/345]  eta: 0:01:06  lr: 0.000124  loss: 0.8171 (0.8002)  time: 0.2505  data: 0.0000  max mem: 10917
[09:41:48.106510] Epoch: [21]  [100/345]  eta: 0:01:01  lr: 0.000124  loss: 0.8060 (0.8014)  time: 0.2510  data: 0.0000  max mem: 10917
[09:41:53.133763] Epoch: [21]  [120/345]  eta: 0:00:56  lr: 0.000124  loss: 0.8123 (0.8026)  time: 0.2513  data: 0.0001  max mem: 10917
[09:41:58.148969] Epoch: [21]  [140/345]  eta: 0:00:51  lr: 0.000124  loss: 0.7856 (0.8012)  time: 0.2507  data: 0.0001  max mem: 10917
[09:42:03.176827] Epoch: [21]  [160/345]  eta: 0:00:46  lr: 0.000124  loss: 0.7898 (0.8000)  time: 0.2513  data: 0.0001  max mem: 10917
[09:42:08.209340] Epoch: [21]  [180/345]  eta: 0:00:41  lr: 0.000124  loss: 0.7939 (0.8003)  time: 0.2516  data: 0.0000  max mem: 10917
[09:42:13.244392] Epoch: [21]  [200/345]  eta: 0:00:36  lr: 0.000124  loss: 0.8104 (0.8010)  time: 0.2517  data: 0.0001  max mem: 10917
[09:42:18.280182] Epoch: [21]  [220/345]  eta: 0:00:31  lr: 0.000124  loss: 0.8011 (0.8010)  time: 0.2517  data: 0.0001  max mem: 10917
[09:42:23.317653] Epoch: [21]  [240/345]  eta: 0:00:26  lr: 0.000124  loss: 0.8021 (0.8010)  time: 0.2518  data: 0.0000  max mem: 10917
[09:42:28.349098] Epoch: [21]  [260/345]  eta: 0:00:21  lr: 0.000124  loss: 0.8051 (0.8013)  time: 0.2515  data: 0.0001  max mem: 10917
[09:42:33.376153] Epoch: [21]  [280/345]  eta: 0:00:16  lr: 0.000124  loss: 0.7846 (0.8006)  time: 0.2513  data: 0.0001  max mem: 10917
[09:42:38.405100] Epoch: [21]  [300/345]  eta: 0:00:11  lr: 0.000124  loss: 0.8038 (0.8008)  time: 0.2514  data: 0.0000  max mem: 10917
[09:42:43.436813] Epoch: [21]  [320/345]  eta: 0:00:06  lr: 0.000124  loss: 0.7936 (0.8007)  time: 0.2515  data: 0.0001  max mem: 10917
[09:42:48.472702] Epoch: [21]  [340/345]  eta: 0:00:01  lr: 0.000124  loss: 0.8115 (0.8014)  time: 0.2517  data: 0.0001  max mem: 10917
[09:42:49.480438] Epoch: [21]  [344/345]  eta: 0:00:00  lr: 0.000124  loss: 0.8044 (0.8013)  time: 0.2517  data: 0.0001  max mem: 10917
[09:42:49.536511] Epoch: [21] Total time: 0:01:26 (0.2519 s / it)
[09:42:49.537023] Averaged stats: lr: 0.000124  loss: 0.8044 (0.8013)
[09:42:49.774019] Test:  [  0/345]  eta: 0:01:20  loss: 0.8249 (0.8249)  time: 0.2342  data: 0.1538  max mem: 10917
[09:42:50.620778] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7599 (0.7647)  time: 0.0982  data: 0.0168  max mem: 10917
[09:42:51.476214] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7605 (0.7675)  time: 0.0850  data: 0.0033  max mem: 10917
[09:42:52.304148] Test:  [ 30/345]  eta: 0:00:28  loss: 0.7724 (0.7674)  time: 0.0841  data: 0.0019  max mem: 10917
[09:42:53.168512] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7687 (0.7674)  time: 0.0846  data: 0.0019  max mem: 10917
[09:42:54.049037] Test:  [ 50/345]  eta: 0:00:26  loss: 0.7646 (0.7668)  time: 0.0872  data: 0.0043  max mem: 10917
[09:42:54.895087] Test:  [ 60/345]  eta: 0:00:25  loss: 0.7589 (0.7653)  time: 0.0863  data: 0.0030  max mem: 10917
[09:42:55.735780] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7620 (0.7652)  time: 0.0843  data: 0.0005  max mem: 10917
[09:42:56.579139] Test:  [ 80/345]  eta: 0:00:23  loss: 0.7656 (0.7652)  time: 0.0842  data: 0.0001  max mem: 10917
[09:42:57.428026] Test:  [ 90/345]  eta: 0:00:22  loss: 0.7681 (0.7664)  time: 0.0846  data: 0.0001  max mem: 10917
[09:42:58.278615] Test:  [100/345]  eta: 0:00:21  loss: 0.7681 (0.7664)  time: 0.0849  data: 0.0001  max mem: 10917
[09:42:59.133260] Test:  [110/345]  eta: 0:00:20  loss: 0.7594 (0.7658)  time: 0.0852  data: 0.0001  max mem: 10917
[09:42:59.991807] Test:  [120/345]  eta: 0:00:19  loss: 0.7664 (0.7667)  time: 0.0856  data: 0.0001  max mem: 10917
[09:43:00.853803] Test:  [130/345]  eta: 0:00:18  loss: 0.7598 (0.7658)  time: 0.0860  data: 0.0001  max mem: 10917
[09:43:01.718823] Test:  [140/345]  eta: 0:00:17  loss: 0.7598 (0.7660)  time: 0.0863  data: 0.0001  max mem: 10917
[09:43:02.587591] Test:  [150/345]  eta: 0:00:16  loss: 0.7565 (0.7655)  time: 0.0866  data: 0.0001  max mem: 10917
[09:43:03.459298] Test:  [160/345]  eta: 0:00:15  loss: 0.7678 (0.7659)  time: 0.0870  data: 0.0001  max mem: 10917
[09:43:04.335480] Test:  [170/345]  eta: 0:00:15  loss: 0.7695 (0.7658)  time: 0.0873  data: 0.0001  max mem: 10917
[09:43:05.215071] Test:  [180/345]  eta: 0:00:14  loss: 0.7642 (0.7661)  time: 0.0877  data: 0.0001  max mem: 10917
[09:43:06.096885] Test:  [190/345]  eta: 0:00:13  loss: 0.7771 (0.7666)  time: 0.0880  data: 0.0001  max mem: 10917
[09:43:06.983573] Test:  [200/345]  eta: 0:00:12  loss: 0.7741 (0.7670)  time: 0.0884  data: 0.0001  max mem: 10917
[09:43:07.874831] Test:  [210/345]  eta: 0:00:11  loss: 0.7646 (0.7666)  time: 0.0888  data: 0.0001  max mem: 10917
[09:43:08.768083] Test:  [220/345]  eta: 0:00:10  loss: 0.7555 (0.7663)  time: 0.0892  data: 0.0001  max mem: 10917
[09:43:09.665844] Test:  [230/345]  eta: 0:00:10  loss: 0.7620 (0.7660)  time: 0.0895  data: 0.0001  max mem: 10917
[09:43:10.567231] Test:  [240/345]  eta: 0:00:09  loss: 0.7645 (0.7661)  time: 0.0899  data: 0.0001  max mem: 10917
[09:43:11.471275] Test:  [250/345]  eta: 0:00:08  loss: 0.7616 (0.7658)  time: 0.0902  data: 0.0001  max mem: 10917
[09:43:12.379037] Test:  [260/345]  eta: 0:00:07  loss: 0.7512 (0.7657)  time: 0.0905  data: 0.0001  max mem: 10917
[09:43:13.290702] Test:  [270/345]  eta: 0:00:06  loss: 0.7610 (0.7658)  time: 0.0909  data: 0.0001  max mem: 10917
[09:43:14.205288] Test:  [280/345]  eta: 0:00:05  loss: 0.7626 (0.7659)  time: 0.0913  data: 0.0001  max mem: 10917
[09:43:15.124464] Test:  [290/345]  eta: 0:00:04  loss: 0.7645 (0.7663)  time: 0.0916  data: 0.0001  max mem: 10917
[09:43:16.046611] Test:  [300/345]  eta: 0:00:03  loss: 0.7678 (0.7664)  time: 0.0920  data: 0.0001  max mem: 10917
[09:43:16.972102] Test:  [310/345]  eta: 0:00:03  loss: 0.7635 (0.7667)  time: 0.0923  data: 0.0001  max mem: 10917
[09:43:17.900668] Test:  [320/345]  eta: 0:00:02  loss: 0.7668 (0.7669)  time: 0.0927  data: 0.0001  max mem: 10917
[09:43:18.833148] Test:  [330/345]  eta: 0:00:01  loss: 0.7667 (0.7667)  time: 0.0930  data: 0.0001  max mem: 10917
[09:43:19.768528] Test:  [340/345]  eta: 0:00:00  loss: 0.7628 (0.7667)  time: 0.0933  data: 0.0001  max mem: 10917
[09:43:20.144566] Test:  [344/345]  eta: 0:00:00  loss: 0.7633 (0.7669)  time: 0.0935  data: 0.0001  max mem: 10917
[09:43:20.201814] Test: Total time: 0:00:30 (0.0889 s / it)
[09:43:30.672545] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8859 (0.8859)  time: 0.2233  data: 0.1434  max mem: 10917
[09:43:31.508937] Test:  [10/57]  eta: 0:00:04  loss: 0.9076 (0.9081)  time: 0.0963  data: 0.0153  max mem: 10917
[09:43:32.324864] Test:  [20/57]  eta: 0:00:03  loss: 0.9093 (0.8985)  time: 0.0826  data: 0.0013  max mem: 10917
[09:43:33.144982] Test:  [30/57]  eta: 0:00:02  loss: 0.7902 (0.8566)  time: 0.0818  data: 0.0001  max mem: 10917
[09:43:33.969205] Test:  [40/57]  eta: 0:00:01  loss: 0.7794 (0.8348)  time: 0.0822  data: 0.0001  max mem: 10917
[09:43:34.797266] Test:  [50/57]  eta: 0:00:00  loss: 0.7831 (0.8284)  time: 0.0826  data: 0.0001  max mem: 10917
[09:43:35.247126] Test:  [56/57]  eta: 0:00:00  loss: 0.7911 (0.8335)  time: 0.0803  data: 0.0001  max mem: 10917
[09:43:35.302598] Test: Total time: 0:00:04 (0.0852 s / it)
[09:43:37.090221] Dice score of the network on the train images: 0.779313, val images: 0.797336
[09:43:37.093804] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:43:37.489861] Epoch: [22]  [  0/345]  eta: 0:02:16  lr: 0.000124  loss: 0.7937 (0.7937)  time: 0.3950  data: 0.1435  max mem: 10917
[09:43:42.478984] Epoch: [22]  [ 20/345]  eta: 0:01:23  lr: 0.000124  loss: 0.7984 (0.8004)  time: 0.2494  data: 0.0001  max mem: 10917
[09:43:47.487359] Epoch: [22]  [ 40/345]  eta: 0:01:17  lr: 0.000123  loss: 0.7969 (0.7988)  time: 0.2504  data: 0.0000  max mem: 10917
[09:43:52.499435] Epoch: [22]  [ 60/345]  eta: 0:01:11  lr: 0.000123  loss: 0.7915 (0.7970)  time: 0.2506  data: 0.0001  max mem: 10917
[09:43:57.505862] Epoch: [22]  [ 80/345]  eta: 0:01:06  lr: 0.000123  loss: 0.7900 (0.7967)  time: 0.2503  data: 0.0001  max mem: 10917
[09:44:02.526026] Epoch: [22]  [100/345]  eta: 0:01:01  lr: 0.000123  loss: 0.7833 (0.7954)  time: 0.2510  data: 0.0001  max mem: 10917
[09:44:07.558965] Epoch: [22]  [120/345]  eta: 0:00:56  lr: 0.000123  loss: 0.7895 (0.7949)  time: 0.2516  data: 0.0001  max mem: 10917
[09:44:12.589910] Epoch: [22]  [140/345]  eta: 0:00:51  lr: 0.000123  loss: 0.7901 (0.7945)  time: 0.2515  data: 0.0000  max mem: 10917
[09:44:17.618668] Epoch: [22]  [160/345]  eta: 0:00:46  lr: 0.000123  loss: 0.8017 (0.7955)  time: 0.2514  data: 0.0000  max mem: 10917
[09:44:22.643183] Epoch: [22]  [180/345]  eta: 0:00:41  lr: 0.000123  loss: 0.8112 (0.7971)  time: 0.2512  data: 0.0000  max mem: 10917
[09:44:27.669219] Epoch: [22]  [200/345]  eta: 0:00:36  lr: 0.000123  loss: 0.8045 (0.7977)  time: 0.2513  data: 0.0001  max mem: 10917
[09:44:32.706426] Epoch: [22]  [220/345]  eta: 0:00:31  lr: 0.000123  loss: 0.7902 (0.7971)  time: 0.2518  data: 0.0000  max mem: 10917
[09:44:37.746446] Epoch: [22]  [240/345]  eta: 0:00:26  lr: 0.000123  loss: 0.7951 (0.7968)  time: 0.2520  data: 0.0000  max mem: 10917
[09:44:42.793831] Epoch: [22]  [260/345]  eta: 0:00:21  lr: 0.000122  loss: 0.7925 (0.7964)  time: 0.2523  data: 0.0000  max mem: 10917
[09:44:47.836964] Epoch: [22]  [280/345]  eta: 0:00:16  lr: 0.000122  loss: 0.7873 (0.7959)  time: 0.2521  data: 0.0001  max mem: 10917
[09:44:52.885980] Epoch: [22]  [300/345]  eta: 0:00:11  lr: 0.000122  loss: 0.7878 (0.7955)  time: 0.2524  data: 0.0001  max mem: 10917
[09:44:57.934770] Epoch: [22]  [320/345]  eta: 0:00:06  lr: 0.000122  loss: 0.7912 (0.7954)  time: 0.2524  data: 0.0001  max mem: 10917
[09:45:02.984947] Epoch: [22]  [340/345]  eta: 0:00:01  lr: 0.000122  loss: 0.7845 (0.7947)  time: 0.2525  data: 0.0001  max mem: 10917
[09:45:03.996765] Epoch: [22]  [344/345]  eta: 0:00:00  lr: 0.000122  loss: 0.7861 (0.7945)  time: 0.2526  data: 0.0001  max mem: 10917
[09:45:04.052707] Epoch: [22] Total time: 0:01:26 (0.2521 s / it)
[09:45:04.053014] Averaged stats: lr: 0.000122  loss: 0.7861 (0.7945)
[09:45:04.285380] Test:  [  0/345]  eta: 0:01:18  loss: 0.7441 (0.7441)  time: 0.2290  data: 0.1486  max mem: 10917
[09:45:05.106053] Test:  [ 10/345]  eta: 0:00:31  loss: 0.7446 (0.7499)  time: 0.0953  data: 0.0136  max mem: 10917
[09:45:05.928833] Test:  [ 20/345]  eta: 0:00:28  loss: 0.7475 (0.7539)  time: 0.0821  data: 0.0001  max mem: 10917
[09:45:06.755850] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7535 (0.7539)  time: 0.0824  data: 0.0001  max mem: 10917
[09:45:07.587777] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7552 (0.7546)  time: 0.0829  data: 0.0001  max mem: 10917
[09:45:08.421723] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7564 (0.7560)  time: 0.0832  data: 0.0001  max mem: 10917
[09:45:09.259659] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7623 (0.7569)  time: 0.0835  data: 0.0001  max mem: 10917
[09:45:10.101899] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7543 (0.7564)  time: 0.0840  data: 0.0001  max mem: 10917
[09:45:10.946419] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7499 (0.7567)  time: 0.0843  data: 0.0001  max mem: 10917
[09:45:11.794597] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7501 (0.7556)  time: 0.0846  data: 0.0001  max mem: 10917
[09:45:12.646633] Test:  [100/345]  eta: 0:00:20  loss: 0.7548 (0.7555)  time: 0.0850  data: 0.0001  max mem: 10917
[09:45:13.502458] Test:  [110/345]  eta: 0:00:19  loss: 0.7511 (0.7553)  time: 0.0853  data: 0.0001  max mem: 10917
[09:45:14.361669] Test:  [120/345]  eta: 0:00:19  loss: 0.7423 (0.7544)  time: 0.0857  data: 0.0001  max mem: 10917
[09:45:15.223852] Test:  [130/345]  eta: 0:00:18  loss: 0.7469 (0.7544)  time: 0.0860  data: 0.0001  max mem: 10917
[09:45:16.089437] Test:  [140/345]  eta: 0:00:17  loss: 0.7497 (0.7540)  time: 0.0863  data: 0.0001  max mem: 10917
[09:45:16.959224] Test:  [150/345]  eta: 0:00:16  loss: 0.7507 (0.7544)  time: 0.0867  data: 0.0001  max mem: 10917
[09:45:17.831843] Test:  [160/345]  eta: 0:00:15  loss: 0.7502 (0.7541)  time: 0.0871  data: 0.0001  max mem: 10917
[09:45:18.708271] Test:  [170/345]  eta: 0:00:14  loss: 0.7439 (0.7535)  time: 0.0874  data: 0.0001  max mem: 10917
[09:45:19.587613] Test:  [180/345]  eta: 0:00:14  loss: 0.7502 (0.7534)  time: 0.0877  data: 0.0001  max mem: 10917
[09:45:20.471165] Test:  [190/345]  eta: 0:00:13  loss: 0.7502 (0.7534)  time: 0.0881  data: 0.0001  max mem: 10917
[09:45:21.358224] Test:  [200/345]  eta: 0:00:12  loss: 0.7508 (0.7535)  time: 0.0884  data: 0.0001  max mem: 10917
[09:45:22.248425] Test:  [210/345]  eta: 0:00:11  loss: 0.7466 (0.7529)  time: 0.0888  data: 0.0001  max mem: 10917
[09:45:23.142824] Test:  [220/345]  eta: 0:00:10  loss: 0.7466 (0.7531)  time: 0.0892  data: 0.0001  max mem: 10917
[09:45:24.040833] Test:  [230/345]  eta: 0:00:09  loss: 0.7568 (0.7532)  time: 0.0896  data: 0.0001  max mem: 10917
[09:45:24.942833] Test:  [240/345]  eta: 0:00:09  loss: 0.7500 (0.7527)  time: 0.0900  data: 0.0001  max mem: 10917
[09:45:25.848032] Test:  [250/345]  eta: 0:00:08  loss: 0.7500 (0.7531)  time: 0.0903  data: 0.0001  max mem: 10917
[09:45:26.755733] Test:  [260/345]  eta: 0:00:07  loss: 0.7484 (0.7529)  time: 0.0906  data: 0.0001  max mem: 10917
[09:45:27.667971] Test:  [270/345]  eta: 0:00:06  loss: 0.7481 (0.7530)  time: 0.0909  data: 0.0001  max mem: 10917
[09:45:28.583137] Test:  [280/345]  eta: 0:00:05  loss: 0.7492 (0.7528)  time: 0.0913  data: 0.0001  max mem: 10917
[09:45:29.501756] Test:  [290/345]  eta: 0:00:04  loss: 0.7488 (0.7526)  time: 0.0916  data: 0.0001  max mem: 10917
[09:45:30.424673] Test:  [300/345]  eta: 0:00:03  loss: 0.7486 (0.7525)  time: 0.0920  data: 0.0001  max mem: 10917
[09:45:31.350421] Test:  [310/345]  eta: 0:00:03  loss: 0.7530 (0.7528)  time: 0.0924  data: 0.0001  max mem: 10917
[09:45:32.279222] Test:  [320/345]  eta: 0:00:02  loss: 0.7569 (0.7530)  time: 0.0927  data: 0.0001  max mem: 10917
[09:45:33.212300] Test:  [330/345]  eta: 0:00:01  loss: 0.7509 (0.7529)  time: 0.0930  data: 0.0001  max mem: 10917
[09:45:34.147559] Test:  [340/345]  eta: 0:00:00  loss: 0.7526 (0.7530)  time: 0.0934  data: 0.0001  max mem: 10917
[09:45:34.523113] Test:  [344/345]  eta: 0:00:00  loss: 0.7554 (0.7531)  time: 0.0935  data: 0.0001  max mem: 10917
[09:45:34.580373] Test: Total time: 0:00:30 (0.0885 s / it)
[09:45:44.924877] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8883 (0.8883)  time: 0.2172  data: 0.1375  max mem: 10917
[09:45:45.738874] Test:  [10/57]  eta: 0:00:04  loss: 0.8883 (0.8971)  time: 0.0937  data: 0.0126  max mem: 10917
[09:45:46.555229] Test:  [20/57]  eta: 0:00:03  loss: 0.8864 (0.8818)  time: 0.0815  data: 0.0001  max mem: 10917
[09:45:47.375693] Test:  [30/57]  eta: 0:00:02  loss: 0.7787 (0.8413)  time: 0.0818  data: 0.0001  max mem: 10917
[09:45:48.199928] Test:  [40/57]  eta: 0:00:01  loss: 0.7629 (0.8195)  time: 0.0822  data: 0.0001  max mem: 10917
[09:45:49.028129] Test:  [50/57]  eta: 0:00:00  loss: 0.7543 (0.8120)  time: 0.0826  data: 0.0001  max mem: 10917
[09:45:49.477681] Test:  [56/57]  eta: 0:00:00  loss: 0.7702 (0.8168)  time: 0.0803  data: 0.0001  max mem: 10917
[09:45:49.533838] Test: Total time: 0:00:04 (0.0847 s / it)
[09:45:51.296093] Dice score of the network on the train images: 0.792525, val images: 0.815293
[09:45:51.296328] saving best_dice_model_0 @ epoch 22
[09:45:52.256441] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:45:52.653564] Epoch: [23]  [  0/345]  eta: 0:02:16  lr: 0.000122  loss: 0.7765 (0.7765)  time: 0.3959  data: 0.1433  max mem: 10917
[09:45:57.655382] Epoch: [23]  [ 20/345]  eta: 0:01:23  lr: 0.000122  loss: 0.7792 (0.7801)  time: 0.2500  data: 0.0001  max mem: 10917
[09:46:02.665738] Epoch: [23]  [ 40/345]  eta: 0:01:17  lr: 0.000122  loss: 0.7832 (0.7821)  time: 0.2505  data: 0.0001  max mem: 10917
[09:46:07.680328] Epoch: [23]  [ 60/345]  eta: 0:01:12  lr: 0.000122  loss: 0.7781 (0.7826)  time: 0.2507  data: 0.0001  max mem: 10917
[09:46:12.696048] Epoch: [23]  [ 80/345]  eta: 0:01:06  lr: 0.000121  loss: 0.7808 (0.7833)  time: 0.2507  data: 0.0001  max mem: 10917
[09:46:17.717899] Epoch: [23]  [100/345]  eta: 0:01:01  lr: 0.000121  loss: 0.7872 (0.7846)  time: 0.2510  data: 0.0001  max mem: 10917
[09:46:22.748724] Epoch: [23]  [120/345]  eta: 0:00:56  lr: 0.000121  loss: 0.7860 (0.7855)  time: 0.2515  data: 0.0001  max mem: 10917
[09:46:27.773995] Epoch: [23]  [140/345]  eta: 0:00:51  lr: 0.000121  loss: 0.7831 (0.7862)  time: 0.2512  data: 0.0000  max mem: 10917
[09:46:32.799667] Epoch: [23]  [160/345]  eta: 0:00:46  lr: 0.000121  loss: 0.7821 (0.7862)  time: 0.2512  data: 0.0000  max mem: 10917
[09:46:37.828150] Epoch: [23]  [180/345]  eta: 0:00:41  lr: 0.000121  loss: 0.7851 (0.7860)  time: 0.2514  data: 0.0000  max mem: 10917
[09:46:42.855071] Epoch: [23]  [200/345]  eta: 0:00:36  lr: 0.000121  loss: 0.7920 (0.7871)  time: 0.2513  data: 0.0001  max mem: 10917
[09:46:47.890874] Epoch: [23]  [220/345]  eta: 0:00:31  lr: 0.000121  loss: 0.7932 (0.7877)  time: 0.2517  data: 0.0001  max mem: 10917
[09:46:52.930898] Epoch: [23]  [240/345]  eta: 0:00:26  lr: 0.000120  loss: 0.7967 (0.7888)  time: 0.2520  data: 0.0000  max mem: 10917
[09:46:57.975300] Epoch: [23]  [260/345]  eta: 0:00:21  lr: 0.000120  loss: 0.7931 (0.7894)  time: 0.2522  data: 0.0000  max mem: 10917
[09:47:03.016739] Epoch: [23]  [280/345]  eta: 0:00:16  lr: 0.000120  loss: 0.7946 (0.7900)  time: 0.2520  data: 0.0001  max mem: 10917
[09:47:08.060309] Epoch: [23]  [300/345]  eta: 0:00:11  lr: 0.000120  loss: 0.7942 (0.7906)  time: 0.2521  data: 0.0000  max mem: 10917
[09:47:13.104316] Epoch: [23]  [320/345]  eta: 0:00:06  lr: 0.000120  loss: 0.7838 (0.7903)  time: 0.2522  data: 0.0000  max mem: 10917
[09:47:18.148795] Epoch: [23]  [340/345]  eta: 0:00:01  lr: 0.000120  loss: 0.7883 (0.7901)  time: 0.2522  data: 0.0000  max mem: 10917
[09:47:19.158290] Epoch: [23]  [344/345]  eta: 0:00:00  lr: 0.000120  loss: 0.7810 (0.7901)  time: 0.2522  data: 0.0001  max mem: 10917
[09:47:19.215085] Epoch: [23] Total time: 0:01:26 (0.2521 s / it)
[09:47:19.215611] Averaged stats: lr: 0.000120  loss: 0.7810 (0.7901)
[09:47:19.453968] Test:  [  0/345]  eta: 0:01:20  loss: 0.7491 (0.7491)  time: 0.2346  data: 0.1548  max mem: 10917
[09:47:20.275750] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7581 (0.7681)  time: 0.0960  data: 0.0142  max mem: 10917
[09:47:21.099117] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7618 (0.7663)  time: 0.0822  data: 0.0001  max mem: 10917
[09:47:21.926123] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7618 (0.7648)  time: 0.0825  data: 0.0001  max mem: 10917
[09:47:22.758131] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7573 (0.7631)  time: 0.0829  data: 0.0001  max mem: 10917
[09:47:23.592514] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7606 (0.7630)  time: 0.0833  data: 0.0001  max mem: 10917
[09:47:24.431396] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7654 (0.7640)  time: 0.0836  data: 0.0001  max mem: 10917
[09:47:25.272482] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7638 (0.7633)  time: 0.0839  data: 0.0001  max mem: 10917
[09:47:26.117520] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7591 (0.7628)  time: 0.0843  data: 0.0001  max mem: 10917
[09:47:26.965881] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7590 (0.7627)  time: 0.0846  data: 0.0001  max mem: 10917
[09:47:27.817669] Test:  [100/345]  eta: 0:00:20  loss: 0.7577 (0.7620)  time: 0.0850  data: 0.0001  max mem: 10917
[09:47:28.672601] Test:  [110/345]  eta: 0:00:20  loss: 0.7575 (0.7617)  time: 0.0853  data: 0.0001  max mem: 10917
[09:47:29.531901] Test:  [120/345]  eta: 0:00:19  loss: 0.7604 (0.7627)  time: 0.0857  data: 0.0001  max mem: 10917
[09:47:30.394471] Test:  [130/345]  eta: 0:00:18  loss: 0.7574 (0.7621)  time: 0.0860  data: 0.0001  max mem: 10917
[09:47:31.260509] Test:  [140/345]  eta: 0:00:17  loss: 0.7595 (0.7626)  time: 0.0864  data: 0.0001  max mem: 10917
[09:47:32.129198] Test:  [150/345]  eta: 0:00:16  loss: 0.7614 (0.7625)  time: 0.0867  data: 0.0001  max mem: 10917
[09:47:33.002662] Test:  [160/345]  eta: 0:00:15  loss: 0.7567 (0.7616)  time: 0.0871  data: 0.0001  max mem: 10917
[09:47:33.878790] Test:  [170/345]  eta: 0:00:14  loss: 0.7549 (0.7614)  time: 0.0874  data: 0.0001  max mem: 10917
[09:47:34.758809] Test:  [180/345]  eta: 0:00:14  loss: 0.7587 (0.7612)  time: 0.0878  data: 0.0001  max mem: 10917
[09:47:35.642476] Test:  [190/345]  eta: 0:00:13  loss: 0.7484 (0.7603)  time: 0.0881  data: 0.0001  max mem: 10917
[09:47:36.529458] Test:  [200/345]  eta: 0:00:12  loss: 0.7455 (0.7601)  time: 0.0885  data: 0.0001  max mem: 10917
[09:47:37.420486] Test:  [210/345]  eta: 0:00:11  loss: 0.7584 (0.7602)  time: 0.0889  data: 0.0001  max mem: 10917
[09:47:38.313030] Test:  [220/345]  eta: 0:00:10  loss: 0.7627 (0.7601)  time: 0.0891  data: 0.0001  max mem: 10917
[09:47:39.210290] Test:  [230/345]  eta: 0:00:09  loss: 0.7627 (0.7602)  time: 0.0894  data: 0.0001  max mem: 10917
[09:47:40.112468] Test:  [240/345]  eta: 0:00:09  loss: 0.7620 (0.7604)  time: 0.0899  data: 0.0001  max mem: 10917
[09:47:41.016876] Test:  [250/345]  eta: 0:00:08  loss: 0.7541 (0.7601)  time: 0.0903  data: 0.0001  max mem: 10917
[09:47:41.925566] Test:  [260/345]  eta: 0:00:07  loss: 0.7541 (0.7602)  time: 0.0906  data: 0.0001  max mem: 10917
[09:47:42.837827] Test:  [270/345]  eta: 0:00:06  loss: 0.7625 (0.7602)  time: 0.0910  data: 0.0001  max mem: 10917
[09:47:43.752515] Test:  [280/345]  eta: 0:00:05  loss: 0.7556 (0.7598)  time: 0.0913  data: 0.0001  max mem: 10917
[09:47:44.671785] Test:  [290/345]  eta: 0:00:04  loss: 0.7542 (0.7598)  time: 0.0916  data: 0.0001  max mem: 10917
[09:47:45.594034] Test:  [300/345]  eta: 0:00:03  loss: 0.7637 (0.7601)  time: 0.0920  data: 0.0001  max mem: 10917
[09:47:46.520043] Test:  [310/345]  eta: 0:00:03  loss: 0.7564 (0.7599)  time: 0.0924  data: 0.0001  max mem: 10917
[09:47:47.449646] Test:  [320/345]  eta: 0:00:02  loss: 0.7562 (0.7599)  time: 0.0927  data: 0.0001  max mem: 10917
[09:47:48.382641] Test:  [330/345]  eta: 0:00:01  loss: 0.7595 (0.7600)  time: 0.0931  data: 0.0001  max mem: 10917
[09:47:49.318686] Test:  [340/345]  eta: 0:00:00  loss: 0.7637 (0.7601)  time: 0.0934  data: 0.0001  max mem: 10917
[09:47:49.694474] Test:  [344/345]  eta: 0:00:00  loss: 0.7637 (0.7600)  time: 0.0935  data: 0.0001  max mem: 10917
[09:47:49.749951] Test: Total time: 0:00:30 (0.0885 s / it)
[09:48:00.147554] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9470 (0.9470)  time: 0.2255  data: 0.1455  max mem: 10917
[09:48:00.960831] Test:  [10/57]  eta: 0:00:04  loss: 0.9133 (0.9144)  time: 0.0944  data: 0.0133  max mem: 10917
[09:48:01.780619] Test:  [20/57]  eta: 0:00:03  loss: 0.9012 (0.8963)  time: 0.0815  data: 0.0001  max mem: 10917
[09:48:02.602607] Test:  [30/57]  eta: 0:00:02  loss: 0.7889 (0.8553)  time: 0.0819  data: 0.0001  max mem: 10917
[09:48:03.427295] Test:  [40/57]  eta: 0:00:01  loss: 0.7756 (0.8318)  time: 0.0823  data: 0.0001  max mem: 10917
[09:48:04.257071] Test:  [50/57]  eta: 0:00:00  loss: 0.7627 (0.8253)  time: 0.0826  data: 0.0001  max mem: 10917
[09:48:04.707072] Test:  [56/57]  eta: 0:00:00  loss: 0.7943 (0.8284)  time: 0.0804  data: 0.0001  max mem: 10917
[09:48:04.762425] Test: Total time: 0:00:04 (0.0849 s / it)
[09:48:06.501088] Dice score of the network on the train images: 0.774328, val images: 0.800284
[09:48:06.504691] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:48:06.903980] Epoch: [24]  [  0/345]  eta: 0:02:17  lr: 0.000120  loss: 0.8204 (0.8204)  time: 0.3982  data: 0.1468  max mem: 10917
[09:48:11.893055] Epoch: [24]  [ 20/345]  eta: 0:01:23  lr: 0.000119  loss: 0.7926 (0.7940)  time: 0.2494  data: 0.0001  max mem: 10917
[09:48:16.883817] Epoch: [24]  [ 40/345]  eta: 0:01:17  lr: 0.000119  loss: 0.7908 (0.7937)  time: 0.2495  data: 0.0001  max mem: 10917
[09:48:21.879656] Epoch: [24]  [ 60/345]  eta: 0:01:11  lr: 0.000119  loss: 0.7788 (0.7898)  time: 0.2498  data: 0.0001  max mem: 10917
[09:48:26.895681] Epoch: [24]  [ 80/345]  eta: 0:01:06  lr: 0.000119  loss: 0.7834 (0.7887)  time: 0.2508  data: 0.0001  max mem: 10917
[09:48:31.924638] Epoch: [24]  [100/345]  eta: 0:01:01  lr: 0.000119  loss: 0.7891 (0.7894)  time: 0.2514  data: 0.0001  max mem: 10917
[09:48:36.946298] Epoch: [24]  [120/345]  eta: 0:00:56  lr: 0.000119  loss: 0.7847 (0.7887)  time: 0.2510  data: 0.0001  max mem: 10917
[09:48:41.970612] Epoch: [24]  [140/345]  eta: 0:00:51  lr: 0.000118  loss: 0.7883 (0.7896)  time: 0.2512  data: 0.0001  max mem: 10917
[09:48:46.988053] Epoch: [24]  [160/345]  eta: 0:00:46  lr: 0.000118  loss: 0.7880 (0.7892)  time: 0.2508  data: 0.0000  max mem: 10917
[09:48:52.006559] Epoch: [24]  [180/345]  eta: 0:00:41  lr: 0.000118  loss: 0.7856 (0.7891)  time: 0.2509  data: 0.0001  max mem: 10917
[09:48:57.027714] Epoch: [24]  [200/345]  eta: 0:00:36  lr: 0.000118  loss: 0.7898 (0.7892)  time: 0.2510  data: 0.0001  max mem: 10917
[09:49:02.052718] Epoch: [24]  [220/345]  eta: 0:00:31  lr: 0.000118  loss: 0.7751 (0.7886)  time: 0.2512  data: 0.0001  max mem: 10917
[09:49:07.079328] Epoch: [24]  [240/345]  eta: 0:00:26  lr: 0.000118  loss: 0.7807 (0.7883)  time: 0.2513  data: 0.0001  max mem: 10917
[09:49:12.097837] Epoch: [24]  [260/345]  eta: 0:00:21  lr: 0.000117  loss: 0.7855 (0.7887)  time: 0.2509  data: 0.0000  max mem: 10917
[09:49:17.122991] Epoch: [24]  [280/345]  eta: 0:00:16  lr: 0.000117  loss: 0.7832 (0.7882)  time: 0.2512  data: 0.0001  max mem: 10917
[09:49:22.156099] Epoch: [24]  [300/345]  eta: 0:00:11  lr: 0.000117  loss: 0.7733 (0.7875)  time: 0.2516  data: 0.0001  max mem: 10917
[09:49:27.183797] Epoch: [24]  [320/345]  eta: 0:00:06  lr: 0.000117  loss: 0.7796 (0.7872)  time: 0.2514  data: 0.0001  max mem: 10917
[09:49:32.212355] Epoch: [24]  [340/345]  eta: 0:00:01  lr: 0.000117  loss: 0.7807 (0.7871)  time: 0.2514  data: 0.0000  max mem: 10917
[09:49:33.217054] Epoch: [24]  [344/345]  eta: 0:00:00  lr: 0.000117  loss: 0.7860 (0.7871)  time: 0.2513  data: 0.0001  max mem: 10917
[09:49:33.272767] Epoch: [24] Total time: 0:01:26 (0.2515 s / it)
[09:49:33.273265] Averaged stats: lr: 0.000117  loss: 0.7860 (0.7871)
[09:49:33.510243] Test:  [  0/345]  eta: 0:01:20  loss: 0.7527 (0.7527)  time: 0.2339  data: 0.1537  max mem: 10917
[09:49:34.426035] Test:  [ 10/345]  eta: 0:00:34  loss: 0.7599 (0.7559)  time: 0.1045  data: 0.0231  max mem: 10917
[09:49:35.283729] Test:  [ 20/345]  eta: 0:00:31  loss: 0.7563 (0.7562)  time: 0.0886  data: 0.0069  max mem: 10917
[09:49:36.111110] Test:  [ 30/345]  eta: 0:00:28  loss: 0.7514 (0.7518)  time: 0.0842  data: 0.0019  max mem: 10917
[09:49:36.941539] Test:  [ 40/345]  eta: 0:00:27  loss: 0.7411 (0.7501)  time: 0.0828  data: 0.0001  max mem: 10917
[09:49:37.775827] Test:  [ 50/345]  eta: 0:00:26  loss: 0.7381 (0.7496)  time: 0.0832  data: 0.0001  max mem: 10917
[09:49:38.613052] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7427 (0.7494)  time: 0.0835  data: 0.0001  max mem: 10917
[09:49:39.454817] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7498 (0.7497)  time: 0.0839  data: 0.0001  max mem: 10917
[09:49:40.299569] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7470 (0.7490)  time: 0.0843  data: 0.0001  max mem: 10917
[09:49:41.147661] Test:  [ 90/345]  eta: 0:00:22  loss: 0.7357 (0.7472)  time: 0.0846  data: 0.0001  max mem: 10917
[09:49:41.999704] Test:  [100/345]  eta: 0:00:21  loss: 0.7394 (0.7475)  time: 0.0850  data: 0.0001  max mem: 10917
[09:49:42.855596] Test:  [110/345]  eta: 0:00:20  loss: 0.7429 (0.7466)  time: 0.0853  data: 0.0001  max mem: 10917
[09:49:43.714997] Test:  [120/345]  eta: 0:00:19  loss: 0.7356 (0.7461)  time: 0.0857  data: 0.0001  max mem: 10917
[09:49:44.578696] Test:  [130/345]  eta: 0:00:18  loss: 0.7470 (0.7465)  time: 0.0861  data: 0.0001  max mem: 10917
[09:49:45.444325] Test:  [140/345]  eta: 0:00:17  loss: 0.7585 (0.7474)  time: 0.0864  data: 0.0001  max mem: 10917
[09:49:46.314387] Test:  [150/345]  eta: 0:00:16  loss: 0.7588 (0.7478)  time: 0.0867  data: 0.0001  max mem: 10917
[09:49:47.186956] Test:  [160/345]  eta: 0:00:15  loss: 0.7458 (0.7474)  time: 0.0871  data: 0.0001  max mem: 10917
[09:49:48.063267] Test:  [170/345]  eta: 0:00:15  loss: 0.7443 (0.7476)  time: 0.0874  data: 0.0001  max mem: 10917
[09:49:48.943678] Test:  [180/345]  eta: 0:00:14  loss: 0.7513 (0.7474)  time: 0.0878  data: 0.0001  max mem: 10917
[09:49:49.826949] Test:  [190/345]  eta: 0:00:13  loss: 0.7473 (0.7477)  time: 0.0881  data: 0.0001  max mem: 10917
[09:49:50.713689] Test:  [200/345]  eta: 0:00:12  loss: 0.7468 (0.7475)  time: 0.0885  data: 0.0001  max mem: 10917
[09:49:51.604350] Test:  [210/345]  eta: 0:00:11  loss: 0.7359 (0.7471)  time: 0.0888  data: 0.0001  max mem: 10917
[09:49:52.497717] Test:  [220/345]  eta: 0:00:10  loss: 0.7431 (0.7473)  time: 0.0892  data: 0.0001  max mem: 10917
[09:49:53.395450] Test:  [230/345]  eta: 0:00:10  loss: 0.7452 (0.7475)  time: 0.0895  data: 0.0001  max mem: 10917
[09:49:54.296924] Test:  [240/345]  eta: 0:00:09  loss: 0.7495 (0.7475)  time: 0.0899  data: 0.0001  max mem: 10917
[09:49:55.201157] Test:  [250/345]  eta: 0:00:08  loss: 0.7541 (0.7478)  time: 0.0902  data: 0.0001  max mem: 10917
[09:49:56.108882] Test:  [260/345]  eta: 0:00:07  loss: 0.7531 (0.7481)  time: 0.0905  data: 0.0001  max mem: 10917
[09:49:57.020849] Test:  [270/345]  eta: 0:00:06  loss: 0.7503 (0.7481)  time: 0.0909  data: 0.0001  max mem: 10917
[09:49:57.935669] Test:  [280/345]  eta: 0:00:05  loss: 0.7503 (0.7482)  time: 0.0913  data: 0.0001  max mem: 10917
[09:49:58.854075] Test:  [290/345]  eta: 0:00:04  loss: 0.7463 (0.7481)  time: 0.0916  data: 0.0001  max mem: 10917
[09:49:59.775315] Test:  [300/345]  eta: 0:00:03  loss: 0.7452 (0.7483)  time: 0.0919  data: 0.0001  max mem: 10917
[09:50:00.701123] Test:  [310/345]  eta: 0:00:03  loss: 0.7478 (0.7485)  time: 0.0923  data: 0.0001  max mem: 10917
[09:50:01.629889] Test:  [320/345]  eta: 0:00:02  loss: 0.7568 (0.7488)  time: 0.0927  data: 0.0001  max mem: 10917
[09:50:02.562821] Test:  [330/345]  eta: 0:00:01  loss: 0.7533 (0.7488)  time: 0.0930  data: 0.0001  max mem: 10917
[09:50:03.498779] Test:  [340/345]  eta: 0:00:00  loss: 0.7440 (0.7486)  time: 0.0934  data: 0.0001  max mem: 10917
[09:50:03.874681] Test:  [344/345]  eta: 0:00:00  loss: 0.7440 (0.7486)  time: 0.0935  data: 0.0001  max mem: 10917
[09:50:03.929377] Test: Total time: 0:00:30 (0.0889 s / it)
[09:50:14.285601] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8910 (0.8910)  time: 0.2168  data: 0.1369  max mem: 10917
[09:50:15.099626] Test:  [10/57]  eta: 0:00:04  loss: 0.8910 (0.9082)  time: 0.0936  data: 0.0125  max mem: 10917
[09:50:15.916717] Test:  [20/57]  eta: 0:00:03  loss: 0.8900 (0.8899)  time: 0.0815  data: 0.0001  max mem: 10917
[09:50:16.738505] Test:  [30/57]  eta: 0:00:02  loss: 0.7889 (0.8501)  time: 0.0819  data: 0.0001  max mem: 10917
[09:50:17.563164] Test:  [40/57]  eta: 0:00:01  loss: 0.7762 (0.8291)  time: 0.0823  data: 0.0001  max mem: 10917
[09:50:18.391929] Test:  [50/57]  eta: 0:00:00  loss: 0.7663 (0.8211)  time: 0.0826  data: 0.0001  max mem: 10917
[09:50:18.841775] Test:  [56/57]  eta: 0:00:00  loss: 0.7799 (0.8247)  time: 0.0804  data: 0.0001  max mem: 10917
[09:50:18.896153] Test: Total time: 0:00:04 (0.0847 s / it)
[09:50:20.655412] Dice score of the network on the train images: 0.796569, val images: 0.806503
[09:50:20.658908] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:50:21.053179] Epoch: [25]  [  0/345]  eta: 0:02:15  lr: 0.000117  loss: 0.7611 (0.7611)  time: 0.3935  data: 0.1418  max mem: 10917
[09:50:26.034088] Epoch: [25]  [ 20/345]  eta: 0:01:23  lr: 0.000116  loss: 0.7821 (0.7833)  time: 0.2490  data: 0.0000  max mem: 10917
[09:50:31.021219] Epoch: [25]  [ 40/345]  eta: 0:01:17  lr: 0.000116  loss: 0.7833 (0.7844)  time: 0.2493  data: 0.0000  max mem: 10917
[09:50:36.015325] Epoch: [25]  [ 60/345]  eta: 0:01:11  lr: 0.000116  loss: 0.7894 (0.7862)  time: 0.2497  data: 0.0000  max mem: 10917
[09:50:41.015886] Epoch: [25]  [ 80/345]  eta: 0:01:06  lr: 0.000116  loss: 0.7943 (0.7874)  time: 0.2500  data: 0.0001  max mem: 10917
[09:50:46.024414] Epoch: [25]  [100/345]  eta: 0:01:01  lr: 0.000116  loss: 0.7867 (0.7871)  time: 0.2504  data: 0.0000  max mem: 10917
[09:50:51.030677] Epoch: [25]  [120/345]  eta: 0:00:56  lr: 0.000115  loss: 0.7791 (0.7861)  time: 0.2503  data: 0.0000  max mem: 10917
[09:50:56.035759] Epoch: [25]  [140/345]  eta: 0:00:51  lr: 0.000115  loss: 0.7889 (0.7864)  time: 0.2502  data: 0.0001  max mem: 10917
[09:51:01.047452] Epoch: [25]  [160/345]  eta: 0:00:46  lr: 0.000115  loss: 0.7790 (0.7857)  time: 0.2505  data: 0.0001  max mem: 10917
[09:51:06.065013] Epoch: [25]  [180/345]  eta: 0:00:41  lr: 0.000115  loss: 0.7883 (0.7859)  time: 0.2508  data: 0.0000  max mem: 10917
[09:51:11.082146] Epoch: [25]  [200/345]  eta: 0:00:36  lr: 0.000115  loss: 0.7710 (0.7849)  time: 0.2508  data: 0.0001  max mem: 10917
[09:51:16.100866] Epoch: [25]  [220/345]  eta: 0:00:31  lr: 0.000114  loss: 0.7934 (0.7857)  time: 0.2509  data: 0.0000  max mem: 10917
[09:51:21.124461] Epoch: [25]  [240/345]  eta: 0:00:26  lr: 0.000114  loss: 0.7866 (0.7860)  time: 0.2511  data: 0.0001  max mem: 10917
[09:51:26.146329] Epoch: [25]  [260/345]  eta: 0:00:21  lr: 0.000114  loss: 0.7907 (0.7865)  time: 0.2511  data: 0.0000  max mem: 10917
[09:51:31.169014] Epoch: [25]  [280/345]  eta: 0:00:16  lr: 0.000114  loss: 0.7778 (0.7858)  time: 0.2511  data: 0.0000  max mem: 10917
[09:51:36.198377] Epoch: [25]  [300/345]  eta: 0:00:11  lr: 0.000114  loss: 0.7781 (0.7855)  time: 0.2514  data: 0.0000  max mem: 10917
[09:51:41.229388] Epoch: [25]  [320/345]  eta: 0:00:06  lr: 0.000113  loss: 0.7727 (0.7848)  time: 0.2515  data: 0.0000  max mem: 10917
[09:51:46.258506] Epoch: [25]  [340/345]  eta: 0:00:01  lr: 0.000113  loss: 0.7715 (0.7842)  time: 0.2514  data: 0.0000  max mem: 10917
[09:51:47.264548] Epoch: [25]  [344/345]  eta: 0:00:00  lr: 0.000113  loss: 0.7748 (0.7842)  time: 0.2514  data: 0.0001  max mem: 10917
[09:51:47.320272] Epoch: [25] Total time: 0:01:26 (0.2512 s / it)
[09:51:47.320568] Averaged stats: lr: 0.000113  loss: 0.7748 (0.7842)
[09:51:47.553837] Test:  [  0/345]  eta: 0:01:19  loss: 0.7732 (0.7732)  time: 0.2300  data: 0.1500  max mem: 10917
[09:51:48.422289] Test:  [ 10/345]  eta: 0:00:33  loss: 0.7555 (0.7523)  time: 0.0998  data: 0.0183  max mem: 10917
[09:51:49.284919] Test:  [ 20/345]  eta: 0:00:30  loss: 0.7493 (0.7538)  time: 0.0865  data: 0.0047  max mem: 10917
[09:51:50.112659] Test:  [ 30/345]  eta: 0:00:28  loss: 0.7493 (0.7546)  time: 0.0845  data: 0.0021  max mem: 10917
[09:51:50.943315] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7476 (0.7557)  time: 0.0829  data: 0.0001  max mem: 10917
[09:51:51.778240] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7423 (0.7533)  time: 0.0832  data: 0.0001  max mem: 10917
[09:51:52.617128] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7437 (0.7534)  time: 0.0836  data: 0.0001  max mem: 10917
[09:51:53.458296] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7575 (0.7538)  time: 0.0839  data: 0.0001  max mem: 10917
[09:51:54.302323] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7480 (0.7534)  time: 0.0842  data: 0.0001  max mem: 10917
[09:51:55.151312] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7448 (0.7527)  time: 0.0846  data: 0.0001  max mem: 10917
[09:51:56.002802] Test:  [100/345]  eta: 0:00:21  loss: 0.7483 (0.7532)  time: 0.0850  data: 0.0001  max mem: 10917
[09:51:56.858882] Test:  [110/345]  eta: 0:00:20  loss: 0.7541 (0.7530)  time: 0.0853  data: 0.0001  max mem: 10917
[09:51:57.717987] Test:  [120/345]  eta: 0:00:19  loss: 0.7552 (0.7536)  time: 0.0857  data: 0.0001  max mem: 10917
[09:51:58.580422] Test:  [130/345]  eta: 0:00:18  loss: 0.7556 (0.7539)  time: 0.0860  data: 0.0001  max mem: 10917
[09:51:59.446214] Test:  [140/345]  eta: 0:00:17  loss: 0.7544 (0.7537)  time: 0.0864  data: 0.0001  max mem: 10917
[09:52:00.315440] Test:  [150/345]  eta: 0:00:16  loss: 0.7520 (0.7535)  time: 0.0867  data: 0.0001  max mem: 10917
[09:52:01.189038] Test:  [160/345]  eta: 0:00:15  loss: 0.7461 (0.7532)  time: 0.0871  data: 0.0001  max mem: 10917
[09:52:02.066386] Test:  [170/345]  eta: 0:00:15  loss: 0.7497 (0.7535)  time: 0.0875  data: 0.0001  max mem: 10917
[09:52:02.947251] Test:  [180/345]  eta: 0:00:14  loss: 0.7510 (0.7531)  time: 0.0878  data: 0.0001  max mem: 10917
[09:52:03.830181] Test:  [190/345]  eta: 0:00:13  loss: 0.7455 (0.7531)  time: 0.0881  data: 0.0001  max mem: 10917
[09:52:04.717327] Test:  [200/345]  eta: 0:00:12  loss: 0.7522 (0.7532)  time: 0.0885  data: 0.0001  max mem: 10917
[09:52:05.607346] Test:  [210/345]  eta: 0:00:11  loss: 0.7544 (0.7537)  time: 0.0888  data: 0.0001  max mem: 10917
[09:52:06.501949] Test:  [220/345]  eta: 0:00:10  loss: 0.7565 (0.7538)  time: 0.0892  data: 0.0001  max mem: 10917
[09:52:07.399822] Test:  [230/345]  eta: 0:00:09  loss: 0.7486 (0.7536)  time: 0.0896  data: 0.0001  max mem: 10917
[09:52:08.301608] Test:  [240/345]  eta: 0:00:09  loss: 0.7506 (0.7542)  time: 0.0899  data: 0.0001  max mem: 10917
[09:52:09.206492] Test:  [250/345]  eta: 0:00:08  loss: 0.7644 (0.7543)  time: 0.0903  data: 0.0001  max mem: 10917
[09:52:10.114978] Test:  [260/345]  eta: 0:00:07  loss: 0.7524 (0.7541)  time: 0.0906  data: 0.0001  max mem: 10917
[09:52:11.026538] Test:  [270/345]  eta: 0:00:06  loss: 0.7503 (0.7542)  time: 0.0910  data: 0.0001  max mem: 10917
[09:52:11.942005] Test:  [280/345]  eta: 0:00:05  loss: 0.7522 (0.7542)  time: 0.0913  data: 0.0001  max mem: 10917
[09:52:12.860667] Test:  [290/345]  eta: 0:00:04  loss: 0.7522 (0.7542)  time: 0.0917  data: 0.0001  max mem: 10917
[09:52:13.783275] Test:  [300/345]  eta: 0:00:03  loss: 0.7615 (0.7544)  time: 0.0920  data: 0.0001  max mem: 10917
[09:52:14.709259] Test:  [310/345]  eta: 0:00:03  loss: 0.7573 (0.7544)  time: 0.0924  data: 0.0001  max mem: 10917
[09:52:15.637975] Test:  [320/345]  eta: 0:00:02  loss: 0.7457 (0.7543)  time: 0.0927  data: 0.0001  max mem: 10917
[09:52:16.570774] Test:  [330/345]  eta: 0:00:01  loss: 0.7504 (0.7544)  time: 0.0930  data: 0.0001  max mem: 10917
[09:52:17.506104] Test:  [340/345]  eta: 0:00:00  loss: 0.7529 (0.7544)  time: 0.0934  data: 0.0001  max mem: 10917
[09:52:17.881560] Test:  [344/345]  eta: 0:00:00  loss: 0.7548 (0.7543)  time: 0.0935  data: 0.0001  max mem: 10917
[09:52:17.938981] Test: Total time: 0:00:30 (0.0887 s / it)
[09:52:28.286421] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8745 (0.8745)  time: 0.2181  data: 0.1381  max mem: 10917
[09:52:29.101008] Test:  [10/57]  eta: 0:00:04  loss: 0.8804 (0.9015)  time: 0.0938  data: 0.0126  max mem: 10917
[09:52:29.919064] Test:  [20/57]  eta: 0:00:03  loss: 0.8804 (0.8851)  time: 0.0816  data: 0.0001  max mem: 10917
[09:52:30.740339] Test:  [30/57]  eta: 0:00:02  loss: 0.7778 (0.8456)  time: 0.0819  data: 0.0001  max mem: 10917
[09:52:31.565203] Test:  [40/57]  eta: 0:00:01  loss: 0.7767 (0.8254)  time: 0.0823  data: 0.0001  max mem: 10917
[09:52:32.395078] Test:  [50/57]  eta: 0:00:00  loss: 0.7738 (0.8189)  time: 0.0827  data: 0.0001  max mem: 10917
[09:52:32.845585] Test:  [56/57]  eta: 0:00:00  loss: 0.7827 (0.8230)  time: 0.0805  data: 0.0001  max mem: 10917
[09:52:32.900870] Test: Total time: 0:00:04 (0.0848 s / it)
[09:52:34.630668] Dice score of the network on the train images: 0.792377, val images: 0.804756
[09:52:34.634199] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:52:35.034977] Epoch: [26]  [  0/345]  eta: 0:02:17  lr: 0.000113  loss: 0.7988 (0.7988)  time: 0.4000  data: 0.1487  max mem: 10917
[09:52:40.018876] Epoch: [26]  [ 20/345]  eta: 0:01:23  lr: 0.000113  loss: 0.7928 (0.7966)  time: 0.2492  data: 0.0000  max mem: 10917
[09:52:45.009320] Epoch: [26]  [ 40/345]  eta: 0:01:17  lr: 0.000113  loss: 0.7834 (0.7922)  time: 0.2495  data: 0.0001  max mem: 10917
[09:52:50.000060] Epoch: [26]  [ 60/345]  eta: 0:01:11  lr: 0.000112  loss: 0.7780 (0.7887)  time: 0.2495  data: 0.0000  max mem: 10917
[09:52:54.993371] Epoch: [26]  [ 80/345]  eta: 0:01:06  lr: 0.000112  loss: 0.7740 (0.7856)  time: 0.2496  data: 0.0001  max mem: 10917
[09:52:59.995857] Epoch: [26]  [100/345]  eta: 0:01:01  lr: 0.000112  loss: 0.7763 (0.7841)  time: 0.2501  data: 0.0000  max mem: 10917
[09:53:04.998620] Epoch: [26]  [120/345]  eta: 0:00:56  lr: 0.000112  loss: 0.7766 (0.7824)  time: 0.2501  data: 0.0000  max mem: 10917
[09:53:10.008106] Epoch: [26]  [140/345]  eta: 0:00:51  lr: 0.000111  loss: 0.7763 (0.7817)  time: 0.2504  data: 0.0001  max mem: 10917
[09:53:15.020252] Epoch: [26]  [160/345]  eta: 0:00:46  lr: 0.000111  loss: 0.7699 (0.7800)  time: 0.2506  data: 0.0001  max mem: 10917
[09:53:20.033009] Epoch: [26]  [180/345]  eta: 0:00:41  lr: 0.000111  loss: 0.7689 (0.7793)  time: 0.2506  data: 0.0000  max mem: 10917
[09:53:25.045625] Epoch: [26]  [200/345]  eta: 0:00:36  lr: 0.000111  loss: 0.7767 (0.7791)  time: 0.2506  data: 0.0001  max mem: 10917
[09:53:30.063666] Epoch: [26]  [220/345]  eta: 0:00:31  lr: 0.000110  loss: 0.7762 (0.7787)  time: 0.2509  data: 0.0000  max mem: 10917
[09:53:35.083431] Epoch: [26]  [240/345]  eta: 0:00:26  lr: 0.000110  loss: 0.7679 (0.7779)  time: 0.2510  data: 0.0000  max mem: 10917
[09:53:40.108155] Epoch: [26]  [260/345]  eta: 0:00:21  lr: 0.000110  loss: 0.7692 (0.7770)  time: 0.2512  data: 0.0000  max mem: 10917
[09:53:45.133198] Epoch: [26]  [280/345]  eta: 0:00:16  lr: 0.000110  loss: 0.7642 (0.7762)  time: 0.2512  data: 0.0000  max mem: 10917
[09:53:50.228350] Epoch: [26]  [300/345]  eta: 0:00:11  lr: 0.000110  loss: 0.7739 (0.7758)  time: 0.2547  data: 0.0000  max mem: 10917
[09:53:55.253265] Epoch: [26]  [320/345]  eta: 0:00:06  lr: 0.000109  loss: 0.7613 (0.7753)  time: 0.2512  data: 0.0000  max mem: 10917
[09:54:00.284072] Epoch: [26]  [340/345]  eta: 0:00:01  lr: 0.000109  loss: 0.7701 (0.7751)  time: 0.2515  data: 0.0000  max mem: 10917
[09:54:01.289888] Epoch: [26]  [344/345]  eta: 0:00:00  lr: 0.000109  loss: 0.7691 (0.7752)  time: 0.2515  data: 0.0001  max mem: 10917
[09:54:01.350872] Epoch: [26] Total time: 0:01:26 (0.2514 s / it)
[09:54:01.351227] Averaged stats: lr: 0.000109  loss: 0.7691 (0.7752)
[09:54:01.582649] Test:  [  0/345]  eta: 0:01:18  loss: 0.7343 (0.7343)  time: 0.2284  data: 0.1482  max mem: 10917
[09:54:02.404271] Test:  [ 10/345]  eta: 0:00:31  loss: 0.7343 (0.7338)  time: 0.0954  data: 0.0136  max mem: 10917
[09:54:03.228182] Test:  [ 20/345]  eta: 0:00:28  loss: 0.7305 (0.7334)  time: 0.0822  data: 0.0001  max mem: 10917
[09:54:04.054444] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7380 (0.7373)  time: 0.0825  data: 0.0001  max mem: 10917
[09:54:04.886030] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7429 (0.7386)  time: 0.0828  data: 0.0001  max mem: 10917
[09:54:05.719714] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7381 (0.7386)  time: 0.0832  data: 0.0001  max mem: 10917
[09:54:06.556884] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7443 (0.7399)  time: 0.0835  data: 0.0001  max mem: 10917
[09:54:07.397537] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7465 (0.7404)  time: 0.0838  data: 0.0001  max mem: 10917
[09:54:08.242850] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7436 (0.7413)  time: 0.0843  data: 0.0001  max mem: 10917
[09:54:09.091167] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7384 (0.7400)  time: 0.0846  data: 0.0001  max mem: 10917
[09:54:09.942633] Test:  [100/345]  eta: 0:00:20  loss: 0.7379 (0.7403)  time: 0.0849  data: 0.0001  max mem: 10917
[09:54:10.797431] Test:  [110/345]  eta: 0:00:19  loss: 0.7388 (0.7407)  time: 0.0853  data: 0.0001  max mem: 10917
[09:54:11.656348] Test:  [120/345]  eta: 0:00:19  loss: 0.7382 (0.7410)  time: 0.0856  data: 0.0001  max mem: 10917
[09:54:12.518419] Test:  [130/345]  eta: 0:00:18  loss: 0.7394 (0.7407)  time: 0.0860  data: 0.0001  max mem: 10917
[09:54:13.384371] Test:  [140/345]  eta: 0:00:17  loss: 0.7402 (0.7409)  time: 0.0864  data: 0.0001  max mem: 10917
[09:54:14.253778] Test:  [150/345]  eta: 0:00:16  loss: 0.7416 (0.7407)  time: 0.0867  data: 0.0001  max mem: 10917
[09:54:15.126948] Test:  [160/345]  eta: 0:00:15  loss: 0.7346 (0.7408)  time: 0.0871  data: 0.0001  max mem: 10917
[09:54:16.003442] Test:  [170/345]  eta: 0:00:14  loss: 0.7347 (0.7406)  time: 0.0874  data: 0.0001  max mem: 10917
[09:54:16.883428] Test:  [180/345]  eta: 0:00:14  loss: 0.7426 (0.7412)  time: 0.0878  data: 0.0001  max mem: 10917
[09:54:17.766486] Test:  [190/345]  eta: 0:00:13  loss: 0.7426 (0.7413)  time: 0.0881  data: 0.0001  max mem: 10917
[09:54:18.653596] Test:  [200/345]  eta: 0:00:12  loss: 0.7433 (0.7418)  time: 0.0885  data: 0.0001  max mem: 10917
[09:54:19.543395] Test:  [210/345]  eta: 0:00:11  loss: 0.7442 (0.7417)  time: 0.0888  data: 0.0001  max mem: 10917
[09:54:20.436787] Test:  [220/345]  eta: 0:00:10  loss: 0.7379 (0.7418)  time: 0.0891  data: 0.0001  max mem: 10917
[09:54:21.334267] Test:  [230/345]  eta: 0:00:09  loss: 0.7379 (0.7421)  time: 0.0895  data: 0.0001  max mem: 10917
[09:54:22.235666] Test:  [240/345]  eta: 0:00:09  loss: 0.7372 (0.7420)  time: 0.0899  data: 0.0001  max mem: 10917
[09:54:23.140252] Test:  [250/345]  eta: 0:00:08  loss: 0.7362 (0.7419)  time: 0.0903  data: 0.0001  max mem: 10917
[09:54:24.048139] Test:  [260/345]  eta: 0:00:07  loss: 0.7441 (0.7423)  time: 0.0906  data: 0.0001  max mem: 10917
[09:54:24.959106] Test:  [270/345]  eta: 0:00:06  loss: 0.7384 (0.7424)  time: 0.0909  data: 0.0001  max mem: 10917
[09:54:25.874283] Test:  [280/345]  eta: 0:00:05  loss: 0.7371 (0.7424)  time: 0.0913  data: 0.0001  max mem: 10917
[09:54:26.793148] Test:  [290/345]  eta: 0:00:04  loss: 0.7425 (0.7424)  time: 0.0917  data: 0.0001  max mem: 10917
[09:54:27.715324] Test:  [300/345]  eta: 0:00:03  loss: 0.7428 (0.7425)  time: 0.0920  data: 0.0001  max mem: 10917
[09:54:28.641044] Test:  [310/345]  eta: 0:00:03  loss: 0.7443 (0.7427)  time: 0.0923  data: 0.0001  max mem: 10917
[09:54:29.570041] Test:  [320/345]  eta: 0:00:02  loss: 0.7406 (0.7426)  time: 0.0927  data: 0.0001  max mem: 10917
[09:54:30.501561] Test:  [330/345]  eta: 0:00:01  loss: 0.7385 (0.7427)  time: 0.0930  data: 0.0001  max mem: 10917
[09:54:31.437553] Test:  [340/345]  eta: 0:00:00  loss: 0.7418 (0.7427)  time: 0.0933  data: 0.0001  max mem: 10917
[09:54:31.813481] Test:  [344/345]  eta: 0:00:00  loss: 0.7442 (0.7427)  time: 0.0935  data: 0.0001  max mem: 10917
[09:54:31.868395] Test: Total time: 0:00:30 (0.0884 s / it)
[09:54:42.279790] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9130 (0.9130)  time: 0.2217  data: 0.1420  max mem: 10917
[09:54:43.096536] Test:  [10/57]  eta: 0:00:04  loss: 0.8902 (0.9084)  time: 0.0943  data: 0.0132  max mem: 10917
[09:54:43.915163] Test:  [20/57]  eta: 0:00:03  loss: 0.8807 (0.8922)  time: 0.0817  data: 0.0002  max mem: 10917
[09:54:44.737238] Test:  [30/57]  eta: 0:00:02  loss: 0.7845 (0.8519)  time: 0.0820  data: 0.0001  max mem: 10917
[09:54:45.561629] Test:  [40/57]  eta: 0:00:01  loss: 0.7743 (0.8310)  time: 0.0823  data: 0.0001  max mem: 10917
[09:54:46.391581] Test:  [50/57]  eta: 0:00:00  loss: 0.7606 (0.8232)  time: 0.0827  data: 0.0001  max mem: 10917
[09:54:46.841963] Test:  [56/57]  eta: 0:00:00  loss: 0.7856 (0.8266)  time: 0.0805  data: 0.0001  max mem: 10917
[09:54:46.895037] Test: Total time: 0:00:04 (0.0849 s / it)
[09:54:48.631490] Dice score of the network on the train images: 0.806875, val images: 0.806659
[09:54:48.634958] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:54:49.029228] Epoch: [27]  [  0/345]  eta: 0:02:15  lr: 0.000109  loss: 0.7896 (0.7896)  time: 0.3935  data: 0.1417  max mem: 10917
[09:54:54.015206] Epoch: [27]  [ 20/345]  eta: 0:01:23  lr: 0.000109  loss: 0.7843 (0.7794)  time: 0.2493  data: 0.0001  max mem: 10917
[09:54:59.002986] Epoch: [27]  [ 40/345]  eta: 0:01:17  lr: 0.000108  loss: 0.7666 (0.7754)  time: 0.2494  data: 0.0001  max mem: 10917
[09:55:03.999008] Epoch: [27]  [ 60/345]  eta: 0:01:11  lr: 0.000108  loss: 0.7721 (0.7759)  time: 0.2498  data: 0.0001  max mem: 10917
[09:55:08.998399] Epoch: [27]  [ 80/345]  eta: 0:01:06  lr: 0.000108  loss: 0.7773 (0.7788)  time: 0.2499  data: 0.0001  max mem: 10917
[09:55:14.000967] Epoch: [27]  [100/345]  eta: 0:01:01  lr: 0.000108  loss: 0.8029 (0.7835)  time: 0.2501  data: 0.0000  max mem: 10917
[09:55:18.994951] Epoch: [27]  [120/345]  eta: 0:00:56  lr: 0.000107  loss: 0.7805 (0.7837)  time: 0.2497  data: 0.0000  max mem: 10917
[09:55:24.004843] Epoch: [27]  [140/345]  eta: 0:00:51  lr: 0.000107  loss: 0.7796 (0.7829)  time: 0.2505  data: 0.0001  max mem: 10917
[09:55:29.026134] Epoch: [27]  [160/345]  eta: 0:00:46  lr: 0.000107  loss: 0.7832 (0.7829)  time: 0.2510  data: 0.0001  max mem: 10917
[09:55:34.054184] Epoch: [27]  [180/345]  eta: 0:00:41  lr: 0.000107  loss: 0.7742 (0.7821)  time: 0.2514  data: 0.0001  max mem: 10917
[09:55:39.086808] Epoch: [27]  [200/345]  eta: 0:00:36  lr: 0.000106  loss: 0.7738 (0.7817)  time: 0.2516  data: 0.0001  max mem: 10917
[09:55:44.120486] Epoch: [27]  [220/345]  eta: 0:00:31  lr: 0.000106  loss: 0.7874 (0.7823)  time: 0.2516  data: 0.0001  max mem: 10917
[09:55:49.156827] Epoch: [27]  [240/345]  eta: 0:00:26  lr: 0.000106  loss: 0.7795 (0.7823)  time: 0.2518  data: 0.0001  max mem: 10917
[09:55:54.190930] Epoch: [27]  [260/345]  eta: 0:00:21  lr: 0.000106  loss: 0.7759 (0.7816)  time: 0.2517  data: 0.0001  max mem: 10917
[09:55:59.223440] Epoch: [27]  [280/345]  eta: 0:00:16  lr: 0.000105  loss: 0.7667 (0.7808)  time: 0.2516  data: 0.0001  max mem: 10917
[09:56:04.253565] Epoch: [27]  [300/345]  eta: 0:00:11  lr: 0.000105  loss: 0.7673 (0.7804)  time: 0.2515  data: 0.0000  max mem: 10917
[09:56:09.283970] Epoch: [27]  [320/345]  eta: 0:00:06  lr: 0.000105  loss: 0.7746 (0.7801)  time: 0.2515  data: 0.0001  max mem: 10917
[09:56:14.305093] Epoch: [27]  [340/345]  eta: 0:00:01  lr: 0.000104  loss: 0.7752 (0.7796)  time: 0.2510  data: 0.0000  max mem: 10917
[09:56:15.310829] Epoch: [27]  [344/345]  eta: 0:00:00  lr: 0.000104  loss: 0.7767 (0.7797)  time: 0.2511  data: 0.0001  max mem: 10917
[09:56:15.369290] Epoch: [27] Total time: 0:01:26 (0.2514 s / it)
[09:56:15.369724] Averaged stats: lr: 0.000104  loss: 0.7767 (0.7797)
[09:56:15.607896] Test:  [  0/345]  eta: 0:01:21  loss: 0.7059 (0.7059)  time: 0.2349  data: 0.1548  max mem: 10917
[09:56:16.428427] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7373 (0.7431)  time: 0.0959  data: 0.0141  max mem: 10917
[09:56:17.252283] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7520 (0.7490)  time: 0.0822  data: 0.0001  max mem: 10917
[09:56:18.079645] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7427 (0.7468)  time: 0.0825  data: 0.0001  max mem: 10917
[09:56:18.909941] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7391 (0.7454)  time: 0.0828  data: 0.0001  max mem: 10917
[09:56:19.744128] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7423 (0.7456)  time: 0.0832  data: 0.0001  max mem: 10917
[09:56:20.582205] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7447 (0.7449)  time: 0.0836  data: 0.0001  max mem: 10917
[09:56:21.423316] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7397 (0.7445)  time: 0.0839  data: 0.0001  max mem: 10917
[09:56:22.268035] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7569 (0.7461)  time: 0.0842  data: 0.0001  max mem: 10917
[09:56:23.115882] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7449 (0.7453)  time: 0.0846  data: 0.0001  max mem: 10917
[09:56:23.968184] Test:  [100/345]  eta: 0:00:20  loss: 0.7394 (0.7447)  time: 0.0850  data: 0.0001  max mem: 10917
[09:56:24.823895] Test:  [110/345]  eta: 0:00:19  loss: 0.7446 (0.7449)  time: 0.0854  data: 0.0001  max mem: 10917
[09:56:25.683844] Test:  [120/345]  eta: 0:00:19  loss: 0.7446 (0.7449)  time: 0.0857  data: 0.0001  max mem: 10917
[09:56:26.546201] Test:  [130/345]  eta: 0:00:18  loss: 0.7435 (0.7449)  time: 0.0861  data: 0.0001  max mem: 10917
[09:56:27.412339] Test:  [140/345]  eta: 0:00:17  loss: 0.7488 (0.7454)  time: 0.0864  data: 0.0001  max mem: 10917
[09:56:28.281650] Test:  [150/345]  eta: 0:00:16  loss: 0.7448 (0.7450)  time: 0.0867  data: 0.0001  max mem: 10917
[09:56:29.154243] Test:  [160/345]  eta: 0:00:15  loss: 0.7417 (0.7451)  time: 0.0870  data: 0.0001  max mem: 10917
[09:56:30.030749] Test:  [170/345]  eta: 0:00:14  loss: 0.7460 (0.7455)  time: 0.0874  data: 0.0001  max mem: 10917
[09:56:30.909938] Test:  [180/345]  eta: 0:00:14  loss: 0.7509 (0.7459)  time: 0.0877  data: 0.0001  max mem: 10917
[09:56:31.792287] Test:  [190/345]  eta: 0:00:13  loss: 0.7509 (0.7460)  time: 0.0880  data: 0.0001  max mem: 10917
[09:56:32.678951] Test:  [200/345]  eta: 0:00:12  loss: 0.7428 (0.7456)  time: 0.0884  data: 0.0001  max mem: 10917
[09:56:33.569858] Test:  [210/345]  eta: 0:00:11  loss: 0.7428 (0.7455)  time: 0.0888  data: 0.0001  max mem: 10917
[09:56:34.463829] Test:  [220/345]  eta: 0:00:10  loss: 0.7442 (0.7455)  time: 0.0892  data: 0.0001  max mem: 10917
[09:56:35.361654] Test:  [230/345]  eta: 0:00:09  loss: 0.7443 (0.7455)  time: 0.0895  data: 0.0001  max mem: 10917
[09:56:36.263066] Test:  [240/345]  eta: 0:00:09  loss: 0.7443 (0.7454)  time: 0.0899  data: 0.0001  max mem: 10917
[09:56:37.167558] Test:  [250/345]  eta: 0:00:08  loss: 0.7382 (0.7453)  time: 0.0902  data: 0.0001  max mem: 10917
[09:56:38.075226] Test:  [260/345]  eta: 0:00:07  loss: 0.7386 (0.7453)  time: 0.0906  data: 0.0001  max mem: 10917
[09:56:38.987292] Test:  [270/345]  eta: 0:00:06  loss: 0.7469 (0.7454)  time: 0.0909  data: 0.0001  max mem: 10917
[09:56:39.901835] Test:  [280/345]  eta: 0:00:05  loss: 0.7447 (0.7452)  time: 0.0913  data: 0.0001  max mem: 10917
[09:56:40.820300] Test:  [290/345]  eta: 0:00:04  loss: 0.7432 (0.7451)  time: 0.0916  data: 0.0001  max mem: 10917
[09:56:41.742349] Test:  [300/345]  eta: 0:00:03  loss: 0.7432 (0.7451)  time: 0.0920  data: 0.0001  max mem: 10917
[09:56:42.667914] Test:  [310/345]  eta: 0:00:03  loss: 0.7459 (0.7450)  time: 0.0923  data: 0.0001  max mem: 10917
[09:56:43.596747] Test:  [320/345]  eta: 0:00:02  loss: 0.7414 (0.7448)  time: 0.0927  data: 0.0001  max mem: 10917
[09:56:44.529330] Test:  [330/345]  eta: 0:00:01  loss: 0.7404 (0.7446)  time: 0.0930  data: 0.0001  max mem: 10917
[09:56:45.465525] Test:  [340/345]  eta: 0:00:00  loss: 0.7404 (0.7445)  time: 0.0934  data: 0.0001  max mem: 10917
[09:56:45.841655] Test:  [344/345]  eta: 0:00:00  loss: 0.7433 (0.7446)  time: 0.0935  data: 0.0001  max mem: 10917
[09:56:45.897010] Test: Total time: 0:00:30 (0.0885 s / it)
[09:56:56.382248] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8979 (0.8979)  time: 0.2184  data: 0.1388  max mem: 10917
[09:56:57.196000] Test:  [10/57]  eta: 0:00:04  loss: 0.8979 (0.9044)  time: 0.0938  data: 0.0127  max mem: 10917
[09:56:58.013731] Test:  [20/57]  eta: 0:00:03  loss: 0.8887 (0.8910)  time: 0.0815  data: 0.0001  max mem: 10917
[09:56:58.835056] Test:  [30/57]  eta: 0:00:02  loss: 0.7921 (0.8513)  time: 0.0819  data: 0.0001  max mem: 10917
[09:56:59.658999] Test:  [40/57]  eta: 0:00:01  loss: 0.7726 (0.8300)  time: 0.0822  data: 0.0001  max mem: 10917
[09:57:00.488145] Test:  [50/57]  eta: 0:00:00  loss: 0.7695 (0.8230)  time: 0.0826  data: 0.0001  max mem: 10917
[09:57:00.939334] Test:  [56/57]  eta: 0:00:00  loss: 0.7900 (0.8270)  time: 0.0804  data: 0.0001  max mem: 10917
[09:57:00.994400] Test: Total time: 0:00:04 (0.0848 s / it)
[09:57:02.745026] Dice score of the network on the train images: 0.790255, val images: 0.799617
[09:57:02.748496] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:57:03.143017] Epoch: [28]  [  0/345]  eta: 0:02:15  lr: 0.000104  loss: 0.7647 (0.7647)  time: 0.3937  data: 0.1419  max mem: 10917
[09:57:08.135092] Epoch: [28]  [ 20/345]  eta: 0:01:23  lr: 0.000104  loss: 0.7703 (0.7711)  time: 0.2496  data: 0.0001  max mem: 10917
[09:57:13.122364] Epoch: [28]  [ 40/345]  eta: 0:01:17  lr: 0.000104  loss: 0.7738 (0.7717)  time: 0.2493  data: 0.0001  max mem: 10917
[09:57:18.111031] Epoch: [28]  [ 60/345]  eta: 0:01:11  lr: 0.000103  loss: 0.7713 (0.7722)  time: 0.2494  data: 0.0000  max mem: 10917
[09:57:23.104540] Epoch: [28]  [ 80/345]  eta: 0:01:06  lr: 0.000103  loss: 0.7701 (0.7714)  time: 0.2496  data: 0.0000  max mem: 10917
[09:57:28.109242] Epoch: [28]  [100/345]  eta: 0:01:01  lr: 0.000103  loss: 0.7642 (0.7702)  time: 0.2502  data: 0.0001  max mem: 10917
[09:57:33.125130] Epoch: [28]  [120/345]  eta: 0:00:56  lr: 0.000103  loss: 0.7659 (0.7697)  time: 0.2508  data: 0.0000  max mem: 10917
[09:57:38.138597] Epoch: [28]  [140/345]  eta: 0:00:51  lr: 0.000102  loss: 0.7682 (0.7696)  time: 0.2506  data: 0.0001  max mem: 10917
[09:57:43.163581] Epoch: [28]  [160/345]  eta: 0:00:46  lr: 0.000102  loss: 0.7717 (0.7701)  time: 0.2512  data: 0.0000  max mem: 10917
[09:57:48.192181] Epoch: [28]  [180/345]  eta: 0:00:41  lr: 0.000102  loss: 0.7695 (0.7701)  time: 0.2514  data: 0.0000  max mem: 10917
[09:57:53.220492] Epoch: [28]  [200/345]  eta: 0:00:36  lr: 0.000101  loss: 0.7739 (0.7705)  time: 0.2514  data: 0.0001  max mem: 10917
[09:57:58.249610] Epoch: [28]  [220/345]  eta: 0:00:31  lr: 0.000101  loss: 0.7620 (0.7699)  time: 0.2514  data: 0.0000  max mem: 10917
[09:58:03.281164] Epoch: [28]  [240/345]  eta: 0:00:26  lr: 0.000101  loss: 0.7665 (0.7700)  time: 0.2515  data: 0.0001  max mem: 10917
[09:58:08.312369] Epoch: [28]  [260/345]  eta: 0:00:21  lr: 0.000101  loss: 0.7649 (0.7698)  time: 0.2515  data: 0.0000  max mem: 10917
[09:58:13.348106] Epoch: [28]  [280/345]  eta: 0:00:16  lr: 0.000100  loss: 0.7752 (0.7701)  time: 0.2518  data: 0.0000  max mem: 10917
[09:58:18.385363] Epoch: [28]  [300/345]  eta: 0:00:11  lr: 0.000100  loss: 0.7699 (0.7702)  time: 0.2518  data: 0.0000  max mem: 10917
[09:58:23.424665] Epoch: [28]  [320/345]  eta: 0:00:06  lr: 0.000100  loss: 0.7577 (0.7698)  time: 0.2519  data: 0.0000  max mem: 10917
[09:58:28.460604] Epoch: [28]  [340/345]  eta: 0:00:01  lr: 0.000099  loss: 0.7648 (0.7697)  time: 0.2518  data: 0.0000  max mem: 10917
[09:58:29.469543] Epoch: [28]  [344/345]  eta: 0:00:00  lr: 0.000099  loss: 0.7648 (0.7697)  time: 0.2518  data: 0.0001  max mem: 10917
[09:58:29.527722] Epoch: [28] Total time: 0:01:26 (0.2515 s / it)
[09:58:29.527929] Averaged stats: lr: 0.000099  loss: 0.7648 (0.7697)
[09:58:29.761569] Test:  [  0/345]  eta: 0:01:18  loss: 0.7418 (0.7418)  time: 0.2289  data: 0.1487  max mem: 10917
[09:58:30.587535] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7293 (0.7326)  time: 0.0958  data: 0.0140  max mem: 10917
[09:58:31.410871] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7286 (0.7327)  time: 0.0824  data: 0.0003  max mem: 10917
[09:58:32.238135] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7313 (0.7330)  time: 0.0825  data: 0.0001  max mem: 10917
[09:58:33.068284] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7373 (0.7341)  time: 0.0828  data: 0.0001  max mem: 10917
[09:58:33.903000] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7318 (0.7335)  time: 0.0832  data: 0.0001  max mem: 10917
[09:58:34.740536] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7322 (0.7347)  time: 0.0836  data: 0.0001  max mem: 10917
[09:58:35.581771] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7346 (0.7348)  time: 0.0839  data: 0.0001  max mem: 10917
[09:58:36.426616] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7294 (0.7335)  time: 0.0843  data: 0.0001  max mem: 10917
[09:58:37.274560] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7290 (0.7332)  time: 0.0846  data: 0.0001  max mem: 10917
[09:58:38.126421] Test:  [100/345]  eta: 0:00:20  loss: 0.7290 (0.7329)  time: 0.0849  data: 0.0001  max mem: 10917
[09:58:38.981382] Test:  [110/345]  eta: 0:00:19  loss: 0.7278 (0.7324)  time: 0.0853  data: 0.0001  max mem: 10917
[09:58:39.840306] Test:  [120/345]  eta: 0:00:19  loss: 0.7307 (0.7325)  time: 0.0856  data: 0.0001  max mem: 10917
[09:58:40.702765] Test:  [130/345]  eta: 0:00:18  loss: 0.7366 (0.7331)  time: 0.0860  data: 0.0001  max mem: 10917
[09:58:41.568589] Test:  [140/345]  eta: 0:00:17  loss: 0.7350 (0.7332)  time: 0.0864  data: 0.0001  max mem: 10917
[09:58:42.438220] Test:  [150/345]  eta: 0:00:16  loss: 0.7350 (0.7333)  time: 0.0867  data: 0.0001  max mem: 10917
[09:58:43.310770] Test:  [160/345]  eta: 0:00:15  loss: 0.7290 (0.7328)  time: 0.0871  data: 0.0001  max mem: 10917
[09:58:44.187378] Test:  [170/345]  eta: 0:00:14  loss: 0.7290 (0.7330)  time: 0.0874  data: 0.0001  max mem: 10917
[09:58:45.067141] Test:  [180/345]  eta: 0:00:14  loss: 0.7279 (0.7329)  time: 0.0878  data: 0.0001  max mem: 10917
[09:58:45.949797] Test:  [190/345]  eta: 0:00:13  loss: 0.7279 (0.7328)  time: 0.0881  data: 0.0001  max mem: 10917
[09:58:46.837023] Test:  [200/345]  eta: 0:00:12  loss: 0.7244 (0.7324)  time: 0.0884  data: 0.0001  max mem: 10917
[09:58:47.727589] Test:  [210/345]  eta: 0:00:11  loss: 0.7244 (0.7322)  time: 0.0888  data: 0.0001  max mem: 10917
[09:58:48.621515] Test:  [220/345]  eta: 0:00:10  loss: 0.7319 (0.7324)  time: 0.0892  data: 0.0001  max mem: 10917
[09:58:49.519415] Test:  [230/345]  eta: 0:00:09  loss: 0.7268 (0.7319)  time: 0.0895  data: 0.0001  max mem: 10917
[09:58:50.420788] Test:  [240/345]  eta: 0:00:09  loss: 0.7319 (0.7324)  time: 0.0899  data: 0.0001  max mem: 10917
[09:58:51.325636] Test:  [250/345]  eta: 0:00:08  loss: 0.7394 (0.7326)  time: 0.0903  data: 0.0001  max mem: 10917
[09:58:52.233738] Test:  [260/345]  eta: 0:00:07  loss: 0.7316 (0.7326)  time: 0.0906  data: 0.0001  max mem: 10917
[09:58:53.145921] Test:  [270/345]  eta: 0:00:06  loss: 0.7332 (0.7326)  time: 0.0910  data: 0.0001  max mem: 10917
[09:58:54.060987] Test:  [280/345]  eta: 0:00:05  loss: 0.7338 (0.7327)  time: 0.0913  data: 0.0001  max mem: 10917
[09:58:54.979743] Test:  [290/345]  eta: 0:00:04  loss: 0.7285 (0.7324)  time: 0.0916  data: 0.0001  max mem: 10917
[09:58:55.902276] Test:  [300/345]  eta: 0:00:03  loss: 0.7275 (0.7324)  time: 0.0920  data: 0.0001  max mem: 10917
[09:58:56.827567] Test:  [310/345]  eta: 0:00:03  loss: 0.7261 (0.7321)  time: 0.0923  data: 0.0001  max mem: 10917
[09:58:57.755872] Test:  [320/345]  eta: 0:00:02  loss: 0.7276 (0.7324)  time: 0.0926  data: 0.0001  max mem: 10917
[09:58:58.688509] Test:  [330/345]  eta: 0:00:01  loss: 0.7374 (0.7323)  time: 0.0930  data: 0.0001  max mem: 10917
[09:58:59.624363] Test:  [340/345]  eta: 0:00:00  loss: 0.7207 (0.7323)  time: 0.0934  data: 0.0001  max mem: 10917
[09:58:59.999807] Test:  [344/345]  eta: 0:00:00  loss: 0.7248 (0.7322)  time: 0.0935  data: 0.0001  max mem: 10917
[09:59:00.057757] Test: Total time: 0:00:30 (0.0885 s / it)
[09:59:10.511236] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8787 (0.8787)  time: 0.2189  data: 0.1391  max mem: 10917
[09:59:11.324511] Test:  [10/57]  eta: 0:00:04  loss: 0.8873 (0.9012)  time: 0.0938  data: 0.0127  max mem: 10917
[09:59:12.142252] Test:  [20/57]  eta: 0:00:03  loss: 0.8873 (0.8859)  time: 0.0815  data: 0.0001  max mem: 10917
[09:59:12.963660] Test:  [30/57]  eta: 0:00:02  loss: 0.7864 (0.8475)  time: 0.0819  data: 0.0001  max mem: 10917
[09:59:13.788337] Test:  [40/57]  eta: 0:00:01  loss: 0.7733 (0.8284)  time: 0.0823  data: 0.0001  max mem: 10917
[09:59:14.616387] Test:  [50/57]  eta: 0:00:00  loss: 0.7626 (0.8210)  time: 0.0826  data: 0.0001  max mem: 10917
[09:59:15.066177] Test:  [56/57]  eta: 0:00:00  loss: 0.7847 (0.8251)  time: 0.0804  data: 0.0001  max mem: 10917
[09:59:15.121685] Test: Total time: 0:00:04 (0.0847 s / it)
[09:59:16.873331] Dice score of the network on the train images: 0.806415, val images: 0.812416
[09:59:16.876754] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:59:17.273111] Epoch: [29]  [  0/345]  eta: 0:02:16  lr: 0.000099  loss: 0.7457 (0.7457)  time: 0.3953  data: 0.1431  max mem: 10917
[09:59:22.275526] Epoch: [29]  [ 20/345]  eta: 0:01:23  lr: 0.000099  loss: 0.7574 (0.7612)  time: 0.2501  data: 0.0001  max mem: 10917
[09:59:27.262463] Epoch: [29]  [ 40/345]  eta: 0:01:17  lr: 0.000099  loss: 0.7659 (0.7653)  time: 0.2493  data: 0.0001  max mem: 10917
[09:59:32.253520] Epoch: [29]  [ 60/345]  eta: 0:01:11  lr: 0.000098  loss: 0.7711 (0.7676)  time: 0.2495  data: 0.0001  max mem: 10917
[09:59:37.250234] Epoch: [29]  [ 80/345]  eta: 0:01:06  lr: 0.000098  loss: 0.7598 (0.7670)  time: 0.2498  data: 0.0001  max mem: 10917
[09:59:42.253445] Epoch: [29]  [100/345]  eta: 0:01:01  lr: 0.000098  loss: 0.7536 (0.7652)  time: 0.2501  data: 0.0001  max mem: 10917
[09:59:47.271556] Epoch: [29]  [120/345]  eta: 0:00:56  lr: 0.000097  loss: 0.7645 (0.7651)  time: 0.2509  data: 0.0001  max mem: 10917
[09:59:52.295327] Epoch: [29]  [140/345]  eta: 0:00:51  lr: 0.000097  loss: 0.7654 (0.7653)  time: 0.2511  data: 0.0001  max mem: 10917
[09:59:57.321597] Epoch: [29]  [160/345]  eta: 0:00:46  lr: 0.000097  loss: 0.7671 (0.7662)  time: 0.2513  data: 0.0001  max mem: 10917
[10:00:02.347417] Epoch: [29]  [180/345]  eta: 0:00:41  lr: 0.000096  loss: 0.7713 (0.7669)  time: 0.2512  data: 0.0001  max mem: 10917
[10:00:07.377551] Epoch: [29]  [200/345]  eta: 0:00:36  lr: 0.000096  loss: 0.7687 (0.7669)  time: 0.2515  data: 0.0000  max mem: 10917
[10:00:12.410965] Epoch: [29]  [220/345]  eta: 0:00:31  lr: 0.000096  loss: 0.7698 (0.7676)  time: 0.2516  data: 0.0000  max mem: 10917
[10:00:17.443477] Epoch: [29]  [240/345]  eta: 0:00:26  lr: 0.000095  loss: 0.7702 (0.7681)  time: 0.2516  data: 0.0000  max mem: 10917
[10:00:22.480576] Epoch: [29]  [260/345]  eta: 0:00:21  lr: 0.000095  loss: 0.7679 (0.7682)  time: 0.2518  data: 0.0001  max mem: 10917
[10:00:27.522014] Epoch: [29]  [280/345]  eta: 0:00:16  lr: 0.000095  loss: 0.7757 (0.7689)  time: 0.2520  data: 0.0001  max mem: 10917
[10:00:32.558740] Epoch: [29]  [300/345]  eta: 0:00:11  lr: 0.000094  loss: 0.7680 (0.7690)  time: 0.2518  data: 0.0001  max mem: 10917
[10:00:37.599963] Epoch: [29]  [320/345]  eta: 0:00:06  lr: 0.000094  loss: 0.7715 (0.7690)  time: 0.2520  data: 0.0001  max mem: 10917
[10:00:42.645596] Epoch: [29]  [340/345]  eta: 0:00:01  lr: 0.000094  loss: 0.7705 (0.7688)  time: 0.2522  data: 0.0001  max mem: 10917
[10:00:43.655293] Epoch: [29]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.7666 (0.7688)  time: 0.2522  data: 0.0001  max mem: 10917
[10:00:43.711664] Epoch: [29] Total time: 0:01:26 (0.2517 s / it)
[10:00:43.712137] Averaged stats: lr: 0.000094  loss: 0.7666 (0.7688)
[10:00:43.945957] Test:  [  0/345]  eta: 0:01:19  loss: 0.7440 (0.7440)  time: 0.2303  data: 0.1498  max mem: 10917
[10:00:44.767360] Test:  [ 10/345]  eta: 0:00:31  loss: 0.7381 (0.7372)  time: 0.0955  data: 0.0137  max mem: 10917
[10:00:45.590675] Test:  [ 20/345]  eta: 0:00:28  loss: 0.7286 (0.7307)  time: 0.0822  data: 0.0001  max mem: 10917
[10:00:46.418402] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7271 (0.7324)  time: 0.0825  data: 0.0001  max mem: 10917
[10:00:47.248936] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7337 (0.7328)  time: 0.0829  data: 0.0001  max mem: 10917
[10:00:48.083700] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7343 (0.7328)  time: 0.0832  data: 0.0001  max mem: 10917
[10:00:48.921805] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7347 (0.7330)  time: 0.0836  data: 0.0001  max mem: 10917
[10:00:49.763506] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7337 (0.7331)  time: 0.0839  data: 0.0001  max mem: 10917
[10:00:50.607991] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7337 (0.7342)  time: 0.0843  data: 0.0001  max mem: 10917
[10:00:51.456936] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7351 (0.7343)  time: 0.0846  data: 0.0001  max mem: 10917
[10:00:52.308675] Test:  [100/345]  eta: 0:00:20  loss: 0.7343 (0.7342)  time: 0.0850  data: 0.0001  max mem: 10917
[10:00:53.163996] Test:  [110/345]  eta: 0:00:19  loss: 0.7357 (0.7348)  time: 0.0853  data: 0.0001  max mem: 10917
[10:00:54.023057] Test:  [120/345]  eta: 0:00:19  loss: 0.7305 (0.7344)  time: 0.0857  data: 0.0001  max mem: 10917
[10:00:54.885358] Test:  [130/345]  eta: 0:00:18  loss: 0.7300 (0.7348)  time: 0.0860  data: 0.0001  max mem: 10917
[10:00:55.750773] Test:  [140/345]  eta: 0:00:17  loss: 0.7354 (0.7350)  time: 0.0863  data: 0.0001  max mem: 10917
[10:00:56.621021] Test:  [150/345]  eta: 0:00:16  loss: 0.7310 (0.7348)  time: 0.0867  data: 0.0001  max mem: 10917
[10:00:57.493560] Test:  [160/345]  eta: 0:00:15  loss: 0.7313 (0.7348)  time: 0.0871  data: 0.0001  max mem: 10917
[10:00:58.369801] Test:  [170/345]  eta: 0:00:14  loss: 0.7374 (0.7351)  time: 0.0874  data: 0.0001  max mem: 10917
[10:00:59.249664] Test:  [180/345]  eta: 0:00:14  loss: 0.7405 (0.7354)  time: 0.0878  data: 0.0001  max mem: 10917
[10:01:00.132531] Test:  [190/345]  eta: 0:00:13  loss: 0.7325 (0.7353)  time: 0.0881  data: 0.0001  max mem: 10917
[10:01:01.019850] Test:  [200/345]  eta: 0:00:12  loss: 0.7296 (0.7352)  time: 0.0885  data: 0.0001  max mem: 10917
[10:01:01.910704] Test:  [210/345]  eta: 0:00:11  loss: 0.7343 (0.7351)  time: 0.0889  data: 0.0001  max mem: 10917
[10:01:02.804177] Test:  [220/345]  eta: 0:00:10  loss: 0.7341 (0.7347)  time: 0.0892  data: 0.0001  max mem: 10917
[10:01:03.701417] Test:  [230/345]  eta: 0:00:09  loss: 0.7299 (0.7349)  time: 0.0895  data: 0.0001  max mem: 10917
[10:01:04.602162] Test:  [240/345]  eta: 0:00:09  loss: 0.7359 (0.7352)  time: 0.0899  data: 0.0001  max mem: 10917
[10:01:05.506080] Test:  [250/345]  eta: 0:00:08  loss: 0.7347 (0.7351)  time: 0.0902  data: 0.0001  max mem: 10917
[10:01:06.414187] Test:  [260/345]  eta: 0:00:07  loss: 0.7324 (0.7352)  time: 0.0906  data: 0.0001  max mem: 10917
[10:01:07.326354] Test:  [270/345]  eta: 0:00:06  loss: 0.7320 (0.7353)  time: 0.0910  data: 0.0001  max mem: 10917
[10:01:08.241514] Test:  [280/345]  eta: 0:00:05  loss: 0.7321 (0.7352)  time: 0.0913  data: 0.0001  max mem: 10917
[10:01:09.159523] Test:  [290/345]  eta: 0:00:04  loss: 0.7352 (0.7355)  time: 0.0916  data: 0.0001  max mem: 10917
[10:01:10.081709] Test:  [300/345]  eta: 0:00:03  loss: 0.7352 (0.7352)  time: 0.0920  data: 0.0001  max mem: 10917
[10:01:11.007460] Test:  [310/345]  eta: 0:00:03  loss: 0.7247 (0.7352)  time: 0.0923  data: 0.0001  max mem: 10917
[10:01:11.936703] Test:  [320/345]  eta: 0:00:02  loss: 0.7292 (0.7352)  time: 0.0927  data: 0.0001  max mem: 10917
[10:01:12.868975] Test:  [330/345]  eta: 0:00:01  loss: 0.7292 (0.7353)  time: 0.0930  data: 0.0001  max mem: 10917
[10:01:13.805289] Test:  [340/345]  eta: 0:00:00  loss: 0.7292 (0.7351)  time: 0.0934  data: 0.0001  max mem: 10917
[10:01:14.180752] Test:  [344/345]  eta: 0:00:00  loss: 0.7292 (0.7351)  time: 0.0935  data: 0.0001  max mem: 10917
[10:01:14.238431] Test: Total time: 0:00:30 (0.0885 s / it)
[10:01:24.779564] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9135 (0.9135)  time: 0.2173  data: 0.1375  max mem: 10917
[10:01:25.592153] Test:  [10/57]  eta: 0:00:04  loss: 0.9091 (0.9176)  time: 0.0935  data: 0.0126  max mem: 10917
[10:01:26.409470] Test:  [20/57]  eta: 0:00:03  loss: 0.9091 (0.9085)  time: 0.0814  data: 0.0001  max mem: 10917
[10:01:27.230741] Test:  [30/57]  eta: 0:00:02  loss: 0.8039 (0.8656)  time: 0.0819  data: 0.0001  max mem: 10917
[10:01:28.055066] Test:  [40/57]  eta: 0:00:01  loss: 0.7866 (0.8437)  time: 0.0822  data: 0.0001  max mem: 10917
[10:01:28.883859] Test:  [50/57]  eta: 0:00:00  loss: 0.7866 (0.8362)  time: 0.0826  data: 0.0001  max mem: 10917
[10:01:29.334225] Test:  [56/57]  eta: 0:00:00  loss: 0.7997 (0.8403)  time: 0.0804  data: 0.0001  max mem: 10917
[10:01:29.389489] Test: Total time: 0:00:04 (0.0847 s / it)
[10:01:31.167042] Dice score of the network on the train images: 0.815970, val images: 0.798645
[10:01:31.170385] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:01:31.566128] Epoch: [30]  [  0/345]  eta: 0:02:16  lr: 0.000094  loss: 0.7643 (0.7643)  time: 0.3946  data: 0.1421  max mem: 10917
[10:01:36.559844] Epoch: [30]  [ 20/345]  eta: 0:01:23  lr: 0.000093  loss: 0.7671 (0.7667)  time: 0.2496  data: 0.0001  max mem: 10917
[10:01:41.549020] Epoch: [30]  [ 40/345]  eta: 0:01:17  lr: 0.000093  loss: 0.7652 (0.7658)  time: 0.2494  data: 0.0001  max mem: 10917
[10:01:46.537418] Epoch: [30]  [ 60/345]  eta: 0:01:11  lr: 0.000093  loss: 0.7639 (0.7662)  time: 0.2494  data: 0.0001  max mem: 10917
[10:01:51.527897] Epoch: [30]  [ 80/345]  eta: 0:01:06  lr: 0.000092  loss: 0.7637 (0.7661)  time: 0.2495  data: 0.0001  max mem: 10917
[10:01:56.521726] Epoch: [30]  [100/345]  eta: 0:01:01  lr: 0.000092  loss: 0.7833 (0.7689)  time: 0.2497  data: 0.0001  max mem: 10917
[10:02:01.523135] Epoch: [30]  [120/345]  eta: 0:00:56  lr: 0.000092  loss: 0.7752 (0.7708)  time: 0.2500  data: 0.0001  max mem: 10917
[10:02:06.525163] Epoch: [30]  [140/345]  eta: 0:00:51  lr: 0.000091  loss: 0.7739 (0.7720)  time: 0.2501  data: 0.0001  max mem: 10917
[10:02:11.537183] Epoch: [30]  [160/345]  eta: 0:00:46  lr: 0.000091  loss: 0.7662 (0.7713)  time: 0.2506  data: 0.0000  max mem: 10917
[10:02:16.549465] Epoch: [30]  [180/345]  eta: 0:00:41  lr: 0.000091  loss: 0.7632 (0.7709)  time: 0.2506  data: 0.0001  max mem: 10917
[10:02:21.630641] Epoch: [30]  [200/345]  eta: 0:00:36  lr: 0.000090  loss: 0.7677 (0.7708)  time: 0.2540  data: 0.0001  max mem: 10917
[10:02:26.643795] Epoch: [30]  [220/345]  eta: 0:00:31  lr: 0.000090  loss: 0.7644 (0.7706)  time: 0.2506  data: 0.0001  max mem: 10917
[10:02:31.662050] Epoch: [30]  [240/345]  eta: 0:00:26  lr: 0.000090  loss: 0.7958 (0.7726)  time: 0.2509  data: 0.0001  max mem: 10917
[10:02:36.691926] Epoch: [30]  [260/345]  eta: 0:00:21  lr: 0.000089  loss: 0.7839 (0.7738)  time: 0.2515  data: 0.0001  max mem: 10917
[10:02:41.726959] Epoch: [30]  [280/345]  eta: 0:00:16  lr: 0.000089  loss: 0.7782 (0.7741)  time: 0.2517  data: 0.0000  max mem: 10917
[10:02:46.762121] Epoch: [30]  [300/345]  eta: 0:00:11  lr: 0.000089  loss: 0.7691 (0.7739)  time: 0.2517  data: 0.0001  max mem: 10917
[10:02:51.803549] Epoch: [30]  [320/345]  eta: 0:00:06  lr: 0.000088  loss: 0.7637 (0.7734)  time: 0.2520  data: 0.0000  max mem: 10917
[10:02:56.844828] Epoch: [30]  [340/345]  eta: 0:00:01  lr: 0.000088  loss: 0.7676 (0.7729)  time: 0.2520  data: 0.0000  max mem: 10917
[10:02:57.852581] Epoch: [30]  [344/345]  eta: 0:00:00  lr: 0.000088  loss: 0.7605 (0.7727)  time: 0.2520  data: 0.0001  max mem: 10917
[10:02:57.911931] Epoch: [30] Total time: 0:01:26 (0.2514 s / it)
[10:02:57.912372] Averaged stats: lr: 0.000088  loss: 0.7605 (0.7727)
[10:02:58.149576] Test:  [  0/345]  eta: 0:01:20  loss: 0.7266 (0.7266)  time: 0.2334  data: 0.1534  max mem: 10917
[10:02:58.984489] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7266 (0.7313)  time: 0.0970  data: 0.0154  max mem: 10917
[10:02:59.807955] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7252 (0.7330)  time: 0.0828  data: 0.0008  max mem: 10917
[10:03:00.635544] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7336 (0.7340)  time: 0.0825  data: 0.0001  max mem: 10917
[10:03:01.465275] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7280 (0.7316)  time: 0.0828  data: 0.0001  max mem: 10917
[10:03:02.299789] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7251 (0.7325)  time: 0.0832  data: 0.0001  max mem: 10917
[10:03:03.138247] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7246 (0.7320)  time: 0.0836  data: 0.0001  max mem: 10917
[10:03:03.979645] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7358 (0.7328)  time: 0.0839  data: 0.0001  max mem: 10917
[10:03:04.824408] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7330 (0.7324)  time: 0.0843  data: 0.0001  max mem: 10917
[10:03:05.672471] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7288 (0.7321)  time: 0.0846  data: 0.0001  max mem: 10917
[10:03:06.524216] Test:  [100/345]  eta: 0:00:20  loss: 0.7244 (0.7316)  time: 0.0849  data: 0.0001  max mem: 10917
[10:03:07.380167] Test:  [110/345]  eta: 0:00:20  loss: 0.7244 (0.7314)  time: 0.0853  data: 0.0001  max mem: 10917
[10:03:08.239475] Test:  [120/345]  eta: 0:00:19  loss: 0.7295 (0.7311)  time: 0.0857  data: 0.0001  max mem: 10917
[10:03:09.102833] Test:  [130/345]  eta: 0:00:18  loss: 0.7295 (0.7312)  time: 0.0861  data: 0.0001  max mem: 10917
[10:03:09.969072] Test:  [140/345]  eta: 0:00:17  loss: 0.7303 (0.7312)  time: 0.0864  data: 0.0001  max mem: 10917
[10:03:10.839254] Test:  [150/345]  eta: 0:00:16  loss: 0.7306 (0.7314)  time: 0.0868  data: 0.0001  max mem: 10917
[10:03:11.712109] Test:  [160/345]  eta: 0:00:15  loss: 0.7260 (0.7309)  time: 0.0871  data: 0.0001  max mem: 10917
[10:03:12.588233] Test:  [170/345]  eta: 0:00:15  loss: 0.7300 (0.7308)  time: 0.0874  data: 0.0001  max mem: 10917
[10:03:13.468172] Test:  [180/345]  eta: 0:00:14  loss: 0.7303 (0.7308)  time: 0.0877  data: 0.0001  max mem: 10917
[10:03:14.352493] Test:  [190/345]  eta: 0:00:13  loss: 0.7311 (0.7311)  time: 0.0881  data: 0.0001  max mem: 10917
[10:03:15.239600] Test:  [200/345]  eta: 0:00:12  loss: 0.7291 (0.7310)  time: 0.0885  data: 0.0001  max mem: 10917
[10:03:16.130218] Test:  [210/345]  eta: 0:00:11  loss: 0.7315 (0.7311)  time: 0.0888  data: 0.0001  max mem: 10917
[10:03:17.024148] Test:  [220/345]  eta: 0:00:10  loss: 0.7339 (0.7314)  time: 0.0892  data: 0.0001  max mem: 10917
[10:03:17.921739] Test:  [230/345]  eta: 0:00:09  loss: 0.7333 (0.7314)  time: 0.0895  data: 0.0001  max mem: 10917
[10:03:18.823324] Test:  [240/345]  eta: 0:00:09  loss: 0.7285 (0.7316)  time: 0.0899  data: 0.0001  max mem: 10917
[10:03:19.727257] Test:  [250/345]  eta: 0:00:08  loss: 0.7285 (0.7315)  time: 0.0902  data: 0.0001  max mem: 10917
[10:03:20.635011] Test:  [260/345]  eta: 0:00:07  loss: 0.7264 (0.7315)  time: 0.0905  data: 0.0001  max mem: 10917
[10:03:21.545949] Test:  [270/345]  eta: 0:00:06  loss: 0.7341 (0.7316)  time: 0.0909  data: 0.0001  max mem: 10917
[10:03:22.461924] Test:  [280/345]  eta: 0:00:05  loss: 0.7292 (0.7313)  time: 0.0913  data: 0.0001  max mem: 10917
[10:03:23.381984] Test:  [290/345]  eta: 0:00:04  loss: 0.7292 (0.7315)  time: 0.0917  data: 0.0001  max mem: 10917
[10:03:24.303820] Test:  [300/345]  eta: 0:00:03  loss: 0.7331 (0.7317)  time: 0.0920  data: 0.0001  max mem: 10917
[10:03:25.229114] Test:  [310/345]  eta: 0:00:03  loss: 0.7331 (0.7317)  time: 0.0923  data: 0.0001  max mem: 10917
[10:03:26.158141] Test:  [320/345]  eta: 0:00:02  loss: 0.7286 (0.7317)  time: 0.0927  data: 0.0001  max mem: 10917
[10:03:27.090820] Test:  [330/345]  eta: 0:00:01  loss: 0.7277 (0.7315)  time: 0.0930  data: 0.0001  max mem: 10917
[10:03:28.026536] Test:  [340/345]  eta: 0:00:00  loss: 0.7261 (0.7316)  time: 0.0934  data: 0.0001  max mem: 10917
[10:03:28.402921] Test:  [344/345]  eta: 0:00:00  loss: 0.7289 (0.7316)  time: 0.0936  data: 0.0001  max mem: 10917
[10:03:28.459875] Test: Total time: 0:00:30 (0.0885 s / it)
[10:03:38.767260] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8926 (0.8926)  time: 0.2182  data: 0.1384  max mem: 10917
[10:03:39.581461] Test:  [10/57]  eta: 0:00:04  loss: 0.9073 (0.9085)  time: 0.0938  data: 0.0126  max mem: 10917
[10:03:40.398239] Test:  [20/57]  eta: 0:00:03  loss: 0.9073 (0.8935)  time: 0.0815  data: 0.0001  max mem: 10917
[10:03:41.219133] Test:  [30/57]  eta: 0:00:02  loss: 0.7935 (0.8527)  time: 0.0818  data: 0.0001  max mem: 10917
[10:03:42.044852] Test:  [40/57]  eta: 0:00:01  loss: 0.7759 (0.8310)  time: 0.0823  data: 0.0001  max mem: 10917
[10:03:42.872709] Test:  [50/57]  eta: 0:00:00  loss: 0.7675 (0.8238)  time: 0.0826  data: 0.0001  max mem: 10917
[10:03:43.322891] Test:  [56/57]  eta: 0:00:00  loss: 0.7864 (0.8284)  time: 0.0804  data: 0.0001  max mem: 10917
[10:03:43.379573] Test: Total time: 0:00:04 (0.0848 s / it)
[10:03:45.126817] Dice score of the network on the train images: 0.813430, val images: 0.809142
[10:03:45.129875] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:03:45.522390] Epoch: [31]  [  0/345]  eta: 0:02:15  lr: 0.000088  loss: 0.7779 (0.7779)  time: 0.3917  data: 0.1377  max mem: 10917

[10:03:50.522628] Epoch: [31]  [ 20/345]  eta: 0:01:23  lr: 0.000088  loss: 0.7610 (0.7657)  time: 0.2500  data: 0.0000  max mem: 10917
[10:03:55.524204] Epoch: [31]  [ 40/345]  eta: 0:01:17  lr: 0.000087  loss: 0.7605 (0.7656)  time: 0.2500  data: 0.0000  max mem: 10917
[10:04:00.519371] Epoch: [31]  [ 60/345]  eta: 0:01:11  lr: 0.000087  loss: 0.7597 (0.7628)  time: 0.2497  data: 0.0001  max mem: 10917
[10:04:05.509204] Epoch: [31]  [ 80/345]  eta: 0:01:06  lr: 0.000087  loss: 0.7606 (0.7622)  time: 0.2494  data: 0.0001  max mem: 10917
[10:04:10.506138] Epoch: [31]  [100/345]  eta: 0:01:01  lr: 0.000086  loss: 0.7614 (0.7625)  time: 0.2498  data: 0.0001  max mem: 10917
[10:04:15.512300] Epoch: [31]  [120/345]  eta: 0:00:56  lr: 0.000086  loss: 0.7596 (0.7632)  time: 0.2503  data: 0.0001  max mem: 10917
[10:04:20.517453] Epoch: [31]  [140/345]  eta: 0:00:51  lr: 0.000085  loss: 0.7686 (0.7640)  time: 0.2502  data: 0.0001  max mem: 10917
[10:04:25.523074] Epoch: [31]  [160/345]  eta: 0:00:46  lr: 0.000085  loss: 0.7663 (0.7648)  time: 0.2502  data: 0.0001  max mem: 10917
[10:04:30.528778] Epoch: [31]  [180/345]  eta: 0:00:41  lr: 0.000085  loss: 0.7556 (0.7644)  time: 0.2502  data: 0.0001  max mem: 10917
[10:04:35.541429] Epoch: [31]  [200/345]  eta: 0:00:36  lr: 0.000084  loss: 0.7634 (0.7646)  time: 0.2506  data: 0.0000  max mem: 10917

[10:04:40.555234] Epoch: [31]  [220/345]  eta: 0:00:31  lr: 0.000084  loss: 0.7604 (0.7645)  time: 0.2506  data: 0.0000  max mem: 10917
[10:04:45.574147] Epoch: [31]  [240/345]  eta: 0:00:26  lr: 0.000084  loss: 0.7553 (0.7640)  time: 0.2509  data: 0.0000  max mem: 10917

[10:04:50.593021] Epoch: [31]  [260/345]  eta: 0:00:21  lr: 0.000083  loss: 0.7683 (0.7645)  time: 0.2509  data: 0.0001  max mem: 10917
[10:04:55.614718] Epoch: [31]  [280/345]  eta: 0:00:16  lr: 0.000083  loss: 0.7884 (0.7669)  time: 0.2510  data: 0.0000  max mem: 10917
[10:05:00.646951] Epoch: [31]  [300/345]  eta: 0:00:11  lr: 0.000083  loss: 0.7749 (0.7679)  time: 0.2516  data: 0.0001  max mem: 10917
[10:05:05.686229] Epoch: [31]  [320/345]  eta: 0:00:06  lr: 0.000082  loss: 0.7720 (0.7683)  time: 0.2519  data: 0.0000  max mem: 10917
[10:05:10.725508] Epoch: [31]  [340/345]  eta: 0:00:01  lr: 0.000082  loss: 0.7616 (0.7681)  time: 0.2519  data: 0.0000  max mem: 10917
[10:05:11.733073] Epoch: [31]  [344/345]  eta: 0:00:00  lr: 0.000082  loss: 0.7653 (0.7681)  time: 0.2519  data: 0.0001  max mem: 10917
[10:05:11.788861] Epoch: [31] Total time: 0:01:26 (0.2512 s / it)
[10:05:11.789296] Averaged stats: lr: 0.000082  loss: 0.7653 (0.7681)
[10:05:12.023170] Test:  [  0/345]  eta: 0:01:19  loss: 0.7238 (0.7238)  time: 0.2305  data: 0.1503  max mem: 10917
[10:05:12.852705] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7274 (0.7300)  time: 0.0963  data: 0.0145  max mem: 10917
[10:05:13.676166] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7282 (0.7298)  time: 0.0826  data: 0.0005  max mem: 10917
[10:05:14.502053] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7282 (0.7300)  time: 0.0824  data: 0.0001  max mem: 10917
[10:05:15.333513] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7261 (0.7284)  time: 0.0828  data: 0.0001  max mem: 10917
[10:05:16.166553] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7289 (0.7306)  time: 0.0832  data: 0.0001  max mem: 10917
[10:05:17.004067] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7289 (0.7289)  time: 0.0835  data: 0.0001  max mem: 10917
[10:05:17.845295] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7221 (0.7306)  time: 0.0839  data: 0.0001  max mem: 10917
[10:05:18.690044] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7347 (0.7307)  time: 0.0842  data: 0.0001  max mem: 10917
[10:05:19.537818] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7312 (0.7311)  time: 0.0846  data: 0.0001  max mem: 10917
[10:05:20.390230] Test:  [100/345]  eta: 0:00:20  loss: 0.7308 (0.7310)  time: 0.0850  data: 0.0001  max mem: 10917
[10:05:21.245232] Test:  [110/345]  eta: 0:00:20  loss: 0.7313 (0.7315)  time: 0.0853  data: 0.0001  max mem: 10917
[10:05:22.104634] Test:  [120/345]  eta: 0:00:19  loss: 0.7329 (0.7316)  time: 0.0857  data: 0.0001  max mem: 10917
[10:05:22.967013] Test:  [130/345]  eta: 0:00:18  loss: 0.7363 (0.7323)  time: 0.0860  data: 0.0001  max mem: 10917
[10:05:23.832968] Test:  [140/345]  eta: 0:00:17  loss: 0.7292 (0.7320)  time: 0.0864  data: 0.0001  max mem: 10917
[10:05:24.701766] Test:  [150/345]  eta: 0:00:16  loss: 0.7268 (0.7317)  time: 0.0867  data: 0.0001  max mem: 10917
[10:05:25.575033] Test:  [160/345]  eta: 0:00:15  loss: 0.7256 (0.7319)  time: 0.0871  data: 0.0001  max mem: 10917
[10:05:26.451890] Test:  [170/345]  eta: 0:00:14  loss: 0.7301 (0.7322)  time: 0.0874  data: 0.0001  max mem: 10917
[10:05:27.331464] Test:  [180/345]  eta: 0:00:14  loss: 0.7315 (0.7322)  time: 0.0877  data: 0.0001  max mem: 10917
[10:05:28.215051] Test:  [190/345]  eta: 0:00:13  loss: 0.7237 (0.7317)  time: 0.0881  data: 0.0001  max mem: 10917
[10:05:29.102715] Test:  [200/345]  eta: 0:00:12  loss: 0.7261 (0.7316)  time: 0.0885  data: 0.0001  max mem: 10917
[10:05:29.993207] Test:  [210/345]  eta: 0:00:11  loss: 0.7299 (0.7318)  time: 0.0889  data: 0.0001  max mem: 10917
[10:05:30.886104] Test:  [220/345]  eta: 0:00:10  loss: 0.7363 (0.7321)  time: 0.0891  data: 0.0001  max mem: 10917
[10:05:31.783019] Test:  [230/345]  eta: 0:00:09  loss: 0.7363 (0.7323)  time: 0.0894  data: 0.0001  max mem: 10917
[10:05:32.683917] Test:  [240/345]  eta: 0:00:09  loss: 0.7325 (0.7324)  time: 0.0898  data: 0.0001  max mem: 10917
[10:05:33.587855] Test:  [250/345]  eta: 0:00:08  loss: 0.7328 (0.7325)  time: 0.0902  data: 0.0001  max mem: 10917
[10:05:34.495580] Test:  [260/345]  eta: 0:00:07  loss: 0.7323 (0.7326)  time: 0.0905  data: 0.0001  max mem: 10917
[10:05:35.407442] Test:  [270/345]  eta: 0:00:06  loss: 0.7323 (0.7327)  time: 0.0909  data: 0.0001  max mem: 10917
[10:05:36.322758] Test:  [280/345]  eta: 0:00:05  loss: 0.7323 (0.7327)  time: 0.0913  data: 0.0001  max mem: 10917
[10:05:37.241329] Test:  [290/345]  eta: 0:00:04  loss: 0.7299 (0.7327)  time: 0.0916  data: 0.0001  max mem: 10917
[10:05:38.163865] Test:  [300/345]  eta: 0:00:03  loss: 0.7360 (0.7328)  time: 0.0920  data: 0.0001  max mem: 10917
[10:05:39.089511] Test:  [310/345]  eta: 0:00:03  loss: 0.7309 (0.7326)  time: 0.0924  data: 0.0001  max mem: 10917
[10:05:40.018623] Test:  [320/345]  eta: 0:00:02  loss: 0.7264 (0.7326)  time: 0.0927  data: 0.0001  max mem: 10917
[10:05:40.950926] Test:  [330/345]  eta: 0:00:01  loss: 0.7279 (0.7325)  time: 0.0930  data: 0.0001  max mem: 10917
[10:05:41.886915] Test:  [340/345]  eta: 0:00:00  loss: 0.7248 (0.7324)  time: 0.0934  data: 0.0001  max mem: 10917
[10:05:42.262975] Test:  [344/345]  eta: 0:00:00  loss: 0.7276 (0.7323)  time: 0.0935  data: 0.0001  max mem: 10917
[10:05:42.320115] Test: Total time: 0:00:30 (0.0885 s / it)
[10:05:52.789668] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8792 (0.8792)  time: 0.2224  data: 0.1425  max mem: 10917
[10:05:53.602877] Test:  [10/57]  eta: 0:00:04  loss: 0.9039 (0.9073)  time: 0.0941  data: 0.0130  max mem: 10917
[10:05:54.420998] Test:  [20/57]  eta: 0:00:03  loss: 0.9012 (0.8916)  time: 0.0815  data: 0.0001  max mem: 10917
[10:05:55.242447] Test:  [30/57]  eta: 0:00:02  loss: 0.7966 (0.8527)  time: 0.0819  data: 0.0001  max mem: 10917
[10:05:56.067042] Test:  [40/57]  eta: 0:00:01  loss: 0.7723 (0.8325)  time: 0.0823  data: 0.0001  max mem: 10917
[10:05:56.895991] Test:  [50/57]  eta: 0:00:00  loss: 0.7685 (0.8253)  time: 0.0826  data: 0.0001  max mem: 10917
[10:05:57.346418] Test:  [56/57]  eta: 0:00:00  loss: 0.7916 (0.8296)  time: 0.0804  data: 0.0001  max mem: 10917
[10:05:57.401959] Test: Total time: 0:00:04 (0.0848 s / it)
[10:05:59.142185] Dice score of the network on the train images: 0.812058, val images: 0.810984
[10:05:59.146366] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:05:59.540018] Epoch: [32]  [  0/345]  eta: 0:02:15  lr: 0.000082  loss: 0.7753 (0.7753)  time: 0.3917  data: 0.1410  max mem: 10917
[10:06:04.520214] Epoch: [32]  [ 20/345]  eta: 0:01:23  lr: 0.000081  loss: 0.7621 (0.7672)  time: 0.2490  data: 0.0001  max mem: 10917
[10:06:09.504014] Epoch: [32]  [ 40/345]  eta: 0:01:17  lr: 0.000081  loss: 0.7559 (0.7650)  time: 0.2491  data: 0.0001  max mem: 10917
[10:06:14.491358] Epoch: [32]  [ 60/345]  eta: 0:01:11  lr: 0.000081  loss: 0.7605 (0.7640)  time: 0.2493  data: 0.0001  max mem: 10917
[10:06:19.483038] Epoch: [32]  [ 80/345]  eta: 0:01:06  lr: 0.000080  loss: 0.7469 (0.7605)  time: 0.2495  data: 0.0001  max mem: 10917
[10:06:24.480392] Epoch: [32]  [100/345]  eta: 0:01:01  lr: 0.000080  loss: 0.7566 (0.7597)  time: 0.2498  data: 0.0000  max mem: 10917
[10:06:29.482065] Epoch: [32]  [120/345]  eta: 0:00:56  lr: 0.000080  loss: 0.7546 (0.7590)  time: 0.2500  data: 0.0000  max mem: 10917
[10:06:34.484154] Epoch: [32]  [140/345]  eta: 0:00:51  lr: 0.000079  loss: 0.7549 (0.7589)  time: 0.2501  data: 0.0001  max mem: 10917
[10:06:39.487635] Epoch: [32]  [160/345]  eta: 0:00:46  lr: 0.000079  loss: 0.7649 (0.7602)  time: 0.2501  data: 0.0001  max mem: 10917
[10:06:44.507487] Epoch: [32]  [180/345]  eta: 0:00:41  lr: 0.000079  loss: 0.7642 (0.7605)  time: 0.2510  data: 0.0001  max mem: 10917
[10:06:49.532029] Epoch: [32]  [200/345]  eta: 0:00:36  lr: 0.000078  loss: 0.7576 (0.7600)  time: 0.2512  data: 0.0000  max mem: 10917
[10:06:54.560842] Epoch: [32]  [220/345]  eta: 0:00:31  lr: 0.000078  loss: 0.7607 (0.7600)  time: 0.2514  data: 0.0001  max mem: 10917
[10:06:59.593521] Epoch: [32]  [240/345]  eta: 0:00:26  lr: 0.000077  loss: 0.7550 (0.7599)  time: 0.2516  data: 0.0000  max mem: 10917
[10:07:04.631806] Epoch: [32]  [260/345]  eta: 0:00:21  lr: 0.000077  loss: 0.7648 (0.7605)  time: 0.2519  data: 0.0000  max mem: 10917
[10:07:09.667204] Epoch: [32]  [280/345]  eta: 0:00:16  lr: 0.000077  loss: 0.7685 (0.7612)  time: 0.2517  data: 0.0000  max mem: 10917
[10:07:14.703140] Epoch: [32]  [300/345]  eta: 0:00:11  lr: 0.000076  loss: 0.7664 (0.7616)  time: 0.2518  data: 0.0000  max mem: 10917
[10:07:19.737236] Epoch: [32]  [320/345]  eta: 0:00:06  lr: 0.000076  loss: 0.7602 (0.7616)  time: 0.2517  data: 0.0001  max mem: 10917
[10:07:24.773583] Epoch: [32]  [340/345]  eta: 0:00:01  lr: 0.000076  loss: 0.7681 (0.7620)  time: 0.2518  data: 0.0001  max mem: 10917
[10:07:25.778687] Epoch: [32]  [344/345]  eta: 0:00:00  lr: 0.000076  loss: 0.7681 (0.7621)  time: 0.2516  data: 0.0001  max mem: 10917
[10:07:25.834787] Epoch: [32] Total time: 0:01:26 (0.2513 s / it)
[10:07:25.835325] Averaged stats: lr: 0.000076  loss: 0.7681 (0.7621)
[10:07:26.073257] Test:  [  0/345]  eta: 0:01:21  loss: 0.7134 (0.7134)  time: 0.2351  data: 0.1549  max mem: 10917
[10:07:26.903881] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7258 (0.7267)  time: 0.0968  data: 0.0151  max mem: 10917
[10:07:27.728720] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7258 (0.7267)  time: 0.0827  data: 0.0006  max mem: 10917
[10:07:28.554888] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7263 (0.7289)  time: 0.0825  data: 0.0001  max mem: 10917
[10:07:29.386493] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7282 (0.7300)  time: 0.0828  data: 0.0001  max mem: 10917
[10:07:30.220740] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7341 (0.7314)  time: 0.0832  data: 0.0001  max mem: 10917
[10:07:31.059585] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7259 (0.7306)  time: 0.0836  data: 0.0001  max mem: 10917
[10:07:31.901443] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7258 (0.7310)  time: 0.0840  data: 0.0001  max mem: 10917
[10:07:32.747318] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7325 (0.7315)  time: 0.0843  data: 0.0001  max mem: 10917
[10:07:33.595686] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7359 (0.7319)  time: 0.0847  data: 0.0001  max mem: 10917
[10:07:34.448257] Test:  [100/345]  eta: 0:00:20  loss: 0.7384 (0.7320)  time: 0.0850  data: 0.0001  max mem: 10917
[10:07:35.303360] Test:  [110/345]  eta: 0:00:20  loss: 0.7331 (0.7317)  time: 0.0853  data: 0.0001  max mem: 10917
[10:07:36.162361] Test:  [120/345]  eta: 0:00:19  loss: 0.7293 (0.7323)  time: 0.0857  data: 0.0001  max mem: 10917
[10:07:37.025298] Test:  [130/345]  eta: 0:00:18  loss: 0.7364 (0.7329)  time: 0.0860  data: 0.0001  max mem: 10917
[10:07:37.891102] Test:  [140/345]  eta: 0:00:17  loss: 0.7389 (0.7335)  time: 0.0864  data: 0.0001  max mem: 10917
[10:07:38.760841] Test:  [150/345]  eta: 0:00:16  loss: 0.7299 (0.7334)  time: 0.0867  data: 0.0001  max mem: 10917
[10:07:39.634338] Test:  [160/345]  eta: 0:00:15  loss: 0.7299 (0.7333)  time: 0.0871  data: 0.0001  max mem: 10917
[10:07:40.510565] Test:  [170/345]  eta: 0:00:15  loss: 0.7351 (0.7334)  time: 0.0874  data: 0.0001  max mem: 10917
[10:07:41.391182] Test:  [180/345]  eta: 0:00:14  loss: 0.7354 (0.7337)  time: 0.0878  data: 0.0001  max mem: 10917
[10:07:42.274252] Test:  [190/345]  eta: 0:00:13  loss: 0.7331 (0.7336)  time: 0.0881  data: 0.0001  max mem: 10917
[10:07:43.161720] Test:  [200/345]  eta: 0:00:12  loss: 0.7352 (0.7338)  time: 0.0885  data: 0.0001  max mem: 10917
[10:07:44.053060] Test:  [210/345]  eta: 0:00:11  loss: 0.7362 (0.7339)  time: 0.0889  data: 0.0001  max mem: 10917
[10:07:44.946527] Test:  [220/345]  eta: 0:00:10  loss: 0.7323 (0.7338)  time: 0.0892  data: 0.0001  max mem: 10917
[10:07:45.844984] Test:  [230/345]  eta: 0:00:09  loss: 0.7323 (0.7338)  time: 0.0895  data: 0.0001  max mem: 10917
[10:07:46.747471] Test:  [240/345]  eta: 0:00:09  loss: 0.7306 (0.7338)  time: 0.0900  data: 0.0001  max mem: 10917
[10:07:47.652572] Test:  [250/345]  eta: 0:00:08  loss: 0.7303 (0.7337)  time: 0.0903  data: 0.0001  max mem: 10917
[10:07:48.560328] Test:  [260/345]  eta: 0:00:07  loss: 0.7275 (0.7337)  time: 0.0906  data: 0.0001  max mem: 10917
[10:07:49.471620] Test:  [270/345]  eta: 0:00:06  loss: 0.7253 (0.7337)  time: 0.0909  data: 0.0001  max mem: 10917
[10:07:50.387265] Test:  [280/345]  eta: 0:00:05  loss: 0.7267 (0.7335)  time: 0.0913  data: 0.0001  max mem: 10917
[10:07:51.305760] Test:  [290/345]  eta: 0:00:04  loss: 0.7335 (0.7336)  time: 0.0917  data: 0.0001  max mem: 10917
[10:07:52.227819] Test:  [300/345]  eta: 0:00:03  loss: 0.7269 (0.7334)  time: 0.0920  data: 0.0001  max mem: 10917
[10:07:53.154332] Test:  [310/345]  eta: 0:00:03  loss: 0.7291 (0.7336)  time: 0.0924  data: 0.0001  max mem: 10917
[10:07:54.082777] Test:  [320/345]  eta: 0:00:02  loss: 0.7299 (0.7334)  time: 0.0927  data: 0.0001  max mem: 10917
[10:07:55.015322] Test:  [330/345]  eta: 0:00:01  loss: 0.7293 (0.7333)  time: 0.0930  data: 0.0001  max mem: 10917
[10:07:55.952077] Test:  [340/345]  eta: 0:00:00  loss: 0.7335 (0.7335)  time: 0.0934  data: 0.0001  max mem: 10917
[10:07:56.327723] Test:  [344/345]  eta: 0:00:00  loss: 0.7350 (0.7336)  time: 0.0935  data: 0.0001  max mem: 10917
[10:07:56.384164] Test: Total time: 0:00:30 (0.0885 s / it)
[10:08:06.795455] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8494 (0.8494)  time: 0.2214  data: 0.1418  max mem: 10917
[10:08:07.617742] Test:  [10/57]  eta: 0:00:04  loss: 0.8886 (0.9047)  time: 0.0948  data: 0.0137  max mem: 10917
[10:08:08.436068] Test:  [20/57]  eta: 0:00:03  loss: 0.9024 (0.8912)  time: 0.0820  data: 0.0005  max mem: 10917
[10:08:09.257706] Test:  [30/57]  eta: 0:00:02  loss: 0.7798 (0.8520)  time: 0.0819  data: 0.0001  max mem: 10917
[10:08:10.081859] Test:  [40/57]  eta: 0:00:01  loss: 0.7768 (0.8310)  time: 0.0822  data: 0.0001  max mem: 10917
[10:08:10.910980] Test:  [50/57]  eta: 0:00:00  loss: 0.7661 (0.8240)  time: 0.0826  data: 0.0001  max mem: 10917
[10:08:11.360454] Test:  [56/57]  eta: 0:00:00  loss: 0.7926 (0.8287)  time: 0.0804  data: 0.0001  max mem: 10917
[10:08:11.416525] Test: Total time: 0:00:04 (0.0850 s / it)
[10:08:13.193220] Dice score of the network on the train images: 0.804644, val images: 0.803975
[10:08:13.201964] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:08:13.593900] Epoch: [33]  [  0/345]  eta: 0:02:14  lr: 0.000075  loss: 0.7462 (0.7462)  time: 0.3911  data: 0.1400  max mem: 10917
[10:08:18.583795] Epoch: [33]  [ 20/345]  eta: 0:01:23  lr: 0.000075  loss: 0.7588 (0.7609)  time: 0.2495  data: 0.0001  max mem: 10917
[10:08:23.584203] Epoch: [33]  [ 40/345]  eta: 0:01:17  lr: 0.000075  loss: 0.7521 (0.7592)  time: 0.2500  data: 0.0001  max mem: 10917
[10:08:28.594158] Epoch: [33]  [ 60/345]  eta: 0:01:11  lr: 0.000074  loss: 0.7624 (0.7596)  time: 0.2505  data: 0.0001  max mem: 10917
[10:08:33.593229] Epoch: [33]  [ 80/345]  eta: 0:01:06  lr: 0.000074  loss: 0.7642 (0.7609)  time: 0.2499  data: 0.0001  max mem: 10917
[10:08:38.608268] Epoch: [33]  [100/345]  eta: 0:01:01  lr: 0.000074  loss: 0.7586 (0.7606)  time: 0.2507  data: 0.0001  max mem: 10917
[10:08:43.632047] Epoch: [33]  [120/345]  eta: 0:00:56  lr: 0.000073  loss: 0.7583 (0.7601)  time: 0.2512  data: 0.0001  max mem: 10917
[10:08:48.660247] Epoch: [33]  [140/345]  eta: 0:00:51  lr: 0.000073  loss: 0.7619 (0.7599)  time: 0.2514  data: 0.0000  max mem: 10917
[10:08:53.691197] Epoch: [33]  [160/345]  eta: 0:00:46  lr: 0.000073  loss: 0.7572 (0.7600)  time: 0.2515  data: 0.0000  max mem: 10917
[10:08:58.719049] Epoch: [33]  [180/345]  eta: 0:00:41  lr: 0.000072  loss: 0.7535 (0.7592)  time: 0.2513  data: 0.0001  max mem: 10917
[10:09:03.736283] Epoch: [33]  [200/345]  eta: 0:00:36  lr: 0.000072  loss: 0.7483 (0.7585)  time: 0.2508  data: 0.0001  max mem: 10917
[10:09:08.755923] Epoch: [33]  [220/345]  eta: 0:00:31  lr: 0.000071  loss: 0.7592 (0.7587)  time: 0.2509  data: 0.0001  max mem: 10917
[10:09:13.778153] Epoch: [33]  [240/345]  eta: 0:00:26  lr: 0.000071  loss: 0.7534 (0.7584)  time: 0.2511  data: 0.0001  max mem: 10917
[10:09:18.798487] Epoch: [33]  [260/345]  eta: 0:00:21  lr: 0.000071  loss: 0.7578 (0.7584)  time: 0.2510  data: 0.0001  max mem: 10917
[10:09:23.826615] Epoch: [33]  [280/345]  eta: 0:00:16  lr: 0.000070  loss: 0.7492 (0.7581)  time: 0.2514  data: 0.0001  max mem: 10917
[10:09:28.852479] Epoch: [33]  [300/345]  eta: 0:00:11  lr: 0.000070  loss: 0.7569 (0.7581)  time: 0.2513  data: 0.0001  max mem: 10917
[10:09:33.878743] Epoch: [33]  [320/345]  eta: 0:00:06  lr: 0.000070  loss: 0.7495 (0.7577)  time: 0.2513  data: 0.0001  max mem: 10917
[10:09:38.903638] Epoch: [33]  [340/345]  eta: 0:00:01  lr: 0.000069  loss: 0.7547 (0.7576)  time: 0.2512  data: 0.0001  max mem: 10917
[10:09:39.909887] Epoch: [33]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.7536 (0.7576)  time: 0.2513  data: 0.0001  max mem: 10917
[10:09:39.968178] Epoch: [33] Total time: 0:01:26 (0.2515 s / it)
[10:09:39.968573] Averaged stats: lr: 0.000069  loss: 0.7536 (0.7576)
[10:09:40.209254] Test:  [  0/345]  eta: 0:01:22  loss: 0.7378 (0.7378)  time: 0.2381  data: 0.1577  max mem: 10917
[10:09:41.029437] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7092 (0.7168)  time: 0.0961  data: 0.0144  max mem: 10917
[10:09:41.852626] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7130 (0.7166)  time: 0.0821  data: 0.0001  max mem: 10917
[10:09:42.680146] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7151 (0.7170)  time: 0.0825  data: 0.0001  max mem: 10917
[10:09:43.511259] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7189 (0.7183)  time: 0.0829  data: 0.0001  max mem: 10917
[10:09:44.345605] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7226 (0.7199)  time: 0.0832  data: 0.0001  max mem: 10917
[10:09:45.183331] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7226 (0.7204)  time: 0.0836  data: 0.0001  max mem: 10917
[10:09:46.024544] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7183 (0.7208)  time: 0.0839  data: 0.0001  max mem: 10917
[10:09:46.869111] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7183 (0.7212)  time: 0.0842  data: 0.0001  max mem: 10917
[10:09:47.717419] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7164 (0.7207)  time: 0.0846  data: 0.0001  max mem: 10917
[10:09:48.569271] Test:  [100/345]  eta: 0:00:20  loss: 0.7149 (0.7209)  time: 0.0850  data: 0.0001  max mem: 10917
[10:09:49.424741] Test:  [110/345]  eta: 0:00:20  loss: 0.7205 (0.7211)  time: 0.0853  data: 0.0001  max mem: 10917
[10:09:50.283388] Test:  [120/345]  eta: 0:00:19  loss: 0.7229 (0.7216)  time: 0.0857  data: 0.0001  max mem: 10917
[10:09:51.145699] Test:  [130/345]  eta: 0:00:18  loss: 0.7193 (0.7213)  time: 0.0860  data: 0.0001  max mem: 10917
[10:09:52.011292] Test:  [140/345]  eta: 0:00:17  loss: 0.7125 (0.7210)  time: 0.0863  data: 0.0001  max mem: 10917
[10:09:52.880831] Test:  [150/345]  eta: 0:00:16  loss: 0.7125 (0.7217)  time: 0.0867  data: 0.0001  max mem: 10917
[10:09:53.753479] Test:  [160/345]  eta: 0:00:15  loss: 0.7232 (0.7214)  time: 0.0871  data: 0.0001  max mem: 10917
[10:09:54.630077] Test:  [170/345]  eta: 0:00:14  loss: 0.7184 (0.7216)  time: 0.0874  data: 0.0001  max mem: 10917
[10:09:55.509241] Test:  [180/345]  eta: 0:00:14  loss: 0.7261 (0.7222)  time: 0.0877  data: 0.0001  max mem: 10917
[10:09:56.392385] Test:  [190/345]  eta: 0:00:13  loss: 0.7150 (0.7218)  time: 0.0881  data: 0.0001  max mem: 10917
[10:09:57.278672] Test:  [200/345]  eta: 0:00:12  loss: 0.7150 (0.7220)  time: 0.0884  data: 0.0001  max mem: 10917
[10:09:58.169298] Test:  [210/345]  eta: 0:00:11  loss: 0.7239 (0.7221)  time: 0.0888  data: 0.0001  max mem: 10917
[10:09:59.062197] Test:  [220/345]  eta: 0:00:10  loss: 0.7245 (0.7223)  time: 0.0891  data: 0.0001  max mem: 10917
[10:09:59.960129] Test:  [230/345]  eta: 0:00:09  loss: 0.7234 (0.7226)  time: 0.0895  data: 0.0001  max mem: 10917
[10:10:00.860309] Test:  [240/345]  eta: 0:00:09  loss: 0.7189 (0.7225)  time: 0.0899  data: 0.0001  max mem: 10917
[10:10:01.764167] Test:  [250/345]  eta: 0:00:08  loss: 0.7171 (0.7223)  time: 0.0902  data: 0.0001  max mem: 10917
[10:10:02.672324] Test:  [260/345]  eta: 0:00:07  loss: 0.7218 (0.7226)  time: 0.0906  data: 0.0001  max mem: 10917
[10:10:03.584615] Test:  [270/345]  eta: 0:00:06  loss: 0.7247 (0.7226)  time: 0.0910  data: 0.0001  max mem: 10917
[10:10:04.499435] Test:  [280/345]  eta: 0:00:05  loss: 0.7233 (0.7226)  time: 0.0913  data: 0.0001  max mem: 10917
[10:10:05.418464] Test:  [290/345]  eta: 0:00:04  loss: 0.7246 (0.7228)  time: 0.0916  data: 0.0001  max mem: 10917
[10:10:06.341008] Test:  [300/345]  eta: 0:00:03  loss: 0.7246 (0.7228)  time: 0.0920  data: 0.0001  max mem: 10917
[10:10:07.267404] Test:  [310/345]  eta: 0:00:03  loss: 0.7246 (0.7230)  time: 0.0924  data: 0.0001  max mem: 10917
[10:10:08.196752] Test:  [320/345]  eta: 0:00:02  loss: 0.7261 (0.7231)  time: 0.0927  data: 0.0001  max mem: 10917
[10:10:09.129631] Test:  [330/345]  eta: 0:00:01  loss: 0.7155 (0.7228)  time: 0.0931  data: 0.0001  max mem: 10917
[10:10:10.065379] Test:  [340/345]  eta: 0:00:00  loss: 0.7157 (0.7229)  time: 0.0934  data: 0.0001  max mem: 10917
[10:10:10.441115] Test:  [344/345]  eta: 0:00:00  loss: 0.7157 (0.7229)  time: 0.0935  data: 0.0001  max mem: 10917
[10:10:10.499023] Test: Total time: 0:00:30 (0.0885 s / it)
[10:10:20.983960] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8845 (0.8845)  time: 0.2263  data: 0.1466  max mem: 10917
[10:10:21.802113] Test:  [10/57]  eta: 0:00:04  loss: 0.9006 (0.9112)  time: 0.0949  data: 0.0138  max mem: 10917
[10:10:22.619479] Test:  [20/57]  eta: 0:00:03  loss: 0.9078 (0.8960)  time: 0.0817  data: 0.0003  max mem: 10917
[10:10:23.441111] Test:  [30/57]  eta: 0:00:02  loss: 0.8039 (0.8558)  time: 0.0819  data: 0.0001  max mem: 10917
[10:10:24.265441] Test:  [40/57]  eta: 0:00:01  loss: 0.7753 (0.8346)  time: 0.0822  data: 0.0001  max mem: 10917
[10:10:25.093928] Test:  [50/57]  eta: 0:00:00  loss: 0.7661 (0.8270)  time: 0.0826  data: 0.0001  max mem: 10917
[10:10:25.544526] Test:  [56/57]  eta: 0:00:00  loss: 0.7893 (0.8321)  time: 0.0804  data: 0.0001  max mem: 10917
[10:10:25.600152] Test: Total time: 0:00:04 (0.0850 s / it)
[10:10:27.355262] Dice score of the network on the train images: 0.821747, val images: 0.811121
[10:10:27.358293] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:10:27.754980] Epoch: [34]  [  0/345]  eta: 0:02:16  lr: 0.000069  loss: 0.7514 (0.7514)  time: 0.3958  data: 0.1434  max mem: 10917
[10:10:32.760185] Epoch: [34]  [ 20/345]  eta: 0:01:23  lr: 0.000069  loss: 0.7527 (0.7525)  time: 0.2502  data: 0.0000  max mem: 10917
[10:10:37.767970] Epoch: [34]  [ 40/345]  eta: 0:01:17  lr: 0.000068  loss: 0.7521 (0.7523)  time: 0.2504  data: 0.0001  max mem: 10917
[10:10:42.779968] Epoch: [34]  [ 60/345]  eta: 0:01:12  lr: 0.000068  loss: 0.7491 (0.7515)  time: 0.2506  data: 0.0001  max mem: 10917
[10:10:47.792241] Epoch: [34]  [ 80/345]  eta: 0:01:06  lr: 0.000068  loss: 0.7507 (0.7516)  time: 0.2506  data: 0.0000  max mem: 10917
[10:10:52.883791] Epoch: [34]  [100/345]  eta: 0:01:01  lr: 0.000067  loss: 0.7524 (0.7516)  time: 0.2545  data: 0.0000  max mem: 10917
[10:10:57.914650] Epoch: [34]  [120/345]  eta: 0:00:56  lr: 0.000067  loss: 0.7593 (0.7524)  time: 0.2515  data: 0.0001  max mem: 10917
[10:11:02.943107] Epoch: [34]  [140/345]  eta: 0:00:51  lr: 0.000066  loss: 0.7568 (0.7533)  time: 0.2514  data: 0.0001  max mem: 10917
[10:11:07.972934] Epoch: [34]  [160/345]  eta: 0:00:46  lr: 0.000066  loss: 0.7540 (0.7539)  time: 0.2515  data: 0.0000  max mem: 10917
[10:11:13.002638] Epoch: [34]  [180/345]  eta: 0:00:41  lr: 0.000066  loss: 0.7409 (0.7528)  time: 0.2515  data: 0.0000  max mem: 10917
[10:11:18.037874] Epoch: [34]  [200/345]  eta: 0:00:36  lr: 0.000065  loss: 0.7419 (0.7518)  time: 0.2517  data: 0.0001  max mem: 10917
[10:11:23.059558] Epoch: [34]  [220/345]  eta: 0:00:31  lr: 0.000065  loss: 0.7508 (0.7520)  time: 0.2510  data: 0.0001  max mem: 10917
[10:11:28.082589] Epoch: [34]  [240/345]  eta: 0:00:26  lr: 0.000064  loss: 0.7492 (0.7521)  time: 0.2511  data: 0.0001  max mem: 10917

[10:11:33.106972] Epoch: [34]  [260/345]  eta: 0:00:21  lr: 0.000064  loss: 0.7569 (0.7527)  time: 0.2512  data: 0.0001  max mem: 10917
[10:11:38.128778] Epoch: [34]  [280/345]  eta: 0:00:16  lr: 0.000064  loss: 0.7587 (0.7530)  time: 0.2511  data: 0.0001  max mem: 10917
[10:11:43.156015] Epoch: [34]  [300/345]  eta: 0:00:11  lr: 0.000063  loss: 0.7564 (0.7535)  time: 0.2513  data: 0.0001  max mem: 10917
[10:11:48.183070] Epoch: [34]  [320/345]  eta: 0:00:06  lr: 0.000063  loss: 0.7542 (0.7538)  time: 0.2513  data: 0.0001  max mem: 10917
[10:11:53.209964] Epoch: [34]  [340/345]  eta: 0:00:01  lr: 0.000063  loss: 0.7547 (0.7539)  time: 0.2513  data: 0.0001  max mem: 10917
[10:11:54.216748] Epoch: [34]  [344/345]  eta: 0:00:00  lr: 0.000063  loss: 0.7549 (0.7541)  time: 0.2514  data: 0.0001  max mem: 10917
[10:11:54.275851] Epoch: [34] Total time: 0:01:26 (0.2519 s / it)
[10:11:54.276246] Averaged stats: lr: 0.000063  loss: 0.7549 (0.7541)
[10:11:54.509062] Test:  [  0/345]  eta: 0:01:19  loss: 0.7230 (0.7230)  time: 0.2293  data: 0.1488  max mem: 10917
[10:11:55.344830] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7230 (0.7236)  time: 0.0967  data: 0.0150  max mem: 10917
[10:11:56.168813] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7239 (0.7235)  time: 0.0829  data: 0.0009  max mem: 10917
[10:11:56.995540] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7239 (0.7232)  time: 0.0825  data: 0.0001  max mem: 10917
[10:11:57.825895] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7211 (0.7225)  time: 0.0828  data: 0.0001  max mem: 10917
[10:11:58.659952] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7183 (0.7225)  time: 0.0832  data: 0.0001  max mem: 10917
[10:11:59.498029] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7233 (0.7233)  time: 0.0836  data: 0.0001  max mem: 10917
[10:12:00.340081] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7233 (0.7234)  time: 0.0840  data: 0.0001  max mem: 10917
[10:12:01.184732] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7223 (0.7235)  time: 0.0843  data: 0.0001  max mem: 10917
[10:12:02.032829] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7217 (0.7231)  time: 0.0846  data: 0.0001  max mem: 10917
[10:12:02.884879] Test:  [100/345]  eta: 0:00:20  loss: 0.7142 (0.7222)  time: 0.0850  data: 0.0001  max mem: 10917
[10:12:03.740775] Test:  [110/345]  eta: 0:00:20  loss: 0.7142 (0.7219)  time: 0.0853  data: 0.0001  max mem: 10917
[10:12:04.600808] Test:  [120/345]  eta: 0:00:19  loss: 0.7189 (0.7218)  time: 0.0857  data: 0.0001  max mem: 10917
[10:12:05.462941] Test:  [130/345]  eta: 0:00:18  loss: 0.7211 (0.7218)  time: 0.0861  data: 0.0001  max mem: 10917
[10:12:06.328577] Test:  [140/345]  eta: 0:00:17  loss: 0.7159 (0.7212)  time: 0.0863  data: 0.0001  max mem: 10917
[10:12:07.197587] Test:  [150/345]  eta: 0:00:16  loss: 0.7165 (0.7211)  time: 0.0867  data: 0.0001  max mem: 10917
[10:12:08.070076] Test:  [160/345]  eta: 0:00:15  loss: 0.7189 (0.7210)  time: 0.0870  data: 0.0001  max mem: 10917
[10:12:08.946426] Test:  [170/345]  eta: 0:00:15  loss: 0.7209 (0.7212)  time: 0.0874  data: 0.0001  max mem: 10917
[10:12:09.826901] Test:  [180/345]  eta: 0:00:14  loss: 0.7282 (0.7217)  time: 0.0878  data: 0.0001  max mem: 10917
[10:12:10.711207] Test:  [190/345]  eta: 0:00:13  loss: 0.7282 (0.7218)  time: 0.0882  data: 0.0001  max mem: 10917
[10:12:11.598018] Test:  [200/345]  eta: 0:00:12  loss: 0.7259 (0.7222)  time: 0.0885  data: 0.0001  max mem: 10917
[10:12:12.488780] Test:  [210/345]  eta: 0:00:11  loss: 0.7230 (0.7222)  time: 0.0888  data: 0.0001  max mem: 10917
[10:12:13.383367] Test:  [220/345]  eta: 0:00:10  loss: 0.7224 (0.7224)  time: 0.0892  data: 0.0001  max mem: 10917
[10:12:14.280908] Test:  [230/345]  eta: 0:00:09  loss: 0.7251 (0.7226)  time: 0.0896  data: 0.0001  max mem: 10917
[10:12:15.182367] Test:  [240/345]  eta: 0:00:09  loss: 0.7244 (0.7227)  time: 0.0899  data: 0.0001  max mem: 10917
[10:12:16.086337] Test:  [250/345]  eta: 0:00:08  loss: 0.7200 (0.7225)  time: 0.0902  data: 0.0001  max mem: 10917
[10:12:16.995595] Test:  [260/345]  eta: 0:00:07  loss: 0.7216 (0.7228)  time: 0.0906  data: 0.0001  max mem: 10917
[10:12:17.909190] Test:  [270/345]  eta: 0:00:06  loss: 0.7265 (0.7229)  time: 0.0911  data: 0.0001  max mem: 10917
[10:12:18.824652] Test:  [280/345]  eta: 0:00:05  loss: 0.7225 (0.7227)  time: 0.0914  data: 0.0001  max mem: 10917
[10:12:19.743610] Test:  [290/345]  eta: 0:00:04  loss: 0.7159 (0.7227)  time: 0.0917  data: 0.0001  max mem: 10917
[10:12:20.665693] Test:  [300/345]  eta: 0:00:03  loss: 0.7276 (0.7228)  time: 0.0920  data: 0.0001  max mem: 10917
[10:12:21.591728] Test:  [310/345]  eta: 0:00:03  loss: 0.7241 (0.7229)  time: 0.0924  data: 0.0001  max mem: 10917
[10:12:22.521579] Test:  [320/345]  eta: 0:00:02  loss: 0.7218 (0.7229)  time: 0.0927  data: 0.0001  max mem: 10917
[10:12:23.453822] Test:  [330/345]  eta: 0:00:01  loss: 0.7202 (0.7229)  time: 0.0931  data: 0.0001  max mem: 10917
[10:12:24.389226] Test:  [340/345]  eta: 0:00:00  loss: 0.7257 (0.7230)  time: 0.0933  data: 0.0001  max mem: 10917
[10:12:24.765925] Test:  [344/345]  eta: 0:00:00  loss: 0.7229 (0.7230)  time: 0.0935  data: 0.0001  max mem: 10917
[10:12:24.822017] Test: Total time: 0:00:30 (0.0885 s / it)
[10:12:35.323640] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8926 (0.8926)  time: 0.2191  data: 0.1392  max mem: 10917
[10:12:36.136163] Test:  [10/57]  eta: 0:00:04  loss: 0.9021 (0.9133)  time: 0.0937  data: 0.0127  max mem: 10917
[10:12:36.954917] Test:  [20/57]  eta: 0:00:03  loss: 0.9072 (0.8988)  time: 0.0815  data: 0.0001  max mem: 10917
[10:12:37.776414] Test:  [30/57]  eta: 0:00:02  loss: 0.8003 (0.8575)  time: 0.0819  data: 0.0001  max mem: 10917
[10:12:38.601555] Test:  [40/57]  eta: 0:00:01  loss: 0.7751 (0.8361)  time: 0.0823  data: 0.0001  max mem: 10917
[10:12:39.431474] Test:  [50/57]  eta: 0:00:00  loss: 0.7674 (0.8277)  time: 0.0827  data: 0.0001  max mem: 10917
[10:12:39.881972] Test:  [56/57]  eta: 0:00:00  loss: 0.7939 (0.8328)  time: 0.0805  data: 0.0001  max mem: 10917
[10:12:39.938356] Test: Total time: 0:00:04 (0.0848 s / it)
[10:12:41.704431] Dice score of the network on the train images: 0.820147, val images: 0.806735
[10:12:41.707505] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:12:42.102162] Epoch: [35]  [  0/345]  eta: 0:02:15  lr: 0.000063  loss: 0.7484 (0.7484)  time: 0.3939  data: 0.1419  max mem: 10917
[10:12:47.092359] Epoch: [35]  [ 20/345]  eta: 0:01:23  lr: 0.000062  loss: 0.7598 (0.7585)  time: 0.2495  data: 0.0001  max mem: 10917
[10:12:52.084163] Epoch: [35]  [ 40/345]  eta: 0:01:17  lr: 0.000062  loss: 0.7604 (0.7582)  time: 0.2496  data: 0.0001  max mem: 10917
[10:12:57.084085] Epoch: [35]  [ 60/345]  eta: 0:01:11  lr: 0.000061  loss: 0.7497 (0.7569)  time: 0.2500  data: 0.0000  max mem: 10917
[10:13:02.084640] Epoch: [35]  [ 80/345]  eta: 0:01:06  lr: 0.000061  loss: 0.7459 (0.7557)  time: 0.2500  data: 0.0001  max mem: 10917
[10:13:07.083725] Epoch: [35]  [100/345]  eta: 0:01:01  lr: 0.000061  loss: 0.7454 (0.7537)  time: 0.2499  data: 0.0000  max mem: 10917
[10:13:12.092930] Epoch: [35]  [120/345]  eta: 0:00:56  lr: 0.000060  loss: 0.7561 (0.7546)  time: 0.2504  data: 0.0000  max mem: 10917
[10:13:17.104557] Epoch: [35]  [140/345]  eta: 0:00:51  lr: 0.000060  loss: 0.7508 (0.7539)  time: 0.2505  data: 0.0000  max mem: 10917
[10:13:22.115930] Epoch: [35]  [160/345]  eta: 0:00:46  lr: 0.000059  loss: 0.7588 (0.7544)  time: 0.2505  data: 0.0000  max mem: 10917
[10:13:27.133872] Epoch: [35]  [180/345]  eta: 0:00:41  lr: 0.000059  loss: 0.7508 (0.7541)  time: 0.2509  data: 0.0001  max mem: 10917
[10:13:32.167648] Epoch: [35]  [200/345]  eta: 0:00:36  lr: 0.000059  loss: 0.7537 (0.7539)  time: 0.2516  data: 0.0001  max mem: 10917
[10:13:37.204999] Epoch: [35]  [220/345]  eta: 0:00:31  lr: 0.000058  loss: 0.7526 (0.7540)  time: 0.2518  data: 0.0001  max mem: 10917
[10:13:42.242126] Epoch: [35]  [240/345]  eta: 0:00:26  lr: 0.000058  loss: 0.7469 (0.7539)  time: 0.2518  data: 0.0001  max mem: 10917

[10:13:47.283663] Epoch: [35]  [260/345]  eta: 0:00:21  lr: 0.000058  loss: 0.7520 (0.7538)  time: 0.2520  data: 0.0001  max mem: 10917
[10:13:52.327752] Epoch: [35]  [280/345]  eta: 0:00:16  lr: 0.000057  loss: 0.7562 (0.7539)  time: 0.2522  data: 0.0001  max mem: 10917
[10:13:57.372206] Epoch: [35]  [300/345]  eta: 0:00:11  lr: 0.000057  loss: 0.7538 (0.7538)  time: 0.2522  data: 0.0001  max mem: 10917
[10:14:02.405663] Epoch: [35]  [320/345]  eta: 0:00:06  lr: 0.000056  loss: 0.7474 (0.7533)  time: 0.2516  data: 0.0001  max mem: 10917
[10:14:07.435009] Epoch: [35]  [340/345]  eta: 0:00:01  lr: 0.000056  loss: 0.7505 (0.7534)  time: 0.2514  data: 0.0001  max mem: 10917
[10:14:08.440597] Epoch: [35]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.7493 (0.7533)  time: 0.2514  data: 0.0001  max mem: 10917
[10:14:08.496976] Epoch: [35] Total time: 0:01:26 (0.2516 s / it)
[10:14:08.497365] Averaged stats: lr: 0.000056  loss: 0.7493 (0.7533)
[10:14:08.730327] Test:  [  0/345]  eta: 0:01:19  loss: 0.7006 (0.7006)  time: 0.2300  data: 0.1500  max mem: 10917
[10:14:09.550371] Test:  [ 10/345]  eta: 0:00:31  loss: 0.7195 (0.7227)  time: 0.0954  data: 0.0137  max mem: 10917
[10:14:10.374327] Test:  [ 20/345]  eta: 0:00:28  loss: 0.7212 (0.7242)  time: 0.0821  data: 0.0001  max mem: 10917
[10:14:11.201539] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7202 (0.7228)  time: 0.0825  data: 0.0001  max mem: 10917
[10:14:12.031504] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7152 (0.7219)  time: 0.0828  data: 0.0001  max mem: 10917
[10:14:12.866047] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7161 (0.7211)  time: 0.0832  data: 0.0001  max mem: 10917
[10:14:13.703751] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7181 (0.7211)  time: 0.0836  data: 0.0001  max mem: 10917
[10:14:14.544247] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7181 (0.7216)  time: 0.0839  data: 0.0001  max mem: 10917
[10:14:15.389803] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7218 (0.7218)  time: 0.0843  data: 0.0001  max mem: 10917
[10:14:16.238241] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7201 (0.7217)  time: 0.0847  data: 0.0001  max mem: 10917
[10:14:17.089492] Test:  [100/345]  eta: 0:00:20  loss: 0.7174 (0.7217)  time: 0.0849  data: 0.0001  max mem: 10917
[10:14:17.945304] Test:  [110/345]  eta: 0:00:19  loss: 0.7166 (0.7212)  time: 0.0853  data: 0.0001  max mem: 10917
[10:14:18.804643] Test:  [120/345]  eta: 0:00:19  loss: 0.7187 (0.7211)  time: 0.0857  data: 0.0001  max mem: 10917
[10:14:19.668114] Test:  [130/345]  eta: 0:00:18  loss: 0.7197 (0.7211)  time: 0.0861  data: 0.0001  max mem: 10917
[10:14:20.534138] Test:  [140/345]  eta: 0:00:17  loss: 0.7197 (0.7211)  time: 0.0864  data: 0.0001  max mem: 10917
[10:14:21.404178] Test:  [150/345]  eta: 0:00:16  loss: 0.7182 (0.7207)  time: 0.0868  data: 0.0001  max mem: 10917
[10:14:22.276265] Test:  [160/345]  eta: 0:00:15  loss: 0.7130 (0.7204)  time: 0.0871  data: 0.0001  max mem: 10917
[10:14:23.153735] Test:  [170/345]  eta: 0:00:14  loss: 0.7194 (0.7205)  time: 0.0874  data: 0.0001  max mem: 10917
[10:14:24.034115] Test:  [180/345]  eta: 0:00:14  loss: 0.7194 (0.7206)  time: 0.0878  data: 0.0001  max mem: 10917
[10:14:24.918149] Test:  [190/345]  eta: 0:00:13  loss: 0.7162 (0.7204)  time: 0.0882  data: 0.0001  max mem: 10917
[10:14:25.805002] Test:  [200/345]  eta: 0:00:12  loss: 0.7180 (0.7204)  time: 0.0885  data: 0.0001  max mem: 10917
[10:14:26.696085] Test:  [210/345]  eta: 0:00:11  loss: 0.7184 (0.7203)  time: 0.0889  data: 0.0001  max mem: 10917
[10:14:27.589538] Test:  [220/345]  eta: 0:00:10  loss: 0.7135 (0.7200)  time: 0.0892  data: 0.0001  max mem: 10917
[10:14:28.487765] Test:  [230/345]  eta: 0:00:09  loss: 0.7155 (0.7202)  time: 0.0895  data: 0.0001  max mem: 10917
[10:14:29.389057] Test:  [240/345]  eta: 0:00:09  loss: 0.7291 (0.7205)  time: 0.0899  data: 0.0001  max mem: 10917
[10:14:30.293438] Test:  [250/345]  eta: 0:00:08  loss: 0.7237 (0.7206)  time: 0.0902  data: 0.0001  max mem: 10917
[10:14:31.201650] Test:  [260/345]  eta: 0:00:07  loss: 0.7225 (0.7206)  time: 0.0906  data: 0.0001  max mem: 10917
[10:14:32.113356] Test:  [270/345]  eta: 0:00:06  loss: 0.7221 (0.7206)  time: 0.0909  data: 0.0001  max mem: 10917
[10:14:33.028643] Test:  [280/345]  eta: 0:00:05  loss: 0.7184 (0.7206)  time: 0.0913  data: 0.0001  max mem: 10917
[10:14:33.947725] Test:  [290/345]  eta: 0:00:04  loss: 0.7172 (0.7204)  time: 0.0917  data: 0.0001  max mem: 10917
[10:14:34.869583] Test:  [300/345]  eta: 0:00:03  loss: 0.7152 (0.7202)  time: 0.0920  data: 0.0001  max mem: 10917
[10:14:35.794504] Test:  [310/345]  eta: 0:00:03  loss: 0.7163 (0.7204)  time: 0.0923  data: 0.0001  max mem: 10917
[10:14:36.723576] Test:  [320/345]  eta: 0:00:02  loss: 0.7164 (0.7203)  time: 0.0927  data: 0.0001  max mem: 10917
[10:14:37.655890] Test:  [330/345]  eta: 0:00:01  loss: 0.7143 (0.7203)  time: 0.0930  data: 0.0001  max mem: 10917
[10:14:38.591703] Test:  [340/345]  eta: 0:00:00  loss: 0.7143 (0.7201)  time: 0.0934  data: 0.0001  max mem: 10917
[10:14:38.967887] Test:  [344/345]  eta: 0:00:00  loss: 0.7143 (0.7201)  time: 0.0935  data: 0.0001  max mem: 10917
[10:14:39.024750] Test: Total time: 0:00:30 (0.0885 s / it)
[10:14:49.519702] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8707 (0.8707)  time: 0.2182  data: 0.1385  max mem: 10917
[10:14:50.332322] Test:  [10/57]  eta: 0:00:04  loss: 0.8930 (0.9015)  time: 0.0936  data: 0.0127  max mem: 10917
[10:14:51.150006] Test:  [20/57]  eta: 0:00:03  loss: 0.8908 (0.8883)  time: 0.0814  data: 0.0001  max mem: 10917
[10:14:51.971715] Test:  [30/57]  eta: 0:00:02  loss: 0.7855 (0.8487)  time: 0.0819  data: 0.0001  max mem: 10917
[10:14:52.796375] Test:  [40/57]  eta: 0:00:01  loss: 0.7741 (0.8276)  time: 0.0823  data: 0.0001  max mem: 10917
[10:14:53.625846] Test:  [50/57]  eta: 0:00:00  loss: 0.7605 (0.8202)  time: 0.0827  data: 0.0001  max mem: 10917
[10:14:54.075564] Test:  [56/57]  eta: 0:00:00  loss: 0.7865 (0.8258)  time: 0.0804  data: 0.0001  max mem: 10917
[10:14:54.133952] Test: Total time: 0:00:04 (0.0848 s / it)
[10:14:55.875559] Dice score of the network on the train images: 0.817971, val images: 0.810249
[10:14:55.878579] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:14:56.278147] Epoch: [36]  [  0/345]  eta: 0:02:17  lr: 0.000056  loss: 0.7334 (0.7334)  time: 0.3988  data: 0.1473  max mem: 10917
[10:15:01.269686] Epoch: [36]  [ 20/345]  eta: 0:01:23  lr: 0.000056  loss: 0.7498 (0.7478)  time: 0.2495  data: 0.0001  max mem: 10917
[10:15:06.271604] Epoch: [36]  [ 40/345]  eta: 0:01:17  lr: 0.000055  loss: 0.7451 (0.7490)  time: 0.2500  data: 0.0001  max mem: 10917
[10:15:11.284791] Epoch: [36]  [ 60/345]  eta: 0:01:11  lr: 0.000055  loss: 0.7526 (0.7502)  time: 0.2506  data: 0.0001  max mem: 10917
[10:15:16.302344] Epoch: [36]  [ 80/345]  eta: 0:01:06  lr: 0.000054  loss: 0.7523 (0.7515)  time: 0.2508  data: 0.0001  max mem: 10917
[10:15:21.321098] Epoch: [36]  [100/345]  eta: 0:01:01  lr: 0.000054  loss: 0.7551 (0.7527)  time: 0.2509  data: 0.0001  max mem: 10917
[10:15:26.347762] Epoch: [36]  [120/345]  eta: 0:00:56  lr: 0.000054  loss: 0.7551 (0.7535)  time: 0.2513  data: 0.0001  max mem: 10917
[10:15:31.361086] Epoch: [36]  [140/345]  eta: 0:00:51  lr: 0.000053  loss: 0.7391 (0.7513)  time: 0.2506  data: 0.0001  max mem: 10917
[10:15:36.370004] Epoch: [36]  [160/345]  eta: 0:00:46  lr: 0.000053  loss: 0.7447 (0.7509)  time: 0.2504  data: 0.0000  max mem: 10917
[10:15:41.387314] Epoch: [36]  [180/345]  eta: 0:00:41  lr: 0.000053  loss: 0.7429 (0.7499)  time: 0.2508  data: 0.0001  max mem: 10917
[10:15:46.402700] Epoch: [36]  [200/345]  eta: 0:00:36  lr: 0.000052  loss: 0.7481 (0.7499)  time: 0.2507  data: 0.0001  max mem: 10917

[10:15:51.427446] Epoch: [36]  [220/345]  eta: 0:00:31  lr: 0.000052  loss: 0.7459 (0.7499)  time: 0.2512  data: 0.0001  max mem: 10917
[10:15:56.456081] Epoch: [36]  [240/345]  eta: 0:00:26  lr: 0.000051  loss: 0.7534 (0.7506)  time: 0.2514  data: 0.0001  max mem: 10917
[10:16:01.480681] Epoch: [36]  [260/345]  eta: 0:00:21  lr: 0.000051  loss: 0.7527 (0.7509)  time: 0.2512  data: 0.0000  max mem: 10917
[10:16:06.518977] Epoch: [36]  [280/345]  eta: 0:00:16  lr: 0.000051  loss: 0.7435 (0.7508)  time: 0.2519  data: 0.0001  max mem: 10917
[10:16:11.548926] Epoch: [36]  [300/345]  eta: 0:00:11  lr: 0.000050  loss: 0.7482 (0.7513)  time: 0.2515  data: 0.0001  max mem: 10917
[10:16:16.575186] Epoch: [36]  [320/345]  eta: 0:00:06  lr: 0.000050  loss: 0.7462 (0.7511)  time: 0.2513  data: 0.0000  max mem: 10917
[10:16:21.602273] Epoch: [36]  [340/345]  eta: 0:00:01  lr: 0.000050  loss: 0.7417 (0.7506)  time: 0.2513  data: 0.0001  max mem: 10917
[10:16:22.609841] Epoch: [36]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.7420 (0.7506)  time: 0.2514  data: 0.0001  max mem: 10917
[10:16:22.667250] Epoch: [36] Total time: 0:01:26 (0.2516 s / it)
[10:16:22.667581] Averaged stats: lr: 0.000050  loss: 0.7420 (0.7506)
[10:16:22.902626] Test:  [  0/345]  eta: 0:01:20  loss: 0.7127 (0.7127)  time: 0.2322  data: 0.1519  max mem: 10917
[10:16:23.741515] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7173 (0.7175)  time: 0.0973  data: 0.0157  max mem: 10917
[10:16:24.574867] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7175 (0.7180)  time: 0.0835  data: 0.0016  max mem: 10917
[10:16:25.401171] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7159 (0.7181)  time: 0.0829  data: 0.0006  max mem: 10917
[10:16:26.232690] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7159 (0.7175)  time: 0.0828  data: 0.0001  max mem: 10917
[10:16:27.066870] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7177 (0.7177)  time: 0.0832  data: 0.0001  max mem: 10917
[10:16:27.905203] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7130 (0.7172)  time: 0.0836  data: 0.0001  max mem: 10917
[10:16:28.747134] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7138 (0.7170)  time: 0.0840  data: 0.0001  max mem: 10917
[10:16:29.592483] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7158 (0.7172)  time: 0.0843  data: 0.0001  max mem: 10917
[10:16:30.440874] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7158 (0.7171)  time: 0.0846  data: 0.0001  max mem: 10917
[10:16:31.293539] Test:  [100/345]  eta: 0:00:20  loss: 0.7181 (0.7174)  time: 0.0850  data: 0.0001  max mem: 10917
[10:16:32.149364] Test:  [110/345]  eta: 0:00:20  loss: 0.7217 (0.7173)  time: 0.0854  data: 0.0001  max mem: 10917
[10:16:33.009073] Test:  [120/345]  eta: 0:00:19  loss: 0.7217 (0.7180)  time: 0.0857  data: 0.0001  max mem: 10917
[10:16:33.872258] Test:  [130/345]  eta: 0:00:18  loss: 0.7186 (0.7179)  time: 0.0861  data: 0.0001  max mem: 10917
[10:16:34.739130] Test:  [140/345]  eta: 0:00:17  loss: 0.7122 (0.7171)  time: 0.0865  data: 0.0001  max mem: 10917
[10:16:35.608247] Test:  [150/345]  eta: 0:00:16  loss: 0.7125 (0.7172)  time: 0.0868  data: 0.0001  max mem: 10917
[10:16:36.481321] Test:  [160/345]  eta: 0:00:15  loss: 0.7159 (0.7172)  time: 0.0871  data: 0.0001  max mem: 10917
[10:16:37.358022] Test:  [170/345]  eta: 0:00:15  loss: 0.7159 (0.7171)  time: 0.0874  data: 0.0001  max mem: 10917
[10:16:38.238146] Test:  [180/345]  eta: 0:00:14  loss: 0.7166 (0.7175)  time: 0.0878  data: 0.0001  max mem: 10917
[10:16:39.121986] Test:  [190/345]  eta: 0:00:13  loss: 0.7193 (0.7174)  time: 0.0882  data: 0.0001  max mem: 10917
[10:16:40.009414] Test:  [200/345]  eta: 0:00:12  loss: 0.7193 (0.7176)  time: 0.0885  data: 0.0001  max mem: 10917
[10:16:40.900123] Test:  [210/345]  eta: 0:00:11  loss: 0.7184 (0.7177)  time: 0.0889  data: 0.0001  max mem: 10917
[10:16:41.793370] Test:  [220/345]  eta: 0:00:10  loss: 0.7179 (0.7177)  time: 0.0892  data: 0.0001  max mem: 10917
[10:16:42.691203] Test:  [230/345]  eta: 0:00:09  loss: 0.7133 (0.7177)  time: 0.0895  data: 0.0001  max mem: 10917
[10:16:43.593287] Test:  [240/345]  eta: 0:00:09  loss: 0.7118 (0.7175)  time: 0.0899  data: 0.0001  max mem: 10917
[10:16:44.497483] Test:  [250/345]  eta: 0:00:08  loss: 0.7111 (0.7175)  time: 0.0903  data: 0.0001  max mem: 10917
[10:16:45.406139] Test:  [260/345]  eta: 0:00:07  loss: 0.7166 (0.7177)  time: 0.0906  data: 0.0001  max mem: 10917
[10:16:46.317789] Test:  [270/345]  eta: 0:00:06  loss: 0.7148 (0.7174)  time: 0.0910  data: 0.0001  max mem: 10917
[10:16:47.232964] Test:  [280/345]  eta: 0:00:05  loss: 0.7146 (0.7175)  time: 0.0913  data: 0.0001  max mem: 10917
[10:16:48.151843] Test:  [290/345]  eta: 0:00:04  loss: 0.7094 (0.7171)  time: 0.0917  data: 0.0001  max mem: 10917
[10:16:49.074237] Test:  [300/345]  eta: 0:00:03  loss: 0.7067 (0.7168)  time: 0.0920  data: 0.0001  max mem: 10917
[10:16:50.000016] Test:  [310/345]  eta: 0:00:03  loss: 0.7095 (0.7167)  time: 0.0924  data: 0.0001  max mem: 10917
[10:16:50.929048] Test:  [320/345]  eta: 0:00:02  loss: 0.7140 (0.7167)  time: 0.0927  data: 0.0001  max mem: 10917
[10:16:51.861487] Test:  [330/345]  eta: 0:00:01  loss: 0.7193 (0.7168)  time: 0.0930  data: 0.0001  max mem: 10917
[10:16:52.797064] Test:  [340/345]  eta: 0:00:00  loss: 0.7095 (0.7166)  time: 0.0934  data: 0.0001  max mem: 10917
[10:16:53.173062] Test:  [344/345]  eta: 0:00:00  loss: 0.7060 (0.7166)  time: 0.0935  data: 0.0001  max mem: 10917
[10:16:53.229743] Test: Total time: 0:00:30 (0.0886 s / it)
[10:17:03.617264] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8839 (0.8839)  time: 0.2173  data: 0.1375  max mem: 10917
[10:17:04.444386] Test:  [10/57]  eta: 0:00:04  loss: 0.9103 (0.9190)  time: 0.0949  data: 0.0139  max mem: 10917
[10:17:05.262725] Test:  [20/57]  eta: 0:00:03  loss: 0.9060 (0.9005)  time: 0.0822  data: 0.0008  max mem: 10917
[10:17:06.083980] Test:  [30/57]  eta: 0:00:02  loss: 0.8012 (0.8594)  time: 0.0819  data: 0.0001  max mem: 10917
[10:17:06.908185] Test:  [40/57]  eta: 0:00:01  loss: 0.7786 (0.8383)  time: 0.0822  data: 0.0001  max mem: 10917
[10:17:07.736902] Test:  [50/57]  eta: 0:00:00  loss: 0.7649 (0.8299)  time: 0.0826  data: 0.0001  max mem: 10917
[10:17:08.187366] Test:  [56/57]  eta: 0:00:00  loss: 0.8046 (0.8357)  time: 0.0804  data: 0.0001  max mem: 10917
[10:17:08.242360] Test: Total time: 0:00:04 (0.0850 s / it)
[10:17:10.038140] Dice score of the network on the train images: 0.821312, val images: 0.809354
[10:17:10.041226] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:17:10.434813] Epoch: [37]  [  0/345]  eta: 0:02:15  lr: 0.000050  loss: 0.7218 (0.7218)  time: 0.3928  data: 0.1413  max mem: 10917
[10:17:15.424269] Epoch: [37]  [ 20/345]  eta: 0:01:23  lr: 0.000049  loss: 0.7503 (0.7500)  time: 0.2494  data: 0.0001  max mem: 10917
[10:17:20.418239] Epoch: [37]  [ 40/345]  eta: 0:01:17  lr: 0.000049  loss: 0.7467 (0.7487)  time: 0.2497  data: 0.0000  max mem: 10917
[10:17:25.417361] Epoch: [37]  [ 60/345]  eta: 0:01:11  lr: 0.000048  loss: 0.7502 (0.7495)  time: 0.2499  data: 0.0001  max mem: 10917
[10:17:30.417312] Epoch: [37]  [ 80/345]  eta: 0:01:06  lr: 0.000048  loss: 0.7438 (0.7492)  time: 0.2500  data: 0.0000  max mem: 10917
[10:17:35.421037] Epoch: [37]  [100/345]  eta: 0:01:01  lr: 0.000048  loss: 0.7497 (0.7492)  time: 0.2501  data: 0.0001  max mem: 10917
[10:17:40.428327] Epoch: [37]  [120/345]  eta: 0:00:56  lr: 0.000047  loss: 0.7466 (0.7490)  time: 0.2503  data: 0.0001  max mem: 10917
[10:17:45.441266] Epoch: [37]  [140/345]  eta: 0:00:51  lr: 0.000047  loss: 0.7492 (0.7495)  time: 0.2506  data: 0.0001  max mem: 10917
[10:17:50.459793] Epoch: [37]  [160/345]  eta: 0:00:46  lr: 0.000047  loss: 0.7428 (0.7493)  time: 0.2509  data: 0.0001  max mem: 10917
[10:17:55.482219] Epoch: [37]  [180/345]  eta: 0:00:41  lr: 0.000046  loss: 0.7452 (0.7494)  time: 0.2511  data: 0.0001  max mem: 10917
[10:18:00.496036] Epoch: [37]  [200/345]  eta: 0:00:36  lr: 0.000046  loss: 0.7485 (0.7495)  time: 0.2507  data: 0.0001  max mem: 10917
[10:18:05.515926] Epoch: [37]  [220/345]  eta: 0:00:31  lr: 0.000045  loss: 0.7491 (0.7497)  time: 0.2510  data: 0.0001  max mem: 10917
[10:18:10.545675] Epoch: [37]  [240/345]  eta: 0:00:26  lr: 0.000045  loss: 0.7502 (0.7496)  time: 0.2514  data: 0.0001  max mem: 10917

[10:18:15.584012] Epoch: [37]  [260/345]  eta: 0:00:21  lr: 0.000045  loss: 0.7495 (0.7498)  time: 0.2519  data: 0.0000  max mem: 10917
[10:18:20.623601] Epoch: [37]  [280/345]  eta: 0:00:16  lr: 0.000044  loss: 0.7509 (0.7500)  time: 0.2519  data: 0.0001  max mem: 10917
[10:18:25.663857] Epoch: [37]  [300/345]  eta: 0:00:11  lr: 0.000044  loss: 0.7568 (0.7507)  time: 0.2520  data: 0.0000  max mem: 10917
[10:18:30.706773] Epoch: [37]  [320/345]  eta: 0:00:06  lr: 0.000044  loss: 0.7532 (0.7509)  time: 0.2521  data: 0.0000  max mem: 10917
[10:18:35.822385] Epoch: [37]  [340/345]  eta: 0:00:01  lr: 0.000043  loss: 0.7475 (0.7508)  time: 0.2557  data: 0.0001  max mem: 10917
[10:18:36.831693] Epoch: [37]  [344/345]  eta: 0:00:00  lr: 0.000043  loss: 0.7489 (0.7509)  time: 0.2558  data: 0.0001  max mem: 10917
[10:18:36.893365] Epoch: [37] Total time: 0:01:26 (0.2517 s / it)
[10:18:36.893794] Averaged stats: lr: 0.000043  loss: 0.7489 (0.7509)
[10:18:37.135503] Test:  [  0/345]  eta: 0:01:22  loss: 0.7288 (0.7288)  time: 0.2383  data: 0.1579  max mem: 10917
[10:18:37.955768] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7235 (0.7248)  time: 0.0962  data: 0.0144  max mem: 10917
[10:18:38.779175] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7183 (0.7198)  time: 0.0821  data: 0.0001  max mem: 10917
[10:18:39.606753] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7129 (0.7186)  time: 0.0825  data: 0.0001  max mem: 10917
[10:18:40.437536] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7186 (0.7190)  time: 0.0829  data: 0.0001  max mem: 10917
[10:18:41.271574] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7175 (0.7191)  time: 0.0832  data: 0.0001  max mem: 10917
[10:18:42.109867] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7229 (0.7192)  time: 0.0836  data: 0.0001  max mem: 10917
[10:18:42.950716] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7205 (0.7190)  time: 0.0839  data: 0.0001  max mem: 10917
[10:18:43.794590] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7205 (0.7200)  time: 0.0842  data: 0.0001  max mem: 10917
[10:18:44.642942] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7174 (0.7193)  time: 0.0846  data: 0.0001  max mem: 10917
[10:18:45.494907] Test:  [100/345]  eta: 0:00:20  loss: 0.7104 (0.7185)  time: 0.0850  data: 0.0001  max mem: 10917
[10:18:46.349969] Test:  [110/345]  eta: 0:00:20  loss: 0.7115 (0.7184)  time: 0.0853  data: 0.0001  max mem: 10917
[10:18:47.208931] Test:  [120/345]  eta: 0:00:19  loss: 0.7175 (0.7182)  time: 0.0857  data: 0.0001  max mem: 10917
[10:18:48.070717] Test:  [130/345]  eta: 0:00:18  loss: 0.7197 (0.7182)  time: 0.0860  data: 0.0001  max mem: 10917
[10:18:48.936334] Test:  [140/345]  eta: 0:00:17  loss: 0.7155 (0.7182)  time: 0.0863  data: 0.0001  max mem: 10917
[10:18:49.806236] Test:  [150/345]  eta: 0:00:16  loss: 0.7183 (0.7188)  time: 0.0867  data: 0.0001  max mem: 10917
[10:18:50.680286] Test:  [160/345]  eta: 0:00:15  loss: 0.7246 (0.7189)  time: 0.0871  data: 0.0001  max mem: 10917
[10:18:51.557295] Test:  [170/345]  eta: 0:00:14  loss: 0.7122 (0.7187)  time: 0.0875  data: 0.0001  max mem: 10917
[10:18:52.437498] Test:  [180/345]  eta: 0:00:14  loss: 0.7101 (0.7186)  time: 0.0878  data: 0.0001  max mem: 10917
[10:18:53.320099] Test:  [190/345]  eta: 0:00:13  loss: 0.7108 (0.7187)  time: 0.0881  data: 0.0001  max mem: 10917
[10:18:54.206691] Test:  [200/345]  eta: 0:00:12  loss: 0.7117 (0.7186)  time: 0.0884  data: 0.0001  max mem: 10917
[10:18:55.097335] Test:  [210/345]  eta: 0:00:11  loss: 0.7149 (0.7190)  time: 0.0888  data: 0.0001  max mem: 10917
[10:18:55.990864] Test:  [220/345]  eta: 0:00:10  loss: 0.7166 (0.7190)  time: 0.0892  data: 0.0001  max mem: 10917
[10:18:56.888282] Test:  [230/345]  eta: 0:00:09  loss: 0.7152 (0.7188)  time: 0.0895  data: 0.0001  max mem: 10917
[10:18:57.790480] Test:  [240/345]  eta: 0:00:09  loss: 0.7229 (0.7191)  time: 0.0899  data: 0.0001  max mem: 10917
[10:18:58.694766] Test:  [250/345]  eta: 0:00:08  loss: 0.7231 (0.7189)  time: 0.0903  data: 0.0001  max mem: 10917
[10:18:59.603230] Test:  [260/345]  eta: 0:00:07  loss: 0.7161 (0.7187)  time: 0.0906  data: 0.0001  max mem: 10917
[10:19:00.514933] Test:  [270/345]  eta: 0:00:06  loss: 0.7161 (0.7188)  time: 0.0910  data: 0.0001  max mem: 10917
[10:19:01.430001] Test:  [280/345]  eta: 0:00:05  loss: 0.7158 (0.7187)  time: 0.0913  data: 0.0001  max mem: 10917
[10:19:02.348768] Test:  [290/345]  eta: 0:00:04  loss: 0.7134 (0.7188)  time: 0.0916  data: 0.0001  max mem: 10917
[10:19:03.271040] Test:  [300/345]  eta: 0:00:03  loss: 0.7140 (0.7189)  time: 0.0920  data: 0.0001  max mem: 10917
[10:19:04.196242] Test:  [310/345]  eta: 0:00:03  loss: 0.7220 (0.7191)  time: 0.0923  data: 0.0001  max mem: 10917
[10:19:05.125910] Test:  [320/345]  eta: 0:00:02  loss: 0.7247 (0.7194)  time: 0.0927  data: 0.0001  max mem: 10917
[10:19:06.058611] Test:  [330/345]  eta: 0:00:01  loss: 0.7201 (0.7194)  time: 0.0931  data: 0.0001  max mem: 10917
[10:19:06.994583] Test:  [340/345]  eta: 0:00:00  loss: 0.7142 (0.7194)  time: 0.0934  data: 0.0001  max mem: 10917
[10:19:07.369922] Test:  [344/345]  eta: 0:00:00  loss: 0.7142 (0.7195)  time: 0.0935  data: 0.0001  max mem: 10917
[10:19:07.425845] Test: Total time: 0:00:30 (0.0885 s / it)
[10:19:17.775388] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8764 (0.8764)  time: 0.2173  data: 0.1376  max mem: 10917
[10:19:18.589313] Test:  [10/57]  eta: 0:00:04  loss: 0.9095 (0.9187)  time: 0.0937  data: 0.0126  max mem: 10917
[10:19:19.406037] Test:  [20/57]  eta: 0:00:03  loss: 0.8909 (0.8996)  time: 0.0815  data: 0.0001  max mem: 10917
[10:19:20.227352] Test:  [30/57]  eta: 0:00:02  loss: 0.8008 (0.8600)  time: 0.0819  data: 0.0001  max mem: 10917
[10:19:21.052461] Test:  [40/57]  eta: 0:00:01  loss: 0.7836 (0.8391)  time: 0.0823  data: 0.0001  max mem: 10917
[10:19:21.880868] Test:  [50/57]  eta: 0:00:00  loss: 0.7836 (0.8310)  time: 0.0826  data: 0.0001  max mem: 10917
[10:19:22.331369] Test:  [56/57]  eta: 0:00:00  loss: 0.8040 (0.8357)  time: 0.0804  data: 0.0001  max mem: 10917
[10:19:22.387532] Test: Total time: 0:00:04 (0.0847 s / it)
[10:19:24.122794] Dice score of the network on the train images: 0.818474, val images: 0.808404
[10:19:24.125968] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:19:24.517034] Epoch: [38]  [  0/345]  eta: 0:02:14  lr: 0.000043  loss: 0.7372 (0.7372)  time: 0.3902  data: 0.1389  max mem: 10917
[10:19:29.500520] Epoch: [38]  [ 20/345]  eta: 0:01:23  lr: 0.000043  loss: 0.7528 (0.7507)  time: 0.2491  data: 0.0001  max mem: 10917
[10:19:34.498340] Epoch: [38]  [ 40/345]  eta: 0:01:17  lr: 0.000042  loss: 0.7400 (0.7470)  time: 0.2498  data: 0.0001  max mem: 10917
[10:19:39.504838] Epoch: [38]  [ 60/345]  eta: 0:01:11  lr: 0.000042  loss: 0.7523 (0.7498)  time: 0.2503  data: 0.0000  max mem: 10917
[10:19:44.515683] Epoch: [38]  [ 80/345]  eta: 0:01:06  lr: 0.000042  loss: 0.7461 (0.7495)  time: 0.2505  data: 0.0001  max mem: 10917
[10:19:49.530503] Epoch: [38]  [100/345]  eta: 0:01:01  lr: 0.000041  loss: 0.7468 (0.7496)  time: 0.2507  data: 0.0001  max mem: 10917
[10:19:54.549624] Epoch: [38]  [120/345]  eta: 0:00:56  lr: 0.000041  loss: 0.7515 (0.7501)  time: 0.2509  data: 0.0001  max mem: 10917
[10:19:59.576178] Epoch: [38]  [140/345]  eta: 0:00:51  lr: 0.000041  loss: 0.7467 (0.7496)  time: 0.2513  data: 0.0001  max mem: 10917
[10:20:04.605888] Epoch: [38]  [160/345]  eta: 0:00:46  lr: 0.000040  loss: 0.7444 (0.7492)  time: 0.2514  data: 0.0001  max mem: 10917
[10:20:09.632857] Epoch: [38]  [180/345]  eta: 0:00:41  lr: 0.000040  loss: 0.7446 (0.7496)  time: 0.2513  data: 0.0000  max mem: 10917
[10:20:14.658243] Epoch: [38]  [200/345]  eta: 0:00:36  lr: 0.000040  loss: 0.7486 (0.7495)  time: 0.2512  data: 0.0001  max mem: 10917
[10:20:19.690527] Epoch: [38]  [220/345]  eta: 0:00:31  lr: 0.000039  loss: 0.7510 (0.7494)  time: 0.2516  data: 0.0000  max mem: 10917
[10:20:24.722359] Epoch: [38]  [240/345]  eta: 0:00:26  lr: 0.000039  loss: 0.7473 (0.7491)  time: 0.2515  data: 0.0001  max mem: 10917

[10:20:29.753554] Epoch: [38]  [260/345]  eta: 0:00:21  lr: 0.000039  loss: 0.7416 (0.7486)  time: 0.2515  data: 0.0000  max mem: 10917
[10:20:34.788877] Epoch: [38]  [280/345]  eta: 0:00:16  lr: 0.000038  loss: 0.7431 (0.7484)  time: 0.2517  data: 0.0000  max mem: 10917
[10:20:39.826576] Epoch: [38]  [300/345]  eta: 0:00:11  lr: 0.000038  loss: 0.7387 (0.7480)  time: 0.2518  data: 0.0000  max mem: 10917
[10:20:44.862144] Epoch: [38]  [320/345]  eta: 0:00:06  lr: 0.000038  loss: 0.7485 (0.7482)  time: 0.2517  data: 0.0000  max mem: 10917
[10:20:49.902895] Epoch: [38]  [340/345]  eta: 0:00:01  lr: 0.000037  loss: 0.7418 (0.7480)  time: 0.2520  data: 0.0000  max mem: 10917
[10:20:50.912048] Epoch: [38]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 0.7418 (0.7479)  time: 0.2521  data: 0.0001  max mem: 10917
[10:20:50.967805] Epoch: [38] Total time: 0:01:26 (0.2517 s / it)
[10:20:50.968060] Averaged stats: lr: 0.000037  loss: 0.7418 (0.7479)
[10:20:51.199313] Test:  [  0/345]  eta: 0:01:18  loss: 0.7094 (0.7094)  time: 0.2274  data: 0.1474  max mem: 10917
[10:20:52.028853] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7096 (0.7124)  time: 0.0960  data: 0.0143  max mem: 10917
[10:20:52.851809] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7096 (0.7128)  time: 0.0825  data: 0.0006  max mem: 10917
[10:20:53.680019] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7133 (0.7145)  time: 0.0825  data: 0.0001  max mem: 10917
[10:20:54.510648] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7148 (0.7147)  time: 0.0829  data: 0.0001  max mem: 10917
[10:20:55.344702] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7075 (0.7147)  time: 0.0832  data: 0.0001  max mem: 10917
[10:20:56.183757] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7213 (0.7161)  time: 0.0836  data: 0.0001  max mem: 10917
[10:20:57.025092] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7132 (0.7161)  time: 0.0840  data: 0.0001  max mem: 10917
[10:20:57.869463] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7113 (0.7152)  time: 0.0842  data: 0.0001  max mem: 10917
[10:20:58.717804] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7072 (0.7148)  time: 0.0846  data: 0.0001  max mem: 10917
[10:20:59.570665] Test:  [100/345]  eta: 0:00:20  loss: 0.7104 (0.7146)  time: 0.0850  data: 0.0001  max mem: 10917
[10:21:00.426524] Test:  [110/345]  eta: 0:00:20  loss: 0.7120 (0.7145)  time: 0.0854  data: 0.0001  max mem: 10917
[10:21:01.285961] Test:  [120/345]  eta: 0:00:19  loss: 0.7130 (0.7146)  time: 0.0857  data: 0.0001  max mem: 10917
[10:21:02.148825] Test:  [130/345]  eta: 0:00:18  loss: 0.7142 (0.7148)  time: 0.0861  data: 0.0001  max mem: 10917
[10:21:03.014267] Test:  [140/345]  eta: 0:00:17  loss: 0.7154 (0.7148)  time: 0.0864  data: 0.0001  max mem: 10917
[10:21:03.884833] Test:  [150/345]  eta: 0:00:16  loss: 0.7170 (0.7155)  time: 0.0867  data: 0.0001  max mem: 10917
[10:21:04.757870] Test:  [160/345]  eta: 0:00:15  loss: 0.7169 (0.7155)  time: 0.0871  data: 0.0001  max mem: 10917
[10:21:05.634948] Test:  [170/345]  eta: 0:00:14  loss: 0.7118 (0.7153)  time: 0.0875  data: 0.0001  max mem: 10917
[10:21:06.515219] Test:  [180/345]  eta: 0:00:14  loss: 0.7079 (0.7153)  time: 0.0878  data: 0.0001  max mem: 10917
[10:21:07.397999] Test:  [190/345]  eta: 0:00:13  loss: 0.7196 (0.7154)  time: 0.0881  data: 0.0001  max mem: 10917
[10:21:08.284894] Test:  [200/345]  eta: 0:00:12  loss: 0.7172 (0.7153)  time: 0.0884  data: 0.0001  max mem: 10917
[10:21:09.175361] Test:  [210/345]  eta: 0:00:11  loss: 0.7091 (0.7150)  time: 0.0888  data: 0.0001  max mem: 10917
[10:21:10.069028] Test:  [220/345]  eta: 0:00:10  loss: 0.7160 (0.7154)  time: 0.0892  data: 0.0001  max mem: 10917
[10:21:10.966619] Test:  [230/345]  eta: 0:00:09  loss: 0.7161 (0.7151)  time: 0.0895  data: 0.0001  max mem: 10917
[10:21:11.868854] Test:  [240/345]  eta: 0:00:09  loss: 0.7151 (0.7151)  time: 0.0899  data: 0.0001  max mem: 10917
[10:21:12.773089] Test:  [250/345]  eta: 0:00:08  loss: 0.7131 (0.7150)  time: 0.0903  data: 0.0001  max mem: 10917
[10:21:13.681229] Test:  [260/345]  eta: 0:00:07  loss: 0.7139 (0.7152)  time: 0.0906  data: 0.0001  max mem: 10917
[10:21:14.593026] Test:  [270/345]  eta: 0:00:06  loss: 0.7156 (0.7152)  time: 0.0909  data: 0.0001  max mem: 10917
[10:21:15.508907] Test:  [280/345]  eta: 0:00:05  loss: 0.7132 (0.7151)  time: 0.0913  data: 0.0001  max mem: 10917
[10:21:16.427757] Test:  [290/345]  eta: 0:00:04  loss: 0.7122 (0.7151)  time: 0.0917  data: 0.0001  max mem: 10917
[10:21:17.350487] Test:  [300/345]  eta: 0:00:03  loss: 0.7139 (0.7151)  time: 0.0920  data: 0.0001  max mem: 10917
[10:21:18.275595] Test:  [310/345]  eta: 0:00:03  loss: 0.7164 (0.7151)  time: 0.0923  data: 0.0001  max mem: 10917
[10:21:19.204203] Test:  [320/345]  eta: 0:00:02  loss: 0.7163 (0.7150)  time: 0.0926  data: 0.0001  max mem: 10917
[10:21:20.136638] Test:  [330/345]  eta: 0:00:01  loss: 0.7181 (0.7151)  time: 0.0930  data: 0.0001  max mem: 10917
[10:21:21.072513] Test:  [340/345]  eta: 0:00:00  loss: 0.7146 (0.7151)  time: 0.0934  data: 0.0001  max mem: 10917
[10:21:21.448037] Test:  [344/345]  eta: 0:00:00  loss: 0.7162 (0.7150)  time: 0.0935  data: 0.0001  max mem: 10917
[10:21:21.503956] Test: Total time: 0:00:30 (0.0885 s / it)
[10:21:31.859479] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8777 (0.8777)  time: 0.2165  data: 0.1365  max mem: 10917
[10:21:32.674031] Test:  [10/57]  eta: 0:00:04  loss: 0.9144 (0.9180)  time: 0.0937  data: 0.0125  max mem: 10917
[10:21:33.491498] Test:  [20/57]  eta: 0:00:03  loss: 0.9104 (0.9040)  time: 0.0815  data: 0.0001  max mem: 10917
[10:21:34.312483] Test:  [30/57]  eta: 0:00:02  loss: 0.7971 (0.8634)  time: 0.0819  data: 0.0001  max mem: 10917
[10:21:35.137198] Test:  [40/57]  eta: 0:00:01  loss: 0.7870 (0.8425)  time: 0.0822  data: 0.0001  max mem: 10917
[10:21:35.966220] Test:  [50/57]  eta: 0:00:00  loss: 0.7823 (0.8347)  time: 0.0826  data: 0.0001  max mem: 10917
[10:21:36.416229] Test:  [56/57]  eta: 0:00:00  loss: 0.8006 (0.8401)  time: 0.0804  data: 0.0001  max mem: 10917
[10:21:36.472067] Test: Total time: 0:00:04 (0.0847 s / it)
[10:21:38.212722] Dice score of the network on the train images: 0.827156, val images: 0.804715
[10:21:38.216403] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:21:38.610031] Epoch: [39]  [  0/345]  eta: 0:02:15  lr: 0.000037  loss: 0.7576 (0.7576)  time: 0.3925  data: 0.1401  max mem: 10917
[10:21:43.610105] Epoch: [39]  [ 20/345]  eta: 0:01:23  lr: 0.000037  loss: 0.7455 (0.7479)  time: 0.2499  data: 0.0001  max mem: 10917
[10:21:48.612940] Epoch: [39]  [ 40/345]  eta: 0:01:17  lr: 0.000036  loss: 0.7441 (0.7464)  time: 0.2501  data: 0.0001  max mem: 10917
[10:21:53.624069] Epoch: [39]  [ 60/345]  eta: 0:01:11  lr: 0.000036  loss: 0.7414 (0.7453)  time: 0.2505  data: 0.0001  max mem: 10917
[10:21:58.640993] Epoch: [39]  [ 80/345]  eta: 0:01:06  lr: 0.000036  loss: 0.7485 (0.7457)  time: 0.2508  data: 0.0001  max mem: 10917
[10:22:03.660513] Epoch: [39]  [100/345]  eta: 0:01:01  lr: 0.000035  loss: 0.7463 (0.7464)  time: 0.2509  data: 0.0000  max mem: 10917
[10:22:08.682016] Epoch: [39]  [120/345]  eta: 0:00:56  lr: 0.000035  loss: 0.7440 (0.7464)  time: 0.2510  data: 0.0000  max mem: 10917
[10:22:13.710193] Epoch: [39]  [140/345]  eta: 0:00:51  lr: 0.000035  loss: 0.7387 (0.7459)  time: 0.2514  data: 0.0000  max mem: 10917
[10:22:18.739835] Epoch: [39]  [160/345]  eta: 0:00:46  lr: 0.000034  loss: 0.7437 (0.7461)  time: 0.2514  data: 0.0000  max mem: 10917
[10:22:23.771891] Epoch: [39]  [180/345]  eta: 0:00:41  lr: 0.000034  loss: 0.7467 (0.7464)  time: 0.2516  data: 0.0000  max mem: 10917
[10:22:28.806110] Epoch: [39]  [200/345]  eta: 0:00:36  lr: 0.000034  loss: 0.7439 (0.7462)  time: 0.2517  data: 0.0000  max mem: 10917
[10:22:33.838571] Epoch: [39]  [220/345]  eta: 0:00:31  lr: 0.000033  loss: 0.7419 (0.7459)  time: 0.2516  data: 0.0000  max mem: 10917
[10:22:38.875724] Epoch: [39]  [240/345]  eta: 0:00:26  lr: 0.000033  loss: 0.7474 (0.7460)  time: 0.2518  data: 0.0000  max mem: 10917
[10:22:43.914192] Epoch: [39]  [260/345]  eta: 0:00:21  lr: 0.000033  loss: 0.7383 (0.7454)  time: 0.2519  data: 0.0000  max mem: 10917
[10:22:48.958334] Epoch: [39]  [280/345]  eta: 0:00:16  lr: 0.000032  loss: 0.7467 (0.7453)  time: 0.2522  data: 0.0000  max mem: 10917
[10:22:53.997200] Epoch: [39]  [300/345]  eta: 0:00:11  lr: 0.000032  loss: 0.7451 (0.7454)  time: 0.2519  data: 0.0001  max mem: 10917
[10:22:59.041903] Epoch: [39]  [320/345]  eta: 0:00:06  lr: 0.000032  loss: 0.7451 (0.7455)  time: 0.2522  data: 0.0000  max mem: 10917
[10:23:04.086474] Epoch: [39]  [340/345]  eta: 0:00:01  lr: 0.000031  loss: 0.7478 (0.7456)  time: 0.2522  data: 0.0000  max mem: 10917
[10:23:05.096530] Epoch: [39]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 0.7433 (0.7455)  time: 0.2522  data: 0.0001  max mem: 10917
[10:23:05.153098] Epoch: [39] Total time: 0:01:26 (0.2520 s / it)
[10:23:05.153603] Averaged stats: lr: 0.000031  loss: 0.7433 (0.7455)
[10:23:05.388195] Test:  [  0/345]  eta: 0:01:19  loss: 0.7225 (0.7225)  time: 0.2306  data: 0.1504  max mem: 10917
[10:23:06.213689] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7221 (0.7215)  time: 0.0959  data: 0.0143  max mem: 10917
[10:23:07.036363] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7163 (0.7184)  time: 0.0823  data: 0.0004  max mem: 10917
[10:23:07.864742] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7102 (0.7174)  time: 0.0825  data: 0.0001  max mem: 10917
[10:23:08.694665] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7087 (0.7165)  time: 0.0829  data: 0.0001  max mem: 10917
[10:23:09.527878] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7166 (0.7171)  time: 0.0831  data: 0.0001  max mem: 10917
[10:23:10.365629] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7171 (0.7171)  time: 0.0835  data: 0.0001  max mem: 10917
[10:23:11.206818] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7129 (0.7167)  time: 0.0839  data: 0.0001  max mem: 10917
[10:23:12.050691] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7129 (0.7170)  time: 0.0842  data: 0.0001  max mem: 10917
[10:23:12.898668] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7154 (0.7166)  time: 0.0845  data: 0.0001  max mem: 10917
[10:23:13.750471] Test:  [100/345]  eta: 0:00:20  loss: 0.7148 (0.7163)  time: 0.0849  data: 0.0001  max mem: 10917
[10:23:14.605611] Test:  [110/345]  eta: 0:00:19  loss: 0.7055 (0.7151)  time: 0.0853  data: 0.0001  max mem: 10917
[10:23:15.464895] Test:  [120/345]  eta: 0:00:19  loss: 0.7020 (0.7143)  time: 0.0857  data: 0.0001  max mem: 10917
[10:23:16.326923] Test:  [130/345]  eta: 0:00:18  loss: 0.7033 (0.7137)  time: 0.0860  data: 0.0001  max mem: 10917
[10:23:17.193002] Test:  [140/345]  eta: 0:00:17  loss: 0.7138 (0.7142)  time: 0.0864  data: 0.0001  max mem: 10917
[10:23:18.062468] Test:  [150/345]  eta: 0:00:16  loss: 0.7191 (0.7145)  time: 0.0867  data: 0.0001  max mem: 10917
[10:23:18.934965] Test:  [160/345]  eta: 0:00:15  loss: 0.7145 (0.7143)  time: 0.0870  data: 0.0001  max mem: 10917
[10:23:19.811042] Test:  [170/345]  eta: 0:00:14  loss: 0.7131 (0.7143)  time: 0.0874  data: 0.0001  max mem: 10917
[10:23:20.690732] Test:  [180/345]  eta: 0:00:14  loss: 0.7131 (0.7142)  time: 0.0877  data: 0.0001  max mem: 10917
[10:23:21.573483] Test:  [190/345]  eta: 0:00:13  loss: 0.7098 (0.7139)  time: 0.0881  data: 0.0001  max mem: 10917
[10:23:22.459984] Test:  [200/345]  eta: 0:00:12  loss: 0.7073 (0.7138)  time: 0.0884  data: 0.0001  max mem: 10917
[10:23:23.350508] Test:  [210/345]  eta: 0:00:11  loss: 0.7093 (0.7135)  time: 0.0888  data: 0.0001  max mem: 10917
[10:23:24.244028] Test:  [220/345]  eta: 0:00:10  loss: 0.7085 (0.7135)  time: 0.0892  data: 0.0001  max mem: 10917
[10:23:25.141665] Test:  [230/345]  eta: 0:00:09  loss: 0.7078 (0.7134)  time: 0.0895  data: 0.0001  max mem: 10917
[10:23:26.042818] Test:  [240/345]  eta: 0:00:09  loss: 0.7139 (0.7136)  time: 0.0899  data: 0.0001  max mem: 10917
[10:23:26.946895] Test:  [250/345]  eta: 0:00:08  loss: 0.7139 (0.7134)  time: 0.0902  data: 0.0001  max mem: 10917
[10:23:27.854769] Test:  [260/345]  eta: 0:00:07  loss: 0.7077 (0.7132)  time: 0.0905  data: 0.0001  max mem: 10917
[10:23:28.766274] Test:  [270/345]  eta: 0:00:06  loss: 0.7070 (0.7132)  time: 0.0909  data: 0.0001  max mem: 10917
[10:23:29.680907] Test:  [280/345]  eta: 0:00:05  loss: 0.7075 (0.7131)  time: 0.0913  data: 0.0001  max mem: 10917
[10:23:30.599734] Test:  [290/345]  eta: 0:00:04  loss: 0.7117 (0.7132)  time: 0.0916  data: 0.0001  max mem: 10917
[10:23:31.522001] Test:  [300/345]  eta: 0:00:03  loss: 0.7125 (0.7132)  time: 0.0920  data: 0.0001  max mem: 10917
[10:23:32.447712] Test:  [310/345]  eta: 0:00:03  loss: 0.7143 (0.7133)  time: 0.0924  data: 0.0001  max mem: 10917
[10:23:33.375194] Test:  [320/345]  eta: 0:00:02  loss: 0.7162 (0.7135)  time: 0.0926  data: 0.0001  max mem: 10917
[10:23:34.307872] Test:  [330/345]  eta: 0:00:01  loss: 0.7143 (0.7136)  time: 0.0930  data: 0.0001  max mem: 10917
[10:23:35.242724] Test:  [340/345]  eta: 0:00:00  loss: 0.7084 (0.7134)  time: 0.0933  data: 0.0001  max mem: 10917
[10:23:35.618428] Test:  [344/345]  eta: 0:00:00  loss: 0.7086 (0.7135)  time: 0.0935  data: 0.0001  max mem: 10917
[10:23:35.675433] Test: Total time: 0:00:30 (0.0885 s / it)
[10:23:46.110166] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8770 (0.8770)  time: 0.2220  data: 0.1421  max mem: 10917
[10:23:46.922101] Test:  [10/57]  eta: 0:00:04  loss: 0.9107 (0.9162)  time: 0.0939  data: 0.0130  max mem: 10917
[10:23:47.738846] Test:  [20/57]  eta: 0:00:03  loss: 0.9072 (0.8998)  time: 0.0814  data: 0.0001  max mem: 10917
[10:23:48.559442] Test:  [30/57]  eta: 0:00:02  loss: 0.7961 (0.8602)  time: 0.0818  data: 0.0001  max mem: 10917
[10:23:49.384453] Test:  [40/57]  eta: 0:00:01  loss: 0.7847 (0.8398)  time: 0.0822  data: 0.0001  max mem: 10917
[10:23:50.212982] Test:  [50/57]  eta: 0:00:00  loss: 0.7812 (0.8317)  time: 0.0826  data: 0.0001  max mem: 10917
[10:23:50.663025] Test:  [56/57]  eta: 0:00:00  loss: 0.7987 (0.8373)  time: 0.0804  data: 0.0001  max mem: 10917
[10:23:50.720794] Test: Total time: 0:00:04 (0.0848 s / it)
[10:23:52.506249] Dice score of the network on the train images: 0.826735, val images: 0.806471
[10:23:52.509839] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:23:52.908787] Epoch: [40]  [  0/345]  eta: 0:02:17  lr: 0.000031  loss: 0.7353 (0.7353)  time: 0.3978  data: 0.1455  max mem: 10917
[10:23:57.914589] Epoch: [40]  [ 20/345]  eta: 0:01:23  lr: 0.000031  loss: 0.7407 (0.7428)  time: 0.2502  data: 0.0001  max mem: 10917
[10:24:02.924471] Epoch: [40]  [ 40/345]  eta: 0:01:17  lr: 0.000031  loss: 0.7409 (0.7425)  time: 0.2504  data: 0.0001  max mem: 10917
[10:24:07.939397] Epoch: [40]  [ 60/345]  eta: 0:01:12  lr: 0.000030  loss: 0.7460 (0.7433)  time: 0.2507  data: 0.0001  max mem: 10917
[10:24:12.956919] Epoch: [40]  [ 80/345]  eta: 0:01:06  lr: 0.000030  loss: 0.7370 (0.7430)  time: 0.2508  data: 0.0001  max mem: 10917
[10:24:17.977080] Epoch: [40]  [100/345]  eta: 0:01:01  lr: 0.000030  loss: 0.7444 (0.7432)  time: 0.2510  data: 0.0001  max mem: 10917
[10:24:22.998961] Epoch: [40]  [120/345]  eta: 0:00:56  lr: 0.000029  loss: 0.7368 (0.7426)  time: 0.2510  data: 0.0001  max mem: 10917
[10:24:28.031859] Epoch: [40]  [140/345]  eta: 0:00:51  lr: 0.000029  loss: 0.7438 (0.7426)  time: 0.2516  data: 0.0001  max mem: 10917
[10:24:33.059539] Epoch: [40]  [160/345]  eta: 0:00:46  lr: 0.000029  loss: 0.7408 (0.7427)  time: 0.2513  data: 0.0001  max mem: 10917

[10:24:38.089526] Epoch: [40]  [180/345]  eta: 0:00:41  lr: 0.000028  loss: 0.7413 (0.7426)  time: 0.2515  data: 0.0001  max mem: 10917
[10:24:43.126911] Epoch: [40]  [200/345]  eta: 0:00:36  lr: 0.000028  loss: 0.7427 (0.7428)  time: 0.2518  data: 0.0001  max mem: 10917
[10:24:48.161107] Epoch: [40]  [220/345]  eta: 0:00:31  lr: 0.000028  loss: 0.7392 (0.7431)  time: 0.2517  data: 0.0001  max mem: 10917
[10:24:53.195924] Epoch: [40]  [240/345]  eta: 0:00:26  lr: 0.000027  loss: 0.7444 (0.7433)  time: 0.2517  data: 0.0001  max mem: 10917
[10:24:58.241767] Epoch: [40]  [260/345]  eta: 0:00:21  lr: 0.000027  loss: 0.7353 (0.7430)  time: 0.2522  data: 0.0001  max mem: 10917
[10:25:03.287713] Epoch: [40]  [280/345]  eta: 0:00:16  lr: 0.000027  loss: 0.7428 (0.7433)  time: 0.2523  data: 0.0001  max mem: 10917
[10:25:08.332186] Epoch: [40]  [300/345]  eta: 0:00:11  lr: 0.000026  loss: 0.7354 (0.7430)  time: 0.2522  data: 0.0001  max mem: 10917
[10:25:13.382273] Epoch: [40]  [320/345]  eta: 0:00:06  lr: 0.000026  loss: 0.7463 (0.7432)  time: 0.2525  data: 0.0001  max mem: 10917
[10:25:18.429951] Epoch: [40]  [340/345]  eta: 0:00:01  lr: 0.000026  loss: 0.7424 (0.7433)  time: 0.2523  data: 0.0000  max mem: 10917
[10:25:19.441387] Epoch: [40]  [344/345]  eta: 0:00:00  lr: 0.000026  loss: 0.7424 (0.7435)  time: 0.2524  data: 0.0001  max mem: 10917
[10:25:19.497001] Epoch: [40] Total time: 0:01:26 (0.2521 s / it)
[10:25:19.497469] Averaged stats: lr: 0.000026  loss: 0.7424 (0.7435)
[10:25:19.732568] Test:  [  0/345]  eta: 0:01:19  loss: 0.6976 (0.6976)  time: 0.2308  data: 0.1509  max mem: 10917
[10:25:20.554401] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7111 (0.7097)  time: 0.0956  data: 0.0140  max mem: 10917
[10:25:21.377632] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7111 (0.7106)  time: 0.0822  data: 0.0002  max mem: 10917
[10:25:22.204270] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7076 (0.7090)  time: 0.0824  data: 0.0001  max mem: 10917
[10:25:23.034582] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7095 (0.7105)  time: 0.0828  data: 0.0001  max mem: 10917
[10:25:23.868438] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7095 (0.7101)  time: 0.0832  data: 0.0001  max mem: 10917
[10:25:24.706236] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7086 (0.7108)  time: 0.0835  data: 0.0001  max mem: 10917
[10:25:25.547025] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7053 (0.7098)  time: 0.0839  data: 0.0001  max mem: 10917
[10:25:26.392030] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7028 (0.7096)  time: 0.0842  data: 0.0001  max mem: 10917
[10:25:27.241072] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7082 (0.7098)  time: 0.0847  data: 0.0001  max mem: 10917
[10:25:28.092013] Test:  [100/345]  eta: 0:00:20  loss: 0.7098 (0.7102)  time: 0.0850  data: 0.0001  max mem: 10917
[10:25:28.947202] Test:  [110/345]  eta: 0:00:19  loss: 0.7091 (0.7102)  time: 0.0853  data: 0.0001  max mem: 10917
[10:25:29.805884] Test:  [120/345]  eta: 0:00:19  loss: 0.7100 (0.7105)  time: 0.0856  data: 0.0001  max mem: 10917
[10:25:30.668001] Test:  [130/345]  eta: 0:00:18  loss: 0.7112 (0.7109)  time: 0.0860  data: 0.0001  max mem: 10917
[10:25:31.533899] Test:  [140/345]  eta: 0:00:17  loss: 0.7103 (0.7106)  time: 0.0864  data: 0.0001  max mem: 10917
[10:25:32.403816] Test:  [150/345]  eta: 0:00:16  loss: 0.7113 (0.7107)  time: 0.0867  data: 0.0001  max mem: 10917
[10:25:33.277218] Test:  [160/345]  eta: 0:00:15  loss: 0.7158 (0.7111)  time: 0.0871  data: 0.0001  max mem: 10917
[10:25:34.153650] Test:  [170/345]  eta: 0:00:14  loss: 0.7128 (0.7111)  time: 0.0874  data: 0.0001  max mem: 10917
[10:25:35.033752] Test:  [180/345]  eta: 0:00:14  loss: 0.7103 (0.7111)  time: 0.0878  data: 0.0001  max mem: 10917
[10:25:35.917051] Test:  [190/345]  eta: 0:00:13  loss: 0.7126 (0.7111)  time: 0.0881  data: 0.0001  max mem: 10917
[10:25:36.804166] Test:  [200/345]  eta: 0:00:12  loss: 0.7087 (0.7110)  time: 0.0885  data: 0.0001  max mem: 10917
[10:25:37.695067] Test:  [210/345]  eta: 0:00:11  loss: 0.7049 (0.7106)  time: 0.0889  data: 0.0001  max mem: 10917
[10:25:38.588850] Test:  [220/345]  eta: 0:00:10  loss: 0.7110 (0.7109)  time: 0.0892  data: 0.0001  max mem: 10917
[10:25:39.485608] Test:  [230/345]  eta: 0:00:09  loss: 0.7127 (0.7110)  time: 0.0895  data: 0.0001  max mem: 10917
[10:25:40.386588] Test:  [240/345]  eta: 0:00:09  loss: 0.7161 (0.7114)  time: 0.0898  data: 0.0001  max mem: 10917
[10:25:41.291016] Test:  [250/345]  eta: 0:00:08  loss: 0.7161 (0.7114)  time: 0.0902  data: 0.0001  max mem: 10917
[10:25:42.199055] Test:  [260/345]  eta: 0:00:07  loss: 0.7138 (0.7114)  time: 0.0906  data: 0.0001  max mem: 10917
[10:25:43.109455] Test:  [270/345]  eta: 0:00:06  loss: 0.7107 (0.7113)  time: 0.0909  data: 0.0001  max mem: 10917
[10:25:44.023954] Test:  [280/345]  eta: 0:00:05  loss: 0.7107 (0.7113)  time: 0.0912  data: 0.0001  max mem: 10917
[10:25:44.941901] Test:  [290/345]  eta: 0:00:04  loss: 0.7119 (0.7115)  time: 0.0916  data: 0.0001  max mem: 10917
[10:25:45.863935] Test:  [300/345]  eta: 0:00:03  loss: 0.7182 (0.7118)  time: 0.0920  data: 0.0001  max mem: 10917
[10:25:46.789072] Test:  [310/345]  eta: 0:00:03  loss: 0.7103 (0.7116)  time: 0.0923  data: 0.0001  max mem: 10917
[10:25:47.718819] Test:  [320/345]  eta: 0:00:02  loss: 0.7103 (0.7117)  time: 0.0927  data: 0.0001  max mem: 10917
[10:25:48.651174] Test:  [330/345]  eta: 0:00:01  loss: 0.7132 (0.7118)  time: 0.0931  data: 0.0001  max mem: 10917
[10:25:49.587049] Test:  [340/345]  eta: 0:00:00  loss: 0.7110 (0.7118)  time: 0.0934  data: 0.0001  max mem: 10917
[10:25:49.962838] Test:  [344/345]  eta: 0:00:00  loss: 0.7131 (0.7119)  time: 0.0935  data: 0.0001  max mem: 10917
[10:25:50.020477] Test: Total time: 0:00:30 (0.0885 s / it)
[10:26:00.546440] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8810 (0.8810)  time: 0.2167  data: 0.1370  max mem: 10917
[10:26:01.359088] Test:  [10/57]  eta: 0:00:04  loss: 0.9128 (0.9174)  time: 0.0935  data: 0.0125  max mem: 10917
[10:26:02.176709] Test:  [20/57]  eta: 0:00:03  loss: 0.9088 (0.9022)  time: 0.0814  data: 0.0001  max mem: 10917
[10:26:02.998173] Test:  [30/57]  eta: 0:00:02  loss: 0.7964 (0.8614)  time: 0.0819  data: 0.0001  max mem: 10917
[10:26:03.822383] Test:  [40/57]  eta: 0:00:01  loss: 0.7858 (0.8406)  time: 0.0822  data: 0.0001  max mem: 10917
[10:26:04.650501] Test:  [50/57]  eta: 0:00:00  loss: 0.7732 (0.8325)  time: 0.0826  data: 0.0001  max mem: 10917
[10:26:05.100900] Test:  [56/57]  eta: 0:00:00  loss: 0.8053 (0.8384)  time: 0.0804  data: 0.0001  max mem: 10917
[10:26:05.157062] Test: Total time: 0:00:04 (0.0847 s / it)
[10:26:06.904296] Dice score of the network on the train images: 0.827370, val images: 0.809666
[10:26:06.907748] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:26:07.301789] Epoch: [41]  [  0/345]  eta: 0:02:15  lr: 0.000026  loss: 0.7333 (0.7333)  time: 0.3931  data: 0.1399  max mem: 10917
[10:26:12.308535] Epoch: [41]  [ 20/345]  eta: 0:01:23  lr: 0.000025  loss: 0.7425 (0.7445)  time: 0.2503  data: 0.0000  max mem: 10917
[10:26:17.317830] Epoch: [41]  [ 40/345]  eta: 0:01:17  lr: 0.000025  loss: 0.7434 (0.7463)  time: 0.2504  data: 0.0001  max mem: 10917
[10:26:22.330235] Epoch: [41]  [ 60/345]  eta: 0:01:12  lr: 0.000025  loss: 0.7419 (0.7453)  time: 0.2506  data: 0.0001  max mem: 10917
[10:26:27.346083] Epoch: [41]  [ 80/345]  eta: 0:01:06  lr: 0.000025  loss: 0.7328 (0.7430)  time: 0.2508  data: 0.0001  max mem: 10917
[10:26:32.367494] Epoch: [41]  [100/345]  eta: 0:01:01  lr: 0.000024  loss: 0.7395 (0.7424)  time: 0.2510  data: 0.0000  max mem: 10917
[10:26:37.386586] Epoch: [41]  [120/345]  eta: 0:00:56  lr: 0.000024  loss: 0.7420 (0.7431)  time: 0.2509  data: 0.0001  max mem: 10917
[10:26:42.402259] Epoch: [41]  [140/345]  eta: 0:00:51  lr: 0.000024  loss: 0.7419 (0.7430)  time: 0.2507  data: 0.0001  max mem: 10917
[10:26:47.426069] Epoch: [41]  [160/345]  eta: 0:00:46  lr: 0.000023  loss: 0.7387 (0.7430)  time: 0.2511  data: 0.0001  max mem: 10917
[10:26:52.461342] Epoch: [41]  [180/345]  eta: 0:00:41  lr: 0.000023  loss: 0.7427 (0.7432)  time: 0.2517  data: 0.0001  max mem: 10917
[10:26:57.484792] Epoch: [41]  [200/345]  eta: 0:00:36  lr: 0.000023  loss: 0.7389 (0.7427)  time: 0.2511  data: 0.0001  max mem: 10917
[10:27:02.508074] Epoch: [41]  [220/345]  eta: 0:00:31  lr: 0.000022  loss: 0.7409 (0.7424)  time: 0.2511  data: 0.0001  max mem: 10917
[10:27:07.615276] Epoch: [41]  [240/345]  eta: 0:00:26  lr: 0.000022  loss: 0.7378 (0.7422)  time: 0.2553  data: 0.0001  max mem: 10917
[10:27:12.644996] Epoch: [41]  [260/345]  eta: 0:00:21  lr: 0.000022  loss: 0.7421 (0.7422)  time: 0.2514  data: 0.0001  max mem: 10917
[10:27:17.686572] Epoch: [41]  [280/345]  eta: 0:00:16  lr: 0.000022  loss: 0.7440 (0.7424)  time: 0.2520  data: 0.0001  max mem: 10917
[10:27:22.736931] Epoch: [41]  [300/345]  eta: 0:00:11  lr: 0.000021  loss: 0.7428 (0.7425)  time: 0.2525  data: 0.0001  max mem: 10917
[10:27:27.783049] Epoch: [41]  [320/345]  eta: 0:00:06  lr: 0.000021  loss: 0.7442 (0.7426)  time: 0.2523  data: 0.0001  max mem: 10917
[10:27:32.831969] Epoch: [41]  [340/345]  eta: 0:00:01  lr: 0.000021  loss: 0.7334 (0.7423)  time: 0.2524  data: 0.0001  max mem: 10917
[10:27:33.841170] Epoch: [41]  [344/345]  eta: 0:00:00  lr: 0.000021  loss: 0.7330 (0.7422)  time: 0.2524  data: 0.0001  max mem: 10917
[10:27:33.903338] Epoch: [41] Total time: 0:01:26 (0.2522 s / it)
[10:27:33.903769] Averaged stats: lr: 0.000021  loss: 0.7330 (0.7422)
[10:27:34.139356] Test:  [  0/345]  eta: 0:01:19  loss: 0.7204 (0.7204)  time: 0.2318  data: 0.1514  max mem: 10917
[10:27:34.982840] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7051 (0.7081)  time: 0.0977  data: 0.0161  max mem: 10917
[10:27:35.806472] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7104 (0.7106)  time: 0.0833  data: 0.0013  max mem: 10917
[10:27:36.634465] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7067 (0.7093)  time: 0.0825  data: 0.0001  max mem: 10917
[10:27:37.464741] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7064 (0.7092)  time: 0.0829  data: 0.0001  max mem: 10917
[10:27:38.299326] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7086 (0.7092)  time: 0.0832  data: 0.0001  max mem: 10917
[10:27:39.137181] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7107 (0.7097)  time: 0.0836  data: 0.0001  max mem: 10917
[10:27:39.978114] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7102 (0.7085)  time: 0.0839  data: 0.0001  max mem: 10917
[10:27:40.822445] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7109 (0.7097)  time: 0.0842  data: 0.0001  max mem: 10917
[10:27:41.671108] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7132 (0.7097)  time: 0.0846  data: 0.0001  max mem: 10917
[10:27:42.522942] Test:  [100/345]  eta: 0:00:20  loss: 0.7070 (0.7089)  time: 0.0850  data: 0.0001  max mem: 10917
[10:27:43.378426] Test:  [110/345]  eta: 0:00:20  loss: 0.7082 (0.7096)  time: 0.0853  data: 0.0001  max mem: 10917
[10:27:44.237194] Test:  [120/345]  eta: 0:00:19  loss: 0.7088 (0.7094)  time: 0.0857  data: 0.0001  max mem: 10917
[10:27:45.099250] Test:  [130/345]  eta: 0:00:18  loss: 0.7078 (0.7091)  time: 0.0860  data: 0.0001  max mem: 10917
[10:27:45.964747] Test:  [140/345]  eta: 0:00:17  loss: 0.7053 (0.7091)  time: 0.0863  data: 0.0001  max mem: 10917
[10:27:46.833904] Test:  [150/345]  eta: 0:00:16  loss: 0.7090 (0.7093)  time: 0.0867  data: 0.0001  max mem: 10917
[10:27:47.705816] Test:  [160/345]  eta: 0:00:15  loss: 0.7153 (0.7096)  time: 0.0870  data: 0.0001  max mem: 10917
[10:27:48.582081] Test:  [170/345]  eta: 0:00:15  loss: 0.7107 (0.7097)  time: 0.0874  data: 0.0001  max mem: 10917
[10:27:49.463026] Test:  [180/345]  eta: 0:00:14  loss: 0.7069 (0.7098)  time: 0.0878  data: 0.0001  max mem: 10917
[10:27:50.345767] Test:  [190/345]  eta: 0:00:13  loss: 0.7069 (0.7100)  time: 0.0881  data: 0.0001  max mem: 10917
[10:27:51.232584] Test:  [200/345]  eta: 0:00:12  loss: 0.7023 (0.7097)  time: 0.0884  data: 0.0001  max mem: 10917
[10:27:52.122978] Test:  [210/345]  eta: 0:00:11  loss: 0.7027 (0.7098)  time: 0.0888  data: 0.0001  max mem: 10917
[10:27:53.016851] Test:  [220/345]  eta: 0:00:10  loss: 0.7124 (0.7096)  time: 0.0892  data: 0.0001  max mem: 10917
[10:27:53.914118] Test:  [230/345]  eta: 0:00:09  loss: 0.7100 (0.7098)  time: 0.0895  data: 0.0001  max mem: 10917
[10:27:54.816139] Test:  [240/345]  eta: 0:00:09  loss: 0.7100 (0.7099)  time: 0.0899  data: 0.0001  max mem: 10917
[10:27:55.720602] Test:  [250/345]  eta: 0:00:08  loss: 0.7092 (0.7101)  time: 0.0903  data: 0.0001  max mem: 10917
[10:27:56.628334] Test:  [260/345]  eta: 0:00:07  loss: 0.7111 (0.7103)  time: 0.0906  data: 0.0001  max mem: 10917
[10:27:57.539579] Test:  [270/345]  eta: 0:00:06  loss: 0.7111 (0.7104)  time: 0.0909  data: 0.0001  max mem: 10917
[10:27:58.454310] Test:  [280/345]  eta: 0:00:05  loss: 0.7070 (0.7102)  time: 0.0913  data: 0.0001  max mem: 10917
[10:27:59.372528] Test:  [290/345]  eta: 0:00:04  loss: 0.7074 (0.7102)  time: 0.0916  data: 0.0001  max mem: 10917
[10:28:00.294845] Test:  [300/345]  eta: 0:00:03  loss: 0.7078 (0.7102)  time: 0.0920  data: 0.0001  max mem: 10917
[10:28:01.220248] Test:  [310/345]  eta: 0:00:03  loss: 0.7067 (0.7101)  time: 0.0923  data: 0.0001  max mem: 10917
[10:28:02.148641] Test:  [320/345]  eta: 0:00:02  loss: 0.7079 (0.7100)  time: 0.0926  data: 0.0001  max mem: 10917
[10:28:03.081284] Test:  [330/345]  eta: 0:00:01  loss: 0.7101 (0.7101)  time: 0.0930  data: 0.0001  max mem: 10917
[10:28:04.017214] Test:  [340/345]  eta: 0:00:00  loss: 0.7078 (0.7101)  time: 0.0934  data: 0.0001  max mem: 10917
[10:28:04.392681] Test:  [344/345]  eta: 0:00:00  loss: 0.7078 (0.7102)  time: 0.0935  data: 0.0001  max mem: 10917
[10:28:04.448455] Test: Total time: 0:00:30 (0.0885 s / it)
[10:28:14.792167] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8823 (0.8823)  time: 0.2200  data: 0.1403  max mem: 10917
[10:28:15.605747] Test:  [10/57]  eta: 0:00:04  loss: 0.9158 (0.9211)  time: 0.0939  data: 0.0128  max mem: 10917
[10:28:16.423531] Test:  [20/57]  eta: 0:00:03  loss: 0.9157 (0.9068)  time: 0.0815  data: 0.0001  max mem: 10917
[10:28:17.244733] Test:  [30/57]  eta: 0:00:02  loss: 0.7996 (0.8656)  time: 0.0819  data: 0.0001  max mem: 10917
[10:28:18.068979] Test:  [40/57]  eta: 0:00:01  loss: 0.7894 (0.8443)  time: 0.0822  data: 0.0001  max mem: 10917
[10:28:18.897642] Test:  [50/57]  eta: 0:00:00  loss: 0.7752 (0.8360)  time: 0.0826  data: 0.0001  max mem: 10917
[10:28:19.347165] Test:  [56/57]  eta: 0:00:00  loss: 0.8082 (0.8422)  time: 0.0804  data: 0.0001  max mem: 10917
[10:28:19.403695] Test: Total time: 0:00:04 (0.0848 s / it)
[10:28:21.181119] Dice score of the network on the train images: 0.831630, val images: 0.808986
[10:28:21.184436] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:28:21.579617] Epoch: [42]  [  0/345]  eta: 0:02:15  lr: 0.000021  loss: 0.7314 (0.7314)  time: 0.3941  data: 0.1418  max mem: 10917
[10:28:26.587914] Epoch: [42]  [ 20/345]  eta: 0:01:23  lr: 0.000020  loss: 0.7375 (0.7383)  time: 0.2504  data: 0.0000  max mem: 10917
[10:28:31.599901] Epoch: [42]  [ 40/345]  eta: 0:01:17  lr: 0.000020  loss: 0.7404 (0.7395)  time: 0.2506  data: 0.0000  max mem: 10917
[10:28:36.616300] Epoch: [42]  [ 60/345]  eta: 0:01:12  lr: 0.000020  loss: 0.7352 (0.7398)  time: 0.2508  data: 0.0000  max mem: 10917
[10:28:41.634614] Epoch: [42]  [ 80/345]  eta: 0:01:06  lr: 0.000020  loss: 0.7417 (0.7405)  time: 0.2509  data: 0.0001  max mem: 10917
[10:28:46.656342] Epoch: [42]  [100/345]  eta: 0:01:01  lr: 0.000019  loss: 0.7405 (0.7409)  time: 0.2510  data: 0.0001  max mem: 10917
[10:28:51.686592] Epoch: [42]  [120/345]  eta: 0:00:56  lr: 0.000019  loss: 0.7409 (0.7411)  time: 0.2515  data: 0.0001  max mem: 10917
[10:28:56.719059] Epoch: [42]  [140/345]  eta: 0:00:51  lr: 0.000019  loss: 0.7401 (0.7408)  time: 0.2516  data: 0.0001  max mem: 10917
[10:29:01.756524] Epoch: [42]  [160/345]  eta: 0:00:46  lr: 0.000018  loss: 0.7390 (0.7412)  time: 0.2518  data: 0.0001  max mem: 10917
[10:29:06.791250] Epoch: [42]  [180/345]  eta: 0:00:41  lr: 0.000018  loss: 0.7317 (0.7405)  time: 0.2517  data: 0.0001  max mem: 10917
[10:29:11.825280] Epoch: [42]  [200/345]  eta: 0:00:36  lr: 0.000018  loss: 0.7358 (0.7403)  time: 0.2517  data: 0.0001  max mem: 10917
[10:29:16.865793] Epoch: [42]  [220/345]  eta: 0:00:31  lr: 0.000018  loss: 0.7392 (0.7404)  time: 0.2520  data: 0.0001  max mem: 10917
[10:29:21.904929] Epoch: [42]  [240/345]  eta: 0:00:26  lr: 0.000017  loss: 0.7401 (0.7404)  time: 0.2519  data: 0.0001  max mem: 10917
[10:29:26.944802] Epoch: [42]  [260/345]  eta: 0:00:21  lr: 0.000017  loss: 0.7405 (0.7402)  time: 0.2519  data: 0.0001  max mem: 10917
[10:29:31.987642] Epoch: [42]  [280/345]  eta: 0:00:16  lr: 0.000017  loss: 0.7408 (0.7405)  time: 0.2521  data: 0.0001  max mem: 10917
[10:29:37.033332] Epoch: [42]  [300/345]  eta: 0:00:11  lr: 0.000017  loss: 0.7388 (0.7406)  time: 0.2522  data: 0.0001  max mem: 10917
[10:29:42.079943] Epoch: [42]  [320/345]  eta: 0:00:06  lr: 0.000016  loss: 0.7350 (0.7402)  time: 0.2523  data: 0.0001  max mem: 10917
[10:29:47.126475] Epoch: [42]  [340/345]  eta: 0:00:01  lr: 0.000016  loss: 0.7376 (0.7401)  time: 0.2523  data: 0.0000  max mem: 10917
[10:29:48.136972] Epoch: [42]  [344/345]  eta: 0:00:00  lr: 0.000016  loss: 0.7380 (0.7402)  time: 0.2523  data: 0.0001  max mem: 10917
[10:29:48.192641] Epoch: [42] Total time: 0:01:27 (0.2522 s / it)
[10:29:48.192959] Averaged stats: lr: 0.000016  loss: 0.7380 (0.7402)
[10:29:48.429310] Test:  [  0/345]  eta: 0:01:20  loss: 0.7259 (0.7259)  time: 0.2328  data: 0.1529  max mem: 10917
[10:29:49.249529] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7032 (0.7122)  time: 0.0957  data: 0.0140  max mem: 10917
[10:29:50.073024] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7032 (0.7085)  time: 0.0821  data: 0.0001  max mem: 10917
[10:29:50.899325] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7073 (0.7097)  time: 0.0824  data: 0.0001  max mem: 10917
[10:29:51.730983] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7092 (0.7105)  time: 0.0828  data: 0.0001  max mem: 10917
[10:29:52.564988] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7099 (0.7111)  time: 0.0832  data: 0.0001  max mem: 10917
[10:29:53.402725] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7108 (0.7110)  time: 0.0835  data: 0.0001  max mem: 10917
[10:29:54.243290] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7130 (0.7106)  time: 0.0839  data: 0.0001  max mem: 10917
[10:29:55.087978] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7101 (0.7102)  time: 0.0842  data: 0.0001  max mem: 10917
[10:29:55.935689] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7107 (0.7107)  time: 0.0846  data: 0.0001  max mem: 10917
[10:29:56.787577] Test:  [100/345]  eta: 0:00:20  loss: 0.7118 (0.7104)  time: 0.0849  data: 0.0001  max mem: 10917
[10:29:57.642392] Test:  [110/345]  eta: 0:00:19  loss: 0.7077 (0.7102)  time: 0.0853  data: 0.0001  max mem: 10917
[10:29:58.501448] Test:  [120/345]  eta: 0:00:19  loss: 0.7056 (0.7099)  time: 0.0856  data: 0.0001  max mem: 10917
[10:29:59.363433] Test:  [130/345]  eta: 0:00:18  loss: 0.7119 (0.7099)  time: 0.0860  data: 0.0001  max mem: 10917
[10:30:00.229199] Test:  [140/345]  eta: 0:00:17  loss: 0.7087 (0.7097)  time: 0.0863  data: 0.0001  max mem: 10917
[10:30:01.098351] Test:  [150/345]  eta: 0:00:16  loss: 0.7086 (0.7097)  time: 0.0867  data: 0.0001  max mem: 10917
[10:30:01.971404] Test:  [160/345]  eta: 0:00:15  loss: 0.7086 (0.7095)  time: 0.0871  data: 0.0001  max mem: 10917
[10:30:02.847450] Test:  [170/345]  eta: 0:00:14  loss: 0.7087 (0.7095)  time: 0.0874  data: 0.0001  max mem: 10917
[10:30:03.727270] Test:  [180/345]  eta: 0:00:14  loss: 0.7097 (0.7095)  time: 0.0877  data: 0.0001  max mem: 10917
[10:30:04.610319] Test:  [190/345]  eta: 0:00:13  loss: 0.7058 (0.7093)  time: 0.0881  data: 0.0001  max mem: 10917
[10:30:05.497554] Test:  [200/345]  eta: 0:00:12  loss: 0.7047 (0.7094)  time: 0.0885  data: 0.0001  max mem: 10917
[10:30:06.388180] Test:  [210/345]  eta: 0:00:11  loss: 0.7125 (0.7097)  time: 0.0888  data: 0.0001  max mem: 10917
[10:30:07.281688] Test:  [220/345]  eta: 0:00:10  loss: 0.7125 (0.7097)  time: 0.0892  data: 0.0001  max mem: 10917
[10:30:08.179591] Test:  [230/345]  eta: 0:00:09  loss: 0.7041 (0.7095)  time: 0.0895  data: 0.0001  max mem: 10917
[10:30:09.080779] Test:  [240/345]  eta: 0:00:09  loss: 0.7032 (0.7094)  time: 0.0899  data: 0.0001  max mem: 10917
[10:30:09.984198] Test:  [250/345]  eta: 0:00:08  loss: 0.7028 (0.7094)  time: 0.0902  data: 0.0001  max mem: 10917
[10:30:10.891691] Test:  [260/345]  eta: 0:00:07  loss: 0.7048 (0.7093)  time: 0.0905  data: 0.0001  max mem: 10917
[10:30:11.802792] Test:  [270/345]  eta: 0:00:06  loss: 0.7055 (0.7092)  time: 0.0909  data: 0.0001  max mem: 10917
[10:30:12.717814] Test:  [280/345]  eta: 0:00:05  loss: 0.7104 (0.7094)  time: 0.0913  data: 0.0001  max mem: 10917
[10:30:13.636959] Test:  [290/345]  eta: 0:00:04  loss: 0.7114 (0.7094)  time: 0.0917  data: 0.0001  max mem: 10917
[10:30:14.559185] Test:  [300/345]  eta: 0:00:03  loss: 0.7063 (0.7093)  time: 0.0920  data: 0.0001  max mem: 10917
[10:30:15.484309] Test:  [310/345]  eta: 0:00:03  loss: 0.7058 (0.7093)  time: 0.0923  data: 0.0001  max mem: 10917
[10:30:16.413277] Test:  [320/345]  eta: 0:00:02  loss: 0.7090 (0.7094)  time: 0.0927  data: 0.0001  max mem: 10917
[10:30:17.345687] Test:  [330/345]  eta: 0:00:01  loss: 0.7090 (0.7094)  time: 0.0930  data: 0.0001  max mem: 10917
[10:30:18.281426] Test:  [340/345]  eta: 0:00:00  loss: 0.7054 (0.7094)  time: 0.0934  data: 0.0001  max mem: 10917
[10:30:18.657262] Test:  [344/345]  eta: 0:00:00  loss: 0.7057 (0.7094)  time: 0.0935  data: 0.0001  max mem: 10917
[10:30:18.709570] Test: Total time: 0:00:30 (0.0884 s / it)
[10:30:29.045529] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8844 (0.8844)  time: 0.2185  data: 0.1384  max mem: 10917
[10:30:29.860025] Test:  [10/57]  eta: 0:00:04  loss: 0.9133 (0.9179)  time: 0.0938  data: 0.0126  max mem: 10917
[10:30:30.677303] Test:  [20/57]  eta: 0:00:03  loss: 0.9133 (0.9045)  time: 0.0815  data: 0.0001  max mem: 10917
[10:30:31.498596] Test:  [30/57]  eta: 0:00:02  loss: 0.7941 (0.8632)  time: 0.0819  data: 0.0001  max mem: 10917
[10:30:32.323172] Test:  [40/57]  eta: 0:00:01  loss: 0.7865 (0.8420)  time: 0.0822  data: 0.0001  max mem: 10917
[10:30:33.152331] Test:  [50/57]  eta: 0:00:00  loss: 0.7744 (0.8338)  time: 0.0826  data: 0.0001  max mem: 10917
[10:30:33.603364] Test:  [56/57]  eta: 0:00:00  loss: 0.8060 (0.8404)  time: 0.0805  data: 0.0001  max mem: 10917
[10:30:33.656870] Test: Total time: 0:00:04 (0.0848 s / it)
[10:30:35.419432] Dice score of the network on the train images: 0.829428, val images: 0.810470
[10:30:35.422908] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:30:35.818136] Epoch: [43]  [  0/345]  eta: 0:02:15  lr: 0.000016  loss: 0.7326 (0.7326)  time: 0.3941  data: 0.1421  max mem: 10917
[10:30:40.826407] Epoch: [43]  [ 20/345]  eta: 0:01:23  lr: 0.000016  loss: 0.7332 (0.7339)  time: 0.2504  data: 0.0001  max mem: 10917
[10:30:45.836566] Epoch: [43]  [ 40/345]  eta: 0:01:17  lr: 0.000016  loss: 0.7345 (0.7350)  time: 0.2505  data: 0.0001  max mem: 10917
[10:30:50.841954] Epoch: [43]  [ 60/345]  eta: 0:01:12  lr: 0.000015  loss: 0.7425 (0.7371)  time: 0.2502  data: 0.0001  max mem: 10917
[10:30:55.840750] Epoch: [43]  [ 80/345]  eta: 0:01:06  lr: 0.000015  loss: 0.7463 (0.7390)  time: 0.2499  data: 0.0001  max mem: 10917
[10:31:00.839688] Epoch: [43]  [100/345]  eta: 0:01:01  lr: 0.000015  loss: 0.7371 (0.7393)  time: 0.2499  data: 0.0001  max mem: 10917
[10:31:05.841100] Epoch: [43]  [120/345]  eta: 0:00:56  lr: 0.000015  loss: 0.7414 (0.7407)  time: 0.2500  data: 0.0001  max mem: 10917
[10:31:10.852625] Epoch: [43]  [140/345]  eta: 0:00:51  lr: 0.000014  loss: 0.7343 (0.7400)  time: 0.2505  data: 0.0001  max mem: 10917
[10:31:15.870962] Epoch: [43]  [160/345]  eta: 0:00:46  lr: 0.000014  loss: 0.7309 (0.7395)  time: 0.2509  data: 0.0001  max mem: 10917
[10:31:20.890298] Epoch: [43]  [180/345]  eta: 0:00:41  lr: 0.000014  loss: 0.7369 (0.7396)  time: 0.2509  data: 0.0001  max mem: 10917
[10:31:25.910748] Epoch: [43]  [200/345]  eta: 0:00:36  lr: 0.000014  loss: 0.7339 (0.7397)  time: 0.2510  data: 0.0000  max mem: 10917
[10:31:30.932793] Epoch: [43]  [220/345]  eta: 0:00:31  lr: 0.000013  loss: 0.7323 (0.7393)  time: 0.2511  data: 0.0001  max mem: 10917
[10:31:35.956479] Epoch: [43]  [240/345]  eta: 0:00:26  lr: 0.000013  loss: 0.7358 (0.7393)  time: 0.2511  data: 0.0001  max mem: 10917
[10:31:40.982822] Epoch: [43]  [260/345]  eta: 0:00:21  lr: 0.000013  loss: 0.7407 (0.7400)  time: 0.2513  data: 0.0000  max mem: 10917
[10:31:46.010939] Epoch: [43]  [280/345]  eta: 0:00:16  lr: 0.000013  loss: 0.7403 (0.7401)  time: 0.2514  data: 0.0001  max mem: 10917
[10:31:51.040414] Epoch: [43]  [300/345]  eta: 0:00:11  lr: 0.000012  loss: 0.7415 (0.7402)  time: 0.2514  data: 0.0001  max mem: 10917
[10:31:56.067262] Epoch: [43]  [320/345]  eta: 0:00:06  lr: 0.000012  loss: 0.7398 (0.7404)  time: 0.2513  data: 0.0001  max mem: 10917
[10:32:01.099154] Epoch: [43]  [340/345]  eta: 0:00:01  lr: 0.000012  loss: 0.7317 (0.7400)  time: 0.2515  data: 0.0000  max mem: 10917
[10:32:02.106249] Epoch: [43]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 0.7328 (0.7401)  time: 0.2516  data: 0.0001  max mem: 10917
[10:32:02.160574] Epoch: [43] Total time: 0:01:26 (0.2514 s / it)
[10:32:02.160962] Averaged stats: lr: 0.000012  loss: 0.7328 (0.7401)
[10:32:02.396202] Test:  [  0/345]  eta: 0:01:20  loss: 0.6994 (0.6994)  time: 0.2326  data: 0.1524  max mem: 10917
[10:32:03.227140] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7082 (0.7063)  time: 0.0966  data: 0.0151  max mem: 10917
[10:32:04.063968] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7056 (0.7061)  time: 0.0833  data: 0.0015  max mem: 10917
[10:32:04.900546] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7060 (0.7070)  time: 0.0836  data: 0.0014  max mem: 10917
[10:32:05.731526] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7083 (0.7074)  time: 0.0833  data: 0.0006  max mem: 10917
[10:32:06.564017] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7083 (0.7085)  time: 0.0831  data: 0.0001  max mem: 10917
[10:32:07.400647] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7078 (0.7087)  time: 0.0834  data: 0.0001  max mem: 10917
[10:32:08.240309] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7066 (0.7082)  time: 0.0838  data: 0.0001  max mem: 10917
[10:32:09.083937] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7068 (0.7089)  time: 0.0841  data: 0.0001  max mem: 10917
[10:32:09.931555] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7087 (0.7092)  time: 0.0845  data: 0.0001  max mem: 10917
[10:32:10.781628] Test:  [100/345]  eta: 0:00:20  loss: 0.7073 (0.7092)  time: 0.0848  data: 0.0001  max mem: 10917
[10:32:11.635251] Test:  [110/345]  eta: 0:00:20  loss: 0.7066 (0.7092)  time: 0.0851  data: 0.0001  max mem: 10917
[10:32:12.493151] Test:  [120/345]  eta: 0:00:19  loss: 0.7066 (0.7091)  time: 0.0855  data: 0.0001  max mem: 10917
[10:32:13.354525] Test:  [130/345]  eta: 0:00:18  loss: 0.7129 (0.7098)  time: 0.0859  data: 0.0001  max mem: 10917
[10:32:14.219374] Test:  [140/345]  eta: 0:00:17  loss: 0.7078 (0.7093)  time: 0.0863  data: 0.0001  max mem: 10917
[10:32:15.087765] Test:  [150/345]  eta: 0:00:16  loss: 0.7067 (0.7100)  time: 0.0866  data: 0.0001  max mem: 10917
[10:32:15.960079] Test:  [160/345]  eta: 0:00:15  loss: 0.7067 (0.7099)  time: 0.0870  data: 0.0001  max mem: 10917
[10:32:16.835360] Test:  [170/345]  eta: 0:00:15  loss: 0.7023 (0.7097)  time: 0.0873  data: 0.0001  max mem: 10917
[10:32:17.714176] Test:  [180/345]  eta: 0:00:14  loss: 0.7044 (0.7097)  time: 0.0877  data: 0.0001  max mem: 10917
[10:32:18.596490] Test:  [190/345]  eta: 0:00:13  loss: 0.7071 (0.7096)  time: 0.0880  data: 0.0001  max mem: 10917
[10:32:19.482049] Test:  [200/345]  eta: 0:00:12  loss: 0.7073 (0.7096)  time: 0.0883  data: 0.0001  max mem: 10917
[10:32:20.372225] Test:  [210/345]  eta: 0:00:11  loss: 0.7073 (0.7097)  time: 0.0887  data: 0.0001  max mem: 10917
[10:32:21.264658] Test:  [220/345]  eta: 0:00:10  loss: 0.7047 (0.7094)  time: 0.0891  data: 0.0001  max mem: 10917
[10:32:22.161203] Test:  [230/345]  eta: 0:00:09  loss: 0.7047 (0.7092)  time: 0.0894  data: 0.0001  max mem: 10917
[10:32:23.061431] Test:  [240/345]  eta: 0:00:09  loss: 0.7092 (0.7094)  time: 0.0898  data: 0.0001  max mem: 10917
[10:32:23.964311] Test:  [250/345]  eta: 0:00:08  loss: 0.7092 (0.7093)  time: 0.0901  data: 0.0001  max mem: 10917
[10:32:24.871349] Test:  [260/345]  eta: 0:00:07  loss: 0.7033 (0.7089)  time: 0.0904  data: 0.0001  max mem: 10917
[10:32:25.781637] Test:  [270/345]  eta: 0:00:06  loss: 0.7027 (0.7088)  time: 0.0908  data: 0.0001  max mem: 10917
[10:32:26.695056] Test:  [280/345]  eta: 0:00:05  loss: 0.7098 (0.7090)  time: 0.0911  data: 0.0001  max mem: 10917
[10:32:27.612056] Test:  [290/345]  eta: 0:00:04  loss: 0.7076 (0.7089)  time: 0.0915  data: 0.0001  max mem: 10917
[10:32:28.534098] Test:  [300/345]  eta: 0:00:03  loss: 0.7071 (0.7089)  time: 0.0919  data: 0.0001  max mem: 10917
[10:32:29.460138] Test:  [310/345]  eta: 0:00:03  loss: 0.7071 (0.7087)  time: 0.0924  data: 0.0001  max mem: 10917
[10:32:30.388035] Test:  [320/345]  eta: 0:00:02  loss: 0.7046 (0.7087)  time: 0.0926  data: 0.0001  max mem: 10917
[10:32:31.320432] Test:  [330/345]  eta: 0:00:01  loss: 0.7090 (0.7086)  time: 0.0930  data: 0.0001  max mem: 10917
[10:32:32.255930] Test:  [340/345]  eta: 0:00:00  loss: 0.7042 (0.7087)  time: 0.0933  data: 0.0001  max mem: 10917
[10:32:32.631688] Test:  [344/345]  eta: 0:00:00  loss: 0.7048 (0.7088)  time: 0.0935  data: 0.0001  max mem: 10917
[10:32:32.686961] Test: Total time: 0:00:30 (0.0885 s / it)
[10:32:43.092346] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8866 (0.8866)  time: 0.2168  data: 0.1370  max mem: 10917
[10:32:43.905769] Test:  [10/57]  eta: 0:00:04  loss: 0.9153 (0.9211)  time: 0.0936  data: 0.0125  max mem: 10917
[10:32:44.722639] Test:  [20/57]  eta: 0:00:03  loss: 0.9206 (0.9092)  time: 0.0815  data: 0.0001  max mem: 10917
[10:32:45.543529] Test:  [30/57]  eta: 0:00:02  loss: 0.7978 (0.8669)  time: 0.0818  data: 0.0001  max mem: 10917
[10:32:46.368224] Test:  [40/57]  eta: 0:00:01  loss: 0.7849 (0.8453)  time: 0.0822  data: 0.0001  max mem: 10917
[10:32:47.197150] Test:  [50/57]  eta: 0:00:00  loss: 0.7787 (0.8369)  time: 0.0826  data: 0.0001  max mem: 10917
[10:32:47.646900] Test:  [56/57]  eta: 0:00:00  loss: 0.8131 (0.8432)  time: 0.0804  data: 0.0001  max mem: 10917
[10:32:47.685397] Test: Total time: 0:00:04 (0.0844 s / it)
[10:32:49.443650] Dice score of the network on the train images: 0.829906, val images: 0.809125
[10:32:49.447329] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:32:49.843787] Epoch: [44]  [  0/345]  eta: 0:02:16  lr: 0.000012  loss: 0.7262 (0.7262)  time: 0.3954  data: 0.1436  max mem: 10917
[10:32:54.832273] Epoch: [44]  [ 20/345]  eta: 0:01:23  lr: 0.000012  loss: 0.7390 (0.7387)  time: 0.2494  data: 0.0001  max mem: 10917
[10:32:59.824113] Epoch: [44]  [ 40/345]  eta: 0:01:17  lr: 0.000011  loss: 0.7440 (0.7412)  time: 0.2495  data: 0.0001  max mem: 10917
[10:33:04.816583] Epoch: [44]  [ 60/345]  eta: 0:01:11  lr: 0.000011  loss: 0.7337 (0.7393)  time: 0.2496  data: 0.0001  max mem: 10917
[10:33:09.812121] Epoch: [44]  [ 80/345]  eta: 0:01:06  lr: 0.000011  loss: 0.7338 (0.7392)  time: 0.2497  data: 0.0001  max mem: 10917
[10:33:14.812344] Epoch: [44]  [100/345]  eta: 0:01:01  lr: 0.000011  loss: 0.7322 (0.7392)  time: 0.2500  data: 0.0001  max mem: 10917
[10:33:19.816609] Epoch: [44]  [120/345]  eta: 0:00:56  lr: 0.000011  loss: 0.7327 (0.7386)  time: 0.2502  data: 0.0001  max mem: 10917
[10:33:24.825836] Epoch: [44]  [140/345]  eta: 0:00:51  lr: 0.000010  loss: 0.7403 (0.7389)  time: 0.2504  data: 0.0000  max mem: 10917
[10:33:29.846082] Epoch: [44]  [160/345]  eta: 0:00:46  lr: 0.000010  loss: 0.7453 (0.7398)  time: 0.2510  data: 0.0001  max mem: 10917
[10:33:34.862233] Epoch: [44]  [180/345]  eta: 0:00:41  lr: 0.000010  loss: 0.7437 (0.7399)  time: 0.2508  data: 0.0001  max mem: 10917
[10:33:39.878204] Epoch: [44]  [200/345]  eta: 0:00:36  lr: 0.000010  loss: 0.7394 (0.7398)  time: 0.2508  data: 0.0001  max mem: 10917
[10:33:44.899330] Epoch: [44]  [220/345]  eta: 0:00:31  lr: 0.000010  loss: 0.7339 (0.7396)  time: 0.2510  data: 0.0001  max mem: 10917
[10:33:49.924863] Epoch: [44]  [240/345]  eta: 0:00:26  lr: 0.000009  loss: 0.7338 (0.7394)  time: 0.2512  data: 0.0001  max mem: 10917
[10:33:54.952489] Epoch: [44]  [260/345]  eta: 0:00:21  lr: 0.000009  loss: 0.7378 (0.7393)  time: 0.2513  data: 0.0001  max mem: 10917
[10:33:59.983379] Epoch: [44]  [280/345]  eta: 0:00:16  lr: 0.000009  loss: 0.7362 (0.7392)  time: 0.2515  data: 0.0001  max mem: 10917
[10:34:05.012082] Epoch: [44]  [300/345]  eta: 0:00:11  lr: 0.000009  loss: 0.7368 (0.7391)  time: 0.2514  data: 0.0001  max mem: 10917
[10:34:10.045029] Epoch: [44]  [320/345]  eta: 0:00:06  lr: 0.000009  loss: 0.7333 (0.7390)  time: 0.2516  data: 0.0001  max mem: 10917
[10:34:15.076857] Epoch: [44]  [340/345]  eta: 0:00:01  lr: 0.000008  loss: 0.7402 (0.7391)  time: 0.2515  data: 0.0001  max mem: 10917
[10:34:16.084429] Epoch: [44]  [344/345]  eta: 0:00:00  lr: 0.000008  loss: 0.7405 (0.7391)  time: 0.2516  data: 0.0001  max mem: 10917
[10:34:16.139293] Epoch: [44] Total time: 0:01:26 (0.2513 s / it)
[10:34:16.139712] Averaged stats: lr: 0.000008  loss: 0.7405 (0.7391)
[10:34:16.371955] Test:  [  0/345]  eta: 0:01:19  loss: 0.6912 (0.6912)  time: 0.2295  data: 0.1491  max mem: 10917
[10:34:17.192678] Test:  [ 10/345]  eta: 0:00:31  loss: 0.7082 (0.7078)  time: 0.0954  data: 0.0136  max mem: 10917
[10:34:18.015705] Test:  [ 20/345]  eta: 0:00:28  loss: 0.7086 (0.7093)  time: 0.0821  data: 0.0001  max mem: 10917
[10:34:18.844051] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7059 (0.7080)  time: 0.0825  data: 0.0001  max mem: 10917
[10:34:19.674118] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7060 (0.7088)  time: 0.0829  data: 0.0001  max mem: 10917
[10:34:20.508437] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7075 (0.7087)  time: 0.0832  data: 0.0001  max mem: 10917
[10:34:21.345912] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7072 (0.7083)  time: 0.0835  data: 0.0001  max mem: 10917
[10:34:22.187664] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7052 (0.7079)  time: 0.0839  data: 0.0001  max mem: 10917
[10:34:23.032342] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7000 (0.7075)  time: 0.0843  data: 0.0001  max mem: 10917
[10:34:23.880620] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7079 (0.7085)  time: 0.0846  data: 0.0001  max mem: 10917
[10:34:24.732975] Test:  [100/345]  eta: 0:00:20  loss: 0.7082 (0.7087)  time: 0.0850  data: 0.0001  max mem: 10917
[10:34:25.588388] Test:  [110/345]  eta: 0:00:19  loss: 0.7140 (0.7088)  time: 0.0853  data: 0.0001  max mem: 10917
[10:34:26.447466] Test:  [120/345]  eta: 0:00:19  loss: 0.7094 (0.7085)  time: 0.0857  data: 0.0001  max mem: 10917
[10:34:27.309601] Test:  [130/345]  eta: 0:00:18  loss: 0.7006 (0.7080)  time: 0.0860  data: 0.0001  max mem: 10917
[10:34:28.175168] Test:  [140/345]  eta: 0:00:17  loss: 0.7034 (0.7080)  time: 0.0863  data: 0.0001  max mem: 10917
[10:34:29.046455] Test:  [150/345]  eta: 0:00:16  loss: 0.7115 (0.7081)  time: 0.0868  data: 0.0001  max mem: 10917
[10:34:29.918981] Test:  [160/345]  eta: 0:00:15  loss: 0.7095 (0.7083)  time: 0.0871  data: 0.0001  max mem: 10917
[10:34:30.796364] Test:  [170/345]  eta: 0:00:14  loss: 0.7068 (0.7083)  time: 0.0874  data: 0.0001  max mem: 10917
[10:34:31.676090] Test:  [180/345]  eta: 0:00:14  loss: 0.7111 (0.7084)  time: 0.0878  data: 0.0001  max mem: 10917
[10:34:32.558856] Test:  [190/345]  eta: 0:00:13  loss: 0.7114 (0.7083)  time: 0.0881  data: 0.0001  max mem: 10917
[10:34:33.445695] Test:  [200/345]  eta: 0:00:12  loss: 0.7054 (0.7083)  time: 0.0884  data: 0.0001  max mem: 10917
[10:34:34.335435] Test:  [210/345]  eta: 0:00:11  loss: 0.7065 (0.7081)  time: 0.0888  data: 0.0001  max mem: 10917
[10:34:35.229491] Test:  [220/345]  eta: 0:00:10  loss: 0.7069 (0.7082)  time: 0.0891  data: 0.0001  max mem: 10917
[10:34:36.126918] Test:  [230/345]  eta: 0:00:09  loss: 0.7098 (0.7083)  time: 0.0895  data: 0.0001  max mem: 10917
[10:34:37.028489] Test:  [240/345]  eta: 0:00:09  loss: 0.7065 (0.7083)  time: 0.0899  data: 0.0001  max mem: 10917
[10:34:37.932774] Test:  [250/345]  eta: 0:00:08  loss: 0.7063 (0.7084)  time: 0.0902  data: 0.0001  max mem: 10917
[10:34:38.840553] Test:  [260/345]  eta: 0:00:07  loss: 0.7051 (0.7084)  time: 0.0906  data: 0.0001  max mem: 10917
[10:34:39.752832] Test:  [270/345]  eta: 0:00:06  loss: 0.7098 (0.7086)  time: 0.0910  data: 0.0001  max mem: 10917
[10:34:40.667892] Test:  [280/345]  eta: 0:00:05  loss: 0.7106 (0.7086)  time: 0.0913  data: 0.0001  max mem: 10917
[10:34:41.586804] Test:  [290/345]  eta: 0:00:04  loss: 0.7068 (0.7086)  time: 0.0917  data: 0.0001  max mem: 10917
[10:34:42.509455] Test:  [300/345]  eta: 0:00:03  loss: 0.7090 (0.7089)  time: 0.0920  data: 0.0001  max mem: 10917
[10:34:43.435230] Test:  [310/345]  eta: 0:00:03  loss: 0.7085 (0.7089)  time: 0.0924  data: 0.0001  max mem: 10917
[10:34:44.363901] Test:  [320/345]  eta: 0:00:02  loss: 0.7024 (0.7088)  time: 0.0927  data: 0.0001  max mem: 10917
[10:34:45.296468] Test:  [330/345]  eta: 0:00:01  loss: 0.7025 (0.7087)  time: 0.0930  data: 0.0001  max mem: 10917
[10:34:46.232351] Test:  [340/345]  eta: 0:00:00  loss: 0.7106 (0.7088)  time: 0.0934  data: 0.0001  max mem: 10917
[10:34:46.608193] Test:  [344/345]  eta: 0:00:00  loss: 0.7088 (0.7087)  time: 0.0935  data: 0.0001  max mem: 10917
[10:34:46.663721] Test: Total time: 0:00:30 (0.0885 s / it)
[10:34:57.143028] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8900 (0.8900)  time: 0.2218  data: 0.1418  max mem: 10917
[10:34:57.956287] Test:  [10/57]  eta: 0:00:04  loss: 0.9183 (0.9243)  time: 0.0940  data: 0.0130  max mem: 10917
[10:34:58.773277] Test:  [20/57]  eta: 0:00:03  loss: 0.9188 (0.9101)  time: 0.0814  data: 0.0001  max mem: 10917
[10:34:59.594867] Test:  [30/57]  eta: 0:00:02  loss: 0.7992 (0.8676)  time: 0.0819  data: 0.0001  max mem: 10917
[10:35:00.419127] Test:  [40/57]  eta: 0:00:01  loss: 0.7840 (0.8456)  time: 0.0822  data: 0.0001  max mem: 10917
[10:35:01.248356] Test:  [50/57]  eta: 0:00:00  loss: 0.7764 (0.8371)  time: 0.0826  data: 0.0001  max mem: 10917
[10:35:01.698060] Test:  [56/57]  eta: 0:00:00  loss: 0.8067 (0.8438)  time: 0.0804  data: 0.0001  max mem: 10917
[10:35:01.755486] Test: Total time: 0:00:04 (0.0848 s / it)
[10:35:03.528908] Dice score of the network on the train images: 0.830910, val images: 0.811053
[10:35:03.532534] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:35:03.926552] Epoch: [45]  [  0/345]  eta: 0:02:15  lr: 0.000008  loss: 0.7347 (0.7347)  time: 0.3930  data: 0.1404  max mem: 10917

[10:35:08.922025] Epoch: [45]  [ 20/345]  eta: 0:01:23  lr: 0.000008  loss: 0.7391 (0.7401)  time: 0.2497  data: 0.0001  max mem: 10917
[10:35:13.920745] Epoch: [45]  [ 40/345]  eta: 0:01:17  lr: 0.000008  loss: 0.7317 (0.7369)  time: 0.2499  data: 0.0001  max mem: 10917
[10:35:18.906085] Epoch: [45]  [ 60/345]  eta: 0:01:11  lr: 0.000008  loss: 0.7337 (0.7365)  time: 0.2492  data: 0.0001  max mem: 10917
[10:35:23.904479] Epoch: [45]  [ 80/345]  eta: 0:01:06  lr: 0.000008  loss: 0.7397 (0.7372)  time: 0.2499  data: 0.0001  max mem: 10917
[10:35:28.907615] Epoch: [45]  [100/345]  eta: 0:01:01  lr: 0.000007  loss: 0.7425 (0.7378)  time: 0.2501  data: 0.0001  max mem: 10917
[10:35:33.912072] Epoch: [45]  [120/345]  eta: 0:00:56  lr: 0.000007  loss: 0.7362 (0.7378)  time: 0.2502  data: 0.0000  max mem: 10917
[10:35:38.932426] Epoch: [45]  [140/345]  eta: 0:00:51  lr: 0.000007  loss: 0.7414 (0.7388)  time: 0.2510  data: 0.0001  max mem: 10917
[10:35:44.033284] Epoch: [45]  [160/345]  eta: 0:00:46  lr: 0.000007  loss: 0.7295 (0.7380)  time: 0.2550  data: 0.0001  max mem: 10917
[10:35:49.064234] Epoch: [45]  [180/345]  eta: 0:00:41  lr: 0.000007  loss: 0.7372 (0.7377)  time: 0.2515  data: 0.0000  max mem: 10917
[10:35:54.102161] Epoch: [45]  [200/345]  eta: 0:00:36  lr: 0.000007  loss: 0.7396 (0.7381)  time: 0.2519  data: 0.0001  max mem: 10917
[10:35:59.126292] Epoch: [45]  [220/345]  eta: 0:00:31  lr: 0.000006  loss: 0.7372 (0.7380)  time: 0.2512  data: 0.0001  max mem: 10917
[10:36:04.151661] Epoch: [45]  [240/345]  eta: 0:00:26  lr: 0.000006  loss: 0.7359 (0.7380)  time: 0.2512  data: 0.0000  max mem: 10917
[10:36:09.165627] Epoch: [45]  [260/345]  eta: 0:00:21  lr: 0.000006  loss: 0.7333 (0.7381)  time: 0.2507  data: 0.0000  max mem: 10917
[10:36:14.189899] Epoch: [45]  [280/345]  eta: 0:00:16  lr: 0.000006  loss: 0.7339 (0.7381)  time: 0.2512  data: 0.0000  max mem: 10917
[10:36:19.209357] Epoch: [45]  [300/345]  eta: 0:00:11  lr: 0.000006  loss: 0.7388 (0.7383)  time: 0.2509  data: 0.0000  max mem: 10917
[10:36:24.233134] Epoch: [45]  [320/345]  eta: 0:00:06  lr: 0.000006  loss: 0.7395 (0.7383)  time: 0.2511  data: 0.0000  max mem: 10917
[10:36:29.258130] Epoch: [45]  [340/345]  eta: 0:00:01  lr: 0.000005  loss: 0.7323 (0.7382)  time: 0.2512  data: 0.0000  max mem: 10917
[10:36:30.264601] Epoch: [45]  [344/345]  eta: 0:00:00  lr: 0.000005  loss: 0.7397 (0.7381)  time: 0.2513  data: 0.0001  max mem: 10917
[10:36:30.326199] Epoch: [45] Total time: 0:01:26 (0.2516 s / it)
[10:36:30.326649] Averaged stats: lr: 0.000005  loss: 0.7397 (0.7381)
[10:36:30.558515] Test:  [  0/345]  eta: 0:01:18  loss: 0.6934 (0.6934)  time: 0.2288  data: 0.1491  max mem: 10917
[10:36:31.390849] Test:  [ 10/345]  eta: 0:00:32  loss: 0.6997 (0.7035)  time: 0.0964  data: 0.0147  max mem: 10917
[10:36:32.214353] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7028 (0.7047)  time: 0.0827  data: 0.0006  max mem: 10917
[10:36:33.042208] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7020 (0.7034)  time: 0.0825  data: 0.0001  max mem: 10917
[10:36:33.872499] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7008 (0.7031)  time: 0.0829  data: 0.0001  max mem: 10917
[10:36:34.706542] Test:  [ 50/345]  eta: 0:00:25  loss: 0.6975 (0.7032)  time: 0.0832  data: 0.0001  max mem: 10917
[10:36:35.544711] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7047 (0.7043)  time: 0.0836  data: 0.0001  max mem: 10917
[10:36:36.385861] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7119 (0.7051)  time: 0.0839  data: 0.0001  max mem: 10917
[10:36:37.230667] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7110 (0.7057)  time: 0.0843  data: 0.0001  max mem: 10917
[10:36:38.080028] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7029 (0.7056)  time: 0.0847  data: 0.0001  max mem: 10917
[10:36:38.932442] Test:  [100/345]  eta: 0:00:20  loss: 0.7051 (0.7057)  time: 0.0850  data: 0.0001  max mem: 10917
[10:36:39.788193] Test:  [110/345]  eta: 0:00:20  loss: 0.7081 (0.7063)  time: 0.0854  data: 0.0001  max mem: 10917
[10:36:40.646747] Test:  [120/345]  eta: 0:00:19  loss: 0.7065 (0.7063)  time: 0.0857  data: 0.0001  max mem: 10917
[10:36:41.509118] Test:  [130/345]  eta: 0:00:18  loss: 0.7065 (0.7062)  time: 0.0860  data: 0.0001  max mem: 10917
[10:36:42.375361] Test:  [140/345]  eta: 0:00:17  loss: 0.7101 (0.7069)  time: 0.0864  data: 0.0001  max mem: 10917
[10:36:43.244739] Test:  [150/345]  eta: 0:00:16  loss: 0.7113 (0.7072)  time: 0.0867  data: 0.0001  max mem: 10917
[10:36:44.117520] Test:  [160/345]  eta: 0:00:15  loss: 0.7033 (0.7066)  time: 0.0871  data: 0.0001  max mem: 10917
[10:36:44.993630] Test:  [170/345]  eta: 0:00:14  loss: 0.7027 (0.7064)  time: 0.0874  data: 0.0001  max mem: 10917
[10:36:45.873445] Test:  [180/345]  eta: 0:00:14  loss: 0.7053 (0.7066)  time: 0.0877  data: 0.0001  max mem: 10917
[10:36:46.756839] Test:  [190/345]  eta: 0:00:13  loss: 0.7093 (0.7067)  time: 0.0881  data: 0.0001  max mem: 10917
[10:36:47.643946] Test:  [200/345]  eta: 0:00:12  loss: 0.7076 (0.7070)  time: 0.0885  data: 0.0001  max mem: 10917
[10:36:48.534233] Test:  [210/345]  eta: 0:00:11  loss: 0.7083 (0.7074)  time: 0.0888  data: 0.0001  max mem: 10917
[10:36:49.428152] Test:  [220/345]  eta: 0:00:10  loss: 0.7126 (0.7075)  time: 0.0892  data: 0.0001  max mem: 10917
[10:36:50.325287] Test:  [230/345]  eta: 0:00:09  loss: 0.7011 (0.7073)  time: 0.0895  data: 0.0001  max mem: 10917
[10:36:51.225835] Test:  [240/345]  eta: 0:00:09  loss: 0.7003 (0.7073)  time: 0.0898  data: 0.0001  max mem: 10917
[10:36:52.129675] Test:  [250/345]  eta: 0:00:08  loss: 0.7063 (0.7074)  time: 0.0902  data: 0.0001  max mem: 10917
[10:36:53.038002] Test:  [260/345]  eta: 0:00:07  loss: 0.7093 (0.7075)  time: 0.0906  data: 0.0001  max mem: 10917
[10:36:53.950083] Test:  [270/345]  eta: 0:00:06  loss: 0.7086 (0.7075)  time: 0.0909  data: 0.0001  max mem: 10917
[10:36:54.865495] Test:  [280/345]  eta: 0:00:05  loss: 0.7031 (0.7075)  time: 0.0913  data: 0.0001  max mem: 10917
[10:36:55.784032] Test:  [290/345]  eta: 0:00:04  loss: 0.7098 (0.7077)  time: 0.0917  data: 0.0001  max mem: 10917
[10:36:56.706412] Test:  [300/345]  eta: 0:00:03  loss: 0.7100 (0.7078)  time: 0.0920  data: 0.0001  max mem: 10917
[10:36:57.631751] Test:  [310/345]  eta: 0:00:03  loss: 0.7045 (0.7078)  time: 0.0923  data: 0.0001  max mem: 10917
[10:36:58.560295] Test:  [320/345]  eta: 0:00:02  loss: 0.7045 (0.7077)  time: 0.0926  data: 0.0001  max mem: 10917
[10:36:59.492512] Test:  [330/345]  eta: 0:00:01  loss: 0.7054 (0.7077)  time: 0.0930  data: 0.0001  max mem: 10917
[10:37:00.428760] Test:  [340/345]  eta: 0:00:00  loss: 0.7054 (0.7078)  time: 0.0934  data: 0.0001  max mem: 10917
[10:37:00.804433] Test:  [344/345]  eta: 0:00:00  loss: 0.7080 (0.7079)  time: 0.0935  data: 0.0001  max mem: 10917
[10:37:00.859928] Test: Total time: 0:00:30 (0.0885 s / it)
[10:37:11.293047] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8896 (0.8896)  time: 0.2210  data: 0.1412  max mem: 10917
[10:37:12.108071] Test:  [10/57]  eta: 0:00:04  loss: 0.9180 (0.9241)  time: 0.0941  data: 0.0130  max mem: 10917
[10:37:12.924720] Test:  [20/57]  eta: 0:00:03  loss: 0.9180 (0.9092)  time: 0.0815  data: 0.0001  max mem: 10917
[10:37:13.744775] Test:  [30/57]  eta: 0:00:02  loss: 0.7987 (0.8671)  time: 0.0818  data: 0.0001  max mem: 10917
[10:37:14.569511] Test:  [40/57]  eta: 0:00:01  loss: 0.7853 (0.8454)  time: 0.0822  data: 0.0001  max mem: 10917
[10:37:15.397628] Test:  [50/57]  eta: 0:00:00  loss: 0.7780 (0.8371)  time: 0.0826  data: 0.0001  max mem: 10917
[10:37:15.847569] Test:  [56/57]  eta: 0:00:00  loss: 0.8061 (0.8440)  time: 0.0804  data: 0.0001  max mem: 10917
[10:37:15.905556] Test: Total time: 0:00:04 (0.0848 s / it)
[10:37:17.679997] Dice score of the network on the train images: 0.831622, val images: 0.810238
[10:37:17.683765] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:37:18.078652] Epoch: [46]  [  0/345]  eta: 0:02:15  lr: 0.000005  loss: 0.7461 (0.7461)  time: 0.3938  data: 0.1409  max mem: 10917
[10:37:23.084705] Epoch: [46]  [ 20/345]  eta: 0:01:23  lr: 0.000005  loss: 0.7370 (0.7363)  time: 0.2503  data: 0.0001  max mem: 10917
[10:37:28.091923] Epoch: [46]  [ 40/345]  eta: 0:01:17  lr: 0.000005  loss: 0.7357 (0.7373)  time: 0.2503  data: 0.0001  max mem: 10917
[10:37:33.098418] Epoch: [46]  [ 60/345]  eta: 0:01:12  lr: 0.000005  loss: 0.7439 (0.7396)  time: 0.2503  data: 0.0001  max mem: 10917
[10:37:38.112517] Epoch: [46]  [ 80/345]  eta: 0:01:06  lr: 0.000005  loss: 0.7335 (0.7388)  time: 0.2507  data: 0.0001  max mem: 10917

[10:37:43.130439] Epoch: [46]  [100/345]  eta: 0:01:01  lr: 0.000005  loss: 0.7342 (0.7382)  time: 0.2509  data: 0.0001  max mem: 10917
[10:37:48.150693] Epoch: [46]  [120/345]  eta: 0:00:56  lr: 0.000005  loss: 0.7345 (0.7377)  time: 0.2510  data: 0.0001  max mem: 10917

[10:37:53.174446] Epoch: [46]  [140/345]  eta: 0:00:51  lr: 0.000004  loss: 0.7367 (0.7379)  time: 0.2512  data: 0.0001  max mem: 10917
[10:37:58.197795] Epoch: [46]  [160/345]  eta: 0:00:46  lr: 0.000004  loss: 0.7384 (0.7381)  time: 0.2511  data: 0.0000  max mem: 10917
[10:38:03.226802] Epoch: [46]  [180/345]  eta: 0:00:41  lr: 0.000004  loss: 0.7378 (0.7384)  time: 0.2514  data: 0.0001  max mem: 10917
[10:38:08.263436] Epoch: [46]  [200/345]  eta: 0:00:36  lr: 0.000004  loss: 0.7320 (0.7379)  time: 0.2518  data: 0.0001  max mem: 10917
[10:38:13.281806] Epoch: [46]  [220/345]  eta: 0:00:31  lr: 0.000004  loss: 0.7340 (0.7379)  time: 0.2509  data: 0.0000  max mem: 10917
[10:38:18.298761] Epoch: [46]  [240/345]  eta: 0:00:26  lr: 0.000004  loss: 0.7372 (0.7382)  time: 0.2508  data: 0.0001  max mem: 10917
[10:38:23.317006] Epoch: [46]  [260/345]  eta: 0:00:21  lr: 0.000004  loss: 0.7353 (0.7380)  time: 0.2509  data: 0.0001  max mem: 10917
[10:38:28.338514] Epoch: [46]  [280/345]  eta: 0:00:16  lr: 0.000003  loss: 0.7377 (0.7380)  time: 0.2510  data: 0.0001  max mem: 10917
[10:38:33.373030] Epoch: [46]  [300/345]  eta: 0:00:11  lr: 0.000003  loss: 0.7314 (0.7376)  time: 0.2517  data: 0.0001  max mem: 10917
[10:38:38.412302] Epoch: [46]  [320/345]  eta: 0:00:06  lr: 0.000003  loss: 0.7356 (0.7376)  time: 0.2519  data: 0.0001  max mem: 10917
[10:38:43.443523] Epoch: [46]  [340/345]  eta: 0:00:01  lr: 0.000003  loss: 0.7380 (0.7378)  time: 0.2515  data: 0.0001  max mem: 10917
[10:38:44.449852] Epoch: [46]  [344/345]  eta: 0:00:00  lr: 0.000003  loss: 0.7364 (0.7377)  time: 0.2513  data: 0.0001  max mem: 10917
[10:38:44.505724] Epoch: [46] Total time: 0:01:26 (0.2517 s / it)
[10:38:44.506188] Averaged stats: lr: 0.000003  loss: 0.7364 (0.7377)
[10:38:44.736865] Test:  [  0/345]  eta: 0:01:18  loss: 0.7003 (0.7003)  time: 0.2279  data: 0.1479  max mem: 10917
[10:38:45.563358] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7086 (0.7076)  time: 0.0958  data: 0.0140  max mem: 10917
[10:38:46.387268] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7062 (0.7037)  time: 0.0825  data: 0.0003  max mem: 10917
[10:38:47.215469] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7037 (0.7043)  time: 0.0826  data: 0.0001  max mem: 10917
[10:38:48.045989] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7048 (0.7048)  time: 0.0829  data: 0.0001  max mem: 10917
[10:38:48.880773] Test:  [ 50/345]  eta: 0:00:25  loss: 0.6991 (0.7041)  time: 0.0832  data: 0.0001  max mem: 10917
[10:38:49.719395] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7059 (0.7052)  time: 0.0836  data: 0.0001  max mem: 10917
[10:38:50.561214] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7096 (0.7057)  time: 0.0840  data: 0.0001  max mem: 10917
[10:38:51.405404] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7075 (0.7061)  time: 0.0843  data: 0.0001  max mem: 10917
[10:38:52.253858] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7068 (0.7061)  time: 0.0846  data: 0.0001  max mem: 10917
[10:38:53.106267] Test:  [100/345]  eta: 0:00:20  loss: 0.7012 (0.7060)  time: 0.0850  data: 0.0001  max mem: 10917
[10:38:53.961908] Test:  [110/345]  eta: 0:00:20  loss: 0.7012 (0.7063)  time: 0.0854  data: 0.0001  max mem: 10917
[10:38:54.821025] Test:  [120/345]  eta: 0:00:19  loss: 0.7078 (0.7067)  time: 0.0857  data: 0.0001  max mem: 10917
[10:38:55.683099] Test:  [130/345]  eta: 0:00:18  loss: 0.7089 (0.7067)  time: 0.0860  data: 0.0001  max mem: 10917
[10:38:56.548471] Test:  [140/345]  eta: 0:00:17  loss: 0.7089 (0.7071)  time: 0.0863  data: 0.0001  max mem: 10917
[10:38:57.417908] Test:  [150/345]  eta: 0:00:16  loss: 0.7089 (0.7070)  time: 0.0867  data: 0.0001  max mem: 10917
[10:38:58.289784] Test:  [160/345]  eta: 0:00:15  loss: 0.7089 (0.7072)  time: 0.0870  data: 0.0001  max mem: 10917
[10:38:59.165613] Test:  [170/345]  eta: 0:00:14  loss: 0.7106 (0.7075)  time: 0.0873  data: 0.0001  max mem: 10917
[10:39:00.045627] Test:  [180/345]  eta: 0:00:14  loss: 0.7039 (0.7071)  time: 0.0877  data: 0.0001  max mem: 10917
[10:39:00.928314] Test:  [190/345]  eta: 0:00:13  loss: 0.7039 (0.7075)  time: 0.0881  data: 0.0001  max mem: 10917
[10:39:01.815291] Test:  [200/345]  eta: 0:00:12  loss: 0.7102 (0.7076)  time: 0.0884  data: 0.0001  max mem: 10917
[10:39:02.705844] Test:  [210/345]  eta: 0:00:11  loss: 0.7122 (0.7077)  time: 0.0888  data: 0.0001  max mem: 10917
[10:39:03.599471] Test:  [220/345]  eta: 0:00:10  loss: 0.7048 (0.7078)  time: 0.0892  data: 0.0001  max mem: 10917
[10:39:04.497096] Test:  [230/345]  eta: 0:00:09  loss: 0.7087 (0.7080)  time: 0.0895  data: 0.0001  max mem: 10917
[10:39:05.397866] Test:  [240/345]  eta: 0:00:09  loss: 0.7070 (0.7079)  time: 0.0899  data: 0.0001  max mem: 10917
[10:39:06.302129] Test:  [250/345]  eta: 0:00:08  loss: 0.7013 (0.7075)  time: 0.0902  data: 0.0001  max mem: 10917
[10:39:07.209368] Test:  [260/345]  eta: 0:00:07  loss: 0.7013 (0.7076)  time: 0.0905  data: 0.0001  max mem: 10917
[10:39:08.120513] Test:  [270/345]  eta: 0:00:06  loss: 0.7053 (0.7075)  time: 0.0909  data: 0.0001  max mem: 10917
[10:39:09.034999] Test:  [280/345]  eta: 0:00:05  loss: 0.7011 (0.7072)  time: 0.0912  data: 0.0001  max mem: 10917
[10:39:09.953896] Test:  [290/345]  eta: 0:00:04  loss: 0.7014 (0.7072)  time: 0.0916  data: 0.0001  max mem: 10917
[10:39:10.876582] Test:  [300/345]  eta: 0:00:03  loss: 0.7078 (0.7073)  time: 0.0920  data: 0.0001  max mem: 10917
[10:39:11.802084] Test:  [310/345]  eta: 0:00:03  loss: 0.7081 (0.7073)  time: 0.0924  data: 0.0001  max mem: 10917
[10:39:12.731019] Test:  [320/345]  eta: 0:00:02  loss: 0.7084 (0.7074)  time: 0.0927  data: 0.0001  max mem: 10917
[10:39:13.662969] Test:  [330/345]  eta: 0:00:01  loss: 0.7065 (0.7075)  time: 0.0930  data: 0.0001  max mem: 10917
[10:39:14.598231] Test:  [340/345]  eta: 0:00:00  loss: 0.7094 (0.7077)  time: 0.0933  data: 0.0001  max mem: 10917
[10:39:14.973782] Test:  [344/345]  eta: 0:00:00  loss: 0.7137 (0.7078)  time: 0.0935  data: 0.0001  max mem: 10917
[10:39:15.027877] Test: Total time: 0:00:30 (0.0885 s / it)
[10:39:25.469940] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8884 (0.8884)  time: 0.2219  data: 0.1417  max mem: 10917
[10:39:26.286598] Test:  [10/57]  eta: 0:00:04  loss: 0.9186 (0.9243)  time: 0.0943  data: 0.0132  max mem: 10917
[10:39:27.103795] Test:  [20/57]  eta: 0:00:03  loss: 0.9186 (0.9097)  time: 0.0816  data: 0.0002  max mem: 10917
[10:39:27.925124] Test:  [30/57]  eta: 0:00:02  loss: 0.7990 (0.8675)  time: 0.0819  data: 0.0001  max mem: 10917
[10:39:28.749526] Test:  [40/57]  eta: 0:00:01  loss: 0.7853 (0.8457)  time: 0.0822  data: 0.0001  max mem: 10917
[10:39:29.577886] Test:  [50/57]  eta: 0:00:00  loss: 0.7787 (0.8375)  time: 0.0826  data: 0.0001  max mem: 10917
[10:39:30.027563] Test:  [56/57]  eta: 0:00:00  loss: 0.8084 (0.8447)  time: 0.0804  data: 0.0001  max mem: 10917
[10:39:30.085915] Test: Total time: 0:00:04 (0.0849 s / it)
[10:39:31.852819] Dice score of the network on the train images: 0.831508, val images: 0.810105
[10:39:31.856264] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:39:32.247084] Epoch: [47]  [  0/345]  eta: 0:02:14  lr: 0.000003  loss: 0.7416 (0.7416)  time: 0.3898  data: 0.1387  max mem: 10917
[10:39:37.233175] Epoch: [47]  [ 20/345]  eta: 0:01:23  lr: 0.000003  loss: 0.7361 (0.7370)  time: 0.2492  data: 0.0001  max mem: 10917
[10:39:42.218860] Epoch: [47]  [ 40/345]  eta: 0:01:17  lr: 0.000003  loss: 0.7386 (0.7386)  time: 0.2492  data: 0.0001  max mem: 10917
[10:39:47.212653] Epoch: [47]  [ 60/345]  eta: 0:01:11  lr: 0.000003  loss: 0.7386 (0.7396)  time: 0.2496  data: 0.0001  max mem: 10917
[10:39:52.211766] Epoch: [47]  [ 80/345]  eta: 0:01:06  lr: 0.000003  loss: 0.7396 (0.7393)  time: 0.2499  data: 0.0001  max mem: 10917
[10:39:57.211359] Epoch: [47]  [100/345]  eta: 0:01:01  lr: 0.000003  loss: 0.7364 (0.7390)  time: 0.2499  data: 0.0001  max mem: 10917
[10:40:02.214646] Epoch: [47]  [120/345]  eta: 0:00:56  lr: 0.000002  loss: 0.7281 (0.7376)  time: 0.2501  data: 0.0001  max mem: 10917
[10:40:07.221471] Epoch: [47]  [140/345]  eta: 0:00:51  lr: 0.000002  loss: 0.7330 (0.7370)  time: 0.2503  data: 0.0001  max mem: 10917
[10:40:12.232909] Epoch: [47]  [160/345]  eta: 0:00:46  lr: 0.000002  loss: 0.7379 (0.7375)  time: 0.2505  data: 0.0001  max mem: 10917
[10:40:17.246692] Epoch: [47]  [180/345]  eta: 0:00:41  lr: 0.000002  loss: 0.7374 (0.7378)  time: 0.2506  data: 0.0001  max mem: 10917
[10:40:22.261039] Epoch: [47]  [200/345]  eta: 0:00:36  lr: 0.000002  loss: 0.7368 (0.7378)  time: 0.2507  data: 0.0001  max mem: 10917
[10:40:27.275145] Epoch: [47]  [220/345]  eta: 0:00:31  lr: 0.000002  loss: 0.7359 (0.7376)  time: 0.2507  data: 0.0000  max mem: 10917
[10:40:32.292530] Epoch: [47]  [240/345]  eta: 0:00:26  lr: 0.000002  loss: 0.7366 (0.7376)  time: 0.2508  data: 0.0001  max mem: 10917
[10:40:37.312667] Epoch: [47]  [260/345]  eta: 0:00:21  lr: 0.000002  loss: 0.7371 (0.7377)  time: 0.2510  data: 0.0001  max mem: 10917
[10:40:42.332901] Epoch: [47]  [280/345]  eta: 0:00:16  lr: 0.000002  loss: 0.7330 (0.7375)  time: 0.2510  data: 0.0001  max mem: 10917
[10:40:47.355765] Epoch: [47]  [300/345]  eta: 0:00:11  lr: 0.000002  loss: 0.7382 (0.7379)  time: 0.2511  data: 0.0001  max mem: 10917
[10:40:52.379041] Epoch: [47]  [320/345]  eta: 0:00:06  lr: 0.000001  loss: 0.7293 (0.7375)  time: 0.2511  data: 0.0001  max mem: 10917
[10:40:57.402108] Epoch: [47]  [340/345]  eta: 0:00:01  lr: 0.000001  loss: 0.7351 (0.7374)  time: 0.2511  data: 0.0000  max mem: 10917
[10:40:58.407992] Epoch: [47]  [344/345]  eta: 0:00:00  lr: 0.000001  loss: 0.7441 (0.7374)  time: 0.2512  data: 0.0001  max mem: 10917
[10:40:58.444830] Epoch: [47] Total time: 0:01:26 (0.2510 s / it)
[10:40:58.445051] Averaged stats: lr: 0.000001  loss: 0.7441 (0.7374)
[10:40:58.676813] Test:  [  0/345]  eta: 0:01:19  loss: 0.6990 (0.6990)  time: 0.2292  data: 0.1492  max mem: 10917
[10:40:59.496337] Test:  [ 10/345]  eta: 0:00:31  loss: 0.7045 (0.7124)  time: 0.0953  data: 0.0136  max mem: 10917
[10:41:00.319096] Test:  [ 20/345]  eta: 0:00:28  loss: 0.7061 (0.7086)  time: 0.0821  data: 0.0001  max mem: 10917
[10:41:01.145273] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7052 (0.7072)  time: 0.0824  data: 0.0001  max mem: 10917
[10:41:01.976029] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7067 (0.7086)  time: 0.0828  data: 0.0001  max mem: 10917
[10:41:02.809310] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7079 (0.7085)  time: 0.0832  data: 0.0001  max mem: 10917
[10:41:03.646421] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7082 (0.7082)  time: 0.0835  data: 0.0001  max mem: 10917
[10:41:04.487831] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7082 (0.7084)  time: 0.0839  data: 0.0001  max mem: 10917
[10:41:05.332288] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7072 (0.7076)  time: 0.0842  data: 0.0001  max mem: 10917
[10:41:06.179550] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7003 (0.7068)  time: 0.0845  data: 0.0001  max mem: 10917
[10:41:07.031181] Test:  [100/345]  eta: 0:00:20  loss: 0.6996 (0.7065)  time: 0.0849  data: 0.0001  max mem: 10917
[10:41:07.885623] Test:  [110/345]  eta: 0:00:19  loss: 0.7022 (0.7066)  time: 0.0853  data: 0.0001  max mem: 10917
[10:41:08.744334] Test:  [120/345]  eta: 0:00:19  loss: 0.7064 (0.7069)  time: 0.0856  data: 0.0001  max mem: 10917
[10:41:09.606543] Test:  [130/345]  eta: 0:00:18  loss: 0.7064 (0.7066)  time: 0.0860  data: 0.0001  max mem: 10917
[10:41:10.471868] Test:  [140/345]  eta: 0:00:17  loss: 0.7015 (0.7065)  time: 0.0863  data: 0.0001  max mem: 10917
[10:41:11.340870] Test:  [150/345]  eta: 0:00:16  loss: 0.7024 (0.7064)  time: 0.0867  data: 0.0001  max mem: 10917
[10:41:12.213147] Test:  [160/345]  eta: 0:00:15  loss: 0.7070 (0.7066)  time: 0.0870  data: 0.0001  max mem: 10917
[10:41:13.088758] Test:  [170/345]  eta: 0:00:14  loss: 0.7117 (0.7069)  time: 0.0873  data: 0.0001  max mem: 10917
[10:41:13.968226] Test:  [180/345]  eta: 0:00:14  loss: 0.7105 (0.7070)  time: 0.0877  data: 0.0001  max mem: 10917
[10:41:14.850865] Test:  [190/345]  eta: 0:00:13  loss: 0.7049 (0.7068)  time: 0.0881  data: 0.0001  max mem: 10917
[10:41:15.737625] Test:  [200/345]  eta: 0:00:12  loss: 0.7059 (0.7068)  time: 0.0884  data: 0.0001  max mem: 10917
[10:41:16.627194] Test:  [210/345]  eta: 0:00:11  loss: 0.7078 (0.7067)  time: 0.0888  data: 0.0001  max mem: 10917
[10:41:17.520494] Test:  [220/345]  eta: 0:00:10  loss: 0.7092 (0.7070)  time: 0.0891  data: 0.0001  max mem: 10917
[10:41:18.417298] Test:  [230/345]  eta: 0:00:09  loss: 0.7059 (0.7069)  time: 0.0895  data: 0.0001  max mem: 10917
[10:41:19.317803] Test:  [240/345]  eta: 0:00:09  loss: 0.7088 (0.7073)  time: 0.0898  data: 0.0001  max mem: 10917
[10:41:20.221831] Test:  [250/345]  eta: 0:00:08  loss: 0.7088 (0.7072)  time: 0.0902  data: 0.0001  max mem: 10917
[10:41:21.129405] Test:  [260/345]  eta: 0:00:07  loss: 0.7101 (0.7074)  time: 0.0905  data: 0.0001  max mem: 10917
[10:41:22.041199] Test:  [270/345]  eta: 0:00:06  loss: 0.7084 (0.7074)  time: 0.0909  data: 0.0001  max mem: 10917
[10:41:22.955877] Test:  [280/345]  eta: 0:00:05  loss: 0.7067 (0.7074)  time: 0.0913  data: 0.0001  max mem: 10917
[10:41:23.874173] Test:  [290/345]  eta: 0:00:04  loss: 0.7095 (0.7075)  time: 0.0916  data: 0.0001  max mem: 10917
[10:41:24.796282] Test:  [300/345]  eta: 0:00:03  loss: 0.7111 (0.7076)  time: 0.0920  data: 0.0001  max mem: 10917
[10:41:25.720656] Test:  [310/345]  eta: 0:00:03  loss: 0.7052 (0.7076)  time: 0.0923  data: 0.0001  max mem: 10917
[10:41:26.649256] Test:  [320/345]  eta: 0:00:02  loss: 0.7028 (0.7075)  time: 0.0926  data: 0.0001  max mem: 10917
[10:41:27.581702] Test:  [330/345]  eta: 0:00:01  loss: 0.7024 (0.7074)  time: 0.0930  data: 0.0001  max mem: 10917
[10:41:28.517575] Test:  [340/345]  eta: 0:00:00  loss: 0.7060 (0.7075)  time: 0.0934  data: 0.0001  max mem: 10917
[10:41:28.893038] Test:  [344/345]  eta: 0:00:00  loss: 0.7045 (0.7075)  time: 0.0935  data: 0.0001  max mem: 10917
[10:41:28.948828] Test: Total time: 0:00:30 (0.0884 s / it)
[10:41:39.431858] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8897 (0.8897)  time: 0.2186  data: 0.1386  max mem: 10917
[10:41:40.245627] Test:  [10/57]  eta: 0:00:04  loss: 0.9197 (0.9256)  time: 0.0938  data: 0.0127  max mem: 10917
[10:41:41.063583] Test:  [20/57]  eta: 0:00:03  loss: 0.9197 (0.9104)  time: 0.0815  data: 0.0001  max mem: 10917
[10:41:41.884639] Test:  [30/57]  eta: 0:00:02  loss: 0.7997 (0.8682)  time: 0.0819  data: 0.0001  max mem: 10917
[10:41:42.708659] Test:  [40/57]  eta: 0:00:01  loss: 0.7870 (0.8464)  time: 0.0822  data: 0.0001  max mem: 10917
[10:41:43.537010] Test:  [50/57]  eta: 0:00:00  loss: 0.7800 (0.8383)  time: 0.0826  data: 0.0001  max mem: 10917
[10:41:43.987015] Test:  [56/57]  eta: 0:00:00  loss: 0.8081 (0.8456)  time: 0.0804  data: 0.0001  max mem: 10917
[10:41:44.041782] Test: Total time: 0:00:04 (0.0847 s / it)
[10:41:45.782468] Dice score of the network on the train images: 0.831065, val images: 0.808782
[10:41:45.785971] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:41:46.179773] Epoch: [48]  [  0/345]  eta: 0:02:15  lr: 0.000001  loss: 0.7464 (0.7464)  time: 0.3927  data: 0.1414  max mem: 10917
[10:41:51.165693] Epoch: [48]  [ 20/345]  eta: 0:01:23  lr: 0.000001  loss: 0.7312 (0.7368)  time: 0.2492  data: 0.0001  max mem: 10917
[10:41:56.153946] Epoch: [48]  [ 40/345]  eta: 0:01:17  lr: 0.000001  loss: 0.7373 (0.7369)  time: 0.2494  data: 0.0001  max mem: 10917
[10:42:01.141339] Epoch: [48]  [ 60/345]  eta: 0:01:11  lr: 0.000001  loss: 0.7397 (0.7373)  time: 0.2493  data: 0.0001  max mem: 10917
[10:42:06.133715] Epoch: [48]  [ 80/345]  eta: 0:01:06  lr: 0.000001  loss: 0.7345 (0.7373)  time: 0.2496  data: 0.0000  max mem: 10917
[10:42:11.143271] Epoch: [48]  [100/345]  eta: 0:01:01  lr: 0.000001  loss: 0.7444 (0.7391)  time: 0.2504  data: 0.0001  max mem: 10917
[10:42:16.151527] Epoch: [48]  [120/345]  eta: 0:00:56  lr: 0.000001  loss: 0.7392 (0.7392)  time: 0.2504  data: 0.0001  max mem: 10917
[10:42:21.172519] Epoch: [48]  [140/345]  eta: 0:00:51  lr: 0.000001  loss: 0.7366 (0.7391)  time: 0.2510  data: 0.0001  max mem: 10917
[10:42:26.199799] Epoch: [48]  [160/345]  eta: 0:00:46  lr: 0.000001  loss: 0.7404 (0.7389)  time: 0.2513  data: 0.0001  max mem: 10917
[10:42:31.226670] Epoch: [48]  [180/345]  eta: 0:00:41  lr: 0.000001  loss: 0.7402 (0.7391)  time: 0.2513  data: 0.0000  max mem: 10917
[10:42:36.254814] Epoch: [48]  [200/345]  eta: 0:00:36  lr: 0.000001  loss: 0.7335 (0.7386)  time: 0.2514  data: 0.0001  max mem: 10917
[10:42:41.285295] Epoch: [48]  [220/345]  eta: 0:00:31  lr: 0.000001  loss: 0.7335 (0.7383)  time: 0.2515  data: 0.0001  max mem: 10917
[10:42:46.319718] Epoch: [48]  [240/345]  eta: 0:00:26  lr: 0.000001  loss: 0.7342 (0.7380)  time: 0.2517  data: 0.0001  max mem: 10917
[10:42:51.356318] Epoch: [48]  [260/345]  eta: 0:00:21  lr: 0.000001  loss: 0.7330 (0.7379)  time: 0.2518  data: 0.0001  max mem: 10917
[10:42:56.394121] Epoch: [48]  [280/345]  eta: 0:00:16  lr: 0.000000  loss: 0.7321 (0.7375)  time: 0.2518  data: 0.0001  max mem: 10917
[10:43:01.418821] Epoch: [48]  [300/345]  eta: 0:00:11  lr: 0.000000  loss: 0.7336 (0.7374)  time: 0.2512  data: 0.0001  max mem: 10917
[10:43:06.442848] Epoch: [48]  [320/345]  eta: 0:00:06  lr: 0.000000  loss: 0.7321 (0.7372)  time: 0.2512  data: 0.0001  max mem: 10917
[10:43:11.468873] Epoch: [48]  [340/345]  eta: 0:00:01  lr: 0.000000  loss: 0.7348 (0.7371)  time: 0.2513  data: 0.0001  max mem: 10917
[10:43:12.473490] Epoch: [48]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.7365 (0.7372)  time: 0.2512  data: 0.0001  max mem: 10917
[10:43:12.528639] Epoch: [48] Total time: 0:01:26 (0.2514 s / it)
[10:43:12.529089] Averaged stats: lr: 0.000000  loss: 0.7365 (0.7372)
[10:43:12.761793] Test:  [  0/345]  eta: 0:01:19  loss: 0.7087 (0.7087)  time: 0.2302  data: 0.1501  max mem: 10917
[10:43:13.657981] Test:  [ 10/345]  eta: 0:00:34  loss: 0.7011 (0.7021)  time: 0.1023  data: 0.0211  max mem: 10917
[10:43:14.531319] Test:  [ 20/345]  eta: 0:00:30  loss: 0.7023 (0.7070)  time: 0.0884  data: 0.0068  max mem: 10917
[10:43:15.393912] Test:  [ 30/345]  eta: 0:00:29  loss: 0.7066 (0.7072)  time: 0.0867  data: 0.0047  max mem: 10917
[10:43:16.223338] Test:  [ 40/345]  eta: 0:00:27  loss: 0.7075 (0.7076)  time: 0.0846  data: 0.0020  max mem: 10917
[10:43:17.056916] Test:  [ 50/345]  eta: 0:00:26  loss: 0.7101 (0.7093)  time: 0.0831  data: 0.0001  max mem: 10917
[10:43:17.893406] Test:  [ 60/345]  eta: 0:00:25  loss: 0.7114 (0.7094)  time: 0.0835  data: 0.0001  max mem: 10917
[10:43:18.733342] Test:  [ 70/345]  eta: 0:00:24  loss: 0.6999 (0.7084)  time: 0.0838  data: 0.0001  max mem: 10917
[10:43:19.576479] Test:  [ 80/345]  eta: 0:00:23  loss: 0.7010 (0.7082)  time: 0.0841  data: 0.0001  max mem: 10917
[10:43:20.423846] Test:  [ 90/345]  eta: 0:00:22  loss: 0.7028 (0.7077)  time: 0.0845  data: 0.0001  max mem: 10917
[10:43:21.275338] Test:  [100/345]  eta: 0:00:21  loss: 0.7044 (0.7077)  time: 0.0849  data: 0.0001  max mem: 10917
[10:43:22.129315] Test:  [110/345]  eta: 0:00:20  loss: 0.7056 (0.7075)  time: 0.0852  data: 0.0001  max mem: 10917
[10:43:22.986735] Test:  [120/345]  eta: 0:00:19  loss: 0.7033 (0.7080)  time: 0.0855  data: 0.0001  max mem: 10917
[10:43:23.847823] Test:  [130/345]  eta: 0:00:18  loss: 0.7084 (0.7083)  time: 0.0859  data: 0.0001  max mem: 10917
[10:43:24.712530] Test:  [140/345]  eta: 0:00:17  loss: 0.7048 (0.7085)  time: 0.0862  data: 0.0001  max mem: 10917
[10:43:25.580382] Test:  [150/345]  eta: 0:00:16  loss: 0.7041 (0.7081)  time: 0.0866  data: 0.0001  max mem: 10917
[10:43:26.452134] Test:  [160/345]  eta: 0:00:15  loss: 0.7003 (0.7079)  time: 0.0869  data: 0.0001  max mem: 10917
[10:43:27.327007] Test:  [170/345]  eta: 0:00:15  loss: 0.6994 (0.7077)  time: 0.0873  data: 0.0001  max mem: 10917
[10:43:28.205711] Test:  [180/345]  eta: 0:00:14  loss: 0.7045 (0.7079)  time: 0.0876  data: 0.0001  max mem: 10917
[10:43:29.088079] Test:  [190/345]  eta: 0:00:13  loss: 0.7049 (0.7077)  time: 0.0880  data: 0.0001  max mem: 10917
[10:43:29.974920] Test:  [200/345]  eta: 0:00:12  loss: 0.7049 (0.7077)  time: 0.0884  data: 0.0001  max mem: 10917
[10:43:30.864658] Test:  [210/345]  eta: 0:00:11  loss: 0.7071 (0.7076)  time: 0.0888  data: 0.0001  max mem: 10917
[10:43:31.757384] Test:  [220/345]  eta: 0:00:10  loss: 0.7058 (0.7077)  time: 0.0891  data: 0.0001  max mem: 10917
[10:43:32.653488] Test:  [230/345]  eta: 0:00:10  loss: 0.7070 (0.7077)  time: 0.0894  data: 0.0001  max mem: 10917
[10:43:33.554033] Test:  [240/345]  eta: 0:00:09  loss: 0.7004 (0.7075)  time: 0.0898  data: 0.0001  max mem: 10917
[10:43:34.457116] Test:  [250/345]  eta: 0:00:08  loss: 0.7051 (0.7075)  time: 0.0901  data: 0.0001  max mem: 10917
[10:43:35.365393] Test:  [260/345]  eta: 0:00:07  loss: 0.7099 (0.7077)  time: 0.0905  data: 0.0001  max mem: 10917
[10:43:36.277283] Test:  [270/345]  eta: 0:00:06  loss: 0.7081 (0.7076)  time: 0.0909  data: 0.0001  max mem: 10917
[10:43:37.191216] Test:  [280/345]  eta: 0:00:05  loss: 0.7081 (0.7077)  time: 0.0912  data: 0.0001  max mem: 10917
[10:43:38.108926] Test:  [290/345]  eta: 0:00:04  loss: 0.7089 (0.7077)  time: 0.0915  data: 0.0001  max mem: 10917
[10:43:39.030430] Test:  [300/345]  eta: 0:00:03  loss: 0.7079 (0.7076)  time: 0.0919  data: 0.0001  max mem: 10917
[10:43:39.954552] Test:  [310/345]  eta: 0:00:03  loss: 0.7081 (0.7076)  time: 0.0922  data: 0.0001  max mem: 10917
[10:43:40.882013] Test:  [320/345]  eta: 0:00:02  loss: 0.7010 (0.7075)  time: 0.0925  data: 0.0001  max mem: 10917
[10:43:41.814169] Test:  [330/345]  eta: 0:00:01  loss: 0.7010 (0.7075)  time: 0.0929  data: 0.0001  max mem: 10917
[10:43:42.749051] Test:  [340/345]  eta: 0:00:00  loss: 0.7047 (0.7073)  time: 0.0933  data: 0.0001  max mem: 10917
[10:43:43.124077] Test:  [344/345]  eta: 0:00:00  loss: 0.7047 (0.7073)  time: 0.0934  data: 0.0001  max mem: 10917
[10:43:43.180738] Test: Total time: 0:00:30 (0.0888 s / it)
[10:43:53.560928] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8904 (0.8904)  time: 0.2221  data: 0.1421  max mem: 10917
[10:43:54.374801] Test:  [10/57]  eta: 0:00:04  loss: 0.9208 (0.9268)  time: 0.0941  data: 0.0130  max mem: 10917
[10:43:55.192844] Test:  [20/57]  eta: 0:00:03  loss: 0.9208 (0.9121)  time: 0.0815  data: 0.0001  max mem: 10917
[10:43:56.014609] Test:  [30/57]  eta: 0:00:02  loss: 0.8005 (0.8696)  time: 0.0819  data: 0.0001  max mem: 10917
[10:43:56.840083] Test:  [40/57]  eta: 0:00:01  loss: 0.7885 (0.8478)  time: 0.0823  data: 0.0001  max mem: 10917
[10:43:57.668456] Test:  [50/57]  eta: 0:00:00  loss: 0.7810 (0.8396)  time: 0.0826  data: 0.0001  max mem: 10917
[10:43:58.118403] Test:  [56/57]  eta: 0:00:00  loss: 0.8084 (0.8468)  time: 0.0804  data: 0.0001  max mem: 10917
[10:43:58.174452] Test: Total time: 0:00:04 (0.0848 s / it)
[10:43:59.932132] Dice score of the network on the train images: 0.833019, val images: 0.808404
[10:43:59.935160] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:44:00.328605] Epoch: [49]  [  0/345]  eta: 0:02:15  lr: 0.000000  loss: 0.7422 (0.7422)  time: 0.3926  data: 0.1397  max mem: 10917
[10:44:05.326901] Epoch: [49]  [ 20/345]  eta: 0:01:23  lr: 0.000000  loss: 0.7396 (0.7386)  time: 0.2499  data: 0.0001  max mem: 10917
[10:44:10.317763] Epoch: [49]  [ 40/345]  eta: 0:01:17  lr: 0.000000  loss: 0.7403 (0.7400)  time: 0.2495  data: 0.0001  max mem: 10917
[10:44:15.313558] Epoch: [49]  [ 60/345]  eta: 0:01:11  lr: 0.000000  loss: 0.7310 (0.7376)  time: 0.2498  data: 0.0001  max mem: 10917
[10:44:20.381645] Epoch: [49]  [ 80/345]  eta: 0:01:06  lr: 0.000000  loss: 0.7325 (0.7365)  time: 0.2534  data: 0.0001  max mem: 10917
[10:44:25.381659] Epoch: [49]  [100/345]  eta: 0:01:01  lr: 0.000000  loss: 0.7315 (0.7361)  time: 0.2500  data: 0.0001  max mem: 10917
[10:44:30.392633] Epoch: [49]  [120/345]  eta: 0:00:56  lr: 0.000000  loss: 0.7357 (0.7368)  time: 0.2505  data: 0.0001  max mem: 10917
[10:44:35.415539] Epoch: [49]  [140/345]  eta: 0:00:51  lr: 0.000000  loss: 0.7345 (0.7367)  time: 0.2511  data: 0.0001  max mem: 10917
[10:44:40.441778] Epoch: [49]  [160/345]  eta: 0:00:46  lr: 0.000000  loss: 0.7352 (0.7368)  time: 0.2513  data: 0.0001  max mem: 10917
[10:44:45.469867] Epoch: [49]  [180/345]  eta: 0:00:41  lr: 0.000000  loss: 0.7291 (0.7366)  time: 0.2514  data: 0.0001  max mem: 10917
[10:44:50.501703] Epoch: [49]  [200/345]  eta: 0:00:36  lr: 0.000000  loss: 0.7451 (0.7374)  time: 0.2516  data: 0.0000  max mem: 10917
[10:44:55.533183] Epoch: [49]  [220/345]  eta: 0:00:31  lr: 0.000000  loss: 0.7302 (0.7370)  time: 0.2515  data: 0.0000  max mem: 10917
[10:45:00.568109] Epoch: [49]  [240/345]  eta: 0:00:26  lr: 0.000000  loss: 0.7420 (0.7374)  time: 0.2517  data: 0.0000  max mem: 10917
[10:45:05.603779] Epoch: [49]  [260/345]  eta: 0:00:21  lr: 0.000000  loss: 0.7358 (0.7378)  time: 0.2517  data: 0.0000  max mem: 10917
[10:45:10.642194] Epoch: [49]  [280/345]  eta: 0:00:16  lr: 0.000000  loss: 0.7386 (0.7378)  time: 0.2519  data: 0.0000  max mem: 10917
[10:45:15.680947] Epoch: [49]  [300/345]  eta: 0:00:11  lr: 0.000000  loss: 0.7332 (0.7374)  time: 0.2519  data: 0.0000  max mem: 10917
[10:45:20.723535] Epoch: [49]  [320/345]  eta: 0:00:06  lr: 0.000000  loss: 0.7401 (0.7377)  time: 0.2521  data: 0.0000  max mem: 10917
[10:45:25.766080] Epoch: [49]  [340/345]  eta: 0:00:01  lr: 0.000000  loss: 0.7273 (0.7373)  time: 0.2521  data: 0.0000  max mem: 10917
[10:45:26.774112] Epoch: [49]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.7326 (0.7373)  time: 0.2520  data: 0.0001  max mem: 10917
[10:45:26.834966] Epoch: [49] Total time: 0:01:26 (0.2519 s / it)
[10:45:26.835474] Averaged stats: lr: 0.000000  loss: 0.7326 (0.7373)
[10:45:27.073849] Test:  [  0/345]  eta: 0:01:20  loss: 0.7238 (0.7238)  time: 0.2345  data: 0.1540  max mem: 10917
[10:45:27.967222] Test:  [ 10/345]  eta: 0:00:34  loss: 0.7066 (0.7082)  time: 0.1025  data: 0.0211  max mem: 10917
[10:45:28.857972] Test:  [ 20/345]  eta: 0:00:31  loss: 0.7049 (0.7087)  time: 0.0891  data: 0.0075  max mem: 10917
[10:45:29.690911] Test:  [ 30/345]  eta: 0:00:28  loss: 0.7067 (0.7093)  time: 0.0861  data: 0.0040  max mem: 10917
[10:45:30.521588] Test:  [ 40/345]  eta: 0:00:27  loss: 0.7022 (0.7084)  time: 0.0831  data: 0.0004  max mem: 10917
[10:45:31.355686] Test:  [ 50/345]  eta: 0:00:26  loss: 0.7041 (0.7090)  time: 0.0832  data: 0.0001  max mem: 10917
[10:45:32.193677] Test:  [ 60/345]  eta: 0:00:25  loss: 0.7010 (0.7078)  time: 0.0836  data: 0.0001  max mem: 10917
[10:45:33.034440] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7028 (0.7085)  time: 0.0839  data: 0.0001  max mem: 10917
[10:45:33.878417] Test:  [ 80/345]  eta: 0:00:23  loss: 0.7095 (0.7085)  time: 0.0842  data: 0.0001  max mem: 10917
[10:45:34.726694] Test:  [ 90/345]  eta: 0:00:22  loss: 0.7061 (0.7082)  time: 0.0846  data: 0.0001  max mem: 10917
[10:45:35.578338] Test:  [100/345]  eta: 0:00:21  loss: 0.7061 (0.7084)  time: 0.0850  data: 0.0001  max mem: 10917
[10:45:36.434084] Test:  [110/345]  eta: 0:00:20  loss: 0.7016 (0.7078)  time: 0.0853  data: 0.0001  max mem: 10917
[10:45:37.292622] Test:  [120/345]  eta: 0:00:19  loss: 0.7074 (0.7082)  time: 0.0857  data: 0.0001  max mem: 10917
[10:45:38.154455] Test:  [130/345]  eta: 0:00:18  loss: 0.7121 (0.7083)  time: 0.0860  data: 0.0001  max mem: 10917
[10:45:39.019394] Test:  [140/345]  eta: 0:00:17  loss: 0.7061 (0.7085)  time: 0.0863  data: 0.0001  max mem: 10917
[10:45:39.889014] Test:  [150/345]  eta: 0:00:16  loss: 0.7048 (0.7080)  time: 0.0867  data: 0.0001  max mem: 10917
[10:45:40.761415] Test:  [160/345]  eta: 0:00:15  loss: 0.7036 (0.7081)  time: 0.0871  data: 0.0001  max mem: 10917
[10:45:41.637185] Test:  [170/345]  eta: 0:00:15  loss: 0.7062 (0.7083)  time: 0.0874  data: 0.0001  max mem: 10917
[10:45:42.517173] Test:  [180/345]  eta: 0:00:14  loss: 0.7062 (0.7081)  time: 0.0877  data: 0.0001  max mem: 10917
[10:45:43.400000] Test:  [190/345]  eta: 0:00:13  loss: 0.7099 (0.7084)  time: 0.0881  data: 0.0001  max mem: 10917
[10:45:44.286695] Test:  [200/345]  eta: 0:00:12  loss: 0.7094 (0.7085)  time: 0.0884  data: 0.0001  max mem: 10917
[10:45:45.177405] Test:  [210/345]  eta: 0:00:11  loss: 0.7056 (0.7083)  time: 0.0888  data: 0.0001  max mem: 10917
[10:45:46.070486] Test:  [220/345]  eta: 0:00:10  loss: 0.7016 (0.7080)  time: 0.0891  data: 0.0001  max mem: 10917
[10:45:46.966755] Test:  [230/345]  eta: 0:00:10  loss: 0.7009 (0.7080)  time: 0.0894  data: 0.0001  max mem: 10917
[10:45:47.867851] Test:  [240/345]  eta: 0:00:09  loss: 0.7082 (0.7080)  time: 0.0898  data: 0.0001  max mem: 10917
[10:45:48.772344] Test:  [250/345]  eta: 0:00:08  loss: 0.7013 (0.7077)  time: 0.0902  data: 0.0001  max mem: 10917
[10:45:49.679480] Test:  [260/345]  eta: 0:00:07  loss: 0.7004 (0.7077)  time: 0.0905  data: 0.0001  max mem: 10917
[10:45:50.591157] Test:  [270/345]  eta: 0:00:06  loss: 0.7044 (0.7077)  time: 0.0909  data: 0.0001  max mem: 10917
[10:45:51.505706] Test:  [280/345]  eta: 0:00:05  loss: 0.7054 (0.7077)  time: 0.0913  data: 0.0001  max mem: 10917
[10:45:52.423600] Test:  [290/345]  eta: 0:00:04  loss: 0.7029 (0.7076)  time: 0.0916  data: 0.0001  max mem: 10917
[10:45:53.344867] Test:  [300/345]  eta: 0:00:03  loss: 0.7053 (0.7076)  time: 0.0919  data: 0.0001  max mem: 10917
[10:45:54.268860] Test:  [310/345]  eta: 0:00:03  loss: 0.7111 (0.7077)  time: 0.0922  data: 0.0001  max mem: 10917
[10:45:55.197176] Test:  [320/345]  eta: 0:00:02  loss: 0.7103 (0.7077)  time: 0.0926  data: 0.0001  max mem: 10917
[10:45:56.129666] Test:  [330/345]  eta: 0:00:01  loss: 0.7070 (0.7076)  time: 0.0930  data: 0.0001  max mem: 10917
[10:45:57.064940] Test:  [340/345]  eta: 0:00:00  loss: 0.7070 (0.7076)  time: 0.0933  data: 0.0001  max mem: 10917
[10:45:57.440418] Test:  [344/345]  eta: 0:00:00  loss: 0.7075 (0.7076)  time: 0.0935  data: 0.0001  max mem: 10917
[10:45:57.496573] Test: Total time: 0:00:30 (0.0889 s / it)
[10:46:07.936563] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8894 (0.8894)  time: 0.2199  data: 0.1401  max mem: 10917
[10:46:08.749398] Test:  [10/57]  eta: 0:00:04  loss: 0.9194 (0.9251)  time: 0.0938  data: 0.0128  max mem: 10917
[10:46:09.565785] Test:  [20/57]  eta: 0:00:03  loss: 0.9194 (0.9105)  time: 0.0814  data: 0.0001  max mem: 10917
[10:46:10.386460] Test:  [30/57]  eta: 0:00:02  loss: 0.7991 (0.8682)  time: 0.0818  data: 0.0001  max mem: 10917
[10:46:11.210955] Test:  [40/57]  eta: 0:00:01  loss: 0.7861 (0.8463)  time: 0.0822  data: 0.0001  max mem: 10917
[10:46:12.038864] Test:  [50/57]  eta: 0:00:00  loss: 0.7793 (0.8382)  time: 0.0825  data: 0.0001  max mem: 10917
[10:46:12.488549] Test:  [56/57]  eta: 0:00:00  loss: 0.8079 (0.8455)  time: 0.0803  data: 0.0001  max mem: 10917
[10:46:12.546617] Test: Total time: 0:00:04 (0.0847 s / it)
[10:46:14.317226] Dice score of the network on the train images: 0.830477, val images: 0.809099
[10:46:14.318878] Training time 1:52:07
[10:46:15.911386] Load pre-trained checkpoint from: /root/seg_framework/MS-Mamba/output_dir/mslesseg/checkpoints_0/checkpoint-best_dice_model_0.pth
[10:46:15.927796] <All keys matched successfully>
[10:46:16.357622] Test:  [  0/246]  eta: 0:01:30    time: 0.3689  data: 0.1637  max mem: 10917
[10:46:17.769189] Test:  [ 10/246]  eta: 0:00:38    time: 0.1618  data: 0.0149  max mem: 10917
[10:46:22.615664] ---------------------------------
[10:46:22.615889] Patient 1:
[10:46:22.615963]       precision: 0.5246224403381348
[10:46:22.616029]       recall: 0.5260039567947388
[10:46:22.616086]       dice_score: 0.5253123044967651
[10:46:22.619312] Test:  [ 20/246]  eta: 0:01:11    time: 0.3130  data: 0.0001  max mem: 10917
[10:46:24.023500] Test:  [ 30/246]  eta: 0:00:55    time: 0.3127  data: 0.0001  max mem: 10917
[10:46:28.806338] ---------------------------------
[10:46:28.806573] Patient 2:
[10:46:28.806655]       precision: 0.5582655668258667
[10:46:28.806721]       recall: 0.5199394226074219
[10:46:28.806778]       dice_score: 0.5384213328361511
[10:46:28.807314] Test:  [ 40/246]  eta: 0:01:04    time: 0.3094  data: 0.0001  max mem: 10917
[10:46:30.212743] Test:  [ 50/246]  eta: 0:00:54    time: 0.3094  data: 0.0001  max mem: 10917
[10:46:31.758974] Test:  [ 60/246]  eta: 0:00:48    time: 0.1475  data: 0.0001  max mem: 10917
[10:46:35.159780] ---------------------------------
[10:46:35.160008] Patient 3:
[10:46:35.160095]       precision: 0.3814432919025421
[10:46:35.160161]       recall: 0.4465167224407196
[10:46:35.160230]       dice_score: 0.4114227890968323
[10:46:36.409935] Test:  [ 70/246]  eta: 0:00:50    time: 0.3098  data: 0.0001  max mem: 10917
[10:46:37.953048] Test:  [ 80/246]  eta: 0:00:45    time: 0.3097  data: 0.0001  max mem: 10917
[10:46:41.343139] ---------------------------------
[10:46:41.343366] Patient 4:
[10:46:41.343444]       precision: 0.5567567348480225
[10:46:41.343512]       recall: 0.5199394226074219
[10:46:41.343576]       dice_score: 0.5377185940742493
[10:46:42.591878] Test:  [ 90/246]  eta: 0:00:45    time: 0.3091  data: 0.0001  max mem: 10917
[10:46:44.134968] Test:  [100/246]  eta: 0:00:40    time: 0.3091  data: 0.0001  max mem: 10917
[10:46:47.686920] ---------------------------------
[10:46:47.687140] Patient 5:
[10:46:47.687226]       precision: 0.38177570700645447
[10:46:47.687295]       recall: 0.44816237688064575
[10:46:47.687356]       dice_score: 0.41231390833854675
[10:46:48.782537] Test:  [110/246]  eta: 0:00:40    time: 0.3095  data: 0.0001  max mem: 10917
[10:46:50.326152] Test:  [120/246]  eta: 0:00:35    time: 0.3095  data: 0.0001  max mem: 10917
[10:46:53.896929] ---------------------------------
[10:46:53.897153] Patient 6:
[10:46:53.897239]       precision: 0.38090780377388
[10:46:53.897309]       recall: 0.4465167224407196
[10:46:53.897369]       dice_score: 0.41111111640930176
[10:46:54.990480] Test:  [130/246]  eta: 0:00:34    time: 0.3104  data: 0.0001  max mem: 10917
[10:46:56.532361] Test:  [140/246]  eta: 0:00:30    time: 0.3103  data: 0.0001  max mem: 10917
[10:47:00.259301] ---------------------------------
[10:47:00.259522] Patient 7:
[10:47:00.259609]       precision: 0.7618327736854553
[10:47:00.259674]       recall: 0.790610671043396
[10:47:00.259734]       dice_score: 0.7759549617767334
[10:47:01.198876] Test:  [150/246]  eta: 0:00:28    time: 0.3104  data: 0.0001  max mem: 10917
[10:47:02.739896] Test:  [160/246]  eta: 0:00:24    time: 0.3103  data: 0.0001  max mem: 10917
[10:47:06.472924] ---------------------------------
[10:47:06.473150] Patient 8:
[10:47:06.473235]       precision: 0.882907509803772
[10:47:06.473304]       recall: 0.5628555417060852
[10:47:06.473363]       dice_score: 0.6874562501907349
[10:47:07.410750] Test:  [170/246]  eta: 0:00:22    time: 0.3105  data: 0.0001  max mem: 10917
[10:47:08.949812] Test:  [180/246]  eta: 0:00:19    time: 0.3104  data: 0.0001  max mem: 10917
[10:47:12.722714] ---------------------------------
[10:47:12.722933] Patient 9:
[10:47:12.723009]       precision: 0.6826071739196777
[10:47:12.723072]       recall: 0.8189545273780823
[10:47:12.723129]       dice_score: 0.7445904016494751
[10:47:13.660873] Test:  [190/246]  eta: 0:00:16    time: 0.3125  data: 0.0001  max mem: 10917
[10:47:15.200940] Test:  [200/246]  eta: 0:00:13    time: 0.3125  data: 0.0001  max mem: 10917
[10:47:19.099742] ---------------------------------
[10:47:19.099984] Patient 10:
[10:47:19.100074]       precision: 0.6844699382781982
[10:47:19.100143]       recall: 0.817740261554718
[10:47:19.100204]       dice_score: 0.7451934814453125
[10:47:19.884604] Test:  [210/246]  eta: 0:00:10    time: 0.3111  data: 0.0001  max mem: 10917
[10:47:21.424067] Test:  [220/246]  eta: 0:00:07    time: 0.3104  data: 0.0001  max mem: 10917
[10:47:25.321840] ---------------------------------
[10:47:25.322075] Patient 11:
[10:47:25.322163]       precision: 0.8744333386421204
[10:47:25.322238]       recall: 0.7533295750617981
[10:47:25.322300]       dice_score: 0.8093764781951904
[10:47:26.106327] Test:  [230/246]  eta: 0:00:04    time: 0.3104  data: 0.0001  max mem: 10917
[10:47:27.645897] Test:  [240/246]  eta: 0:00:01    time: 0.3110  data: 0.0001  max mem: 10917
[10:47:31.540897] ---------------------------------
[10:47:31.541118] Patient 12:
[10:47:31.541202]       precision: 0.6341003179550171
[10:47:31.541277]       recall: 0.757889986038208
[10:47:31.541336]       dice_score: 0.6904908418655396
[10:47:31.541715] Test:  [245/246]  eta: 0:00:00    time: 0.3099  data: 0.0001  max mem: 10917
[10:47:31.597913] Test: Total time: 0:01:15 (0.3074 s / it)
[10:47:31.598162] ================================
[10:47:31.598256] Averaged over all patients:
[10:47:31.598481]       precision: 0.6087 ± 0.1704
[10:47:31.598617]       recall: 0.6174 ± 0.1490
[10:47:31.598741]       dice_score: 0.6074 ± 0.1448
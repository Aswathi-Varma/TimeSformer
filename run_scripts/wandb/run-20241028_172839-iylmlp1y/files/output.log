[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/val_ft
Not using distributed mode
[17:28:41.271183] job dir: /root/seg_framework/MS-Mamba/run_scripts
[17:28:41.271285] Namespace(accum_iter=1,
model='SegFormer3D',
in_channels=1,
lr=None,
blr=0.001,
min_lr=0,
dist_on_itp=False,
warmup_epochs=20,
device='cuda:0',
seed=42,
layer_decay=0.75,
clip_grad=None,
num_workers=1,
pin_mem=True,
resume='',
mask_mode='concatenate to image',
world_size=1,
embed_dim=1,
local_rank=-1,
dist_url='env://',
nb_classes=2,
data_dir='/root/MSLesSeg24/data',
datalist=None,
preprocess=False,
dim=2,
loss='mask tp1 tp2',
distributed=False)
[17:28:41.271363] device  cuda:0
[17:28:41.272015] Random seed set as 42
[17:28:41.272298] Starting for fold 0
[17:28:41.465040] Elements in data_dir_paths: 11052
[17:28:41.499479] Elements in data_dir_paths: 1803
[17:28:42.992083] number of params: 59617303
[17:28:42.992327] model: Vivim2D(
  (encoder): mamba_block(
    (downsample_layers): SegformerEncoder(
      (patch_embeddings): ModuleList(
        (0): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(2, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (1): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (2): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (3): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (block): ModuleList(
        (0): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): Identity()
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.003703703870996833)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.007407407741993666)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.011111111380159855)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.014814815483987331)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.018518518656492233)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.02222222276031971)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (2): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.025925926864147186)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.029629630967974663)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03333333507180214)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03703703731298447)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04074074327945709)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04444444552063942)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.048148151487112045)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.051851850003004074)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0555555559694767)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.05925925821065903)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06296296417713165)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06666667014360428)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07037036865949631)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07407407462596893)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07777778059244156)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08148147910833359)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08518518507480621)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08888889104127884)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (3): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.09259259700775146)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0962962955236435)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.10000000149011612)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (layer_norm): ModuleList(
        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=64, out_features=256, bias=False)
              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (act): SiLU()
              (x_proj): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_b): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_b): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_b): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_s): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_s): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_s): Linear(in_features=4, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=64, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=256, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=64, out_features=256, bias=False)
              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (act): SiLU()
              (x_proj): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_b): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_b): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_b): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_s): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_s): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_s): Linear(in_features=4, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=64, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=256, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (1): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=128, out_features=512, bias=False)
              (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (act): SiLU()
              (x_proj): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_b): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_b): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_b): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_s): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_s): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_s): Linear(in_features=8, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=128, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=128, out_features=512, bias=False)
              (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (act): SiLU()
              (x_proj): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_b): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_b): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_b): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_s): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_s): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_s): Linear(in_features=8, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=128, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (2): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=320, out_features=1280, bias=False)
              (conv1d): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (act): SiLU()
              (x_proj): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_b): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_b): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_b): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_s): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_s): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_s): Linear(in_features=20, out_features=640, bias=True)
              (out_proj): Linear(in_features=640, out_features=320, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(1280, 1280, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=320, out_features=1280, bias=False)
              (conv1d): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (act): SiLU()
              (x_proj): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_b): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_b): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_b): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_s): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_s): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_s): Linear(in_features=20, out_features=640, bias=True)
              (out_proj): Linear(in_features=640, out_features=320, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(1280, 1280, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (3): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=512, out_features=2048, bias=False)
              (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (act): SiLU()
              (x_proj): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_b): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_b): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_b): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_s): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_s): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_s): Linear(in_features=32, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=512, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=512, out_features=2048, bias=False)
              (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (act): SiLU()
              (x_proj): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_b): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_b): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_b): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_s): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_s): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_s): Linear(in_features=32, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=512, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
  )
  (decoder): SegformerDecodeHead(
    (linear_c): ModuleList(
      (0): SegformerMLP(
        (proj): Linear(in_features=64, out_features=768, bias=True)
      )
      (1): SegformerMLP(
        (proj): Linear(in_features=128, out_features=768, bias=True)
      )
      (2): SegformerMLP(
        (proj): Linear(in_features=320, out_features=768, bias=True)
      )
      (3): SegformerMLP(
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
    )
    (linear_fuse): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (batch_norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): ReLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Conv2d(768, 150, kernel_size=(1, 1), stride=(1, 1))
  )
  (out): Conv2d(768, 1, kernel_size=(1, 1), stride=(1, 1))
)
[17:28:42.995527] base lr: 1.00e-03
[17:28:42.995588] actual lr: 1.25e-04
[17:28:42.995639] accumulate grad iterations: 1
[17:28:42.995686] effective batch size: 32
[17:28:42.997335] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.000125
    maximize: False
    weight_decay: 0.01
)
[17:28:42.999284] Start training for 50 epochs
[17:28:43.001193] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
[17:28:44.559553] Epoch: [0]  [  0/345]  eta: 0:08:57  lr: 0.000000  loss: 1.6965 (1.6965)  time: 1.5574  data: 0.1919  max mem: 14473
[17:28:58.965349] Epoch: [0]  [ 20/345]  eta: 0:04:07  lr: 0.000000  loss: 1.6955 (1.6956)  time: 0.7202  data: 0.0001  max mem: 14938
[17:29:13.446022] Epoch: [0]  [ 40/345]  eta: 0:03:46  lr: 0.000001  loss: 1.6917 (1.6936)  time: 0.7240  data: 0.0001  max mem: 14938
[17:29:28.142727] Epoch: [0]  [ 60/345]  eta: 0:03:30  lr: 0.000001  loss: 1.6874 (1.6916)  time: 0.7348  data: 0.0001  max mem: 14938
[17:29:42.821322] Epoch: [0]  [ 80/345]  eta: 0:03:15  lr: 0.000001  loss: 1.6850 (1.6901)  time: 0.7339  data: 0.0001  max mem: 14938
[17:29:57.577623] Epoch: [0]  [100/345]  eta: 0:03:00  lr: 0.000002  loss: 1.6822 (1.6885)  time: 0.7378  data: 0.0001  max mem: 14938
[17:30:12.393365] Epoch: [0]  [120/345]  eta: 0:02:46  lr: 0.000002  loss: 1.6764 (1.6865)  time: 0.7407  data: 0.0001  max mem: 14938
[17:30:27.251492] Epoch: [0]  [140/345]  eta: 0:02:31  lr: 0.000003  loss: 1.6697 (1.6843)  time: 0.7429  data: 0.0001  max mem: 14938
[17:30:42.128778] Epoch: [0]  [160/345]  eta: 0:02:16  lr: 0.000003  loss: 1.6670 (1.6822)  time: 0.7438  data: 0.0001  max mem: 14938
[17:30:57.041879] Epoch: [0]  [180/345]  eta: 0:02:02  lr: 0.000003  loss: 1.6606 (1.6798)  time: 0.7456  data: 0.0001  max mem: 14938
[17:31:11.979890] Epoch: [0]  [200/345]  eta: 0:01:47  lr: 0.000004  loss: 1.6525 (1.6772)  time: 0.7469  data: 0.0001  max mem: 14938
[17:31:26.932328] Epoch: [0]  [220/345]  eta: 0:01:32  lr: 0.000004  loss: 1.6446 (1.6743)  time: 0.7476  data: 0.0001  max mem: 14938
[17:31:41.891247] Epoch: [0]  [240/345]  eta: 0:01:17  lr: 0.000004  loss: 1.6343 (1.6711)  time: 0.7479  data: 0.0001  max mem: 14938
[17:31:56.841102] Epoch: [0]  [260/345]  eta: 0:01:03  lr: 0.000005  loss: 1.6247 (1.6675)  time: 0.7474  data: 0.0001  max mem: 14938
[17:32:11.783229] Epoch: [0]  [280/345]  eta: 0:00:48  lr: 0.000005  loss: 1.6127 (1.6636)  time: 0.7471  data: 0.0001  max mem: 14938
[17:32:26.726375] Epoch: [0]  [300/345]  eta: 0:00:33  lr: 0.000005  loss: 1.5994 (1.6594)  time: 0.7471  data: 0.0001  max mem: 14938
[17:32:41.678377] Epoch: [0]  [320/345]  eta: 0:00:18  lr: 0.000006  loss: 1.5854 (1.6548)  time: 0.7476  data: 0.0001  max mem: 14938
[17:32:56.642385] Epoch: [0]  [340/345]  eta: 0:00:03  lr: 0.000006  loss: 1.5717 (1.6499)  time: 0.7482  data: 0.0001  max mem: 14938
[17:32:59.632616] Epoch: [0]  [344/345]  eta: 0:00:00  lr: 0.000006  loss: 1.5658 (1.6489)  time: 0.7479  data: 0.0001  max mem: 14938
[17:32:59.690075] Epoch: [0] Total time: 0:04:16 (0.7440 s / it)
[17:32:59.690447] Averaged stats: lr: 0.000006  loss: 1.5658 (1.6489)
[17:33:00.034358] Test:  [  0/345]  eta: 0:01:57  loss: 1.5938 (1.5938)  time: 0.3406  data: 0.1588  max mem: 14938
[17:33:01.872121] Test:  [ 10/345]  eta: 0:01:06  loss: 1.5938 (1.5936)  time: 0.1980  data: 0.0145  max mem: 14938
[17:33:03.713447] Test:  [ 20/345]  eta: 0:01:02  loss: 1.5941 (1.5938)  time: 0.1839  data: 0.0001  max mem: 14938
[17:33:05.558819] Test:  [ 30/345]  eta: 0:00:59  loss: 1.5925 (1.5932)  time: 0.1843  data: 0.0001  max mem: 14938
[17:33:07.409079] Test:  [ 40/345]  eta: 0:00:57  loss: 1.5925 (1.5931)  time: 0.1847  data: 0.0001  max mem: 14938
[17:33:09.259549] Test:  [ 50/345]  eta: 0:00:55  loss: 1.5935 (1.5932)  time: 0.1850  data: 0.0001  max mem: 14938
[17:33:11.115519] Test:  [ 60/345]  eta: 0:00:53  loss: 1.5935 (1.5931)  time: 0.1853  data: 0.0001  max mem: 14938
[17:33:12.973467] Test:  [ 70/345]  eta: 0:00:51  loss: 1.5913 (1.5928)  time: 0.1856  data: 0.0001  max mem: 14938
[17:33:14.835193] Test:  [ 80/345]  eta: 0:00:49  loss: 1.5913 (1.5927)  time: 0.1859  data: 0.0001  max mem: 14938
[17:33:16.701946] Test:  [ 90/345]  eta: 0:00:47  loss: 1.5924 (1.5926)  time: 0.1864  data: 0.0001  max mem: 14938
[17:33:18.572247] Test:  [100/345]  eta: 0:00:45  loss: 1.5928 (1.5926)  time: 0.1868  data: 0.0001  max mem: 14938
[17:33:20.443162] Test:  [110/345]  eta: 0:00:43  loss: 1.5931 (1.5926)  time: 0.1870  data: 0.0001  max mem: 14938
[17:33:22.319861] Test:  [120/345]  eta: 0:00:42  loss: 1.5936 (1.5927)  time: 0.1873  data: 0.0001  max mem: 14938
[17:33:24.198085] Test:  [130/345]  eta: 0:00:40  loss: 1.5921 (1.5925)  time: 0.1877  data: 0.0001  max mem: 14938
[17:33:26.080664] Test:  [140/345]  eta: 0:00:38  loss: 1.5925 (1.5925)  time: 0.1880  data: 0.0001  max mem: 14938
[17:33:27.966507] Test:  [150/345]  eta: 0:00:36  loss: 1.5931 (1.5925)  time: 0.1884  data: 0.0001  max mem: 14938
[17:33:29.856356] Test:  [160/345]  eta: 0:00:34  loss: 1.5937 (1.5926)  time: 0.1887  data: 0.0001  max mem: 14938
[17:33:31.750470] Test:  [170/345]  eta: 0:00:32  loss: 1.5926 (1.5926)  time: 0.1891  data: 0.0001  max mem: 14938
[17:33:33.648998] Test:  [180/345]  eta: 0:00:30  loss: 1.5930 (1.5926)  time: 0.1896  data: 0.0001  max mem: 14938
[17:33:35.550484] Test:  [190/345]  eta: 0:00:29  loss: 1.5934 (1.5926)  time: 0.1899  data: 0.0001  max mem: 14938
[17:33:37.453257] Test:  [200/345]  eta: 0:00:27  loss: 1.5923 (1.5926)  time: 0.1902  data: 0.0001  max mem: 14938
[17:33:39.772533] Test:  [210/345]  eta: 0:00:25  loss: 1.5923 (1.5926)  time: 0.2110  data: 0.0001  max mem: 14938
[17:33:41.693921] Test:  [220/345]  eta: 0:00:23  loss: 1.5940 (1.5926)  time: 0.2120  data: 0.0001  max mem: 14938
[17:33:43.742958] Test:  [230/345]  eta: 0:00:21  loss: 1.5944 (1.5927)  time: 0.1985  data: 0.0001  max mem: 14938
[17:33:45.661596] Test:  [240/345]  eta: 0:00:20  loss: 1.5926 (1.5926)  time: 0.1983  data: 0.0001  max mem: 14938
[17:33:47.754365] Test:  [250/345]  eta: 0:00:18  loss: 1.5926 (1.5927)  time: 0.2005  data: 0.0001  max mem: 14938
[17:33:49.855848] Test:  [260/345]  eta: 0:00:16  loss: 1.5921 (1.5926)  time: 0.2097  data: 0.0001  max mem: 14938
[17:33:51.948063] Test:  [270/345]  eta: 0:00:14  loss: 1.5934 (1.5927)  time: 0.2096  data: 0.0001  max mem: 14938
[17:33:53.909756] Test:  [280/345]  eta: 0:00:12  loss: 1.5934 (1.5926)  time: 0.2026  data: 0.0001  max mem: 14938
[17:33:56.032507] Test:  [290/345]  eta: 0:00:10  loss: 1.5909 (1.5926)  time: 0.2042  data: 0.0001  max mem: 14938
[17:33:58.223845] Test:  [300/345]  eta: 0:00:08  loss: 1.5934 (1.5927)  time: 0.2157  data: 0.0001  max mem: 14938
[17:34:00.390639] Test:  [310/345]  eta: 0:00:06  loss: 1.5937 (1.5927)  time: 0.2179  data: 0.0001  max mem: 14938
[17:34:02.537856] Test:  [320/345]  eta: 0:00:04  loss: 1.5932 (1.5927)  time: 0.2156  data: 0.0001  max mem: 14938
[17:34:04.721652] Test:  [330/345]  eta: 0:00:02  loss: 1.5927 (1.5927)  time: 0.2165  data: 0.0001  max mem: 14938
[17:34:06.697641] Test:  [340/345]  eta: 0:00:00  loss: 1.5917 (1.5926)  time: 0.2079  data: 0.0001  max mem: 14938
[17:34:07.802048] Test:  [344/345]  eta: 0:00:00  loss: 1.5918 (1.5927)  time: 0.2231  data: 0.0001  max mem: 14938
[17:34:07.860501] Test: Total time: 0:01:08 (0.1976 s / it)
[17:34:18.214056] Test:  [ 0/57]  eta: 0:00:18  loss: 1.6031 (1.6031)  time: 0.3221  data: 0.1422  max mem: 14938
[17:34:20.031192] Test:  [10/57]  eta: 0:00:09  loss: 1.5973 (1.5980)  time: 0.1944  data: 0.0130  max mem: 14938
[17:34:21.850156] Test:  [20/57]  eta: 0:00:06  loss: 1.5978 (1.5966)  time: 0.1817  data: 0.0001  max mem: 14938
[17:34:23.674975] Test:  [30/57]  eta: 0:00:05  loss: 1.5949 (1.5923)  time: 0.1821  data: 0.0001  max mem: 14938
[17:34:25.503612] Test:  [40/57]  eta: 0:00:03  loss: 1.5840 (1.5894)  time: 0.1826  data: 0.0001  max mem: 14938
[17:34:27.337714] Test:  [50/57]  eta: 0:00:01  loss: 1.5840 (1.5885)  time: 0.1831  data: 0.0001  max mem: 14938
[17:34:28.352169] Test:  [56/57]  eta: 0:00:00  loss: 1.5873 (1.5884)  time: 0.1789  data: 0.0001  max mem: 14938
[17:34:28.406926] Test: Total time: 0:00:10 (0.1845 s / it)
[17:34:30.173804] Dice score of the network on the train images: 0.000000, val images: 0.000000
[17:34:30.174026] saving best_dice_model_0 @ epoch 0
[17:34:31.381805] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:34:32.267232] Epoch: [1]  [  0/345]  eta: 0:05:05  lr: 0.000006  loss: 1.5589 (1.5589)  time: 0.8843  data: 0.1411  max mem: 14938
[17:34:47.164115] Epoch: [1]  [ 20/345]  eta: 0:04:04  lr: 0.000007  loss: 1.5513 (1.5526)  time: 0.7448  data: 0.0001  max mem: 14938
[17:35:02.104330] Epoch: [1]  [ 40/345]  eta: 0:03:48  lr: 0.000007  loss: 1.5421 (1.5472)  time: 0.7470  data: 0.0001  max mem: 14938
[17:35:17.083868] Epoch: [1]  [ 60/345]  eta: 0:03:33  lr: 0.000007  loss: 1.5235 (1.5400)  time: 0.7489  data: 0.0001  max mem: 14938
[17:35:32.092625] Epoch: [1]  [ 80/345]  eta: 0:03:18  lr: 0.000008  loss: 1.5102 (1.5334)  time: 0.7504  data: 0.0001  max mem: 14938
[17:35:47.115314] Epoch: [1]  [100/345]  eta: 0:03:03  lr: 0.000008  loss: 1.4967 (1.5266)  time: 0.7511  data: 0.0001  max mem: 14938
[17:36:02.145687] Epoch: [1]  [120/345]  eta: 0:02:48  lr: 0.000008  loss: 1.4868 (1.5198)  time: 0.7515  data: 0.0001  max mem: 14938
[17:36:17.175307] Epoch: [1]  [140/345]  eta: 0:02:33  lr: 0.000009  loss: 1.4719 (1.5131)  time: 0.7514  data: 0.0001  max mem: 14938
[17:36:32.199748] Epoch: [1]  [160/345]  eta: 0:02:18  lr: 0.000009  loss: 1.4666 (1.5074)  time: 0.7512  data: 0.0001  max mem: 14938
[17:36:47.218386] Epoch: [1]  [180/345]  eta: 0:02:03  lr: 0.000010  loss: 1.4543 (1.5018)  time: 0.7509  data: 0.0001  max mem: 14938
[17:37:02.227601] Epoch: [1]  [200/345]  eta: 0:01:48  lr: 0.000010  loss: 1.4464 (1.4965)  time: 0.7504  data: 0.0001  max mem: 14938
[17:37:17.354463] Epoch: [1]  [220/345]  eta: 0:01:33  lr: 0.000010  loss: 1.4327 (1.4908)  time: 0.7563  data: 0.0001  max mem: 14938
[17:37:32.347975] Epoch: [1]  [240/345]  eta: 0:01:18  lr: 0.000011  loss: 1.4221 (1.4854)  time: 0.7496  data: 0.0001  max mem: 14938
[17:37:47.339948] Epoch: [1]  [260/345]  eta: 0:01:03  lr: 0.000011  loss: 1.4219 (1.4805)  time: 0.7496  data: 0.0001  max mem: 14938

[17:38:02.325810] Epoch: [1]  [280/345]  eta: 0:00:48  lr: 0.000011  loss: 1.4123 (1.4760)  time: 0.7492  data: 0.0001  max mem: 14938
[17:38:17.319907] Epoch: [1]  [300/345]  eta: 0:00:33  lr: 0.000012  loss: 1.4043 (1.4714)  time: 0.7497  data: 0.0001  max mem: 14938
[17:38:32.315415] Epoch: [1]  [320/345]  eta: 0:00:18  lr: 0.000012  loss: 1.4006 (1.4672)  time: 0.7497  data: 0.0001  max mem: 14938
[17:38:47.309349] Epoch: [1]  [340/345]  eta: 0:00:03  lr: 0.000012  loss: 1.3953 (1.4632)  time: 0.7496  data: 0.0001  max mem: 14938
[17:38:50.310958] Epoch: [1]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 1.3953 (1.4624)  time: 0.7498  data: 0.0001  max mem: 14938
[17:38:50.373047] Epoch: [1] Total time: 0:04:18 (0.7507 s / it)
[17:38:50.373533] Averaged stats: lr: 0.000012  loss: 1.3953 (1.4624)
[17:38:50.714186] Test:  [  0/345]  eta: 0:01:56  loss: 1.3929 (1.3929)  time: 0.3366  data: 0.1552  max mem: 14938
[17:38:52.549972] Test:  [ 10/345]  eta: 0:01:06  loss: 1.3927 (1.3932)  time: 0.1974  data: 0.0142  max mem: 14938
[17:38:54.388857] Test:  [ 20/345]  eta: 0:01:02  loss: 1.3928 (1.3934)  time: 0.1837  data: 0.0001  max mem: 14938
[17:38:56.231399] Test:  [ 30/345]  eta: 0:00:59  loss: 1.3928 (1.3932)  time: 0.1840  data: 0.0001  max mem: 14938
[17:38:58.077399] Test:  [ 40/345]  eta: 0:00:57  loss: 1.3927 (1.3930)  time: 0.1844  data: 0.0001  max mem: 14938
[17:38:59.925525] Test:  [ 50/345]  eta: 0:00:55  loss: 1.3925 (1.3928)  time: 0.1847  data: 0.0001  max mem: 14938
[17:39:01.777577] Test:  [ 60/345]  eta: 0:00:53  loss: 1.3926 (1.3929)  time: 0.1850  data: 0.0001  max mem: 14938
[17:39:03.635400] Test:  [ 70/345]  eta: 0:00:51  loss: 1.3935 (1.3931)  time: 0.1854  data: 0.0001  max mem: 14938
[17:39:05.495730] Test:  [ 80/345]  eta: 0:00:49  loss: 1.3934 (1.3930)  time: 0.1859  data: 0.0001  max mem: 14938
[17:39:07.361352] Test:  [ 90/345]  eta: 0:00:47  loss: 1.3921 (1.3929)  time: 0.1863  data: 0.0001  max mem: 14938
[17:39:09.229176] Test:  [100/345]  eta: 0:00:45  loss: 1.3919 (1.3929)  time: 0.1866  data: 0.0001  max mem: 14938
[17:39:11.102022] Test:  [110/345]  eta: 0:00:43  loss: 1.3929 (1.3929)  time: 0.1870  data: 0.0001  max mem: 14938
[17:39:12.977731] Test:  [120/345]  eta: 0:00:42  loss: 1.3929 (1.3929)  time: 0.1874  data: 0.0001  max mem: 14938
[17:39:14.856376] Test:  [130/345]  eta: 0:00:40  loss: 1.3929 (1.3929)  time: 0.1877  data: 0.0001  max mem: 14938
[17:39:16.739585] Test:  [140/345]  eta: 0:00:38  loss: 1.3933 (1.3929)  time: 0.1880  data: 0.0001  max mem: 14938
[17:39:18.624021] Test:  [150/345]  eta: 0:00:36  loss: 1.3927 (1.3929)  time: 0.1883  data: 0.0001  max mem: 14938
[17:39:20.509787] Test:  [160/345]  eta: 0:00:34  loss: 1.3926 (1.3929)  time: 0.1885  data: 0.0001  max mem: 14938
[17:39:22.400449] Test:  [170/345]  eta: 0:00:32  loss: 1.3929 (1.3929)  time: 0.1888  data: 0.0001  max mem: 14938
[17:39:24.295051] Test:  [180/345]  eta: 0:00:30  loss: 1.3933 (1.3929)  time: 0.1892  data: 0.0001  max mem: 14938
[17:39:26.195420] Test:  [190/345]  eta: 0:00:29  loss: 1.3930 (1.3929)  time: 0.1897  data: 0.0001  max mem: 14938
[17:39:28.097272] Test:  [200/345]  eta: 0:00:27  loss: 1.3932 (1.3929)  time: 0.1901  data: 0.0001  max mem: 14938
[17:39:30.002314] Test:  [210/345]  eta: 0:00:25  loss: 1.3934 (1.3929)  time: 0.1903  data: 0.0001  max mem: 14938
[17:39:31.913477] Test:  [220/345]  eta: 0:00:23  loss: 1.3933 (1.3929)  time: 0.1908  data: 0.0001  max mem: 14938
[17:39:33.827570] Test:  [230/345]  eta: 0:00:21  loss: 1.3929 (1.3929)  time: 0.1912  data: 0.0001  max mem: 14938
[17:39:35.745646] Test:  [240/345]  eta: 0:00:19  loss: 1.3929 (1.3929)  time: 0.1915  data: 0.0001  max mem: 14938
[17:39:37.666202] Test:  [250/345]  eta: 0:00:17  loss: 1.3929 (1.3929)  time: 0.1919  data: 0.0001  max mem: 14938
[17:39:39.591221] Test:  [260/345]  eta: 0:00:16  loss: 1.3924 (1.3929)  time: 0.1922  data: 0.0001  max mem: 14938
[17:39:41.519772] Test:  [270/345]  eta: 0:00:14  loss: 1.3924 (1.3929)  time: 0.1926  data: 0.0001  max mem: 14938
[17:39:43.449787] Test:  [280/345]  eta: 0:00:12  loss: 1.3925 (1.3929)  time: 0.1929  data: 0.0001  max mem: 14938
[17:39:45.385819] Test:  [290/345]  eta: 0:00:10  loss: 1.3927 (1.3929)  time: 0.1933  data: 0.0001  max mem: 14938
[17:39:47.323729] Test:  [300/345]  eta: 0:00:08  loss: 1.3926 (1.3929)  time: 0.1936  data: 0.0001  max mem: 14938
[17:39:49.264760] Test:  [310/345]  eta: 0:00:06  loss: 1.3926 (1.3929)  time: 0.1939  data: 0.0001  max mem: 14938
[17:39:51.208907] Test:  [320/345]  eta: 0:00:04  loss: 1.3924 (1.3929)  time: 0.1942  data: 0.0001  max mem: 14938
[17:39:53.157373] Test:  [330/345]  eta: 0:00:02  loss: 1.3924 (1.3929)  time: 0.1946  data: 0.0001  max mem: 14938
[17:39:55.106838] Test:  [340/345]  eta: 0:00:00  loss: 1.3931 (1.3929)  time: 0.1948  data: 0.0001  max mem: 14938
[17:39:55.888476] Test:  [344/345]  eta: 0:00:00  loss: 1.3933 (1.3929)  time: 0.1950  data: 0.0001  max mem: 14938
[17:39:55.945994] Test: Total time: 0:01:05 (0.1901 s / it)
[17:40:06.291063] Test:  [ 0/57]  eta: 0:00:18  loss: 1.4001 (1.4001)  time: 0.3195  data: 0.1397  max mem: 14938
[17:40:08.106184] Test:  [10/57]  eta: 0:00:09  loss: 1.3978 (1.3968)  time: 0.1940  data: 0.0128  max mem: 14938
[17:40:09.927187] Test:  [20/57]  eta: 0:00:06  loss: 1.3978 (1.3960)  time: 0.1817  data: 0.0001  max mem: 14938
[17:40:11.752634] Test:  [30/57]  eta: 0:00:05  loss: 1.3925 (1.3927)  time: 0.1823  data: 0.0001  max mem: 14938
[17:40:13.581230] Test:  [40/57]  eta: 0:00:03  loss: 1.3870 (1.3906)  time: 0.1827  data: 0.0001  max mem: 14938
[17:40:15.416034] Test:  [50/57]  eta: 0:00:01  loss: 1.3870 (1.3899)  time: 0.1831  data: 0.0001  max mem: 14938
[17:40:16.404985] Test:  [56/57]  eta: 0:00:00  loss: 1.3898 (1.3897)  time: 0.1778  data: 0.0001  max mem: 14938
[17:40:16.463073] Test: Total time: 0:00:10 (0.1841 s / it)
[17:40:18.223206] Dice score of the network on the train images: 0.000000, val images: 0.000000
[17:40:18.228082] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:40:19.115399] Epoch: [2]  [  0/345]  eta: 0:05:05  lr: 0.000013  loss: 1.3903 (1.3903)  time: 0.8863  data: 0.1429  max mem: 14938
[17:40:34.020312] Epoch: [2]  [ 20/345]  eta: 0:04:04  lr: 0.000013  loss: 1.3872 (1.3882)  time: 0.7452  data: 0.0001  max mem: 14938
[17:40:48.960495] Epoch: [2]  [ 40/345]  eta: 0:03:48  lr: 0.000013  loss: 1.3834 (1.3868)  time: 0.7470  data: 0.0001  max mem: 14938
[17:41:03.935347] Epoch: [2]  [ 60/345]  eta: 0:03:33  lr: 0.000014  loss: 1.3799 (1.3847)  time: 0.7487  data: 0.0001  max mem: 14938
[17:41:18.921394] Epoch: [2]  [ 80/345]  eta: 0:03:18  lr: 0.000014  loss: 1.3744 (1.3833)  time: 0.7493  data: 0.0001  max mem: 14938
[17:41:33.926027] Epoch: [2]  [100/345]  eta: 0:03:03  lr: 0.000014  loss: 1.3708 (1.3813)  time: 0.7502  data: 0.0001  max mem: 14938
[17:41:48.950854] Epoch: [2]  [120/345]  eta: 0:02:48  lr: 0.000015  loss: 1.3643 (1.3789)  time: 0.7512  data: 0.0001  max mem: 14938
[17:42:03.969431] Epoch: [2]  [140/345]  eta: 0:02:33  lr: 0.000015  loss: 1.3576 (1.3760)  time: 0.7509  data: 0.0001  max mem: 14938
[17:42:18.964959] Epoch: [2]  [160/345]  eta: 0:02:18  lr: 0.000015  loss: 1.3560 (1.3741)  time: 0.7497  data: 0.0001  max mem: 14938
[17:42:33.960970] Epoch: [2]  [180/345]  eta: 0:02:03  lr: 0.000016  loss: 1.3545 (1.3721)  time: 0.7498  data: 0.0001  max mem: 14938
[17:42:48.954655] Epoch: [2]  [200/345]  eta: 0:01:48  lr: 0.000016  loss: 1.3490 (1.3699)  time: 0.7496  data: 0.0001  max mem: 14938
[17:43:03.938846] Epoch: [2]  [220/345]  eta: 0:01:33  lr: 0.000016  loss: 1.3484 (1.3680)  time: 0.7492  data: 0.0001  max mem: 14938
[17:43:18.927613] Epoch: [2]  [240/345]  eta: 0:01:18  lr: 0.000017  loss: 1.3415 (1.3660)  time: 0.7494  data: 0.0001  max mem: 14938
[17:43:33.921743] Epoch: [2]  [260/345]  eta: 0:01:03  lr: 0.000017  loss: 1.3398 (1.3645)  time: 0.7497  data: 0.0001  max mem: 14938
[17:43:48.912978] Epoch: [2]  [280/345]  eta: 0:00:48  lr: 0.000018  loss: 1.3390 (1.3629)  time: 0.7495  data: 0.0001  max mem: 14938
[17:44:03.909484] Epoch: [2]  [300/345]  eta: 0:00:33  lr: 0.000018  loss: 1.3290 (1.3610)  time: 0.7498  data: 0.0001  max mem: 14938
[17:44:18.902632] Epoch: [2]  [320/345]  eta: 0:00:18  lr: 0.000018  loss: 1.3324 (1.3595)  time: 0.7496  data: 0.0001  max mem: 14938
[17:44:33.896657] Epoch: [2]  [340/345]  eta: 0:00:03  lr: 0.000019  loss: 1.3339 (1.3582)  time: 0.7497  data: 0.0001  max mem: 14938
[17:44:36.895272] Epoch: [2]  [344/345]  eta: 0:00:00  lr: 0.000019  loss: 1.3339 (1.3580)  time: 0.7496  data: 0.0001  max mem: 14938
[17:44:36.959491] Epoch: [2] Total time: 0:04:18 (0.7499 s / it)
[17:44:36.959947] Averaged stats: lr: 0.000019  loss: 1.3339 (1.3580)
[17:44:37.296448] Test:  [  0/345]  eta: 0:01:54  loss: 1.3401 (1.3401)  time: 0.3320  data: 0.1501  max mem: 14938
[17:44:39.132304] Test:  [ 10/345]  eta: 0:01:05  loss: 1.3419 (1.3417)  time: 0.1970  data: 0.0137  max mem: 14938
[17:44:40.970352] Test:  [ 20/345]  eta: 0:01:01  loss: 1.3420 (1.3414)  time: 0.1836  data: 0.0001  max mem: 14938
[17:44:42.813044] Test:  [ 30/345]  eta: 0:00:59  loss: 1.3428 (1.3418)  time: 0.1840  data: 0.0001  max mem: 14938
[17:44:44.658604] Test:  [ 40/345]  eta: 0:00:57  loss: 1.3432 (1.3422)  time: 0.1844  data: 0.0001  max mem: 14938
[17:44:46.508514] Test:  [ 50/345]  eta: 0:00:55  loss: 1.3432 (1.3424)  time: 0.1847  data: 0.0001  max mem: 14938
[17:44:48.362379] Test:  [ 60/345]  eta: 0:00:53  loss: 1.3426 (1.3426)  time: 0.1851  data: 0.0001  max mem: 14938
[17:44:50.218755] Test:  [ 70/345]  eta: 0:00:51  loss: 1.3422 (1.3426)  time: 0.1855  data: 0.0001  max mem: 14938
[17:44:52.077931] Test:  [ 80/345]  eta: 0:00:49  loss: 1.3431 (1.3426)  time: 0.1857  data: 0.0001  max mem: 14938
[17:44:53.941876] Test:  [ 90/345]  eta: 0:00:47  loss: 1.3439 (1.3428)  time: 0.1861  data: 0.0001  max mem: 14938
[17:44:55.809658] Test:  [100/345]  eta: 0:00:45  loss: 1.3436 (1.3427)  time: 0.1865  data: 0.0001  max mem: 14938
[17:44:57.680694] Test:  [110/345]  eta: 0:00:43  loss: 1.3429 (1.3428)  time: 0.1869  data: 0.0001  max mem: 14938
[17:44:59.554958] Test:  [120/345]  eta: 0:00:41  loss: 1.3423 (1.3427)  time: 0.1872  data: 0.0001  max mem: 14938
[17:45:01.434858] Test:  [130/345]  eta: 0:00:40  loss: 1.3427 (1.3428)  time: 0.1877  data: 0.0001  max mem: 14938
[17:45:03.315602] Test:  [140/345]  eta: 0:00:38  loss: 1.3431 (1.3428)  time: 0.1880  data: 0.0001  max mem: 14938
[17:45:05.197987] Test:  [150/345]  eta: 0:00:36  loss: 1.3428 (1.3427)  time: 0.1881  data: 0.0001  max mem: 14938
[17:45:07.084345] Test:  [160/345]  eta: 0:00:34  loss: 1.3429 (1.3428)  time: 0.1884  data: 0.0001  max mem: 14938
[17:45:08.974540] Test:  [170/345]  eta: 0:00:32  loss: 1.3426 (1.3428)  time: 0.1888  data: 0.0001  max mem: 14938
[17:45:10.869962] Test:  [180/345]  eta: 0:00:30  loss: 1.3411 (1.3427)  time: 0.1892  data: 0.0001  max mem: 14938
[17:45:12.768785] Test:  [190/345]  eta: 0:00:29  loss: 1.3422 (1.3427)  time: 0.1897  data: 0.0001  max mem: 14938
[17:45:14.670772] Test:  [200/345]  eta: 0:00:27  loss: 1.3428 (1.3427)  time: 0.1900  data: 0.0001  max mem: 14938
[17:45:16.575314] Test:  [210/345]  eta: 0:00:25  loss: 1.3426 (1.3427)  time: 0.1903  data: 0.0001  max mem: 14938
[17:45:18.484899] Test:  [220/345]  eta: 0:00:23  loss: 1.3418 (1.3427)  time: 0.1907  data: 0.0001  max mem: 14938
[17:45:20.398880] Test:  [230/345]  eta: 0:00:21  loss: 1.3439 (1.3428)  time: 0.1911  data: 0.0001  max mem: 14938
[17:45:22.317031] Test:  [240/345]  eta: 0:00:19  loss: 1.3441 (1.3428)  time: 0.1916  data: 0.0001  max mem: 14938
[17:45:24.236264] Test:  [250/345]  eta: 0:00:17  loss: 1.3431 (1.3428)  time: 0.1918  data: 0.0001  max mem: 14938
[17:45:26.159975] Test:  [260/345]  eta: 0:00:16  loss: 1.3429 (1.3428)  time: 0.1921  data: 0.0001  max mem: 14938
[17:45:28.085966] Test:  [270/345]  eta: 0:00:14  loss: 1.3436 (1.3429)  time: 0.1924  data: 0.0001  max mem: 14938
[17:45:30.016405] Test:  [280/345]  eta: 0:00:12  loss: 1.3448 (1.3429)  time: 0.1928  data: 0.0001  max mem: 14938
[17:45:31.950634] Test:  [290/345]  eta: 0:00:10  loss: 1.3435 (1.3429)  time: 0.1932  data: 0.0001  max mem: 14938
[17:45:33.887692] Test:  [300/345]  eta: 0:00:08  loss: 1.3426 (1.3429)  time: 0.1935  data: 0.0001  max mem: 14938
[17:45:35.825585] Test:  [310/345]  eta: 0:00:06  loss: 1.3421 (1.3428)  time: 0.1937  data: 0.0001  max mem: 14938
[17:45:37.769498] Test:  [320/345]  eta: 0:00:04  loss: 1.3428 (1.3429)  time: 0.1940  data: 0.0001  max mem: 14938
[17:45:39.713357] Test:  [330/345]  eta: 0:00:02  loss: 1.3440 (1.3429)  time: 0.1943  data: 0.0001  max mem: 14938
[17:45:41.664188] Test:  [340/345]  eta: 0:00:00  loss: 1.3431 (1.3429)  time: 0.1947  data: 0.0001  max mem: 14938
[17:45:42.446964] Test:  [344/345]  eta: 0:00:00  loss: 1.3435 (1.3429)  time: 0.1949  data: 0.0001  max mem: 14938
[17:45:42.506902] Test: Total time: 0:01:05 (0.1900 s / it)
[17:45:52.849744] Test:  [ 0/57]  eta: 0:00:18  loss: 1.3513 (1.3513)  time: 0.3221  data: 0.1420  max mem: 14938
[17:45:54.666595] Test:  [10/57]  eta: 0:00:09  loss: 1.3483 (1.3475)  time: 0.1944  data: 0.0130  max mem: 14938
[17:45:56.486994] Test:  [20/57]  eta: 0:00:06  loss: 1.3483 (1.3466)  time: 0.1818  data: 0.0001  max mem: 14938
[17:45:58.311981] Test:  [30/57]  eta: 0:00:05  loss: 1.3410 (1.3424)  time: 0.1822  data: 0.0001  max mem: 14938
[17:46:00.142979] Test:  [40/57]  eta: 0:00:03  loss: 1.3346 (1.3398)  time: 0.1827  data: 0.0001  max mem: 14938
[17:46:01.976946] Test:  [50/57]  eta: 0:00:01  loss: 1.3346 (1.3389)  time: 0.1832  data: 0.0001  max mem: 14938
[17:46:02.966042] Test:  [56/57]  eta: 0:00:00  loss: 1.3385 (1.3387)  time: 0.1777  data: 0.0001  max mem: 14938
[17:46:03.022992] Test: Total time: 0:00:10 (0.1841 s / it)
[17:46:04.783931] Dice score of the network on the train images: 0.000000, val images: 0.000000
[17:46:04.788391] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:46:05.673251] Epoch: [3]  [  0/345]  eta: 0:05:04  lr: 0.000019  loss: 1.3233 (1.3233)  time: 0.8839  data: 0.1436  max mem: 14938
[17:46:20.538913] Epoch: [3]  [ 20/345]  eta: 0:04:03  lr: 0.000019  loss: 1.3268 (1.3270)  time: 0.7432  data: 0.0001  max mem: 14938
[17:46:35.433658] Epoch: [3]  [ 40/345]  eta: 0:03:47  lr: 0.000019  loss: 1.3227 (1.3284)  time: 0.7447  data: 0.0001  max mem: 14938
[17:46:50.374510] Epoch: [3]  [ 60/345]  eta: 0:03:32  lr: 0.000020  loss: 1.3264 (1.3277)  time: 0.7470  data: 0.0001  max mem: 14938
[17:47:05.329315] Epoch: [3]  [ 80/345]  eta: 0:03:18  lr: 0.000020  loss: 1.3173 (1.3259)  time: 0.7477  data: 0.0001  max mem: 14938
[17:47:20.297842] Epoch: [3]  [100/345]  eta: 0:03:03  lr: 0.000021  loss: 1.3134 (1.3249)  time: 0.7484  data: 0.0001  max mem: 14938
[17:47:35.289339] Epoch: [3]  [120/345]  eta: 0:02:48  lr: 0.000021  loss: 1.3152 (1.3246)  time: 0.7495  data: 0.0001  max mem: 14938
[17:47:50.293929] Epoch: [3]  [140/345]  eta: 0:02:33  lr: 0.000021  loss: 1.3108 (1.3230)  time: 0.7502  data: 0.0001  max mem: 14938
[17:48:05.298037] Epoch: [3]  [160/345]  eta: 0:02:18  lr: 0.000022  loss: 1.3077 (1.3214)  time: 0.7502  data: 0.0001  max mem: 14938
[17:48:20.308447] Epoch: [3]  [180/345]  eta: 0:02:03  lr: 0.000022  loss: 1.3088 (1.3203)  time: 0.7505  data: 0.0001  max mem: 14938
[17:48:35.435638] Epoch: [3]  [200/345]  eta: 0:01:48  lr: 0.000022  loss: 1.3048 (1.3189)  time: 0.7563  data: 0.0001  max mem: 14938
[17:48:50.434539] Epoch: [3]  [220/345]  eta: 0:01:33  lr: 0.000023  loss: 1.3027 (1.3180)  time: 0.7499  data: 0.0001  max mem: 14938
[17:49:05.429795] Epoch: [3]  [240/345]  eta: 0:01:18  lr: 0.000023  loss: 1.2995 (1.3170)  time: 0.7497  data: 0.0001  max mem: 14938
[17:49:20.427000] Epoch: [3]  [260/345]  eta: 0:01:03  lr: 0.000023  loss: 1.2995 (1.3157)  time: 0.7498  data: 0.0001  max mem: 14938
[17:49:35.411319] Epoch: [3]  [280/345]  eta: 0:00:48  lr: 0.000024  loss: 1.2979 (1.3145)  time: 0.7492  data: 0.0001  max mem: 14938
[17:49:50.391055] Epoch: [3]  [300/345]  eta: 0:00:33  lr: 0.000024  loss: 1.2991 (1.3137)  time: 0.7489  data: 0.0001  max mem: 14938
[17:50:05.373369] Epoch: [3]  [320/345]  eta: 0:00:18  lr: 0.000025  loss: 1.2967 (1.3128)  time: 0.7491  data: 0.0001  max mem: 14938
[17:50:20.353981] Epoch: [3]  [340/345]  eta: 0:00:03  lr: 0.000025  loss: 1.2926 (1.3118)  time: 0.7490  data: 0.0001  max mem: 14938
[17:50:23.350137] Epoch: [3]  [344/345]  eta: 0:00:00  lr: 0.000025  loss: 1.2922 (1.3117)  time: 0.7490  data: 0.0001  max mem: 14938
[17:50:23.407801] Epoch: [3] Total time: 0:04:18 (0.7496 s / it)
[17:50:23.408038] Averaged stats: lr: 0.000025  loss: 1.2922 (1.3117)
[17:50:23.747741] Test:  [  0/345]  eta: 0:01:55  loss: 1.3003 (1.3003)  time: 0.3343  data: 0.1530  max mem: 14938
[17:50:25.582288] Test:  [ 10/345]  eta: 0:01:06  loss: 1.2929 (1.2935)  time: 0.1971  data: 0.0140  max mem: 14938
[17:50:27.419534] Test:  [ 20/345]  eta: 0:01:01  loss: 1.2918 (1.2925)  time: 0.1835  data: 0.0001  max mem: 14938
[17:50:29.261274] Test:  [ 30/345]  eta: 0:00:59  loss: 1.2912 (1.2926)  time: 0.1839  data: 0.0001  max mem: 14938
[17:50:31.106336] Test:  [ 40/345]  eta: 0:00:57  loss: 1.2924 (1.2925)  time: 0.1843  data: 0.0001  max mem: 14938
[17:50:32.954672] Test:  [ 50/345]  eta: 0:00:55  loss: 1.2926 (1.2925)  time: 0.1846  data: 0.0001  max mem: 14938
[17:50:34.807046] Test:  [ 60/345]  eta: 0:00:53  loss: 1.2913 (1.2922)  time: 0.1850  data: 0.0001  max mem: 14938
[17:50:36.662364] Test:  [ 70/345]  eta: 0:00:51  loss: 1.2925 (1.2923)  time: 0.1853  data: 0.0001  max mem: 14938
[17:50:38.521488] Test:  [ 80/345]  eta: 0:00:49  loss: 1.2925 (1.2922)  time: 0.1857  data: 0.0001  max mem: 14938
[17:50:40.383794] Test:  [ 90/345]  eta: 0:00:47  loss: 1.2900 (1.2919)  time: 0.1860  data: 0.0001  max mem: 14938
[17:50:42.248951] Test:  [100/345]  eta: 0:00:45  loss: 1.2897 (1.2919)  time: 0.1863  data: 0.0001  max mem: 14938
[17:50:44.116832] Test:  [110/345]  eta: 0:00:43  loss: 1.2898 (1.2918)  time: 0.1866  data: 0.0001  max mem: 14938
[17:50:45.989826] Test:  [120/345]  eta: 0:00:41  loss: 1.2922 (1.2918)  time: 0.1870  data: 0.0001  max mem: 14938
[17:50:47.866935] Test:  [130/345]  eta: 0:00:40  loss: 1.2907 (1.2916)  time: 0.1875  data: 0.0001  max mem: 14938
[17:50:49.746424] Test:  [140/345]  eta: 0:00:38  loss: 1.2907 (1.2917)  time: 0.1878  data: 0.0001  max mem: 14938
[17:50:51.629706] Test:  [150/345]  eta: 0:00:36  loss: 1.2925 (1.2916)  time: 0.1881  data: 0.0001  max mem: 14938
[17:50:53.515259] Test:  [160/345]  eta: 0:00:34  loss: 1.2920 (1.2917)  time: 0.1884  data: 0.0001  max mem: 14938
[17:50:55.404949] Test:  [170/345]  eta: 0:00:32  loss: 1.2911 (1.2917)  time: 0.1887  data: 0.0001  max mem: 14938
[17:50:57.299040] Test:  [180/345]  eta: 0:00:30  loss: 1.2904 (1.2916)  time: 0.1891  data: 0.0001  max mem: 14938
[17:50:59.197889] Test:  [190/345]  eta: 0:00:29  loss: 1.2914 (1.2916)  time: 0.1896  data: 0.0001  max mem: 14938
[17:51:01.099545] Test:  [200/345]  eta: 0:00:27  loss: 1.2927 (1.2917)  time: 0.1900  data: 0.0001  max mem: 14938
[17:51:03.004610] Test:  [210/345]  eta: 0:00:25  loss: 1.2927 (1.2916)  time: 0.1903  data: 0.0001  max mem: 14938
[17:51:04.914187] Test:  [220/345]  eta: 0:00:23  loss: 1.2903 (1.2916)  time: 0.1907  data: 0.0001  max mem: 14938
[17:51:06.826526] Test:  [230/345]  eta: 0:00:21  loss: 1.2902 (1.2915)  time: 0.1910  data: 0.0001  max mem: 14938
[17:51:08.743174] Test:  [240/345]  eta: 0:00:19  loss: 1.2876 (1.2915)  time: 0.1914  data: 0.0001  max mem: 14938
[17:51:10.661985] Test:  [250/345]  eta: 0:00:17  loss: 1.2922 (1.2915)  time: 0.1917  data: 0.0001  max mem: 14938
[17:51:12.585821] Test:  [260/345]  eta: 0:00:16  loss: 1.2924 (1.2916)  time: 0.1921  data: 0.0001  max mem: 14938
[17:51:14.512986] Test:  [270/345]  eta: 0:00:14  loss: 1.2917 (1.2916)  time: 0.1925  data: 0.0001  max mem: 14938
[17:51:16.442145] Test:  [280/345]  eta: 0:00:12  loss: 1.2906 (1.2915)  time: 0.1928  data: 0.0001  max mem: 14938
[17:51:18.374879] Test:  [290/345]  eta: 0:00:10  loss: 1.2922 (1.2915)  time: 0.1930  data: 0.0001  max mem: 14938
[17:51:20.310491] Test:  [300/345]  eta: 0:00:08  loss: 1.2935 (1.2916)  time: 0.1934  data: 0.0001  max mem: 14938
[17:51:22.249791] Test:  [310/345]  eta: 0:00:06  loss: 1.2935 (1.2916)  time: 0.1937  data: 0.0001  max mem: 14938
[17:51:24.190547] Test:  [320/345]  eta: 0:00:04  loss: 1.2903 (1.2915)  time: 0.1940  data: 0.0001  max mem: 14938
[17:51:26.134913] Test:  [330/345]  eta: 0:00:02  loss: 1.2900 (1.2915)  time: 0.1942  data: 0.0001  max mem: 14938
[17:51:28.083474] Test:  [340/345]  eta: 0:00:00  loss: 1.2913 (1.2916)  time: 0.1946  data: 0.0001  max mem: 14938
[17:51:28.864827] Test:  [344/345]  eta: 0:00:00  loss: 1.2901 (1.2915)  time: 0.1948  data: 0.0001  max mem: 14938
[17:51:28.924796] Test: Total time: 0:01:05 (0.1899 s / it)
[17:51:39.324200] Test:  [ 0/57]  eta: 0:00:17  loss: 1.3052 (1.3052)  time: 0.3128  data: 0.1336  max mem: 14938
[17:51:41.139063] Test:  [10/57]  eta: 0:00:09  loss: 1.2997 (1.2988)  time: 0.1934  data: 0.0122  max mem: 14938
[17:51:42.958990] Test:  [20/57]  eta: 0:00:06  loss: 1.2997 (1.2981)  time: 0.1817  data: 0.0001  max mem: 14938
[17:51:44.782872] Test:  [30/57]  eta: 0:00:05  loss: 1.2841 (1.2903)  time: 0.1821  data: 0.0001  max mem: 14938
[17:51:46.611658] Test:  [40/57]  eta: 0:00:03  loss: 1.2727 (1.2853)  time: 0.1826  data: 0.0001  max mem: 14938
[17:51:48.444115] Test:  [50/57]  eta: 0:00:01  loss: 1.2727 (1.2834)  time: 0.1830  data: 0.0001  max mem: 14938
[17:51:49.432670] Test:  [56/57]  eta: 0:00:00  loss: 1.2803 (1.2832)  time: 0.1776  data: 0.0001  max mem: 14938
[17:51:49.489386] Test: Total time: 0:00:10 (0.1838 s / it)
[17:51:51.290845] Dice score of the network on the train images: 0.000000, val images: 0.000000
[17:51:51.295233] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:51:52.183354] Epoch: [4]  [  0/345]  eta: 0:05:06  lr: 0.000025  loss: 1.2985 (1.2985)  time: 0.8871  data: 0.1442  max mem: 14938
[17:52:07.062149] Epoch: [4]  [ 20/345]  eta: 0:04:03  lr: 0.000025  loss: 1.2862 (1.2910)  time: 0.7439  data: 0.0001  max mem: 14938
[17:52:22.000517] Epoch: [4]  [ 40/345]  eta: 0:03:48  lr: 0.000026  loss: 1.2880 (1.2895)  time: 0.7469  data: 0.0001  max mem: 14938
[17:52:36.966247] Epoch: [4]  [ 60/345]  eta: 0:03:33  lr: 0.000026  loss: 1.2772 (1.2875)  time: 0.7482  data: 0.0001  max mem: 14938
[17:52:51.970902] Epoch: [4]  [ 80/345]  eta: 0:03:18  lr: 0.000026  loss: 1.2739 (1.2849)  time: 0.7502  data: 0.0001  max mem: 14938
[17:53:06.989023] Epoch: [4]  [100/345]  eta: 0:03:03  lr: 0.000027  loss: 1.2696 (1.2826)  time: 0.7509  data: 0.0001  max mem: 14938
[17:53:21.996622] Epoch: [4]  [120/345]  eta: 0:02:48  lr: 0.000027  loss: 1.2638 (1.2795)  time: 0.7503  data: 0.0001  max mem: 14938
[17:53:37.005246] Epoch: [4]  [140/345]  eta: 0:02:33  lr: 0.000028  loss: 1.2583 (1.2768)  time: 0.7504  data: 0.0001  max mem: 14938
[17:53:52.008276] Epoch: [4]  [160/345]  eta: 0:02:18  lr: 0.000028  loss: 1.2646 (1.2751)  time: 0.7501  data: 0.0001  max mem: 14938
[17:54:07.016237] Epoch: [4]  [180/345]  eta: 0:02:03  lr: 0.000028  loss: 1.2414 (1.2719)  time: 0.7504  data: 0.0001  max mem: 14938
[17:54:22.025410] Epoch: [4]  [200/345]  eta: 0:01:48  lr: 0.000029  loss: 1.2341 (1.2682)  time: 0.7504  data: 0.0001  max mem: 14938
[17:54:37.019415] Epoch: [4]  [220/345]  eta: 0:01:33  lr: 0.000029  loss: 1.2287 (1.2650)  time: 0.7497  data: 0.0001  max mem: 14938
[17:54:52.016468] Epoch: [4]  [240/345]  eta: 0:01:18  lr: 0.000029  loss: 1.2205 (1.2614)  time: 0.7498  data: 0.0001  max mem: 14938
[17:55:07.013945] Epoch: [4]  [260/345]  eta: 0:01:03  lr: 0.000030  loss: 1.2116 (1.2577)  time: 0.7498  data: 0.0001  max mem: 14938
[17:55:21.998393] Epoch: [4]  [280/345]  eta: 0:00:48  lr: 0.000030  loss: 1.2045 (1.2540)  time: 0.7492  data: 0.0001  max mem: 14938
[17:55:36.973632] Epoch: [4]  [300/345]  eta: 0:00:33  lr: 0.000030  loss: 1.1858 (1.2498)  time: 0.7487  data: 0.0001  max mem: 14938
[17:55:51.945521] Epoch: [4]  [320/345]  eta: 0:00:18  lr: 0.000031  loss: 1.1772 (1.2456)  time: 0.7485  data: 0.0001  max mem: 14938
[17:56:06.896911] Epoch: [4]  [340/345]  eta: 0:00:03  lr: 0.000031  loss: 1.1821 (1.2419)  time: 0.7475  data: 0.0001  max mem: 14938
[17:56:09.887152] Epoch: [4]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 1.1821 (1.2414)  time: 0.7474  data: 0.0001  max mem: 14938
[17:56:09.948755] Epoch: [4] Total time: 0:04:18 (0.7497 s / it)
[17:56:09.949207] Averaged stats: lr: 0.000031  loss: 1.1821 (1.2414)
[17:56:10.286636] Test:  [  0/345]  eta: 0:01:55  loss: 1.1807 (1.1807)  time: 0.3337  data: 0.1519  max mem: 14938
[17:56:12.121390] Test:  [ 10/345]  eta: 0:01:06  loss: 1.1651 (1.1607)  time: 0.1971  data: 0.0139  max mem: 14938
[17:56:13.957050] Test:  [ 20/345]  eta: 0:01:01  loss: 1.1549 (1.1592)  time: 0.1835  data: 0.0001  max mem: 14938
[17:56:15.797487] Test:  [ 30/345]  eta: 0:00:59  loss: 1.1521 (1.1532)  time: 0.1838  data: 0.0001  max mem: 14938
[17:56:17.641558] Test:  [ 40/345]  eta: 0:00:57  loss: 1.1521 (1.1554)  time: 0.1842  data: 0.0001  max mem: 14938
[17:56:19.489032] Test:  [ 50/345]  eta: 0:00:55  loss: 1.1537 (1.1534)  time: 0.1845  data: 0.0001  max mem: 14938
[17:56:21.341254] Test:  [ 60/345]  eta: 0:00:53  loss: 1.1500 (1.1537)  time: 0.1849  data: 0.0001  max mem: 14938
[17:56:23.195942] Test:  [ 70/345]  eta: 0:00:51  loss: 1.1496 (1.1530)  time: 0.1853  data: 0.0001  max mem: 14938
[17:56:25.053949] Test:  [ 80/345]  eta: 0:00:49  loss: 1.1451 (1.1522)  time: 0.1856  data: 0.0001  max mem: 14938
[17:56:26.915078] Test:  [ 90/345]  eta: 0:00:47  loss: 1.1495 (1.1524)  time: 0.1859  data: 0.0001  max mem: 14938
[17:56:28.780656] Test:  [100/345]  eta: 0:00:45  loss: 1.1515 (1.1518)  time: 0.1863  data: 0.0001  max mem: 14938
[17:56:30.648327] Test:  [110/345]  eta: 0:00:43  loss: 1.1515 (1.1524)  time: 0.1866  data: 0.0001  max mem: 14938
[17:56:32.520278] Test:  [120/345]  eta: 0:00:41  loss: 1.1475 (1.1518)  time: 0.1869  data: 0.0001  max mem: 14938
[17:56:34.394309] Test:  [130/345]  eta: 0:00:40  loss: 1.1430 (1.1505)  time: 0.1872  data: 0.0001  max mem: 14938
[17:56:36.273787] Test:  [140/345]  eta: 0:00:38  loss: 1.1489 (1.1509)  time: 0.1876  data: 0.0001  max mem: 14938
[17:56:38.154803] Test:  [150/345]  eta: 0:00:36  loss: 1.1548 (1.1513)  time: 0.1880  data: 0.0001  max mem: 14938
[17:56:40.038511] Test:  [160/345]  eta: 0:00:34  loss: 1.1490 (1.1500)  time: 0.1882  data: 0.0001  max mem: 14938
[17:56:41.924497] Test:  [170/345]  eta: 0:00:32  loss: 1.1452 (1.1505)  time: 0.1884  data: 0.0001  max mem: 14938
[17:56:43.817013] Test:  [180/345]  eta: 0:00:30  loss: 1.1457 (1.1501)  time: 0.1889  data: 0.0001  max mem: 14938
[17:56:45.712656] Test:  [190/345]  eta: 0:00:29  loss: 1.1442 (1.1498)  time: 0.1894  data: 0.0001  max mem: 14938
[17:56:47.611802] Test:  [200/345]  eta: 0:00:27  loss: 1.1534 (1.1502)  time: 0.1897  data: 0.0001  max mem: 14938
[17:56:49.514251] Test:  [210/345]  eta: 0:00:25  loss: 1.1618 (1.1509)  time: 0.1900  data: 0.0001  max mem: 14938
[17:56:51.420932] Test:  [220/345]  eta: 0:00:23  loss: 1.1641 (1.1514)  time: 0.1904  data: 0.0001  max mem: 14938
[17:56:53.332089] Test:  [230/345]  eta: 0:00:21  loss: 1.1523 (1.1514)  time: 0.1908  data: 0.0001  max mem: 14938
[17:56:55.245986] Test:  [240/345]  eta: 0:00:19  loss: 1.1593 (1.1519)  time: 0.1912  data: 0.0001  max mem: 14938
[17:56:57.162562] Test:  [250/345]  eta: 0:00:17  loss: 1.1619 (1.1520)  time: 0.1915  data: 0.0001  max mem: 14938
[17:56:59.084287] Test:  [260/345]  eta: 0:00:15  loss: 1.1580 (1.1521)  time: 0.1919  data: 0.0001  max mem: 14938
[17:57:01.009381] Test:  [270/345]  eta: 0:00:14  loss: 1.1544 (1.1522)  time: 0.1923  data: 0.0001  max mem: 14938
[17:57:02.937902] Test:  [280/345]  eta: 0:00:12  loss: 1.1562 (1.1528)  time: 0.1926  data: 0.0001  max mem: 14938
[17:57:04.869103] Test:  [290/345]  eta: 0:00:10  loss: 1.1690 (1.1533)  time: 0.1929  data: 0.0001  max mem: 14938
[17:57:06.803122] Test:  [300/345]  eta: 0:00:08  loss: 1.1534 (1.1533)  time: 0.1932  data: 0.0001  max mem: 14938
[17:57:08.740786] Test:  [310/345]  eta: 0:00:06  loss: 1.1511 (1.1535)  time: 0.1935  data: 0.0001  max mem: 14938
[17:57:10.679442] Test:  [320/345]  eta: 0:00:04  loss: 1.1511 (1.1533)  time: 0.1938  data: 0.0001  max mem: 14938
[17:57:12.622821] Test:  [330/345]  eta: 0:00:02  loss: 1.1548 (1.1534)  time: 0.1941  data: 0.0001  max mem: 14938
[17:57:14.569740] Test:  [340/345]  eta: 0:00:00  loss: 1.1590 (1.1534)  time: 0.1945  data: 0.0001  max mem: 14938
[17:57:15.349178] Test:  [344/345]  eta: 0:00:00  loss: 1.1548 (1.1532)  time: 0.1946  data: 0.0001  max mem: 14938
[17:57:15.408729] Test: Total time: 0:01:05 (0.1897 s / it)
[17:57:25.776417] Test:  [ 0/57]  eta: 0:00:18  loss: 1.2297 (1.2297)  time: 0.3237  data: 0.1445  max mem: 14938
[17:57:27.586299] Test:  [10/57]  eta: 0:00:09  loss: 1.2044 (1.1936)  time: 0.1939  data: 0.0132  max mem: 14938
[17:57:29.404118] Test:  [20/57]  eta: 0:00:06  loss: 1.2150 (1.1951)  time: 0.1813  data: 0.0001  max mem: 14938
[17:57:31.227898] Test:  [30/57]  eta: 0:00:05  loss: 1.1271 (1.1480)  time: 0.1820  data: 0.0001  max mem: 14938
[17:57:33.055365] Test:  [40/57]  eta: 0:00:03  loss: 1.0373 (1.1182)  time: 0.1825  data: 0.0001  max mem: 14938
[17:57:34.886046] Test:  [50/57]  eta: 0:00:01  loss: 1.0397 (1.1097)  time: 0.1828  data: 0.0001  max mem: 14938
[17:57:35.872532] Test:  [56/57]  eta: 0:00:00  loss: 1.0971 (1.1137)  time: 0.1774  data: 0.0001  max mem: 14938
[17:57:35.932264] Test: Total time: 0:00:10 (0.1839 s / it)
[17:57:37.666599] Dice score of the network on the train images: 0.523335, val images: 0.622685
[17:57:37.666823] saving best_prec_model_0 @ epoch 4
[17:57:38.753188] saving best_rec_model_0 @ epoch 4
[17:57:39.798772] saving best_dice_model_0 @ epoch 4
[17:57:40.841095] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:57:41.732620] Epoch: [5]  [  0/345]  eta: 0:05:07  lr: 0.000031  loss: 1.2068 (1.2068)  time: 0.8903  data: 0.1491  max mem: 14938
[17:57:56.565898] Epoch: [5]  [ 20/345]  eta: 0:04:03  lr: 0.000032  loss: 1.1559 (1.1634)  time: 0.7416  data: 0.0001  max mem: 14938
[17:58:11.559116] Epoch: [5]  [ 40/345]  eta: 0:03:48  lr: 0.000032  loss: 1.1517 (1.1597)  time: 0.7496  data: 0.0001  max mem: 14938
[17:58:26.476898] Epoch: [5]  [ 60/345]  eta: 0:03:33  lr: 0.000032  loss: 1.1606 (1.1605)  time: 0.7458  data: 0.0001  max mem: 14938
[17:58:41.433541] Epoch: [5]  [ 80/345]  eta: 0:03:18  lr: 0.000033  loss: 1.1418 (1.1572)  time: 0.7478  data: 0.0001  max mem: 14938
[17:58:56.422548] Epoch: [5]  [100/345]  eta: 0:03:03  lr: 0.000033  loss: 1.1393 (1.1539)  time: 0.7494  data: 0.0001  max mem: 14938
[17:59:11.413696] Epoch: [5]  [120/345]  eta: 0:02:48  lr: 0.000033  loss: 1.1146 (1.1489)  time: 0.7495  data: 0.0001  max mem: 14938
[17:59:26.405410] Epoch: [5]  [140/345]  eta: 0:02:33  lr: 0.000034  loss: 1.1219 (1.1451)  time: 0.7495  data: 0.0001  max mem: 14938
[17:59:41.391096] Epoch: [5]  [160/345]  eta: 0:02:18  lr: 0.000034  loss: 1.1242 (1.1422)  time: 0.7492  data: 0.0001  max mem: 14938
[17:59:56.369667] Epoch: [5]  [180/345]  eta: 0:02:03  lr: 0.000035  loss: 1.1246 (1.1399)  time: 0.7489  data: 0.0001  max mem: 14938
[18:00:11.352484] Epoch: [5]  [200/345]  eta: 0:01:48  lr: 0.000035  loss: 1.0987 (1.1365)  time: 0.7491  data: 0.0001  max mem: 14938
[18:00:26.327001] Epoch: [5]  [220/345]  eta: 0:01:33  lr: 0.000035  loss: 1.0902 (1.1323)  time: 0.7486  data: 0.0001  max mem: 14938
[18:00:41.291930] Epoch: [5]  [240/345]  eta: 0:01:18  lr: 0.000036  loss: 1.0830 (1.1286)  time: 0.7482  data: 0.0001  max mem: 14938
[18:00:56.257503] Epoch: [5]  [260/345]  eta: 0:01:03  lr: 0.000036  loss: 1.0779 (1.1252)  time: 0.7482  data: 0.0001  max mem: 14938
[18:01:11.241583] Epoch: [5]  [280/345]  eta: 0:00:48  lr: 0.000036  loss: 1.0884 (1.1231)  time: 0.7492  data: 0.0001  max mem: 14938
[18:01:26.216721] Epoch: [5]  [300/345]  eta: 0:00:33  lr: 0.000037  loss: 1.0672 (1.1192)  time: 0.7487  data: 0.0001  max mem: 14938
[18:01:41.199680] Epoch: [5]  [320/345]  eta: 0:00:18  lr: 0.000037  loss: 1.0664 (1.1166)  time: 0.7491  data: 0.0001  max mem: 14938
[18:01:56.172079] Epoch: [5]  [340/345]  eta: 0:00:03  lr: 0.000037  loss: 1.0666 (1.1136)  time: 0.7486  data: 0.0001  max mem: 14938
[18:01:59.164472] Epoch: [5]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 1.0670 (1.1130)  time: 0.7485  data: 0.0001  max mem: 14938
[18:01:59.230541] Epoch: [5] Total time: 0:04:18 (0.7490 s / it)
[18:01:59.231023] Averaged stats: lr: 0.000037  loss: 1.0670 (1.1130)
[18:01:59.565033] Test:  [  0/345]  eta: 0:01:53  loss: 0.9771 (0.9771)  time: 0.3296  data: 0.1476  max mem: 14938
[18:02:01.398160] Test:  [ 10/345]  eta: 0:01:05  loss: 1.0181 (1.0137)  time: 0.1965  data: 0.0135  max mem: 14938
[18:02:03.233464] Test:  [ 20/345]  eta: 0:01:01  loss: 1.0187 (1.0177)  time: 0.1833  data: 0.0001  max mem: 14938
[18:02:05.074148] Test:  [ 30/345]  eta: 0:00:59  loss: 1.0226 (1.0222)  time: 0.1837  data: 0.0001  max mem: 14938
[18:02:06.918769] Test:  [ 40/345]  eta: 0:00:57  loss: 1.0190 (1.0208)  time: 0.1842  data: 0.0001  max mem: 14938
[18:02:08.766408] Test:  [ 50/345]  eta: 0:00:55  loss: 1.0161 (1.0214)  time: 0.1846  data: 0.0001  max mem: 14938
[18:02:10.616459] Test:  [ 60/345]  eta: 0:00:53  loss: 1.0100 (1.0198)  time: 0.1848  data: 0.0001  max mem: 14938
[18:02:12.470938] Test:  [ 70/345]  eta: 0:00:51  loss: 1.0151 (1.0210)  time: 0.1852  data: 0.0001  max mem: 14938
[18:02:14.327785] Test:  [ 80/345]  eta: 0:00:49  loss: 1.0213 (1.0211)  time: 0.1855  data: 0.0001  max mem: 14938
[18:02:16.189222] Test:  [ 90/345]  eta: 0:00:47  loss: 1.0125 (1.0203)  time: 0.1859  data: 0.0001  max mem: 14938
[18:02:18.053295] Test:  [100/345]  eta: 0:00:45  loss: 1.0125 (1.0196)  time: 0.1862  data: 0.0001  max mem: 14938
[18:02:19.921801] Test:  [110/345]  eta: 0:00:43  loss: 1.0104 (1.0192)  time: 0.1866  data: 0.0001  max mem: 14938
[18:02:21.793197] Test:  [120/345]  eta: 0:00:41  loss: 1.0170 (1.0190)  time: 0.1869  data: 0.0001  max mem: 14938
[18:02:23.667341] Test:  [130/345]  eta: 0:00:40  loss: 1.0229 (1.0198)  time: 0.1872  data: 0.0001  max mem: 14938
[18:02:25.545305] Test:  [140/345]  eta: 0:00:38  loss: 1.0299 (1.0206)  time: 0.1876  data: 0.0001  max mem: 14938
[18:02:27.427768] Test:  [150/345]  eta: 0:00:36  loss: 1.0299 (1.0208)  time: 0.1880  data: 0.0001  max mem: 14938
[18:02:29.311431] Test:  [160/345]  eta: 0:00:34  loss: 1.0271 (1.0205)  time: 0.1883  data: 0.0001  max mem: 14938
[18:02:31.198328] Test:  [170/345]  eta: 0:00:32  loss: 1.0159 (1.0204)  time: 0.1885  data: 0.0001  max mem: 14938
[18:02:33.091825] Test:  [180/345]  eta: 0:00:30  loss: 1.0183 (1.0204)  time: 0.1890  data: 0.0001  max mem: 14938
[18:02:34.987792] Test:  [190/345]  eta: 0:00:29  loss: 1.0174 (1.0201)  time: 0.1894  data: 0.0001  max mem: 14938
[18:02:36.888343] Test:  [200/345]  eta: 0:00:27  loss: 1.0270 (1.0208)  time: 0.1898  data: 0.0001  max mem: 14938
[18:02:38.790997] Test:  [210/345]  eta: 0:00:25  loss: 1.0294 (1.0208)  time: 0.1901  data: 0.0001  max mem: 14938
[18:02:40.697495] Test:  [220/345]  eta: 0:00:23  loss: 1.0052 (1.0199)  time: 0.1904  data: 0.0001  max mem: 14938
[18:02:42.609830] Test:  [230/345]  eta: 0:00:21  loss: 1.0055 (1.0195)  time: 0.1909  data: 0.0001  max mem: 14938
[18:02:44.524065] Test:  [240/345]  eta: 0:00:19  loss: 1.0190 (1.0201)  time: 0.1913  data: 0.0001  max mem: 14938
[18:02:46.441260] Test:  [250/345]  eta: 0:00:17  loss: 1.0284 (1.0201)  time: 0.1915  data: 0.0001  max mem: 14938
[18:02:48.364722] Test:  [260/345]  eta: 0:00:15  loss: 1.0279 (1.0206)  time: 0.1920  data: 0.0001  max mem: 14938
[18:02:50.290523] Test:  [270/345]  eta: 0:00:14  loss: 1.0298 (1.0207)  time: 0.1924  data: 0.0001  max mem: 14938
[18:02:52.218375] Test:  [280/345]  eta: 0:00:12  loss: 1.0294 (1.0210)  time: 0.1926  data: 0.0001  max mem: 14938
[18:02:54.148782] Test:  [290/345]  eta: 0:00:10  loss: 1.0135 (1.0213)  time: 0.1929  data: 0.0001  max mem: 14938
[18:02:56.083279] Test:  [300/345]  eta: 0:00:08  loss: 1.0262 (1.0219)  time: 0.1932  data: 0.0001  max mem: 14938
[18:02:58.020636] Test:  [310/345]  eta: 0:00:06  loss: 1.0228 (1.0217)  time: 0.1935  data: 0.0001  max mem: 14938
[18:02:59.959950] Test:  [320/345]  eta: 0:00:04  loss: 1.0138 (1.0216)  time: 0.1938  data: 0.0001  max mem: 14938
[18:03:01.902778] Test:  [330/345]  eta: 0:00:02  loss: 1.0152 (1.0216)  time: 0.1941  data: 0.0001  max mem: 14938
[18:03:03.849709] Test:  [340/345]  eta: 0:00:00  loss: 1.0157 (1.0212)  time: 0.1944  data: 0.0001  max mem: 14938
[18:03:04.630473] Test:  [344/345]  eta: 0:00:00  loss: 1.0157 (1.0213)  time: 0.1946  data: 0.0001  max mem: 14938
[18:03:04.690394] Test: Total time: 0:01:05 (0.1897 s / it)
[18:03:15.135959] Test:  [ 0/57]  eta: 0:00:18  loss: 1.1075 (1.1075)  time: 0.3238  data: 0.1448  max mem: 14938
[18:03:16.947537] Test:  [10/57]  eta: 0:00:09  loss: 1.0811 (1.0735)  time: 0.1941  data: 0.0132  max mem: 14938
[18:03:18.767470] Test:  [20/57]  eta: 0:00:06  loss: 1.1051 (1.0799)  time: 0.1815  data: 0.0001  max mem: 14938
[18:03:20.589247] Test:  [30/57]  eta: 0:00:05  loss: 0.9633 (1.0236)  time: 0.1820  data: 0.0001  max mem: 14938
[18:03:22.413722] Test:  [40/57]  eta: 0:00:03  loss: 0.8905 (0.9896)  time: 0.1823  data: 0.0001  max mem: 14938
[18:03:24.245827] Test:  [50/57]  eta: 0:00:01  loss: 0.8905 (0.9799)  time: 0.1828  data: 0.0001  max mem: 14938
[18:03:25.234735] Test:  [56/57]  eta: 0:00:00  loss: 0.9680 (0.9850)  time: 0.1774  data: 0.0001  max mem: 14938
[18:03:25.294679] Test: Total time: 0:00:10 (0.1839 s / it)
[18:03:27.070114] Dice score of the network on the train images: 0.669986, val images: 0.729704
[18:03:27.070333] saving best_prec_model_0 @ epoch 5
[18:03:28.187746] saving best_dice_model_0 @ epoch 5
[18:03:29.356793] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:03:30.242237] Epoch: [6]  [  0/345]  eta: 0:05:05  lr: 0.000038  loss: 1.0379 (1.0379)  time: 0.8844  data: 0.1419  max mem: 14938
[18:03:45.102055] Epoch: [6]  [ 20/345]  eta: 0:04:03  lr: 0.000038  loss: 1.0476 (1.0480)  time: 0.7429  data: 0.0001  max mem: 14938
[18:04:00.005555] Epoch: [6]  [ 40/345]  eta: 0:03:47  lr: 0.000038  loss: 1.0439 (1.0501)  time: 0.7451  data: 0.0001  max mem: 14938
[18:04:14.956117] Epoch: [6]  [ 60/345]  eta: 0:03:33  lr: 0.000039  loss: 1.0407 (1.0453)  time: 0.7475  data: 0.0001  max mem: 14938
[18:04:29.925187] Epoch: [6]  [ 80/345]  eta: 0:03:18  lr: 0.000039  loss: 1.0373 (1.0424)  time: 0.7484  data: 0.0001  max mem: 14938
[18:04:44.907107] Epoch: [6]  [100/345]  eta: 0:03:03  lr: 0.000039  loss: 1.0321 (1.0420)  time: 0.7491  data: 0.0001  max mem: 14938
[18:04:59.933051] Epoch: [6]  [120/345]  eta: 0:02:48  lr: 0.000040  loss: 1.0209 (1.0391)  time: 0.7513  data: 0.0001  max mem: 14938
[18:05:14.937683] Epoch: [6]  [140/345]  eta: 0:02:33  lr: 0.000040  loss: 1.0413 (1.0393)  time: 0.7502  data: 0.0001  max mem: 14938
[18:05:29.949783] Epoch: [6]  [160/345]  eta: 0:02:18  lr: 0.000040  loss: 1.0085 (1.0355)  time: 0.7506  data: 0.0001  max mem: 14938
[18:05:44.947678] Epoch: [6]  [180/345]  eta: 0:02:03  lr: 0.000041  loss: 1.0083 (1.0327)  time: 0.7498  data: 0.0001  max mem: 14938
[18:05:59.939574] Epoch: [6]  [200/345]  eta: 0:01:48  lr: 0.000041  loss: 1.0065 (1.0305)  time: 0.7495  data: 0.0001  max mem: 14938
[18:06:15.058670] Epoch: [6]  [220/345]  eta: 0:01:33  lr: 0.000041  loss: 1.0111 (1.0290)  time: 0.7559  data: 0.0001  max mem: 14938
[18:06:30.042310] Epoch: [6]  [240/345]  eta: 0:01:18  lr: 0.000042  loss: 0.9971 (1.0263)  time: 0.7491  data: 0.0001  max mem: 14938
[18:06:45.029519] Epoch: [6]  [260/345]  eta: 0:01:03  lr: 0.000042  loss: 0.9844 (1.0244)  time: 0.7493  data: 0.0001  max mem: 14938
[18:07:00.011087] Epoch: [6]  [280/345]  eta: 0:00:48  lr: 0.000043  loss: 0.9737 (1.0209)  time: 0.7490  data: 0.0001  max mem: 14938
[18:07:14.987203] Epoch: [6]  [300/345]  eta: 0:00:33  lr: 0.000043  loss: 0.9791 (1.0187)  time: 0.7488  data: 0.0001  max mem: 14938
[18:07:29.961140] Epoch: [6]  [320/345]  eta: 0:00:18  lr: 0.000043  loss: 0.9743 (1.0165)  time: 0.7486  data: 0.0001  max mem: 14938
[18:07:44.942960] Epoch: [6]  [340/345]  eta: 0:00:03  lr: 0.000044  loss: 0.9707 (1.0144)  time: 0.7490  data: 0.0001  max mem: 14938
[18:07:47.940149] Epoch: [6]  [344/345]  eta: 0:00:00  lr: 0.000044  loss: 0.9845 (1.0144)  time: 0.7492  data: 0.0001  max mem: 14938
[18:07:48.003013] Epoch: [6] Total time: 0:04:18 (0.7497 s / it)
[18:07:48.003483] Averaged stats: lr: 0.000044  loss: 0.9845 (1.0144)
[18:07:48.339175] Test:  [  0/345]  eta: 0:01:54  loss: 0.9482 (0.9482)  time: 0.3317  data: 0.1494  max mem: 14938
[18:07:50.173885] Test:  [ 10/345]  eta: 0:01:05  loss: 0.9387 (0.9375)  time: 0.1969  data: 0.0136  max mem: 14938
[18:07:52.009451] Test:  [ 20/345]  eta: 0:01:01  loss: 0.9484 (0.9474)  time: 0.1834  data: 0.0001  max mem: 14938
[18:07:53.850536] Test:  [ 30/345]  eta: 0:00:59  loss: 0.9482 (0.9459)  time: 0.1838  data: 0.0001  max mem: 14938
[18:07:55.695055] Test:  [ 40/345]  eta: 0:00:57  loss: 0.9501 (0.9496)  time: 0.1842  data: 0.0001  max mem: 14938
[18:07:57.543409] Test:  [ 50/345]  eta: 0:00:55  loss: 0.9494 (0.9465)  time: 0.1846  data: 0.0001  max mem: 14938
[18:07:59.395072] Test:  [ 60/345]  eta: 0:00:53  loss: 0.9337 (0.9455)  time: 0.1850  data: 0.0001  max mem: 14938
[18:08:01.250741] Test:  [ 70/345]  eta: 0:00:51  loss: 0.9574 (0.9489)  time: 0.1853  data: 0.0001  max mem: 14938
[18:08:03.109652] Test:  [ 80/345]  eta: 0:00:49  loss: 0.9657 (0.9513)  time: 0.1857  data: 0.0001  max mem: 14938
[18:08:04.971809] Test:  [ 90/345]  eta: 0:00:47  loss: 0.9552 (0.9513)  time: 0.1860  data: 0.0001  max mem: 14938
[18:08:06.837532] Test:  [100/345]  eta: 0:00:45  loss: 0.9364 (0.9499)  time: 0.1863  data: 0.0001  max mem: 14938
[18:08:08.705243] Test:  [110/345]  eta: 0:00:43  loss: 0.9378 (0.9491)  time: 0.1866  data: 0.0001  max mem: 14938
[18:08:10.577682] Test:  [120/345]  eta: 0:00:41  loss: 0.9385 (0.9488)  time: 0.1869  data: 0.0001  max mem: 14938
[18:08:12.453564] Test:  [130/345]  eta: 0:00:40  loss: 0.9292 (0.9482)  time: 0.1874  data: 0.0001  max mem: 14938
[18:08:14.331937] Test:  [140/345]  eta: 0:00:38  loss: 0.9292 (0.9470)  time: 0.1877  data: 0.0001  max mem: 14938
[18:08:16.213613] Test:  [150/345]  eta: 0:00:36  loss: 0.9362 (0.9473)  time: 0.1880  data: 0.0001  max mem: 14938
[18:08:18.098219] Test:  [160/345]  eta: 0:00:34  loss: 0.9300 (0.9469)  time: 0.1883  data: 0.0001  max mem: 14938
[18:08:19.985911] Test:  [170/345]  eta: 0:00:32  loss: 0.9295 (0.9475)  time: 0.1886  data: 0.0001  max mem: 14938
[18:08:21.879081] Test:  [180/345]  eta: 0:00:30  loss: 0.9564 (0.9469)  time: 0.1890  data: 0.0001  max mem: 14938
[18:08:23.776000] Test:  [190/345]  eta: 0:00:29  loss: 0.9333 (0.9460)  time: 0.1895  data: 0.0001  max mem: 14938
[18:08:25.676737] Test:  [200/345]  eta: 0:00:27  loss: 0.9319 (0.9457)  time: 0.1898  data: 0.0001  max mem: 14938
[18:08:27.580920] Test:  [210/345]  eta: 0:00:25  loss: 0.9475 (0.9465)  time: 0.1902  data: 0.0001  max mem: 14938
[18:08:29.489552] Test:  [220/345]  eta: 0:00:23  loss: 0.9497 (0.9460)  time: 0.1906  data: 0.0001  max mem: 14938
[18:08:31.402156] Test:  [230/345]  eta: 0:00:21  loss: 0.9268 (0.9456)  time: 0.1910  data: 0.0001  max mem: 14938
[18:08:33.318742] Test:  [240/345]  eta: 0:00:19  loss: 0.9447 (0.9456)  time: 0.1914  data: 0.0001  max mem: 14938
[18:08:35.237516] Test:  [250/345]  eta: 0:00:17  loss: 0.9425 (0.9453)  time: 0.1917  data: 0.0001  max mem: 14938
[18:08:37.158779] Test:  [260/345]  eta: 0:00:16  loss: 0.9200 (0.9446)  time: 0.1920  data: 0.0001  max mem: 14938
[18:08:39.085134] Test:  [270/345]  eta: 0:00:14  loss: 0.9350 (0.9448)  time: 0.1923  data: 0.0001  max mem: 14938
[18:08:41.015485] Test:  [280/345]  eta: 0:00:12  loss: 0.9542 (0.9450)  time: 0.1928  data: 0.0001  max mem: 14938
[18:08:42.948294] Test:  [290/345]  eta: 0:00:10  loss: 0.9385 (0.9444)  time: 0.1931  data: 0.0001  max mem: 14938
[18:08:44.883324] Test:  [300/345]  eta: 0:00:08  loss: 0.9322 (0.9443)  time: 0.1933  data: 0.0001  max mem: 14938
[18:08:46.821193] Test:  [310/345]  eta: 0:00:06  loss: 0.9428 (0.9440)  time: 0.1936  data: 0.0001  max mem: 14938
[18:08:48.764064] Test:  [320/345]  eta: 0:00:04  loss: 0.9428 (0.9442)  time: 0.1940  data: 0.0001  max mem: 14938
[18:08:50.710633] Test:  [330/345]  eta: 0:00:02  loss: 0.9404 (0.9439)  time: 0.1944  data: 0.0001  max mem: 14938
[18:08:52.657953] Test:  [340/345]  eta: 0:00:00  loss: 0.9383 (0.9436)  time: 0.1946  data: 0.0001  max mem: 14938
[18:08:53.438112] Test:  [344/345]  eta: 0:00:00  loss: 0.9383 (0.9435)  time: 0.1947  data: 0.0001  max mem: 14938
[18:08:53.496561] Test: Total time: 0:01:05 (0.1898 s / it)
[18:09:03.841297] Test:  [ 0/57]  eta: 0:00:18  loss: 1.0435 (1.0435)  time: 0.3161  data: 0.1373  max mem: 14938
[18:09:05.655905] Test:  [10/57]  eta: 0:00:09  loss: 1.0011 (1.0017)  time: 0.1936  data: 0.0125  max mem: 14938
[18:09:07.476745] Test:  [20/57]  eta: 0:00:06  loss: 0.9892 (0.9942)  time: 0.1817  data: 0.0001  max mem: 14938
[18:09:09.300452] Test:  [30/57]  eta: 0:00:05  loss: 0.9062 (0.9455)  time: 0.1822  data: 0.0001  max mem: 14938
[18:09:11.129492] Test:  [40/57]  eta: 0:00:03  loss: 0.8242 (0.9159)  time: 0.1826  data: 0.0001  max mem: 14938
[18:09:12.962517] Test:  [50/57]  eta: 0:00:01  loss: 0.8242 (0.9065)  time: 0.1831  data: 0.0001  max mem: 14938
[18:09:13.952148] Test:  [56/57]  eta: 0:00:00  loss: 0.8807 (0.9109)  time: 0.1777  data: 0.0001  max mem: 14938
[18:09:14.008367] Test: Total time: 0:00:10 (0.1839 s / it)
[18:09:15.732200] Dice score of the network on the train images: 0.689192, val images: 0.756765
[18:09:15.732428] saving best_prec_model_0 @ epoch 6
[18:09:16.849934] saving best_rec_model_0 @ epoch 6
[18:09:18.018615] saving best_dice_model_0 @ epoch 6
[18:09:19.093000] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:09:19.969313] Epoch: [7]  [  0/345]  eta: 0:05:01  lr: 0.000044  loss: 0.9417 (0.9417)  time: 0.8752  data: 0.1366  max mem: 14938
[18:09:34.815322] Epoch: [7]  [ 20/345]  eta: 0:04:03  lr: 0.000044  loss: 0.9624 (0.9695)  time: 0.7422  data: 0.0001  max mem: 14938
[18:09:49.715506] Epoch: [7]  [ 40/345]  eta: 0:03:47  lr: 0.000044  loss: 0.9685 (0.9709)  time: 0.7450  data: 0.0001  max mem: 14938

[18:10:04.648355] Epoch: [7]  [ 60/345]  eta: 0:03:32  lr: 0.000045  loss: 0.9574 (0.9675)  time: 0.7466  data: 0.0001  max mem: 14938
[18:10:19.631359] Epoch: [7]  [ 80/345]  eta: 0:03:18  lr: 0.000045  loss: 0.9618 (0.9654)  time: 0.7491  data: 0.0001  max mem: 14938
[18:10:34.637409] Epoch: [7]  [100/345]  eta: 0:03:03  lr: 0.000046  loss: 0.9674 (0.9689)  time: 0.7503  data: 0.0001  max mem: 14938
[18:10:49.652599] Epoch: [7]  [120/345]  eta: 0:02:48  lr: 0.000046  loss: 0.9625 (0.9683)  time: 0.7507  data: 0.0001  max mem: 14938
[18:11:04.662295] Epoch: [7]  [140/345]  eta: 0:02:33  lr: 0.000046  loss: 0.9582 (0.9666)  time: 0.7504  data: 0.0001  max mem: 14938
[18:11:19.657374] Epoch: [7]  [160/345]  eta: 0:02:18  lr: 0.000047  loss: 0.9538 (0.9653)  time: 0.7497  data: 0.0001  max mem: 14938
[18:11:34.648683] Epoch: [7]  [180/345]  eta: 0:02:03  lr: 0.000047  loss: 0.9447 (0.9647)  time: 0.7495  data: 0.0001  max mem: 14938
[18:11:49.640514] Epoch: [7]  [200/345]  eta: 0:01:48  lr: 0.000047  loss: 0.9461 (0.9627)  time: 0.7495  data: 0.0001  max mem: 14938
[18:12:04.624501] Epoch: [7]  [220/345]  eta: 0:01:33  lr: 0.000048  loss: 0.9413 (0.9613)  time: 0.7492  data: 0.0001  max mem: 14938
[18:12:19.607819] Epoch: [7]  [240/345]  eta: 0:01:18  lr: 0.000048  loss: 0.9381 (0.9590)  time: 0.7491  data: 0.0001  max mem: 14938
[18:12:34.588132] Epoch: [7]  [260/345]  eta: 0:01:03  lr: 0.000048  loss: 0.9225 (0.9565)  time: 0.7490  data: 0.0001  max mem: 14938
[18:12:49.566043] Epoch: [7]  [280/345]  eta: 0:00:48  lr: 0.000049  loss: 0.9259 (0.9550)  time: 0.7488  data: 0.0001  max mem: 14938
[18:13:04.539056] Epoch: [7]  [300/345]  eta: 0:00:33  lr: 0.000049  loss: 0.9243 (0.9532)  time: 0.7486  data: 0.0001  max mem: 14938
[18:13:19.505377] Epoch: [7]  [320/345]  eta: 0:00:18  lr: 0.000050  loss: 0.9291 (0.9521)  time: 0.7483  data: 0.0001  max mem: 14938
[18:13:34.477385] Epoch: [7]  [340/345]  eta: 0:00:03  lr: 0.000050  loss: 0.9211 (0.9509)  time: 0.7486  data: 0.0001  max mem: 14938
[18:13:37.472503] Epoch: [7]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.9284 (0.9504)  time: 0.7485  data: 0.0001  max mem: 14938
[18:13:37.531987] Epoch: [7] Total time: 0:04:18 (0.7491 s / it)
[18:13:37.532488] Averaged stats: lr: 0.000050  loss: 0.9284 (0.9504)
[18:13:37.866579] Test:  [  0/345]  eta: 0:01:53  loss: 0.8664 (0.8664)  time: 0.3304  data: 0.1480  max mem: 14938
[18:13:39.702489] Test:  [ 10/345]  eta: 0:01:05  loss: 0.8664 (0.8652)  time: 0.1969  data: 0.0135  max mem: 14938
[18:13:41.541348] Test:  [ 20/345]  eta: 0:01:01  loss: 0.8689 (0.8743)  time: 0.1837  data: 0.0001  max mem: 14938
[18:13:43.383999] Test:  [ 30/345]  eta: 0:00:59  loss: 0.8689 (0.8723)  time: 0.1840  data: 0.0001  max mem: 14938
[18:13:45.229497] Test:  [ 40/345]  eta: 0:00:57  loss: 0.8535 (0.8659)  time: 0.1844  data: 0.0001  max mem: 14938
[18:13:47.078939] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8671 (0.8679)  time: 0.1847  data: 0.0001  max mem: 14938
[18:13:48.931416] Test:  [ 60/345]  eta: 0:00:53  loss: 0.8681 (0.8690)  time: 0.1850  data: 0.0001  max mem: 14938
[18:13:50.789433] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8592 (0.8680)  time: 0.1855  data: 0.0001  max mem: 14938
[18:13:52.650031] Test:  [ 80/345]  eta: 0:00:49  loss: 0.8614 (0.8682)  time: 0.1858  data: 0.0001  max mem: 14938
[18:13:54.512075] Test:  [ 90/345]  eta: 0:00:47  loss: 0.8614 (0.8687)  time: 0.1860  data: 0.0001  max mem: 14938
[18:13:56.381366] Test:  [100/345]  eta: 0:00:45  loss: 0.8698 (0.8692)  time: 0.1865  data: 0.0001  max mem: 14938
[18:13:58.249672] Test:  [110/345]  eta: 0:00:43  loss: 0.8726 (0.8701)  time: 0.1868  data: 0.0001  max mem: 14938
[18:14:00.123252] Test:  [120/345]  eta: 0:00:41  loss: 0.8779 (0.8705)  time: 0.1870  data: 0.0001  max mem: 14938
[18:14:02.000383] Test:  [130/345]  eta: 0:00:40  loss: 0.8722 (0.8707)  time: 0.1875  data: 0.0001  max mem: 14938
[18:14:03.880490] Test:  [140/345]  eta: 0:00:38  loss: 0.8624 (0.8692)  time: 0.1878  data: 0.0001  max mem: 14938
[18:14:05.762764] Test:  [150/345]  eta: 0:00:36  loss: 0.8731 (0.8706)  time: 0.1881  data: 0.0001  max mem: 14938
[18:14:07.649144] Test:  [160/345]  eta: 0:00:34  loss: 0.8862 (0.8708)  time: 0.1884  data: 0.0001  max mem: 14938
[18:14:09.538935] Test:  [170/345]  eta: 0:00:32  loss: 0.8734 (0.8708)  time: 0.1888  data: 0.0001  max mem: 14938
[18:14:11.432701] Test:  [180/345]  eta: 0:00:30  loss: 0.8734 (0.8713)  time: 0.1891  data: 0.0001  max mem: 14938
[18:14:13.330847] Test:  [190/345]  eta: 0:00:29  loss: 0.8733 (0.8706)  time: 0.1895  data: 0.0001  max mem: 14938
[18:14:15.233489] Test:  [200/345]  eta: 0:00:27  loss: 0.8577 (0.8704)  time: 0.1900  data: 0.0001  max mem: 14938
[18:14:17.140503] Test:  [210/345]  eta: 0:00:25  loss: 0.8668 (0.8704)  time: 0.1904  data: 0.0001  max mem: 14938
[18:14:19.051367] Test:  [220/345]  eta: 0:00:23  loss: 0.8743 (0.8706)  time: 0.1908  data: 0.0001  max mem: 14938
[18:14:20.965502] Test:  [230/345]  eta: 0:00:21  loss: 0.8743 (0.8710)  time: 0.1912  data: 0.0001  max mem: 14938
[18:14:22.883473] Test:  [240/345]  eta: 0:00:19  loss: 0.8753 (0.8714)  time: 0.1916  data: 0.0001  max mem: 14938
[18:14:24.804450] Test:  [250/345]  eta: 0:00:17  loss: 0.8697 (0.8708)  time: 0.1919  data: 0.0001  max mem: 14938
[18:14:26.726945] Test:  [260/345]  eta: 0:00:16  loss: 0.8579 (0.8707)  time: 0.1921  data: 0.0001  max mem: 14938
[18:14:28.655502] Test:  [270/345]  eta: 0:00:14  loss: 0.8627 (0.8709)  time: 0.1925  data: 0.0001  max mem: 14938
[18:14:30.584894] Test:  [280/345]  eta: 0:00:12  loss: 0.8742 (0.8710)  time: 0.1928  data: 0.0001  max mem: 14938
[18:14:32.517367] Test:  [290/345]  eta: 0:00:10  loss: 0.8739 (0.8712)  time: 0.1930  data: 0.0001  max mem: 14938
[18:14:34.455962] Test:  [300/345]  eta: 0:00:08  loss: 0.8742 (0.8713)  time: 0.1935  data: 0.0001  max mem: 14938
[18:14:36.396282] Test:  [310/345]  eta: 0:00:06  loss: 0.8778 (0.8717)  time: 0.1939  data: 0.0001  max mem: 14938
[18:14:38.337828] Test:  [320/345]  eta: 0:00:04  loss: 0.8766 (0.8720)  time: 0.1940  data: 0.0001  max mem: 14938
[18:14:40.285358] Test:  [330/345]  eta: 0:00:02  loss: 0.8669 (0.8718)  time: 0.1944  data: 0.0001  max mem: 14938
[18:14:42.234683] Test:  [340/345]  eta: 0:00:00  loss: 0.8730 (0.8718)  time: 0.1948  data: 0.0001  max mem: 14938
[18:14:43.016669] Test:  [344/345]  eta: 0:00:00  loss: 0.8754 (0.8720)  time: 0.1949  data: 0.0001  max mem: 14938
[18:14:43.074021] Test: Total time: 0:01:05 (0.1900 s / it)
[18:14:53.383221] Test:  [ 0/57]  eta: 0:00:17  loss: 0.9699 (0.9699)  time: 0.3149  data: 0.1355  max mem: 14938
[18:14:55.199366] Test:  [10/57]  eta: 0:00:09  loss: 0.9271 (0.9337)  time: 0.1937  data: 0.0124  max mem: 14938
[18:14:57.021382] Test:  [20/57]  eta: 0:00:06  loss: 0.9244 (0.9288)  time: 0.1818  data: 0.0001  max mem: 14938
[18:14:58.846021] Test:  [30/57]  eta: 0:00:05  loss: 0.8312 (0.8867)  time: 0.1823  data: 0.0001  max mem: 14938
[18:15:00.677780] Test:  [40/57]  eta: 0:00:03  loss: 0.7935 (0.8617)  time: 0.1828  data: 0.0001  max mem: 14938
[18:15:02.511759] Test:  [50/57]  eta: 0:00:01  loss: 0.7963 (0.8542)  time: 0.1832  data: 0.0001  max mem: 14938
[18:15:03.501480] Test:  [56/57]  eta: 0:00:00  loss: 0.8277 (0.8588)  time: 0.1778  data: 0.0001  max mem: 14938
[18:15:03.559885] Test: Total time: 0:00:10 (0.1841 s / it)
[18:15:05.304419] Dice score of the network on the train images: 0.728841, val images: 0.788748
[18:15:05.304640] saving best_prec_model_0 @ epoch 7
[18:15:06.502316] saving best_dice_model_0 @ epoch 7
[18:15:07.567267] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:15:08.451216] Epoch: [8]  [  0/345]  eta: 0:05:04  lr: 0.000050  loss: 0.9409 (0.9409)  time: 0.8828  data: 0.1395  max mem: 14938
[18:15:23.324149] Epoch: [8]  [ 20/345]  eta: 0:04:03  lr: 0.000050  loss: 0.9133 (0.9239)  time: 0.7436  data: 0.0001  max mem: 14938
[18:15:38.240934] Epoch: [8]  [ 40/345]  eta: 0:03:48  lr: 0.000051  loss: 0.9076 (0.9210)  time: 0.7458  data: 0.0001  max mem: 14938
[18:15:53.175533] Epoch: [8]  [ 60/345]  eta: 0:03:33  lr: 0.000051  loss: 0.9234 (0.9231)  time: 0.7467  data: 0.0001  max mem: 14938
[18:16:08.155979] Epoch: [8]  [ 80/345]  eta: 0:03:18  lr: 0.000051  loss: 0.9166 (0.9207)  time: 0.7490  data: 0.0001  max mem: 14938
[18:16:23.162727] Epoch: [8]  [100/345]  eta: 0:03:03  lr: 0.000052  loss: 0.9091 (0.9203)  time: 0.7503  data: 0.0001  max mem: 14938
[18:16:38.176416] Epoch: [8]  [120/345]  eta: 0:02:48  lr: 0.000052  loss: 0.9179 (0.9196)  time: 0.7506  data: 0.0001  max mem: 14938
[18:16:53.311060] Epoch: [8]  [140/345]  eta: 0:02:33  lr: 0.000053  loss: 0.9277 (0.9208)  time: 0.7567  data: 0.0001  max mem: 14938
[18:17:08.319827] Epoch: [8]  [160/345]  eta: 0:02:18  lr: 0.000053  loss: 0.9114 (0.9198)  time: 0.7504  data: 0.0001  max mem: 14938
[18:17:23.315791] Epoch: [8]  [180/345]  eta: 0:02:03  lr: 0.000053  loss: 0.9019 (0.9189)  time: 0.7498  data: 0.0001  max mem: 14938
[18:17:38.314916] Epoch: [8]  [200/345]  eta: 0:01:48  lr: 0.000054  loss: 0.8877 (0.9162)  time: 0.7499  data: 0.0001  max mem: 14938
[18:17:53.304229] Epoch: [8]  [220/345]  eta: 0:01:33  lr: 0.000054  loss: 0.8935 (0.9141)  time: 0.7494  data: 0.0001  max mem: 14938
[18:18:08.297797] Epoch: [8]  [240/345]  eta: 0:01:18  lr: 0.000054  loss: 0.8964 (0.9129)  time: 0.7496  data: 0.0001  max mem: 14938
[18:18:23.299534] Epoch: [8]  [260/345]  eta: 0:01:03  lr: 0.000055  loss: 0.9051 (0.9124)  time: 0.7500  data: 0.0001  max mem: 14938
[18:18:38.308894] Epoch: [8]  [280/345]  eta: 0:00:48  lr: 0.000055  loss: 0.8967 (0.9115)  time: 0.7504  data: 0.0001  max mem: 14938
[18:18:53.301980] Epoch: [8]  [300/345]  eta: 0:00:33  lr: 0.000055  loss: 0.8862 (0.9101)  time: 0.7496  data: 0.0001  max mem: 14938
[18:19:08.296614] Epoch: [8]  [320/345]  eta: 0:00:18  lr: 0.000056  loss: 0.8817 (0.9091)  time: 0.7497  data: 0.0001  max mem: 14938
[18:19:23.290603] Epoch: [8]  [340/345]  eta: 0:00:03  lr: 0.000056  loss: 0.8831 (0.9076)  time: 0.7497  data: 0.0001  max mem: 14938
[18:19:26.288678] Epoch: [8]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.8856 (0.9073)  time: 0.7496  data: 0.0001  max mem: 14938
[18:19:26.353350] Epoch: [8] Total time: 0:04:18 (0.7501 s / it)
[18:19:26.353617] Averaged stats: lr: 0.000056  loss: 0.8856 (0.9073)
[18:19:26.685372] Test:  [  0/345]  eta: 0:01:52  loss: 0.8677 (0.8677)  time: 0.3273  data: 0.1457  max mem: 14938
[18:19:28.522474] Test:  [ 10/345]  eta: 0:01:05  loss: 0.8446 (0.8451)  time: 0.1967  data: 0.0133  max mem: 14938
[18:19:30.360776] Test:  [ 20/345]  eta: 0:01:01  loss: 0.8328 (0.8356)  time: 0.1837  data: 0.0001  max mem: 14938
[18:19:32.203134] Test:  [ 30/345]  eta: 0:00:59  loss: 0.8391 (0.8397)  time: 0.1840  data: 0.0001  max mem: 14938
[18:19:34.049400] Test:  [ 40/345]  eta: 0:00:57  loss: 0.8500 (0.8425)  time: 0.1844  data: 0.0001  max mem: 14938
[18:19:35.898038] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8445 (0.8419)  time: 0.1847  data: 0.0001  max mem: 14938
[18:19:37.752432] Test:  [ 60/345]  eta: 0:00:53  loss: 0.8402 (0.8435)  time: 0.1851  data: 0.0001  max mem: 14938
[18:19:39.608374] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8459 (0.8449)  time: 0.1855  data: 0.0001  max mem: 14938
[18:19:41.469669] Test:  [ 80/345]  eta: 0:00:49  loss: 0.8520 (0.8452)  time: 0.1858  data: 0.0001  max mem: 14938
[18:19:43.333953] Test:  [ 90/345]  eta: 0:00:47  loss: 0.8520 (0.8467)  time: 0.1862  data: 0.0001  max mem: 14938
[18:19:45.201037] Test:  [100/345]  eta: 0:00:45  loss: 0.8479 (0.8464)  time: 0.1865  data: 0.0001  max mem: 14938
[18:19:47.072254] Test:  [110/345]  eta: 0:00:43  loss: 0.8465 (0.8470)  time: 0.1869  data: 0.0001  max mem: 14938
[18:19:48.948174] Test:  [120/345]  eta: 0:00:41  loss: 0.8583 (0.8471)  time: 0.1873  data: 0.0001  max mem: 14938
[18:19:50.825850] Test:  [130/345]  eta: 0:00:40  loss: 0.8304 (0.8464)  time: 0.1876  data: 0.0001  max mem: 14938
[18:19:52.707543] Test:  [140/345]  eta: 0:00:38  loss: 0.8415 (0.8469)  time: 0.1879  data: 0.0001  max mem: 14938
[18:19:54.591135] Test:  [150/345]  eta: 0:00:36  loss: 0.8415 (0.8467)  time: 0.1882  data: 0.0001  max mem: 14938
[18:19:56.478243] Test:  [160/345]  eta: 0:00:34  loss: 0.8381 (0.8470)  time: 0.1885  data: 0.0001  max mem: 14938
[18:19:58.369134] Test:  [170/345]  eta: 0:00:32  loss: 0.8626 (0.8480)  time: 0.1888  data: 0.0001  max mem: 14938
[18:20:00.264975] Test:  [180/345]  eta: 0:00:30  loss: 0.8571 (0.8474)  time: 0.1893  data: 0.0001  max mem: 14938
[18:20:02.164625] Test:  [190/345]  eta: 0:00:29  loss: 0.8461 (0.8479)  time: 0.1897  data: 0.0001  max mem: 14938
[18:20:04.067451] Test:  [200/345]  eta: 0:00:27  loss: 0.8461 (0.8473)  time: 0.1901  data: 0.0001  max mem: 14938
[18:20:05.974021] Test:  [210/345]  eta: 0:00:25  loss: 0.8455 (0.8476)  time: 0.1904  data: 0.0001  max mem: 14938
[18:20:07.884217] Test:  [220/345]  eta: 0:00:23  loss: 0.8455 (0.8475)  time: 0.1908  data: 0.0001  max mem: 14938
[18:20:09.798905] Test:  [230/345]  eta: 0:00:21  loss: 0.8461 (0.8482)  time: 0.1912  data: 0.0001  max mem: 14938
[18:20:11.717778] Test:  [240/345]  eta: 0:00:19  loss: 0.8544 (0.8482)  time: 0.1916  data: 0.0001  max mem: 14938
[18:20:13.638504] Test:  [250/345]  eta: 0:00:17  loss: 0.8424 (0.8476)  time: 0.1919  data: 0.0001  max mem: 14938
[18:20:15.564180] Test:  [260/345]  eta: 0:00:16  loss: 0.8536 (0.8483)  time: 0.1923  data: 0.0001  max mem: 14938
[18:20:17.491947] Test:  [270/345]  eta: 0:00:14  loss: 0.8573 (0.8482)  time: 0.1926  data: 0.0001  max mem: 14938
[18:20:19.423256] Test:  [280/345]  eta: 0:00:12  loss: 0.8575 (0.8490)  time: 0.1929  data: 0.0001  max mem: 14938
[18:20:21.355652] Test:  [290/345]  eta: 0:00:10  loss: 0.8575 (0.8494)  time: 0.1931  data: 0.0001  max mem: 14938
[18:20:23.294626] Test:  [300/345]  eta: 0:00:08  loss: 0.8546 (0.8495)  time: 0.1935  data: 0.0001  max mem: 14938
[18:20:25.234627] Test:  [310/345]  eta: 0:00:06  loss: 0.8546 (0.8497)  time: 0.1939  data: 0.0001  max mem: 14938
[18:20:27.177349] Test:  [320/345]  eta: 0:00:04  loss: 0.8316 (0.8491)  time: 0.1941  data: 0.0001  max mem: 14938
[18:20:29.123236] Test:  [330/345]  eta: 0:00:02  loss: 0.8387 (0.8490)  time: 0.1944  data: 0.0001  max mem: 14938
[18:20:31.072973] Test:  [340/345]  eta: 0:00:00  loss: 0.8480 (0.8496)  time: 0.1947  data: 0.0001  max mem: 14938
[18:20:31.854362] Test:  [344/345]  eta: 0:00:00  loss: 0.8659 (0.8498)  time: 0.1949  data: 0.0001  max mem: 14938
[18:20:31.912568] Test: Total time: 0:01:05 (0.1900 s / it)
[18:20:42.275687] Test:  [ 0/57]  eta: 0:00:17  loss: 0.9242 (0.9242)  time: 0.3158  data: 0.1366  max mem: 14938
[18:20:44.092516] Test:  [10/57]  eta: 0:00:09  loss: 0.8984 (0.9113)  time: 0.1938  data: 0.0125  max mem: 14938
[18:20:45.915505] Test:  [20/57]  eta: 0:00:06  loss: 0.8984 (0.9055)  time: 0.1819  data: 0.0001  max mem: 14938
[18:20:47.741517] Test:  [30/57]  eta: 0:00:05  loss: 0.8216 (0.8667)  time: 0.1824  data: 0.0001  max mem: 14938
[18:20:49.572048] Test:  [40/57]  eta: 0:00:03  loss: 0.7702 (0.8434)  time: 0.1828  data: 0.0001  max mem: 14938
[18:20:51.409629] Test:  [50/57]  eta: 0:00:01  loss: 0.7702 (0.8363)  time: 0.1834  data: 0.0001  max mem: 14938
[18:20:52.399464] Test:  [56/57]  eta: 0:00:00  loss: 0.8175 (0.8421)  time: 0.1779  data: 0.0001  max mem: 14938
[18:20:52.454039] Test: Total time: 0:00:10 (0.1841 s / it)
[18:20:54.170057] Dice score of the network on the train images: 0.723081, val images: 0.795662
[18:20:54.170284] saving best_rec_model_0 @ epoch 8
[18:20:55.255229] saving best_dice_model_0 @ epoch 8
[18:20:56.323962] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:20:57.205407] Epoch: [9]  [  0/345]  eta: 0:05:03  lr: 0.000056  loss: 0.8736 (0.8736)  time: 0.8802  data: 0.1391  max mem: 14938
[18:21:12.091102] Epoch: [9]  [ 20/345]  eta: 0:04:03  lr: 0.000057  loss: 0.8695 (0.8771)  time: 0.7442  data: 0.0001  max mem: 14938
[18:21:27.041291] Epoch: [9]  [ 40/345]  eta: 0:03:48  lr: 0.000057  loss: 0.9088 (0.8885)  time: 0.7475  data: 0.0001  max mem: 14938
[18:21:42.021943] Epoch: [9]  [ 60/345]  eta: 0:03:33  lr: 0.000057  loss: 0.8909 (0.8916)  time: 0.7490  data: 0.0001  max mem: 14938
[18:21:57.037239] Epoch: [9]  [ 80/345]  eta: 0:03:18  lr: 0.000058  loss: 0.8766 (0.8889)  time: 0.7507  data: 0.0001  max mem: 14938
[18:22:12.077947] Epoch: [9]  [100/345]  eta: 0:03:03  lr: 0.000058  loss: 0.8811 (0.8880)  time: 0.7520  data: 0.0001  max mem: 14938
[18:22:27.121882] Epoch: [9]  [120/345]  eta: 0:02:48  lr: 0.000058  loss: 0.8766 (0.8875)  time: 0.7522  data: 0.0001  max mem: 14938
[18:22:42.166459] Epoch: [9]  [140/345]  eta: 0:02:33  lr: 0.000059  loss: 0.8788 (0.8863)  time: 0.7522  data: 0.0001  max mem: 14938
[18:22:57.199524] Epoch: [9]  [160/345]  eta: 0:02:18  lr: 0.000059  loss: 0.8819 (0.8851)  time: 0.7516  data: 0.0001  max mem: 14938
[18:23:12.225619] Epoch: [9]  [180/345]  eta: 0:02:03  lr: 0.000060  loss: 0.8853 (0.8856)  time: 0.7513  data: 0.0001  max mem: 14938
[18:23:27.247696] Epoch: [9]  [200/345]  eta: 0:01:48  lr: 0.000060  loss: 0.8748 (0.8842)  time: 0.7511  data: 0.0001  max mem: 14938
[18:23:42.261774] Epoch: [9]  [220/345]  eta: 0:01:33  lr: 0.000060  loss: 0.8798 (0.8840)  time: 0.7507  data: 0.0001  max mem: 14938
[18:23:57.278931] Epoch: [9]  [240/345]  eta: 0:01:18  lr: 0.000061  loss: 0.8531 (0.8821)  time: 0.7508  data: 0.0001  max mem: 14938
[18:24:12.283583] Epoch: [9]  [260/345]  eta: 0:01:03  lr: 0.000061  loss: 0.8849 (0.8827)  time: 0.7502  data: 0.0001  max mem: 14938
[18:24:27.283207] Epoch: [9]  [280/345]  eta: 0:00:48  lr: 0.000061  loss: 0.8843 (0.8824)  time: 0.7499  data: 0.0001  max mem: 14938
[18:24:42.292650] Epoch: [9]  [300/345]  eta: 0:00:33  lr: 0.000062  loss: 0.8729 (0.8817)  time: 0.7504  data: 0.0001  max mem: 14938
[18:24:57.288081] Epoch: [9]  [320/345]  eta: 0:00:18  lr: 0.000062  loss: 0.8767 (0.8813)  time: 0.7497  data: 0.0001  max mem: 14938
[18:25:12.284153] Epoch: [9]  [340/345]  eta: 0:00:03  lr: 0.000062  loss: 0.8713 (0.8808)  time: 0.7498  data: 0.0001  max mem: 14938
[18:25:15.282307] Epoch: [9]  [344/345]  eta: 0:00:00  lr: 0.000062  loss: 0.8547 (0.8806)  time: 0.7497  data: 0.0001  max mem: 14938
[18:25:15.323132] Epoch: [9] Total time: 0:04:18 (0.7507 s / it)
[18:25:15.323558] Averaged stats: lr: 0.000062  loss: 0.8547 (0.8806)
[18:25:15.664897] Test:  [  0/345]  eta: 0:01:56  loss: 0.8410 (0.8410)  time: 0.3372  data: 0.1548  max mem: 14938
[18:25:17.501626] Test:  [ 10/345]  eta: 0:01:06  loss: 0.8410 (0.8394)  time: 0.1976  data: 0.0141  max mem: 14938
[18:25:19.343193] Test:  [ 20/345]  eta: 0:01:02  loss: 0.8347 (0.8353)  time: 0.1838  data: 0.0001  max mem: 14938
[18:25:21.187370] Test:  [ 30/345]  eta: 0:00:59  loss: 0.8210 (0.8318)  time: 0.1842  data: 0.0001  max mem: 14938
[18:25:23.035373] Test:  [ 40/345]  eta: 0:00:57  loss: 0.8292 (0.8342)  time: 0.1846  data: 0.0001  max mem: 14938
[18:25:24.887377] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8430 (0.8368)  time: 0.1850  data: 0.0001  max mem: 14938
[18:25:26.742215] Test:  [ 60/345]  eta: 0:00:53  loss: 0.8293 (0.8342)  time: 0.1853  data: 0.0001  max mem: 14938
[18:25:28.600306] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8162 (0.8339)  time: 0.1856  data: 0.0001  max mem: 14938
[18:25:30.462157] Test:  [ 80/345]  eta: 0:00:49  loss: 0.8162 (0.8320)  time: 0.1859  data: 0.0001  max mem: 14938
[18:25:32.329512] Test:  [ 90/345]  eta: 0:00:47  loss: 0.8262 (0.8325)  time: 0.1864  data: 0.0001  max mem: 14938
[18:25:34.198184] Test:  [100/345]  eta: 0:00:45  loss: 0.8262 (0.8324)  time: 0.1868  data: 0.0001  max mem: 14938
[18:25:36.070404] Test:  [110/345]  eta: 0:00:43  loss: 0.8223 (0.8320)  time: 0.1870  data: 0.0001  max mem: 14938
[18:25:37.946269] Test:  [120/345]  eta: 0:00:42  loss: 0.8252 (0.8326)  time: 0.1874  data: 0.0001  max mem: 14938
[18:25:39.824023] Test:  [130/345]  eta: 0:00:40  loss: 0.8280 (0.8324)  time: 0.1876  data: 0.0001  max mem: 14938
[18:25:41.706159] Test:  [140/345]  eta: 0:00:38  loss: 0.8227 (0.8314)  time: 0.1879  data: 0.0001  max mem: 14938
[18:25:43.590714] Test:  [150/345]  eta: 0:00:36  loss: 0.8194 (0.8313)  time: 0.1883  data: 0.0001  max mem: 14938
[18:25:45.479683] Test:  [160/345]  eta: 0:00:34  loss: 0.8233 (0.8310)  time: 0.1886  data: 0.0001  max mem: 14938
[18:25:47.371285] Test:  [170/345]  eta: 0:00:32  loss: 0.8291 (0.8317)  time: 0.1890  data: 0.0001  max mem: 14938
[18:25:49.267754] Test:  [180/345]  eta: 0:00:30  loss: 0.8433 (0.8325)  time: 0.1894  data: 0.0001  max mem: 14938
[18:25:51.168799] Test:  [190/345]  eta: 0:00:29  loss: 0.8332 (0.8323)  time: 0.1898  data: 0.0001  max mem: 14938
[18:25:53.072759] Test:  [200/345]  eta: 0:00:27  loss: 0.8265 (0.8321)  time: 0.1902  data: 0.0001  max mem: 14938
[18:25:54.979940] Test:  [210/345]  eta: 0:00:25  loss: 0.8377 (0.8322)  time: 0.1905  data: 0.0001  max mem: 14938
[18:25:56.891487] Test:  [220/345]  eta: 0:00:23  loss: 0.8364 (0.8324)  time: 0.1909  data: 0.0001  max mem: 14938
[18:25:58.806071] Test:  [230/345]  eta: 0:00:21  loss: 0.8451 (0.8331)  time: 0.1913  data: 0.0001  max mem: 14938
[18:26:00.725632] Test:  [240/345]  eta: 0:00:19  loss: 0.8451 (0.8334)  time: 0.1917  data: 0.0001  max mem: 14938
[18:26:02.647183] Test:  [250/345]  eta: 0:00:17  loss: 0.8303 (0.8334)  time: 0.1920  data: 0.0001  max mem: 14938
[18:26:04.570424] Test:  [260/345]  eta: 0:00:16  loss: 0.8281 (0.8332)  time: 0.1922  data: 0.0001  max mem: 14938
[18:26:06.499952] Test:  [270/345]  eta: 0:00:14  loss: 0.8284 (0.8329)  time: 0.1926  data: 0.0001  max mem: 14938
[18:26:08.431902] Test:  [280/345]  eta: 0:00:12  loss: 0.8327 (0.8330)  time: 0.1930  data: 0.0001  max mem: 14938
[18:26:10.366170] Test:  [290/345]  eta: 0:00:10  loss: 0.8304 (0.8327)  time: 0.1933  data: 0.0001  max mem: 14938
[18:26:12.305183] Test:  [300/345]  eta: 0:00:08  loss: 0.8220 (0.8326)  time: 0.1936  data: 0.0001  max mem: 14938
[18:26:14.247378] Test:  [310/345]  eta: 0:00:06  loss: 0.8253 (0.8328)  time: 0.1940  data: 0.0001  max mem: 14938
[18:26:16.191446] Test:  [320/345]  eta: 0:00:04  loss: 0.8383 (0.8330)  time: 0.1943  data: 0.0001  max mem: 14938
[18:26:18.137647] Test:  [330/345]  eta: 0:00:02  loss: 0.8255 (0.8327)  time: 0.1945  data: 0.0001  max mem: 14938
[18:26:20.089269] Test:  [340/345]  eta: 0:00:00  loss: 0.8264 (0.8329)  time: 0.1948  data: 0.0001  max mem: 14938
[18:26:20.872544] Test:  [344/345]  eta: 0:00:00  loss: 0.8264 (0.8328)  time: 0.1951  data: 0.0001  max mem: 14938
[18:26:20.932440] Test: Total time: 0:01:05 (0.1902 s / it)
[18:26:31.479578] Test:  [ 0/57]  eta: 0:00:17  loss: 0.8848 (0.8848)  time: 0.3156  data: 0.1359  max mem: 14938
[18:26:33.297090] Test:  [10/57]  eta: 0:00:09  loss: 0.8848 (0.8988)  time: 0.1938  data: 0.0124  max mem: 14938
[18:26:35.119938] Test:  [20/57]  eta: 0:00:06  loss: 0.8927 (0.8959)  time: 0.1819  data: 0.0001  max mem: 14938
[18:26:36.948635] Test:  [30/57]  eta: 0:00:05  loss: 0.8134 (0.8599)  time: 0.1825  data: 0.0001  max mem: 14938
[18:26:38.780939] Test:  [40/57]  eta: 0:00:03  loss: 0.7716 (0.8390)  time: 0.1830  data: 0.0001  max mem: 14938
[18:26:40.616837] Test:  [50/57]  eta: 0:00:01  loss: 0.7716 (0.8326)  time: 0.1834  data: 0.0001  max mem: 14938
[18:26:41.608515] Test:  [56/57]  eta: 0:00:00  loss: 0.8128 (0.8381)  time: 0.1780  data: 0.0001  max mem: 14938
[18:26:41.666666] Test: Total time: 0:00:10 (0.1843 s / it)
[18:26:43.376549] Dice score of the network on the train images: 0.735418, val images: 0.795600
[18:26:43.380969] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:26:44.263327] Epoch: [10]  [  0/345]  eta: 0:05:03  lr: 0.000063  loss: 0.8904 (0.8904)  time: 0.8811  data: 0.1379  max mem: 14938
[18:26:59.174458] Epoch: [10]  [ 20/345]  eta: 0:04:04  lr: 0.000063  loss: 0.8745 (0.8718)  time: 0.7455  data: 0.0001  max mem: 14938
[18:27:14.134138] Epoch: [10]  [ 40/345]  eta: 0:03:48  lr: 0.000063  loss: 0.8556 (0.8657)  time: 0.7479  data: 0.0001  max mem: 14938
[18:27:29.120687] Epoch: [10]  [ 60/345]  eta: 0:03:33  lr: 0.000064  loss: 0.8680 (0.8663)  time: 0.7493  data: 0.0001  max mem: 14938
[18:27:44.137687] Epoch: [10]  [ 80/345]  eta: 0:03:18  lr: 0.000064  loss: 0.8590 (0.8664)  time: 0.7508  data: 0.0001  max mem: 14938
[18:27:59.169518] Epoch: [10]  [100/345]  eta: 0:03:03  lr: 0.000064  loss: 0.8628 (0.8661)  time: 0.7515  data: 0.0001  max mem: 14938
[18:28:14.220519] Epoch: [10]  [120/345]  eta: 0:02:48  lr: 0.000065  loss: 0.8617 (0.8650)  time: 0.7525  data: 0.0001  max mem: 14938
[18:28:29.257322] Epoch: [10]  [140/345]  eta: 0:02:33  lr: 0.000065  loss: 0.8404 (0.8625)  time: 0.7518  data: 0.0001  max mem: 14938
[18:28:44.297428] Epoch: [10]  [160/345]  eta: 0:02:18  lr: 0.000065  loss: 0.8653 (0.8626)  time: 0.7520  data: 0.0001  max mem: 14938
[18:28:59.335357] Epoch: [10]  [180/345]  eta: 0:02:03  lr: 0.000066  loss: 0.8478 (0.8624)  time: 0.7519  data: 0.0001  max mem: 14938
[18:29:14.359450] Epoch: [10]  [200/345]  eta: 0:01:48  lr: 0.000066  loss: 0.8473 (0.8617)  time: 0.7512  data: 0.0001  max mem: 14938
[18:29:29.382745] Epoch: [10]  [220/345]  eta: 0:01:33  lr: 0.000066  loss: 0.8410 (0.8600)  time: 0.7511  data: 0.0001  max mem: 14938
[18:29:44.398501] Epoch: [10]  [240/345]  eta: 0:01:18  lr: 0.000067  loss: 0.8511 (0.8598)  time: 0.7507  data: 0.0001  max mem: 14938
[18:29:59.401095] Epoch: [10]  [260/345]  eta: 0:01:03  lr: 0.000067  loss: 0.8560 (0.8597)  time: 0.7501  data: 0.0001  max mem: 14938
[18:30:14.409306] Epoch: [10]  [280/345]  eta: 0:00:48  lr: 0.000068  loss: 0.8489 (0.8593)  time: 0.7504  data: 0.0001  max mem: 14938
[18:30:29.409534] Epoch: [10]  [300/345]  eta: 0:00:33  lr: 0.000068  loss: 0.8328 (0.8582)  time: 0.7500  data: 0.0001  max mem: 14938
[18:30:44.417156] Epoch: [10]  [320/345]  eta: 0:00:18  lr: 0.000068  loss: 0.8392 (0.8576)  time: 0.7503  data: 0.0001  max mem: 14938
[18:30:59.413084] Epoch: [10]  [340/345]  eta: 0:00:03  lr: 0.000069  loss: 0.8352 (0.8564)  time: 0.7498  data: 0.0001  max mem: 14938
[18:31:02.414223] Epoch: [10]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.8315 (0.8561)  time: 0.7499  data: 0.0001  max mem: 14938
[18:31:02.476807] Epoch: [10] Total time: 0:04:19 (0.7510 s / it)
[18:31:02.477203] Averaged stats: lr: 0.000069  loss: 0.8315 (0.8561)
[18:31:02.806587] Test:  [  0/345]  eta: 0:01:51  loss: 0.7704 (0.7704)  time: 0.3229  data: 0.1404  max mem: 14938
[18:31:04.645753] Test:  [ 10/345]  eta: 0:01:05  loss: 0.8103 (0.8045)  time: 0.1965  data: 0.0128  max mem: 14938
[18:31:06.486656] Test:  [ 20/345]  eta: 0:01:01  loss: 0.8103 (0.8039)  time: 0.1839  data: 0.0001  max mem: 14938
[18:31:08.330601] Test:  [ 30/345]  eta: 0:00:59  loss: 0.8047 (0.8062)  time: 0.1842  data: 0.0001  max mem: 14938
[18:31:10.178026] Test:  [ 40/345]  eta: 0:00:57  loss: 0.8173 (0.8090)  time: 0.1845  data: 0.0001  max mem: 14938
[18:31:12.029062] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8008 (0.8073)  time: 0.1849  data: 0.0001  max mem: 14938
[18:31:13.885191] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7962 (0.8089)  time: 0.1853  data: 0.0001  max mem: 14938
[18:31:15.744362] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8068 (0.8091)  time: 0.1857  data: 0.0001  max mem: 14938
[18:31:17.604986] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7978 (0.8076)  time: 0.1859  data: 0.0001  max mem: 14938
[18:31:19.469377] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7943 (0.8074)  time: 0.1862  data: 0.0001  max mem: 14938
[18:31:21.336914] Test:  [100/345]  eta: 0:00:45  loss: 0.8187 (0.8086)  time: 0.1865  data: 0.0001  max mem: 14938
[18:31:23.207658] Test:  [110/345]  eta: 0:00:43  loss: 0.8187 (0.8089)  time: 0.1869  data: 0.0001  max mem: 14938
[18:31:25.083496] Test:  [120/345]  eta: 0:00:42  loss: 0.8080 (0.8086)  time: 0.1873  data: 0.0001  max mem: 14938
[18:31:26.963284] Test:  [130/345]  eta: 0:00:40  loss: 0.8080 (0.8083)  time: 0.1877  data: 0.0001  max mem: 14938
[18:31:28.846026] Test:  [140/345]  eta: 0:00:38  loss: 0.8013 (0.8076)  time: 0.1881  data: 0.0001  max mem: 14938
[18:31:30.731661] Test:  [150/345]  eta: 0:00:36  loss: 0.8013 (0.8073)  time: 0.1884  data: 0.0001  max mem: 14938
[18:31:32.619490] Test:  [160/345]  eta: 0:00:34  loss: 0.8087 (0.8078)  time: 0.1886  data: 0.0001  max mem: 14938
[18:31:34.510788] Test:  [170/345]  eta: 0:00:32  loss: 0.8101 (0.8076)  time: 0.1889  data: 0.0001  max mem: 14938
[18:31:36.408135] Test:  [180/345]  eta: 0:00:30  loss: 0.8117 (0.8076)  time: 0.1894  data: 0.0001  max mem: 14938
[18:31:38.306657] Test:  [190/345]  eta: 0:00:29  loss: 0.8140 (0.8085)  time: 0.1897  data: 0.0001  max mem: 14938
[18:31:40.208680] Test:  [200/345]  eta: 0:00:27  loss: 0.8196 (0.8092)  time: 0.1900  data: 0.0001  max mem: 14938
[18:31:42.116256] Test:  [210/345]  eta: 0:00:25  loss: 0.8134 (0.8092)  time: 0.1904  data: 0.0001  max mem: 14938
[18:31:44.026107] Test:  [220/345]  eta: 0:00:23  loss: 0.8069 (0.8096)  time: 0.1908  data: 0.0001  max mem: 14938
[18:31:45.940752] Test:  [230/345]  eta: 0:00:21  loss: 0.8105 (0.8104)  time: 0.1912  data: 0.0001  max mem: 14938
[18:31:47.858784] Test:  [240/345]  eta: 0:00:19  loss: 0.8010 (0.8098)  time: 0.1916  data: 0.0001  max mem: 14938
[18:31:49.780286] Test:  [250/345]  eta: 0:00:17  loss: 0.8062 (0.8099)  time: 0.1919  data: 0.0001  max mem: 14938
[18:31:51.704080] Test:  [260/345]  eta: 0:00:16  loss: 0.8099 (0.8100)  time: 0.1922  data: 0.0001  max mem: 14938
[18:31:53.633139] Test:  [270/345]  eta: 0:00:14  loss: 0.8075 (0.8098)  time: 0.1926  data: 0.0001  max mem: 14938
[18:31:55.564994] Test:  [280/345]  eta: 0:00:12  loss: 0.8037 (0.8097)  time: 0.1930  data: 0.0001  max mem: 14938
[18:31:57.498469] Test:  [290/345]  eta: 0:00:10  loss: 0.8094 (0.8099)  time: 0.1932  data: 0.0001  max mem: 14938
[18:31:59.438044] Test:  [300/345]  eta: 0:00:08  loss: 0.7950 (0.8098)  time: 0.1936  data: 0.0001  max mem: 14938
[18:32:01.379440] Test:  [310/345]  eta: 0:00:06  loss: 0.7822 (0.8090)  time: 0.1940  data: 0.0001  max mem: 14938
[18:32:03.322801] Test:  [320/345]  eta: 0:00:04  loss: 0.8013 (0.8092)  time: 0.1942  data: 0.0001  max mem: 14938
[18:32:05.271629] Test:  [330/345]  eta: 0:00:02  loss: 0.8095 (0.8091)  time: 0.1945  data: 0.0001  max mem: 14938
[18:32:07.222268] Test:  [340/345]  eta: 0:00:00  loss: 0.8025 (0.8093)  time: 0.1949  data: 0.0001  max mem: 14938
[18:32:08.003619] Test:  [344/345]  eta: 0:00:00  loss: 0.8097 (0.8093)  time: 0.1950  data: 0.0001  max mem: 14938
[18:32:08.061802] Test: Total time: 0:01:05 (0.1901 s / it)
[18:32:18.506938] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8952 (0.8952)  time: 0.3166  data: 0.1376  max mem: 14938
[18:32:20.322262] Test:  [10/57]  eta: 0:00:09  loss: 0.8933 (0.8975)  time: 0.1937  data: 0.0126  max mem: 14938
[18:32:22.143298] Test:  [20/57]  eta: 0:00:06  loss: 0.8933 (0.8919)  time: 0.1818  data: 0.0001  max mem: 14938
[18:32:23.968500] Test:  [30/57]  eta: 0:00:05  loss: 0.8028 (0.8525)  time: 0.1823  data: 0.0001  max mem: 14938
[18:32:25.800039] Test:  [40/57]  eta: 0:00:03  loss: 0.7611 (0.8288)  time: 0.1828  data: 0.0001  max mem: 14938
[18:32:27.638391] Test:  [50/57]  eta: 0:00:01  loss: 0.7611 (0.8209)  time: 0.1834  data: 0.0001  max mem: 14938
[18:32:28.629089] Test:  [56/57]  eta: 0:00:00  loss: 0.7922 (0.8258)  time: 0.1781  data: 0.0001  max mem: 14938
[18:32:28.683756] Test: Total time: 0:00:10 (0.1841 s / it)
[18:32:30.433232] Dice score of the network on the train images: 0.760456, val images: 0.806897
[18:32:30.433454] saving best_prec_model_0 @ epoch 10
[18:32:31.646056] saving best_dice_model_0 @ epoch 10
[18:32:32.686674] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:32:33.569894] Epoch: [11]  [  0/345]  eta: 0:05:04  lr: 0.000069  loss: 0.8739 (0.8739)  time: 0.8820  data: 0.1409  max mem: 14938
[18:32:48.435015] Epoch: [11]  [ 20/345]  eta: 0:04:03  lr: 0.000069  loss: 0.8485 (0.8458)  time: 0.7432  data: 0.0001  max mem: 14938
[18:33:03.348709] Epoch: [11]  [ 40/345]  eta: 0:03:48  lr: 0.000069  loss: 0.8302 (0.8425)  time: 0.7456  data: 0.0001  max mem: 14938
[18:33:18.295635] Epoch: [11]  [ 60/345]  eta: 0:03:33  lr: 0.000070  loss: 0.8339 (0.8406)  time: 0.7473  data: 0.0001  max mem: 14938
[18:33:33.285546] Epoch: [11]  [ 80/345]  eta: 0:03:18  lr: 0.000070  loss: 0.8473 (0.8415)  time: 0.7495  data: 0.0001  max mem: 14938
[18:33:48.301358] Epoch: [11]  [100/345]  eta: 0:03:03  lr: 0.000071  loss: 0.8355 (0.8421)  time: 0.7507  data: 0.0001  max mem: 14938
[18:34:03.328657] Epoch: [11]  [120/345]  eta: 0:02:48  lr: 0.000071  loss: 0.8363 (0.8426)  time: 0.7513  data: 0.0001  max mem: 14938
[18:34:18.359281] Epoch: [11]  [140/345]  eta: 0:02:33  lr: 0.000071  loss: 0.8329 (0.8424)  time: 0.7515  data: 0.0001  max mem: 14938
[18:34:33.361137] Epoch: [11]  [160/345]  eta: 0:02:18  lr: 0.000072  loss: 0.8309 (0.8412)  time: 0.7500  data: 0.0001  max mem: 14938
[18:34:48.364066] Epoch: [11]  [180/345]  eta: 0:02:03  lr: 0.000072  loss: 0.8382 (0.8409)  time: 0.7501  data: 0.0001  max mem: 14938
[18:35:03.367843] Epoch: [11]  [200/345]  eta: 0:01:48  lr: 0.000072  loss: 0.8307 (0.8407)  time: 0.7501  data: 0.0001  max mem: 14938

[18:35:18.364480] Epoch: [11]  [220/345]  eta: 0:01:33  lr: 0.000073  loss: 0.8518 (0.8418)  time: 0.7498  data: 0.0001  max mem: 14938
[18:35:33.350827] Epoch: [11]  [240/345]  eta: 0:01:18  lr: 0.000073  loss: 0.8288 (0.8408)  time: 0.7493  data: 0.0001  max mem: 14938
[18:35:48.338757] Epoch: [11]  [260/345]  eta: 0:01:03  lr: 0.000073  loss: 0.8242 (0.8399)  time: 0.7494  data: 0.0001  max mem: 14938
[18:36:03.325784] Epoch: [11]  [280/345]  eta: 0:00:48  lr: 0.000074  loss: 0.8388 (0.8400)  time: 0.7493  data: 0.0001  max mem: 14938
[18:36:18.307582] Epoch: [11]  [300/345]  eta: 0:00:33  lr: 0.000074  loss: 0.8231 (0.8391)  time: 0.7490  data: 0.0001  max mem: 14938
[18:36:33.286193] Epoch: [11]  [320/345]  eta: 0:00:18  lr: 0.000075  loss: 0.8295 (0.8389)  time: 0.7489  data: 0.0001  max mem: 14938
[18:36:48.267685] Epoch: [11]  [340/345]  eta: 0:00:03  lr: 0.000075  loss: 0.8252 (0.8383)  time: 0.7490  data: 0.0001  max mem: 14938
[18:36:51.262298] Epoch: [11]  [344/345]  eta: 0:00:00  lr: 0.000075  loss: 0.8243 (0.8381)  time: 0.7489  data: 0.0001  max mem: 14938
[18:36:51.327157] Epoch: [11] Total time: 0:04:18 (0.7497 s / it)
[18:36:51.327620] Averaged stats: lr: 0.000075  loss: 0.8243 (0.8381)
[18:36:51.660913] Test:  [  0/345]  eta: 0:01:53  loss: 0.8242 (0.8242)  time: 0.3293  data: 0.1470  max mem: 14938
[18:36:53.500152] Test:  [ 10/345]  eta: 0:01:06  loss: 0.8025 (0.8044)  time: 0.1971  data: 0.0134  max mem: 14938
[18:36:55.339634] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7963 (0.7985)  time: 0.1839  data: 0.0001  max mem: 14938
[18:36:57.184681] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7867 (0.7970)  time: 0.1842  data: 0.0001  max mem: 14938
[18:36:59.033942] Test:  [ 40/345]  eta: 0:00:57  loss: 0.8038 (0.8026)  time: 0.1847  data: 0.0001  max mem: 14938
[18:37:00.886797] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8147 (0.8034)  time: 0.1850  data: 0.0001  max mem: 14938
[18:37:02.742092] Test:  [ 60/345]  eta: 0:00:53  loss: 0.8077 (0.8031)  time: 0.1854  data: 0.0001  max mem: 14938
[18:37:04.600205] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8050 (0.8026)  time: 0.1856  data: 0.0001  max mem: 14938
[18:37:06.463168] Test:  [ 80/345]  eta: 0:00:49  loss: 0.8014 (0.8027)  time: 0.1860  data: 0.0001  max mem: 14938
[18:37:08.328771] Test:  [ 90/345]  eta: 0:00:47  loss: 0.8059 (0.8035)  time: 0.1864  data: 0.0001  max mem: 14938
[18:37:10.197482] Test:  [100/345]  eta: 0:00:45  loss: 0.8083 (0.8038)  time: 0.1867  data: 0.0001  max mem: 14938
[18:37:12.069790] Test:  [110/345]  eta: 0:00:43  loss: 0.8092 (0.8043)  time: 0.1870  data: 0.0001  max mem: 14938
[18:37:13.945828] Test:  [120/345]  eta: 0:00:42  loss: 0.8074 (0.8041)  time: 0.1874  data: 0.0001  max mem: 14938
[18:37:15.824754] Test:  [130/345]  eta: 0:00:40  loss: 0.8021 (0.8043)  time: 0.1877  data: 0.0001  max mem: 14938
[18:37:17.708321] Test:  [140/345]  eta: 0:00:38  loss: 0.8021 (0.8043)  time: 0.1881  data: 0.0001  max mem: 14938
[18:37:19.593104] Test:  [150/345]  eta: 0:00:36  loss: 0.8027 (0.8048)  time: 0.1884  data: 0.0001  max mem: 14938
[18:37:21.483436] Test:  [160/345]  eta: 0:00:34  loss: 0.8017 (0.8041)  time: 0.1887  data: 0.0001  max mem: 14938
[18:37:23.376530] Test:  [170/345]  eta: 0:00:32  loss: 0.7925 (0.8036)  time: 0.1891  data: 0.0001  max mem: 14938
[18:37:25.273376] Test:  [180/345]  eta: 0:00:30  loss: 0.8028 (0.8041)  time: 0.1894  data: 0.0001  max mem: 14938
[18:37:27.173029] Test:  [190/345]  eta: 0:00:29  loss: 0.8091 (0.8043)  time: 0.1898  data: 0.0001  max mem: 14938
[18:37:29.074069] Test:  [200/345]  eta: 0:00:27  loss: 0.7937 (0.8038)  time: 0.1900  data: 0.0001  max mem: 14938
[18:37:30.981881] Test:  [210/345]  eta: 0:00:25  loss: 0.7937 (0.8038)  time: 0.1904  data: 0.0001  max mem: 14938
[18:37:32.893471] Test:  [220/345]  eta: 0:00:23  loss: 0.8038 (0.8036)  time: 0.1909  data: 0.0001  max mem: 14938
[18:37:34.809951] Test:  [230/345]  eta: 0:00:21  loss: 0.8022 (0.8034)  time: 0.1914  data: 0.0001  max mem: 14938
[18:37:36.728644] Test:  [240/345]  eta: 0:00:19  loss: 0.7978 (0.8034)  time: 0.1917  data: 0.0001  max mem: 14938
[18:37:38.649663] Test:  [250/345]  eta: 0:00:17  loss: 0.7900 (0.8029)  time: 0.1919  data: 0.0001  max mem: 14938
[18:37:40.573909] Test:  [260/345]  eta: 0:00:16  loss: 0.7894 (0.8026)  time: 0.1922  data: 0.0001  max mem: 14938
[18:37:42.503272] Test:  [270/345]  eta: 0:00:14  loss: 0.8006 (0.8025)  time: 0.1926  data: 0.0001  max mem: 14938
[18:37:44.436401] Test:  [280/345]  eta: 0:00:12  loss: 0.8058 (0.8030)  time: 0.1931  data: 0.0001  max mem: 14938
[18:37:46.371957] Test:  [290/345]  eta: 0:00:10  loss: 0.8176 (0.8032)  time: 0.1934  data: 0.0001  max mem: 14938
[18:37:48.311128] Test:  [300/345]  eta: 0:00:08  loss: 0.8017 (0.8031)  time: 0.1937  data: 0.0001  max mem: 14938
[18:37:50.254470] Test:  [310/345]  eta: 0:00:06  loss: 0.7990 (0.8030)  time: 0.1941  data: 0.0001  max mem: 14938
[18:37:52.197541] Test:  [320/345]  eta: 0:00:04  loss: 0.8042 (0.8032)  time: 0.1943  data: 0.0001  max mem: 14938
[18:37:54.145198] Test:  [330/345]  eta: 0:00:02  loss: 0.8035 (0.8031)  time: 0.1945  data: 0.0001  max mem: 14938
[18:37:56.095832] Test:  [340/345]  eta: 0:00:00  loss: 0.7970 (0.8030)  time: 0.1949  data: 0.0001  max mem: 14938
[18:37:56.878238] Test:  [344/345]  eta: 0:00:00  loss: 0.7970 (0.8029)  time: 0.1950  data: 0.0001  max mem: 14938
[18:37:56.936860] Test: Total time: 0:01:05 (0.1902 s / it)
[18:38:07.286374] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8181 (0.8181)  time: 0.3175  data: 0.1378  max mem: 14938
[18:38:09.102974] Test:  [10/57]  eta: 0:00:09  loss: 0.8658 (0.8761)  time: 0.1939  data: 0.0126  max mem: 14938
[18:38:10.926887] Test:  [20/57]  eta: 0:00:06  loss: 0.8712 (0.8701)  time: 0.1820  data: 0.0001  max mem: 14938
[18:38:12.755349] Test:  [30/57]  eta: 0:00:05  loss: 0.7737 (0.8355)  time: 0.1826  data: 0.0001  max mem: 14938
[18:38:14.587982] Test:  [40/57]  eta: 0:00:03  loss: 0.7586 (0.8171)  time: 0.1830  data: 0.0001  max mem: 14938
[18:38:16.424376] Test:  [50/57]  eta: 0:00:01  loss: 0.7468 (0.8109)  time: 0.1834  data: 0.0001  max mem: 14938
[18:38:17.415062] Test:  [56/57]  eta: 0:00:00  loss: 0.8003 (0.8175)  time: 0.1780  data: 0.0001  max mem: 14938
[18:38:17.474786] Test: Total time: 0:00:10 (0.1843 s / it)
[18:38:19.196695] Dice score of the network on the train images: 0.728987, val images: 0.793597
[18:38:19.196915] saving best_rec_model_0 @ epoch 11
[18:38:20.402630] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:38:21.287613] Epoch: [12]  [  0/345]  eta: 0:05:04  lr: 0.000075  loss: 0.8792 (0.8792)  time: 0.8838  data: 0.1433  max mem: 14938
[18:38:36.160366] Epoch: [12]  [ 20/345]  eta: 0:04:03  lr: 0.000075  loss: 0.8236 (0.8368)  time: 0.7436  data: 0.0001  max mem: 14938
[18:38:51.073902] Epoch: [12]  [ 40/345]  eta: 0:03:48  lr: 0.000076  loss: 0.8248 (0.8327)  time: 0.7456  data: 0.0001  max mem: 14938
[18:39:06.012228] Epoch: [12]  [ 60/345]  eta: 0:03:33  lr: 0.000076  loss: 0.8408 (0.8341)  time: 0.7469  data: 0.0001  max mem: 14938
[18:39:20.984520] Epoch: [12]  [ 80/345]  eta: 0:03:18  lr: 0.000076  loss: 0.8323 (0.8346)  time: 0.7486  data: 0.0001  max mem: 14938
[18:39:35.991727] Epoch: [12]  [100/345]  eta: 0:03:03  lr: 0.000077  loss: 0.8054 (0.8306)  time: 0.7503  data: 0.0001  max mem: 14938
[18:39:51.012765] Epoch: [12]  [120/345]  eta: 0:02:48  lr: 0.000077  loss: 0.8225 (0.8293)  time: 0.7510  data: 0.0001  max mem: 14938
[18:40:06.047862] Epoch: [12]  [140/345]  eta: 0:02:33  lr: 0.000078  loss: 0.8086 (0.8271)  time: 0.7517  data: 0.0001  max mem: 14938
[18:40:21.085307] Epoch: [12]  [160/345]  eta: 0:02:18  lr: 0.000078  loss: 0.8290 (0.8271)  time: 0.7518  data: 0.0001  max mem: 14938
[18:40:36.130403] Epoch: [12]  [180/345]  eta: 0:02:03  lr: 0.000078  loss: 0.8137 (0.8258)  time: 0.7522  data: 0.0001  max mem: 14938
[18:40:51.283246] Epoch: [12]  [200/345]  eta: 0:01:48  lr: 0.000079  loss: 0.8118 (0.8244)  time: 0.7576  data: 0.0001  max mem: 14938
[18:41:06.309329] Epoch: [12]  [220/345]  eta: 0:01:33  lr: 0.000079  loss: 0.8265 (0.8247)  time: 0.7513  data: 0.0001  max mem: 14938
[18:41:21.323633] Epoch: [12]  [240/345]  eta: 0:01:18  lr: 0.000079  loss: 0.8154 (0.8244)  time: 0.7507  data: 0.0001  max mem: 14938
[18:41:36.326093] Epoch: [12]  [260/345]  eta: 0:01:03  lr: 0.000080  loss: 0.8163 (0.8240)  time: 0.7501  data: 0.0001  max mem: 14938
[18:41:51.320278] Epoch: [12]  [280/345]  eta: 0:00:48  lr: 0.000080  loss: 0.8197 (0.8238)  time: 0.7497  data: 0.0001  max mem: 14938
[18:42:06.323473] Epoch: [12]  [300/345]  eta: 0:00:33  lr: 0.000080  loss: 0.8241 (0.8237)  time: 0.7501  data: 0.0001  max mem: 14938
[18:42:21.332756] Epoch: [12]  [320/345]  eta: 0:00:18  lr: 0.000081  loss: 0.8234 (0.8237)  time: 0.7504  data: 0.0001  max mem: 14938
[18:42:36.315654] Epoch: [12]  [340/345]  eta: 0:00:03  lr: 0.000081  loss: 0.8256 (0.8238)  time: 0.7491  data: 0.0001  max mem: 14938
[18:42:39.318897] Epoch: [12]  [344/345]  eta: 0:00:00  lr: 0.000081  loss: 0.8282 (0.8238)  time: 0.7495  data: 0.0001  max mem: 14938
[18:42:39.382148] Epoch: [12] Total time: 0:04:18 (0.7507 s / it)
[18:42:39.382480] Averaged stats: lr: 0.000081  loss: 0.8282 (0.8238)
[18:42:39.724182] Test:  [  0/345]  eta: 0:01:56  loss: 0.8282 (0.8282)  time: 0.3370  data: 0.1546  max mem: 14938
[18:42:41.563277] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7892 (0.7955)  time: 0.1977  data: 0.0141  max mem: 14938
[18:42:43.403794] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7838 (0.7903)  time: 0.1839  data: 0.0001  max mem: 14938
[18:42:45.248985] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7786 (0.7894)  time: 0.1842  data: 0.0001  max mem: 14938
[18:42:47.097538] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7848 (0.7890)  time: 0.1846  data: 0.0001  max mem: 14938
[18:42:48.948699] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7840 (0.7874)  time: 0.1849  data: 0.0001  max mem: 14938
[18:42:50.804088] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7876 (0.7893)  time: 0.1853  data: 0.0001  max mem: 14938
[18:42:52.661676] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7902 (0.7893)  time: 0.1856  data: 0.0001  max mem: 14938
[18:42:54.523771] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7917 (0.7899)  time: 0.1859  data: 0.0001  max mem: 14938
[18:42:56.389395] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7951 (0.7898)  time: 0.1863  data: 0.0001  max mem: 14938
[18:42:58.259742] Test:  [100/345]  eta: 0:00:45  loss: 0.7815 (0.7889)  time: 0.1867  data: 0.0001  max mem: 14938
[18:43:00.133013] Test:  [110/345]  eta: 0:00:43  loss: 0.7787 (0.7884)  time: 0.1871  data: 0.0001  max mem: 14938
[18:43:02.008825] Test:  [120/345]  eta: 0:00:42  loss: 0.7805 (0.7884)  time: 0.1874  data: 0.0001  max mem: 14938
[18:43:03.886988] Test:  [130/345]  eta: 0:00:40  loss: 0.7914 (0.7884)  time: 0.1876  data: 0.0001  max mem: 14938
[18:43:05.771095] Test:  [140/345]  eta: 0:00:38  loss: 0.7872 (0.7884)  time: 0.1881  data: 0.0001  max mem: 14938
[18:43:07.655774] Test:  [150/345]  eta: 0:00:36  loss: 0.7910 (0.7883)  time: 0.1884  data: 0.0001  max mem: 14938
[18:43:09.544383] Test:  [160/345]  eta: 0:00:34  loss: 0.7891 (0.7882)  time: 0.1886  data: 0.0001  max mem: 14938
[18:43:11.435393] Test:  [170/345]  eta: 0:00:32  loss: 0.7864 (0.7880)  time: 0.1889  data: 0.0001  max mem: 14938
[18:43:13.334441] Test:  [180/345]  eta: 0:00:30  loss: 0.7794 (0.7875)  time: 0.1895  data: 0.0001  max mem: 14938
[18:43:15.237796] Test:  [190/345]  eta: 0:00:29  loss: 0.7766 (0.7870)  time: 0.1901  data: 0.0001  max mem: 14938
[18:43:17.141466] Test:  [200/345]  eta: 0:00:27  loss: 0.7784 (0.7871)  time: 0.1903  data: 0.0001  max mem: 14938
[18:43:19.051064] Test:  [210/345]  eta: 0:00:25  loss: 0.7826 (0.7870)  time: 0.1906  data: 0.0001  max mem: 14938
[18:43:20.961828] Test:  [220/345]  eta: 0:00:23  loss: 0.7840 (0.7872)  time: 0.1910  data: 0.0001  max mem: 14938
[18:43:22.877710] Test:  [230/345]  eta: 0:00:21  loss: 0.7892 (0.7871)  time: 0.1913  data: 0.0001  max mem: 14938
[18:43:24.796240] Test:  [240/345]  eta: 0:00:19  loss: 0.7862 (0.7870)  time: 0.1917  data: 0.0001  max mem: 14938
[18:43:26.718506] Test:  [250/345]  eta: 0:00:17  loss: 0.7935 (0.7876)  time: 0.1920  data: 0.0001  max mem: 14938
[18:43:28.643135] Test:  [260/345]  eta: 0:00:16  loss: 0.7854 (0.7874)  time: 0.1923  data: 0.0001  max mem: 14938
[18:43:30.572198] Test:  [270/345]  eta: 0:00:14  loss: 0.7849 (0.7873)  time: 0.1926  data: 0.0001  max mem: 14938
[18:43:32.505533] Test:  [280/345]  eta: 0:00:12  loss: 0.7998 (0.7878)  time: 0.1931  data: 0.0001  max mem: 14938
[18:43:34.439037] Test:  [290/345]  eta: 0:00:10  loss: 0.8010 (0.7880)  time: 0.1933  data: 0.0001  max mem: 14938
[18:43:36.377830] Test:  [300/345]  eta: 0:00:08  loss: 0.7807 (0.7880)  time: 0.1936  data: 0.0001  max mem: 14938
[18:43:38.320929] Test:  [310/345]  eta: 0:00:06  loss: 0.7787 (0.7878)  time: 0.1940  data: 0.0001  max mem: 14938
[18:43:40.265090] Test:  [320/345]  eta: 0:00:04  loss: 0.7800 (0.7876)  time: 0.1943  data: 0.0001  max mem: 14938
[18:43:42.212832] Test:  [330/345]  eta: 0:00:02  loss: 0.7840 (0.7874)  time: 0.1945  data: 0.0001  max mem: 14938
[18:43:44.163443] Test:  [340/345]  eta: 0:00:00  loss: 0.7815 (0.7873)  time: 0.1949  data: 0.0001  max mem: 14938
[18:43:44.946803] Test:  [344/345]  eta: 0:00:00  loss: 0.7826 (0.7874)  time: 0.1951  data: 0.0001  max mem: 14938
[18:43:45.002906] Test: Total time: 0:01:05 (0.1902 s / it)
[18:43:55.471016] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8747 (0.8747)  time: 0.3166  data: 0.1368  max mem: 14938
[18:43:57.286663] Test:  [10/57]  eta: 0:00:09  loss: 0.8794 (0.8821)  time: 0.1938  data: 0.0125  max mem: 14938
[18:43:59.107608] Test:  [20/57]  eta: 0:00:06  loss: 0.8794 (0.8739)  time: 0.1818  data: 0.0001  max mem: 14938
[18:44:00.933625] Test:  [30/57]  eta: 0:00:05  loss: 0.7807 (0.8375)  time: 0.1823  data: 0.0001  max mem: 14938
[18:44:02.768755] Test:  [40/57]  eta: 0:00:03  loss: 0.7556 (0.8165)  time: 0.1830  data: 0.0001  max mem: 14938
[18:44:04.605485] Test:  [50/57]  eta: 0:00:01  loss: 0.7430 (0.8084)  time: 0.1835  data: 0.0001  max mem: 14938
[18:44:05.596286] Test:  [56/57]  eta: 0:00:00  loss: 0.7859 (0.8146)  time: 0.1781  data: 0.0001  max mem: 14938
[18:44:05.654806] Test: Total time: 0:00:10 (0.1842 s / it)
[18:44:07.354826] Dice score of the network on the train images: 0.748356, val images: 0.801446
[18:44:07.358756] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:44:08.240169] Epoch: [13]  [  0/345]  eta: 0:05:03  lr: 0.000081  loss: 0.8191 (0.8191)  time: 0.8804  data: 0.1370  max mem: 14938
[18:44:23.141504] Epoch: [13]  [ 20/345]  eta: 0:04:04  lr: 0.000082  loss: 0.8140 (0.8123)  time: 0.7450  data: 0.0001  max mem: 14938
[18:44:38.084857] Epoch: [13]  [ 40/345]  eta: 0:03:48  lr: 0.000082  loss: 0.8216 (0.8176)  time: 0.7471  data: 0.0001  max mem: 14938
[18:44:53.056974] Epoch: [13]  [ 60/345]  eta: 0:03:33  lr: 0.000082  loss: 0.8286 (0.8239)  time: 0.7486  data: 0.0001  max mem: 14938
[18:45:08.035656] Epoch: [13]  [ 80/345]  eta: 0:03:18  lr: 0.000083  loss: 0.8205 (0.8229)  time: 0.7489  data: 0.0001  max mem: 14938
[18:45:23.064023] Epoch: [13]  [100/345]  eta: 0:03:03  lr: 0.000083  loss: 0.8167 (0.8233)  time: 0.7514  data: 0.0001  max mem: 14938
[18:45:38.095381] Epoch: [13]  [120/345]  eta: 0:02:48  lr: 0.000083  loss: 0.8025 (0.8211)  time: 0.7515  data: 0.0001  max mem: 14938
[18:45:53.138063] Epoch: [13]  [140/345]  eta: 0:02:33  lr: 0.000084  loss: 0.8084 (0.8195)  time: 0.7521  data: 0.0001  max mem: 14938
[18:46:08.181604] Epoch: [13]  [160/345]  eta: 0:02:18  lr: 0.000084  loss: 0.8100 (0.8182)  time: 0.7521  data: 0.0001  max mem: 14938
[18:46:23.196534] Epoch: [13]  [180/345]  eta: 0:02:03  lr: 0.000085  loss: 0.8041 (0.8171)  time: 0.7507  data: 0.0001  max mem: 14938
[18:46:38.221624] Epoch: [13]  [200/345]  eta: 0:01:48  lr: 0.000085  loss: 0.8017 (0.8163)  time: 0.7512  data: 0.0001  max mem: 14938
[18:46:53.224892] Epoch: [13]  [220/345]  eta: 0:01:33  lr: 0.000085  loss: 0.8099 (0.8165)  time: 0.7501  data: 0.0001  max mem: 14938
[18:47:08.217986] Epoch: [13]  [240/345]  eta: 0:01:18  lr: 0.000086  loss: 0.8362 (0.8181)  time: 0.7496  data: 0.0001  max mem: 14938
[18:47:23.234084] Epoch: [13]  [260/345]  eta: 0:01:03  lr: 0.000086  loss: 0.8209 (0.8183)  time: 0.7508  data: 0.0001  max mem: 14938
[18:47:38.237926] Epoch: [13]  [280/345]  eta: 0:00:48  lr: 0.000086  loss: 0.8169 (0.8182)  time: 0.7501  data: 0.0001  max mem: 14938
[18:47:53.245125] Epoch: [13]  [300/345]  eta: 0:00:33  lr: 0.000087  loss: 0.8187 (0.8182)  time: 0.7503  data: 0.0001  max mem: 14938
[18:48:08.250284] Epoch: [13]  [320/345]  eta: 0:00:18  lr: 0.000087  loss: 0.8139 (0.8178)  time: 0.7502  data: 0.0001  max mem: 14938

[18:48:23.254654] Epoch: [13]  [340/345]  eta: 0:00:03  lr: 0.000087  loss: 0.8050 (0.8174)  time: 0.7502  data: 0.0001  max mem: 14938
[18:48:26.254107] Epoch: [13]  [344/345]  eta: 0:00:00  lr: 0.000087  loss: 0.8060 (0.8172)  time: 0.7501  data: 0.0001  max mem: 14938
[18:48:26.315398] Epoch: [13] Total time: 0:04:18 (0.7506 s / it)
[18:48:26.315511] Averaged stats: lr: 0.000087  loss: 0.8060 (0.8172)
[18:48:26.648579] Test:  [  0/345]  eta: 0:01:53  loss: 0.7693 (0.7693)  time: 0.3290  data: 0.1469  max mem: 14938
[18:48:28.485457] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7726 (0.7696)  time: 0.1968  data: 0.0134  max mem: 14938
[18:48:30.324647] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7689 (0.7684)  time: 0.1837  data: 0.0001  max mem: 14938
[18:48:32.167508] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7599 (0.7704)  time: 0.1840  data: 0.0001  max mem: 14938
[18:48:34.014418] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7634 (0.7696)  time: 0.1844  data: 0.0001  max mem: 14938
[18:48:35.864372] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7758 (0.7716)  time: 0.1848  data: 0.0001  max mem: 14938
[18:48:37.719742] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7696 (0.7702)  time: 0.1852  data: 0.0001  max mem: 14938
[18:48:39.575713] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7605 (0.7698)  time: 0.1855  data: 0.0001  max mem: 14938
[18:48:41.437005] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7740 (0.7716)  time: 0.1858  data: 0.0001  max mem: 14938
[18:48:43.300701] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7704 (0.7697)  time: 0.1862  data: 0.0001  max mem: 14938
[18:48:45.167016] Test:  [100/345]  eta: 0:00:45  loss: 0.7631 (0.7694)  time: 0.1865  data: 0.0001  max mem: 14938
[18:48:47.037203] Test:  [110/345]  eta: 0:00:43  loss: 0.7715 (0.7699)  time: 0.1868  data: 0.0001  max mem: 14938
[18:48:48.910320] Test:  [120/345]  eta: 0:00:41  loss: 0.7694 (0.7701)  time: 0.1871  data: 0.0001  max mem: 14938
[18:48:50.787791] Test:  [130/345]  eta: 0:00:40  loss: 0.7701 (0.7706)  time: 0.1875  data: 0.0001  max mem: 14938
[18:48:52.669828] Test:  [140/345]  eta: 0:00:38  loss: 0.7747 (0.7706)  time: 0.1879  data: 0.0001  max mem: 14938
[18:48:54.554008] Test:  [150/345]  eta: 0:00:36  loss: 0.7681 (0.7707)  time: 0.1883  data: 0.0001  max mem: 14938
[18:48:56.441314] Test:  [160/345]  eta: 0:00:34  loss: 0.7663 (0.7703)  time: 0.1885  data: 0.0001  max mem: 14938
[18:48:58.332472] Test:  [170/345]  eta: 0:00:32  loss: 0.7657 (0.7701)  time: 0.1889  data: 0.0001  max mem: 14938
[18:49:00.227080] Test:  [180/345]  eta: 0:00:30  loss: 0.7657 (0.7698)  time: 0.1892  data: 0.0001  max mem: 14938
[18:49:02.125577] Test:  [190/345]  eta: 0:00:29  loss: 0.7707 (0.7701)  time: 0.1896  data: 0.0001  max mem: 14938
[18:49:04.026382] Test:  [200/345]  eta: 0:00:27  loss: 0.7712 (0.7701)  time: 0.1899  data: 0.0001  max mem: 14938
[18:49:05.931798] Test:  [210/345]  eta: 0:00:25  loss: 0.7658 (0.7699)  time: 0.1903  data: 0.0001  max mem: 14938
[18:49:07.842339] Test:  [220/345]  eta: 0:00:23  loss: 0.7672 (0.7698)  time: 0.1907  data: 0.0001  max mem: 14938
[18:49:09.755715] Test:  [230/345]  eta: 0:00:21  loss: 0.7672 (0.7697)  time: 0.1911  data: 0.0001  max mem: 14938
[18:49:11.673483] Test:  [240/345]  eta: 0:00:19  loss: 0.7605 (0.7697)  time: 0.1915  data: 0.0001  max mem: 14938
[18:49:13.594185] Test:  [250/345]  eta: 0:00:17  loss: 0.7563 (0.7692)  time: 0.1919  data: 0.0001  max mem: 14938
[18:49:15.517798] Test:  [260/345]  eta: 0:00:16  loss: 0.7599 (0.7694)  time: 0.1922  data: 0.0001  max mem: 14938
[18:49:17.444916] Test:  [270/345]  eta: 0:00:14  loss: 0.7656 (0.7693)  time: 0.1925  data: 0.0001  max mem: 14938
[18:49:19.375720] Test:  [280/345]  eta: 0:00:12  loss: 0.7676 (0.7693)  time: 0.1928  data: 0.0001  max mem: 14938
[18:49:21.309680] Test:  [290/345]  eta: 0:00:10  loss: 0.7695 (0.7693)  time: 0.1932  data: 0.0001  max mem: 14938
[18:49:23.247237] Test:  [300/345]  eta: 0:00:08  loss: 0.7645 (0.7692)  time: 0.1935  data: 0.0001  max mem: 14938
[18:49:25.187499] Test:  [310/345]  eta: 0:00:06  loss: 0.7641 (0.7691)  time: 0.1938  data: 0.0001  max mem: 14938
[18:49:27.131085] Test:  [320/345]  eta: 0:00:04  loss: 0.7679 (0.7693)  time: 0.1941  data: 0.0001  max mem: 14938
[18:49:29.078014] Test:  [330/345]  eta: 0:00:02  loss: 0.7702 (0.7692)  time: 0.1945  data: 0.0001  max mem: 14938
[18:49:31.027833] Test:  [340/345]  eta: 0:00:00  loss: 0.7653 (0.7691)  time: 0.1948  data: 0.0001  max mem: 14938
[18:49:31.808578] Test:  [344/345]  eta: 0:00:00  loss: 0.7653 (0.7691)  time: 0.1949  data: 0.0001  max mem: 14938
[18:49:31.867024] Test: Total time: 0:01:05 (0.1900 s / it)
[18:49:42.120715] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8615 (0.8615)  time: 0.3189  data: 0.1388  max mem: 14938
[18:49:43.937913] Test:  [10/57]  eta: 0:00:09  loss: 0.8679 (0.8764)  time: 0.1941  data: 0.0127  max mem: 14938
[18:49:45.761302] Test:  [20/57]  eta: 0:00:06  loss: 0.8679 (0.8646)  time: 0.1820  data: 0.0001  max mem: 14938
[18:49:47.586031] Test:  [30/57]  eta: 0:00:05  loss: 0.7714 (0.8290)  time: 0.1824  data: 0.0001  max mem: 14938
[18:49:49.420985] Test:  [40/57]  eta: 0:00:03  loss: 0.7509 (0.8084)  time: 0.1829  data: 0.0001  max mem: 14938
[18:49:51.257373] Test:  [50/57]  eta: 0:00:01  loss: 0.7390 (0.8017)  time: 0.1835  data: 0.0001  max mem: 14938
[18:49:52.248111] Test:  [56/57]  eta: 0:00:00  loss: 0.7733 (0.8078)  time: 0.1780  data: 0.0001  max mem: 14938
[18:49:52.303764] Test: Total time: 0:00:10 (0.1843 s / it)
[18:49:54.016058] Dice score of the network on the train images: 0.767102, val images: 0.811273
[18:49:54.016289] saving best_prec_model_0 @ epoch 13
[18:49:55.086721] saving best_dice_model_0 @ epoch 13
[18:49:56.154438] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:49:57.039885] Epoch: [14]  [  0/345]  eta: 0:05:05  lr: 0.000087  loss: 0.8088 (0.8088)  time: 0.8846  data: 0.1438  max mem: 14938
[18:50:11.928765] Epoch: [14]  [ 20/345]  eta: 0:04:04  lr: 0.000088  loss: 0.7959 (0.8051)  time: 0.7444  data: 0.0001  max mem: 14938
[18:50:26.871453] Epoch: [14]  [ 40/345]  eta: 0:03:48  lr: 0.000088  loss: 0.8033 (0.8079)  time: 0.7471  data: 0.0001  max mem: 14938
[18:50:41.836626] Epoch: [14]  [ 60/345]  eta: 0:03:33  lr: 0.000089  loss: 0.8023 (0.8070)  time: 0.7482  data: 0.0001  max mem: 14938
[18:50:56.821450] Epoch: [14]  [ 80/345]  eta: 0:03:18  lr: 0.000089  loss: 0.7946 (0.8050)  time: 0.7492  data: 0.0001  max mem: 14938
[18:51:11.851329] Epoch: [14]  [100/345]  eta: 0:03:03  lr: 0.000089  loss: 0.8016 (0.8046)  time: 0.7515  data: 0.0001  max mem: 14938
[18:51:26.913401] Epoch: [14]  [120/345]  eta: 0:02:48  lr: 0.000090  loss: 0.8087 (0.8055)  time: 0.7531  data: 0.0001  max mem: 14938
[18:51:41.961753] Epoch: [14]  [140/345]  eta: 0:02:33  lr: 0.000090  loss: 0.8059 (0.8058)  time: 0.7524  data: 0.0001  max mem: 14938
[18:51:56.999477] Epoch: [14]  [160/345]  eta: 0:02:18  lr: 0.000090  loss: 0.8000 (0.8059)  time: 0.7518  data: 0.0001  max mem: 14938
[18:52:12.032017] Epoch: [14]  [180/345]  eta: 0:02:03  lr: 0.000091  loss: 0.8038 (0.8058)  time: 0.7516  data: 0.0001  max mem: 14938
[18:52:27.057062] Epoch: [14]  [200/345]  eta: 0:01:48  lr: 0.000091  loss: 0.8021 (0.8052)  time: 0.7512  data: 0.0001  max mem: 14938
[18:52:42.082002] Epoch: [14]  [220/345]  eta: 0:01:33  lr: 0.000091  loss: 0.8048 (0.8051)  time: 0.7512  data: 0.0001  max mem: 14938
[18:52:57.102551] Epoch: [14]  [240/345]  eta: 0:01:18  lr: 0.000092  loss: 0.8013 (0.8053)  time: 0.7510  data: 0.0001  max mem: 14938
[18:53:12.114185] Epoch: [14]  [260/345]  eta: 0:01:03  lr: 0.000092  loss: 0.8019 (0.8053)  time: 0.7505  data: 0.0001  max mem: 14938
[18:53:27.120151] Epoch: [14]  [280/345]  eta: 0:00:48  lr: 0.000093  loss: 0.8193 (0.8066)  time: 0.7503  data: 0.0001  max mem: 14938
[18:53:42.132050] Epoch: [14]  [300/345]  eta: 0:00:33  lr: 0.000093  loss: 0.8115 (0.8072)  time: 0.7506  data: 0.0001  max mem: 14938
[18:53:57.140283] Epoch: [14]  [320/345]  eta: 0:00:18  lr: 0.000093  loss: 0.8160 (0.8079)  time: 0.7504  data: 0.0001  max mem: 14938
[18:54:12.141497] Epoch: [14]  [340/345]  eta: 0:00:03  lr: 0.000094  loss: 0.8028 (0.8075)  time: 0.7500  data: 0.0001  max mem: 14938
[18:54:15.139551] Epoch: [14]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.8028 (0.8074)  time: 0.7498  data: 0.0001  max mem: 14938
[18:54:15.202926] Epoch: [14] Total time: 0:04:19 (0.7509 s / it)
[18:54:15.203236] Averaged stats: lr: 0.000094  loss: 0.8028 (0.8074)
[18:54:15.537773] Test:  [  0/345]  eta: 0:01:54  loss: 0.7703 (0.7703)  time: 0.3310  data: 0.1495  max mem: 14938
[18:54:17.377151] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7534 (0.7655)  time: 0.1972  data: 0.0137  max mem: 14938
[18:54:19.218630] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7630 (0.7675)  time: 0.1840  data: 0.0001  max mem: 14938
[18:54:21.064561] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7638 (0.7639)  time: 0.1843  data: 0.0001  max mem: 14938
[18:54:22.912627] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7617 (0.7640)  time: 0.1847  data: 0.0001  max mem: 14938
[18:54:24.765569] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7603 (0.7638)  time: 0.1850  data: 0.0001  max mem: 14938
[18:54:26.621043] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7599 (0.7647)  time: 0.1854  data: 0.0001  max mem: 14938
[18:54:28.479617] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7637 (0.7647)  time: 0.1857  data: 0.0001  max mem: 14938
[18:54:30.343713] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7683 (0.7664)  time: 0.1861  data: 0.0001  max mem: 14938
[18:54:32.209277] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7683 (0.7669)  time: 0.1864  data: 0.0001  max mem: 14938
[18:54:34.079700] Test:  [100/345]  eta: 0:00:45  loss: 0.7618 (0.7678)  time: 0.1868  data: 0.0001  max mem: 14938
[18:54:35.953374] Test:  [110/345]  eta: 0:00:43  loss: 0.7605 (0.7677)  time: 0.1872  data: 0.0001  max mem: 14938
[18:54:37.830154] Test:  [120/345]  eta: 0:00:42  loss: 0.7587 (0.7676)  time: 0.1875  data: 0.0001  max mem: 14938
[18:54:39.710595] Test:  [130/345]  eta: 0:00:40  loss: 0.7587 (0.7678)  time: 0.1878  data: 0.0001  max mem: 14938
[18:54:41.594164] Test:  [140/345]  eta: 0:00:38  loss: 0.7677 (0.7680)  time: 0.1882  data: 0.0001  max mem: 14938
[18:54:43.481612] Test:  [150/345]  eta: 0:00:36  loss: 0.7617 (0.7673)  time: 0.1885  data: 0.0001  max mem: 14938
[18:54:45.372676] Test:  [160/345]  eta: 0:00:34  loss: 0.7656 (0.7674)  time: 0.1889  data: 0.0001  max mem: 14938
[18:54:47.266512] Test:  [170/345]  eta: 0:00:32  loss: 0.7682 (0.7671)  time: 0.1892  data: 0.0001  max mem: 14938
[18:54:49.165148] Test:  [180/345]  eta: 0:00:30  loss: 0.7599 (0.7667)  time: 0.1896  data: 0.0001  max mem: 14938
[18:54:51.066303] Test:  [190/345]  eta: 0:00:29  loss: 0.7624 (0.7669)  time: 0.1899  data: 0.0001  max mem: 14938
[18:54:52.973167] Test:  [200/345]  eta: 0:00:27  loss: 0.7706 (0.7668)  time: 0.1904  data: 0.0001  max mem: 14938
[18:54:54.885311] Test:  [210/345]  eta: 0:00:25  loss: 0.7654 (0.7667)  time: 0.1909  data: 0.0001  max mem: 14938
[18:54:56.798955] Test:  [220/345]  eta: 0:00:23  loss: 0.7620 (0.7666)  time: 0.1912  data: 0.0001  max mem: 14938
[18:54:58.714891] Test:  [230/345]  eta: 0:00:21  loss: 0.7573 (0.7661)  time: 0.1914  data: 0.0001  max mem: 14938
[18:55:00.635773] Test:  [240/345]  eta: 0:00:19  loss: 0.7623 (0.7667)  time: 0.1918  data: 0.0001  max mem: 14938
[18:55:02.558202] Test:  [250/345]  eta: 0:00:17  loss: 0.7723 (0.7668)  time: 0.1921  data: 0.0001  max mem: 14938
[18:55:04.487572] Test:  [260/345]  eta: 0:00:16  loss: 0.7711 (0.7668)  time: 0.1925  data: 0.0001  max mem: 14938
[18:55:06.418007] Test:  [270/345]  eta: 0:00:14  loss: 0.7648 (0.7671)  time: 0.1929  data: 0.0001  max mem: 14938
[18:55:08.353191] Test:  [280/345]  eta: 0:00:12  loss: 0.7648 (0.7674)  time: 0.1932  data: 0.0001  max mem: 14938
[18:55:10.287959] Test:  [290/345]  eta: 0:00:10  loss: 0.7599 (0.7672)  time: 0.1934  data: 0.0001  max mem: 14938
[18:55:12.227757] Test:  [300/345]  eta: 0:00:08  loss: 0.7599 (0.7671)  time: 0.1937  data: 0.0001  max mem: 14938
[18:55:14.170736] Test:  [310/345]  eta: 0:00:06  loss: 0.7611 (0.7669)  time: 0.1941  data: 0.0001  max mem: 14938
[18:55:16.116130] Test:  [320/345]  eta: 0:00:04  loss: 0.7661 (0.7670)  time: 0.1944  data: 0.0001  max mem: 14938
[18:55:18.064396] Test:  [330/345]  eta: 0:00:02  loss: 0.7704 (0.7672)  time: 0.1946  data: 0.0001  max mem: 14938
[18:55:20.016869] Test:  [340/345]  eta: 0:00:00  loss: 0.7660 (0.7669)  time: 0.1950  data: 0.0001  max mem: 14938
[18:55:20.799104] Test:  [344/345]  eta: 0:00:00  loss: 0.7727 (0.7671)  time: 0.1951  data: 0.0001  max mem: 14938
[18:55:20.837060] Test: Total time: 0:01:05 (0.1902 s / it)
[18:55:31.256449] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8576 (0.8576)  time: 0.3162  data: 0.1368  max mem: 14938
[18:55:33.076123] Test:  [10/57]  eta: 0:00:09  loss: 0.8917 (0.8923)  time: 0.1941  data: 0.0125  max mem: 14938
[18:55:34.898714] Test:  [20/57]  eta: 0:00:06  loss: 0.8866 (0.8748)  time: 0.1820  data: 0.0001  max mem: 14938
[18:55:36.726779] Test:  [30/57]  eta: 0:00:05  loss: 0.7794 (0.8371)  time: 0.1825  data: 0.0001  max mem: 14938
[18:55:38.559736] Test:  [40/57]  eta: 0:00:03  loss: 0.7566 (0.8162)  time: 0.1830  data: 0.0001  max mem: 14938
[18:55:40.398550] Test:  [50/57]  eta: 0:00:01  loss: 0.7410 (0.8078)  time: 0.1835  data: 0.0001  max mem: 14938
[18:55:41.389680] Test:  [56/57]  eta: 0:00:00  loss: 0.7786 (0.8137)  time: 0.1781  data: 0.0001  max mem: 14938
[18:55:41.446799] Test: Total time: 0:00:10 (0.1843 s / it)
[18:55:43.139118] Dice score of the network on the train images: 0.781664, val images: 0.808438
[18:55:43.139334] saving best_prec_model_0 @ epoch 14
[18:55:44.204865] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:55:45.088592] Epoch: [15]  [  0/345]  eta: 0:05:04  lr: 0.000094  loss: 0.8072 (0.8072)  time: 0.8826  data: 0.1430  max mem: 14938
[18:55:59.974721] Epoch: [15]  [ 20/345]  eta: 0:04:04  lr: 0.000094  loss: 0.7897 (0.7913)  time: 0.7443  data: 0.0001  max mem: 14938
[18:56:14.912530] Epoch: [15]  [ 40/345]  eta: 0:03:48  lr: 0.000094  loss: 0.8332 (0.8180)  time: 0.7468  data: 0.0001  max mem: 14938
[18:56:29.873711] Epoch: [15]  [ 60/345]  eta: 0:03:33  lr: 0.000095  loss: 0.8271 (0.8210)  time: 0.7480  data: 0.0001  max mem: 14938
[18:56:44.868948] Epoch: [15]  [ 80/345]  eta: 0:03:18  lr: 0.000095  loss: 0.8105 (0.8190)  time: 0.7497  data: 0.0001  max mem: 14938
[18:56:59.871060] Epoch: [15]  [100/345]  eta: 0:03:03  lr: 0.000096  loss: 0.8085 (0.8177)  time: 0.7501  data: 0.0001  max mem: 14938
[18:57:14.902291] Epoch: [15]  [120/345]  eta: 0:02:48  lr: 0.000096  loss: 0.8176 (0.8175)  time: 0.7515  data: 0.0001  max mem: 14938
[18:57:29.953694] Epoch: [15]  [140/345]  eta: 0:02:33  lr: 0.000096  loss: 0.7896 (0.8142)  time: 0.7525  data: 0.0001  max mem: 14938
[18:57:44.991976] Epoch: [15]  [160/345]  eta: 0:02:18  lr: 0.000097  loss: 0.7966 (0.8124)  time: 0.7519  data: 0.0001  max mem: 14938
[18:58:00.014060] Epoch: [15]  [180/345]  eta: 0:02:03  lr: 0.000097  loss: 0.8079 (0.8124)  time: 0.7511  data: 0.0001  max mem: 14938
[18:58:15.042541] Epoch: [15]  [200/345]  eta: 0:01:48  lr: 0.000097  loss: 0.8061 (0.8117)  time: 0.7514  data: 0.0001  max mem: 14938
[18:58:30.058905] Epoch: [15]  [220/345]  eta: 0:01:33  lr: 0.000098  loss: 0.7955 (0.8102)  time: 0.7508  data: 0.0001  max mem: 14938
[18:58:45.073616] Epoch: [15]  [240/345]  eta: 0:01:18  lr: 0.000098  loss: 0.8069 (0.8102)  time: 0.7507  data: 0.0001  max mem: 14938
[18:59:00.079786] Epoch: [15]  [260/345]  eta: 0:01:03  lr: 0.000098  loss: 0.7960 (0.8099)  time: 0.7503  data: 0.0001  max mem: 14938
[18:59:15.078427] Epoch: [15]  [280/345]  eta: 0:00:48  lr: 0.000099  loss: 0.8075 (0.8100)  time: 0.7499  data: 0.0001  max mem: 14938
[18:59:30.083883] Epoch: [15]  [300/345]  eta: 0:00:33  lr: 0.000099  loss: 0.8025 (0.8099)  time: 0.7502  data: 0.0001  max mem: 14938
[18:59:45.179496] Epoch: [15]  [320/345]  eta: 0:00:18  lr: 0.000100  loss: 0.7978 (0.8099)  time: 0.7547  data: 0.0001  max mem: 14938
[19:00:00.191587] Epoch: [15]  [340/345]  eta: 0:00:03  lr: 0.000100  loss: 0.7979 (0.8093)  time: 0.7506  data: 0.0001  max mem: 14938
[19:00:03.195807] Epoch: [15]  [344/345]  eta: 0:00:00  lr: 0.000100  loss: 0.8042 (0.8092)  time: 0.7506  data: 0.0001  max mem: 14938
[19:00:03.258437] Epoch: [15] Total time: 0:04:19 (0.7509 s / it)
[19:00:03.258892] Averaged stats: lr: 0.000100  loss: 0.8042 (0.8092)
[19:00:03.597481] Test:  [  0/345]  eta: 0:01:55  loss: 0.7701 (0.7701)  time: 0.3343  data: 0.1528  max mem: 14938
[19:00:05.434183] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7708 (0.7703)  time: 0.1973  data: 0.0140  max mem: 14938
[19:00:07.274279] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7604 (0.7646)  time: 0.1838  data: 0.0001  max mem: 14938
[19:00:09.116614] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7609 (0.7654)  time: 0.1841  data: 0.0001  max mem: 14938
[19:00:10.962046] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7619 (0.7643)  time: 0.1843  data: 0.0001  max mem: 14938
[19:00:12.812336] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7682 (0.7666)  time: 0.1847  data: 0.0001  max mem: 14938
[19:00:14.667420] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7691 (0.7669)  time: 0.1852  data: 0.0001  max mem: 14938
[19:00:16.526584] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7653 (0.7670)  time: 0.1857  data: 0.0001  max mem: 14938
[19:00:18.387373] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7564 (0.7657)  time: 0.1859  data: 0.0001  max mem: 14938
[19:00:20.253284] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7553 (0.7651)  time: 0.1863  data: 0.0001  max mem: 14938
[19:00:22.121557] Test:  [100/345]  eta: 0:00:45  loss: 0.7663 (0.7657)  time: 0.1867  data: 0.0001  max mem: 14938
[19:00:23.993854] Test:  [110/345]  eta: 0:00:43  loss: 0.7687 (0.7661)  time: 0.1870  data: 0.0001  max mem: 14938
[19:00:25.871143] Test:  [120/345]  eta: 0:00:42  loss: 0.7722 (0.7658)  time: 0.1874  data: 0.0001  max mem: 14938
[19:00:27.749201] Test:  [130/345]  eta: 0:00:40  loss: 0.7573 (0.7655)  time: 0.1877  data: 0.0001  max mem: 14938
[19:00:29.630182] Test:  [140/345]  eta: 0:00:38  loss: 0.7590 (0.7658)  time: 0.1879  data: 0.0001  max mem: 14938
[19:00:31.515736] Test:  [150/345]  eta: 0:00:36  loss: 0.7677 (0.7656)  time: 0.1883  data: 0.0001  max mem: 14938
[19:00:33.403257] Test:  [160/345]  eta: 0:00:34  loss: 0.7693 (0.7664)  time: 0.1886  data: 0.0001  max mem: 14938
[19:00:35.294942] Test:  [170/345]  eta: 0:00:32  loss: 0.7729 (0.7663)  time: 0.1889  data: 0.0001  max mem: 14938
[19:00:37.189890] Test:  [180/345]  eta: 0:00:30  loss: 0.7715 (0.7666)  time: 0.1893  data: 0.0001  max mem: 14938
[19:00:39.089453] Test:  [190/345]  eta: 0:00:29  loss: 0.7630 (0.7664)  time: 0.1897  data: 0.0001  max mem: 14938
[19:00:40.990549] Test:  [200/345]  eta: 0:00:27  loss: 0.7628 (0.7664)  time: 0.1900  data: 0.0001  max mem: 14938
[19:00:42.897318] Test:  [210/345]  eta: 0:00:25  loss: 0.7604 (0.7663)  time: 0.1903  data: 0.0001  max mem: 14938
[19:00:44.805147] Test:  [220/345]  eta: 0:00:23  loss: 0.7689 (0.7664)  time: 0.1907  data: 0.0001  max mem: 14938
[19:00:46.718787] Test:  [230/345]  eta: 0:00:21  loss: 0.7672 (0.7665)  time: 0.1910  data: 0.0001  max mem: 14938
[19:00:48.635395] Test:  [240/345]  eta: 0:00:19  loss: 0.7680 (0.7669)  time: 0.1915  data: 0.0001  max mem: 14938
[19:00:50.556308] Test:  [250/345]  eta: 0:00:17  loss: 0.7717 (0.7671)  time: 0.1918  data: 0.0001  max mem: 14938
[19:00:52.479705] Test:  [260/345]  eta: 0:00:16  loss: 0.7579 (0.7669)  time: 0.1922  data: 0.0001  max mem: 14938
[19:00:54.408299] Test:  [270/345]  eta: 0:00:14  loss: 0.7579 (0.7668)  time: 0.1925  data: 0.0001  max mem: 14938
[19:00:56.338800] Test:  [280/345]  eta: 0:00:12  loss: 0.7738 (0.7673)  time: 0.1929  data: 0.0001  max mem: 14938
[19:00:58.273971] Test:  [290/345]  eta: 0:00:10  loss: 0.7770 (0.7676)  time: 0.1932  data: 0.0001  max mem: 14938
[19:01:00.212749] Test:  [300/345]  eta: 0:00:08  loss: 0.7673 (0.7675)  time: 0.1936  data: 0.0001  max mem: 14938
[19:01:02.153805] Test:  [310/345]  eta: 0:00:06  loss: 0.7589 (0.7673)  time: 0.1939  data: 0.0001  max mem: 14938
[19:01:04.096820] Test:  [320/345]  eta: 0:00:04  loss: 0.7611 (0.7672)  time: 0.1942  data: 0.0001  max mem: 14938
[19:01:06.045389] Test:  [330/345]  eta: 0:00:02  loss: 0.7614 (0.7671)  time: 0.1945  data: 0.0001  max mem: 14938
[19:01:07.996406] Test:  [340/345]  eta: 0:00:00  loss: 0.7621 (0.7672)  time: 0.1949  data: 0.0001  max mem: 14938
[19:01:08.778668] Test:  [344/345]  eta: 0:00:00  loss: 0.7614 (0.7670)  time: 0.1951  data: 0.0001  max mem: 14938
[19:01:08.836709] Test: Total time: 0:01:05 (0.1901 s / it)
[19:01:19.188699] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8716 (0.8716)  time: 0.3159  data: 0.1362  max mem: 14938
[19:01:21.004712] Test:  [10/57]  eta: 0:00:09  loss: 0.8727 (0.8770)  time: 0.1937  data: 0.0124  max mem: 14938
[19:01:22.826390] Test:  [20/57]  eta: 0:00:06  loss: 0.8727 (0.8654)  time: 0.1818  data: 0.0001  max mem: 14938
[19:01:24.650639] Test:  [30/57]  eta: 0:00:05  loss: 0.7727 (0.8297)  time: 0.1822  data: 0.0001  max mem: 14938
[19:01:26.482773] Test:  [40/57]  eta: 0:00:03  loss: 0.7582 (0.8110)  time: 0.1828  data: 0.0001  max mem: 14938
[19:01:28.319191] Test:  [50/57]  eta: 0:00:01  loss: 0.7582 (0.8056)  time: 0.1834  data: 0.0001  max mem: 14938
[19:01:29.310850] Test:  [56/57]  eta: 0:00:00  loss: 0.7659 (0.8106)  time: 0.1780  data: 0.0001  max mem: 14938
[19:01:29.368773] Test: Total time: 0:00:10 (0.1841 s / it)
[19:01:31.072967] Dice score of the network on the train images: 0.783006, val images: 0.810494
[19:01:31.073188] saving best_prec_model_0 @ epoch 15
[19:01:32.189595] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:01:33.077329] Epoch: [16]  [  0/345]  eta: 0:05:05  lr: 0.000100  loss: 0.7698 (0.7698)  time: 0.8866  data: 0.1455  max mem: 14938
[19:01:47.971762] Epoch: [16]  [ 20/345]  eta: 0:04:04  lr: 0.000100  loss: 0.7852 (0.7920)  time: 0.7447  data: 0.0001  max mem: 14938
[19:02:02.906302] Epoch: [16]  [ 40/345]  eta: 0:03:48  lr: 0.000101  loss: 0.7999 (0.7966)  time: 0.7467  data: 0.0001  max mem: 14938
[19:02:17.871520] Epoch: [16]  [ 60/345]  eta: 0:03:33  lr: 0.000101  loss: 0.7972 (0.7983)  time: 0.7482  data: 0.0001  max mem: 14938
[19:02:32.867756] Epoch: [16]  [ 80/345]  eta: 0:03:18  lr: 0.000101  loss: 0.8025 (0.7982)  time: 0.7498  data: 0.0001  max mem: 14938
[19:02:47.873588] Epoch: [16]  [100/345]  eta: 0:03:03  lr: 0.000102  loss: 0.7873 (0.7967)  time: 0.7503  data: 0.0001  max mem: 14938
[19:03:02.916743] Epoch: [16]  [120/345]  eta: 0:02:48  lr: 0.000102  loss: 0.7811 (0.7958)  time: 0.7521  data: 0.0001  max mem: 14938
[19:03:17.966991] Epoch: [16]  [140/345]  eta: 0:02:33  lr: 0.000103  loss: 0.7811 (0.7943)  time: 0.7525  data: 0.0001  max mem: 14938
[19:03:33.016869] Epoch: [16]  [160/345]  eta: 0:02:18  lr: 0.000103  loss: 0.7912 (0.7939)  time: 0.7524  data: 0.0001  max mem: 14938
[19:03:48.183829] Epoch: [16]  [180/345]  eta: 0:02:03  lr: 0.000103  loss: 0.7964 (0.7944)  time: 0.7583  data: 0.0001  max mem: 14938
[19:04:03.214029] Epoch: [16]  [200/345]  eta: 0:01:48  lr: 0.000104  loss: 0.8128 (0.7964)  time: 0.7515  data: 0.0001  max mem: 14938
[19:04:18.242893] Epoch: [16]  [220/345]  eta: 0:01:33  lr: 0.000104  loss: 0.8081 (0.7971)  time: 0.7514  data: 0.0001  max mem: 14938
[19:04:33.270121] Epoch: [16]  [240/345]  eta: 0:01:18  lr: 0.000104  loss: 0.8027 (0.7972)  time: 0.7513  data: 0.0001  max mem: 14938
[19:04:48.289356] Epoch: [16]  [260/345]  eta: 0:01:03  lr: 0.000105  loss: 0.7916 (0.7968)  time: 0.7509  data: 0.0001  max mem: 14938
[19:05:03.305507] Epoch: [16]  [280/345]  eta: 0:00:48  lr: 0.000105  loss: 0.7880 (0.7962)  time: 0.7508  data: 0.0001  max mem: 14938
[19:05:18.313944] Epoch: [16]  [300/345]  eta: 0:00:33  lr: 0.000105  loss: 0.7854 (0.7961)  time: 0.7504  data: 0.0001  max mem: 14938
[19:05:33.320550] Epoch: [16]  [320/345]  eta: 0:00:18  lr: 0.000106  loss: 0.7875 (0.7957)  time: 0.7503  data: 0.0001  max mem: 14938
[19:05:48.333221] Epoch: [16]  [340/345]  eta: 0:00:03  lr: 0.000106  loss: 0.8044 (0.7963)  time: 0.7506  data: 0.0001  max mem: 14938
[19:05:51.337188] Epoch: [16]  [344/345]  eta: 0:00:00  lr: 0.000106  loss: 0.8002 (0.7964)  time: 0.7507  data: 0.0001  max mem: 14938
[19:05:51.402035] Epoch: [16] Total time: 0:04:19 (0.7513 s / it)
[19:05:51.402340] Averaged stats: lr: 0.000106  loss: 0.8002 (0.7964)
[19:05:51.740681] Test:  [  0/345]  eta: 0:01:55  loss: 0.7747 (0.7747)  time: 0.3341  data: 0.1527  max mem: 14938
[19:05:53.577159] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7691 (0.7723)  time: 0.1973  data: 0.0139  max mem: 14938
[19:05:55.416590] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7692 (0.7745)  time: 0.1837  data: 0.0001  max mem: 14938
[19:05:57.260440] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7747 (0.7731)  time: 0.1841  data: 0.0001  max mem: 14938
[19:05:59.107170] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7720 (0.7742)  time: 0.1845  data: 0.0001  max mem: 14938
[19:06:00.957633] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7730 (0.7739)  time: 0.1848  data: 0.0001  max mem: 14938
[19:06:02.811870] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7719 (0.7736)  time: 0.1852  data: 0.0001  max mem: 14938
[19:06:04.668922] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7642 (0.7720)  time: 0.1855  data: 0.0001  max mem: 14938
[19:06:06.529241] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7694 (0.7725)  time: 0.1858  data: 0.0001  max mem: 14938
[19:06:08.396320] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7658 (0.7715)  time: 0.1863  data: 0.0001  max mem: 14938
[19:06:10.265164] Test:  [100/345]  eta: 0:00:45  loss: 0.7605 (0.7708)  time: 0.1867  data: 0.0001  max mem: 14938
[19:06:12.137611] Test:  [110/345]  eta: 0:00:43  loss: 0.7629 (0.7708)  time: 0.1870  data: 0.0001  max mem: 14938
[19:06:14.013638] Test:  [120/345]  eta: 0:00:42  loss: 0.7721 (0.7706)  time: 0.1874  data: 0.0001  max mem: 14938
[19:06:15.892546] Test:  [130/345]  eta: 0:00:40  loss: 0.7699 (0.7702)  time: 0.1877  data: 0.0001  max mem: 14938
[19:06:17.774519] Test:  [140/345]  eta: 0:00:38  loss: 0.7698 (0.7707)  time: 0.1880  data: 0.0001  max mem: 14938
[19:06:19.660097] Test:  [150/345]  eta: 0:00:36  loss: 0.7871 (0.7719)  time: 0.1883  data: 0.0001  max mem: 14938
[19:06:21.548038] Test:  [160/345]  eta: 0:00:34  loss: 0.7879 (0.7723)  time: 0.1886  data: 0.0001  max mem: 14938
[19:06:23.440824] Test:  [170/345]  eta: 0:00:32  loss: 0.7672 (0.7720)  time: 0.1890  data: 0.0001  max mem: 14938
[19:06:25.336231] Test:  [180/345]  eta: 0:00:30  loss: 0.7672 (0.7718)  time: 0.1894  data: 0.0001  max mem: 14938
[19:06:27.237038] Test:  [190/345]  eta: 0:00:29  loss: 0.7611 (0.7711)  time: 0.1898  data: 0.0001  max mem: 14938
[19:06:29.139884] Test:  [200/345]  eta: 0:00:27  loss: 0.7571 (0.7705)  time: 0.1901  data: 0.0001  max mem: 14938
[19:06:31.046296] Test:  [210/345]  eta: 0:00:25  loss: 0.7599 (0.7705)  time: 0.1904  data: 0.0001  max mem: 14938
[19:06:32.957909] Test:  [220/345]  eta: 0:00:23  loss: 0.7699 (0.7707)  time: 0.1909  data: 0.0001  max mem: 14938
[19:06:34.871536] Test:  [230/345]  eta: 0:00:21  loss: 0.7661 (0.7707)  time: 0.1912  data: 0.0001  max mem: 14938
[19:06:36.789626] Test:  [240/345]  eta: 0:00:19  loss: 0.7648 (0.7705)  time: 0.1915  data: 0.0001  max mem: 14938
[19:06:38.710637] Test:  [250/345]  eta: 0:00:17  loss: 0.7709 (0.7706)  time: 0.1919  data: 0.0001  max mem: 14938
[19:06:40.634814] Test:  [260/345]  eta: 0:00:16  loss: 0.7708 (0.7705)  time: 0.1922  data: 0.0001  max mem: 14938
[19:06:42.563381] Test:  [270/345]  eta: 0:00:14  loss: 0.7621 (0.7702)  time: 0.1926  data: 0.0001  max mem: 14938
[19:06:44.496125] Test:  [280/345]  eta: 0:00:12  loss: 0.7611 (0.7699)  time: 0.1930  data: 0.0001  max mem: 14938
[19:06:46.430148] Test:  [290/345]  eta: 0:00:10  loss: 0.7717 (0.7701)  time: 0.1933  data: 0.0001  max mem: 14938
[19:06:48.369155] Test:  [300/345]  eta: 0:00:08  loss: 0.7728 (0.7703)  time: 0.1936  data: 0.0001  max mem: 14938
[19:06:50.311024] Test:  [310/345]  eta: 0:00:06  loss: 0.7708 (0.7705)  time: 0.1940  data: 0.0001  max mem: 14938
[19:06:52.254840] Test:  [320/345]  eta: 0:00:04  loss: 0.7686 (0.7706)  time: 0.1942  data: 0.0001  max mem: 14938
[19:06:54.202125] Test:  [330/345]  eta: 0:00:02  loss: 0.7692 (0.7707)  time: 0.1945  data: 0.0001  max mem: 14938
[19:06:56.150844] Test:  [340/345]  eta: 0:00:00  loss: 0.7738 (0.7706)  time: 0.1947  data: 0.0001  max mem: 14938
[19:06:56.932480] Test:  [344/345]  eta: 0:00:00  loss: 0.7706 (0.7707)  time: 0.1949  data: 0.0001  max mem: 14938
[19:06:56.991822] Test: Total time: 0:01:05 (0.1901 s / it)
[19:07:07.434921] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8427 (0.8427)  time: 0.3218  data: 0.1417  max mem: 14938
[19:07:09.249669] Test:  [10/57]  eta: 0:00:09  loss: 0.8828 (0.8870)  time: 0.1942  data: 0.0129  max mem: 14938
[19:07:11.071110] Test:  [20/57]  eta: 0:00:06  loss: 0.8828 (0.8771)  time: 0.1818  data: 0.0001  max mem: 14938
[19:07:12.898596] Test:  [30/57]  eta: 0:00:05  loss: 0.7774 (0.8408)  time: 0.1824  data: 0.0001  max mem: 14938
[19:07:14.732544] Test:  [40/57]  eta: 0:00:03  loss: 0.7643 (0.8214)  time: 0.1830  data: 0.0001  max mem: 14938
[19:07:16.570566] Test:  [50/57]  eta: 0:00:01  loss: 0.7593 (0.8142)  time: 0.1835  data: 0.0001  max mem: 14938
[19:07:17.561055] Test:  [56/57]  eta: 0:00:00  loss: 0.7784 (0.8199)  time: 0.1781  data: 0.0001  max mem: 14938
[19:07:17.617017] Test: Total time: 0:00:10 (0.1843 s / it)
[19:07:19.342403] Dice score of the network on the train images: 0.777413, val images: 0.807487
[19:07:19.346706] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:07:20.231227] Epoch: [17]  [  0/345]  eta: 0:05:04  lr: 0.000106  loss: 0.7751 (0.7751)  time: 0.8835  data: 0.1418  max mem: 14938

[19:07:35.133290] Epoch: [17]  [ 20/345]  eta: 0:04:04  lr: 0.000107  loss: 0.7978 (0.8000)  time: 0.7451  data: 0.0001  max mem: 14938
[19:07:50.073232] Epoch: [17]  [ 40/345]  eta: 0:03:48  lr: 0.000107  loss: 0.8186 (0.8107)  time: 0.7469  data: 0.0001  max mem: 14938
[19:08:05.038820] Epoch: [17]  [ 60/345]  eta: 0:03:33  lr: 0.000107  loss: 0.7925 (0.8068)  time: 0.7482  data: 0.0001  max mem: 14938
[19:08:20.026185] Epoch: [17]  [ 80/345]  eta: 0:03:18  lr: 0.000108  loss: 0.7948 (0.8046)  time: 0.7493  data: 0.0001  max mem: 14938
[19:08:35.047241] Epoch: [17]  [100/345]  eta: 0:03:03  lr: 0.000108  loss: 0.7921 (0.8026)  time: 0.7510  data: 0.0001  max mem: 14938
[19:08:50.100685] Epoch: [17]  [120/345]  eta: 0:02:48  lr: 0.000108  loss: 0.8047 (0.8033)  time: 0.7526  data: 0.0001  max mem: 14938
[19:09:05.157487] Epoch: [17]  [140/345]  eta: 0:02:33  lr: 0.000109  loss: 0.7938 (0.8021)  time: 0.7528  data: 0.0001  max mem: 14938
[19:09:20.339147] Epoch: [17]  [160/345]  eta: 0:02:19  lr: 0.000109  loss: 0.7865 (0.7998)  time: 0.7590  data: 0.0001  max mem: 14938
[19:09:35.377160] Epoch: [17]  [180/345]  eta: 0:02:03  lr: 0.000110  loss: 0.7884 (0.7988)  time: 0.7519  data: 0.0001  max mem: 14938
[19:09:50.417042] Epoch: [17]  [200/345]  eta: 0:01:48  lr: 0.000110  loss: 0.7857 (0.7975)  time: 0.7520  data: 0.0001  max mem: 14938
[19:10:05.457977] Epoch: [17]  [220/345]  eta: 0:01:33  lr: 0.000110  loss: 0.7808 (0.7964)  time: 0.7520  data: 0.0001  max mem: 14938
[19:10:20.486234] Epoch: [17]  [240/345]  eta: 0:01:18  lr: 0.000111  loss: 0.7822 (0.7952)  time: 0.7514  data: 0.0001  max mem: 14938
[19:10:35.503437] Epoch: [17]  [260/345]  eta: 0:01:03  lr: 0.000111  loss: 0.8069 (0.7963)  time: 0.7508  data: 0.0001  max mem: 14938
[19:10:50.524423] Epoch: [17]  [280/345]  eta: 0:00:48  lr: 0.000111  loss: 0.7970 (0.7968)  time: 0.7510  data: 0.0001  max mem: 14938
[19:11:05.534820] Epoch: [17]  [300/345]  eta: 0:00:33  lr: 0.000112  loss: 0.7977 (0.7969)  time: 0.7505  data: 0.0001  max mem: 14938
[19:11:20.546360] Epoch: [17]  [320/345]  eta: 0:00:18  lr: 0.000112  loss: 0.7925 (0.7969)  time: 0.7505  data: 0.0001  max mem: 14938
[19:11:35.546692] Epoch: [17]  [340/345]  eta: 0:00:03  lr: 0.000112  loss: 0.8002 (0.7970)  time: 0.7500  data: 0.0001  max mem: 14938
[19:11:38.547873] Epoch: [17]  [344/345]  eta: 0:00:00  lr: 0.000112  loss: 0.7941 (0.7970)  time: 0.7500  data: 0.0001  max mem: 14938
[19:11:38.611428] Epoch: [17] Total time: 0:04:19 (0.7515 s / it)
[19:11:38.611841] Averaged stats: lr: 0.000112  loss: 0.7941 (0.7970)
[19:11:38.952570] Test:  [  0/345]  eta: 0:01:55  loss: 0.7951 (0.7951)  time: 0.3362  data: 0.1540  max mem: 14938
[19:11:40.790436] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7812 (0.7811)  time: 0.1975  data: 0.0141  max mem: 14938
[19:11:42.628856] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7699 (0.7716)  time: 0.1837  data: 0.0001  max mem: 14938
[19:11:44.472247] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7699 (0.7770)  time: 0.1840  data: 0.0001  max mem: 14938
[19:11:46.320345] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7819 (0.7772)  time: 0.1845  data: 0.0001  max mem: 14938
[19:11:48.171126] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7890 (0.7810)  time: 0.1849  data: 0.0001  max mem: 14938
[19:11:50.024517] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7826 (0.7795)  time: 0.1852  data: 0.0001  max mem: 14938
[19:11:51.882338] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7720 (0.7787)  time: 0.1855  data: 0.0001  max mem: 14938
[19:11:53.743339] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7723 (0.7779)  time: 0.1859  data: 0.0001  max mem: 14938
[19:11:55.608483] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7746 (0.7781)  time: 0.1862  data: 0.0001  max mem: 14938
[19:11:57.476131] Test:  [100/345]  eta: 0:00:45  loss: 0.7717 (0.7780)  time: 0.1866  data: 0.0001  max mem: 14938
[19:11:59.349318] Test:  [110/345]  eta: 0:00:43  loss: 0.7714 (0.7774)  time: 0.1870  data: 0.0001  max mem: 14938
[19:12:01.224437] Test:  [120/345]  eta: 0:00:42  loss: 0.7729 (0.7774)  time: 0.1874  data: 0.0001  max mem: 14938
[19:12:03.103124] Test:  [130/345]  eta: 0:00:40  loss: 0.7806 (0.7780)  time: 0.1876  data: 0.0001  max mem: 14938
[19:12:04.984526] Test:  [140/345]  eta: 0:00:38  loss: 0.7801 (0.7780)  time: 0.1880  data: 0.0001  max mem: 14938
[19:12:06.869296] Test:  [150/345]  eta: 0:00:36  loss: 0.7801 (0.7781)  time: 0.1883  data: 0.0001  max mem: 14938
[19:12:08.755235] Test:  [160/345]  eta: 0:00:34  loss: 0.7801 (0.7780)  time: 0.1885  data: 0.0001  max mem: 14938
[19:12:10.646289] Test:  [170/345]  eta: 0:00:32  loss: 0.7736 (0.7779)  time: 0.1888  data: 0.0001  max mem: 14938
[19:12:12.542348] Test:  [180/345]  eta: 0:00:30  loss: 0.7760 (0.7785)  time: 0.1893  data: 0.0001  max mem: 14938
[19:12:14.443856] Test:  [190/345]  eta: 0:00:29  loss: 0.7803 (0.7788)  time: 0.1898  data: 0.0001  max mem: 14938
[19:12:16.345791] Test:  [200/345]  eta: 0:00:27  loss: 0.7839 (0.7789)  time: 0.1901  data: 0.0001  max mem: 14938
[19:12:18.251143] Test:  [210/345]  eta: 0:00:25  loss: 0.7851 (0.7794)  time: 0.1903  data: 0.0001  max mem: 14938
[19:12:20.162090] Test:  [220/345]  eta: 0:00:23  loss: 0.7764 (0.7792)  time: 0.1908  data: 0.0001  max mem: 14938
[19:12:22.076164] Test:  [230/345]  eta: 0:00:21  loss: 0.7739 (0.7789)  time: 0.1912  data: 0.0001  max mem: 14938
[19:12:23.992420] Test:  [240/345]  eta: 0:00:19  loss: 0.7754 (0.7789)  time: 0.1915  data: 0.0001  max mem: 14938
[19:12:25.912558] Test:  [250/345]  eta: 0:00:17  loss: 0.7808 (0.7790)  time: 0.1918  data: 0.0001  max mem: 14938
[19:12:27.837752] Test:  [260/345]  eta: 0:00:16  loss: 0.7813 (0.7790)  time: 0.1922  data: 0.0001  max mem: 14938
[19:12:29.764992] Test:  [270/345]  eta: 0:00:14  loss: 0.7781 (0.7794)  time: 0.1926  data: 0.0001  max mem: 14938
[19:12:31.696311] Test:  [280/345]  eta: 0:00:12  loss: 0.7735 (0.7795)  time: 0.1929  data: 0.0001  max mem: 14938
[19:12:33.630052] Test:  [290/345]  eta: 0:00:10  loss: 0.7678 (0.7791)  time: 0.1932  data: 0.0001  max mem: 14938
[19:12:35.568370] Test:  [300/345]  eta: 0:00:08  loss: 0.7778 (0.7795)  time: 0.1936  data: 0.0001  max mem: 14938
[19:12:37.508858] Test:  [310/345]  eta: 0:00:06  loss: 0.7867 (0.7798)  time: 0.1939  data: 0.0001  max mem: 14938
[19:12:39.453751] Test:  [320/345]  eta: 0:00:04  loss: 0.7772 (0.7795)  time: 0.1942  data: 0.0001  max mem: 14938
[19:12:41.399736] Test:  [330/345]  eta: 0:00:02  loss: 0.7654 (0.7793)  time: 0.1945  data: 0.0001  max mem: 14938
[19:12:43.349810] Test:  [340/345]  eta: 0:00:00  loss: 0.7697 (0.7791)  time: 0.1948  data: 0.0001  max mem: 14938
[19:12:44.130878] Test:  [344/345]  eta: 0:00:00  loss: 0.7759 (0.7791)  time: 0.1949  data: 0.0001  max mem: 14938
[19:12:44.190424] Test: Total time: 0:01:05 (0.1901 s / it)
[19:12:54.555022] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8726 (0.8726)  time: 0.3232  data: 0.1437  max mem: 14938
[19:12:56.371588] Test:  [10/57]  eta: 0:00:09  loss: 0.8726 (0.8806)  time: 0.1945  data: 0.0131  max mem: 14938
[19:12:58.194979] Test:  [20/57]  eta: 0:00:06  loss: 0.8594 (0.8719)  time: 0.1819  data: 0.0001  max mem: 14938
[19:13:00.020608] Test:  [30/57]  eta: 0:00:05  loss: 0.7771 (0.8352)  time: 0.1824  data: 0.0001  max mem: 14938
[19:13:01.852036] Test:  [40/57]  eta: 0:00:03  loss: 0.7503 (0.8146)  time: 0.1828  data: 0.0001  max mem: 14938
[19:13:03.690767] Test:  [50/57]  eta: 0:00:01  loss: 0.7356 (0.8067)  time: 0.1835  data: 0.0001  max mem: 14938
[19:13:04.681506] Test:  [56/57]  eta: 0:00:00  loss: 0.7851 (0.8128)  time: 0.1780  data: 0.0001  max mem: 14938
[19:13:04.741591] Test: Total time: 0:00:10 (0.1844 s / it)
[19:13:06.445035] Dice score of the network on the train images: 0.743738, val images: 0.805972
[19:13:06.445246] saving best_rec_model_0 @ epoch 17
[19:13:07.624306] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:13:08.508176] Epoch: [18]  [  0/345]  eta: 0:05:04  lr: 0.000113  loss: 0.7980 (0.7980)  time: 0.8827  data: 0.1392  max mem: 14938
[19:13:23.391309] Epoch: [18]  [ 20/345]  eta: 0:04:03  lr: 0.000113  loss: 0.7818 (0.7916)  time: 0.7441  data: 0.0001  max mem: 14938
[19:13:38.331900] Epoch: [18]  [ 40/345]  eta: 0:03:48  lr: 0.000113  loss: 0.7902 (0.7931)  time: 0.7470  data: 0.0001  max mem: 14938
[19:13:53.305789] Epoch: [18]  [ 60/345]  eta: 0:03:33  lr: 0.000114  loss: 0.7936 (0.7935)  time: 0.7486  data: 0.0001  max mem: 14938
[19:14:08.296836] Epoch: [18]  [ 80/345]  eta: 0:03:18  lr: 0.000114  loss: 0.7800 (0.7919)  time: 0.7495  data: 0.0001  max mem: 14938
[19:14:23.301976] Epoch: [18]  [100/345]  eta: 0:03:03  lr: 0.000114  loss: 0.7882 (0.7916)  time: 0.7502  data: 0.0001  max mem: 14938
[19:14:38.324137] Epoch: [18]  [120/345]  eta: 0:02:48  lr: 0.000115  loss: 0.7985 (0.7929)  time: 0.7511  data: 0.0001  max mem: 14938
[19:14:53.372104] Epoch: [18]  [140/345]  eta: 0:02:33  lr: 0.000115  loss: 0.8100 (0.7948)  time: 0.7524  data: 0.0001  max mem: 14938
[19:15:08.409303] Epoch: [18]  [160/345]  eta: 0:02:18  lr: 0.000115  loss: 0.7993 (0.7958)  time: 0.7518  data: 0.0001  max mem: 14938
[19:15:23.448198] Epoch: [18]  [180/345]  eta: 0:02:03  lr: 0.000116  loss: 0.8033 (0.7963)  time: 0.7519  data: 0.0001  max mem: 14938
[19:15:38.478103] Epoch: [18]  [200/345]  eta: 0:01:48  lr: 0.000116  loss: 0.8000 (0.7969)  time: 0.7515  data: 0.0001  max mem: 14938
[19:15:53.499788] Epoch: [18]  [220/345]  eta: 0:01:33  lr: 0.000116  loss: 0.8038 (0.7971)  time: 0.7510  data: 0.0001  max mem: 14938
[19:16:08.513463] Epoch: [18]  [240/345]  eta: 0:01:18  lr: 0.000117  loss: 0.7942 (0.7967)  time: 0.7506  data: 0.0001  max mem: 14938
[19:16:23.516693] Epoch: [18]  [260/345]  eta: 0:01:03  lr: 0.000117  loss: 0.7836 (0.7960)  time: 0.7501  data: 0.0001  max mem: 14938
[19:16:38.514383] Epoch: [18]  [280/345]  eta: 0:00:48  lr: 0.000118  loss: 0.7767 (0.7950)  time: 0.7498  data: 0.0001  max mem: 14938
[19:16:53.510095] Epoch: [18]  [300/345]  eta: 0:00:33  lr: 0.000118  loss: 0.7908 (0.7944)  time: 0.7497  data: 0.0001  max mem: 14938
[19:17:08.503462] Epoch: [18]  [320/345]  eta: 0:00:18  lr: 0.000118  loss: 0.7908 (0.7945)  time: 0.7496  data: 0.0001  max mem: 14938
[19:17:23.491697] Epoch: [18]  [340/345]  eta: 0:00:03  lr: 0.000119  loss: 0.8051 (0.7950)  time: 0.7494  data: 0.0001  max mem: 14938
[19:17:26.491842] Epoch: [18]  [344/345]  eta: 0:00:00  lr: 0.000119  loss: 0.8127 (0.7954)  time: 0.7495  data: 0.0001  max mem: 14938
[19:17:26.557984] Epoch: [18] Total time: 0:04:18 (0.7505 s / it)
[19:17:26.558338] Averaged stats: lr: 0.000119  loss: 0.8127 (0.7954)
[19:17:26.901174] Test:  [  0/345]  eta: 0:01:56  loss: 0.7669 (0.7669)  time: 0.3377  data: 0.1571  max mem: 14938
[19:17:28.738816] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7673 (0.7686)  time: 0.1977  data: 0.0143  max mem: 14938
[19:17:30.578757] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7784 (0.7820)  time: 0.1838  data: 0.0001  max mem: 14938
[19:17:32.422090] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7804 (0.7809)  time: 0.1841  data: 0.0001  max mem: 14938
[19:17:34.269003] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7717 (0.7786)  time: 0.1845  data: 0.0001  max mem: 14938
[19:17:36.120469] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7776 (0.7792)  time: 0.1849  data: 0.0001  max mem: 14938
[19:17:37.975804] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7819 (0.7790)  time: 0.1853  data: 0.0001  max mem: 14938
[19:17:39.832625] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7672 (0.7772)  time: 0.1856  data: 0.0001  max mem: 14938
[19:17:41.692286] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7667 (0.7769)  time: 0.1858  data: 0.0001  max mem: 14938
[19:17:43.556408] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7713 (0.7766)  time: 0.1861  data: 0.0001  max mem: 14938
[19:17:45.424278] Test:  [100/345]  eta: 0:00:45  loss: 0.7684 (0.7757)  time: 0.1865  data: 0.0001  max mem: 14938
[19:17:47.295878] Test:  [110/345]  eta: 0:00:43  loss: 0.7694 (0.7760)  time: 0.1869  data: 0.0001  max mem: 14938
[19:17:49.170032] Test:  [120/345]  eta: 0:00:42  loss: 0.7739 (0.7759)  time: 0.1872  data: 0.0001  max mem: 14938
[19:17:51.047885] Test:  [130/345]  eta: 0:00:40  loss: 0.7739 (0.7758)  time: 0.1876  data: 0.0001  max mem: 14938
[19:17:52.930037] Test:  [140/345]  eta: 0:00:38  loss: 0.7681 (0.7756)  time: 0.1879  data: 0.0001  max mem: 14938
[19:17:54.815429] Test:  [150/345]  eta: 0:00:36  loss: 0.7695 (0.7756)  time: 0.1883  data: 0.0001  max mem: 14938
[19:17:56.703233] Test:  [160/345]  eta: 0:00:34  loss: 0.7759 (0.7765)  time: 0.1886  data: 0.0001  max mem: 14938
[19:17:58.595526] Test:  [170/345]  eta: 0:00:32  loss: 0.7915 (0.7769)  time: 0.1890  data: 0.0001  max mem: 14938
[19:18:00.490993] Test:  [180/345]  eta: 0:00:30  loss: 0.7844 (0.7774)  time: 0.1893  data: 0.0001  max mem: 14938
[19:18:02.390560] Test:  [190/345]  eta: 0:00:29  loss: 0.7843 (0.7776)  time: 0.1897  data: 0.0001  max mem: 14938
[19:18:04.291542] Test:  [200/345]  eta: 0:00:27  loss: 0.7769 (0.7779)  time: 0.1900  data: 0.0001  max mem: 14938
[19:18:06.196829] Test:  [210/345]  eta: 0:00:25  loss: 0.7731 (0.7776)  time: 0.1903  data: 0.0001  max mem: 14938
[19:18:08.105759] Test:  [220/345]  eta: 0:00:23  loss: 0.7664 (0.7772)  time: 0.1907  data: 0.0001  max mem: 14938
[19:18:10.020534] Test:  [230/345]  eta: 0:00:21  loss: 0.7733 (0.7773)  time: 0.1911  data: 0.0001  max mem: 14938
[19:18:11.937431] Test:  [240/345]  eta: 0:00:19  loss: 0.7752 (0.7774)  time: 0.1915  data: 0.0001  max mem: 14938
[19:18:13.859047] Test:  [250/345]  eta: 0:00:17  loss: 0.7714 (0.7769)  time: 0.1919  data: 0.0001  max mem: 14938
[19:18:15.782516] Test:  [260/345]  eta: 0:00:16  loss: 0.7714 (0.7776)  time: 0.1922  data: 0.0001  max mem: 14938
[19:18:17.710995] Test:  [270/345]  eta: 0:00:14  loss: 0.7911 (0.7778)  time: 0.1925  data: 0.0001  max mem: 14938
[19:18:19.643989] Test:  [280/345]  eta: 0:00:12  loss: 0.7795 (0.7779)  time: 0.1930  data: 0.0001  max mem: 14938
[19:18:21.578668] Test:  [290/345]  eta: 0:00:10  loss: 0.7836 (0.7785)  time: 0.1933  data: 0.0001  max mem: 14938
[19:18:23.517176] Test:  [300/345]  eta: 0:00:08  loss: 0.7817 (0.7784)  time: 0.1936  data: 0.0001  max mem: 14938
[19:18:25.457102] Test:  [310/345]  eta: 0:00:06  loss: 0.7723 (0.7781)  time: 0.1939  data: 0.0001  max mem: 14938
[19:18:27.399686] Test:  [320/345]  eta: 0:00:04  loss: 0.7770 (0.7781)  time: 0.1941  data: 0.0001  max mem: 14938
[19:18:29.346943] Test:  [330/345]  eta: 0:00:02  loss: 0.7824 (0.7781)  time: 0.1944  data: 0.0001  max mem: 14938
[19:18:31.296987] Test:  [340/345]  eta: 0:00:00  loss: 0.7709 (0.7778)  time: 0.1948  data: 0.0001  max mem: 14938
[19:18:32.078151] Test:  [344/345]  eta: 0:00:00  loss: 0.7683 (0.7777)  time: 0.1949  data: 0.0001  max mem: 14938
[19:18:32.137584] Test: Total time: 0:01:05 (0.1901 s / it)
[19:18:42.542830] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8763 (0.8763)  time: 0.3197  data: 0.1403  max mem: 14938
[19:18:44.359661] Test:  [10/57]  eta: 0:00:09  loss: 0.8642 (0.8908)  time: 0.1942  data: 0.0128  max mem: 14938
[19:18:46.180186] Test:  [20/57]  eta: 0:00:06  loss: 0.8642 (0.8837)  time: 0.1818  data: 0.0001  max mem: 14938
[19:18:48.007219] Test:  [30/57]  eta: 0:00:05  loss: 0.7839 (0.8455)  time: 0.1823  data: 0.0001  max mem: 14938
[19:18:49.841720] Test:  [40/57]  eta: 0:00:03  loss: 0.7618 (0.8251)  time: 0.1830  data: 0.0001  max mem: 14938
[19:18:51.678236] Test:  [50/57]  eta: 0:00:01  loss: 0.7725 (0.8197)  time: 0.1835  data: 0.0001  max mem: 14938
[19:18:52.668908] Test:  [56/57]  eta: 0:00:00  loss: 0.8061 (0.8262)  time: 0.1780  data: 0.0001  max mem: 14938
[19:18:52.726719] Test: Total time: 0:00:10 (0.1843 s / it)
[19:18:54.472814] Dice score of the network on the train images: 0.767639, val images: 0.784673
[19:18:54.476902] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:18:55.365784] Epoch: [19]  [  0/345]  eta: 0:05:06  lr: 0.000119  loss: 0.8043 (0.8043)  time: 0.8880  data: 0.1458  max mem: 14938
[19:19:10.243187] Epoch: [19]  [ 20/345]  eta: 0:04:03  lr: 0.000119  loss: 0.8099 (0.8093)  time: 0.7438  data: 0.0001  max mem: 14938
[19:19:25.163271] Epoch: [19]  [ 40/345]  eta: 0:03:48  lr: 0.000119  loss: 0.7931 (0.8007)  time: 0.7460  data: 0.0001  max mem: 14938
[19:19:40.109848] Epoch: [19]  [ 60/345]  eta: 0:03:33  lr: 0.000120  loss: 0.7793 (0.7955)  time: 0.7473  data: 0.0001  max mem: 14938
[19:19:55.093193] Epoch: [19]  [ 80/345]  eta: 0:03:18  lr: 0.000120  loss: 0.7836 (0.7924)  time: 0.7491  data: 0.0001  max mem: 14938
[19:20:10.097049] Epoch: [19]  [100/345]  eta: 0:03:03  lr: 0.000121  loss: 0.7915 (0.7924)  time: 0.7502  data: 0.0001  max mem: 14938
[19:20:25.128816] Epoch: [19]  [120/345]  eta: 0:02:48  lr: 0.000121  loss: 0.7808 (0.7908)  time: 0.7515  data: 0.0001  max mem: 14938
[19:20:40.165447] Epoch: [19]  [140/345]  eta: 0:02:33  lr: 0.000121  loss: 0.7831 (0.7897)  time: 0.7518  data: 0.0001  max mem: 14938
[19:20:55.184613] Epoch: [19]  [160/345]  eta: 0:02:18  lr: 0.000122  loss: 0.7802 (0.7892)  time: 0.7509  data: 0.0001  max mem: 14938
[19:21:10.197177] Epoch: [19]  [180/345]  eta: 0:02:03  lr: 0.000122  loss: 0.7923 (0.7894)  time: 0.7506  data: 0.0001  max mem: 14938
[19:21:25.208640] Epoch: [19]  [200/345]  eta: 0:01:48  lr: 0.000122  loss: 0.7747 (0.7879)  time: 0.7505  data: 0.0001  max mem: 14938
[19:21:40.205969] Epoch: [19]  [220/345]  eta: 0:01:33  lr: 0.000123  loss: 0.7718 (0.7863)  time: 0.7498  data: 0.0001  max mem: 14938
[19:21:55.326454] Epoch: [19]  [240/345]  eta: 0:01:18  lr: 0.000123  loss: 0.7753 (0.7858)  time: 0.7560  data: 0.0001  max mem: 14938
[19:22:10.315796] Epoch: [19]  [260/345]  eta: 0:01:03  lr: 0.000123  loss: 0.7690 (0.7848)  time: 0.7494  data: 0.0001  max mem: 14938
[19:22:25.324795] Epoch: [19]  [280/345]  eta: 0:00:48  lr: 0.000124  loss: 0.7726 (0.7839)  time: 0.7504  data: 0.0001  max mem: 14938
[19:22:40.343054] Epoch: [19]  [300/345]  eta: 0:00:33  lr: 0.000124  loss: 0.7748 (0.7834)  time: 0.7509  data: 0.0001  max mem: 14938
[19:22:55.350744] Epoch: [19]  [320/345]  eta: 0:00:18  lr: 0.000125  loss: 0.7639 (0.7826)  time: 0.7503  data: 0.0001  max mem: 14938
[19:23:10.362294] Epoch: [19]  [340/345]  eta: 0:00:03  lr: 0.000125  loss: 0.7692 (0.7821)  time: 0.7505  data: 0.0001  max mem: 14938
[19:23:13.362837] Epoch: [19]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.7700 (0.7821)  time: 0.7504  data: 0.0001  max mem: 14938
[19:23:13.426898] Epoch: [19] Total time: 0:04:18 (0.7506 s / it)
[19:23:13.427380] Averaged stats: lr: 0.000125  loss: 0.7700 (0.7821)
[19:23:13.770325] Test:  [  0/345]  eta: 0:01:56  loss: 0.7454 (0.7454)  time: 0.3371  data: 0.1543  max mem: 14938
[19:23:15.607843] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7454 (0.7472)  time: 0.1976  data: 0.0141  max mem: 14938
[19:23:17.446517] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7495 (0.7505)  time: 0.1837  data: 0.0001  max mem: 14938
[19:23:19.289484] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7472 (0.7476)  time: 0.1840  data: 0.0001  max mem: 14938
[19:23:21.136024] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7472 (0.7498)  time: 0.1844  data: 0.0001  max mem: 14938
[19:23:22.985850] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7482 (0.7493)  time: 0.1848  data: 0.0001  max mem: 14938
[19:23:24.839977] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7475 (0.7493)  time: 0.1851  data: 0.0001  max mem: 14938
[19:23:26.697284] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7409 (0.7481)  time: 0.1855  data: 0.0001  max mem: 14938
[19:23:28.558530] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7445 (0.7485)  time: 0.1859  data: 0.0001  max mem: 14938
[19:23:30.422367] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7503 (0.7488)  time: 0.1862  data: 0.0001  max mem: 14938
[19:23:32.289353] Test:  [100/345]  eta: 0:00:45  loss: 0.7483 (0.7487)  time: 0.1865  data: 0.0001  max mem: 14938
[19:23:34.160367] Test:  [110/345]  eta: 0:00:43  loss: 0.7475 (0.7484)  time: 0.1869  data: 0.0001  max mem: 14938
[19:23:36.036512] Test:  [120/345]  eta: 0:00:42  loss: 0.7409 (0.7483)  time: 0.1873  data: 0.0001  max mem: 14938
[19:23:37.914603] Test:  [130/345]  eta: 0:00:40  loss: 0.7459 (0.7484)  time: 0.1877  data: 0.0001  max mem: 14938
[19:23:39.796222] Test:  [140/345]  eta: 0:00:38  loss: 0.7505 (0.7488)  time: 0.1879  data: 0.0001  max mem: 14938
[19:23:41.679789] Test:  [150/345]  eta: 0:00:36  loss: 0.7546 (0.7492)  time: 0.1882  data: 0.0001  max mem: 14938
[19:23:43.567701] Test:  [160/345]  eta: 0:00:34  loss: 0.7546 (0.7494)  time: 0.1885  data: 0.0001  max mem: 14938
[19:23:45.459246] Test:  [170/345]  eta: 0:00:32  loss: 0.7509 (0.7496)  time: 0.1889  data: 0.0001  max mem: 14938
[19:23:47.356620] Test:  [180/345]  eta: 0:00:30  loss: 0.7461 (0.7493)  time: 0.1894  data: 0.0001  max mem: 14938
[19:23:49.257864] Test:  [190/345]  eta: 0:00:29  loss: 0.7451 (0.7494)  time: 0.1899  data: 0.0001  max mem: 14938
[19:23:51.159036] Test:  [200/345]  eta: 0:00:27  loss: 0.7582 (0.7498)  time: 0.1901  data: 0.0001  max mem: 14938
[19:23:53.062307] Test:  [210/345]  eta: 0:00:25  loss: 0.7514 (0.7497)  time: 0.1902  data: 0.0001  max mem: 14938
[19:23:54.972508] Test:  [220/345]  eta: 0:00:23  loss: 0.7522 (0.7500)  time: 0.1906  data: 0.0001  max mem: 14938
[19:23:56.886580] Test:  [230/345]  eta: 0:00:21  loss: 0.7494 (0.7498)  time: 0.1912  data: 0.0001  max mem: 14938
[19:23:58.803292] Test:  [240/345]  eta: 0:00:19  loss: 0.7458 (0.7500)  time: 0.1915  data: 0.0001  max mem: 14938
[19:24:00.724389] Test:  [250/345]  eta: 0:00:17  loss: 0.7490 (0.7501)  time: 0.1918  data: 0.0001  max mem: 14938
[19:24:02.647722] Test:  [260/345]  eta: 0:00:16  loss: 0.7472 (0.7498)  time: 0.1922  data: 0.0001  max mem: 14938
[19:24:04.576308] Test:  [270/345]  eta: 0:00:14  loss: 0.7472 (0.7497)  time: 0.1925  data: 0.0001  max mem: 14938
[19:24:06.507404] Test:  [280/345]  eta: 0:00:12  loss: 0.7515 (0.7500)  time: 0.1929  data: 0.0001  max mem: 14938
[19:24:08.443515] Test:  [290/345]  eta: 0:00:10  loss: 0.7517 (0.7501)  time: 0.1933  data: 0.0001  max mem: 14938
[19:24:10.381615] Test:  [300/345]  eta: 0:00:08  loss: 0.7532 (0.7505)  time: 0.1937  data: 0.0001  max mem: 14938
[19:24:12.322636] Test:  [310/345]  eta: 0:00:06  loss: 0.7537 (0.7506)  time: 0.1939  data: 0.0001  max mem: 14938
[19:24:14.264095] Test:  [320/345]  eta: 0:00:04  loss: 0.7454 (0.7505)  time: 0.1941  data: 0.0001  max mem: 14938
[19:24:16.209910] Test:  [330/345]  eta: 0:00:02  loss: 0.7375 (0.7501)  time: 0.1943  data: 0.0001  max mem: 14938
[19:24:18.159831] Test:  [340/345]  eta: 0:00:00  loss: 0.7442 (0.7503)  time: 0.1947  data: 0.0001  max mem: 14938
[19:24:18.941052] Test:  [344/345]  eta: 0:00:00  loss: 0.7476 (0.7502)  time: 0.1949  data: 0.0001  max mem: 14938
[19:24:19.001716] Test: Total time: 0:01:05 (0.1901 s / it)
[19:24:29.419480] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8580 (0.8580)  time: 0.3196  data: 0.1396  max mem: 14938
[19:24:31.236983] Test:  [10/57]  eta: 0:00:09  loss: 0.8790 (0.8905)  time: 0.1942  data: 0.0127  max mem: 14938
[19:24:33.059675] Test:  [20/57]  eta: 0:00:06  loss: 0.8790 (0.8761)  time: 0.1819  data: 0.0001  max mem: 14938
[19:24:34.885805] Test:  [30/57]  eta: 0:00:05  loss: 0.7791 (0.8422)  time: 0.1824  data: 0.0001  max mem: 14938
[19:24:36.718107] Test:  [40/57]  eta: 0:00:03  loss: 0.7730 (0.8241)  time: 0.1829  data: 0.0001  max mem: 14938
[19:24:38.557959] Test:  [50/57]  eta: 0:00:01  loss: 0.7730 (0.8186)  time: 0.1836  data: 0.0001  max mem: 14938
[19:24:39.549089] Test:  [56/57]  eta: 0:00:00  loss: 0.7872 (0.8225)  time: 0.1782  data: 0.0001  max mem: 14938
[19:24:39.608845] Test: Total time: 0:00:10 (0.1844 s / it)
[19:24:41.324869] Dice score of the network on the train images: 0.793005, val images: 0.795748
[19:24:41.328853] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:24:42.214485] Epoch: [20]  [  0/345]  eta: 0:05:05  lr: 0.000125  loss: 0.7639 (0.7639)  time: 0.8847  data: 0.1435  max mem: 14938
[19:24:57.097924] Epoch: [20]  [ 20/345]  eta: 0:04:04  lr: 0.000125  loss: 0.7676 (0.7686)  time: 0.7441  data: 0.0001  max mem: 14938
[19:25:12.040836] Epoch: [20]  [ 40/345]  eta: 0:03:48  lr: 0.000125  loss: 0.7760 (0.7737)  time: 0.7471  data: 0.0001  max mem: 14938
[19:25:26.987117] Epoch: [20]  [ 60/345]  eta: 0:03:33  lr: 0.000125  loss: 0.7669 (0.7733)  time: 0.7473  data: 0.0001  max mem: 14938
[19:25:41.955321] Epoch: [20]  [ 80/345]  eta: 0:03:18  lr: 0.000125  loss: 0.7717 (0.7724)  time: 0.7484  data: 0.0001  max mem: 14938
[19:25:56.957777] Epoch: [20]  [100/345]  eta: 0:03:03  lr: 0.000125  loss: 0.7846 (0.7759)  time: 0.7501  data: 0.0001  max mem: 14938
[19:26:11.991372] Epoch: [20]  [120/345]  eta: 0:02:48  lr: 0.000125  loss: 0.7866 (0.7779)  time: 0.7516  data: 0.0001  max mem: 14938
[19:26:27.025501] Epoch: [20]  [140/345]  eta: 0:02:33  lr: 0.000125  loss: 0.7847 (0.7790)  time: 0.7517  data: 0.0001  max mem: 14938
[19:26:42.048096] Epoch: [20]  [160/345]  eta: 0:02:18  lr: 0.000125  loss: 0.7795 (0.7792)  time: 0.7511  data: 0.0001  max mem: 14938
[19:26:57.064971] Epoch: [20]  [180/345]  eta: 0:02:03  lr: 0.000125  loss: 0.7935 (0.7811)  time: 0.7508  data: 0.0001  max mem: 14938
[19:27:12.170022] Epoch: [20]  [200/345]  eta: 0:01:48  lr: 0.000125  loss: 0.7783 (0.7812)  time: 0.7552  data: 0.0001  max mem: 14938
[19:27:27.146553] Epoch: [20]  [220/345]  eta: 0:01:33  lr: 0.000125  loss: 0.7738 (0.7811)  time: 0.7488  data: 0.0001  max mem: 14938
[19:27:42.120633] Epoch: [20]  [240/345]  eta: 0:01:18  lr: 0.000125  loss: 0.7793 (0.7809)  time: 0.7487  data: 0.0001  max mem: 14938
[19:27:57.093640] Epoch: [20]  [260/345]  eta: 0:01:03  lr: 0.000125  loss: 0.7713 (0.7803)  time: 0.7486  data: 0.0001  max mem: 14938
[19:28:12.061533] Epoch: [20]  [280/345]  eta: 0:00:48  lr: 0.000125  loss: 0.7678 (0.7797)  time: 0.7484  data: 0.0001  max mem: 14938
[19:28:27.030662] Epoch: [20]  [300/345]  eta: 0:00:33  lr: 0.000125  loss: 0.7790 (0.7798)  time: 0.7484  data: 0.0001  max mem: 14938
[19:28:41.995888] Epoch: [20]  [320/345]  eta: 0:00:18  lr: 0.000125  loss: 0.7716 (0.7794)  time: 0.7482  data: 0.0001  max mem: 14938
[19:28:56.956696] Epoch: [20]  [340/345]  eta: 0:00:03  lr: 0.000125  loss: 0.7714 (0.7792)  time: 0.7480  data: 0.0001  max mem: 14938
[19:28:59.948734] Epoch: [20]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.7747 (0.7791)  time: 0.7478  data: 0.0001  max mem: 14938
[19:29:00.013402] Epoch: [20] Total time: 0:04:18 (0.7498 s / it)
[19:29:00.013878] Averaged stats: lr: 0.000125  loss: 0.7747 (0.7791)
[19:29:00.350903] Test:  [  0/345]  eta: 0:01:54  loss: 0.7574 (0.7574)  time: 0.3333  data: 0.1514  max mem: 14938
[19:29:02.189168] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7338 (0.7372)  time: 0.1973  data: 0.0138  max mem: 14938
[19:29:04.028381] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7338 (0.7371)  time: 0.1838  data: 0.0001  max mem: 14938
[19:29:05.871704] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7384 (0.7394)  time: 0.1841  data: 0.0001  max mem: 14938
[19:29:07.718928] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7396 (0.7393)  time: 0.1845  data: 0.0001  max mem: 14938
[19:29:09.571136] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7405 (0.7399)  time: 0.1849  data: 0.0001  max mem: 14938
[19:29:11.426740] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7429 (0.7413)  time: 0.1853  data: 0.0001  max mem: 14938
[19:29:13.286987] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7388 (0.7406)  time: 0.1857  data: 0.0001  max mem: 14938
[19:29:15.148854] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7382 (0.7399)  time: 0.1861  data: 0.0001  max mem: 14938
[19:29:17.015033] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7384 (0.7406)  time: 0.1864  data: 0.0001  max mem: 14938
[19:29:18.883481] Test:  [100/345]  eta: 0:00:45  loss: 0.7395 (0.7402)  time: 0.1867  data: 0.0001  max mem: 14938
[19:29:20.754107] Test:  [110/345]  eta: 0:00:43  loss: 0.7351 (0.7403)  time: 0.1869  data: 0.0001  max mem: 14938
[19:29:22.630660] Test:  [120/345]  eta: 0:00:42  loss: 0.7377 (0.7402)  time: 0.1873  data: 0.0001  max mem: 14938
[19:29:24.509316] Test:  [130/345]  eta: 0:00:40  loss: 0.7418 (0.7408)  time: 0.1877  data: 0.0001  max mem: 14938
[19:29:26.392335] Test:  [140/345]  eta: 0:00:38  loss: 0.7399 (0.7408)  time: 0.1880  data: 0.0001  max mem: 14938
[19:29:28.278283] Test:  [150/345]  eta: 0:00:36  loss: 0.7399 (0.7414)  time: 0.1884  data: 0.0001  max mem: 14938
[19:29:30.166819] Test:  [160/345]  eta: 0:00:34  loss: 0.7377 (0.7412)  time: 0.1887  data: 0.0001  max mem: 14938
[19:29:32.059336] Test:  [170/345]  eta: 0:00:32  loss: 0.7385 (0.7411)  time: 0.1890  data: 0.0001  max mem: 14938
[19:29:33.954935] Test:  [180/345]  eta: 0:00:30  loss: 0.7324 (0.7408)  time: 0.1894  data: 0.0001  max mem: 14938
[19:29:35.855148] Test:  [190/345]  eta: 0:00:29  loss: 0.7306 (0.7405)  time: 0.1897  data: 0.0001  max mem: 14938
[19:29:37.757788] Test:  [200/345]  eta: 0:00:27  loss: 0.7386 (0.7404)  time: 0.1901  data: 0.0001  max mem: 14938
[19:29:39.666481] Test:  [210/345]  eta: 0:00:25  loss: 0.7442 (0.7415)  time: 0.1905  data: 0.0001  max mem: 14938
[19:29:41.577346] Test:  [220/345]  eta: 0:00:23  loss: 0.7443 (0.7413)  time: 0.1909  data: 0.0001  max mem: 14938
[19:29:43.491926] Test:  [230/345]  eta: 0:00:21  loss: 0.7429 (0.7413)  time: 0.1912  data: 0.0001  max mem: 14938
[19:29:45.410378] Test:  [240/345]  eta: 0:00:19  loss: 0.7374 (0.7414)  time: 0.1916  data: 0.0001  max mem: 14938
[19:29:47.333048] Test:  [250/345]  eta: 0:00:17  loss: 0.7379 (0.7416)  time: 0.1920  data: 0.0001  max mem: 14938
[19:29:49.258031] Test:  [260/345]  eta: 0:00:16  loss: 0.7369 (0.7414)  time: 0.1923  data: 0.0001  max mem: 14938
[19:29:51.188123] Test:  [270/345]  eta: 0:00:14  loss: 0.7387 (0.7417)  time: 0.1927  data: 0.0001  max mem: 14938
[19:29:53.120204] Test:  [280/345]  eta: 0:00:12  loss: 0.7398 (0.7418)  time: 0.1931  data: 0.0001  max mem: 14938
[19:29:55.054485] Test:  [290/345]  eta: 0:00:10  loss: 0.7419 (0.7419)  time: 0.1933  data: 0.0001  max mem: 14938
[19:29:56.993439] Test:  [300/345]  eta: 0:00:08  loss: 0.7431 (0.7420)  time: 0.1936  data: 0.0001  max mem: 14938
[19:29:58.934562] Test:  [310/345]  eta: 0:00:06  loss: 0.7410 (0.7419)  time: 0.1940  data: 0.0001  max mem: 14938
[19:30:00.878080] Test:  [320/345]  eta: 0:00:04  loss: 0.7437 (0.7422)  time: 0.1942  data: 0.0001  max mem: 14938
[19:30:02.825352] Test:  [330/345]  eta: 0:00:02  loss: 0.7464 (0.7423)  time: 0.1945  data: 0.0001  max mem: 14938
[19:30:04.777549] Test:  [340/345]  eta: 0:00:00  loss: 0.7467 (0.7425)  time: 0.1949  data: 0.0001  max mem: 14938
[19:30:05.559405] Test:  [344/345]  eta: 0:00:00  loss: 0.7467 (0.7426)  time: 0.1951  data: 0.0001  max mem: 14938
[19:30:05.595888] Test: Total time: 0:01:05 (0.1901 s / it)
[19:30:16.051852] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8100 (0.8100)  time: 0.3252  data: 0.1455  max mem: 14938
[19:30:17.869800] Test:  [10/57]  eta: 0:00:09  loss: 0.8705 (0.8592)  time: 0.1948  data: 0.0133  max mem: 14938
[19:30:19.690861] Test:  [20/57]  eta: 0:00:06  loss: 0.8661 (0.8511)  time: 0.1819  data: 0.0001  max mem: 14938
[19:30:21.515286] Test:  [30/57]  eta: 0:00:05  loss: 0.7636 (0.8172)  time: 0.1822  data: 0.0001  max mem: 14938
[19:30:23.345696] Test:  [40/57]  eta: 0:00:03  loss: 0.7487 (0.8005)  time: 0.1827  data: 0.0001  max mem: 14938
[19:30:25.181699] Test:  [50/57]  eta: 0:00:01  loss: 0.7487 (0.7946)  time: 0.1833  data: 0.0001  max mem: 14938
[19:30:26.172914] Test:  [56/57]  eta: 0:00:00  loss: 0.7739 (0.7998)  time: 0.1780  data: 0.0001  max mem: 14938
[19:30:26.231791] Test: Total time: 0:00:10 (0.1843 s / it)
[19:30:27.986352] Dice score of the network on the train images: 0.783882, val images: 0.809511
[19:30:27.990507] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:30:28.882420] Epoch: [21]  [  0/345]  eta: 0:05:07  lr: 0.000125  loss: 0.7865 (0.7865)  time: 0.8909  data: 0.1496  max mem: 14938
[19:30:43.798426] Epoch: [21]  [ 20/345]  eta: 0:04:04  lr: 0.000125  loss: 0.7634 (0.7647)  time: 0.7457  data: 0.0001  max mem: 14938
[19:30:58.737585] Epoch: [21]  [ 40/345]  eta: 0:03:48  lr: 0.000125  loss: 0.7706 (0.7680)  time: 0.7469  data: 0.0001  max mem: 14938
[19:31:13.706112] Epoch: [21]  [ 60/345]  eta: 0:03:33  lr: 0.000125  loss: 0.7619 (0.7669)  time: 0.7484  data: 0.0001  max mem: 14938
[19:31:28.689873] Epoch: [21]  [ 80/345]  eta: 0:03:18  lr: 0.000124  loss: 0.7614 (0.7664)  time: 0.7491  data: 0.0001  max mem: 14938
[19:31:43.698414] Epoch: [21]  [100/345]  eta: 0:03:03  lr: 0.000124  loss: 0.7593 (0.7656)  time: 0.7504  data: 0.0001  max mem: 14938
[19:31:58.720541] Epoch: [21]  [120/345]  eta: 0:02:48  lr: 0.000124  loss: 0.7585 (0.7644)  time: 0.7511  data: 0.0001  max mem: 14938
[19:32:13.747749] Epoch: [21]  [140/345]  eta: 0:02:33  lr: 0.000124  loss: 0.7612 (0.7639)  time: 0.7513  data: 0.0001  max mem: 14938

[19:32:28.892435] Epoch: [21]  [160/345]  eta: 0:02:18  lr: 0.000124  loss: 0.7656 (0.7637)  time: 0.7572  data: 0.0001  max mem: 14938
[19:32:43.882640] Epoch: [21]  [180/345]  eta: 0:02:03  lr: 0.000124  loss: 0.7693 (0.7650)  time: 0.7495  data: 0.0001  max mem: 14938
[19:32:58.868868] Epoch: [21]  [200/345]  eta: 0:01:48  lr: 0.000124  loss: 0.7632 (0.7654)  time: 0.7493  data: 0.0001  max mem: 14938
[19:33:13.839677] Epoch: [21]  [220/345]  eta: 0:01:33  lr: 0.000124  loss: 0.7669 (0.7653)  time: 0.7485  data: 0.0001  max mem: 14938
[19:33:28.823120] Epoch: [21]  [240/345]  eta: 0:01:18  lr: 0.000124  loss: 0.7779 (0.7668)  time: 0.7491  data: 0.0001  max mem: 14938
[19:33:43.810022] Epoch: [21]  [260/345]  eta: 0:01:03  lr: 0.000124  loss: 0.7743 (0.7679)  time: 0.7493  data: 0.0001  max mem: 14938
[19:33:58.795112] Epoch: [21]  [280/345]  eta: 0:00:48  lr: 0.000124  loss: 0.7703 (0.7681)  time: 0.7492  data: 0.0001  max mem: 14938
[19:34:13.773082] Epoch: [21]  [300/345]  eta: 0:00:33  lr: 0.000124  loss: 0.7707 (0.7683)  time: 0.7489  data: 0.0001  max mem: 14938
[19:34:28.760222] Epoch: [21]  [320/345]  eta: 0:00:18  lr: 0.000124  loss: 0.7689 (0.7685)  time: 0.7493  data: 0.0001  max mem: 14938
[19:34:43.733430] Epoch: [21]  [340/345]  eta: 0:00:03  lr: 0.000124  loss: 0.7682 (0.7686)  time: 0.7486  data: 0.0001  max mem: 14938
[19:34:46.727385] Epoch: [21]  [344/345]  eta: 0:00:00  lr: 0.000124  loss: 0.7666 (0.7686)  time: 0.7485  data: 0.0001  max mem: 14938
[19:34:46.792030] Epoch: [21] Total time: 0:04:18 (0.7501 s / it)
[19:34:46.792297] Averaged stats: lr: 0.000124  loss: 0.7666 (0.7686)
[19:34:47.131274] Test:  [  0/345]  eta: 0:01:55  loss: 0.7195 (0.7195)  time: 0.3353  data: 0.1535  max mem: 14938
[19:34:48.969858] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7270 (0.7313)  time: 0.1976  data: 0.0140  max mem: 14938
[19:34:50.810125] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7384 (0.7350)  time: 0.1839  data: 0.0001  max mem: 14938
[19:34:52.654614] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7397 (0.7379)  time: 0.1842  data: 0.0001  max mem: 14938
[19:34:54.501278] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7445 (0.7392)  time: 0.1845  data: 0.0001  max mem: 14938
[19:34:56.352541] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7385 (0.7398)  time: 0.1848  data: 0.0001  max mem: 14938
[19:34:58.209924] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7324 (0.7382)  time: 0.1854  data: 0.0001  max mem: 14938
[19:35:00.068089] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7317 (0.7382)  time: 0.1857  data: 0.0001  max mem: 14938
[19:35:01.929927] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7368 (0.7382)  time: 0.1859  data: 0.0001  max mem: 14938
[19:35:03.796092] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7394 (0.7385)  time: 0.1863  data: 0.0001  max mem: 14938
[19:35:05.663805] Test:  [100/345]  eta: 0:00:45  loss: 0.7369 (0.7383)  time: 0.1866  data: 0.0001  max mem: 14938
[19:35:07.536645] Test:  [110/345]  eta: 0:00:43  loss: 0.7436 (0.7393)  time: 0.1870  data: 0.0001  max mem: 14938
[19:35:09.412565] Test:  [120/345]  eta: 0:00:42  loss: 0.7449 (0.7397)  time: 0.1874  data: 0.0001  max mem: 14938
[19:35:11.291560] Test:  [130/345]  eta: 0:00:40  loss: 0.7360 (0.7398)  time: 0.1877  data: 0.0001  max mem: 14938
[19:35:13.173953] Test:  [140/345]  eta: 0:00:38  loss: 0.7340 (0.7399)  time: 0.1880  data: 0.0001  max mem: 14938
[19:35:15.058226] Test:  [150/345]  eta: 0:00:36  loss: 0.7460 (0.7402)  time: 0.1883  data: 0.0001  max mem: 14938
[19:35:16.946699] Test:  [160/345]  eta: 0:00:34  loss: 0.7460 (0.7404)  time: 0.1886  data: 0.0001  max mem: 14938
[19:35:18.839127] Test:  [170/345]  eta: 0:00:32  loss: 0.7367 (0.7403)  time: 0.1890  data: 0.0001  max mem: 14938
[19:35:20.735149] Test:  [180/345]  eta: 0:00:30  loss: 0.7351 (0.7398)  time: 0.1894  data: 0.0001  max mem: 14938
[19:35:22.635582] Test:  [190/345]  eta: 0:00:29  loss: 0.7297 (0.7393)  time: 0.1898  data: 0.0001  max mem: 14938
[19:35:24.538204] Test:  [200/345]  eta: 0:00:27  loss: 0.7313 (0.7394)  time: 0.1901  data: 0.0001  max mem: 14938
[19:35:26.445548] Test:  [210/345]  eta: 0:00:25  loss: 0.7342 (0.7391)  time: 0.1904  data: 0.0001  max mem: 14938
[19:35:28.356282] Test:  [220/345]  eta: 0:00:23  loss: 0.7363 (0.7390)  time: 0.1909  data: 0.0001  max mem: 14938
[19:35:30.271515] Test:  [230/345]  eta: 0:00:21  loss: 0.7363 (0.7388)  time: 0.1912  data: 0.0001  max mem: 14938
[19:35:32.189638] Test:  [240/345]  eta: 0:00:19  loss: 0.7355 (0.7388)  time: 0.1916  data: 0.0001  max mem: 14938
[19:35:34.110609] Test:  [250/345]  eta: 0:00:17  loss: 0.7375 (0.7388)  time: 0.1919  data: 0.0001  max mem: 14938
[19:35:36.036135] Test:  [260/345]  eta: 0:00:16  loss: 0.7371 (0.7386)  time: 0.1923  data: 0.0001  max mem: 14938
[19:35:37.964073] Test:  [270/345]  eta: 0:00:14  loss: 0.7411 (0.7391)  time: 0.1926  data: 0.0001  max mem: 14938
[19:35:39.895799] Test:  [280/345]  eta: 0:00:12  loss: 0.7425 (0.7391)  time: 0.1929  data: 0.0001  max mem: 14938
[19:35:41.829504] Test:  [290/345]  eta: 0:00:10  loss: 0.7347 (0.7388)  time: 0.1932  data: 0.0001  max mem: 14938
[19:35:43.767496] Test:  [300/345]  eta: 0:00:08  loss: 0.7338 (0.7388)  time: 0.1935  data: 0.0001  max mem: 14938
[19:35:45.709746] Test:  [310/345]  eta: 0:00:06  loss: 0.7434 (0.7392)  time: 0.1940  data: 0.0001  max mem: 14938
[19:35:47.654809] Test:  [320/345]  eta: 0:00:04  loss: 0.7367 (0.7390)  time: 0.1943  data: 0.0001  max mem: 14938
[19:35:49.601831] Test:  [330/345]  eta: 0:00:02  loss: 0.7303 (0.7389)  time: 0.1946  data: 0.0001  max mem: 14938
[19:35:51.553231] Test:  [340/345]  eta: 0:00:00  loss: 0.7340 (0.7388)  time: 0.1949  data: 0.0001  max mem: 14938
[19:35:52.334964] Test:  [344/345]  eta: 0:00:00  loss: 0.7312 (0.7387)  time: 0.1950  data: 0.0001  max mem: 14938
[19:35:52.395736] Test: Total time: 0:01:05 (0.1901 s / it)
[19:36:02.829000] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8469 (0.8469)  time: 0.3189  data: 0.1390  max mem: 14938
[19:36:04.645821] Test:  [10/57]  eta: 0:00:09  loss: 0.8657 (0.8775)  time: 0.1941  data: 0.0127  max mem: 14938
[19:36:06.469274] Test:  [20/57]  eta: 0:00:06  loss: 0.8729 (0.8674)  time: 0.1820  data: 0.0001  max mem: 14938
[19:36:08.296820] Test:  [30/57]  eta: 0:00:05  loss: 0.7707 (0.8296)  time: 0.1825  data: 0.0001  max mem: 14938
[19:36:10.128744] Test:  [40/57]  eta: 0:00:03  loss: 0.7605 (0.8107)  time: 0.1829  data: 0.0001  max mem: 14938
[19:36:11.964579] Test:  [50/57]  eta: 0:00:01  loss: 0.7552 (0.8040)  time: 0.1833  data: 0.0001  max mem: 14938
[19:36:12.955842] Test:  [56/57]  eta: 0:00:00  loss: 0.7675 (0.8096)  time: 0.1780  data: 0.0001  max mem: 14938
[19:36:13.015930] Test: Total time: 0:00:10 (0.1843 s / it)
[19:36:14.814653] Dice score of the network on the train images: 0.796097, val images: 0.812936
[19:36:14.814878] saving best_dice_model_0 @ epoch 21
[19:36:15.990713] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:36:16.876006] Epoch: [22]  [  0/345]  eta: 0:05:05  lr: 0.000124  loss: 0.7631 (0.7631)  time: 0.8843  data: 0.1420  max mem: 14938
[19:36:31.764342] Epoch: [22]  [ 20/345]  eta: 0:04:04  lr: 0.000124  loss: 0.7722 (0.7740)  time: 0.7444  data: 0.0001  max mem: 14938
[19:36:46.698993] Epoch: [22]  [ 40/345]  eta: 0:03:48  lr: 0.000123  loss: 0.7665 (0.7721)  time: 0.7467  data: 0.0001  max mem: 14938
[19:37:01.669506] Epoch: [22]  [ 60/345]  eta: 0:03:33  lr: 0.000123  loss: 0.7977 (0.7847)  time: 0.7485  data: 0.0001  max mem: 14938
[19:37:16.661511] Epoch: [22]  [ 80/345]  eta: 0:03:18  lr: 0.000123  loss: 0.7948 (0.7874)  time: 0.7496  data: 0.0001  max mem: 14938
[19:37:31.675017] Epoch: [22]  [100/345]  eta: 0:03:03  lr: 0.000123  loss: 0.7807 (0.7862)  time: 0.7506  data: 0.0001  max mem: 14938
[19:37:46.704023] Epoch: [22]  [120/345]  eta: 0:02:48  lr: 0.000123  loss: 0.7601 (0.7822)  time: 0.7514  data: 0.0001  max mem: 14938
[19:38:01.736630] Epoch: [22]  [140/345]  eta: 0:02:33  lr: 0.000123  loss: 0.7685 (0.7804)  time: 0.7516  data: 0.0001  max mem: 14938
[19:38:16.756597] Epoch: [22]  [160/345]  eta: 0:02:18  lr: 0.000123  loss: 0.7588 (0.7779)  time: 0.7510  data: 0.0001  max mem: 14938
[19:38:31.770851] Epoch: [22]  [180/345]  eta: 0:02:03  lr: 0.000123  loss: 0.7597 (0.7761)  time: 0.7507  data: 0.0001  max mem: 14938
[19:38:46.769677] Epoch: [22]  [200/345]  eta: 0:01:48  lr: 0.000123  loss: 0.7796 (0.7763)  time: 0.7499  data: 0.0001  max mem: 14938
[19:39:01.764239] Epoch: [22]  [220/345]  eta: 0:01:33  lr: 0.000123  loss: 0.7618 (0.7752)  time: 0.7497  data: 0.0001  max mem: 14938
[19:39:16.760694] Epoch: [22]  [240/345]  eta: 0:01:18  lr: 0.000123  loss: 0.7670 (0.7743)  time: 0.7498  data: 0.0001  max mem: 14938
[19:39:31.751464] Epoch: [22]  [260/345]  eta: 0:01:03  lr: 0.000122  loss: 0.7682 (0.7738)  time: 0.7495  data: 0.0001  max mem: 14938
[19:39:46.743795] Epoch: [22]  [280/345]  eta: 0:00:48  lr: 0.000122  loss: 0.7599 (0.7729)  time: 0.7496  data: 0.0001  max mem: 14938
[19:40:01.740756] Epoch: [22]  [300/345]  eta: 0:00:33  lr: 0.000122  loss: 0.7631 (0.7724)  time: 0.7498  data: 0.0001  max mem: 14938
[19:40:16.726524] Epoch: [22]  [320/345]  eta: 0:00:18  lr: 0.000122  loss: 0.7688 (0.7723)  time: 0.7493  data: 0.0001  max mem: 14938
[19:40:31.705163] Epoch: [22]  [340/345]  eta: 0:00:03  lr: 0.000122  loss: 0.7730 (0.7722)  time: 0.7489  data: 0.0001  max mem: 14938
[19:40:34.700084] Epoch: [22]  [344/345]  eta: 0:00:00  lr: 0.000122  loss: 0.7703 (0.7720)  time: 0.7490  data: 0.0001  max mem: 14938
[19:40:34.767045] Epoch: [22] Total time: 0:04:18 (0.7501 s / it)
[19:40:34.767554] Averaged stats: lr: 0.000122  loss: 0.7703 (0.7720)
[19:40:35.107184] Test:  [  0/345]  eta: 0:01:55  loss: 0.7346 (0.7346)  time: 0.3352  data: 0.1531  max mem: 14938
[19:40:36.945028] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7350 (0.7353)  time: 0.1975  data: 0.0140  max mem: 14938
[19:40:38.784758] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7330 (0.7325)  time: 0.1838  data: 0.0001  max mem: 14938
[19:40:40.627495] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7330 (0.7338)  time: 0.1841  data: 0.0001  max mem: 14938
[19:40:42.474370] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7407 (0.7358)  time: 0.1844  data: 0.0001  max mem: 14938
[19:40:44.324897] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7374 (0.7352)  time: 0.1848  data: 0.0001  max mem: 14938
[19:40:46.179044] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7334 (0.7353)  time: 0.1852  data: 0.0001  max mem: 14938
[19:40:48.035750] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7349 (0.7358)  time: 0.1855  data: 0.0001  max mem: 14938
[19:40:49.897191] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7361 (0.7361)  time: 0.1859  data: 0.0001  max mem: 14938
[19:40:51.762354] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7368 (0.7359)  time: 0.1863  data: 0.0001  max mem: 14938
[19:40:53.629422] Test:  [100/345]  eta: 0:00:45  loss: 0.7366 (0.7365)  time: 0.1866  data: 0.0001  max mem: 14938
[19:40:55.502242] Test:  [110/345]  eta: 0:00:43  loss: 0.7380 (0.7366)  time: 0.1869  data: 0.0001  max mem: 14938
[19:40:57.377402] Test:  [120/345]  eta: 0:00:42  loss: 0.7388 (0.7369)  time: 0.1874  data: 0.0001  max mem: 14938
[19:40:59.255240] Test:  [130/345]  eta: 0:00:40  loss: 0.7432 (0.7376)  time: 0.1876  data: 0.0001  max mem: 14938
[19:41:01.137232] Test:  [140/345]  eta: 0:00:38  loss: 0.7421 (0.7381)  time: 0.1879  data: 0.0001  max mem: 14938
[19:41:03.023238] Test:  [150/345]  eta: 0:00:36  loss: 0.7345 (0.7375)  time: 0.1884  data: 0.0001  max mem: 14938
[19:41:04.909004] Test:  [160/345]  eta: 0:00:34  loss: 0.7358 (0.7379)  time: 0.1885  data: 0.0001  max mem: 14938
[19:41:06.799872] Test:  [170/345]  eta: 0:00:32  loss: 0.7358 (0.7378)  time: 0.1888  data: 0.0001  max mem: 14938
[19:41:08.697329] Test:  [180/345]  eta: 0:00:30  loss: 0.7340 (0.7381)  time: 0.1894  data: 0.0001  max mem: 14938
[19:41:10.597889] Test:  [190/345]  eta: 0:00:29  loss: 0.7454 (0.7383)  time: 0.1899  data: 0.0001  max mem: 14938
[19:41:12.500392] Test:  [200/345]  eta: 0:00:27  loss: 0.7363 (0.7380)  time: 0.1901  data: 0.0001  max mem: 14938
[19:41:14.407033] Test:  [210/345]  eta: 0:00:25  loss: 0.7361 (0.7379)  time: 0.1904  data: 0.0001  max mem: 14938
[19:41:16.318055] Test:  [220/345]  eta: 0:00:23  loss: 0.7379 (0.7383)  time: 0.1908  data: 0.0001  max mem: 14938
[19:41:18.233175] Test:  [230/345]  eta: 0:00:21  loss: 0.7379 (0.7383)  time: 0.1913  data: 0.0001  max mem: 14938
[19:41:20.149313] Test:  [240/345]  eta: 0:00:19  loss: 0.7348 (0.7385)  time: 0.1915  data: 0.0001  max mem: 14938
[19:41:22.069965] Test:  [250/345]  eta: 0:00:17  loss: 0.7494 (0.7391)  time: 0.1918  data: 0.0001  max mem: 14938
[19:41:23.995052] Test:  [260/345]  eta: 0:00:16  loss: 0.7417 (0.7391)  time: 0.1922  data: 0.0001  max mem: 14938
[19:41:25.922653] Test:  [270/345]  eta: 0:00:14  loss: 0.7403 (0.7394)  time: 0.1926  data: 0.0001  max mem: 14938
[19:41:27.853480] Test:  [280/345]  eta: 0:00:12  loss: 0.7416 (0.7394)  time: 0.1929  data: 0.0001  max mem: 14938
[19:41:29.786770] Test:  [290/345]  eta: 0:00:10  loss: 0.7383 (0.7394)  time: 0.1932  data: 0.0001  max mem: 14938
[19:41:31.724669] Test:  [300/345]  eta: 0:00:08  loss: 0.7383 (0.7394)  time: 0.1935  data: 0.0001  max mem: 14938
[19:41:33.664416] Test:  [310/345]  eta: 0:00:06  loss: 0.7403 (0.7396)  time: 0.1938  data: 0.0001  max mem: 14938
[19:41:35.607277] Test:  [320/345]  eta: 0:00:04  loss: 0.7441 (0.7397)  time: 0.1941  data: 0.0001  max mem: 14938
[19:41:37.554360] Test:  [330/345]  eta: 0:00:02  loss: 0.7491 (0.7401)  time: 0.1945  data: 0.0001  max mem: 14938
[19:41:39.505185] Test:  [340/345]  eta: 0:00:00  loss: 0.7561 (0.7405)  time: 0.1948  data: 0.0001  max mem: 14938
[19:41:40.288079] Test:  [344/345]  eta: 0:00:00  loss: 0.7443 (0.7405)  time: 0.1951  data: 0.0001  max mem: 14938
[19:41:40.345974] Test: Total time: 0:01:05 (0.1901 s / it)
[19:41:50.756961] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8282 (0.8282)  time: 0.3230  data: 0.1432  max mem: 14938
[19:41:52.575572] Test:  [10/57]  eta: 0:00:09  loss: 0.8647 (0.8667)  time: 0.1946  data: 0.0131  max mem: 14938
[19:41:54.399194] Test:  [20/57]  eta: 0:00:06  loss: 0.8781 (0.8644)  time: 0.1820  data: 0.0001  max mem: 14938
[19:41:56.227370] Test:  [30/57]  eta: 0:00:05  loss: 0.7552 (0.8257)  time: 0.1825  data: 0.0001  max mem: 14938
[19:41:58.058846] Test:  [40/57]  eta: 0:00:03  loss: 0.7473 (0.8054)  time: 0.1829  data: 0.0001  max mem: 14938
[19:41:59.895079] Test:  [50/57]  eta: 0:00:01  loss: 0.7321 (0.7973)  time: 0.1833  data: 0.0001  max mem: 14938
[19:42:00.884574] Test:  [56/57]  eta: 0:00:00  loss: 0.7677 (0.8025)  time: 0.1779  data: 0.0001  max mem: 14938
[19:42:00.940867] Test: Total time: 0:00:10 (0.1843 s / it)
[19:42:02.712354] Dice score of the network on the train images: 0.785984, val images: 0.822195
[19:42:02.712573] saving best_dice_model_0 @ epoch 22
[19:42:03.813378] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:42:04.701811] Epoch: [23]  [  0/345]  eta: 0:05:06  lr: 0.000122  loss: 0.7650 (0.7650)  time: 0.8873  data: 0.1453  max mem: 14938
[19:42:19.565436] Epoch: [23]  [ 20/345]  eta: 0:04:03  lr: 0.000122  loss: 0.7793 (0.7770)  time: 0.7431  data: 0.0001  max mem: 14938
[19:42:34.502596] Epoch: [23]  [ 40/345]  eta: 0:03:48  lr: 0.000122  loss: 0.7992 (0.7905)  time: 0.7468  data: 0.0001  max mem: 14938
[19:42:49.474620] Epoch: [23]  [ 60/345]  eta: 0:03:33  lr: 0.000122  loss: 0.7865 (0.7903)  time: 0.7485  data: 0.0001  max mem: 14938
[19:43:04.465074] Epoch: [23]  [ 80/345]  eta: 0:03:18  lr: 0.000121  loss: 0.7710 (0.7880)  time: 0.7495  data: 0.0001  max mem: 14938
[19:43:19.606844] Epoch: [23]  [100/345]  eta: 0:03:03  lr: 0.000121  loss: 0.7697 (0.7841)  time: 0.7570  data: 0.0001  max mem: 14938
[19:43:34.622187] Epoch: [23]  [120/345]  eta: 0:02:48  lr: 0.000121  loss: 0.7644 (0.7824)  time: 0.7507  data: 0.0001  max mem: 14938
[19:43:49.663803] Epoch: [23]  [140/345]  eta: 0:02:33  lr: 0.000121  loss: 0.7579 (0.7792)  time: 0.7520  data: 0.0001  max mem: 14938
[19:44:04.671160] Epoch: [23]  [160/345]  eta: 0:02:18  lr: 0.000121  loss: 0.7609 (0.7778)  time: 0.7503  data: 0.0001  max mem: 14938
[19:44:19.663719] Epoch: [23]  [180/345]  eta: 0:02:03  lr: 0.000121  loss: 0.7743 (0.7777)  time: 0.7496  data: 0.0001  max mem: 14938
[19:44:34.647946] Epoch: [23]  [200/345]  eta: 0:01:48  lr: 0.000121  loss: 0.7686 (0.7769)  time: 0.7492  data: 0.0001  max mem: 14938
[19:44:49.631049] Epoch: [23]  [220/345]  eta: 0:01:33  lr: 0.000121  loss: 0.7707 (0.7764)  time: 0.7491  data: 0.0001  max mem: 14938
[19:45:04.611714] Epoch: [23]  [240/345]  eta: 0:01:18  lr: 0.000120  loss: 0.7643 (0.7754)  time: 0.7490  data: 0.0001  max mem: 14938
[19:45:19.589513] Epoch: [23]  [260/345]  eta: 0:01:03  lr: 0.000120  loss: 0.7664 (0.7748)  time: 0.7488  data: 0.0001  max mem: 14938
[19:45:34.562573] Epoch: [23]  [280/345]  eta: 0:00:48  lr: 0.000120  loss: 0.7608 (0.7739)  time: 0.7486  data: 0.0001  max mem: 14938
[19:45:49.533255] Epoch: [23]  [300/345]  eta: 0:00:33  lr: 0.000120  loss: 0.7549 (0.7729)  time: 0.7485  data: 0.0001  max mem: 14938
[19:46:04.521351] Epoch: [23]  [320/345]  eta: 0:00:18  lr: 0.000120  loss: 0.7575 (0.7723)  time: 0.7494  data: 0.0001  max mem: 14938
[19:46:19.505027] Epoch: [23]  [340/345]  eta: 0:00:03  lr: 0.000120  loss: 0.7587 (0.7714)  time: 0.7491  data: 0.0001  max mem: 14938
[19:46:22.502449] Epoch: [23]  [344/345]  eta: 0:00:00  lr: 0.000120  loss: 0.7562 (0.7712)  time: 0.7492  data: 0.0001  max mem: 14938
[19:46:22.562972] Epoch: [23] Total time: 0:04:18 (0.7500 s / it)
[19:46:22.563373] Averaged stats: lr: 0.000120  loss: 0.7562 (0.7712)
[19:46:22.897307] Test:  [  0/345]  eta: 0:01:53  loss: 0.7383 (0.7383)  time: 0.3298  data: 0.1475  max mem: 14938
[19:46:24.734382] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7358 (0.7358)  time: 0.1969  data: 0.0135  max mem: 14938
[19:46:26.574135] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7356 (0.7350)  time: 0.1838  data: 0.0001  max mem: 14938
[19:46:28.416717] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7316 (0.7333)  time: 0.1841  data: 0.0001  max mem: 14938
[19:46:30.264018] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7283 (0.7342)  time: 0.1844  data: 0.0001  max mem: 14938
[19:46:32.114722] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7357 (0.7351)  time: 0.1849  data: 0.0001  max mem: 14938
[19:46:33.969827] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7354 (0.7348)  time: 0.1852  data: 0.0001  max mem: 14938
[19:46:35.827312] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7303 (0.7330)  time: 0.1856  data: 0.0001  max mem: 14938
[19:46:37.688404] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7287 (0.7330)  time: 0.1859  data: 0.0001  max mem: 14938
[19:46:39.551792] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7310 (0.7327)  time: 0.1862  data: 0.0001  max mem: 14938
[19:46:41.419081] Test:  [100/345]  eta: 0:00:45  loss: 0.7310 (0.7332)  time: 0.1865  data: 0.0001  max mem: 14938
[19:46:43.291244] Test:  [110/345]  eta: 0:00:43  loss: 0.7385 (0.7336)  time: 0.1869  data: 0.0001  max mem: 14938
[19:46:45.166698] Test:  [120/345]  eta: 0:00:42  loss: 0.7325 (0.7333)  time: 0.1873  data: 0.0001  max mem: 14938
[19:46:47.043818] Test:  [130/345]  eta: 0:00:40  loss: 0.7325 (0.7332)  time: 0.1876  data: 0.0001  max mem: 14938
[19:46:48.926527] Test:  [140/345]  eta: 0:00:38  loss: 0.7304 (0.7329)  time: 0.1879  data: 0.0001  max mem: 14938
[19:46:50.811658] Test:  [150/345]  eta: 0:00:36  loss: 0.7304 (0.7325)  time: 0.1883  data: 0.0001  max mem: 14938
[19:46:52.700307] Test:  [160/345]  eta: 0:00:34  loss: 0.7339 (0.7330)  time: 0.1886  data: 0.0001  max mem: 14938
[19:46:54.592449] Test:  [170/345]  eta: 0:00:32  loss: 0.7339 (0.7330)  time: 0.1890  data: 0.0001  max mem: 14938
[19:46:56.489649] Test:  [180/345]  eta: 0:00:30  loss: 0.7295 (0.7330)  time: 0.1894  data: 0.0001  max mem: 14938
[19:46:58.388030] Test:  [190/345]  eta: 0:00:29  loss: 0.7281 (0.7331)  time: 0.1897  data: 0.0001  max mem: 14938
[19:47:00.291077] Test:  [200/345]  eta: 0:00:27  loss: 0.7309 (0.7329)  time: 0.1900  data: 0.0001  max mem: 14938
[19:47:02.198414] Test:  [210/345]  eta: 0:00:25  loss: 0.7305 (0.7329)  time: 0.1905  data: 0.0001  max mem: 14938
[19:47:04.109088] Test:  [220/345]  eta: 0:00:23  loss: 0.7306 (0.7330)  time: 0.1908  data: 0.0001  max mem: 14938
[19:47:06.024563] Test:  [230/345]  eta: 0:00:21  loss: 0.7306 (0.7329)  time: 0.1913  data: 0.0001  max mem: 14938
[19:47:07.944285] Test:  [240/345]  eta: 0:00:19  loss: 0.7260 (0.7326)  time: 0.1917  data: 0.0001  max mem: 14938
[19:47:09.866340] Test:  [250/345]  eta: 0:00:17  loss: 0.7275 (0.7325)  time: 0.1920  data: 0.0001  max mem: 14938
[19:47:11.791098] Test:  [260/345]  eta: 0:00:16  loss: 0.7290 (0.7328)  time: 0.1923  data: 0.0001  max mem: 14938
[19:47:13.718904] Test:  [270/345]  eta: 0:00:14  loss: 0.7290 (0.7327)  time: 0.1926  data: 0.0001  max mem: 14938
[19:47:15.650467] Test:  [280/345]  eta: 0:00:12  loss: 0.7230 (0.7325)  time: 0.1929  data: 0.0001  max mem: 14938
[19:47:17.585555] Test:  [290/345]  eta: 0:00:10  loss: 0.7232 (0.7323)  time: 0.1933  data: 0.0001  max mem: 14938
[19:47:19.523486] Test:  [300/345]  eta: 0:00:08  loss: 0.7229 (0.7322)  time: 0.1936  data: 0.0001  max mem: 14938
[19:47:21.465169] Test:  [310/345]  eta: 0:00:06  loss: 0.7229 (0.7322)  time: 0.1939  data: 0.0001  max mem: 14938
[19:47:23.409186] Test:  [320/345]  eta: 0:00:04  loss: 0.7305 (0.7320)  time: 0.1942  data: 0.0001  max mem: 14938
[19:47:25.355755] Test:  [330/345]  eta: 0:00:02  loss: 0.7305 (0.7319)  time: 0.1945  data: 0.0001  max mem: 14938
[19:47:27.307335] Test:  [340/345]  eta: 0:00:00  loss: 0.7300 (0.7317)  time: 0.1949  data: 0.0001  max mem: 14938
[19:47:28.089034] Test:  [344/345]  eta: 0:00:00  loss: 0.7309 (0.7319)  time: 0.1950  data: 0.0001  max mem: 14938
[19:47:28.146998] Test: Total time: 0:01:05 (0.1901 s / it)
[19:47:38.631779] Test:  [ 0/57]  eta: 0:00:18  loss: 0.9047 (0.9047)  time: 0.3185  data: 0.1389  max mem: 14938
[19:47:40.448548] Test:  [10/57]  eta: 0:00:09  loss: 0.8832 (0.8845)  time: 0.1940  data: 0.0127  max mem: 14938
[19:47:42.270489] Test:  [20/57]  eta: 0:00:06  loss: 0.8778 (0.8739)  time: 0.1819  data: 0.0001  max mem: 14938
[19:47:44.095697] Test:  [30/57]  eta: 0:00:05  loss: 0.7633 (0.8329)  time: 0.1823  data: 0.0001  max mem: 14938
[19:47:45.928189] Test:  [40/57]  eta: 0:00:03  loss: 0.7550 (0.8112)  time: 0.1828  data: 0.0001  max mem: 14938
[19:47:47.764600] Test:  [50/57]  eta: 0:00:01  loss: 0.7464 (0.8044)  time: 0.1834  data: 0.0001  max mem: 14938
[19:47:48.753496] Test:  [56/57]  eta: 0:00:00  loss: 0.7624 (0.8100)  time: 0.1779  data: 0.0001  max mem: 14938
[19:47:48.810598] Test: Total time: 0:00:10 (0.1842 s / it)
[19:47:50.568975] Dice score of the network on the train images: 0.801517, val images: 0.814625
[19:47:50.569174] saving best_prec_model_0 @ epoch 23
[19:47:51.663717] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:47:52.553656] Epoch: [24]  [  0/345]  eta: 0:05:06  lr: 0.000120  loss: 0.7418 (0.7418)  time: 0.8888  data: 0.1473  max mem: 14938
[19:48:07.450258] Epoch: [24]  [ 20/345]  eta: 0:04:04  lr: 0.000119  loss: 0.7612 (0.7617)  time: 0.7448  data: 0.0001  max mem: 14938
[19:48:22.396195] Epoch: [24]  [ 40/345]  eta: 0:03:48  lr: 0.000119  loss: 0.7557 (0.7625)  time: 0.7472  data: 0.0001  max mem: 14938
[19:48:37.489544] Epoch: [24]  [ 60/345]  eta: 0:03:34  lr: 0.000119  loss: 0.7573 (0.7621)  time: 0.7546  data: 0.0001  max mem: 14938
[19:48:52.482617] Epoch: [24]  [ 80/345]  eta: 0:03:18  lr: 0.000119  loss: 0.7697 (0.7653)  time: 0.7496  data: 0.0001  max mem: 14938
[19:49:07.492058] Epoch: [24]  [100/345]  eta: 0:03:03  lr: 0.000119  loss: 0.7891 (0.7694)  time: 0.7504  data: 0.0001  max mem: 14938
[19:49:22.524922] Epoch: [24]  [120/345]  eta: 0:02:48  lr: 0.000119  loss: 0.7660 (0.7692)  time: 0.7516  data: 0.0001  max mem: 14938
[19:49:37.559598] Epoch: [24]  [140/345]  eta: 0:02:33  lr: 0.000118  loss: 0.7607 (0.7685)  time: 0.7517  data: 0.0001  max mem: 14938
[19:49:52.588007] Epoch: [24]  [160/345]  eta: 0:02:18  lr: 0.000118  loss: 0.7654 (0.7679)  time: 0.7514  data: 0.0001  max mem: 14938
[19:50:07.604188] Epoch: [24]  [180/345]  eta: 0:02:03  lr: 0.000118  loss: 0.7639 (0.7678)  time: 0.7508  data: 0.0001  max mem: 14938
[19:50:22.621011] Epoch: [24]  [200/345]  eta: 0:01:48  lr: 0.000118  loss: 0.7581 (0.7671)  time: 0.7508  data: 0.0001  max mem: 14938
[19:50:37.617805] Epoch: [24]  [220/345]  eta: 0:01:33  lr: 0.000118  loss: 0.7576 (0.7665)  time: 0.7498  data: 0.0001  max mem: 14938
[19:50:52.603523] Epoch: [24]  [240/345]  eta: 0:01:18  lr: 0.000118  loss: 0.7585 (0.7656)  time: 0.7492  data: 0.0001  max mem: 14938
[19:51:07.585009] Epoch: [24]  [260/345]  eta: 0:01:03  lr: 0.000117  loss: 0.7509 (0.7648)  time: 0.7490  data: 0.0001  max mem: 14938
[19:51:22.564238] Epoch: [24]  [280/345]  eta: 0:00:48  lr: 0.000117  loss: 0.7576 (0.7644)  time: 0.7489  data: 0.0001  max mem: 14938
[19:51:37.532588] Epoch: [24]  [300/345]  eta: 0:00:33  lr: 0.000117  loss: 0.7518 (0.7639)  time: 0.7484  data: 0.0001  max mem: 14938
[19:51:52.513085] Epoch: [24]  [320/345]  eta: 0:00:18  lr: 0.000117  loss: 0.7542 (0.7634)  time: 0.7490  data: 0.0001  max mem: 14938
[19:52:07.496381] Epoch: [24]  [340/345]  eta: 0:00:03  lr: 0.000117  loss: 0.7515 (0.7630)  time: 0.7491  data: 0.0001  max mem: 14938
[19:52:10.491680] Epoch: [24]  [344/345]  eta: 0:00:00  lr: 0.000117  loss: 0.7502 (0.7628)  time: 0.7491  data: 0.0001  max mem: 14938
[19:52:10.555953] Epoch: [24] Total time: 0:04:18 (0.7504 s / it)
[19:52:10.556340] Averaged stats: lr: 0.000117  loss: 0.7502 (0.7628)
[19:52:10.889717] Test:  [  0/345]  eta: 0:01:53  loss: 0.7309 (0.7309)  time: 0.3287  data: 0.1471  max mem: 14938
[19:52:12.725909] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7309 (0.7309)  time: 0.1968  data: 0.0134  max mem: 14938
[19:52:14.565276] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7291 (0.7311)  time: 0.1837  data: 0.0001  max mem: 14938
[19:52:16.408487] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7189 (0.7276)  time: 0.1841  data: 0.0001  max mem: 14938
[19:52:18.256607] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7190 (0.7290)  time: 0.1845  data: 0.0001  max mem: 14938
[19:52:20.106651] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7271 (0.7280)  time: 0.1849  data: 0.0001  max mem: 14938
[19:52:21.961339] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7169 (0.7265)  time: 0.1852  data: 0.0001  max mem: 14938
[19:52:23.818258] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7195 (0.7263)  time: 0.1855  data: 0.0001  max mem: 14938
[19:52:25.679678] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7195 (0.7255)  time: 0.1859  data: 0.0001  max mem: 14938
[19:52:27.542954] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7273 (0.7260)  time: 0.1862  data: 0.0001  max mem: 14938
[19:52:29.410233] Test:  [100/345]  eta: 0:00:45  loss: 0.7273 (0.7257)  time: 0.1865  data: 0.0001  max mem: 14938
[19:52:31.281256] Test:  [110/345]  eta: 0:00:43  loss: 0.7229 (0.7260)  time: 0.1869  data: 0.0001  max mem: 14938
[19:52:33.156784] Test:  [120/345]  eta: 0:00:42  loss: 0.7238 (0.7262)  time: 0.1873  data: 0.0001  max mem: 14938
[19:52:35.035051] Test:  [130/345]  eta: 0:00:40  loss: 0.7238 (0.7260)  time: 0.1876  data: 0.0001  max mem: 14938
[19:52:36.916491] Test:  [140/345]  eta: 0:00:38  loss: 0.7203 (0.7257)  time: 0.1879  data: 0.0001  max mem: 14938
[19:52:38.801790] Test:  [150/345]  eta: 0:00:36  loss: 0.7216 (0.7257)  time: 0.1883  data: 0.0001  max mem: 14938
[19:52:40.690428] Test:  [160/345]  eta: 0:00:34  loss: 0.7255 (0.7260)  time: 0.1886  data: 0.0001  max mem: 14938
[19:52:42.580538] Test:  [170/345]  eta: 0:00:32  loss: 0.7255 (0.7257)  time: 0.1889  data: 0.0001  max mem: 14938
[19:52:44.479295] Test:  [180/345]  eta: 0:00:30  loss: 0.7181 (0.7255)  time: 0.1894  data: 0.0001  max mem: 14938
[19:52:46.379399] Test:  [190/345]  eta: 0:00:29  loss: 0.7257 (0.7258)  time: 0.1899  data: 0.0001  max mem: 14938
[19:52:48.282088] Test:  [200/345]  eta: 0:00:27  loss: 0.7272 (0.7256)  time: 0.1901  data: 0.0001  max mem: 14938
[19:52:50.188967] Test:  [210/345]  eta: 0:00:25  loss: 0.7274 (0.7257)  time: 0.1904  data: 0.0001  max mem: 14938
[19:52:52.099043] Test:  [220/345]  eta: 0:00:23  loss: 0.7262 (0.7255)  time: 0.1908  data: 0.0001  max mem: 14938
[19:52:54.014458] Test:  [230/345]  eta: 0:00:21  loss: 0.7168 (0.7251)  time: 0.1912  data: 0.0001  max mem: 14938
[19:52:55.931177] Test:  [240/345]  eta: 0:00:19  loss: 0.7197 (0.7250)  time: 0.1916  data: 0.0001  max mem: 14938
[19:52:57.851928] Test:  [250/345]  eta: 0:00:17  loss: 0.7184 (0.7250)  time: 0.1918  data: 0.0001  max mem: 14938
[19:52:59.777114] Test:  [260/345]  eta: 0:00:16  loss: 0.7138 (0.7247)  time: 0.1922  data: 0.0001  max mem: 14938
[19:53:01.703735] Test:  [270/345]  eta: 0:00:14  loss: 0.7258 (0.7250)  time: 0.1925  data: 0.0001  max mem: 14938
[19:53:03.635490] Test:  [280/345]  eta: 0:00:12  loss: 0.7269 (0.7251)  time: 0.1929  data: 0.0001  max mem: 14938
[19:53:05.569603] Test:  [290/345]  eta: 0:00:10  loss: 0.7240 (0.7251)  time: 0.1932  data: 0.0001  max mem: 14938
[19:53:07.506867] Test:  [300/345]  eta: 0:00:08  loss: 0.7146 (0.7249)  time: 0.1935  data: 0.0001  max mem: 14938
[19:53:09.448050] Test:  [310/345]  eta: 0:00:06  loss: 0.7133 (0.7248)  time: 0.1939  data: 0.0001  max mem: 14938
[19:53:11.390908] Test:  [320/345]  eta: 0:00:04  loss: 0.7136 (0.7246)  time: 0.1942  data: 0.0001  max mem: 14938
[19:53:13.335442] Test:  [330/345]  eta: 0:00:02  loss: 0.7209 (0.7250)  time: 0.1943  data: 0.0001  max mem: 14938
[19:53:15.286175] Test:  [340/345]  eta: 0:00:00  loss: 0.7280 (0.7252)  time: 0.1947  data: 0.0001  max mem: 14938
[19:53:16.068041] Test:  [344/345]  eta: 0:00:00  loss: 0.7240 (0.7252)  time: 0.1949  data: 0.0001  max mem: 14938
[19:53:16.124608] Test: Total time: 0:01:05 (0.1900 s / it)
[19:53:26.516561] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8368 (0.8368)  time: 0.3217  data: 0.1421  max mem: 14938
[19:53:28.335031] Test:  [10/57]  eta: 0:00:09  loss: 0.8679 (0.8702)  time: 0.1945  data: 0.0130  max mem: 14938
[19:53:30.155467] Test:  [20/57]  eta: 0:00:06  loss: 0.8679 (0.8584)  time: 0.1819  data: 0.0001  max mem: 14938
[19:53:31.979801] Test:  [30/57]  eta: 0:00:05  loss: 0.7553 (0.8201)  time: 0.1822  data: 0.0001  max mem: 14938
[19:53:33.811576] Test:  [40/57]  eta: 0:00:03  loss: 0.7450 (0.7997)  time: 0.1828  data: 0.0001  max mem: 14938
[19:53:35.647315] Test:  [50/57]  eta: 0:00:01  loss: 0.7411 (0.7930)  time: 0.1833  data: 0.0001  max mem: 14938
[19:53:36.636526] Test:  [56/57]  eta: 0:00:00  loss: 0.7547 (0.7992)  time: 0.1779  data: 0.0001  max mem: 14938
[19:53:36.694423] Test: Total time: 0:00:10 (0.1842 s / it)
[19:53:38.430035] Dice score of the network on the train images: 0.798555, val images: 0.817528
[19:53:38.434768] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:53:39.318153] Epoch: [25]  [  0/345]  eta: 0:05:04  lr: 0.000117  loss: 0.7467 (0.7467)  time: 0.8823  data: 0.1414  max mem: 14938
[19:53:54.208645] Epoch: [25]  [ 20/345]  eta: 0:04:04  lr: 0.000116  loss: 0.7574 (0.7533)  time: 0.7445  data: 0.0001  max mem: 14938
[19:54:09.140144] Epoch: [25]  [ 40/345]  eta: 0:03:48  lr: 0.000116  loss: 0.7433 (0.7508)  time: 0.7465  data: 0.0001  max mem: 14938
[19:54:24.100151] Epoch: [25]  [ 60/345]  eta: 0:03:33  lr: 0.000116  loss: 0.7496 (0.7517)  time: 0.7480  data: 0.0001  max mem: 14938
[19:54:39.079498] Epoch: [25]  [ 80/345]  eta: 0:03:18  lr: 0.000116  loss: 0.7526 (0.7519)  time: 0.7489  data: 0.0001  max mem: 14938
[19:54:54.071621] Epoch: [25]  [100/345]  eta: 0:03:03  lr: 0.000116  loss: 0.7454 (0.7512)  time: 0.7496  data: 0.0001  max mem: 14938
[19:55:09.089581] Epoch: [25]  [120/345]  eta: 0:02:48  lr: 0.000115  loss: 0.7531 (0.7513)  time: 0.7509  data: 0.0001  max mem: 14938
[19:55:24.107031] Epoch: [25]  [140/345]  eta: 0:02:33  lr: 0.000115  loss: 0.7569 (0.7525)  time: 0.7508  data: 0.0001  max mem: 14938
[19:55:39.125052] Epoch: [25]  [160/345]  eta: 0:02:18  lr: 0.000115  loss: 0.7517 (0.7528)  time: 0.7509  data: 0.0001  max mem: 14938
[19:55:54.138613] Epoch: [25]  [180/345]  eta: 0:02:03  lr: 0.000115  loss: 0.7749 (0.7548)  time: 0.7506  data: 0.0001  max mem: 14938
[19:56:09.139941] Epoch: [25]  [200/345]  eta: 0:01:48  lr: 0.000115  loss: 0.7534 (0.7548)  time: 0.7500  data: 0.0001  max mem: 14938
[19:56:24.140604] Epoch: [25]  [220/345]  eta: 0:01:33  lr: 0.000114  loss: 0.7463 (0.7544)  time: 0.7500  data: 0.0001  max mem: 14938
[19:56:39.136266] Epoch: [25]  [240/345]  eta: 0:01:18  lr: 0.000114  loss: 0.7459 (0.7540)  time: 0.7497  data: 0.0001  max mem: 14938
[19:56:54.130668] Epoch: [25]  [260/345]  eta: 0:01:03  lr: 0.000114  loss: 0.7538 (0.7541)  time: 0.7497  data: 0.0001  max mem: 14938
[19:57:09.124690] Epoch: [25]  [280/345]  eta: 0:00:48  lr: 0.000114  loss: 0.7572 (0.7543)  time: 0.7497  data: 0.0001  max mem: 14938
[19:57:24.121064] Epoch: [25]  [300/345]  eta: 0:00:33  lr: 0.000114  loss: 0.7629 (0.7551)  time: 0.7498  data: 0.0001  max mem: 14938
[19:57:39.100368] Epoch: [25]  [320/345]  eta: 0:00:18  lr: 0.000113  loss: 0.7597 (0.7554)  time: 0.7489  data: 0.0001  max mem: 14938
[19:57:54.085947] Epoch: [25]  [340/345]  eta: 0:00:03  lr: 0.000113  loss: 0.7489 (0.7552)  time: 0.7492  data: 0.0001  max mem: 14938
[19:57:57.080917] Epoch: [25]  [344/345]  eta: 0:00:00  lr: 0.000113  loss: 0.7537 (0.7553)  time: 0.7490  data: 0.0001  max mem: 14938
[19:57:57.141134] Epoch: [25] Total time: 0:04:18 (0.7499 s / it)
[19:57:57.141591] Averaged stats: lr: 0.000113  loss: 0.7537 (0.7553)
[19:57:57.475909] Test:  [  0/345]  eta: 0:01:53  loss: 0.6937 (0.6937)  time: 0.3301  data: 0.1486  max mem: 14938
[19:57:59.313022] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7514 (0.7467)  time: 0.1969  data: 0.0136  max mem: 14938
[19:58:01.152874] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7416 (0.7435)  time: 0.1838  data: 0.0001  max mem: 14938
[19:58:02.996552] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7384 (0.7403)  time: 0.1841  data: 0.0001  max mem: 14938
[19:58:04.843295] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7405 (0.7426)  time: 0.1845  data: 0.0001  max mem: 14938
[19:58:06.693179] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7389 (0.7420)  time: 0.1848  data: 0.0001  max mem: 14938
[19:58:08.547513] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7368 (0.7424)  time: 0.1852  data: 0.0001  max mem: 14938
[19:58:10.404549] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7404 (0.7428)  time: 0.1855  data: 0.0001  max mem: 14938
[19:58:12.265593] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7434 (0.7428)  time: 0.1859  data: 0.0001  max mem: 14938
[19:58:14.129562] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7434 (0.7432)  time: 0.1862  data: 0.0001  max mem: 14938
[19:58:15.996512] Test:  [100/345]  eta: 0:00:45  loss: 0.7405 (0.7426)  time: 0.1865  data: 0.0001  max mem: 14938
[19:58:17.868277] Test:  [110/345]  eta: 0:00:43  loss: 0.7442 (0.7437)  time: 0.1869  data: 0.0001  max mem: 14938
[19:58:19.742346] Test:  [120/345]  eta: 0:00:42  loss: 0.7545 (0.7438)  time: 0.1872  data: 0.0001  max mem: 14938
[19:58:21.620741] Test:  [130/345]  eta: 0:00:40  loss: 0.7384 (0.7433)  time: 0.1876  data: 0.0001  max mem: 14938
[19:58:23.502777] Test:  [140/345]  eta: 0:00:38  loss: 0.7404 (0.7438)  time: 0.1880  data: 0.0001  max mem: 14938
[19:58:25.387510] Test:  [150/345]  eta: 0:00:36  loss: 0.7464 (0.7437)  time: 0.1883  data: 0.0001  max mem: 14938
[19:58:27.274016] Test:  [160/345]  eta: 0:00:34  loss: 0.7452 (0.7436)  time: 0.1885  data: 0.0001  max mem: 14938
[19:58:29.165608] Test:  [170/345]  eta: 0:00:32  loss: 0.7452 (0.7438)  time: 0.1889  data: 0.0001  max mem: 14938
[19:58:31.059832] Test:  [180/345]  eta: 0:00:30  loss: 0.7438 (0.7438)  time: 0.1892  data: 0.0001  max mem: 14938
[19:58:32.958992] Test:  [190/345]  eta: 0:00:29  loss: 0.7411 (0.7439)  time: 0.1896  data: 0.0001  max mem: 14938
[19:58:34.860497] Test:  [200/345]  eta: 0:00:27  loss: 0.7449 (0.7442)  time: 0.1900  data: 0.0001  max mem: 14938
[19:58:36.767249] Test:  [210/345]  eta: 0:00:25  loss: 0.7393 (0.7440)  time: 0.1904  data: 0.0001  max mem: 14938
[19:58:38.677577] Test:  [220/345]  eta: 0:00:23  loss: 0.7366 (0.7441)  time: 0.1908  data: 0.0001  max mem: 14938
[19:58:40.591095] Test:  [230/345]  eta: 0:00:21  loss: 0.7423 (0.7444)  time: 0.1911  data: 0.0001  max mem: 14938
[19:58:42.508152] Test:  [240/345]  eta: 0:00:19  loss: 0.7505 (0.7447)  time: 0.1915  data: 0.0001  max mem: 14938
[19:58:44.430920] Test:  [250/345]  eta: 0:00:17  loss: 0.7501 (0.7448)  time: 0.1919  data: 0.0001  max mem: 14938
[19:58:46.356725] Test:  [260/345]  eta: 0:00:16  loss: 0.7453 (0.7449)  time: 0.1923  data: 0.0001  max mem: 14938
[19:58:48.287147] Test:  [270/345]  eta: 0:00:14  loss: 0.7418 (0.7447)  time: 0.1928  data: 0.0001  max mem: 14938
[19:58:50.219641] Test:  [280/345]  eta: 0:00:12  loss: 0.7419 (0.7449)  time: 0.1931  data: 0.0001  max mem: 14938
[19:58:52.154886] Test:  [290/345]  eta: 0:00:10  loss: 0.7484 (0.7450)  time: 0.1933  data: 0.0001  max mem: 14938
[19:58:54.093618] Test:  [300/345]  eta: 0:00:08  loss: 0.7426 (0.7446)  time: 0.1936  data: 0.0001  max mem: 14938
[19:58:56.036010] Test:  [310/345]  eta: 0:00:06  loss: 0.7398 (0.7446)  time: 0.1940  data: 0.0001  max mem: 14938
[19:58:57.980441] Test:  [320/345]  eta: 0:00:04  loss: 0.7388 (0.7444)  time: 0.1943  data: 0.0001  max mem: 14938
[19:58:59.929476] Test:  [330/345]  eta: 0:00:02  loss: 0.7386 (0.7444)  time: 0.1946  data: 0.0001  max mem: 14938
[19:59:01.880625] Test:  [340/345]  eta: 0:00:00  loss: 0.7507 (0.7445)  time: 0.1950  data: 0.0001  max mem: 14938
[19:59:02.662520] Test:  [344/345]  eta: 0:00:00  loss: 0.7509 (0.7446)  time: 0.1951  data: 0.0001  max mem: 14938
[19:59:02.722408] Test: Total time: 0:01:05 (0.1901 s / it)
[19:59:13.127650] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8965 (0.8965)  time: 0.3204  data: 0.1408  max mem: 14938
[19:59:14.944275] Test:  [10/57]  eta: 0:00:09  loss: 0.8981 (0.9043)  time: 0.1942  data: 0.0129  max mem: 14938
[19:59:16.765402] Test:  [20/57]  eta: 0:00:06  loss: 0.9137 (0.8963)  time: 0.1818  data: 0.0001  max mem: 14938
[19:59:18.591302] Test:  [30/57]  eta: 0:00:05  loss: 0.7923 (0.8553)  time: 0.1823  data: 0.0001  max mem: 14938
[19:59:20.421727] Test:  [40/57]  eta: 0:00:03  loss: 0.7558 (0.8316)  time: 0.1828  data: 0.0001  max mem: 14938
[19:59:22.257813] Test:  [50/57]  eta: 0:00:01  loss: 0.7633 (0.8261)  time: 0.1833  data: 0.0001  max mem: 14938
[19:59:23.247753] Test:  [56/57]  eta: 0:00:00  loss: 0.8150 (0.8334)  time: 0.1779  data: 0.0001  max mem: 14938
[19:59:23.306541] Test: Total time: 0:00:10 (0.1842 s / it)
[19:59:25.059831] Dice score of the network on the train images: 0.802155, val images: 0.779196
[19:59:25.063509] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:59:25.946092] Epoch: [26]  [  0/345]  eta: 0:05:04  lr: 0.000113  loss: 0.7437 (0.7437)  time: 0.8817  data: 0.1405  max mem: 14938

[19:59:40.825794] Epoch: [26]  [ 20/345]  eta: 0:04:03  lr: 0.000113  loss: 0.7713 (0.7665)  time: 0.7439  data: 0.0001  max mem: 14938
[19:59:55.745242] Epoch: [26]  [ 40/345]  eta: 0:03:48  lr: 0.000113  loss: 0.7525 (0.7610)  time: 0.7459  data: 0.0001  max mem: 14938
[20:00:10.692460] Epoch: [26]  [ 60/345]  eta: 0:03:33  lr: 0.000112  loss: 0.7587 (0.7602)  time: 0.7473  data: 0.0001  max mem: 14938
[20:00:25.660360] Epoch: [26]  [ 80/345]  eta: 0:03:18  lr: 0.000112  loss: 0.7397 (0.7568)  time: 0.7484  data: 0.0001  max mem: 14938
[20:00:40.644294] Epoch: [26]  [100/345]  eta: 0:03:03  lr: 0.000112  loss: 0.7425 (0.7549)  time: 0.7492  data: 0.0001  max mem: 14938
[20:00:55.658833] Epoch: [26]  [120/345]  eta: 0:02:48  lr: 0.000112  loss: 0.7473 (0.7545)  time: 0.7507  data: 0.0001  max mem: 14938
[20:01:10.671606] Epoch: [26]  [140/345]  eta: 0:02:33  lr: 0.000111  loss: 0.7450 (0.7530)  time: 0.7506  data: 0.0001  max mem: 14938
[20:01:25.688023] Epoch: [26]  [160/345]  eta: 0:02:18  lr: 0.000111  loss: 0.7468 (0.7525)  time: 0.7508  data: 0.0001  max mem: 14938
[20:01:40.702425] Epoch: [26]  [180/345]  eta: 0:02:03  lr: 0.000111  loss: 0.7457 (0.7516)  time: 0.7507  data: 0.0001  max mem: 14938
[20:01:55.692755] Epoch: [26]  [200/345]  eta: 0:01:48  lr: 0.000111  loss: 0.7593 (0.7522)  time: 0.7495  data: 0.0001  max mem: 14938
[20:02:10.678329] Epoch: [26]  [220/345]  eta: 0:01:33  lr: 0.000110  loss: 0.7496 (0.7521)  time: 0.7492  data: 0.0001  max mem: 14938
[20:02:25.652759] Epoch: [26]  [240/345]  eta: 0:01:18  lr: 0.000110  loss: 0.7529 (0.7522)  time: 0.7487  data: 0.0001  max mem: 14938
[20:02:40.626629] Epoch: [26]  [260/345]  eta: 0:01:03  lr: 0.000110  loss: 0.7440 (0.7517)  time: 0.7487  data: 0.0001  max mem: 14938
[20:02:55.595809] Epoch: [26]  [280/345]  eta: 0:00:48  lr: 0.000110  loss: 0.7525 (0.7514)  time: 0.7484  data: 0.0001  max mem: 14938
[20:03:10.562714] Epoch: [26]  [300/345]  eta: 0:00:33  lr: 0.000110  loss: 0.7412 (0.7512)  time: 0.7483  data: 0.0001  max mem: 14938
[20:03:25.529006] Epoch: [26]  [320/345]  eta: 0:00:18  lr: 0.000109  loss: 0.7471 (0.7509)  time: 0.7483  data: 0.0001  max mem: 14938
[20:03:40.495296] Epoch: [26]  [340/345]  eta: 0:00:03  lr: 0.000109  loss: 0.7454 (0.7507)  time: 0.7483  data: 0.0001  max mem: 14938
[20:03:43.489954] Epoch: [26]  [344/345]  eta: 0:00:00  lr: 0.000109  loss: 0.7469 (0.7506)  time: 0.7483  data: 0.0001  max mem: 14938
[20:03:43.555989] Epoch: [26] Total time: 0:04:18 (0.7493 s / it)
[20:03:43.556495] Averaged stats: lr: 0.000109  loss: 0.7469 (0.7506)
[20:03:43.894100] Test:  [  0/345]  eta: 0:01:54  loss: 0.7253 (0.7253)  time: 0.3333  data: 0.1515  max mem: 14938
[20:03:45.733840] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7275 (0.7297)  time: 0.1975  data: 0.0138  max mem: 14938
[20:03:47.573400] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7275 (0.7285)  time: 0.1839  data: 0.0001  max mem: 14938
[20:03:49.417873] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7196 (0.7253)  time: 0.1842  data: 0.0001  max mem: 14938
[20:03:51.266201] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7150 (0.7231)  time: 0.1846  data: 0.0001  max mem: 14938
[20:03:53.117255] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7252 (0.7248)  time: 0.1849  data: 0.0001  max mem: 14938
[20:03:54.971871] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7276 (0.7250)  time: 0.1852  data: 0.0001  max mem: 14938
[20:03:56.829489] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7260 (0.7252)  time: 0.1856  data: 0.0001  max mem: 14938
[20:03:58.691851] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7269 (0.7250)  time: 0.1860  data: 0.0001  max mem: 14938
[20:04:00.556736] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7223 (0.7244)  time: 0.1863  data: 0.0001  max mem: 14938
[20:04:02.424397] Test:  [100/345]  eta: 0:00:45  loss: 0.7225 (0.7251)  time: 0.1866  data: 0.0001  max mem: 14938
[20:04:04.295092] Test:  [110/345]  eta: 0:00:43  loss: 0.7276 (0.7255)  time: 0.1869  data: 0.0001  max mem: 14938
[20:04:06.170366] Test:  [120/345]  eta: 0:00:42  loss: 0.7233 (0.7251)  time: 0.1873  data: 0.0001  max mem: 14938
[20:04:08.048580] Test:  [130/345]  eta: 0:00:40  loss: 0.7228 (0.7255)  time: 0.1876  data: 0.0001  max mem: 14938
[20:04:09.930706] Test:  [140/345]  eta: 0:00:38  loss: 0.7275 (0.7256)  time: 0.1880  data: 0.0001  max mem: 14938
[20:04:11.816915] Test:  [150/345]  eta: 0:00:36  loss: 0.7275 (0.7263)  time: 0.1884  data: 0.0001  max mem: 14938
[20:04:13.706332] Test:  [160/345]  eta: 0:00:34  loss: 0.7191 (0.7254)  time: 0.1887  data: 0.0001  max mem: 14938
[20:04:15.595912] Test:  [170/345]  eta: 0:00:32  loss: 0.7148 (0.7251)  time: 0.1889  data: 0.0001  max mem: 14938
[20:04:17.494580] Test:  [180/345]  eta: 0:00:30  loss: 0.7198 (0.7252)  time: 0.1894  data: 0.0001  max mem: 14938
[20:04:19.395523] Test:  [190/345]  eta: 0:00:29  loss: 0.7195 (0.7249)  time: 0.1899  data: 0.0001  max mem: 14938
[20:04:21.297053] Test:  [200/345]  eta: 0:00:27  loss: 0.7158 (0.7247)  time: 0.1901  data: 0.0001  max mem: 14938
[20:04:23.204870] Test:  [210/345]  eta: 0:00:25  loss: 0.7198 (0.7248)  time: 0.1904  data: 0.0001  max mem: 14938
[20:04:25.113577] Test:  [220/345]  eta: 0:00:23  loss: 0.7213 (0.7247)  time: 0.1908  data: 0.0001  max mem: 14938
[20:04:27.028456] Test:  [230/345]  eta: 0:00:21  loss: 0.7213 (0.7246)  time: 0.1911  data: 0.0001  max mem: 14938
[20:04:28.947306] Test:  [240/345]  eta: 0:00:19  loss: 0.7206 (0.7246)  time: 0.1916  data: 0.0001  max mem: 14938
[20:04:30.868409] Test:  [250/345]  eta: 0:00:17  loss: 0.7193 (0.7245)  time: 0.1919  data: 0.0001  max mem: 14938
[20:04:32.795276] Test:  [260/345]  eta: 0:00:16  loss: 0.7201 (0.7244)  time: 0.1923  data: 0.0001  max mem: 14938
[20:04:34.725387] Test:  [270/345]  eta: 0:00:14  loss: 0.7211 (0.7244)  time: 0.1928  data: 0.0001  max mem: 14938
[20:04:36.656744] Test:  [280/345]  eta: 0:00:12  loss: 0.7244 (0.7245)  time: 0.1930  data: 0.0001  max mem: 14938
[20:04:38.590543] Test:  [290/345]  eta: 0:00:10  loss: 0.7205 (0.7243)  time: 0.1932  data: 0.0001  max mem: 14938
[20:04:40.529568] Test:  [300/345]  eta: 0:00:08  loss: 0.7224 (0.7244)  time: 0.1936  data: 0.0001  max mem: 14938
[20:04:42.471901] Test:  [310/345]  eta: 0:00:06  loss: 0.7230 (0.7245)  time: 0.1940  data: 0.0001  max mem: 14938
[20:04:44.415213] Test:  [320/345]  eta: 0:00:04  loss: 0.7250 (0.7246)  time: 0.1942  data: 0.0001  max mem: 14938
[20:04:46.362751] Test:  [330/345]  eta: 0:00:02  loss: 0.7216 (0.7245)  time: 0.1945  data: 0.0001  max mem: 14938
[20:04:48.312591] Test:  [340/345]  eta: 0:00:00  loss: 0.7181 (0.7244)  time: 0.1948  data: 0.0001  max mem: 14938
[20:04:49.093886] Test:  [344/345]  eta: 0:00:00  loss: 0.7182 (0.7242)  time: 0.1950  data: 0.0001  max mem: 14938
[20:04:49.151375] Test: Total time: 0:01:05 (0.1901 s / it)
[20:04:59.486758] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8315 (0.8315)  time: 0.3207  data: 0.1404  max mem: 14938
[20:05:01.305014] Test:  [10/57]  eta: 0:00:09  loss: 0.8634 (0.8710)  time: 0.1944  data: 0.0128  max mem: 14938
[20:05:03.128111] Test:  [20/57]  eta: 0:00:06  loss: 0.8634 (0.8585)  time: 0.1820  data: 0.0001  max mem: 14938
[20:05:04.953968] Test:  [30/57]  eta: 0:00:05  loss: 0.7500 (0.8199)  time: 0.1824  data: 0.0001  max mem: 14938
[20:05:06.785710] Test:  [40/57]  eta: 0:00:03  loss: 0.7435 (0.8001)  time: 0.1828  data: 0.0001  max mem: 14938
[20:05:08.621326] Test:  [50/57]  eta: 0:00:01  loss: 0.7321 (0.7936)  time: 0.1833  data: 0.0001  max mem: 14938
[20:05:09.611819] Test:  [56/57]  eta: 0:00:00  loss: 0.7639 (0.8002)  time: 0.1779  data: 0.0001  max mem: 14938
[20:05:09.665137] Test: Total time: 0:00:10 (0.1842 s / it)
[20:05:11.462642] Dice score of the network on the train images: 0.805637, val images: 0.817120
[20:05:11.466338] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:05:12.354027] Epoch: [27]  [  0/345]  eta: 0:05:05  lr: 0.000109  loss: 0.7747 (0.7747)  time: 0.8869  data: 0.1465  max mem: 14938
[20:05:27.228138] Epoch: [27]  [ 20/345]  eta: 0:04:03  lr: 0.000109  loss: 0.7415 (0.7466)  time: 0.7437  data: 0.0001  max mem: 14938
[20:05:42.152717] Epoch: [27]  [ 40/345]  eta: 0:03:48  lr: 0.000108  loss: 0.7390 (0.7448)  time: 0.7462  data: 0.0001  max mem: 14938
[20:05:57.109691] Epoch: [27]  [ 60/345]  eta: 0:03:33  lr: 0.000108  loss: 0.7386 (0.7439)  time: 0.7478  data: 0.0001  max mem: 14938
[20:06:12.075638] Epoch: [27]  [ 80/345]  eta: 0:03:18  lr: 0.000108  loss: 0.7446 (0.7447)  time: 0.7483  data: 0.0001  max mem: 14938
[20:06:27.068201] Epoch: [27]  [100/345]  eta: 0:03:03  lr: 0.000108  loss: 0.7435 (0.7447)  time: 0.7496  data: 0.0001  max mem: 14938
[20:06:42.074464] Epoch: [27]  [120/345]  eta: 0:02:48  lr: 0.000107  loss: 0.7353 (0.7447)  time: 0.7503  data: 0.0001  max mem: 14938
[20:06:57.079241] Epoch: [27]  [140/345]  eta: 0:02:33  lr: 0.000107  loss: 0.7373 (0.7439)  time: 0.7502  data: 0.0001  max mem: 14938
[20:07:12.076188] Epoch: [27]  [160/345]  eta: 0:02:18  lr: 0.000107  loss: 0.7382 (0.7435)  time: 0.7498  data: 0.0001  max mem: 14938
[20:07:27.068356] Epoch: [27]  [180/345]  eta: 0:02:03  lr: 0.000107  loss: 0.7393 (0.7430)  time: 0.7496  data: 0.0001  max mem: 14938
[20:07:42.061033] Epoch: [27]  [200/345]  eta: 0:01:48  lr: 0.000106  loss: 0.7387 (0.7429)  time: 0.7496  data: 0.0001  max mem: 14938
[20:07:57.043096] Epoch: [27]  [220/345]  eta: 0:01:33  lr: 0.000106  loss: 0.7407 (0.7429)  time: 0.7491  data: 0.0001  max mem: 14938
[20:08:12.023341] Epoch: [27]  [240/345]  eta: 0:01:18  lr: 0.000106  loss: 0.7493 (0.7437)  time: 0.7490  data: 0.0001  max mem: 14938
[20:08:26.993723] Epoch: [27]  [260/345]  eta: 0:01:03  lr: 0.000106  loss: 0.7594 (0.7453)  time: 0.7485  data: 0.0001  max mem: 14938
[20:08:41.969886] Epoch: [27]  [280/345]  eta: 0:00:48  lr: 0.000105  loss: 0.7536 (0.7459)  time: 0.7488  data: 0.0001  max mem: 14938
[20:08:57.023918] Epoch: [27]  [300/345]  eta: 0:00:33  lr: 0.000105  loss: 0.7408 (0.7458)  time: 0.7527  data: 0.0001  max mem: 14938
[20:09:11.993531] Epoch: [27]  [320/345]  eta: 0:00:18  lr: 0.000105  loss: 0.7368 (0.7456)  time: 0.7484  data: 0.0001  max mem: 14938
[20:09:26.964171] Epoch: [27]  [340/345]  eta: 0:00:03  lr: 0.000104  loss: 0.7609 (0.7466)  time: 0.7485  data: 0.0001  max mem: 14938
[20:09:29.955566] Epoch: [27]  [344/345]  eta: 0:00:00  lr: 0.000104  loss: 0.7621 (0.7469)  time: 0.7482  data: 0.0001  max mem: 14938
[20:09:30.021033] Epoch: [27] Total time: 0:04:18 (0.7494 s / it)
[20:09:30.021482] Averaged stats: lr: 0.000104  loss: 0.7621 (0.7469)
[20:09:30.358619] Test:  [  0/345]  eta: 0:01:54  loss: 0.7406 (0.7406)  time: 0.3333  data: 0.1514  max mem: 14938
[20:09:32.197224] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7475 (0.7461)  time: 0.1974  data: 0.0138  max mem: 14938
[20:09:34.038421] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7407 (0.7392)  time: 0.1839  data: 0.0001  max mem: 14938
[20:09:35.882640] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7333 (0.7387)  time: 0.1842  data: 0.0001  max mem: 14938
[20:09:37.729522] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7326 (0.7378)  time: 0.1845  data: 0.0001  max mem: 14938
[20:09:39.580927] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7414 (0.7393)  time: 0.1849  data: 0.0001  max mem: 14938
[20:09:41.436465] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7377 (0.7391)  time: 0.1853  data: 0.0001  max mem: 14938
[20:09:43.295327] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7377 (0.7396)  time: 0.1857  data: 0.0001  max mem: 14938
[20:09:45.158435] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7413 (0.7401)  time: 0.1860  data: 0.0001  max mem: 14938
[20:09:47.025369] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7413 (0.7404)  time: 0.1865  data: 0.0001  max mem: 14938
[20:09:48.893540] Test:  [100/345]  eta: 0:00:45  loss: 0.7444 (0.7411)  time: 0.1867  data: 0.0001  max mem: 14938
[20:09:50.764517] Test:  [110/345]  eta: 0:00:43  loss: 0.7422 (0.7410)  time: 0.1869  data: 0.0001  max mem: 14938
[20:09:52.640518] Test:  [120/345]  eta: 0:00:42  loss: 0.7379 (0.7412)  time: 0.1873  data: 0.0001  max mem: 14938
[20:09:54.519289] Test:  [130/345]  eta: 0:00:40  loss: 0.7415 (0.7415)  time: 0.1877  data: 0.0001  max mem: 14938
[20:09:56.401379] Test:  [140/345]  eta: 0:00:38  loss: 0.7449 (0.7416)  time: 0.1880  data: 0.0001  max mem: 14938
[20:09:58.286135] Test:  [150/345]  eta: 0:00:36  loss: 0.7359 (0.7412)  time: 0.1883  data: 0.0001  max mem: 14938
[20:10:00.173839] Test:  [160/345]  eta: 0:00:34  loss: 0.7327 (0.7411)  time: 0.1886  data: 0.0001  max mem: 14938
[20:10:02.064431] Test:  [170/345]  eta: 0:00:32  loss: 0.7339 (0.7408)  time: 0.1889  data: 0.0001  max mem: 14938
[20:10:03.961760] Test:  [180/345]  eta: 0:00:30  loss: 0.7314 (0.7403)  time: 0.1893  data: 0.0001  max mem: 14938
[20:10:05.863091] Test:  [190/345]  eta: 0:00:29  loss: 0.7312 (0.7400)  time: 0.1899  data: 0.0001  max mem: 14938
[20:10:07.767284] Test:  [200/345]  eta: 0:00:27  loss: 0.7312 (0.7399)  time: 0.1902  data: 0.0001  max mem: 14938
[20:10:09.673836] Test:  [210/345]  eta: 0:00:25  loss: 0.7315 (0.7398)  time: 0.1905  data: 0.0001  max mem: 14938
[20:10:11.584360] Test:  [220/345]  eta: 0:00:23  loss: 0.7383 (0.7400)  time: 0.1908  data: 0.0001  max mem: 14938
[20:10:13.499044] Test:  [230/345]  eta: 0:00:21  loss: 0.7455 (0.7404)  time: 0.1912  data: 0.0001  max mem: 14938
[20:10:15.418267] Test:  [240/345]  eta: 0:00:19  loss: 0.7497 (0.7403)  time: 0.1916  data: 0.0001  max mem: 14938
[20:10:17.340944] Test:  [250/345]  eta: 0:00:17  loss: 0.7407 (0.7403)  time: 0.1920  data: 0.0001  max mem: 14938
[20:10:19.264864] Test:  [260/345]  eta: 0:00:16  loss: 0.7329 (0.7399)  time: 0.1923  data: 0.0001  max mem: 14938
[20:10:21.194664] Test:  [270/345]  eta: 0:00:14  loss: 0.7318 (0.7399)  time: 0.1926  data: 0.0001  max mem: 14938
[20:10:23.126065] Test:  [280/345]  eta: 0:00:12  loss: 0.7366 (0.7399)  time: 0.1930  data: 0.0001  max mem: 14938
[20:10:25.062073] Test:  [290/345]  eta: 0:00:10  loss: 0.7400 (0.7400)  time: 0.1933  data: 0.0001  max mem: 14938
[20:10:27.001236] Test:  [300/345]  eta: 0:00:08  loss: 0.7400 (0.7399)  time: 0.1937  data: 0.0001  max mem: 14938
[20:10:28.942577] Test:  [310/345]  eta: 0:00:06  loss: 0.7442 (0.7403)  time: 0.1940  data: 0.0001  max mem: 14938
[20:10:30.886605] Test:  [320/345]  eta: 0:00:04  loss: 0.7442 (0.7405)  time: 0.1942  data: 0.0001  max mem: 14938
[20:10:32.834997] Test:  [330/345]  eta: 0:00:02  loss: 0.7400 (0.7406)  time: 0.1946  data: 0.0001  max mem: 14938
[20:10:34.785989] Test:  [340/345]  eta: 0:00:00  loss: 0.7408 (0.7406)  time: 0.1949  data: 0.0001  max mem: 14938
[20:10:35.567962] Test:  [344/345]  eta: 0:00:00  loss: 0.7350 (0.7404)  time: 0.1951  data: 0.0001  max mem: 14938
[20:10:35.627853] Test: Total time: 0:01:05 (0.1902 s / it)
[20:10:45.913199] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8471 (0.8471)  time: 0.3220  data: 0.1420  max mem: 14938
[20:10:47.730804] Test:  [10/57]  eta: 0:00:09  loss: 0.8671 (0.8771)  time: 0.1944  data: 0.0130  max mem: 14938
[20:10:49.554290] Test:  [20/57]  eta: 0:00:06  loss: 0.8892 (0.8742)  time: 0.1820  data: 0.0001  max mem: 14938
[20:10:51.381723] Test:  [30/57]  eta: 0:00:05  loss: 0.7595 (0.8354)  time: 0.1825  data: 0.0001  max mem: 14938
[20:10:53.212308] Test:  [40/57]  eta: 0:00:03  loss: 0.7501 (0.8141)  time: 0.1829  data: 0.0001  max mem: 14938
[20:10:55.048087] Test:  [50/57]  eta: 0:00:01  loss: 0.7445 (0.8074)  time: 0.1833  data: 0.0001  max mem: 14938
[20:10:56.038661] Test:  [56/57]  eta: 0:00:00  loss: 0.7856 (0.8136)  time: 0.1779  data: 0.0001  max mem: 14938
[20:10:56.098394] Test: Total time: 0:00:10 (0.1843 s / it)
[20:10:57.862048] Dice score of the network on the train images: 0.775469, val images: 0.804095
[20:10:57.865763] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:10:58.756272] Epoch: [28]  [  0/345]  eta: 0:05:06  lr: 0.000104  loss: 0.7733 (0.7733)  time: 0.8897  data: 0.1489  max mem: 14938
[20:11:13.646905] Epoch: [28]  [ 20/345]  eta: 0:04:04  lr: 0.000104  loss: 0.7535 (0.7581)  time: 0.7445  data: 0.0001  max mem: 14938
[20:11:28.601617] Epoch: [28]  [ 40/345]  eta: 0:03:48  lr: 0.000104  loss: 0.7570 (0.7572)  time: 0.7477  data: 0.0001  max mem: 14938
[20:11:43.573137] Epoch: [28]  [ 60/345]  eta: 0:03:33  lr: 0.000103  loss: 0.7471 (0.7552)  time: 0.7485  data: 0.0001  max mem: 14938
[20:11:58.563515] Epoch: [28]  [ 80/345]  eta: 0:03:18  lr: 0.000103  loss: 0.7510 (0.7541)  time: 0.7495  data: 0.0001  max mem: 14938
[20:12:13.577686] Epoch: [28]  [100/345]  eta: 0:03:03  lr: 0.000103  loss: 0.7442 (0.7534)  time: 0.7507  data: 0.0001  max mem: 14938
[20:12:28.574829] Epoch: [28]  [120/345]  eta: 0:02:48  lr: 0.000103  loss: 0.7471 (0.7533)  time: 0.7498  data: 0.0001  max mem: 14938
[20:12:43.583449] Epoch: [28]  [140/345]  eta: 0:02:33  lr: 0.000102  loss: 0.7728 (0.7561)  time: 0.7504  data: 0.0001  max mem: 14938
[20:12:58.583714] Epoch: [28]  [160/345]  eta: 0:02:18  lr: 0.000102  loss: 0.7577 (0.7565)  time: 0.7500  data: 0.0001  max mem: 14938
[20:13:13.576749] Epoch: [28]  [180/345]  eta: 0:02:03  lr: 0.000102  loss: 0.7608 (0.7567)  time: 0.7496  data: 0.0001  max mem: 14938
[20:13:28.564884] Epoch: [28]  [200/345]  eta: 0:01:48  lr: 0.000101  loss: 0.7557 (0.7565)  time: 0.7494  data: 0.0001  max mem: 14938
[20:13:43.549842] Epoch: [28]  [220/345]  eta: 0:01:33  lr: 0.000101  loss: 0.7491 (0.7559)  time: 0.7492  data: 0.0001  max mem: 14938
[20:13:58.528482] Epoch: [28]  [240/345]  eta: 0:01:18  lr: 0.000101  loss: 0.7474 (0.7555)  time: 0.7489  data: 0.0001  max mem: 14938
[20:14:13.510423] Epoch: [28]  [260/345]  eta: 0:01:03  lr: 0.000101  loss: 0.7585 (0.7556)  time: 0.7491  data: 0.0001  max mem: 14938
[20:14:28.482233] Epoch: [28]  [280/345]  eta: 0:00:48  lr: 0.000100  loss: 0.7523 (0.7552)  time: 0.7486  data: 0.0001  max mem: 14938
[20:14:43.453490] Epoch: [28]  [300/345]  eta: 0:00:33  lr: 0.000100  loss: 0.7370 (0.7544)  time: 0.7485  data: 0.0001  max mem: 14938
[20:14:58.419404] Epoch: [28]  [320/345]  eta: 0:00:18  lr: 0.000100  loss: 0.7501 (0.7542)  time: 0.7483  data: 0.0001  max mem: 14938
[20:15:13.407990] Epoch: [28]  [340/345]  eta: 0:00:03  lr: 0.000099  loss: 0.7464 (0.7540)  time: 0.7494  data: 0.0001  max mem: 14938
[20:15:16.407351] Epoch: [28]  [344/345]  eta: 0:00:00  lr: 0.000099  loss: 0.7463 (0.7538)  time: 0.7496  data: 0.0001  max mem: 14938
[20:15:16.471445] Epoch: [28] Total time: 0:04:18 (0.7496 s / it)
[20:15:16.471746] Averaged stats: lr: 0.000099  loss: 0.7463 (0.7538)
[20:15:16.816283] Test:  [  0/345]  eta: 0:01:57  loss: 0.7155 (0.7155)  time: 0.3402  data: 0.1585  max mem: 14938
[20:15:18.653607] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7221 (0.7238)  time: 0.1979  data: 0.0145  max mem: 14938
[20:15:20.494134] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7226 (0.7247)  time: 0.1838  data: 0.0001  max mem: 14938
[20:15:22.336632] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7229 (0.7258)  time: 0.1841  data: 0.0001  max mem: 14938
[20:15:24.182621] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7229 (0.7250)  time: 0.1844  data: 0.0001  max mem: 14938
[20:15:26.033888] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7194 (0.7238)  time: 0.1848  data: 0.0001  max mem: 14938
[20:15:27.889163] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7133 (0.7215)  time: 0.1853  data: 0.0001  max mem: 14938
[20:15:29.746415] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7184 (0.7214)  time: 0.1856  data: 0.0001  max mem: 14938
[20:15:31.607736] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7184 (0.7208)  time: 0.1859  data: 0.0001  max mem: 14938
[20:15:33.472577] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7139 (0.7202)  time: 0.1863  data: 0.0001  max mem: 14938
[20:15:35.340565] Test:  [100/345]  eta: 0:00:45  loss: 0.7208 (0.7209)  time: 0.1866  data: 0.0001  max mem: 14938
[20:15:37.211584] Test:  [110/345]  eta: 0:00:43  loss: 0.7253 (0.7209)  time: 0.1869  data: 0.0001  max mem: 14938
[20:15:39.085790] Test:  [120/345]  eta: 0:00:42  loss: 0.7141 (0.7207)  time: 0.1872  data: 0.0001  max mem: 14938
[20:15:40.965204] Test:  [130/345]  eta: 0:00:40  loss: 0.7222 (0.7213)  time: 0.1876  data: 0.0001  max mem: 14938
[20:15:42.848374] Test:  [140/345]  eta: 0:00:38  loss: 0.7194 (0.7209)  time: 0.1881  data: 0.0001  max mem: 14938
[20:15:44.733254] Test:  [150/345]  eta: 0:00:36  loss: 0.7146 (0.7204)  time: 0.1884  data: 0.0001  max mem: 14938
[20:15:46.620936] Test:  [160/345]  eta: 0:00:34  loss: 0.7150 (0.7206)  time: 0.1886  data: 0.0001  max mem: 14938
[20:15:48.512555] Test:  [170/345]  eta: 0:00:32  loss: 0.7232 (0.7210)  time: 0.1889  data: 0.0001  max mem: 14938
[20:15:50.409676] Test:  [180/345]  eta: 0:00:30  loss: 0.7228 (0.7212)  time: 0.1894  data: 0.0001  max mem: 14938
[20:15:52.311777] Test:  [190/345]  eta: 0:00:29  loss: 0.7192 (0.7207)  time: 0.1899  data: 0.0001  max mem: 14938
[20:15:54.213962] Test:  [200/345]  eta: 0:00:27  loss: 0.7183 (0.7206)  time: 0.1902  data: 0.0001  max mem: 14938
[20:15:56.123146] Test:  [210/345]  eta: 0:00:25  loss: 0.7194 (0.7208)  time: 0.1905  data: 0.0001  max mem: 14938
[20:15:58.033189] Test:  [220/345]  eta: 0:00:23  loss: 0.7213 (0.7208)  time: 0.1909  data: 0.0001  max mem: 14938
[20:15:59.947830] Test:  [230/345]  eta: 0:00:21  loss: 0.7243 (0.7209)  time: 0.1912  data: 0.0001  max mem: 14938
[20:16:01.866059] Test:  [240/345]  eta: 0:00:19  loss: 0.7263 (0.7211)  time: 0.1916  data: 0.0001  max mem: 14938
[20:16:03.787798] Test:  [250/345]  eta: 0:00:17  loss: 0.7224 (0.7212)  time: 0.1920  data: 0.0001  max mem: 14938
[20:16:05.711431] Test:  [260/345]  eta: 0:00:16  loss: 0.7130 (0.7208)  time: 0.1922  data: 0.0001  max mem: 14938
[20:16:07.638755] Test:  [270/345]  eta: 0:00:14  loss: 0.7088 (0.7204)  time: 0.1925  data: 0.0001  max mem: 14938
[20:16:09.569590] Test:  [280/345]  eta: 0:00:12  loss: 0.7115 (0.7204)  time: 0.1929  data: 0.0001  max mem: 14938
[20:16:11.503552] Test:  [290/345]  eta: 0:00:10  loss: 0.7186 (0.7206)  time: 0.1932  data: 0.0001  max mem: 14938
[20:16:13.443262] Test:  [300/345]  eta: 0:00:08  loss: 0.7175 (0.7203)  time: 0.1936  data: 0.0001  max mem: 14938
[20:16:15.383686] Test:  [310/345]  eta: 0:00:06  loss: 0.7113 (0.7202)  time: 0.1940  data: 0.0001  max mem: 14938
[20:16:17.327892] Test:  [320/345]  eta: 0:00:04  loss: 0.7155 (0.7202)  time: 0.1942  data: 0.0001  max mem: 14938
[20:16:19.274446] Test:  [330/345]  eta: 0:00:02  loss: 0.7159 (0.7202)  time: 0.1945  data: 0.0001  max mem: 14938
[20:16:21.225441] Test:  [340/345]  eta: 0:00:00  loss: 0.7182 (0.7202)  time: 0.1948  data: 0.0001  max mem: 14938
[20:16:22.007503] Test:  [344/345]  eta: 0:00:00  loss: 0.7161 (0.7202)  time: 0.1950  data: 0.0001  max mem: 14938
[20:16:22.067248] Test: Total time: 0:01:05 (0.1901 s / it)
[20:16:32.579497] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8629 (0.8629)  time: 0.3199  data: 0.1402  max mem: 14938
[20:16:34.396508] Test:  [10/57]  eta: 0:00:09  loss: 0.8865 (0.8826)  time: 0.1942  data: 0.0128  max mem: 14938
[20:16:36.219373] Test:  [20/57]  eta: 0:00:06  loss: 0.8865 (0.8757)  time: 0.1819  data: 0.0001  max mem: 14938
[20:16:38.045376] Test:  [30/57]  eta: 0:00:05  loss: 0.7584 (0.8349)  time: 0.1824  data: 0.0001  max mem: 14938
[20:16:39.875937] Test:  [40/57]  eta: 0:00:03  loss: 0.7500 (0.8140)  time: 0.1828  data: 0.0001  max mem: 14938
[20:16:41.710576] Test:  [50/57]  eta: 0:00:01  loss: 0.7472 (0.8068)  time: 0.1832  data: 0.0001  max mem: 14938
[20:16:42.700161] Test:  [56/57]  eta: 0:00:00  loss: 0.7644 (0.8133)  time: 0.1778  data: 0.0001  max mem: 14938
[20:16:42.756228] Test: Total time: 0:00:10 (0.1842 s / it)
[20:16:44.512934] Dice score of the network on the train images: 0.807574, val images: 0.813601
[20:16:44.516576] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:16:45.404940] Epoch: [29]  [  0/345]  eta: 0:05:06  lr: 0.000099  loss: 0.7468 (0.7468)  time: 0.8875  data: 0.1459  max mem: 14938
[20:17:00.296670] Epoch: [29]  [ 20/345]  eta: 0:04:04  lr: 0.000099  loss: 0.7380 (0.7414)  time: 0.7445  data: 0.0001  max mem: 14938
[20:17:15.249218] Epoch: [29]  [ 40/345]  eta: 0:03:48  lr: 0.000099  loss: 0.7427 (0.7438)  time: 0.7476  data: 0.0001  max mem: 14938
[20:17:30.220132] Epoch: [29]  [ 60/345]  eta: 0:03:33  lr: 0.000098  loss: 0.7376 (0.7432)  time: 0.7485  data: 0.0001  max mem: 14938
[20:17:45.216319] Epoch: [29]  [ 80/345]  eta: 0:03:18  lr: 0.000098  loss: 0.7404 (0.7429)  time: 0.7498  data: 0.0001  max mem: 14938
[20:18:00.226621] Epoch: [29]  [100/345]  eta: 0:03:03  lr: 0.000098  loss: 0.7349 (0.7422)  time: 0.7505  data: 0.0001  max mem: 14938
[20:18:15.253404] Epoch: [29]  [120/345]  eta: 0:02:48  lr: 0.000097  loss: 0.7382 (0.7418)  time: 0.7513  data: 0.0001  max mem: 14938
[20:18:30.276032] Epoch: [29]  [140/345]  eta: 0:02:33  lr: 0.000097  loss: 0.7484 (0.7430)  time: 0.7511  data: 0.0001  max mem: 14938
[20:18:45.297931] Epoch: [29]  [160/345]  eta: 0:02:18  lr: 0.000097  loss: 0.7540 (0.7444)  time: 0.7511  data: 0.0001  max mem: 14938
[20:19:00.308411] Epoch: [29]  [180/345]  eta: 0:02:03  lr: 0.000096  loss: 0.7451 (0.7446)  time: 0.7505  data: 0.0001  max mem: 14938
[20:19:15.314619] Epoch: [29]  [200/345]  eta: 0:01:48  lr: 0.000096  loss: 0.7514 (0.7450)  time: 0.7503  data: 0.0001  max mem: 14938
[20:19:30.317644] Epoch: [29]  [220/345]  eta: 0:01:33  lr: 0.000096  loss: 0.7402 (0.7449)  time: 0.7501  data: 0.0001  max mem: 14938
[20:19:45.301953] Epoch: [29]  [240/345]  eta: 0:01:18  lr: 0.000095  loss: 0.7382 (0.7448)  time: 0.7492  data: 0.0001  max mem: 14938
[20:20:00.282145] Epoch: [29]  [260/345]  eta: 0:01:03  lr: 0.000095  loss: 0.7458 (0.7450)  time: 0.7490  data: 0.0001  max mem: 14938
[20:20:15.266972] Epoch: [29]  [280/345]  eta: 0:00:48  lr: 0.000095  loss: 0.7653 (0.7468)  time: 0.7492  data: 0.0001  max mem: 14938
[20:20:30.322851] Epoch: [29]  [300/345]  eta: 0:00:33  lr: 0.000094  loss: 0.7502 (0.7473)  time: 0.7528  data: 0.0001  max mem: 14938
[20:20:45.297823] Epoch: [29]  [320/345]  eta: 0:00:18  lr: 0.000094  loss: 0.7510 (0.7475)  time: 0.7487  data: 0.0001  max mem: 14938
[20:21:00.276574] Epoch: [29]  [340/345]  eta: 0:00:03  lr: 0.000094  loss: 0.7502 (0.7473)  time: 0.7489  data: 0.0001  max mem: 14938
[20:21:03.278156] Epoch: [29]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.7477 (0.7473)  time: 0.7492  data: 0.0001  max mem: 14938
[20:21:03.343756] Epoch: [29] Total time: 0:04:18 (0.7502 s / it)
[20:21:03.344018] Averaged stats: lr: 0.000094  loss: 0.7477 (0.7473)
[20:21:03.674916] Test:  [  0/345]  eta: 0:01:52  loss: 0.7165 (0.7165)  time: 0.3252  data: 0.1436  max mem: 14938
[20:21:05.514412] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7204 (0.7205)  time: 0.1967  data: 0.0131  max mem: 14938
[20:21:07.352434] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7197 (0.7198)  time: 0.1838  data: 0.0001  max mem: 14938
[20:21:09.196540] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7148 (0.7196)  time: 0.1841  data: 0.0001  max mem: 14938
[20:21:11.044296] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7215 (0.7211)  time: 0.1845  data: 0.0001  max mem: 14938
[20:21:12.896349] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7227 (0.7212)  time: 0.1849  data: 0.0001  max mem: 14938
[20:21:14.751572] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7196 (0.7217)  time: 0.1853  data: 0.0001  max mem: 14938
[20:21:16.610850] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7194 (0.7210)  time: 0.1857  data: 0.0001  max mem: 14938
[20:21:18.473562] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7209 (0.7212)  time: 0.1860  data: 0.0001  max mem: 14938
[20:21:20.339076] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7217 (0.7210)  time: 0.1864  data: 0.0001  max mem: 14938
[20:21:22.208243] Test:  [100/345]  eta: 0:00:45  loss: 0.7217 (0.7217)  time: 0.1867  data: 0.0001  max mem: 14938
[20:21:24.078383] Test:  [110/345]  eta: 0:00:43  loss: 0.7184 (0.7205)  time: 0.1869  data: 0.0001  max mem: 14938
[20:21:25.953895] Test:  [120/345]  eta: 0:00:42  loss: 0.7108 (0.7195)  time: 0.1872  data: 0.0001  max mem: 14938
[20:21:27.831617] Test:  [130/345]  eta: 0:00:40  loss: 0.7134 (0.7197)  time: 0.1876  data: 0.0001  max mem: 14938
[20:21:29.714017] Test:  [140/345]  eta: 0:00:38  loss: 0.7155 (0.7194)  time: 0.1880  data: 0.0001  max mem: 14938
[20:21:31.600307] Test:  [150/345]  eta: 0:00:36  loss: 0.7136 (0.7192)  time: 0.1884  data: 0.0001  max mem: 14938
[20:21:33.490346] Test:  [160/345]  eta: 0:00:34  loss: 0.7134 (0.7190)  time: 0.1888  data: 0.0001  max mem: 14938
[20:21:35.381815] Test:  [170/345]  eta: 0:00:32  loss: 0.7094 (0.7187)  time: 0.1890  data: 0.0001  max mem: 14938
[20:21:37.279844] Test:  [180/345]  eta: 0:00:30  loss: 0.7100 (0.7184)  time: 0.1894  data: 0.0001  max mem: 14938
[20:21:39.180399] Test:  [190/345]  eta: 0:00:29  loss: 0.7151 (0.7187)  time: 0.1899  data: 0.0001  max mem: 14938
[20:21:41.082722] Test:  [200/345]  eta: 0:00:27  loss: 0.7151 (0.7185)  time: 0.1901  data: 0.0001  max mem: 14938
[20:21:42.990042] Test:  [210/345]  eta: 0:00:25  loss: 0.7139 (0.7186)  time: 0.1904  data: 0.0001  max mem: 14938
[20:21:44.900696] Test:  [220/345]  eta: 0:00:23  loss: 0.7188 (0.7187)  time: 0.1908  data: 0.0001  max mem: 14938
[20:21:46.815509] Test:  [230/345]  eta: 0:00:21  loss: 0.7134 (0.7184)  time: 0.1912  data: 0.0001  max mem: 14938
[20:21:48.735704] Test:  [240/345]  eta: 0:00:19  loss: 0.7109 (0.7184)  time: 0.1917  data: 0.0001  max mem: 14938
[20:21:50.656032] Test:  [250/345]  eta: 0:00:17  loss: 0.7194 (0.7185)  time: 0.1920  data: 0.0001  max mem: 14938
[20:21:52.580691] Test:  [260/345]  eta: 0:00:16  loss: 0.7171 (0.7182)  time: 0.1922  data: 0.0001  max mem: 14938
[20:21:54.510738] Test:  [270/345]  eta: 0:00:14  loss: 0.7123 (0.7182)  time: 0.1927  data: 0.0001  max mem: 14938
[20:21:56.444067] Test:  [280/345]  eta: 0:00:12  loss: 0.7092 (0.7181)  time: 0.1931  data: 0.0001  max mem: 14938
[20:21:58.377993] Test:  [290/345]  eta: 0:00:10  loss: 0.7167 (0.7183)  time: 0.1933  data: 0.0001  max mem: 14938
[20:22:00.316907] Test:  [300/345]  eta: 0:00:08  loss: 0.7181 (0.7180)  time: 0.1936  data: 0.0001  max mem: 14938
[20:22:02.257579] Test:  [310/345]  eta: 0:00:06  loss: 0.7172 (0.7181)  time: 0.1939  data: 0.0001  max mem: 14938
[20:22:04.202675] Test:  [320/345]  eta: 0:00:04  loss: 0.7172 (0.7184)  time: 0.1942  data: 0.0001  max mem: 14938
[20:22:06.150414] Test:  [330/345]  eta: 0:00:02  loss: 0.7168 (0.7185)  time: 0.1946  data: 0.0001  max mem: 14938
[20:22:08.102202] Test:  [340/345]  eta: 0:00:00  loss: 0.7132 (0.7183)  time: 0.1949  data: 0.0001  max mem: 14938
[20:22:08.884527] Test:  [344/345]  eta: 0:00:00  loss: 0.7119 (0.7183)  time: 0.1951  data: 0.0001  max mem: 14938
[20:22:08.943251] Test: Total time: 0:01:05 (0.1901 s / it)
[20:22:19.411597] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8308 (0.8308)  time: 0.3192  data: 0.1392  max mem: 14938
[20:22:21.228943] Test:  [10/57]  eta: 0:00:09  loss: 0.8524 (0.8636)  time: 0.1942  data: 0.0127  max mem: 14938
[20:22:23.051170] Test:  [20/57]  eta: 0:00:06  loss: 0.8634 (0.8557)  time: 0.1819  data: 0.0001  max mem: 14938
[20:22:24.875446] Test:  [30/57]  eta: 0:00:05  loss: 0.7461 (0.8177)  time: 0.1823  data: 0.0001  max mem: 14938
[20:22:26.707227] Test:  [40/57]  eta: 0:00:03  loss: 0.7391 (0.7973)  time: 0.1827  data: 0.0001  max mem: 14938
[20:22:28.542782] Test:  [50/57]  eta: 0:00:01  loss: 0.7256 (0.7897)  time: 0.1833  data: 0.0001  max mem: 14938
[20:22:29.532180] Test:  [56/57]  eta: 0:00:00  loss: 0.7552 (0.7963)  time: 0.1779  data: 0.0001  max mem: 14938
[20:22:29.588509] Test: Total time: 0:00:10 (0.1842 s / it)
[20:22:31.313293] Dice score of the network on the train images: 0.792947, val images: 0.823572
[20:22:31.313514] saving best_dice_model_0 @ epoch 29
[20:22:32.434310] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:22:33.321958] Epoch: [30]  [  0/345]  eta: 0:05:05  lr: 0.000094  loss: 0.7286 (0.7286)  time: 0.8867  data: 0.1447  max mem: 14938
[20:22:48.208281] Epoch: [30]  [ 20/345]  eta: 0:04:04  lr: 0.000093  loss: 0.7401 (0.7393)  time: 0.7443  data: 0.0001  max mem: 14938
[20:23:03.158856] Epoch: [30]  [ 40/345]  eta: 0:03:48  lr: 0.000093  loss: 0.7424 (0.7400)  time: 0.7475  data: 0.0001  max mem: 14938
[20:23:18.126193] Epoch: [30]  [ 60/345]  eta: 0:03:33  lr: 0.000093  loss: 0.7310 (0.7393)  time: 0.7483  data: 0.0001  max mem: 14938
[20:23:33.115754] Epoch: [30]  [ 80/345]  eta: 0:03:18  lr: 0.000092  loss: 0.7315 (0.7388)  time: 0.7494  data: 0.0001  max mem: 14938
[20:23:48.115652] Epoch: [30]  [100/345]  eta: 0:03:03  lr: 0.000092  loss: 0.7311 (0.7373)  time: 0.7500  data: 0.0001  max mem: 14938
[20:24:03.158827] Epoch: [30]  [120/345]  eta: 0:02:48  lr: 0.000092  loss: 0.7424 (0.7379)  time: 0.7521  data: 0.0001  max mem: 14938
[20:24:18.203955] Epoch: [30]  [140/345]  eta: 0:02:33  lr: 0.000091  loss: 0.7532 (0.7404)  time: 0.7522  data: 0.0001  max mem: 14938
[20:24:33.231354] Epoch: [30]  [160/345]  eta: 0:02:18  lr: 0.000091  loss: 0.7422 (0.7412)  time: 0.7513  data: 0.0001  max mem: 14938
[20:24:48.239500] Epoch: [30]  [180/345]  eta: 0:02:03  lr: 0.000091  loss: 0.7443 (0.7421)  time: 0.7504  data: 0.0001  max mem: 14938
[20:25:03.250883] Epoch: [30]  [200/345]  eta: 0:01:48  lr: 0.000090  loss: 0.7437 (0.7422)  time: 0.7505  data: 0.0001  max mem: 14938
[20:25:18.254002] Epoch: [30]  [220/345]  eta: 0:01:33  lr: 0.000090  loss: 0.7291 (0.7412)  time: 0.7501  data: 0.0001  max mem: 14938
[20:25:33.263141] Epoch: [30]  [240/345]  eta: 0:01:18  lr: 0.000090  loss: 0.7397 (0.7413)  time: 0.7504  data: 0.0001  max mem: 14938
[20:25:48.274687] Epoch: [30]  [260/345]  eta: 0:01:03  lr: 0.000089  loss: 0.7382 (0.7410)  time: 0.7505  data: 0.0001  max mem: 14938
[20:26:03.271258] Epoch: [30]  [280/345]  eta: 0:00:48  lr: 0.000089  loss: 0.7379 (0.7411)  time: 0.7498  data: 0.0001  max mem: 14938
[20:26:18.267660] Epoch: [30]  [300/345]  eta: 0:00:33  lr: 0.000089  loss: 0.7400 (0.7411)  time: 0.7498  data: 0.0001  max mem: 14938
[20:26:33.261776] Epoch: [30]  [320/345]  eta: 0:00:18  lr: 0.000088  loss: 0.7331 (0.7409)  time: 0.7497  data: 0.0001  max mem: 14938
[20:26:48.254768] Epoch: [30]  [340/345]  eta: 0:00:03  lr: 0.000088  loss: 0.7375 (0.7407)  time: 0.7496  data: 0.0001  max mem: 14938
[20:26:51.254071] Epoch: [30]  [344/345]  eta: 0:00:00  lr: 0.000088  loss: 0.7375 (0.7406)  time: 0.7497  data: 0.0001  max mem: 14938
[20:26:51.317020] Epoch: [30] Total time: 0:04:18 (0.7504 s / it)
[20:26:51.317505] Averaged stats: lr: 0.000088  loss: 0.7375 (0.7406)
[20:26:51.656400] Test:  [  0/345]  eta: 0:01:55  loss: 0.7324 (0.7324)  time: 0.3343  data: 0.1531  max mem: 14938
[20:26:53.496230] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7263 (0.7228)  time: 0.1976  data: 0.0140  max mem: 14938
[20:26:55.338171] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7165 (0.7173)  time: 0.1840  data: 0.0001  max mem: 14938
[20:26:57.182785] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7118 (0.7143)  time: 0.1843  data: 0.0001  max mem: 14938
[20:26:59.029872] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7096 (0.7128)  time: 0.1845  data: 0.0001  max mem: 14938
[20:27:00.881713] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7097 (0.7124)  time: 0.1849  data: 0.0001  max mem: 14938
[20:27:02.737895] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7059 (0.7125)  time: 0.1853  data: 0.0001  max mem: 14938
[20:27:04.595781] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7036 (0.7118)  time: 0.1857  data: 0.0001  max mem: 14938
[20:27:06.459190] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7077 (0.7110)  time: 0.1860  data: 0.0001  max mem: 14938
[20:27:08.323681] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7076 (0.7110)  time: 0.1863  data: 0.0001  max mem: 14938
[20:27:10.193505] Test:  [100/345]  eta: 0:00:45  loss: 0.7078 (0.7110)  time: 0.1867  data: 0.0001  max mem: 14938
[20:27:12.065848] Test:  [110/345]  eta: 0:00:43  loss: 0.7074 (0.7105)  time: 0.1871  data: 0.0001  max mem: 14938
[20:27:13.942505] Test:  [120/345]  eta: 0:00:42  loss: 0.7056 (0.7102)  time: 0.1874  data: 0.0001  max mem: 14938
[20:27:15.821348] Test:  [130/345]  eta: 0:00:40  loss: 0.7093 (0.7104)  time: 0.1877  data: 0.0001  max mem: 14938
[20:27:17.705205] Test:  [140/345]  eta: 0:00:38  loss: 0.7157 (0.7108)  time: 0.1881  data: 0.0001  max mem: 14938
[20:27:19.591647] Test:  [150/345]  eta: 0:00:36  loss: 0.7161 (0.7111)  time: 0.1885  data: 0.0001  max mem: 14938
[20:27:21.480238] Test:  [160/345]  eta: 0:00:34  loss: 0.7156 (0.7115)  time: 0.1887  data: 0.0001  max mem: 14938
[20:27:23.373501] Test:  [170/345]  eta: 0:00:32  loss: 0.7056 (0.7111)  time: 0.1890  data: 0.0001  max mem: 14938
[20:27:25.270667] Test:  [180/345]  eta: 0:00:30  loss: 0.7044 (0.7111)  time: 0.1895  data: 0.0001  max mem: 14938
[20:27:27.170102] Test:  [190/345]  eta: 0:00:29  loss: 0.7130 (0.7112)  time: 0.1898  data: 0.0001  max mem: 14938
[20:27:29.072719] Test:  [200/345]  eta: 0:00:27  loss: 0.7073 (0.7113)  time: 0.1901  data: 0.0001  max mem: 14938
[20:27:30.982164] Test:  [210/345]  eta: 0:00:25  loss: 0.7103 (0.7114)  time: 0.1906  data: 0.0001  max mem: 14938
[20:27:32.895627] Test:  [220/345]  eta: 0:00:23  loss: 0.7103 (0.7114)  time: 0.1911  data: 0.0001  max mem: 14938
[20:27:34.809827] Test:  [230/345]  eta: 0:00:21  loss: 0.7098 (0.7112)  time: 0.1913  data: 0.0001  max mem: 14938
[20:27:36.729353] Test:  [240/345]  eta: 0:00:19  loss: 0.7021 (0.7109)  time: 0.1916  data: 0.0001  max mem: 14938
[20:27:38.651440] Test:  [250/345]  eta: 0:00:17  loss: 0.7010 (0.7111)  time: 0.1920  data: 0.0001  max mem: 14938
[20:27:40.576011] Test:  [260/345]  eta: 0:00:16  loss: 0.7190 (0.7113)  time: 0.1923  data: 0.0001  max mem: 14938
[20:27:42.505251] Test:  [270/345]  eta: 0:00:14  loss: 0.7176 (0.7115)  time: 0.1926  data: 0.0001  max mem: 14938
[20:27:44.437227] Test:  [280/345]  eta: 0:00:12  loss: 0.7105 (0.7114)  time: 0.1930  data: 0.0001  max mem: 14938
[20:27:46.374073] Test:  [290/345]  eta: 0:00:10  loss: 0.7100 (0.7115)  time: 0.1934  data: 0.0001  max mem: 14938
[20:27:48.313439] Test:  [300/345]  eta: 0:00:08  loss: 0.7166 (0.7115)  time: 0.1938  data: 0.0001  max mem: 14938
[20:27:50.256352] Test:  [310/345]  eta: 0:00:06  loss: 0.7077 (0.7114)  time: 0.1941  data: 0.0001  max mem: 14938
[20:27:52.201750] Test:  [320/345]  eta: 0:00:04  loss: 0.7139 (0.7116)  time: 0.1944  data: 0.0001  max mem: 14938
[20:27:54.148137] Test:  [330/345]  eta: 0:00:02  loss: 0.7164 (0.7116)  time: 0.1945  data: 0.0001  max mem: 14938
[20:27:56.099288] Test:  [340/345]  eta: 0:00:00  loss: 0.7072 (0.7116)  time: 0.1948  data: 0.0001  max mem: 14938
[20:27:56.880511] Test:  [344/345]  eta: 0:00:00  loss: 0.7072 (0.7115)  time: 0.1949  data: 0.0001  max mem: 14938
[20:27:56.940119] Test: Total time: 0:01:05 (0.1902 s / it)
[20:28:07.263628] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8292 (0.8292)  time: 0.3222  data: 0.1420  max mem: 14938
[20:28:09.081322] Test:  [10/57]  eta: 0:00:09  loss: 0.8638 (0.8769)  time: 0.1945  data: 0.0130  max mem: 14938
[20:28:10.902835] Test:  [20/57]  eta: 0:00:06  loss: 0.8775 (0.8693)  time: 0.1819  data: 0.0001  max mem: 14938
[20:28:12.729750] Test:  [30/57]  eta: 0:00:05  loss: 0.7583 (0.8301)  time: 0.1824  data: 0.0001  max mem: 14938
[20:28:14.562087] Test:  [40/57]  eta: 0:00:03  loss: 0.7534 (0.8108)  time: 0.1829  data: 0.0001  max mem: 14938
[20:28:16.400738] Test:  [50/57]  eta: 0:00:01  loss: 0.7450 (0.8036)  time: 0.1835  data: 0.0001  max mem: 14938
[20:28:17.391352] Test:  [56/57]  eta: 0:00:00  loss: 0.7580 (0.8099)  time: 0.1781  data: 0.0001  max mem: 14938
[20:28:17.448664] Test: Total time: 0:00:10 (0.1843 s / it)
[20:28:19.165984] Dice score of the network on the train images: 0.821968, val images: 0.812635
[20:28:19.166200] saving best_prec_model_0 @ epoch 30
[20:28:20.377092] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft

[20:28:21.258696] Epoch: [31]  [  0/345]  eta: 0:05:03  lr: 0.000088  loss: 0.7180 (0.7180)  time: 0.8807  data: 0.1387  max mem: 14938
[20:28:36.157388] Epoch: [31]  [ 20/345]  eta: 0:04:04  lr: 0.000088  loss: 0.7359 (0.7384)  time: 0.7449  data: 0.0001  max mem: 14938
[20:28:51.105217] Epoch: [31]  [ 40/345]  eta: 0:03:48  lr: 0.000087  loss: 0.7314 (0.7357)  time: 0.7474  data: 0.0001  max mem: 14938
[20:29:06.088974] Epoch: [31]  [ 60/345]  eta: 0:03:33  lr: 0.000087  loss: 0.7333 (0.7346)  time: 0.7491  data: 0.0001  max mem: 14938
[20:29:21.098342] Epoch: [31]  [ 80/345]  eta: 0:03:18  lr: 0.000087  loss: 0.7341 (0.7346)  time: 0.7504  data: 0.0001  max mem: 14938
[20:29:36.137535] Epoch: [31]  [100/345]  eta: 0:03:03  lr: 0.000086  loss: 0.7270 (0.7345)  time: 0.7519  data: 0.0001  max mem: 14938
[20:29:51.186066] Epoch: [31]  [120/345]  eta: 0:02:48  lr: 0.000086  loss: 0.7282 (0.7336)  time: 0.7524  data: 0.0001  max mem: 14938
[20:30:06.234627] Epoch: [31]  [140/345]  eta: 0:02:33  lr: 0.000085  loss: 0.7251 (0.7332)  time: 0.7524  data: 0.0001  max mem: 14938
[20:30:21.270689] Epoch: [31]  [160/345]  eta: 0:02:18  lr: 0.000085  loss: 0.7357 (0.7335)  time: 0.7518  data: 0.0001  max mem: 14938
[20:30:36.302768] Epoch: [31]  [180/345]  eta: 0:02:03  lr: 0.000085  loss: 0.7382 (0.7336)  time: 0.7516  data: 0.0001  max mem: 14938
[20:30:51.317068] Epoch: [31]  [200/345]  eta: 0:01:48  lr: 0.000084  loss: 0.7332 (0.7340)  time: 0.7507  data: 0.0001  max mem: 14938
[20:31:06.446353] Epoch: [31]  [220/345]  eta: 0:01:33  lr: 0.000084  loss: 0.7284 (0.7335)  time: 0.7564  data: 0.0001  max mem: 14938
[20:31:21.440344] Epoch: [31]  [240/345]  eta: 0:01:18  lr: 0.000084  loss: 0.7267 (0.7332)  time: 0.7497  data: 0.0001  max mem: 14938
[20:31:36.442497] Epoch: [31]  [260/345]  eta: 0:01:03  lr: 0.000083  loss: 0.7363 (0.7336)  time: 0.7501  data: 0.0001  max mem: 14938
[20:31:51.430521] Epoch: [31]  [280/345]  eta: 0:00:48  lr: 0.000083  loss: 0.7348 (0.7337)  time: 0.7494  data: 0.0001  max mem: 14938
[20:32:06.438504] Epoch: [31]  [300/345]  eta: 0:00:33  lr: 0.000083  loss: 0.7352 (0.7340)  time: 0.7504  data: 0.0001  max mem: 14938
[20:32:21.447454] Epoch: [31]  [320/345]  eta: 0:00:18  lr: 0.000082  loss: 0.7276 (0.7337)  time: 0.7504  data: 0.0001  max mem: 14938
[20:32:36.456282] Epoch: [31]  [340/345]  eta: 0:00:03  lr: 0.000082  loss: 0.7286 (0.7335)  time: 0.7504  data: 0.0001  max mem: 14938
[20:32:39.457398] Epoch: [31]  [344/345]  eta: 0:00:00  lr: 0.000082  loss: 0.7284 (0.7335)  time: 0.7504  data: 0.0001  max mem: 14938
[20:32:39.521263] Epoch: [31] Total time: 0:04:19 (0.7511 s / it)
[20:32:39.521634] Averaged stats: lr: 0.000082  loss: 0.7284 (0.7335)
[20:32:39.854793] Test:  [  0/345]  eta: 0:01:52  loss: 0.7274 (0.7274)  time: 0.3273  data: 0.1459  max mem: 14938
[20:32:41.692657] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7035 (0.7051)  time: 0.1968  data: 0.0133  max mem: 14938
[20:32:43.533070] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7038 (0.7058)  time: 0.1838  data: 0.0001  max mem: 14938
[20:32:45.376952] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7089 (0.7081)  time: 0.1842  data: 0.0001  max mem: 14938
[20:32:47.225330] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7089 (0.7089)  time: 0.1846  data: 0.0001  max mem: 14938
[20:32:49.076303] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7060 (0.7086)  time: 0.1849  data: 0.0001  max mem: 14938
[20:32:50.931740] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7076 (0.7082)  time: 0.1853  data: 0.0001  max mem: 14938
[20:32:52.789439] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7100 (0.7088)  time: 0.1856  data: 0.0001  max mem: 14938
[20:32:54.649490] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7040 (0.7084)  time: 0.1858  data: 0.0001  max mem: 14938
[20:32:56.514752] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7107 (0.7088)  time: 0.1862  data: 0.0001  max mem: 14938
[20:32:58.382623] Test:  [100/345]  eta: 0:00:45  loss: 0.7117 (0.7091)  time: 0.1866  data: 0.0001  max mem: 14938
[20:33:00.254106] Test:  [110/345]  eta: 0:00:43  loss: 0.7069 (0.7090)  time: 0.1869  data: 0.0001  max mem: 14938
[20:33:02.130048] Test:  [120/345]  eta: 0:00:42  loss: 0.7069 (0.7086)  time: 0.1873  data: 0.0001  max mem: 14938
[20:33:04.008489] Test:  [130/345]  eta: 0:00:40  loss: 0.7078 (0.7088)  time: 0.1877  data: 0.0001  max mem: 14938
[20:33:05.890877] Test:  [140/345]  eta: 0:00:38  loss: 0.7073 (0.7089)  time: 0.1880  data: 0.0001  max mem: 14938
[20:33:07.774873] Test:  [150/345]  eta: 0:00:36  loss: 0.7100 (0.7090)  time: 0.1883  data: 0.0001  max mem: 14938
[20:33:09.663121] Test:  [160/345]  eta: 0:00:34  loss: 0.7170 (0.7095)  time: 0.1886  data: 0.0001  max mem: 14938
[20:33:11.554157] Test:  [170/345]  eta: 0:00:32  loss: 0.7170 (0.7101)  time: 0.1889  data: 0.0001  max mem: 14938
[20:33:13.451726] Test:  [180/345]  eta: 0:00:30  loss: 0.7184 (0.7106)  time: 0.1894  data: 0.0001  max mem: 14938
[20:33:15.353126] Test:  [190/345]  eta: 0:00:29  loss: 0.7130 (0.7104)  time: 0.1899  data: 0.0001  max mem: 14938
[20:33:17.254876] Test:  [200/345]  eta: 0:00:27  loss: 0.7093 (0.7104)  time: 0.1901  data: 0.0001  max mem: 14938
[20:33:19.162671] Test:  [210/345]  eta: 0:00:25  loss: 0.7089 (0.7104)  time: 0.1904  data: 0.0001  max mem: 14938
[20:33:21.072884] Test:  [220/345]  eta: 0:00:23  loss: 0.7089 (0.7103)  time: 0.1908  data: 0.0001  max mem: 14938
[20:33:22.988710] Test:  [230/345]  eta: 0:00:21  loss: 0.7089 (0.7102)  time: 0.1913  data: 0.0001  max mem: 14938
[20:33:24.908966] Test:  [240/345]  eta: 0:00:19  loss: 0.7089 (0.7102)  time: 0.1918  data: 0.0001  max mem: 14938
[20:33:26.830437] Test:  [250/345]  eta: 0:00:17  loss: 0.7094 (0.7101)  time: 0.1920  data: 0.0001  max mem: 14938
[20:33:28.753830] Test:  [260/345]  eta: 0:00:16  loss: 0.7082 (0.7102)  time: 0.1922  data: 0.0001  max mem: 14938
[20:33:30.684260] Test:  [270/345]  eta: 0:00:14  loss: 0.7098 (0.7105)  time: 0.1926  data: 0.0001  max mem: 14938
[20:33:32.616063] Test:  [280/345]  eta: 0:00:12  loss: 0.7112 (0.7106)  time: 0.1931  data: 0.0001  max mem: 14938
[20:33:34.551251] Test:  [290/345]  eta: 0:00:10  loss: 0.7109 (0.7106)  time: 0.1933  data: 0.0001  max mem: 14938
[20:33:36.489727] Test:  [300/345]  eta: 0:00:08  loss: 0.7108 (0.7107)  time: 0.1936  data: 0.0001  max mem: 14938
[20:33:38.431681] Test:  [310/345]  eta: 0:00:06  loss: 0.7015 (0.7103)  time: 0.1940  data: 0.0001  max mem: 14938
[20:33:40.376104] Test:  [320/345]  eta: 0:00:04  loss: 0.7080 (0.7104)  time: 0.1943  data: 0.0001  max mem: 14938
[20:33:42.323054] Test:  [330/345]  eta: 0:00:02  loss: 0.7080 (0.7104)  time: 0.1945  data: 0.0001  max mem: 14938
[20:33:44.274163] Test:  [340/345]  eta: 0:00:00  loss: 0.7073 (0.7104)  time: 0.1949  data: 0.0001  max mem: 14938
[20:33:45.055876] Test:  [344/345]  eta: 0:00:00  loss: 0.7098 (0.7105)  time: 0.1950  data: 0.0001  max mem: 14938
[20:33:45.113551] Test: Total time: 0:01:05 (0.1901 s / it)
[20:33:55.608526] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8547 (0.8547)  time: 0.3208  data: 0.1413  max mem: 14938
[20:33:57.426106] Test:  [10/57]  eta: 0:00:09  loss: 0.8919 (0.8857)  time: 0.1943  data: 0.0129  max mem: 14938
[20:33:59.247649] Test:  [20/57]  eta: 0:00:06  loss: 0.8921 (0.8760)  time: 0.1819  data: 0.0001  max mem: 14938
[20:34:01.073944] Test:  [30/57]  eta: 0:00:05  loss: 0.7684 (0.8327)  time: 0.1823  data: 0.0001  max mem: 14938
[20:34:02.905024] Test:  [40/57]  eta: 0:00:03  loss: 0.7406 (0.8106)  time: 0.1828  data: 0.0001  max mem: 14938
[20:34:04.742110] Test:  [50/57]  eta: 0:00:01  loss: 0.7333 (0.8022)  time: 0.1834  data: 0.0001  max mem: 14938
[20:34:05.731686] Test:  [56/57]  eta: 0:00:00  loss: 0.7559 (0.8077)  time: 0.1779  data: 0.0001  max mem: 14938
[20:34:05.788957] Test: Total time: 0:00:10 (0.1842 s / it)
[20:34:07.571749] Dice score of the network on the train images: 0.815775, val images: 0.825919
[20:34:07.571973] saving best_dice_model_0 @ epoch 31
[20:34:08.679985] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:34:09.566564] Epoch: [32]  [  0/345]  eta: 0:05:05  lr: 0.000082  loss: 0.7310 (0.7310)  time: 0.8854  data: 0.1456  max mem: 14938
[20:34:24.458795] Epoch: [32]  [ 20/345]  eta: 0:04:04  lr: 0.000081  loss: 0.7263 (0.7313)  time: 0.7446  data: 0.0001  max mem: 14938
[20:34:39.408040] Epoch: [32]  [ 40/345]  eta: 0:03:48  lr: 0.000081  loss: 0.7416 (0.7362)  time: 0.7474  data: 0.0001  max mem: 14938
[20:34:54.394165] Epoch: [32]  [ 60/345]  eta: 0:03:33  lr: 0.000081  loss: 0.7380 (0.7366)  time: 0.7493  data: 0.0001  max mem: 14938
[20:35:09.393783] Epoch: [32]  [ 80/345]  eta: 0:03:18  lr: 0.000080  loss: 0.7229 (0.7347)  time: 0.7499  data: 0.0001  max mem: 14938
[20:35:24.416320] Epoch: [32]  [100/345]  eta: 0:03:03  lr: 0.000080  loss: 0.7324 (0.7342)  time: 0.7511  data: 0.0001  max mem: 14938
[20:35:39.570424] Epoch: [32]  [120/345]  eta: 0:02:48  lr: 0.000080  loss: 0.7279 (0.7338)  time: 0.7577  data: 0.0001  max mem: 14938
[20:35:54.598333] Epoch: [32]  [140/345]  eta: 0:02:33  lr: 0.000079  loss: 0.7250 (0.7327)  time: 0.7514  data: 0.0001  max mem: 14938
[20:36:09.621694] Epoch: [32]  [160/345]  eta: 0:02:18  lr: 0.000079  loss: 0.7324 (0.7330)  time: 0.7511  data: 0.0001  max mem: 14938
[20:36:24.644502] Epoch: [32]  [180/345]  eta: 0:02:03  lr: 0.000079  loss: 0.7257 (0.7319)  time: 0.7511  data: 0.0001  max mem: 14938
[20:36:39.663341] Epoch: [32]  [200/345]  eta: 0:01:48  lr: 0.000078  loss: 0.7303 (0.7316)  time: 0.7509  data: 0.0001  max mem: 14938
[20:36:54.676637] Epoch: [32]  [220/345]  eta: 0:01:33  lr: 0.000078  loss: 0.7237 (0.7311)  time: 0.7506  data: 0.0001  max mem: 14938
[20:37:09.679038] Epoch: [32]  [240/345]  eta: 0:01:18  lr: 0.000077  loss: 0.7298 (0.7313)  time: 0.7501  data: 0.0001  max mem: 14938
[20:37:24.668092] Epoch: [32]  [260/345]  eta: 0:01:03  lr: 0.000077  loss: 0.7279 (0.7313)  time: 0.7494  data: 0.0001  max mem: 14938
[20:37:39.659225] Epoch: [32]  [280/345]  eta: 0:00:48  lr: 0.000077  loss: 0.7402 (0.7320)  time: 0.7495  data: 0.0001  max mem: 14938
[20:37:54.635693] Epoch: [32]  [300/345]  eta: 0:00:33  lr: 0.000076  loss: 0.7310 (0.7322)  time: 0.7488  data: 0.0001  max mem: 14938
[20:38:09.605918] Epoch: [32]  [320/345]  eta: 0:00:18  lr: 0.000076  loss: 0.7307 (0.7324)  time: 0.7485  data: 0.0001  max mem: 14938
[20:38:24.587163] Epoch: [32]  [340/345]  eta: 0:00:03  lr: 0.000076  loss: 0.7468 (0.7331)  time: 0.7490  data: 0.0001  max mem: 14938
[20:38:27.584694] Epoch: [32]  [344/345]  eta: 0:00:00  lr: 0.000076  loss: 0.7405 (0.7331)  time: 0.7491  data: 0.0001  max mem: 14938
[20:38:27.647642] Epoch: [32] Total time: 0:04:18 (0.7506 s / it)
[20:38:27.648039] Averaged stats: lr: 0.000076  loss: 0.7405 (0.7331)
[20:38:27.979291] Test:  [  0/345]  eta: 0:01:53  loss: 0.7200 (0.7200)  time: 0.3277  data: 0.1464  max mem: 14938
[20:38:29.818310] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7031 (0.7060)  time: 0.1969  data: 0.0134  max mem: 14938
[20:38:31.658794] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7093 (0.7122)  time: 0.1839  data: 0.0001  max mem: 14938
[20:38:33.502305] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7116 (0.7113)  time: 0.1841  data: 0.0001  max mem: 14938
[20:38:35.349977] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7088 (0.7112)  time: 0.1845  data: 0.0001  max mem: 14938
[20:38:37.201240] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7088 (0.7112)  time: 0.1849  data: 0.0001  max mem: 14938
[20:38:39.056361] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7069 (0.7109)  time: 0.1853  data: 0.0001  max mem: 14938
[20:38:40.913406] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7157 (0.7118)  time: 0.1856  data: 0.0001  max mem: 14938
[20:38:42.776300] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7165 (0.7125)  time: 0.1859  data: 0.0001  max mem: 14938
[20:38:44.641583] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7152 (0.7129)  time: 0.1864  data: 0.0001  max mem: 14938
[20:38:46.510279] Test:  [100/345]  eta: 0:00:45  loss: 0.7155 (0.7131)  time: 0.1867  data: 0.0001  max mem: 14938
[20:38:48.383664] Test:  [110/345]  eta: 0:00:43  loss: 0.7170 (0.7132)  time: 0.1871  data: 0.0001  max mem: 14938
[20:38:50.259956] Test:  [120/345]  eta: 0:00:42  loss: 0.7103 (0.7129)  time: 0.1874  data: 0.0001  max mem: 14938
[20:38:52.139703] Test:  [130/345]  eta: 0:00:40  loss: 0.7082 (0.7124)  time: 0.1878  data: 0.0001  max mem: 14938
[20:38:54.021720] Test:  [140/345]  eta: 0:00:38  loss: 0.7070 (0.7124)  time: 0.1880  data: 0.0001  max mem: 14938
[20:38:55.907955] Test:  [150/345]  eta: 0:00:36  loss: 0.7065 (0.7123)  time: 0.1884  data: 0.0001  max mem: 14938
[20:38:57.798048] Test:  [160/345]  eta: 0:00:34  loss: 0.7077 (0.7123)  time: 0.1888  data: 0.0001  max mem: 14938
[20:38:59.691996] Test:  [170/345]  eta: 0:00:32  loss: 0.7158 (0.7126)  time: 0.1892  data: 0.0001  max mem: 14938
[20:39:01.590275] Test:  [180/345]  eta: 0:00:30  loss: 0.7114 (0.7124)  time: 0.1896  data: 0.0001  max mem: 14938
[20:39:03.491418] Test:  [190/345]  eta: 0:00:29  loss: 0.7114 (0.7125)  time: 0.1899  data: 0.0001  max mem: 14938
[20:39:05.394606] Test:  [200/345]  eta: 0:00:27  loss: 0.7133 (0.7123)  time: 0.1902  data: 0.0001  max mem: 14938
[20:39:07.301485] Test:  [210/345]  eta: 0:00:25  loss: 0.7078 (0.7122)  time: 0.1905  data: 0.0001  max mem: 14938
[20:39:09.211991] Test:  [220/345]  eta: 0:00:23  loss: 0.7128 (0.7126)  time: 0.1908  data: 0.0001  max mem: 14938
[20:39:11.127454] Test:  [230/345]  eta: 0:00:21  loss: 0.7141 (0.7127)  time: 0.1912  data: 0.0001  max mem: 14938
[20:39:13.046288] Test:  [240/345]  eta: 0:00:19  loss: 0.7126 (0.7126)  time: 0.1917  data: 0.0001  max mem: 14938
[20:39:14.969503] Test:  [250/345]  eta: 0:00:17  loss: 0.7121 (0.7124)  time: 0.1921  data: 0.0001  max mem: 14938
[20:39:16.895813] Test:  [260/345]  eta: 0:00:16  loss: 0.7098 (0.7124)  time: 0.1924  data: 0.0001  max mem: 14938
[20:39:18.825246] Test:  [270/345]  eta: 0:00:14  loss: 0.7150 (0.7124)  time: 0.1927  data: 0.0001  max mem: 14938
[20:39:20.758701] Test:  [280/345]  eta: 0:00:12  loss: 0.7113 (0.7122)  time: 0.1931  data: 0.0001  max mem: 14938
[20:39:22.693927] Test:  [290/345]  eta: 0:00:10  loss: 0.7111 (0.7123)  time: 0.1934  data: 0.0001  max mem: 14938
[20:39:24.633063] Test:  [300/345]  eta: 0:00:08  loss: 0.7137 (0.7122)  time: 0.1937  data: 0.0001  max mem: 14938
[20:39:26.576046] Test:  [310/345]  eta: 0:00:06  loss: 0.7117 (0.7123)  time: 0.1941  data: 0.0001  max mem: 14938
[20:39:28.520380] Test:  [320/345]  eta: 0:00:04  loss: 0.7109 (0.7122)  time: 0.1943  data: 0.0001  max mem: 14938
[20:39:30.469719] Test:  [330/345]  eta: 0:00:02  loss: 0.7153 (0.7124)  time: 0.1946  data: 0.0001  max mem: 14938
[20:39:32.421204] Test:  [340/345]  eta: 0:00:00  loss: 0.7116 (0.7122)  time: 0.1950  data: 0.0001  max mem: 14938
[20:39:33.203387] Test:  [344/345]  eta: 0:00:00  loss: 0.7068 (0.7123)  time: 0.1951  data: 0.0001  max mem: 14938
[20:39:33.264506] Test: Total time: 0:01:05 (0.1902 s / it)
[20:39:43.758793] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8366 (0.8366)  time: 0.3211  data: 0.1414  max mem: 14938
[20:39:45.576350] Test:  [10/57]  eta: 0:00:09  loss: 0.8718 (0.8703)  time: 0.1943  data: 0.0129  max mem: 14938
[20:39:47.399361] Test:  [20/57]  eta: 0:00:06  loss: 0.8718 (0.8634)  time: 0.1820  data: 0.0001  max mem: 14938
[20:39:49.227922] Test:  [30/57]  eta: 0:00:05  loss: 0.7605 (0.8257)  time: 0.1825  data: 0.0001  max mem: 14938
[20:39:51.059181] Test:  [40/57]  eta: 0:00:03  loss: 0.7481 (0.8069)  time: 0.1829  data: 0.0001  max mem: 14938
[20:39:52.896124] Test:  [50/57]  eta: 0:00:01  loss: 0.7394 (0.7990)  time: 0.1834  data: 0.0001  max mem: 14938
[20:39:53.886225] Test:  [56/57]  eta: 0:00:00  loss: 0.7623 (0.8046)  time: 0.1779  data: 0.0001  max mem: 14938
[20:39:53.942128] Test: Total time: 0:00:10 (0.1843 s / it)
[20:39:55.712108] Dice score of the network on the train images: 0.821221, val images: 0.821050
[20:39:55.716292] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:39:56.596118] Epoch: [33]  [  0/345]  eta: 0:05:03  lr: 0.000075  loss: 0.7422 (0.7422)  time: 0.8788  data: 0.1374  max mem: 14938
[20:40:11.497981] Epoch: [33]  [ 20/345]  eta: 0:04:04  lr: 0.000075  loss: 0.7341 (0.7355)  time: 0.7450  data: 0.0001  max mem: 14938
[20:40:26.433408] Epoch: [33]  [ 40/345]  eta: 0:03:48  lr: 0.000075  loss: 0.7220 (0.7314)  time: 0.7467  data: 0.0001  max mem: 14938
[20:40:41.398243] Epoch: [33]  [ 60/345]  eta: 0:03:33  lr: 0.000074  loss: 0.7227 (0.7296)  time: 0.7482  data: 0.0001  max mem: 14938
[20:40:56.410625] Epoch: [33]  [ 80/345]  eta: 0:03:18  lr: 0.000074  loss: 0.7263 (0.7297)  time: 0.7506  data: 0.0001  max mem: 14938
[20:41:11.421056] Epoch: [33]  [100/345]  eta: 0:03:03  lr: 0.000074  loss: 0.7341 (0.7303)  time: 0.7505  data: 0.0001  max mem: 14938
[20:41:26.576070] Epoch: [33]  [120/345]  eta: 0:02:48  lr: 0.000073  loss: 0.7251 (0.7305)  time: 0.7577  data: 0.0001  max mem: 14938
[20:41:41.608276] Epoch: [33]  [140/345]  eta: 0:02:33  lr: 0.000073  loss: 0.7313 (0.7305)  time: 0.7516  data: 0.0001  max mem: 14938
[20:41:56.636707] Epoch: [33]  [160/345]  eta: 0:02:18  lr: 0.000073  loss: 0.7405 (0.7312)  time: 0.7514  data: 0.0001  max mem: 14938
[20:42:11.661630] Epoch: [33]  [180/345]  eta: 0:02:03  lr: 0.000072  loss: 0.7210 (0.7303)  time: 0.7512  data: 0.0001  max mem: 14938
[20:42:26.676205] Epoch: [33]  [200/345]  eta: 0:01:48  lr: 0.000072  loss: 0.7271 (0.7303)  time: 0.7507  data: 0.0001  max mem: 14938
[20:42:41.683876] Epoch: [33]  [220/345]  eta: 0:01:33  lr: 0.000071  loss: 0.7244 (0.7301)  time: 0.7503  data: 0.0001  max mem: 14938
[20:42:56.690199] Epoch: [33]  [240/345]  eta: 0:01:18  lr: 0.000071  loss: 0.7280 (0.7301)  time: 0.7503  data: 0.0001  max mem: 14938
[20:43:11.687046] Epoch: [33]  [260/345]  eta: 0:01:03  lr: 0.000071  loss: 0.7254 (0.7298)  time: 0.7498  data: 0.0001  max mem: 14938
[20:43:26.691549] Epoch: [33]  [280/345]  eta: 0:00:48  lr: 0.000070  loss: 0.7253 (0.7296)  time: 0.7502  data: 0.0001  max mem: 14938
[20:43:41.701458] Epoch: [33]  [300/345]  eta: 0:00:33  lr: 0.000070  loss: 0.7256 (0.7294)  time: 0.7504  data: 0.0001  max mem: 14938
[20:43:56.679694] Epoch: [33]  [320/345]  eta: 0:00:18  lr: 0.000070  loss: 0.7222 (0.7288)  time: 0.7489  data: 0.0001  max mem: 14938
[20:44:11.659045] Epoch: [33]  [340/345]  eta: 0:00:03  lr: 0.000069  loss: 0.7221 (0.7284)  time: 0.7489  data: 0.0001  max mem: 14938
[20:44:14.655688] Epoch: [33]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.7223 (0.7284)  time: 0.7489  data: 0.0001  max mem: 14938
[20:44:14.720742] Epoch: [33] Total time: 0:04:19 (0.7507 s / it)
[20:44:14.721223] Averaged stats: lr: 0.000069  loss: 0.7223 (0.7284)
[20:44:15.052029] Test:  [  0/345]  eta: 0:01:52  loss: 0.6899 (0.6899)  time: 0.3272  data: 0.1449  max mem: 14938
[20:44:16.889427] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6961 (0.7015)  time: 0.1967  data: 0.0132  max mem: 14938
[20:44:18.728571] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7033 (0.7033)  time: 0.1838  data: 0.0001  max mem: 14938
[20:44:20.572558] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7006 (0.7015)  time: 0.1841  data: 0.0001  max mem: 14938
[20:44:22.420110] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6976 (0.7009)  time: 0.1845  data: 0.0001  max mem: 14938
[20:44:24.270530] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7014 (0.7015)  time: 0.1848  data: 0.0001  max mem: 14938
[20:44:26.125011] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7005 (0.7013)  time: 0.1852  data: 0.0001  max mem: 14938
[20:44:27.983250] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6993 (0.7009)  time: 0.1856  data: 0.0001  max mem: 14938
[20:44:29.846077] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6942 (0.7006)  time: 0.1860  data: 0.0001  max mem: 14938
[20:44:31.709867] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6978 (0.7007)  time: 0.1863  data: 0.0001  max mem: 14938
[20:44:33.580062] Test:  [100/345]  eta: 0:00:45  loss: 0.6988 (0.7007)  time: 0.1866  data: 0.0001  max mem: 14938
[20:44:35.452198] Test:  [110/345]  eta: 0:00:43  loss: 0.7025 (0.7010)  time: 0.1871  data: 0.0001  max mem: 14938
[20:44:37.329744] Test:  [120/345]  eta: 0:00:42  loss: 0.7008 (0.7008)  time: 0.1874  data: 0.0001  max mem: 14938
[20:44:39.209400] Test:  [130/345]  eta: 0:00:40  loss: 0.6928 (0.7006)  time: 0.1878  data: 0.0001  max mem: 14938
[20:44:41.090759] Test:  [140/345]  eta: 0:00:38  loss: 0.6932 (0.7003)  time: 0.1880  data: 0.0001  max mem: 14938
[20:44:42.977428] Test:  [150/345]  eta: 0:00:36  loss: 0.6982 (0.7010)  time: 0.1884  data: 0.0001  max mem: 14938
[20:44:44.866779] Test:  [160/345]  eta: 0:00:34  loss: 0.7032 (0.7009)  time: 0.1888  data: 0.0001  max mem: 14938
[20:44:46.759434] Test:  [170/345]  eta: 0:00:32  loss: 0.6983 (0.7009)  time: 0.1890  data: 0.0001  max mem: 14938
[20:44:48.656485] Test:  [180/345]  eta: 0:00:30  loss: 0.6979 (0.7009)  time: 0.1894  data: 0.0001  max mem: 14938
[20:44:50.559873] Test:  [190/345]  eta: 0:00:29  loss: 0.6978 (0.7009)  time: 0.1900  data: 0.0001  max mem: 14938
[20:44:52.463336] Test:  [200/345]  eta: 0:00:27  loss: 0.6978 (0.7011)  time: 0.1903  data: 0.0001  max mem: 14938
[20:44:54.370687] Test:  [210/345]  eta: 0:00:25  loss: 0.7048 (0.7014)  time: 0.1905  data: 0.0001  max mem: 14938
[20:44:56.282927] Test:  [220/345]  eta: 0:00:23  loss: 0.6977 (0.7011)  time: 0.1909  data: 0.0001  max mem: 14938
[20:44:58.198502] Test:  [230/345]  eta: 0:00:21  loss: 0.6933 (0.7009)  time: 0.1913  data: 0.0001  max mem: 14938
[20:45:00.116904] Test:  [240/345]  eta: 0:00:19  loss: 0.6933 (0.7008)  time: 0.1916  data: 0.0001  max mem: 14938
[20:45:02.038743] Test:  [250/345]  eta: 0:00:17  loss: 0.7001 (0.7009)  time: 0.1920  data: 0.0001  max mem: 14938
[20:45:03.964404] Test:  [260/345]  eta: 0:00:16  loss: 0.7009 (0.7010)  time: 0.1923  data: 0.0001  max mem: 14938
[20:45:05.898017] Test:  [270/345]  eta: 0:00:14  loss: 0.7003 (0.7010)  time: 0.1929  data: 0.0001  max mem: 14938
[20:45:07.829352] Test:  [280/345]  eta: 0:00:12  loss: 0.7024 (0.7012)  time: 0.1932  data: 0.0001  max mem: 14938
[20:45:09.765224] Test:  [290/345]  eta: 0:00:10  loss: 0.7022 (0.7012)  time: 0.1933  data: 0.0001  max mem: 14938
[20:45:11.703474] Test:  [300/345]  eta: 0:00:08  loss: 0.6943 (0.7013)  time: 0.1937  data: 0.0001  max mem: 14938
[20:45:13.645867] Test:  [310/345]  eta: 0:00:06  loss: 0.6985 (0.7012)  time: 0.1940  data: 0.0001  max mem: 14938
[20:45:15.592300] Test:  [320/345]  eta: 0:00:04  loss: 0.6985 (0.7012)  time: 0.1944  data: 0.0001  max mem: 14938
[20:45:17.540235] Test:  [330/345]  eta: 0:00:02  loss: 0.6960 (0.7011)  time: 0.1947  data: 0.0001  max mem: 14938
[20:45:19.490565] Test:  [340/345]  eta: 0:00:00  loss: 0.6981 (0.7012)  time: 0.1949  data: 0.0001  max mem: 14938
[20:45:20.273811] Test:  [344/345]  eta: 0:00:00  loss: 0.6981 (0.7011)  time: 0.1951  data: 0.0001  max mem: 14938
[20:45:20.332387] Test: Total time: 0:01:05 (0.1902 s / it)
[20:45:30.774910] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8319 (0.8319)  time: 0.3171  data: 0.1376  max mem: 14938
[20:45:32.590005] Test:  [10/57]  eta: 0:00:09  loss: 0.8809 (0.8776)  time: 0.1938  data: 0.0126  max mem: 14938
[20:45:34.412433] Test:  [20/57]  eta: 0:00:06  loss: 0.8871 (0.8700)  time: 0.1818  data: 0.0001  max mem: 14938
[20:45:36.238686] Test:  [30/57]  eta: 0:00:05  loss: 0.7520 (0.8298)  time: 0.1824  data: 0.0001  max mem: 14938
[20:45:38.069136] Test:  [40/57]  eta: 0:00:03  loss: 0.7422 (0.8087)  time: 0.1828  data: 0.0001  max mem: 14938
[20:45:39.904442] Test:  [50/57]  eta: 0:00:01  loss: 0.7271 (0.8001)  time: 0.1832  data: 0.0001  max mem: 14938
[20:45:40.894916] Test:  [56/57]  eta: 0:00:00  loss: 0.7548 (0.8064)  time: 0.1778  data: 0.0001  max mem: 14938
[20:45:40.953185] Test: Total time: 0:00:10 (0.1841 s / it)
[20:45:42.696772] Dice score of the network on the train images: 0.829038, val images: 0.821315
[20:45:42.700410] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:45:43.582914] Epoch: [34]  [  0/345]  eta: 0:05:04  lr: 0.000069  loss: 0.7156 (0.7156)  time: 0.8817  data: 0.1399  max mem: 14938

[20:45:58.482233] Epoch: [34]  [ 20/345]  eta: 0:04:04  lr: 0.000069  loss: 0.7185 (0.7221)  time: 0.7449  data: 0.0001  max mem: 14938
[20:46:13.447438] Epoch: [34]  [ 40/345]  eta: 0:03:48  lr: 0.000068  loss: 0.7208 (0.7230)  time: 0.7482  data: 0.0001  max mem: 14938
[20:46:28.407090] Epoch: [34]  [ 60/345]  eta: 0:03:33  lr: 0.000068  loss: 0.7186 (0.7224)  time: 0.7479  data: 0.0001  max mem: 14938
[20:46:43.386792] Epoch: [34]  [ 80/345]  eta: 0:03:18  lr: 0.000068  loss: 0.7236 (0.7225)  time: 0.7489  data: 0.0001  max mem: 14938
[20:46:58.382662] Epoch: [34]  [100/345]  eta: 0:03:03  lr: 0.000067  loss: 0.7244 (0.7243)  time: 0.7497  data: 0.0001  max mem: 14938
[20:47:13.525750] Epoch: [34]  [120/345]  eta: 0:02:48  lr: 0.000067  loss: 0.7148 (0.7232)  time: 0.7571  data: 0.0001  max mem: 14938
[20:47:28.538225] Epoch: [34]  [140/345]  eta: 0:02:33  lr: 0.000066  loss: 0.7213 (0.7229)  time: 0.7506  data: 0.0001  max mem: 14938
[20:47:43.551667] Epoch: [34]  [160/345]  eta: 0:02:18  lr: 0.000066  loss: 0.7248 (0.7230)  time: 0.7506  data: 0.0001  max mem: 14938
[20:47:58.584891] Epoch: [34]  [180/345]  eta: 0:02:03  lr: 0.000066  loss: 0.7253 (0.7231)  time: 0.7516  data: 0.0001  max mem: 14938
[20:48:13.590123] Epoch: [34]  [200/345]  eta: 0:01:48  lr: 0.000065  loss: 0.7347 (0.7240)  time: 0.7502  data: 0.0001  max mem: 14938
[20:48:28.590916] Epoch: [34]  [220/345]  eta: 0:01:33  lr: 0.000065  loss: 0.7257 (0.7242)  time: 0.7500  data: 0.0001  max mem: 14938
[20:48:43.592075] Epoch: [34]  [240/345]  eta: 0:01:18  lr: 0.000064  loss: 0.7217 (0.7242)  time: 0.7500  data: 0.0001  max mem: 14938
[20:48:58.580587] Epoch: [34]  [260/345]  eta: 0:01:03  lr: 0.000064  loss: 0.7236 (0.7245)  time: 0.7494  data: 0.0001  max mem: 14938
[20:49:13.564334] Epoch: [34]  [280/345]  eta: 0:00:48  lr: 0.000064  loss: 0.7186 (0.7242)  time: 0.7491  data: 0.0001  max mem: 14938
[20:49:28.550024] Epoch: [34]  [300/345]  eta: 0:00:33  lr: 0.000063  loss: 0.7204 (0.7242)  time: 0.7492  data: 0.0001  max mem: 14938
[20:49:43.531510] Epoch: [34]  [320/345]  eta: 0:00:18  lr: 0.000063  loss: 0.7381 (0.7251)  time: 0.7490  data: 0.0001  max mem: 14938
[20:49:58.507574] Epoch: [34]  [340/345]  eta: 0:00:03  lr: 0.000063  loss: 0.7300 (0.7256)  time: 0.7488  data: 0.0001  max mem: 14938
[20:50:01.502677] Epoch: [34]  [344/345]  eta: 0:00:00  lr: 0.000063  loss: 0.7285 (0.7257)  time: 0.7488  data: 0.0001  max mem: 14938
[20:50:01.565552] Epoch: [34] Total time: 0:04:18 (0.7503 s / it)
[20:50:01.566010] Averaged stats: lr: 0.000063  loss: 0.7285 (0.7257)
[20:50:01.903555] Test:  [  0/345]  eta: 0:01:55  loss: 0.7152 (0.7152)  time: 0.3335  data: 0.1520  max mem: 14938
[20:50:03.739688] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6992 (0.7011)  time: 0.1972  data: 0.0139  max mem: 14938
[20:50:05.578486] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7036 (0.7031)  time: 0.1837  data: 0.0001  max mem: 14938
[20:50:07.421306] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7060 (0.7039)  time: 0.1840  data: 0.0001  max mem: 14938
[20:50:09.269606] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7038 (0.7037)  time: 0.1845  data: 0.0001  max mem: 14938
[20:50:11.120074] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7010 (0.7032)  time: 0.1849  data: 0.0001  max mem: 14938
[20:50:12.975478] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7058 (0.7046)  time: 0.1852  data: 0.0001  max mem: 14938
[20:50:14.832947] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7076 (0.7042)  time: 0.1856  data: 0.0001  max mem: 14938
[20:50:16.694094] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7045 (0.7047)  time: 0.1859  data: 0.0001  max mem: 14938
[20:50:18.557327] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7039 (0.7050)  time: 0.1862  data: 0.0001  max mem: 14938
[20:50:20.425237] Test:  [100/345]  eta: 0:00:45  loss: 0.7099 (0.7054)  time: 0.1865  data: 0.0001  max mem: 14938
[20:50:22.294626] Test:  [110/345]  eta: 0:00:43  loss: 0.7078 (0.7053)  time: 0.1868  data: 0.0001  max mem: 14938
[20:50:24.169800] Test:  [120/345]  eta: 0:00:42  loss: 0.7078 (0.7058)  time: 0.1872  data: 0.0001  max mem: 14938
[20:50:26.048448] Test:  [130/345]  eta: 0:00:40  loss: 0.7048 (0.7056)  time: 0.1876  data: 0.0001  max mem: 14938
[20:50:27.930167] Test:  [140/345]  eta: 0:00:38  loss: 0.7037 (0.7053)  time: 0.1880  data: 0.0001  max mem: 14938
[20:50:29.814452] Test:  [150/345]  eta: 0:00:36  loss: 0.6966 (0.7051)  time: 0.1883  data: 0.0001  max mem: 14938
[20:50:31.703478] Test:  [160/345]  eta: 0:00:34  loss: 0.6966 (0.7046)  time: 0.1886  data: 0.0001  max mem: 14938
[20:50:33.594916] Test:  [170/345]  eta: 0:00:32  loss: 0.7022 (0.7047)  time: 0.1890  data: 0.0001  max mem: 14938
[20:50:35.493752] Test:  [180/345]  eta: 0:00:30  loss: 0.7005 (0.7044)  time: 0.1895  data: 0.0001  max mem: 14938
[20:50:37.394944] Test:  [190/345]  eta: 0:00:29  loss: 0.7009 (0.7046)  time: 0.1900  data: 0.0001  max mem: 14938
[20:50:39.297782] Test:  [200/345]  eta: 0:00:27  loss: 0.6997 (0.7043)  time: 0.1902  data: 0.0001  max mem: 14938
[20:50:41.205701] Test:  [210/345]  eta: 0:00:25  loss: 0.6998 (0.7043)  time: 0.1905  data: 0.0001  max mem: 14938
[20:50:43.116583] Test:  [220/345]  eta: 0:00:23  loss: 0.7050 (0.7043)  time: 0.1909  data: 0.0001  max mem: 14938
[20:50:45.031279] Test:  [230/345]  eta: 0:00:21  loss: 0.7016 (0.7044)  time: 0.1912  data: 0.0001  max mem: 14938
[20:50:46.950145] Test:  [240/345]  eta: 0:00:19  loss: 0.7088 (0.7047)  time: 0.1916  data: 0.0001  max mem: 14938
[20:50:48.871569] Test:  [250/345]  eta: 0:00:17  loss: 0.7088 (0.7046)  time: 0.1920  data: 0.0001  max mem: 14938
[20:50:50.794781] Test:  [260/345]  eta: 0:00:16  loss: 0.7012 (0.7046)  time: 0.1922  data: 0.0001  max mem: 14938
[20:50:52.723713] Test:  [270/345]  eta: 0:00:14  loss: 0.7038 (0.7047)  time: 0.1926  data: 0.0001  max mem: 14938
[20:50:54.654425] Test:  [280/345]  eta: 0:00:12  loss: 0.6990 (0.7043)  time: 0.1929  data: 0.0001  max mem: 14938
[20:50:56.591275] Test:  [290/345]  eta: 0:00:10  loss: 0.6990 (0.7043)  time: 0.1933  data: 0.0001  max mem: 14938
[20:50:58.530102] Test:  [300/345]  eta: 0:00:08  loss: 0.7041 (0.7041)  time: 0.1937  data: 0.0001  max mem: 14938
[20:51:00.471105] Test:  [310/345]  eta: 0:00:06  loss: 0.7009 (0.7041)  time: 0.1939  data: 0.0001  max mem: 14938
[20:51:02.414918] Test:  [320/345]  eta: 0:00:04  loss: 0.6989 (0.7041)  time: 0.1942  data: 0.0001  max mem: 14938
[20:51:04.363037] Test:  [330/345]  eta: 0:00:02  loss: 0.6979 (0.7040)  time: 0.1945  data: 0.0001  max mem: 14938
[20:51:06.313242] Test:  [340/345]  eta: 0:00:00  loss: 0.7034 (0.7040)  time: 0.1949  data: 0.0001  max mem: 14938
[20:51:07.094515] Test:  [344/345]  eta: 0:00:00  loss: 0.7016 (0.7039)  time: 0.1950  data: 0.0001  max mem: 14938
[20:51:07.153716] Test: Total time: 0:01:05 (0.1901 s / it)
[20:51:17.503216] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8537 (0.8537)  time: 0.3162  data: 0.1365  max mem: 14938
[20:51:19.321698] Test:  [10/57]  eta: 0:00:09  loss: 0.8747 (0.8767)  time: 0.1940  data: 0.0125  max mem: 14938
[20:51:21.144608] Test:  [20/57]  eta: 0:00:06  loss: 0.8747 (0.8717)  time: 0.1820  data: 0.0001  max mem: 14938
[20:51:22.970628] Test:  [30/57]  eta: 0:00:05  loss: 0.7537 (0.8303)  time: 0.1824  data: 0.0001  max mem: 14938
[20:51:24.802404] Test:  [40/57]  eta: 0:00:03  loss: 0.7397 (0.8086)  time: 0.1828  data: 0.0001  max mem: 14938
[20:51:26.638662] Test:  [50/57]  eta: 0:00:01  loss: 0.7331 (0.8002)  time: 0.1834  data: 0.0001  max mem: 14938
[20:51:27.628679] Test:  [56/57]  eta: 0:00:00  loss: 0.7584 (0.8062)  time: 0.1780  data: 0.0001  max mem: 14938
[20:51:27.688010] Test: Total time: 0:00:10 (0.1842 s / it)
[20:51:29.440126] Dice score of the network on the train images: 0.815936, val images: 0.820937
[20:51:29.443763] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:51:30.328247] Epoch: [35]  [  0/345]  eta: 0:05:04  lr: 0.000063  loss: 0.7478 (0.7478)  time: 0.8837  data: 0.1425  max mem: 14938
[20:51:45.224897] Epoch: [35]  [ 20/345]  eta: 0:04:04  lr: 0.000062  loss: 0.7206 (0.7224)  time: 0.7448  data: 0.0001  max mem: 14938
[20:52:00.185642] Epoch: [35]  [ 40/345]  eta: 0:03:48  lr: 0.000062  loss: 0.7246 (0.7252)  time: 0.7480  data: 0.0001  max mem: 14938
[20:52:15.173555] Epoch: [35]  [ 60/345]  eta: 0:03:33  lr: 0.000061  loss: 0.7212 (0.7249)  time: 0.7493  data: 0.0001  max mem: 14938
[20:52:30.180197] Epoch: [35]  [ 80/345]  eta: 0:03:18  lr: 0.000061  loss: 0.7208 (0.7242)  time: 0.7503  data: 0.0001  max mem: 14938
[20:52:45.205960] Epoch: [35]  [100/345]  eta: 0:03:03  lr: 0.000061  loss: 0.7228 (0.7244)  time: 0.7512  data: 0.0001  max mem: 14938
[20:53:00.247584] Epoch: [35]  [120/345]  eta: 0:02:48  lr: 0.000060  loss: 0.7294 (0.7254)  time: 0.7520  data: 0.0001  max mem: 14938
[20:53:15.380796] Epoch: [35]  [140/345]  eta: 0:02:34  lr: 0.000060  loss: 0.7282 (0.7262)  time: 0.7566  data: 0.0001  max mem: 14938
[20:53:30.385267] Epoch: [35]  [160/345]  eta: 0:02:18  lr: 0.000059  loss: 0.7200 (0.7257)  time: 0.7502  data: 0.0001  max mem: 14938
[20:53:45.408736] Epoch: [35]  [180/345]  eta: 0:02:03  lr: 0.000059  loss: 0.7243 (0.7259)  time: 0.7511  data: 0.0001  max mem: 14938
[20:54:00.432351] Epoch: [35]  [200/345]  eta: 0:01:48  lr: 0.000059  loss: 0.7240 (0.7259)  time: 0.7511  data: 0.0001  max mem: 14938
[20:54:15.445015] Epoch: [35]  [220/345]  eta: 0:01:33  lr: 0.000058  loss: 0.7252 (0.7259)  time: 0.7506  data: 0.0001  max mem: 14938
[20:54:30.463066] Epoch: [35]  [240/345]  eta: 0:01:18  lr: 0.000058  loss: 0.7258 (0.7258)  time: 0.7509  data: 0.0001  max mem: 14938
[20:54:45.469782] Epoch: [35]  [260/345]  eta: 0:01:03  lr: 0.000058  loss: 0.7282 (0.7261)  time: 0.7503  data: 0.0001  max mem: 14938
[20:55:00.464867] Epoch: [35]  [280/345]  eta: 0:00:48  lr: 0.000057  loss: 0.7204 (0.7261)  time: 0.7497  data: 0.0001  max mem: 14938
[20:55:15.456315] Epoch: [35]  [300/345]  eta: 0:00:33  lr: 0.000057  loss: 0.7251 (0.7262)  time: 0.7495  data: 0.0001  max mem: 14938
[20:55:30.454778] Epoch: [35]  [320/345]  eta: 0:00:18  lr: 0.000056  loss: 0.7204 (0.7258)  time: 0.7499  data: 0.0001  max mem: 14938
[20:55:45.447066] Epoch: [35]  [340/345]  eta: 0:00:03  lr: 0.000056  loss: 0.7266 (0.7258)  time: 0.7496  data: 0.0001  max mem: 14938
[20:55:48.446301] Epoch: [35]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.7247 (0.7259)  time: 0.7496  data: 0.0001  max mem: 14938
[20:55:48.508915] Epoch: [35] Total time: 0:04:19 (0.7509 s / it)
[20:55:48.509412] Averaged stats: lr: 0.000056  loss: 0.7247 (0.7259)
[20:55:48.848786] Test:  [  0/345]  eta: 0:01:55  loss: 0.7257 (0.7257)  time: 0.3351  data: 0.1534  max mem: 14938
[20:55:50.687324] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7030 (0.7076)  time: 0.1975  data: 0.0140  max mem: 14938
[20:55:52.527620] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7021 (0.7033)  time: 0.1839  data: 0.0001  max mem: 14938
[20:55:54.370514] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6941 (0.7010)  time: 0.1841  data: 0.0001  max mem: 14938
[20:55:56.218494] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6938 (0.6998)  time: 0.1845  data: 0.0001  max mem: 14938
[20:55:58.071032] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6963 (0.6993)  time: 0.1850  data: 0.0001  max mem: 14938
[20:55:59.925681] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6947 (0.6986)  time: 0.1853  data: 0.0001  max mem: 14938
[20:56:01.783947] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6957 (0.6984)  time: 0.1856  data: 0.0001  max mem: 14938
[20:56:03.644010] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6994 (0.6993)  time: 0.1859  data: 0.0001  max mem: 14938
[20:56:05.509441] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7004 (0.6991)  time: 0.1862  data: 0.0001  max mem: 14938
[20:56:07.377873] Test:  [100/345]  eta: 0:00:45  loss: 0.7004 (0.6997)  time: 0.1866  data: 0.0001  max mem: 14938
[20:56:09.248847] Test:  [110/345]  eta: 0:00:43  loss: 0.7025 (0.7001)  time: 0.1869  data: 0.0001  max mem: 14938
[20:56:11.122832] Test:  [120/345]  eta: 0:00:42  loss: 0.7023 (0.7001)  time: 0.1872  data: 0.0001  max mem: 14938
[20:56:13.002006] Test:  [130/345]  eta: 0:00:40  loss: 0.7004 (0.7002)  time: 0.1876  data: 0.0001  max mem: 14938
[20:56:14.884218] Test:  [140/345]  eta: 0:00:38  loss: 0.7004 (0.7003)  time: 0.1880  data: 0.0001  max mem: 14938
[20:56:16.769703] Test:  [150/345]  eta: 0:00:36  loss: 0.6951 (0.7001)  time: 0.1883  data: 0.0001  max mem: 14938
[20:56:18.657563] Test:  [160/345]  eta: 0:00:34  loss: 0.6957 (0.7002)  time: 0.1886  data: 0.0001  max mem: 14938
[20:56:20.548878] Test:  [170/345]  eta: 0:00:32  loss: 0.7000 (0.7004)  time: 0.1889  data: 0.0001  max mem: 14938
[20:56:22.444946] Test:  [180/345]  eta: 0:00:30  loss: 0.6972 (0.7002)  time: 0.1893  data: 0.0001  max mem: 14938
[20:56:24.344329] Test:  [190/345]  eta: 0:00:29  loss: 0.6927 (0.7002)  time: 0.1897  data: 0.0001  max mem: 14938
[20:56:26.245957] Test:  [200/345]  eta: 0:00:27  loss: 0.6931 (0.6999)  time: 0.1900  data: 0.0001  max mem: 14938
[20:56:28.153440] Test:  [210/345]  eta: 0:00:25  loss: 0.6931 (0.7000)  time: 0.1904  data: 0.0001  max mem: 14938
[20:56:30.064538] Test:  [220/345]  eta: 0:00:23  loss: 0.6993 (0.7000)  time: 0.1909  data: 0.0001  max mem: 14938
[20:56:31.979546] Test:  [230/345]  eta: 0:00:21  loss: 0.6993 (0.7000)  time: 0.1913  data: 0.0001  max mem: 14938
[20:56:33.896467] Test:  [240/345]  eta: 0:00:19  loss: 0.6951 (0.6997)  time: 0.1915  data: 0.0001  max mem: 14938
[20:56:35.816906] Test:  [250/345]  eta: 0:00:17  loss: 0.6951 (0.6995)  time: 0.1918  data: 0.0001  max mem: 14938
[20:56:37.741177] Test:  [260/345]  eta: 0:00:16  loss: 0.6970 (0.6994)  time: 0.1922  data: 0.0001  max mem: 14938
[20:56:39.670001] Test:  [270/345]  eta: 0:00:14  loss: 0.6969 (0.6993)  time: 0.1926  data: 0.0001  max mem: 14938
[20:56:41.602679] Test:  [280/345]  eta: 0:00:12  loss: 0.6957 (0.6992)  time: 0.1930  data: 0.0001  max mem: 14938
[20:56:43.537013] Test:  [290/345]  eta: 0:00:10  loss: 0.6955 (0.6991)  time: 0.1933  data: 0.0001  max mem: 14938
[20:56:45.474179] Test:  [300/345]  eta: 0:00:08  loss: 0.6975 (0.6992)  time: 0.1935  data: 0.0001  max mem: 14938
[20:56:47.416068] Test:  [310/345]  eta: 0:00:06  loss: 0.7028 (0.6994)  time: 0.1939  data: 0.0001  max mem: 14938
[20:56:49.359141] Test:  [320/345]  eta: 0:00:04  loss: 0.7019 (0.6993)  time: 0.1942  data: 0.0001  max mem: 14938
[20:56:51.305011] Test:  [330/345]  eta: 0:00:02  loss: 0.6991 (0.6994)  time: 0.1944  data: 0.0001  max mem: 14938
[20:56:53.255610] Test:  [340/345]  eta: 0:00:00  loss: 0.6939 (0.6993)  time: 0.1948  data: 0.0001  max mem: 14938
[20:56:54.037572] Test:  [344/345]  eta: 0:00:00  loss: 0.6939 (0.6993)  time: 0.1949  data: 0.0001  max mem: 14938
[20:56:54.094726] Test: Total time: 0:01:05 (0.1901 s / it)
[20:57:04.662390] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8200 (0.8200)  time: 0.3208  data: 0.1414  max mem: 14938
[20:57:06.477915] Test:  [10/57]  eta: 0:00:09  loss: 0.8835 (0.8746)  time: 0.1942  data: 0.0129  max mem: 14938
[20:57:08.299887] Test:  [20/57]  eta: 0:00:06  loss: 0.8835 (0.8640)  time: 0.1818  data: 0.0001  max mem: 14938
[20:57:10.125744] Test:  [30/57]  eta: 0:00:05  loss: 0.7472 (0.8237)  time: 0.1823  data: 0.0001  max mem: 14938
[20:57:11.956543] Test:  [40/57]  eta: 0:00:03  loss: 0.7387 (0.8034)  time: 0.1828  data: 0.0001  max mem: 14938
[20:57:13.791068] Test:  [50/57]  eta: 0:00:01  loss: 0.7309 (0.7954)  time: 0.1832  data: 0.0001  max mem: 14938
[20:57:14.780500] Test:  [56/57]  eta: 0:00:00  loss: 0.7591 (0.8012)  time: 0.1778  data: 0.0001  max mem: 14938
[20:57:14.818552] Test: Total time: 0:00:10 (0.1838 s / it)
[20:57:16.549952] Dice score of the network on the train images: 0.822764, val images: 0.823519
[20:57:16.554117] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:57:17.443870] Epoch: [36]  [  0/345]  eta: 0:05:06  lr: 0.000056  loss: 0.7102 (0.7102)  time: 0.8887  data: 0.1466  max mem: 14938
[20:57:32.341146] Epoch: [36]  [ 20/345]  eta: 0:04:04  lr: 0.000056  loss: 0.7208 (0.7225)  time: 0.7448  data: 0.0001  max mem: 14938
[20:57:47.300514] Epoch: [36]  [ 40/345]  eta: 0:03:48  lr: 0.000055  loss: 0.7179 (0.7214)  time: 0.7479  data: 0.0001  max mem: 14938
[20:58:02.280039] Epoch: [36]  [ 60/345]  eta: 0:03:33  lr: 0.000055  loss: 0.7251 (0.7229)  time: 0.7489  data: 0.0001  max mem: 14938
[20:58:17.285495] Epoch: [36]  [ 80/345]  eta: 0:03:18  lr: 0.000054  loss: 0.7273 (0.7239)  time: 0.7502  data: 0.0001  max mem: 14938
[20:58:32.307961] Epoch: [36]  [100/345]  eta: 0:03:03  lr: 0.000054  loss: 0.7219 (0.7242)  time: 0.7511  data: 0.0001  max mem: 14938
[20:58:47.469175] Epoch: [36]  [120/345]  eta: 0:02:49  lr: 0.000054  loss: 0.7233 (0.7245)  time: 0.7580  data: 0.0001  max mem: 14938
[20:59:02.508410] Epoch: [36]  [140/345]  eta: 0:02:34  lr: 0.000053  loss: 0.7233 (0.7241)  time: 0.7519  data: 0.0001  max mem: 14938
[20:59:17.540144] Epoch: [36]  [160/345]  eta: 0:02:19  lr: 0.000053  loss: 0.7236 (0.7242)  time: 0.7515  data: 0.0001  max mem: 14938
[20:59:32.554705] Epoch: [36]  [180/345]  eta: 0:02:03  lr: 0.000053  loss: 0.7236 (0.7244)  time: 0.7507  data: 0.0001  max mem: 14938
[20:59:47.552433] Epoch: [36]  [200/345]  eta: 0:01:48  lr: 0.000052  loss: 0.7155 (0.7242)  time: 0.7498  data: 0.0001  max mem: 14938
[21:00:02.533343] Epoch: [36]  [220/345]  eta: 0:01:33  lr: 0.000052  loss: 0.7236 (0.7239)  time: 0.7490  data: 0.0001  max mem: 14938

[21:00:17.516260] Epoch: [36]  [240/345]  eta: 0:01:18  lr: 0.000051  loss: 0.7200 (0.7238)  time: 0.7491  data: 0.0001  max mem: 14938
[21:00:32.502738] Epoch: [36]  [260/345]  eta: 0:01:03  lr: 0.000051  loss: 0.7185 (0.7233)  time: 0.7493  data: 0.0001  max mem: 14938
[21:00:47.485722] Epoch: [36]  [280/345]  eta: 0:00:48  lr: 0.000051  loss: 0.7223 (0.7232)  time: 0.7491  data: 0.0001  max mem: 14938
[21:01:02.467530] Epoch: [36]  [300/345]  eta: 0:00:33  lr: 0.000050  loss: 0.7152 (0.7231)  time: 0.7490  data: 0.0001  max mem: 14938
[21:01:17.438214] Epoch: [36]  [320/345]  eta: 0:00:18  lr: 0.000050  loss: 0.7142 (0.7229)  time: 0.7485  data: 0.0001  max mem: 14938
[21:01:32.431528] Epoch: [36]  [340/345]  eta: 0:00:03  lr: 0.000050  loss: 0.7231 (0.7228)  time: 0.7496  data: 0.0001  max mem: 14938
[21:01:35.429303] Epoch: [36]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.7231 (0.7228)  time: 0.7496  data: 0.0001  max mem: 14938
[21:01:35.492758] Epoch: [36] Total time: 0:04:18 (0.7505 s / it)
[21:01:35.493017] Averaged stats: lr: 0.000050  loss: 0.7231 (0.7228)
[21:01:35.831661] Test:  [  0/345]  eta: 0:01:55  loss: 0.6795 (0.6795)  time: 0.3346  data: 0.1521  max mem: 14938
[21:01:37.669694] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6957 (0.6950)  time: 0.1974  data: 0.0139  max mem: 14938
[21:01:39.508035] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6941 (0.6949)  time: 0.1838  data: 0.0001  max mem: 14938
[21:01:41.350722] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6933 (0.6943)  time: 0.1840  data: 0.0001  max mem: 14938
[21:01:43.199004] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6933 (0.6939)  time: 0.1845  data: 0.0001  max mem: 14938
[21:01:45.050493] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6998 (0.6955)  time: 0.1849  data: 0.0001  max mem: 14938
[21:01:46.904818] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6893 (0.6946)  time: 0.1852  data: 0.0001  max mem: 14938
[21:01:48.761646] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6884 (0.6938)  time: 0.1855  data: 0.0001  max mem: 14938
[21:01:50.623135] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6890 (0.6933)  time: 0.1859  data: 0.0001  max mem: 14938
[21:01:52.487656] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6958 (0.6945)  time: 0.1862  data: 0.0001  max mem: 14938
[21:01:54.355143] Test:  [100/345]  eta: 0:00:45  loss: 0.7068 (0.6950)  time: 0.1865  data: 0.0001  max mem: 14938
[21:01:56.226949] Test:  [110/345]  eta: 0:00:43  loss: 0.6962 (0.6951)  time: 0.1869  data: 0.0001  max mem: 14938
[21:01:58.103091] Test:  [120/345]  eta: 0:00:42  loss: 0.6997 (0.6955)  time: 0.1873  data: 0.0001  max mem: 14938
[21:01:59.981846] Test:  [130/345]  eta: 0:00:40  loss: 0.6983 (0.6956)  time: 0.1877  data: 0.0001  max mem: 14938
[21:02:01.864066] Test:  [140/345]  eta: 0:00:38  loss: 0.6961 (0.6956)  time: 0.1880  data: 0.0001  max mem: 14938
[21:02:03.747887] Test:  [150/345]  eta: 0:00:36  loss: 0.6961 (0.6955)  time: 0.1883  data: 0.0001  max mem: 14938
[21:02:05.636564] Test:  [160/345]  eta: 0:00:34  loss: 0.7015 (0.6960)  time: 0.1886  data: 0.0001  max mem: 14938
[21:02:07.527957] Test:  [170/345]  eta: 0:00:32  loss: 0.7018 (0.6964)  time: 0.1890  data: 0.0001  max mem: 14938
[21:02:09.425896] Test:  [180/345]  eta: 0:00:30  loss: 0.6965 (0.6963)  time: 0.1894  data: 0.0001  max mem: 14938
[21:02:11.326776] Test:  [190/345]  eta: 0:00:29  loss: 0.6937 (0.6962)  time: 0.1899  data: 0.0001  max mem: 14938
[21:02:13.230755] Test:  [200/345]  eta: 0:00:27  loss: 0.6937 (0.6961)  time: 0.1902  data: 0.0001  max mem: 14938
[21:02:15.138175] Test:  [210/345]  eta: 0:00:25  loss: 0.6921 (0.6959)  time: 0.1905  data: 0.0001  max mem: 14938
[21:02:17.048351] Test:  [220/345]  eta: 0:00:23  loss: 0.6915 (0.6958)  time: 0.1908  data: 0.0001  max mem: 14938
[21:02:18.963850] Test:  [230/345]  eta: 0:00:21  loss: 0.6936 (0.6957)  time: 0.1912  data: 0.0001  max mem: 14938
[21:02:20.883455] Test:  [240/345]  eta: 0:00:19  loss: 0.6941 (0.6956)  time: 0.1917  data: 0.0001  max mem: 14938
[21:02:22.806100] Test:  [250/345]  eta: 0:00:17  loss: 0.6915 (0.6954)  time: 0.1921  data: 0.0001  max mem: 14938
[21:02:24.731345] Test:  [260/345]  eta: 0:00:16  loss: 0.6915 (0.6954)  time: 0.1923  data: 0.0001  max mem: 14938
[21:02:26.658963] Test:  [270/345]  eta: 0:00:14  loss: 0.6972 (0.6956)  time: 0.1926  data: 0.0001  max mem: 14938
[21:02:28.590016] Test:  [280/345]  eta: 0:00:12  loss: 0.6928 (0.6955)  time: 0.1929  data: 0.0001  max mem: 14938
[21:02:30.523164] Test:  [290/345]  eta: 0:00:10  loss: 0.6928 (0.6956)  time: 0.1932  data: 0.0001  max mem: 14938
[21:02:32.461460] Test:  [300/345]  eta: 0:00:08  loss: 0.6953 (0.6954)  time: 0.1935  data: 0.0001  max mem: 14938
[21:02:34.402830] Test:  [310/345]  eta: 0:00:06  loss: 0.6950 (0.6954)  time: 0.1939  data: 0.0001  max mem: 14938
[21:02:36.347662] Test:  [320/345]  eta: 0:00:04  loss: 0.6975 (0.6956)  time: 0.1943  data: 0.0001  max mem: 14938
[21:02:38.295580] Test:  [330/345]  eta: 0:00:02  loss: 0.6988 (0.6957)  time: 0.1946  data: 0.0001  max mem: 14938
[21:02:40.247113] Test:  [340/345]  eta: 0:00:00  loss: 0.6948 (0.6957)  time: 0.1949  data: 0.0001  max mem: 14938
[21:02:41.029350] Test:  [344/345]  eta: 0:00:00  loss: 0.6937 (0.6957)  time: 0.1951  data: 0.0001  max mem: 14938
[21:02:41.088824] Test: Total time: 0:01:05 (0.1901 s / it)
[21:02:51.437484] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8513 (0.8513)  time: 0.3188  data: 0.1392  max mem: 14938
[21:02:53.255508] Test:  [10/57]  eta: 0:00:09  loss: 0.8923 (0.8864)  time: 0.1942  data: 0.0127  max mem: 14938
[21:02:55.077050] Test:  [20/57]  eta: 0:00:06  loss: 0.8923 (0.8708)  time: 0.1819  data: 0.0001  max mem: 14938
[21:02:56.903282] Test:  [30/57]  eta: 0:00:05  loss: 0.7556 (0.8294)  time: 0.1823  data: 0.0001  max mem: 14938
[21:02:58.732943] Test:  [40/57]  eta: 0:00:03  loss: 0.7463 (0.8080)  time: 0.1827  data: 0.0001  max mem: 14938
[21:03:00.568479] Test:  [50/57]  eta: 0:00:01  loss: 0.7312 (0.7994)  time: 0.1832  data: 0.0001  max mem: 14938
[21:03:01.558261] Test:  [56/57]  eta: 0:00:00  loss: 0.7463 (0.8044)  time: 0.1778  data: 0.0001  max mem: 14938
[21:03:01.617803] Test: Total time: 0:00:10 (0.1842 s / it)
[21:03:03.369470] Dice score of the network on the train images: 0.830926, val images: 0.821484
[21:03:03.374232] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:03:04.262026] Epoch: [37]  [  0/345]  eta: 0:05:05  lr: 0.000050  loss: 0.7298 (0.7298)  time: 0.8867  data: 0.1452  max mem: 14938
[21:03:19.149111] Epoch: [37]  [ 20/345]  eta: 0:04:04  lr: 0.000049  loss: 0.7143 (0.7180)  time: 0.7443  data: 0.0001  max mem: 14938
[21:03:34.095833] Epoch: [37]  [ 40/345]  eta: 0:03:48  lr: 0.000049  loss: 0.7141 (0.7173)  time: 0.7473  data: 0.0001  max mem: 14938
[21:03:49.048375] Epoch: [37]  [ 60/345]  eta: 0:03:33  lr: 0.000048  loss: 0.7209 (0.7184)  time: 0.7476  data: 0.0001  max mem: 14938
[21:04:04.154461] Epoch: [37]  [ 80/345]  eta: 0:03:18  lr: 0.000048  loss: 0.7223 (0.7191)  time: 0.7553  data: 0.0001  max mem: 14938
[21:04:19.169498] Epoch: [37]  [100/345]  eta: 0:03:03  lr: 0.000048  loss: 0.7129 (0.7185)  time: 0.7507  data: 0.0001  max mem: 14938
[21:04:34.197804] Epoch: [37]  [120/345]  eta: 0:02:48  lr: 0.000047  loss: 0.7130 (0.7186)  time: 0.7514  data: 0.0001  max mem: 14938
[21:04:49.232743] Epoch: [37]  [140/345]  eta: 0:02:33  lr: 0.000047  loss: 0.7178 (0.7186)  time: 0.7517  data: 0.0001  max mem: 14938
[21:05:04.262102] Epoch: [37]  [160/345]  eta: 0:02:18  lr: 0.000047  loss: 0.7167 (0.7185)  time: 0.7514  data: 0.0001  max mem: 14938
[21:05:19.286000] Epoch: [37]  [180/345]  eta: 0:02:03  lr: 0.000046  loss: 0.7159 (0.7185)  time: 0.7512  data: 0.0001  max mem: 14938
[21:05:34.299423] Epoch: [37]  [200/345]  eta: 0:01:48  lr: 0.000046  loss: 0.7152 (0.7185)  time: 0.7506  data: 0.0001  max mem: 14938
[21:05:49.310237] Epoch: [37]  [220/345]  eta: 0:01:33  lr: 0.000045  loss: 0.7182 (0.7185)  time: 0.7505  data: 0.0001  max mem: 14938
[21:06:04.309164] Epoch: [37]  [240/345]  eta: 0:01:18  lr: 0.000045  loss: 0.7162 (0.7184)  time: 0.7499  data: 0.0001  max mem: 14938
[21:06:19.319725] Epoch: [37]  [260/345]  eta: 0:01:03  lr: 0.000045  loss: 0.7201 (0.7187)  time: 0.7505  data: 0.0001  max mem: 14938
[21:06:34.322294] Epoch: [37]  [280/345]  eta: 0:00:48  lr: 0.000044  loss: 0.7160 (0.7187)  time: 0.7501  data: 0.0001  max mem: 14938
[21:06:49.322392] Epoch: [37]  [300/345]  eta: 0:00:33  lr: 0.000044  loss: 0.7133 (0.7184)  time: 0.7500  data: 0.0001  max mem: 14938
[21:07:04.408571] Epoch: [37]  [320/345]  eta: 0:00:18  lr: 0.000044  loss: 0.7115 (0.7183)  time: 0.7543  data: 0.0001  max mem: 14938
[21:07:19.388775] Epoch: [37]  [340/345]  eta: 0:00:03  lr: 0.000043  loss: 0.7205 (0.7185)  time: 0.7490  data: 0.0001  max mem: 14938
[21:07:22.385380] Epoch: [37]  [344/345]  eta: 0:00:00  lr: 0.000043  loss: 0.7245 (0.7185)  time: 0.7490  data: 0.0001  max mem: 14938
[21:07:22.450740] Epoch: [37] Total time: 0:04:19 (0.7509 s / it)
[21:07:22.451023] Averaged stats: lr: 0.000043  loss: 0.7245 (0.7185)
[21:07:22.787537] Test:  [  0/345]  eta: 0:01:54  loss: 0.7013 (0.7013)  time: 0.3330  data: 0.1515  max mem: 14938
[21:07:24.624706] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6923 (0.6928)  time: 0.1972  data: 0.0138  max mem: 14938
[21:07:26.464374] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6862 (0.6913)  time: 0.1838  data: 0.0001  max mem: 14938
[21:07:28.307712] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6888 (0.6927)  time: 0.1841  data: 0.0001  max mem: 14938
[21:07:30.156525] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6920 (0.6932)  time: 0.1846  data: 0.0001  max mem: 14938
[21:07:32.009314] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6947 (0.6936)  time: 0.1850  data: 0.0001  max mem: 14938
[21:07:33.863801] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6899 (0.6930)  time: 0.1853  data: 0.0001  max mem: 14938
[21:07:35.720267] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6856 (0.6921)  time: 0.1855  data: 0.0001  max mem: 14938
[21:07:37.581201] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6835 (0.6913)  time: 0.1858  data: 0.0001  max mem: 14938
[21:07:39.446150] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6894 (0.6917)  time: 0.1862  data: 0.0001  max mem: 14938
[21:07:41.315070] Test:  [100/345]  eta: 0:00:45  loss: 0.6920 (0.6917)  time: 0.1866  data: 0.0001  max mem: 14938
[21:07:43.186677] Test:  [110/345]  eta: 0:00:43  loss: 0.6940 (0.6922)  time: 0.1870  data: 0.0001  max mem: 14938
[21:07:45.061222] Test:  [120/345]  eta: 0:00:42  loss: 0.6928 (0.6921)  time: 0.1873  data: 0.0001  max mem: 14938
[21:07:46.941214] Test:  [130/345]  eta: 0:00:40  loss: 0.6913 (0.6922)  time: 0.1877  data: 0.0001  max mem: 14938
[21:07:48.824375] Test:  [140/345]  eta: 0:00:38  loss: 0.6881 (0.6923)  time: 0.1881  data: 0.0001  max mem: 14938
[21:07:50.710165] Test:  [150/345]  eta: 0:00:36  loss: 0.6904 (0.6924)  time: 0.1884  data: 0.0001  max mem: 14938
[21:07:52.598145] Test:  [160/345]  eta: 0:00:34  loss: 0.6919 (0.6925)  time: 0.1886  data: 0.0001  max mem: 14938
[21:07:54.489360] Test:  [170/345]  eta: 0:00:32  loss: 0.6866 (0.6920)  time: 0.1889  data: 0.0001  max mem: 14938
[21:07:56.385973] Test:  [180/345]  eta: 0:00:30  loss: 0.6862 (0.6922)  time: 0.1893  data: 0.0001  max mem: 14938
[21:07:58.286774] Test:  [190/345]  eta: 0:00:29  loss: 0.6966 (0.6925)  time: 0.1898  data: 0.0001  max mem: 14938
[21:08:00.189250] Test:  [200/345]  eta: 0:00:27  loss: 0.6969 (0.6926)  time: 0.1901  data: 0.0001  max mem: 14938
[21:08:02.098013] Test:  [210/345]  eta: 0:00:25  loss: 0.6930 (0.6927)  time: 0.1905  data: 0.0001  max mem: 14938
[21:08:04.010011] Test:  [220/345]  eta: 0:00:23  loss: 0.6927 (0.6927)  time: 0.1910  data: 0.0001  max mem: 14938
[21:08:05.925029] Test:  [230/345]  eta: 0:00:21  loss: 0.6887 (0.6925)  time: 0.1913  data: 0.0001  max mem: 14938
[21:08:07.842859] Test:  [240/345]  eta: 0:00:19  loss: 0.6930 (0.6926)  time: 0.1916  data: 0.0001  max mem: 14938
[21:08:09.764900] Test:  [250/345]  eta: 0:00:17  loss: 0.6921 (0.6925)  time: 0.1919  data: 0.0001  max mem: 14938
[21:08:11.691391] Test:  [260/345]  eta: 0:00:16  loss: 0.6919 (0.6925)  time: 0.1924  data: 0.0001  max mem: 14938
[21:08:13.620281] Test:  [270/345]  eta: 0:00:14  loss: 0.6906 (0.6923)  time: 0.1927  data: 0.0001  max mem: 14938
[21:08:15.551777] Test:  [280/345]  eta: 0:00:12  loss: 0.6894 (0.6923)  time: 0.1930  data: 0.0001  max mem: 14938
[21:08:17.487705] Test:  [290/345]  eta: 0:00:10  loss: 0.6928 (0.6924)  time: 0.1933  data: 0.0001  max mem: 14938
[21:08:19.426125] Test:  [300/345]  eta: 0:00:08  loss: 0.6928 (0.6924)  time: 0.1937  data: 0.0001  max mem: 14938
[21:08:21.367126] Test:  [310/345]  eta: 0:00:06  loss: 0.6894 (0.6923)  time: 0.1939  data: 0.0001  max mem: 14938
[21:08:23.311713] Test:  [320/345]  eta: 0:00:04  loss: 0.6897 (0.6923)  time: 0.1942  data: 0.0001  max mem: 14938
[21:08:25.258738] Test:  [330/345]  eta: 0:00:02  loss: 0.6920 (0.6924)  time: 0.1945  data: 0.0001  max mem: 14938
[21:08:27.209962] Test:  [340/345]  eta: 0:00:00  loss: 0.6985 (0.6927)  time: 0.1949  data: 0.0001  max mem: 14938
[21:08:27.992076] Test:  [344/345]  eta: 0:00:00  loss: 0.7019 (0.6928)  time: 0.1950  data: 0.0001  max mem: 14938
[21:08:28.049855] Test: Total time: 0:01:05 (0.1901 s / it)
[21:08:38.339150] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8482 (0.8482)  time: 0.3193  data: 0.1394  max mem: 14938
[21:08:40.157525] Test:  [10/57]  eta: 0:00:09  loss: 0.8945 (0.8832)  time: 0.1943  data: 0.0127  max mem: 14938
[21:08:41.980831] Test:  [20/57]  eta: 0:00:06  loss: 0.8945 (0.8741)  time: 0.1820  data: 0.0001  max mem: 14938
[21:08:43.808082] Test:  [30/57]  eta: 0:00:05  loss: 0.7550 (0.8320)  time: 0.1825  data: 0.0001  max mem: 14938
[21:08:45.640590] Test:  [40/57]  eta: 0:00:03  loss: 0.7473 (0.8106)  time: 0.1829  data: 0.0001  max mem: 14938
[21:08:47.475529] Test:  [50/57]  eta: 0:00:01  loss: 0.7308 (0.8020)  time: 0.1833  data: 0.0001  max mem: 14938
[21:08:48.466628] Test:  [56/57]  eta: 0:00:00  loss: 0.7555 (0.8075)  time: 0.1779  data: 0.0001  max mem: 14938
[21:08:48.522075] Test: Total time: 0:00:10 (0.1843 s / it)
[21:08:50.313811] Dice score of the network on the train images: 0.836228, val images: 0.819090
[21:08:50.314048] saving best_prec_model_0 @ epoch 37
[21:08:51.437487] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:08:52.323999] Epoch: [38]  [  0/345]  eta: 0:05:05  lr: 0.000043  loss: 0.7186 (0.7186)  time: 0.8854  data: 0.1418  max mem: 14938
[21:09:07.205980] Epoch: [38]  [ 20/345]  eta: 0:04:04  lr: 0.000043  loss: 0.7195 (0.7174)  time: 0.7441  data: 0.0001  max mem: 14938
[21:09:22.149638] Epoch: [38]  [ 40/345]  eta: 0:03:48  lr: 0.000042  loss: 0.7147 (0.7179)  time: 0.7471  data: 0.0001  max mem: 14938
[21:09:37.129797] Epoch: [38]  [ 60/345]  eta: 0:03:33  lr: 0.000042  loss: 0.7154 (0.7173)  time: 0.7490  data: 0.0001  max mem: 14938
[21:09:52.130388] Epoch: [38]  [ 80/345]  eta: 0:03:18  lr: 0.000042  loss: 0.7152 (0.7168)  time: 0.7500  data: 0.0001  max mem: 14938
[21:10:07.129892] Epoch: [38]  [100/345]  eta: 0:03:03  lr: 0.000041  loss: 0.7145 (0.7165)  time: 0.7499  data: 0.0001  max mem: 14938
[21:10:22.152869] Epoch: [38]  [120/345]  eta: 0:02:48  lr: 0.000041  loss: 0.7193 (0.7173)  time: 0.7511  data: 0.0001  max mem: 14938
[21:10:37.175532] Epoch: [38]  [140/345]  eta: 0:02:33  lr: 0.000041  loss: 0.7163 (0.7174)  time: 0.7511  data: 0.0001  max mem: 14938
[21:10:52.191952] Epoch: [38]  [160/345]  eta: 0:02:18  lr: 0.000040  loss: 0.7087 (0.7168)  time: 0.7508  data: 0.0001  max mem: 14938
[21:11:07.215614] Epoch: [38]  [180/345]  eta: 0:02:03  lr: 0.000040  loss: 0.7104 (0.7165)  time: 0.7511  data: 0.0001  max mem: 14938
[21:11:22.231805] Epoch: [38]  [200/345]  eta: 0:01:48  lr: 0.000040  loss: 0.7136 (0.7165)  time: 0.7508  data: 0.0001  max mem: 14938
[21:11:37.238311] Epoch: [38]  [220/345]  eta: 0:01:33  lr: 0.000039  loss: 0.7136 (0.7164)  time: 0.7503  data: 0.0001  max mem: 14938
[21:11:52.232583] Epoch: [38]  [240/345]  eta: 0:01:18  lr: 0.000039  loss: 0.7142 (0.7162)  time: 0.7497  data: 0.0001  max mem: 14938
[21:12:07.224129] Epoch: [38]  [260/345]  eta: 0:01:03  lr: 0.000039  loss: 0.7079 (0.7157)  time: 0.7495  data: 0.0001  max mem: 14938
[21:12:22.207307] Epoch: [38]  [280/345]  eta: 0:00:48  lr: 0.000038  loss: 0.7146 (0.7159)  time: 0.7491  data: 0.0001  max mem: 14938
[21:12:37.186779] Epoch: [38]  [300/345]  eta: 0:00:33  lr: 0.000038  loss: 0.7168 (0.7160)  time: 0.7489  data: 0.0001  max mem: 14938
[21:12:52.167518] Epoch: [38]  [320/345]  eta: 0:00:18  lr: 0.000038  loss: 0.7110 (0.7159)  time: 0.7490  data: 0.0001  max mem: 14938
[21:13:07.150846] Epoch: [38]  [340/345]  eta: 0:00:03  lr: 0.000037  loss: 0.7171 (0.7161)  time: 0.7491  data: 0.0001  max mem: 14938
[21:13:10.145457] Epoch: [38]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 0.7171 (0.7160)  time: 0.7490  data: 0.0001  max mem: 14938
[21:13:10.189156] Epoch: [38] Total time: 0:04:18 (0.7500 s / it)
[21:13:10.189422] Averaged stats: lr: 0.000037  loss: 0.7171 (0.7160)
[21:13:10.521300] Test:  [  0/345]  eta: 0:01:53  loss: 0.6640 (0.6640)  time: 0.3281  data: 0.1460  max mem: 14938
[21:13:12.360275] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6951 (0.6950)  time: 0.1969  data: 0.0133  max mem: 14938
[21:13:14.201386] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6939 (0.6940)  time: 0.1839  data: 0.0001  max mem: 14938
[21:13:16.045637] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6852 (0.6921)  time: 0.1842  data: 0.0001  max mem: 14938
[21:13:17.895045] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6844 (0.6918)  time: 0.1846  data: 0.0001  max mem: 14938
[21:13:19.746855] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6881 (0.6917)  time: 0.1850  data: 0.0001  max mem: 14938
[21:13:21.603268] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6915 (0.6915)  time: 0.1854  data: 0.0001  max mem: 14938
[21:13:23.461575] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6923 (0.6913)  time: 0.1857  data: 0.0001  max mem: 14938
[21:13:25.324557] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6896 (0.6914)  time: 0.1860  data: 0.0001  max mem: 14938
[21:13:27.189579] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6918 (0.6915)  time: 0.1864  data: 0.0001  max mem: 14938
[21:13:29.058478] Test:  [100/345]  eta: 0:00:45  loss: 0.6948 (0.6920)  time: 0.1866  data: 0.0001  max mem: 14938
[21:13:30.931397] Test:  [110/345]  eta: 0:00:43  loss: 0.6945 (0.6920)  time: 0.1870  data: 0.0001  max mem: 14938
[21:13:32.805637] Test:  [120/345]  eta: 0:00:42  loss: 0.6893 (0.6920)  time: 0.1873  data: 0.0001  max mem: 14938
[21:13:34.684758] Test:  [130/345]  eta: 0:00:40  loss: 0.6893 (0.6916)  time: 0.1876  data: 0.0001  max mem: 14938
[21:13:36.568217] Test:  [140/345]  eta: 0:00:38  loss: 0.6870 (0.6913)  time: 0.1881  data: 0.0001  max mem: 14938
[21:13:38.454776] Test:  [150/345]  eta: 0:00:36  loss: 0.6870 (0.6915)  time: 0.1885  data: 0.0001  max mem: 14938
[21:13:40.342672] Test:  [160/345]  eta: 0:00:34  loss: 0.6852 (0.6911)  time: 0.1887  data: 0.0001  max mem: 14938
[21:13:42.235704] Test:  [170/345]  eta: 0:00:32  loss: 0.6907 (0.6914)  time: 0.1890  data: 0.0001  max mem: 14938
[21:13:44.133326] Test:  [180/345]  eta: 0:00:30  loss: 0.6854 (0.6909)  time: 0.1895  data: 0.0001  max mem: 14938
[21:13:46.033317] Test:  [190/345]  eta: 0:00:29  loss: 0.6854 (0.6910)  time: 0.1898  data: 0.0001  max mem: 14938
[21:13:47.935588] Test:  [200/345]  eta: 0:00:27  loss: 0.6939 (0.6910)  time: 0.1901  data: 0.0001  max mem: 14938
[21:13:49.843329] Test:  [210/345]  eta: 0:00:25  loss: 0.6898 (0.6910)  time: 0.1905  data: 0.0001  max mem: 14938
[21:13:51.755801] Test:  [220/345]  eta: 0:00:23  loss: 0.6842 (0.6908)  time: 0.1910  data: 0.0001  max mem: 14938
[21:13:53.669356] Test:  [230/345]  eta: 0:00:21  loss: 0.6876 (0.6910)  time: 0.1913  data: 0.0001  max mem: 14938
[21:13:55.588407] Test:  [240/345]  eta: 0:00:19  loss: 0.6895 (0.6910)  time: 0.1916  data: 0.0001  max mem: 14938
[21:13:57.511289] Test:  [250/345]  eta: 0:00:17  loss: 0.6862 (0.6908)  time: 0.1920  data: 0.0001  max mem: 14938
[21:13:59.437289] Test:  [260/345]  eta: 0:00:16  loss: 0.6884 (0.6909)  time: 0.1924  data: 0.0001  max mem: 14938
[21:14:01.366109] Test:  [270/345]  eta: 0:00:14  loss: 0.6919 (0.6909)  time: 0.1927  data: 0.0001  max mem: 14938
[21:14:03.298666] Test:  [280/345]  eta: 0:00:12  loss: 0.6908 (0.6907)  time: 0.1930  data: 0.0001  max mem: 14938
[21:14:05.233906] Test:  [290/345]  eta: 0:00:10  loss: 0.6908 (0.6907)  time: 0.1933  data: 0.0001  max mem: 14938
[21:14:07.174328] Test:  [300/345]  eta: 0:00:08  loss: 0.6897 (0.6907)  time: 0.1937  data: 0.0001  max mem: 14938
[21:14:09.116932] Test:  [310/345]  eta: 0:00:06  loss: 0.6834 (0.6905)  time: 0.1941  data: 0.0001  max mem: 14938
[21:14:11.060233] Test:  [320/345]  eta: 0:00:04  loss: 0.6874 (0.6906)  time: 0.1942  data: 0.0001  max mem: 14938
[21:14:13.008425] Test:  [330/345]  eta: 0:00:02  loss: 0.6871 (0.6905)  time: 0.1945  data: 0.0001  max mem: 14938
[21:14:14.959472] Test:  [340/345]  eta: 0:00:00  loss: 0.6850 (0.6906)  time: 0.1949  data: 0.0001  max mem: 14938
[21:14:15.741338] Test:  [344/345]  eta: 0:00:00  loss: 0.6850 (0.6905)  time: 0.1951  data: 0.0001  max mem: 14938
[21:14:15.800631] Test: Total time: 0:01:05 (0.1902 s / it)
[21:14:26.224290] Test:  [ 0/57]  eta: 0:00:17  loss: 0.8483 (0.8483)  time: 0.3154  data: 0.1363  max mem: 14938
[21:14:28.042216] Test:  [10/57]  eta: 0:00:09  loss: 0.8905 (0.8794)  time: 0.1939  data: 0.0125  max mem: 14938
[21:14:29.866802] Test:  [20/57]  eta: 0:00:06  loss: 0.8905 (0.8706)  time: 0.1821  data: 0.0001  max mem: 14938
[21:14:31.693977] Test:  [30/57]  eta: 0:00:05  loss: 0.7504 (0.8290)  time: 0.1825  data: 0.0001  max mem: 14938
[21:14:33.525109] Test:  [40/57]  eta: 0:00:03  loss: 0.7430 (0.8076)  time: 0.1829  data: 0.0001  max mem: 14938
[21:14:35.362221] Test:  [50/57]  eta: 0:00:01  loss: 0.7344 (0.7993)  time: 0.1834  data: 0.0001  max mem: 14938
[21:14:36.352533] Test:  [56/57]  eta: 0:00:00  loss: 0.7551 (0.8050)  time: 0.1779  data: 0.0001  max mem: 14938
[21:14:36.411700] Test: Total time: 0:00:10 (0.1843 s / it)
[21:14:38.166319] Dice score of the network on the train images: 0.832898, val images: 0.821649
[21:14:38.170424] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:14:39.056512] Epoch: [39]  [  0/345]  eta: 0:05:05  lr: 0.000037  loss: 0.7185 (0.7185)  time: 0.8850  data: 0.1427  max mem: 14938
[21:14:53.940413] Epoch: [39]  [ 20/345]  eta: 0:04:04  lr: 0.000037  loss: 0.7114 (0.7108)  time: 0.7441  data: 0.0001  max mem: 14938
[21:15:08.883910] Epoch: [39]  [ 40/345]  eta: 0:03:48  lr: 0.000036  loss: 0.7177 (0.7149)  time: 0.7471  data: 0.0001  max mem: 14938
[21:15:23.863137] Epoch: [39]  [ 60/345]  eta: 0:03:33  lr: 0.000036  loss: 0.7096 (0.7152)  time: 0.7489  data: 0.0001  max mem: 14938
[21:15:38.861576] Epoch: [39]  [ 80/345]  eta: 0:03:18  lr: 0.000036  loss: 0.7108 (0.7147)  time: 0.7499  data: 0.0001  max mem: 14938
[21:15:53.876285] Epoch: [39]  [100/345]  eta: 0:03:03  lr: 0.000035  loss: 0.7199 (0.7158)  time: 0.7507  data: 0.0001  max mem: 14938
[21:16:08.890130] Epoch: [39]  [120/345]  eta: 0:02:48  lr: 0.000035  loss: 0.7103 (0.7157)  time: 0.7506  data: 0.0001  max mem: 14938
[21:16:23.906893] Epoch: [39]  [140/345]  eta: 0:02:33  lr: 0.000035  loss: 0.7085 (0.7149)  time: 0.7508  data: 0.0001  max mem: 14938
[21:16:38.918682] Epoch: [39]  [160/345]  eta: 0:02:18  lr: 0.000034  loss: 0.7084 (0.7146)  time: 0.7505  data: 0.0001  max mem: 14938
[21:16:53.931356] Epoch: [39]  [180/345]  eta: 0:02:03  lr: 0.000034  loss: 0.7141 (0.7146)  time: 0.7506  data: 0.0001  max mem: 14938
[21:17:08.952573] Epoch: [39]  [200/345]  eta: 0:01:48  lr: 0.000034  loss: 0.7148 (0.7148)  time: 0.7510  data: 0.0001  max mem: 14938
[21:17:23.963568] Epoch: [39]  [220/345]  eta: 0:01:33  lr: 0.000033  loss: 0.7154 (0.7150)  time: 0.7505  data: 0.0001  max mem: 14938
[21:17:38.962677] Epoch: [39]  [240/345]  eta: 0:01:18  lr: 0.000033  loss: 0.7084 (0.7149)  time: 0.7499  data: 0.0001  max mem: 14938
[21:17:53.970625] Epoch: [39]  [260/345]  eta: 0:01:03  lr: 0.000033  loss: 0.7151 (0.7150)  time: 0.7503  data: 0.0001  max mem: 14938
[21:18:09.052995] Epoch: [39]  [280/345]  eta: 0:00:48  lr: 0.000032  loss: 0.7065 (0.7147)  time: 0.7541  data: 0.0001  max mem: 14938
[21:18:24.044344] Epoch: [39]  [300/345]  eta: 0:00:33  lr: 0.000032  loss: 0.7114 (0.7147)  time: 0.7495  data: 0.0001  max mem: 14938
[21:18:39.039834] Epoch: [39]  [320/345]  eta: 0:00:18  lr: 0.000032  loss: 0.7137 (0.7147)  time: 0.7497  data: 0.0001  max mem: 14938
[21:18:54.034554] Epoch: [39]  [340/345]  eta: 0:00:03  lr: 0.000031  loss: 0.7150 (0.7147)  time: 0.7497  data: 0.0001  max mem: 14938
[21:18:57.033537] Epoch: [39]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 0.7150 (0.7147)  time: 0.7498  data: 0.0001  max mem: 14938
[21:18:57.098071] Epoch: [39] Total time: 0:04:18 (0.7505 s / it)
[21:18:57.098391] Averaged stats: lr: 0.000031  loss: 0.7150 (0.7147)
[21:18:57.432233] Test:  [  0/345]  eta: 0:01:53  loss: 0.6853 (0.6853)  time: 0.3294  data: 0.1475  max mem: 14938
[21:18:59.268948] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6858 (0.6868)  time: 0.1968  data: 0.0135  max mem: 14938
[21:19:01.108628] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6890 (0.6909)  time: 0.1838  data: 0.0001  max mem: 14938
[21:19:02.952343] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6876 (0.6886)  time: 0.1841  data: 0.0001  max mem: 14938
[21:19:04.799120] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6828 (0.6874)  time: 0.1845  data: 0.0001  max mem: 14938
[21:19:06.649366] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6847 (0.6886)  time: 0.1848  data: 0.0001  max mem: 14938
[21:19:08.502545] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6897 (0.6902)  time: 0.1851  data: 0.0001  max mem: 14938
[21:19:10.358417] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6897 (0.6903)  time: 0.1854  data: 0.0001  max mem: 14938
[21:19:12.218561] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6856 (0.6900)  time: 0.1857  data: 0.0001  max mem: 14938
[21:19:14.084336] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6868 (0.6896)  time: 0.1862  data: 0.0001  max mem: 14938
[21:19:15.950911] Test:  [100/345]  eta: 0:00:45  loss: 0.6870 (0.6897)  time: 0.1866  data: 0.0001  max mem: 14938
[21:19:17.822253] Test:  [110/345]  eta: 0:00:43  loss: 0.6839 (0.6892)  time: 0.1868  data: 0.0001  max mem: 14938
[21:19:19.697674] Test:  [120/345]  eta: 0:00:42  loss: 0.6842 (0.6899)  time: 0.1873  data: 0.0001  max mem: 14938
[21:19:21.574953] Test:  [130/345]  eta: 0:00:40  loss: 0.6921 (0.6904)  time: 0.1876  data: 0.0001  max mem: 14938
[21:19:23.457769] Test:  [140/345]  eta: 0:00:38  loss: 0.6908 (0.6904)  time: 0.1880  data: 0.0001  max mem: 14938
[21:19:25.342343] Test:  [150/345]  eta: 0:00:36  loss: 0.6864 (0.6900)  time: 0.1883  data: 0.0001  max mem: 14938
[21:19:27.229730] Test:  [160/345]  eta: 0:00:34  loss: 0.6846 (0.6899)  time: 0.1885  data: 0.0001  max mem: 14938
[21:19:29.120342] Test:  [170/345]  eta: 0:00:32  loss: 0.6838 (0.6896)  time: 0.1889  data: 0.0001  max mem: 14938
[21:19:31.018190] Test:  [180/345]  eta: 0:00:30  loss: 0.6896 (0.6899)  time: 0.1894  data: 0.0001  max mem: 14938
[21:19:32.919787] Test:  [190/345]  eta: 0:00:29  loss: 0.6915 (0.6901)  time: 0.1899  data: 0.0001  max mem: 14938
[21:19:34.822604] Test:  [200/345]  eta: 0:00:27  loss: 0.6863 (0.6898)  time: 0.1902  data: 0.0001  max mem: 14938
[21:19:36.729439] Test:  [210/345]  eta: 0:00:25  loss: 0.6874 (0.6901)  time: 0.1904  data: 0.0001  max mem: 14938
[21:19:38.641008] Test:  [220/345]  eta: 0:00:23  loss: 0.6890 (0.6901)  time: 0.1909  data: 0.0001  max mem: 14938
[21:19:40.557049] Test:  [230/345]  eta: 0:00:21  loss: 0.6835 (0.6900)  time: 0.1913  data: 0.0001  max mem: 14938
[21:19:42.476985] Test:  [240/345]  eta: 0:00:19  loss: 0.6825 (0.6899)  time: 0.1918  data: 0.0001  max mem: 14938
[21:19:44.400808] Test:  [250/345]  eta: 0:00:17  loss: 0.6943 (0.6901)  time: 0.1921  data: 0.0001  max mem: 14938
[21:19:46.325288] Test:  [260/345]  eta: 0:00:16  loss: 0.6958 (0.6903)  time: 0.1924  data: 0.0001  max mem: 14938
[21:19:48.252682] Test:  [270/345]  eta: 0:00:14  loss: 0.6908 (0.6903)  time: 0.1925  data: 0.0001  max mem: 14938
[21:19:50.186194] Test:  [280/345]  eta: 0:00:12  loss: 0.6880 (0.6903)  time: 0.1930  data: 0.0001  max mem: 14938
[21:19:52.121065] Test:  [290/345]  eta: 0:00:10  loss: 0.6903 (0.6904)  time: 0.1934  data: 0.0001  max mem: 14938
[21:19:54.060502] Test:  [300/345]  eta: 0:00:08  loss: 0.6844 (0.6901)  time: 0.1937  data: 0.0001  max mem: 14938
[21:19:56.002309] Test:  [310/345]  eta: 0:00:06  loss: 0.6819 (0.6902)  time: 0.1940  data: 0.0001  max mem: 14938
[21:19:57.946761] Test:  [320/345]  eta: 0:00:04  loss: 0.6914 (0.6902)  time: 0.1943  data: 0.0001  max mem: 14938
[21:19:59.894358] Test:  [330/345]  eta: 0:00:02  loss: 0.6903 (0.6901)  time: 0.1946  data: 0.0001  max mem: 14938
[21:20:01.848031] Test:  [340/345]  eta: 0:00:00  loss: 0.6865 (0.6900)  time: 0.1950  data: 0.0001  max mem: 14938
[21:20:02.630744] Test:  [344/345]  eta: 0:00:00  loss: 0.6865 (0.6900)  time: 0.1952  data: 0.0001  max mem: 14938
[21:20:02.687899] Test: Total time: 0:01:05 (0.1901 s / it)
[21:20:13.063346] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8475 (0.8475)  time: 0.3182  data: 0.1382  max mem: 14938
[21:20:14.879712] Test:  [10/57]  eta: 0:00:09  loss: 0.8813 (0.8796)  time: 0.1940  data: 0.0126  max mem: 14938
[21:20:16.699551] Test:  [20/57]  eta: 0:00:06  loss: 0.8813 (0.8662)  time: 0.1817  data: 0.0001  max mem: 14938
[21:20:18.523598] Test:  [30/57]  eta: 0:00:05  loss: 0.7442 (0.8238)  time: 0.1821  data: 0.0001  max mem: 14938
[21:20:20.352976] Test:  [40/57]  eta: 0:00:03  loss: 0.7365 (0.8025)  time: 0.1826  data: 0.0001  max mem: 14938
[21:20:22.187049] Test:  [50/57]  eta: 0:00:01  loss: 0.7295 (0.7945)  time: 0.1831  data: 0.0001  max mem: 14938
[21:20:23.177009] Test:  [56/57]  eta: 0:00:00  loss: 0.7542 (0.8002)  time: 0.1777  data: 0.0001  max mem: 14938
[21:20:23.234317] Test: Total time: 0:00:10 (0.1840 s / it)
[21:20:24.952777] Dice score of the network on the train images: 0.826734, val images: 0.824606
[21:20:24.957524] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:20:25.842832] Epoch: [40]  [  0/345]  eta: 0:05:05  lr: 0.000031  loss: 0.7250 (0.7250)  time: 0.8842  data: 0.1409  max mem: 14938
[21:20:40.744109] Epoch: [40]  [ 20/345]  eta: 0:04:04  lr: 0.000031  loss: 0.7143 (0.7145)  time: 0.7450  data: 0.0001  max mem: 14938
[21:20:55.701396] Epoch: [40]  [ 40/345]  eta: 0:03:48  lr: 0.000031  loss: 0.7174 (0.7159)  time: 0.7478  data: 0.0001  max mem: 14938
[21:21:10.686882] Epoch: [40]  [ 60/345]  eta: 0:03:33  lr: 0.000030  loss: 0.7150 (0.7160)  time: 0.7492  data: 0.0001  max mem: 14938
[21:21:25.688321] Epoch: [40]  [ 80/345]  eta: 0:03:18  lr: 0.000030  loss: 0.7198 (0.7161)  time: 0.7500  data: 0.0001  max mem: 14938
[21:21:40.698192] Epoch: [40]  [100/345]  eta: 0:03:03  lr: 0.000030  loss: 0.7110 (0.7161)  time: 0.7504  data: 0.0001  max mem: 14938
[21:21:55.730218] Epoch: [40]  [120/345]  eta: 0:02:48  lr: 0.000029  loss: 0.7158 (0.7162)  time: 0.7516  data: 0.0001  max mem: 14938
[21:22:10.758811] Epoch: [40]  [140/345]  eta: 0:02:33  lr: 0.000029  loss: 0.7146 (0.7165)  time: 0.7514  data: 0.0001  max mem: 14938
[21:22:25.771729] Epoch: [40]  [160/345]  eta: 0:02:18  lr: 0.000029  loss: 0.7125 (0.7161)  time: 0.7506  data: 0.0001  max mem: 14938
[21:22:40.793859] Epoch: [40]  [180/345]  eta: 0:02:03  lr: 0.000028  loss: 0.7080 (0.7155)  time: 0.7511  data: 0.0001  max mem: 14938
[21:22:55.803736] Epoch: [40]  [200/345]  eta: 0:01:48  lr: 0.000028  loss: 0.7098 (0.7151)  time: 0.7505  data: 0.0001  max mem: 14938
[21:23:10.809990] Epoch: [40]  [220/345]  eta: 0:01:33  lr: 0.000028  loss: 0.7181 (0.7153)  time: 0.7503  data: 0.0001  max mem: 14938
[21:23:25.805358] Epoch: [40]  [240/345]  eta: 0:01:18  lr: 0.000027  loss: 0.7109 (0.7149)  time: 0.7497  data: 0.0001  max mem: 14938
[21:23:40.805924] Epoch: [40]  [260/345]  eta: 0:01:03  lr: 0.000027  loss: 0.7090 (0.7147)  time: 0.7500  data: 0.0001  max mem: 14938
[21:23:55.797044] Epoch: [40]  [280/345]  eta: 0:00:48  lr: 0.000027  loss: 0.7075 (0.7142)  time: 0.7495  data: 0.0001  max mem: 14938
[21:24:10.780877] Epoch: [40]  [300/345]  eta: 0:00:33  lr: 0.000026  loss: 0.7047 (0.7137)  time: 0.7491  data: 0.0001  max mem: 14938
[21:24:25.778420] Epoch: [40]  [320/345]  eta: 0:00:18  lr: 0.000026  loss: 0.7151 (0.7139)  time: 0.7498  data: 0.0001  max mem: 14938
[21:24:40.758441] Epoch: [40]  [340/345]  eta: 0:00:03  lr: 0.000026  loss: 0.7137 (0.7140)  time: 0.7490  data: 0.0001  max mem: 14938
[21:24:43.760755] Epoch: [40]  [344/345]  eta: 0:00:00  lr: 0.000026  loss: 0.7142 (0.7140)  time: 0.7493  data: 0.0001  max mem: 14938
[21:24:43.823547] Epoch: [40] Total time: 0:04:18 (0.7503 s / it)
[21:24:43.823786] Averaged stats: lr: 0.000026  loss: 0.7142 (0.7140)
[21:24:44.155933] Test:  [  0/345]  eta: 0:01:53  loss: 0.6941 (0.6941)  time: 0.3280  data: 0.1458  max mem: 14938
[21:24:45.994051] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6881 (0.6898)  time: 0.1968  data: 0.0133  max mem: 14938
[21:24:47.833505] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6881 (0.6895)  time: 0.1838  data: 0.0001  max mem: 14938
[21:24:49.676901] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6825 (0.6870)  time: 0.1841  data: 0.0001  max mem: 14938
[21:24:51.524072] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6802 (0.6859)  time: 0.1845  data: 0.0001  max mem: 14938
[21:24:53.374598] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6852 (0.6865)  time: 0.1848  data: 0.0001  max mem: 14938
[21:24:55.228755] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6896 (0.6870)  time: 0.1852  data: 0.0001  max mem: 14938
[21:24:57.086839] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6868 (0.6873)  time: 0.1856  data: 0.0001  max mem: 14938
[21:24:58.948592] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6868 (0.6875)  time: 0.1859  data: 0.0001  max mem: 14938
[21:25:00.813986] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6864 (0.6870)  time: 0.1863  data: 0.0001  max mem: 14938
[21:25:02.681742] Test:  [100/345]  eta: 0:00:45  loss: 0.6885 (0.6874)  time: 0.1866  data: 0.0001  max mem: 14938
[21:25:04.554298] Test:  [110/345]  eta: 0:00:43  loss: 0.6882 (0.6870)  time: 0.1870  data: 0.0001  max mem: 14938
[21:25:06.430288] Test:  [120/345]  eta: 0:00:42  loss: 0.6804 (0.6865)  time: 0.1874  data: 0.0001  max mem: 14938
[21:25:08.308769] Test:  [130/345]  eta: 0:00:40  loss: 0.6819 (0.6863)  time: 0.1877  data: 0.0001  max mem: 14938
[21:25:10.191720] Test:  [140/345]  eta: 0:00:38  loss: 0.6853 (0.6863)  time: 0.1880  data: 0.0001  max mem: 14938
[21:25:12.076481] Test:  [150/345]  eta: 0:00:36  loss: 0.6913 (0.6867)  time: 0.1883  data: 0.0001  max mem: 14938
[21:25:13.965562] Test:  [160/345]  eta: 0:00:34  loss: 0.6875 (0.6867)  time: 0.1886  data: 0.0001  max mem: 14938
[21:25:15.856940] Test:  [170/345]  eta: 0:00:32  loss: 0.6870 (0.6868)  time: 0.1890  data: 0.0001  max mem: 14938
[21:25:17.755454] Test:  [180/345]  eta: 0:00:30  loss: 0.6877 (0.6869)  time: 0.1894  data: 0.0001  max mem: 14938
[21:25:19.655179] Test:  [190/345]  eta: 0:00:29  loss: 0.6883 (0.6869)  time: 0.1899  data: 0.0001  max mem: 14938
[21:25:21.557835] Test:  [200/345]  eta: 0:00:27  loss: 0.6899 (0.6873)  time: 0.1901  data: 0.0001  max mem: 14938
[21:25:23.464683] Test:  [210/345]  eta: 0:00:25  loss: 0.6945 (0.6875)  time: 0.1904  data: 0.0001  max mem: 14938
[21:25:25.375964] Test:  [220/345]  eta: 0:00:23  loss: 0.6906 (0.6875)  time: 0.1909  data: 0.0001  max mem: 14938
[21:25:27.291461] Test:  [230/345]  eta: 0:00:21  loss: 0.6881 (0.6876)  time: 0.1913  data: 0.0001  max mem: 14938
[21:25:29.210544] Test:  [240/345]  eta: 0:00:19  loss: 0.6884 (0.6877)  time: 0.1917  data: 0.0001  max mem: 14938
[21:25:31.131187] Test:  [250/345]  eta: 0:00:17  loss: 0.6904 (0.6880)  time: 0.1919  data: 0.0001  max mem: 14938
[21:25:33.057086] Test:  [260/345]  eta: 0:00:16  loss: 0.6852 (0.6880)  time: 0.1923  data: 0.0001  max mem: 14938
[21:25:34.986085] Test:  [270/345]  eta: 0:00:14  loss: 0.6839 (0.6879)  time: 0.1927  data: 0.0001  max mem: 14938
[21:25:36.916989] Test:  [280/345]  eta: 0:00:12  loss: 0.6874 (0.6879)  time: 0.1929  data: 0.0001  max mem: 14938
[21:25:38.854425] Test:  [290/345]  eta: 0:00:10  loss: 0.6900 (0.6880)  time: 0.1934  data: 0.0001  max mem: 14938
[21:25:40.792813] Test:  [300/345]  eta: 0:00:08  loss: 0.6903 (0.6880)  time: 0.1937  data: 0.0001  max mem: 14938
[21:25:42.734866] Test:  [310/345]  eta: 0:00:06  loss: 0.6921 (0.6880)  time: 0.1940  data: 0.0001  max mem: 14938
[21:25:44.678105] Test:  [320/345]  eta: 0:00:04  loss: 0.6921 (0.6882)  time: 0.1942  data: 0.0001  max mem: 14938
[21:25:46.625471] Test:  [330/345]  eta: 0:00:02  loss: 0.6865 (0.6882)  time: 0.1945  data: 0.0001  max mem: 14938
[21:25:48.576200] Test:  [340/345]  eta: 0:00:00  loss: 0.6862 (0.6884)  time: 0.1949  data: 0.0001  max mem: 14938
[21:25:49.357761] Test:  [344/345]  eta: 0:00:00  loss: 0.6853 (0.6883)  time: 0.1950  data: 0.0001  max mem: 14938
[21:25:49.415837] Test: Total time: 0:01:05 (0.1901 s / it)
[21:25:59.829116] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8631 (0.8631)  time: 0.3187  data: 0.1391  max mem: 14938
[21:26:01.647275] Test:  [10/57]  eta: 0:00:09  loss: 0.8932 (0.8881)  time: 0.1942  data: 0.0127  max mem: 14938
[21:26:03.469031] Test:  [20/57]  eta: 0:00:06  loss: 0.8932 (0.8743)  time: 0.1819  data: 0.0001  max mem: 14938
[21:26:05.295019] Test:  [30/57]  eta: 0:00:05  loss: 0.7542 (0.8320)  time: 0.1823  data: 0.0001  max mem: 14938
[21:26:07.126598] Test:  [40/57]  eta: 0:00:03  loss: 0.7429 (0.8107)  time: 0.1828  data: 0.0001  max mem: 14938
[21:26:08.962900] Test:  [50/57]  eta: 0:00:01  loss: 0.7329 (0.8023)  time: 0.1833  data: 0.0001  max mem: 14938
[21:26:09.953234] Test:  [56/57]  eta: 0:00:00  loss: 0.7546 (0.8075)  time: 0.1780  data: 0.0001  max mem: 14938
[21:26:10.012144] Test: Total time: 0:00:10 (0.1843 s / it)
[21:26:11.757367] Dice score of the network on the train images: 0.836430, val images: 0.821821
[21:26:11.761677] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:26:12.648689] Epoch: [41]  [  0/345]  eta: 0:05:05  lr: 0.000026  loss: 0.6914 (0.6914)  time: 0.8859  data: 0.1427  max mem: 14938
[21:26:27.546909] Epoch: [41]  [ 20/345]  eta: 0:04:04  lr: 0.000025  loss: 0.7022 (0.7047)  time: 0.7449  data: 0.0001  max mem: 14938
[21:26:42.499098] Epoch: [41]  [ 40/345]  eta: 0:03:48  lr: 0.000025  loss: 0.7132 (0.7092)  time: 0.7476  data: 0.0001  max mem: 14938
[21:26:57.476449] Epoch: [41]  [ 60/345]  eta: 0:03:33  lr: 0.000025  loss: 0.7125 (0.7109)  time: 0.7488  data: 0.0001  max mem: 14938
[21:27:12.450826] Epoch: [41]  [ 80/345]  eta: 0:03:18  lr: 0.000025  loss: 0.7100 (0.7117)  time: 0.7487  data: 0.0001  max mem: 14938
[21:27:27.450506] Epoch: [41]  [100/345]  eta: 0:03:03  lr: 0.000024  loss: 0.7120 (0.7119)  time: 0.7499  data: 0.0001  max mem: 14938
[21:27:42.470233] Epoch: [41]  [120/345]  eta: 0:02:48  lr: 0.000024  loss: 0.7067 (0.7114)  time: 0.7509  data: 0.0001  max mem: 14938
[21:27:57.484693] Epoch: [41]  [140/345]  eta: 0:02:33  lr: 0.000024  loss: 0.7030 (0.7111)  time: 0.7507  data: 0.0001  max mem: 14938
[21:28:12.499097] Epoch: [41]  [160/345]  eta: 0:02:18  lr: 0.000023  loss: 0.7115 (0.7109)  time: 0.7507  data: 0.0001  max mem: 14938
[21:28:27.517101] Epoch: [41]  [180/345]  eta: 0:02:03  lr: 0.000023  loss: 0.7088 (0.7108)  time: 0.7509  data: 0.0001  max mem: 14938
[21:28:42.533732] Epoch: [41]  [200/345]  eta: 0:01:48  lr: 0.000023  loss: 0.7095 (0.7107)  time: 0.7508  data: 0.0001  max mem: 14938
[21:28:57.546390] Epoch: [41]  [220/345]  eta: 0:01:33  lr: 0.000022  loss: 0.7090 (0.7106)  time: 0.7506  data: 0.0001  max mem: 14938
[21:29:12.549011] Epoch: [41]  [240/345]  eta: 0:01:18  lr: 0.000022  loss: 0.7108 (0.7109)  time: 0.7501  data: 0.0001  max mem: 14938
[21:29:27.535459] Epoch: [41]  [260/345]  eta: 0:01:03  lr: 0.000022  loss: 0.7152 (0.7113)  time: 0.7493  data: 0.0001  max mem: 14938
[21:29:42.516340] Epoch: [41]  [280/345]  eta: 0:00:48  lr: 0.000022  loss: 0.7129 (0.7115)  time: 0.7490  data: 0.0001  max mem: 14938
[21:29:57.515937] Epoch: [41]  [300/345]  eta: 0:00:33  lr: 0.000021  loss: 0.7122 (0.7117)  time: 0.7499  data: 0.0001  max mem: 14938
[21:30:12.511500] Epoch: [41]  [320/345]  eta: 0:00:18  lr: 0.000021  loss: 0.7052 (0.7116)  time: 0.7497  data: 0.0001  max mem: 14938
[21:30:27.508761] Epoch: [41]  [340/345]  eta: 0:00:03  lr: 0.000021  loss: 0.7084 (0.7115)  time: 0.7498  data: 0.0001  max mem: 14938
[21:30:30.508123] Epoch: [41]  [344/345]  eta: 0:00:00  lr: 0.000021  loss: 0.7084 (0.7115)  time: 0.7498  data: 0.0001  max mem: 14938
[21:30:30.566948] Epoch: [41] Total time: 0:04:18 (0.7502 s / it)
[21:30:30.567243] Averaged stats: lr: 0.000021  loss: 0.7084 (0.7115)
[21:30:30.903683] Test:  [  0/345]  eta: 0:01:54  loss: 0.6769 (0.6769)  time: 0.3320  data: 0.1499  max mem: 14938
[21:30:32.740591] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6938 (0.6890)  time: 0.1971  data: 0.0137  max mem: 14938
[21:30:34.581795] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6948 (0.6926)  time: 0.1838  data: 0.0001  max mem: 14938
[21:30:36.425448] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6943 (0.6920)  time: 0.1842  data: 0.0001  max mem: 14938
[21:30:38.271893] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6821 (0.6900)  time: 0.1845  data: 0.0001  max mem: 14938
[21:30:40.121148] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6813 (0.6884)  time: 0.1847  data: 0.0001  max mem: 14938
[21:30:41.976194] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6804 (0.6875)  time: 0.1852  data: 0.0001  max mem: 14938
[21:30:43.834470] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6865 (0.6877)  time: 0.1856  data: 0.0001  max mem: 14938
[21:30:45.694885] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6865 (0.6875)  time: 0.1859  data: 0.0001  max mem: 14938
[21:30:47.560015] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6838 (0.6870)  time: 0.1862  data: 0.0001  max mem: 14938
[21:30:49.427282] Test:  [100/345]  eta: 0:00:45  loss: 0.6823 (0.6870)  time: 0.1866  data: 0.0001  max mem: 14938
[21:30:51.299487] Test:  [110/345]  eta: 0:00:43  loss: 0.6843 (0.6872)  time: 0.1869  data: 0.0001  max mem: 14938
[21:30:53.173783] Test:  [120/345]  eta: 0:00:42  loss: 0.6878 (0.6872)  time: 0.1873  data: 0.0001  max mem: 14938
[21:30:55.051569] Test:  [130/345]  eta: 0:00:40  loss: 0.6839 (0.6874)  time: 0.1876  data: 0.0001  max mem: 14938
[21:30:56.934079] Test:  [140/345]  eta: 0:00:38  loss: 0.6869 (0.6877)  time: 0.1880  data: 0.0001  max mem: 14938
[21:30:58.820335] Test:  [150/345]  eta: 0:00:36  loss: 0.6877 (0.6875)  time: 0.1884  data: 0.0001  max mem: 14938
[21:31:00.706548] Test:  [160/345]  eta: 0:00:34  loss: 0.6845 (0.6873)  time: 0.1886  data: 0.0001  max mem: 14938
[21:31:02.598688] Test:  [170/345]  eta: 0:00:32  loss: 0.6839 (0.6870)  time: 0.1889  data: 0.0001  max mem: 14938
[21:31:04.494362] Test:  [180/345]  eta: 0:00:30  loss: 0.6859 (0.6872)  time: 0.1893  data: 0.0001  max mem: 14938
[21:31:06.393635] Test:  [190/345]  eta: 0:00:29  loss: 0.6910 (0.6872)  time: 0.1897  data: 0.0001  max mem: 14938
[21:31:08.296175] Test:  [200/345]  eta: 0:00:27  loss: 0.6896 (0.6874)  time: 0.1900  data: 0.0001  max mem: 14938
[21:31:10.204310] Test:  [210/345]  eta: 0:00:25  loss: 0.6841 (0.6870)  time: 0.1905  data: 0.0001  max mem: 14938
[21:31:12.115179] Test:  [220/345]  eta: 0:00:23  loss: 0.6804 (0.6870)  time: 0.1909  data: 0.0001  max mem: 14938
[21:31:14.031395] Test:  [230/345]  eta: 0:00:21  loss: 0.6815 (0.6870)  time: 0.1913  data: 0.0001  max mem: 14938
[21:31:15.948630] Test:  [240/345]  eta: 0:00:19  loss: 0.6842 (0.6871)  time: 0.1916  data: 0.0001  max mem: 14938
[21:31:17.870661] Test:  [250/345]  eta: 0:00:17  loss: 0.6858 (0.6872)  time: 0.1919  data: 0.0001  max mem: 14938
[21:31:19.795357] Test:  [260/345]  eta: 0:00:16  loss: 0.6804 (0.6870)  time: 0.1923  data: 0.0001  max mem: 14938
[21:31:21.723191] Test:  [270/345]  eta: 0:00:14  loss: 0.6814 (0.6870)  time: 0.1926  data: 0.0001  max mem: 14938
[21:31:23.656563] Test:  [280/345]  eta: 0:00:12  loss: 0.6827 (0.6870)  time: 0.1930  data: 0.0001  max mem: 14938
[21:31:25.591792] Test:  [290/345]  eta: 0:00:10  loss: 0.6877 (0.6871)  time: 0.1934  data: 0.0001  max mem: 14938
[21:31:27.531924] Test:  [300/345]  eta: 0:00:08  loss: 0.6852 (0.6871)  time: 0.1937  data: 0.0001  max mem: 14938
[21:31:29.472697] Test:  [310/345]  eta: 0:00:06  loss: 0.6853 (0.6871)  time: 0.1940  data: 0.0001  max mem: 14938
[21:31:31.416584] Test:  [320/345]  eta: 0:00:04  loss: 0.6847 (0.6870)  time: 0.1942  data: 0.0001  max mem: 14938
[21:31:33.364646] Test:  [330/345]  eta: 0:00:02  loss: 0.6839 (0.6870)  time: 0.1945  data: 0.0001  max mem: 14938
[21:31:35.314594] Test:  [340/345]  eta: 0:00:00  loss: 0.6853 (0.6871)  time: 0.1948  data: 0.0001  max mem: 14938
[21:31:36.096574] Test:  [344/345]  eta: 0:00:00  loss: 0.6891 (0.6872)  time: 0.1950  data: 0.0001  max mem: 14938
[21:31:36.155521] Test: Total time: 0:01:05 (0.1901 s / it)
[21:31:46.570771] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8567 (0.8567)  time: 0.3191  data: 0.1390  max mem: 14938
[21:31:48.388551] Test:  [10/57]  eta: 0:00:09  loss: 0.8899 (0.8863)  time: 0.1942  data: 0.0127  max mem: 14938
[21:31:50.210292] Test:  [20/57]  eta: 0:00:06  loss: 0.8899 (0.8729)  time: 0.1819  data: 0.0001  max mem: 14938
[21:31:52.037261] Test:  [30/57]  eta: 0:00:05  loss: 0.7523 (0.8301)  time: 0.1824  data: 0.0001  max mem: 14938
[21:31:53.867325] Test:  [40/57]  eta: 0:00:03  loss: 0.7390 (0.8084)  time: 0.1828  data: 0.0001  max mem: 14938
[21:31:55.705701] Test:  [50/57]  eta: 0:00:01  loss: 0.7307 (0.8001)  time: 0.1834  data: 0.0001  max mem: 14938
[21:31:56.696098] Test:  [56/57]  eta: 0:00:00  loss: 0.7547 (0.8055)  time: 0.1780  data: 0.0001  max mem: 14938
[21:31:56.755698] Test: Total time: 0:00:10 (0.1843 s / it)
[21:31:58.505471] Dice score of the network on the train images: 0.833623, val images: 0.822617
[21:31:58.509759] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:31:59.398358] Epoch: [42]  [  0/345]  eta: 0:05:06  lr: 0.000021  loss: 0.7005 (0.7005)  time: 0.8875  data: 0.1445  max mem: 14938
[21:32:14.304611] Epoch: [42]  [ 20/345]  eta: 0:04:04  lr: 0.000020  loss: 0.7056 (0.7064)  time: 0.7453  data: 0.0001  max mem: 14938
[21:32:29.257646] Epoch: [42]  [ 40/345]  eta: 0:03:48  lr: 0.000020  loss: 0.7089 (0.7081)  time: 0.7476  data: 0.0001  max mem: 14938
[21:32:44.244161] Epoch: [42]  [ 60/345]  eta: 0:03:33  lr: 0.000020  loss: 0.7078 (0.7085)  time: 0.7493  data: 0.0001  max mem: 14938
[21:32:59.236039] Epoch: [42]  [ 80/345]  eta: 0:03:18  lr: 0.000020  loss: 0.7164 (0.7101)  time: 0.7495  data: 0.0001  max mem: 14938
[21:33:14.235345] Epoch: [42]  [100/345]  eta: 0:03:03  lr: 0.000019  loss: 0.7112 (0.7110)  time: 0.7499  data: 0.0001  max mem: 14938
[21:33:29.226159] Epoch: [42]  [120/345]  eta: 0:02:48  lr: 0.000019  loss: 0.7146 (0.7113)  time: 0.7495  data: 0.0001  max mem: 14938
[21:33:44.227009] Epoch: [42]  [140/345]  eta: 0:02:33  lr: 0.000019  loss: 0.7094 (0.7110)  time: 0.7500  data: 0.0001  max mem: 14938
[21:33:59.244334] Epoch: [42]  [160/345]  eta: 0:02:18  lr: 0.000018  loss: 0.7081 (0.7107)  time: 0.7508  data: 0.0001  max mem: 14938
[21:34:14.266029] Epoch: [42]  [180/345]  eta: 0:02:03  lr: 0.000018  loss: 0.7057 (0.7101)  time: 0.7510  data: 0.0001  max mem: 14938
[21:34:29.274243] Epoch: [42]  [200/345]  eta: 0:01:48  lr: 0.000018  loss: 0.7114 (0.7105)  time: 0.7504  data: 0.0001  max mem: 14938
[21:34:44.283290] Epoch: [42]  [220/345]  eta: 0:01:33  lr: 0.000018  loss: 0.7083 (0.7104)  time: 0.7504  data: 0.0001  max mem: 14938
[21:34:59.281647] Epoch: [42]  [240/345]  eta: 0:01:18  lr: 0.000017  loss: 0.7073 (0.7104)  time: 0.7499  data: 0.0001  max mem: 14938
[21:35:14.274783] Epoch: [42]  [260/345]  eta: 0:01:03  lr: 0.000017  loss: 0.7089 (0.7105)  time: 0.7496  data: 0.0001  max mem: 14938
[21:35:29.269590] Epoch: [42]  [280/345]  eta: 0:00:48  lr: 0.000017  loss: 0.7044 (0.7102)  time: 0.7497  data: 0.0001  max mem: 14938
[21:35:44.259046] Epoch: [42]  [300/345]  eta: 0:00:33  lr: 0.000017  loss: 0.7125 (0.7105)  time: 0.7494  data: 0.0001  max mem: 14938
[21:35:59.254422] Epoch: [42]  [320/345]  eta: 0:00:18  lr: 0.000016  loss: 0.7019 (0.7105)  time: 0.7497  data: 0.0001  max mem: 14938
[21:36:14.345856] Epoch: [42]  [340/345]  eta: 0:00:03  lr: 0.000016  loss: 0.7077 (0.7104)  time: 0.7545  data: 0.0001  max mem: 14938
[21:36:17.343954] Epoch: [42]  [344/345]  eta: 0:00:00  lr: 0.000016  loss: 0.7068 (0.7104)  time: 0.7543  data: 0.0001  max mem: 14938
[21:36:17.406797] Epoch: [42] Total time: 0:04:18 (0.7504 s / it)
[21:36:17.407295] Averaged stats: lr: 0.000016  loss: 0.7068 (0.7104)
[21:36:17.745723] Test:  [  0/345]  eta: 0:01:55  loss: 0.7098 (0.7098)  time: 0.3338  data: 0.1518  max mem: 14938
[21:36:19.583488] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6896 (0.6899)  time: 0.1973  data: 0.0139  max mem: 14938
[21:36:21.424100] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6798 (0.6856)  time: 0.1838  data: 0.0001  max mem: 14938
[21:36:23.267031] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6798 (0.6851)  time: 0.1841  data: 0.0001  max mem: 14938
[21:36:25.113769] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6831 (0.6861)  time: 0.1844  data: 0.0001  max mem: 14938
[21:36:26.965458] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6866 (0.6865)  time: 0.1849  data: 0.0001  max mem: 14938
[21:36:28.821267] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6870 (0.6864)  time: 0.1853  data: 0.0001  max mem: 14938
[21:36:30.678897] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6842 (0.6864)  time: 0.1856  data: 0.0001  max mem: 14938
[21:36:32.541314] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6814 (0.6857)  time: 0.1860  data: 0.0001  max mem: 14938
[21:36:34.405176] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6829 (0.6856)  time: 0.1863  data: 0.0001  max mem: 14938
[21:36:36.273909] Test:  [100/345]  eta: 0:00:45  loss: 0.6807 (0.6857)  time: 0.1866  data: 0.0001  max mem: 14938
[21:36:38.146166] Test:  [110/345]  eta: 0:00:43  loss: 0.6807 (0.6860)  time: 0.1870  data: 0.0001  max mem: 14938
[21:36:40.020337] Test:  [120/345]  eta: 0:00:42  loss: 0.6809 (0.6858)  time: 0.1873  data: 0.0001  max mem: 14938
[21:36:41.900007] Test:  [130/345]  eta: 0:00:40  loss: 0.6862 (0.6859)  time: 0.1876  data: 0.0001  max mem: 14938
[21:36:43.782330] Test:  [140/345]  eta: 0:00:38  loss: 0.6862 (0.6860)  time: 0.1880  data: 0.0001  max mem: 14938
[21:36:45.667801] Test:  [150/345]  eta: 0:00:36  loss: 0.6850 (0.6856)  time: 0.1883  data: 0.0001  max mem: 14938
[21:36:47.553905] Test:  [160/345]  eta: 0:00:34  loss: 0.6795 (0.6855)  time: 0.1885  data: 0.0001  max mem: 14938
[21:36:49.445206] Test:  [170/345]  eta: 0:00:32  loss: 0.6835 (0.6857)  time: 0.1888  data: 0.0001  max mem: 14938
[21:36:51.340559] Test:  [180/345]  eta: 0:00:30  loss: 0.6898 (0.6859)  time: 0.1893  data: 0.0001  max mem: 14938
[21:36:53.240458] Test:  [190/345]  eta: 0:00:29  loss: 0.6893 (0.6863)  time: 0.1897  data: 0.0001  max mem: 14938
[21:36:55.141672] Test:  [200/345]  eta: 0:00:27  loss: 0.6836 (0.6862)  time: 0.1900  data: 0.0001  max mem: 14938
[21:36:57.047911] Test:  [210/345]  eta: 0:00:25  loss: 0.6836 (0.6862)  time: 0.1903  data: 0.0001  max mem: 14938
[21:36:58.959418] Test:  [220/345]  eta: 0:00:23  loss: 0.6868 (0.6863)  time: 0.1908  data: 0.0001  max mem: 14938
[21:37:00.874290] Test:  [230/345]  eta: 0:00:21  loss: 0.6875 (0.6864)  time: 0.1913  data: 0.0001  max mem: 14938
[21:37:02.792747] Test:  [240/345]  eta: 0:00:19  loss: 0.6865 (0.6863)  time: 0.1916  data: 0.0001  max mem: 14938
[21:37:04.713751] Test:  [250/345]  eta: 0:00:17  loss: 0.6877 (0.6865)  time: 0.1919  data: 0.0001  max mem: 14938
[21:37:06.638674] Test:  [260/345]  eta: 0:00:16  loss: 0.6890 (0.6863)  time: 0.1922  data: 0.0001  max mem: 14938
[21:37:08.565995] Test:  [270/345]  eta: 0:00:14  loss: 0.6803 (0.6862)  time: 0.1926  data: 0.0001  max mem: 14938
[21:37:10.497215] Test:  [280/345]  eta: 0:00:12  loss: 0.6856 (0.6864)  time: 0.1929  data: 0.0001  max mem: 14938
[21:37:12.431051] Test:  [290/345]  eta: 0:00:10  loss: 0.6856 (0.6864)  time: 0.1932  data: 0.0001  max mem: 14938
[21:37:14.368353] Test:  [300/345]  eta: 0:00:08  loss: 0.6830 (0.6863)  time: 0.1935  data: 0.0001  max mem: 14938
[21:37:16.308466] Test:  [310/345]  eta: 0:00:06  loss: 0.6837 (0.6862)  time: 0.1938  data: 0.0001  max mem: 14938
[21:37:18.252551] Test:  [320/345]  eta: 0:00:04  loss: 0.6837 (0.6861)  time: 0.1941  data: 0.0001  max mem: 14938
[21:37:20.198481] Test:  [330/345]  eta: 0:00:02  loss: 0.6865 (0.6862)  time: 0.1945  data: 0.0001  max mem: 14938
[21:37:22.149063] Test:  [340/345]  eta: 0:00:00  loss: 0.6892 (0.6863)  time: 0.1948  data: 0.0001  max mem: 14938
[21:37:22.930593] Test:  [344/345]  eta: 0:00:00  loss: 0.6890 (0.6862)  time: 0.1949  data: 0.0001  max mem: 14938
[21:37:22.988394] Test: Total time: 0:01:05 (0.1901 s / it)
[21:37:33.331973] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8617 (0.8617)  time: 0.3172  data: 0.1379  max mem: 14938
[21:37:35.149719] Test:  [10/57]  eta: 0:00:09  loss: 0.8927 (0.8892)  time: 0.1940  data: 0.0126  max mem: 14938
[21:37:36.971706] Test:  [20/57]  eta: 0:00:06  loss: 0.8927 (0.8757)  time: 0.1819  data: 0.0001  max mem: 14938
[21:37:38.798792] Test:  [30/57]  eta: 0:00:05  loss: 0.7538 (0.8323)  time: 0.1824  data: 0.0001  max mem: 14938
[21:37:40.627815] Test:  [40/57]  eta: 0:00:03  loss: 0.7395 (0.8102)  time: 0.1828  data: 0.0001  max mem: 14938
[21:37:42.465000] Test:  [50/57]  eta: 0:00:01  loss: 0.7287 (0.8015)  time: 0.1833  data: 0.0001  max mem: 14938
[21:37:43.454845] Test:  [56/57]  eta: 0:00:00  loss: 0.7555 (0.8066)  time: 0.1779  data: 0.0001  max mem: 14938
[21:37:43.514797] Test: Total time: 0:00:10 (0.1842 s / it)
[21:37:45.251807] Dice score of the network on the train images: 0.834810, val images: 0.823214
[21:37:45.255890] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:37:46.143946] Epoch: [43]  [  0/345]  eta: 0:05:06  lr: 0.000016  loss: 0.7034 (0.7034)  time: 0.8870  data: 0.1444  max mem: 14938
[21:38:01.018697] Epoch: [43]  [ 20/345]  eta: 0:04:03  lr: 0.000016  loss: 0.7088 (0.7096)  time: 0.7437  data: 0.0001  max mem: 14938
[21:38:15.955391] Epoch: [43]  [ 40/345]  eta: 0:03:48  lr: 0.000016  loss: 0.7124 (0.7103)  time: 0.7468  data: 0.0001  max mem: 14938
[21:38:30.930905] Epoch: [43]  [ 60/345]  eta: 0:03:33  lr: 0.000015  loss: 0.7137 (0.7105)  time: 0.7487  data: 0.0001  max mem: 14938
[21:38:45.928245] Epoch: [43]  [ 80/345]  eta: 0:03:18  lr: 0.000015  loss: 0.7060 (0.7099)  time: 0.7498  data: 0.0001  max mem: 14938
[21:39:00.945126] Epoch: [43]  [100/345]  eta: 0:03:03  lr: 0.000015  loss: 0.7060 (0.7096)  time: 0.7508  data: 0.0001  max mem: 14938
[21:39:15.975568] Epoch: [43]  [120/345]  eta: 0:02:48  lr: 0.000015  loss: 0.7078 (0.7094)  time: 0.7515  data: 0.0001  max mem: 14938
[21:39:31.015204] Epoch: [43]  [140/345]  eta: 0:02:33  lr: 0.000014  loss: 0.7088 (0.7092)  time: 0.7519  data: 0.0001  max mem: 14938
[21:39:46.043148] Epoch: [43]  [160/345]  eta: 0:02:18  lr: 0.000014  loss: 0.7090 (0.7094)  time: 0.7514  data: 0.0001  max mem: 14938
[21:40:01.066718] Epoch: [43]  [180/345]  eta: 0:02:03  lr: 0.000014  loss: 0.7112 (0.7094)  time: 0.7511  data: 0.0001  max mem: 14938
[21:40:16.094486] Epoch: [43]  [200/345]  eta: 0:01:48  lr: 0.000014  loss: 0.7051 (0.7092)  time: 0.7513  data: 0.0001  max mem: 14938
[21:40:31.107510] Epoch: [43]  [220/345]  eta: 0:01:33  lr: 0.000013  loss: 0.7074 (0.7091)  time: 0.7506  data: 0.0001  max mem: 14938
[21:40:46.245726] Epoch: [43]  [240/345]  eta: 0:01:18  lr: 0.000013  loss: 0.7076 (0.7091)  time: 0.7569  data: 0.0001  max mem: 14938
[21:41:01.259493] Epoch: [43]  [260/345]  eta: 0:01:03  lr: 0.000013  loss: 0.7068 (0.7090)  time: 0.7506  data: 0.0001  max mem: 14938
[21:41:16.254612] Epoch: [43]  [280/345]  eta: 0:00:48  lr: 0.000013  loss: 0.7112 (0.7091)  time: 0.7497  data: 0.0001  max mem: 14938
[21:41:31.235887] Epoch: [43]  [300/345]  eta: 0:00:33  lr: 0.000012  loss: 0.7089 (0.7093)  time: 0.7490  data: 0.0001  max mem: 14938
[21:41:46.213706] Epoch: [43]  [320/345]  eta: 0:00:18  lr: 0.000012  loss: 0.7096 (0.7094)  time: 0.7488  data: 0.0001  max mem: 14938
[21:42:01.193410] Epoch: [43]  [340/345]  eta: 0:00:03  lr: 0.000012  loss: 0.7101 (0.7094)  time: 0.7489  data: 0.0001  max mem: 14938
[21:42:04.186983] Epoch: [43]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 0.7101 (0.7094)  time: 0.7488  data: 0.0001  max mem: 14938
[21:42:04.249442] Epoch: [43] Total time: 0:04:18 (0.7507 s / it)
[21:42:04.249730] Averaged stats: lr: 0.000012  loss: 0.7101 (0.7094)
[21:42:04.585693] Test:  [  0/345]  eta: 0:01:54  loss: 0.6817 (0.6817)  time: 0.3323  data: 0.1507  max mem: 14938
[21:42:06.422919] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6817 (0.6835)  time: 0.1972  data: 0.0138  max mem: 14938
[21:42:08.262584] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6836 (0.6858)  time: 0.1838  data: 0.0001  max mem: 14938
[21:42:10.105536] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6806 (0.6842)  time: 0.1841  data: 0.0001  max mem: 14938
[21:42:11.954262] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6787 (0.6841)  time: 0.1845  data: 0.0001  max mem: 14938
[21:42:13.804168] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6793 (0.6838)  time: 0.1849  data: 0.0001  max mem: 14938
[21:42:15.658418] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6801 (0.6838)  time: 0.1852  data: 0.0001  max mem: 14938
[21:42:17.516310] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6813 (0.6841)  time: 0.1856  data: 0.0001  max mem: 14938
[21:42:19.376816] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6815 (0.6843)  time: 0.1859  data: 0.0001  max mem: 14938
[21:42:21.240681] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6803 (0.6840)  time: 0.1862  data: 0.0001  max mem: 14938
[21:42:23.108945] Test:  [100/345]  eta: 0:00:45  loss: 0.6814 (0.6845)  time: 0.1866  data: 0.0001  max mem: 14938
[21:42:24.979355] Test:  [110/345]  eta: 0:00:43  loss: 0.6895 (0.6849)  time: 0.1869  data: 0.0001  max mem: 14938
[21:42:26.854653] Test:  [120/345]  eta: 0:00:42  loss: 0.6876 (0.6853)  time: 0.1872  data: 0.0001  max mem: 14938
[21:42:28.733872] Test:  [130/345]  eta: 0:00:40  loss: 0.6855 (0.6850)  time: 0.1877  data: 0.0001  max mem: 14938
[21:42:30.615044] Test:  [140/345]  eta: 0:00:38  loss: 0.6813 (0.6850)  time: 0.1880  data: 0.0001  max mem: 14938
[21:42:32.500117] Test:  [150/345]  eta: 0:00:36  loss: 0.6849 (0.6853)  time: 0.1883  data: 0.0001  max mem: 14938
[21:42:34.388201] Test:  [160/345]  eta: 0:00:34  loss: 0.6848 (0.6850)  time: 0.1886  data: 0.0001  max mem: 14938
[21:42:36.277464] Test:  [170/345]  eta: 0:00:32  loss: 0.6850 (0.6855)  time: 0.1888  data: 0.0001  max mem: 14938
[21:42:38.174545] Test:  [180/345]  eta: 0:00:30  loss: 0.6883 (0.6854)  time: 0.1893  data: 0.0001  max mem: 14938
[21:42:40.076659] Test:  [190/345]  eta: 0:00:29  loss: 0.6857 (0.6853)  time: 0.1899  data: 0.0001  max mem: 14938
[21:42:41.979769] Test:  [200/345]  eta: 0:00:27  loss: 0.6857 (0.6854)  time: 0.1902  data: 0.0001  max mem: 14938
[21:42:43.888469] Test:  [210/345]  eta: 0:00:25  loss: 0.6820 (0.6853)  time: 0.1905  data: 0.0001  max mem: 14938
[21:42:45.801070] Test:  [220/345]  eta: 0:00:23  loss: 0.6816 (0.6852)  time: 0.1910  data: 0.0001  max mem: 14938
[21:42:47.717174] Test:  [230/345]  eta: 0:00:21  loss: 0.6791 (0.6851)  time: 0.1914  data: 0.0001  max mem: 14938
[21:42:49.637705] Test:  [240/345]  eta: 0:00:19  loss: 0.6774 (0.6849)  time: 0.1918  data: 0.0001  max mem: 14938
[21:42:51.559700] Test:  [250/345]  eta: 0:00:17  loss: 0.6857 (0.6850)  time: 0.1921  data: 0.0001  max mem: 14938
[21:42:53.484957] Test:  [260/345]  eta: 0:00:16  loss: 0.6885 (0.6853)  time: 0.1923  data: 0.0001  max mem: 14938
[21:42:55.416149] Test:  [270/345]  eta: 0:00:14  loss: 0.6825 (0.6850)  time: 0.1928  data: 0.0001  max mem: 14938
[21:42:57.348271] Test:  [280/345]  eta: 0:00:12  loss: 0.6814 (0.6852)  time: 0.1931  data: 0.0001  max mem: 14938
[21:42:59.285112] Test:  [290/345]  eta: 0:00:10  loss: 0.6837 (0.6852)  time: 0.1934  data: 0.0001  max mem: 14938
[21:43:01.223807] Test:  [300/345]  eta: 0:00:08  loss: 0.6834 (0.6852)  time: 0.1937  data: 0.0001  max mem: 14938
[21:43:03.165241] Test:  [310/345]  eta: 0:00:06  loss: 0.6823 (0.6852)  time: 0.1940  data: 0.0001  max mem: 14938
[21:43:05.108916] Test:  [320/345]  eta: 0:00:04  loss: 0.6823 (0.6852)  time: 0.1942  data: 0.0001  max mem: 14938
[21:43:07.055852] Test:  [330/345]  eta: 0:00:02  loss: 0.6826 (0.6851)  time: 0.1945  data: 0.0001  max mem: 14938
[21:43:09.007322] Test:  [340/345]  eta: 0:00:00  loss: 0.6809 (0.6850)  time: 0.1949  data: 0.0001  max mem: 14938
[21:43:09.788543] Test:  [344/345]  eta: 0:00:00  loss: 0.6809 (0.6850)  time: 0.1950  data: 0.0001  max mem: 14938
[21:43:09.824481] Test: Total time: 0:01:05 (0.1901 s / it)
[21:43:20.228998] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8654 (0.8654)  time: 0.3173  data: 0.1369  max mem: 14938
[21:43:22.045373] Test:  [10/57]  eta: 0:00:09  loss: 0.8944 (0.8909)  time: 0.1939  data: 0.0125  max mem: 14938
[21:43:23.867760] Test:  [20/57]  eta: 0:00:06  loss: 0.8944 (0.8771)  time: 0.1819  data: 0.0001  max mem: 14938
[21:43:25.693167] Test:  [30/57]  eta: 0:00:05  loss: 0.7545 (0.8338)  time: 0.1823  data: 0.0001  max mem: 14938
[21:43:27.523716] Test:  [40/57]  eta: 0:00:03  loss: 0.7410 (0.8118)  time: 0.1827  data: 0.0001  max mem: 14938
[21:43:29.358736] Test:  [50/57]  eta: 0:00:01  loss: 0.7326 (0.8032)  time: 0.1832  data: 0.0001  max mem: 14938
[21:43:30.347962] Test:  [56/57]  eta: 0:00:00  loss: 0.7544 (0.8083)  time: 0.1778  data: 0.0001  max mem: 14938
[21:43:30.407143] Test: Total time: 0:00:10 (0.1841 s / it)
[21:43:32.119715] Dice score of the network on the train images: 0.838914, val images: 0.822284
[21:43:32.123731] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:43:33.007231] Epoch: [44]  [  0/345]  eta: 0:05:04  lr: 0.000012  loss: 0.6942 (0.6942)  time: 0.8824  data: 0.1381  max mem: 14938
[21:43:47.888925] Epoch: [44]  [ 20/345]  eta: 0:04:03  lr: 0.000012  loss: 0.7096 (0.7099)  time: 0.7440  data: 0.0001  max mem: 14938
[21:44:02.825909] Epoch: [44]  [ 40/345]  eta: 0:03:48  lr: 0.000011  loss: 0.7043 (0.7081)  time: 0.7468  data: 0.0001  max mem: 14938
[21:44:17.790851] Epoch: [44]  [ 60/345]  eta: 0:03:33  lr: 0.000011  loss: 0.7074 (0.7085)  time: 0.7482  data: 0.0001  max mem: 14938
[21:44:32.764061] Epoch: [44]  [ 80/345]  eta: 0:03:18  lr: 0.000011  loss: 0.6988 (0.7071)  time: 0.7486  data: 0.0001  max mem: 14938
[21:44:47.763035] Epoch: [44]  [100/345]  eta: 0:03:03  lr: 0.000011  loss: 0.7087 (0.7074)  time: 0.7499  data: 0.0001  max mem: 14938
[21:45:02.782613] Epoch: [44]  [120/345]  eta: 0:02:48  lr: 0.000011  loss: 0.7030 (0.7071)  time: 0.7509  data: 0.0001  max mem: 14938
[21:45:17.798935] Epoch: [44]  [140/345]  eta: 0:02:33  lr: 0.000010  loss: 0.7055 (0.7070)  time: 0.7508  data: 0.0001  max mem: 14938
[21:45:32.809673] Epoch: [44]  [160/345]  eta: 0:02:18  lr: 0.000010  loss: 0.7085 (0.7075)  time: 0.7505  data: 0.0001  max mem: 14938
[21:45:47.939692] Epoch: [44]  [180/345]  eta: 0:02:03  lr: 0.000010  loss: 0.7137 (0.7084)  time: 0.7565  data: 0.0001  max mem: 14938
[21:46:02.963030] Epoch: [44]  [200/345]  eta: 0:01:48  lr: 0.000010  loss: 0.7049 (0.7084)  time: 0.7511  data: 0.0001  max mem: 14938
[21:46:17.979253] Epoch: [44]  [220/345]  eta: 0:01:33  lr: 0.000010  loss: 0.7049 (0.7084)  time: 0.7508  data: 0.0001  max mem: 14938
[21:46:32.982294] Epoch: [44]  [240/345]  eta: 0:01:18  lr: 0.000009  loss: 0.7069 (0.7086)  time: 0.7501  data: 0.0001  max mem: 14938
[21:46:47.992490] Epoch: [44]  [260/345]  eta: 0:01:03  lr: 0.000009  loss: 0.7106 (0.7088)  time: 0.7505  data: 0.0001  max mem: 14938
[21:47:02.983608] Epoch: [44]  [280/345]  eta: 0:00:48  lr: 0.000009  loss: 0.7063 (0.7087)  time: 0.7495  data: 0.0001  max mem: 14938
[21:47:17.982675] Epoch: [44]  [300/345]  eta: 0:00:33  lr: 0.000009  loss: 0.7073 (0.7087)  time: 0.7499  data: 0.0001  max mem: 14938
[21:47:32.979404] Epoch: [44]  [320/345]  eta: 0:00:18  lr: 0.000009  loss: 0.7057 (0.7087)  time: 0.7498  data: 0.0001  max mem: 14938
[21:47:47.959135] Epoch: [44]  [340/345]  eta: 0:00:03  lr: 0.000008  loss: 0.7077 (0.7087)  time: 0.7489  data: 0.0001  max mem: 14938
[21:47:50.952610] Epoch: [44]  [344/345]  eta: 0:00:00  lr: 0.000008  loss: 0.7116 (0.7087)  time: 0.7489  data: 0.0001  max mem: 14938
[21:47:50.995803] Epoch: [44] Total time: 0:04:18 (0.7504 s / it)
[21:47:50.996088] Averaged stats: lr: 0.000008  loss: 0.7116 (0.7087)
[21:47:51.331385] Test:  [  0/345]  eta: 0:01:54  loss: 0.6916 (0.6916)  time: 0.3318  data: 0.1500  max mem: 14938
[21:47:53.168480] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6851 (0.6830)  time: 0.1971  data: 0.0137  max mem: 14938
[21:47:55.007344] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6804 (0.6833)  time: 0.1837  data: 0.0001  max mem: 14938
[21:47:56.851575] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6823 (0.6870)  time: 0.1841  data: 0.0001  max mem: 14938
[21:47:58.697223] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6865 (0.6865)  time: 0.1844  data: 0.0001  max mem: 14938
[21:48:00.547893] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6853 (0.6861)  time: 0.1848  data: 0.0001  max mem: 14938
[21:48:02.402762] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6773 (0.6847)  time: 0.1852  data: 0.0001  max mem: 14938
[21:48:04.259922] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6804 (0.6846)  time: 0.1856  data: 0.0001  max mem: 14938
[21:48:06.120183] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6866 (0.6858)  time: 0.1858  data: 0.0001  max mem: 14938
[21:48:07.984007] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6828 (0.6856)  time: 0.1862  data: 0.0001  max mem: 14938
[21:48:09.850612] Test:  [100/345]  eta: 0:00:45  loss: 0.6808 (0.6855)  time: 0.1865  data: 0.0001  max mem: 14938
[21:48:11.722488] Test:  [110/345]  eta: 0:00:43  loss: 0.6811 (0.6854)  time: 0.1869  data: 0.0001  max mem: 14938
[21:48:13.598693] Test:  [120/345]  eta: 0:00:42  loss: 0.6808 (0.6849)  time: 0.1873  data: 0.0001  max mem: 14938
[21:48:15.477133] Test:  [130/345]  eta: 0:00:40  loss: 0.6808 (0.6849)  time: 0.1877  data: 0.0001  max mem: 14938
[21:48:17.358713] Test:  [140/345]  eta: 0:00:38  loss: 0.6840 (0.6849)  time: 0.1880  data: 0.0001  max mem: 14938
[21:48:19.243004] Test:  [150/345]  eta: 0:00:36  loss: 0.6823 (0.6848)  time: 0.1882  data: 0.0001  max mem: 14938
[21:48:21.130091] Test:  [160/345]  eta: 0:00:34  loss: 0.6831 (0.6846)  time: 0.1885  data: 0.0001  max mem: 14938
[21:48:23.021099] Test:  [170/345]  eta: 0:00:32  loss: 0.6834 (0.6846)  time: 0.1888  data: 0.0001  max mem: 14938
[21:48:24.917258] Test:  [180/345]  eta: 0:00:30  loss: 0.6866 (0.6848)  time: 0.1893  data: 0.0001  max mem: 14938
[21:48:26.815509] Test:  [190/345]  eta: 0:00:29  loss: 0.6903 (0.6853)  time: 0.1897  data: 0.0001  max mem: 14938
[21:48:28.717006] Test:  [200/345]  eta: 0:00:27  loss: 0.6903 (0.6851)  time: 0.1899  data: 0.0001  max mem: 14938
[21:48:30.622007] Test:  [210/345]  eta: 0:00:25  loss: 0.6850 (0.6850)  time: 0.1903  data: 0.0001  max mem: 14938
[21:48:32.532372] Test:  [220/345]  eta: 0:00:23  loss: 0.6851 (0.6850)  time: 0.1907  data: 0.0001  max mem: 14938
[21:48:34.446813] Test:  [230/345]  eta: 0:00:21  loss: 0.6837 (0.6850)  time: 0.1912  data: 0.0001  max mem: 14938
[21:48:36.363754] Test:  [240/345]  eta: 0:00:19  loss: 0.6770 (0.6847)  time: 0.1915  data: 0.0001  max mem: 14938
[21:48:38.286935] Test:  [250/345]  eta: 0:00:17  loss: 0.6787 (0.6845)  time: 0.1920  data: 0.0001  max mem: 14938
[21:48:40.211872] Test:  [260/345]  eta: 0:00:16  loss: 0.6795 (0.6845)  time: 0.1924  data: 0.0001  max mem: 14938
[21:48:42.139776] Test:  [270/345]  eta: 0:00:14  loss: 0.6830 (0.6844)  time: 0.1926  data: 0.0001  max mem: 14938
[21:48:44.069704] Test:  [280/345]  eta: 0:00:12  loss: 0.6830 (0.6845)  time: 0.1928  data: 0.0001  max mem: 14938
[21:48:46.005566] Test:  [290/345]  eta: 0:00:10  loss: 0.6812 (0.6844)  time: 0.1932  data: 0.0001  max mem: 14938
[21:48:47.943164] Test:  [300/345]  eta: 0:00:08  loss: 0.6805 (0.6844)  time: 0.1936  data: 0.0001  max mem: 14938
[21:48:49.883963] Test:  [310/345]  eta: 0:00:06  loss: 0.6855 (0.6845)  time: 0.1939  data: 0.0001  max mem: 14938
[21:48:51.827740] Test:  [320/345]  eta: 0:00:04  loss: 0.6871 (0.6847)  time: 0.1942  data: 0.0001  max mem: 14938
[21:48:53.773205] Test:  [330/345]  eta: 0:00:02  loss: 0.6848 (0.6845)  time: 0.1944  data: 0.0001  max mem: 14938
[21:48:55.722554] Test:  [340/345]  eta: 0:00:00  loss: 0.6761 (0.6843)  time: 0.1947  data: 0.0001  max mem: 14938
[21:48:56.506077] Test:  [344/345]  eta: 0:00:00  loss: 0.6734 (0.6843)  time: 0.1950  data: 0.0001  max mem: 14938
[21:48:56.564937] Test: Total time: 0:01:05 (0.1900 s / it)
[21:49:06.959393] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8569 (0.8569)  time: 0.3171  data: 0.1374  max mem: 14938
[21:49:08.775576] Test:  [10/57]  eta: 0:00:09  loss: 0.8958 (0.8879)  time: 0.1939  data: 0.0126  max mem: 14938
[21:49:10.596789] Test:  [20/57]  eta: 0:00:06  loss: 0.8958 (0.8752)  time: 0.1818  data: 0.0001  max mem: 14938
[21:49:12.422115] Test:  [30/57]  eta: 0:00:05  loss: 0.7545 (0.8322)  time: 0.1823  data: 0.0001  max mem: 14938
[21:49:14.252449] Test:  [40/57]  eta: 0:00:03  loss: 0.7403 (0.8105)  time: 0.1827  data: 0.0001  max mem: 14938
[21:49:16.086928] Test:  [50/57]  eta: 0:00:01  loss: 0.7296 (0.8020)  time: 0.1832  data: 0.0001  max mem: 14938
[21:49:17.076357] Test:  [56/57]  eta: 0:00:00  loss: 0.7549 (0.8071)  time: 0.1777  data: 0.0001  max mem: 14938
[21:49:17.133929] Test: Total time: 0:00:10 (0.1841 s / it)
[21:49:18.894279] Dice score of the network on the train images: 0.837895, val images: 0.821439
[21:49:18.899055] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:49:19.782051] Epoch: [45]  [  0/345]  eta: 0:05:04  lr: 0.000008  loss: 0.7196 (0.7196)  time: 0.8819  data: 0.1423  max mem: 14938
[21:49:34.672688] Epoch: [45]  [ 20/345]  eta: 0:04:04  lr: 0.000008  loss: 0.7038 (0.7079)  time: 0.7445  data: 0.0001  max mem: 14938
[21:49:49.608795] Epoch: [45]  [ 40/345]  eta: 0:03:48  lr: 0.000008  loss: 0.7059 (0.7079)  time: 0.7468  data: 0.0001  max mem: 14938
[21:50:04.566770] Epoch: [45]  [ 60/345]  eta: 0:03:33  lr: 0.000008  loss: 0.7018 (0.7077)  time: 0.7479  data: 0.0001  max mem: 14938
[21:50:19.550880] Epoch: [45]  [ 80/345]  eta: 0:03:18  lr: 0.000008  loss: 0.7077 (0.7080)  time: 0.7492  data: 0.0001  max mem: 14938
[21:50:34.552428] Epoch: [45]  [100/345]  eta: 0:03:03  lr: 0.000007  loss: 0.7097 (0.7085)  time: 0.7500  data: 0.0001  max mem: 14938
[21:50:49.573381] Epoch: [45]  [120/345]  eta: 0:02:48  lr: 0.000007  loss: 0.7094 (0.7086)  time: 0.7510  data: 0.0001  max mem: 14938
[21:51:04.583850] Epoch: [45]  [140/345]  eta: 0:02:33  lr: 0.000007  loss: 0.7051 (0.7083)  time: 0.7505  data: 0.0001  max mem: 14938
[21:51:19.719596] Epoch: [45]  [160/345]  eta: 0:02:18  lr: 0.000007  loss: 0.7037 (0.7081)  time: 0.7567  data: 0.0001  max mem: 14938
[21:51:34.720139] Epoch: [45]  [180/345]  eta: 0:02:03  lr: 0.000007  loss: 0.7055 (0.7082)  time: 0.7500  data: 0.0001  max mem: 14938
[21:51:49.713725] Epoch: [45]  [200/345]  eta: 0:01:48  lr: 0.000007  loss: 0.7047 (0.7081)  time: 0.7496  data: 0.0001  max mem: 14938
[21:52:04.712633] Epoch: [45]  [220/345]  eta: 0:01:33  lr: 0.000006  loss: 0.7152 (0.7083)  time: 0.7499  data: 0.0001  max mem: 14938
[21:52:19.721957] Epoch: [45]  [240/345]  eta: 0:01:18  lr: 0.000006  loss: 0.7076 (0.7086)  time: 0.7504  data: 0.0001  max mem: 14938
[21:52:34.707029] Epoch: [45]  [260/345]  eta: 0:01:03  lr: 0.000006  loss: 0.7062 (0.7085)  time: 0.7492  data: 0.0001  max mem: 14938
[21:52:49.692032] Epoch: [45]  [280/345]  eta: 0:00:48  lr: 0.000006  loss: 0.7060 (0.7085)  time: 0.7492  data: 0.0001  max mem: 14938
[21:53:04.672392] Epoch: [45]  [300/345]  eta: 0:00:33  lr: 0.000006  loss: 0.7015 (0.7082)  time: 0.7490  data: 0.0001  max mem: 14938
[21:53:19.678991] Epoch: [45]  [320/345]  eta: 0:00:18  lr: 0.000006  loss: 0.7070 (0.7081)  time: 0.7503  data: 0.0001  max mem: 14938
[21:53:34.666638] Epoch: [45]  [340/345]  eta: 0:00:03  lr: 0.000005  loss: 0.7044 (0.7080)  time: 0.7493  data: 0.0001  max mem: 14938
[21:53:37.665802] Epoch: [45]  [344/345]  eta: 0:00:00  lr: 0.000005  loss: 0.7044 (0.7079)  time: 0.7495  data: 0.0001  max mem: 14938
[21:53:37.726159] Epoch: [45] Total time: 0:04:18 (0.7502 s / it)
[21:53:37.726425] Averaged stats: lr: 0.000005  loss: 0.7044 (0.7079)
[21:53:38.060534] Test:  [  0/345]  eta: 0:01:53  loss: 0.6632 (0.6632)  time: 0.3299  data: 0.1483  max mem: 14938
[21:53:39.898391] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6764 (0.6797)  time: 0.1970  data: 0.0135  max mem: 14938
[21:53:41.737542] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6805 (0.6837)  time: 0.1838  data: 0.0001  max mem: 14938
[21:53:43.581580] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6827 (0.6821)  time: 0.1841  data: 0.0001  max mem: 14938
[21:53:45.430445] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6846 (0.6847)  time: 0.1846  data: 0.0001  max mem: 14938
[21:53:47.281254] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6881 (0.6850)  time: 0.1849  data: 0.0001  max mem: 14938
[21:53:49.135782] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6828 (0.6844)  time: 0.1852  data: 0.0001  max mem: 14938
[21:53:50.994691] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6794 (0.6841)  time: 0.1856  data: 0.0001  max mem: 14938
[21:53:52.854409] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6822 (0.6848)  time: 0.1859  data: 0.0001  max mem: 14938
[21:53:54.718952] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6862 (0.6844)  time: 0.1862  data: 0.0001  max mem: 14938
[21:53:56.586660] Test:  [100/345]  eta: 0:00:45  loss: 0.6848 (0.6844)  time: 0.1866  data: 0.0001  max mem: 14938
[21:53:58.458454] Test:  [110/345]  eta: 0:00:43  loss: 0.6815 (0.6843)  time: 0.1869  data: 0.0001  max mem: 14938
[21:54:00.335190] Test:  [120/345]  eta: 0:00:42  loss: 0.6813 (0.6843)  time: 0.1874  data: 0.0001  max mem: 14938
[21:54:02.213653] Test:  [130/345]  eta: 0:00:40  loss: 0.6772 (0.6836)  time: 0.1877  data: 0.0001  max mem: 14938
[21:54:04.096572] Test:  [140/345]  eta: 0:00:38  loss: 0.6755 (0.6833)  time: 0.1880  data: 0.0001  max mem: 14938
[21:54:05.982361] Test:  [150/345]  eta: 0:00:36  loss: 0.6821 (0.6834)  time: 0.1884  data: 0.0001  max mem: 14938
[21:54:07.871308] Test:  [160/345]  eta: 0:00:34  loss: 0.6821 (0.6831)  time: 0.1887  data: 0.0001  max mem: 14938
[21:54:09.762330] Test:  [170/345]  eta: 0:00:32  loss: 0.6820 (0.6832)  time: 0.1890  data: 0.0001  max mem: 14938
[21:54:11.659915] Test:  [180/345]  eta: 0:00:30  loss: 0.6856 (0.6837)  time: 0.1894  data: 0.0001  max mem: 14938
[21:54:13.559846] Test:  [190/345]  eta: 0:00:29  loss: 0.6858 (0.6838)  time: 0.1898  data: 0.0001  max mem: 14938
[21:54:15.465075] Test:  [200/345]  eta: 0:00:27  loss: 0.6820 (0.6838)  time: 0.1902  data: 0.0001  max mem: 14938
[21:54:17.371967] Test:  [210/345]  eta: 0:00:25  loss: 0.6820 (0.6838)  time: 0.1906  data: 0.0001  max mem: 14938
[21:54:19.283926] Test:  [220/345]  eta: 0:00:23  loss: 0.6820 (0.6838)  time: 0.1909  data: 0.0001  max mem: 14938
[21:54:21.197858] Test:  [230/345]  eta: 0:00:21  loss: 0.6820 (0.6838)  time: 0.1912  data: 0.0001  max mem: 14938
[21:54:23.115444] Test:  [240/345]  eta: 0:00:19  loss: 0.6752 (0.6835)  time: 0.1915  data: 0.0001  max mem: 14938
[21:54:25.035117] Test:  [250/345]  eta: 0:00:17  loss: 0.6803 (0.6836)  time: 0.1918  data: 0.0001  max mem: 14938
[21:54:26.960126] Test:  [260/345]  eta: 0:00:16  loss: 0.6810 (0.6836)  time: 0.1922  data: 0.0001  max mem: 14938
[21:54:28.888303] Test:  [270/345]  eta: 0:00:14  loss: 0.6784 (0.6833)  time: 0.1926  data: 0.0001  max mem: 14938
[21:54:30.819831] Test:  [280/345]  eta: 0:00:12  loss: 0.6801 (0.6835)  time: 0.1929  data: 0.0001  max mem: 14938
[21:54:32.753501] Test:  [290/345]  eta: 0:00:10  loss: 0.6830 (0.6834)  time: 0.1932  data: 0.0001  max mem: 14938
[21:54:34.691931] Test:  [300/345]  eta: 0:00:08  loss: 0.6868 (0.6838)  time: 0.1936  data: 0.0001  max mem: 14938
[21:54:36.631974] Test:  [310/345]  eta: 0:00:06  loss: 0.6888 (0.6838)  time: 0.1939  data: 0.0001  max mem: 14938
[21:54:38.575641] Test:  [320/345]  eta: 0:00:04  loss: 0.6844 (0.6841)  time: 0.1941  data: 0.0001  max mem: 14938
[21:54:40.523227] Test:  [330/345]  eta: 0:00:02  loss: 0.6824 (0.6839)  time: 0.1945  data: 0.0001  max mem: 14938
[21:54:42.473126] Test:  [340/345]  eta: 0:00:00  loss: 0.6784 (0.6838)  time: 0.1948  data: 0.0001  max mem: 14938
[21:54:43.256701] Test:  [344/345]  eta: 0:00:00  loss: 0.6790 (0.6837)  time: 0.1951  data: 0.0001  max mem: 14938
[21:54:43.314722] Test: Total time: 0:01:05 (0.1901 s / it)
[21:54:53.722042] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8609 (0.8609)  time: 0.3187  data: 0.1389  max mem: 14938
[21:54:55.537000] Test:  [10/57]  eta: 0:00:09  loss: 0.8966 (0.8887)  time: 0.1939  data: 0.0127  max mem: 14938
[21:54:57.358143] Test:  [20/57]  eta: 0:00:06  loss: 0.8966 (0.8759)  time: 0.1817  data: 0.0001  max mem: 14938
[21:54:59.186071] Test:  [30/57]  eta: 0:00:05  loss: 0.7557 (0.8329)  time: 0.1824  data: 0.0001  max mem: 14938
[21:55:01.017287] Test:  [40/57]  eta: 0:00:03  loss: 0.7408 (0.8111)  time: 0.1829  data: 0.0001  max mem: 14938
[21:55:02.851819] Test:  [50/57]  eta: 0:00:01  loss: 0.7314 (0.8026)  time: 0.1832  data: 0.0001  max mem: 14938
[21:55:03.840527] Test:  [56/57]  eta: 0:00:00  loss: 0.7540 (0.8078)  time: 0.1777  data: 0.0001  max mem: 14938
[21:55:03.897731] Test: Total time: 0:00:10 (0.1841 s / it)
[21:55:05.633296] Dice score of the network on the train images: 0.839524, val images: 0.821678
[21:55:05.637390] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:55:06.528360] Epoch: [46]  [  0/345]  eta: 0:05:06  lr: 0.000005  loss: 0.7055 (0.7055)  time: 0.8898  data: 0.1473  max mem: 14938
[21:55:21.431436] Epoch: [46]  [ 20/345]  eta: 0:04:04  lr: 0.000005  loss: 0.7049 (0.7059)  time: 0.7451  data: 0.0001  max mem: 14938
[21:55:36.393814] Epoch: [46]  [ 40/345]  eta: 0:03:48  lr: 0.000005  loss: 0.7068 (0.7061)  time: 0.7481  data: 0.0001  max mem: 14938
[21:55:51.374350] Epoch: [46]  [ 60/345]  eta: 0:03:33  lr: 0.000005  loss: 0.7051 (0.7061)  time: 0.7490  data: 0.0001  max mem: 14938
[21:56:06.383450] Epoch: [46]  [ 80/345]  eta: 0:03:18  lr: 0.000005  loss: 0.7121 (0.7083)  time: 0.7504  data: 0.0001  max mem: 14938
[21:56:21.410241] Epoch: [46]  [100/345]  eta: 0:03:03  lr: 0.000005  loss: 0.7061 (0.7083)  time: 0.7513  data: 0.0001  max mem: 14938
[21:56:36.445979] Epoch: [46]  [120/345]  eta: 0:02:48  lr: 0.000005  loss: 0.7030 (0.7082)  time: 0.7518  data: 0.0001  max mem: 14938
[21:56:51.482328] Epoch: [46]  [140/345]  eta: 0:02:33  lr: 0.000004  loss: 0.7046 (0.7080)  time: 0.7518  data: 0.0001  max mem: 14938
[21:57:06.513653] Epoch: [46]  [160/345]  eta: 0:02:18  lr: 0.000004  loss: 0.7080 (0.7081)  time: 0.7515  data: 0.0001  max mem: 14938
[21:57:21.527183] Epoch: [46]  [180/345]  eta: 0:02:03  lr: 0.000004  loss: 0.7073 (0.7077)  time: 0.7506  data: 0.0001  max mem: 14938
[21:57:36.548823] Epoch: [46]  [200/345]  eta: 0:01:48  lr: 0.000004  loss: 0.7079 (0.7078)  time: 0.7510  data: 0.0001  max mem: 14938
[21:57:51.560803] Epoch: [46]  [220/345]  eta: 0:01:33  lr: 0.000004  loss: 0.7052 (0.7078)  time: 0.7506  data: 0.0001  max mem: 14938
[21:58:06.573457] Epoch: [46]  [240/345]  eta: 0:01:18  lr: 0.000004  loss: 0.7109 (0.7081)  time: 0.7506  data: 0.0001  max mem: 14938
[21:58:21.574619] Epoch: [46]  [260/345]  eta: 0:01:03  lr: 0.000004  loss: 0.7025 (0.7077)  time: 0.7500  data: 0.0001  max mem: 14938
[21:58:36.582592] Epoch: [46]  [280/345]  eta: 0:00:48  lr: 0.000003  loss: 0.6991 (0.7074)  time: 0.7504  data: 0.0001  max mem: 14938
[21:58:51.583840] Epoch: [46]  [300/345]  eta: 0:00:33  lr: 0.000003  loss: 0.7086 (0.7075)  time: 0.7500  data: 0.0001  max mem: 14938
[21:59:06.576200] Epoch: [46]  [320/345]  eta: 0:00:18  lr: 0.000003  loss: 0.7089 (0.7076)  time: 0.7496  data: 0.0001  max mem: 14938
[21:59:21.570115] Epoch: [46]  [340/345]  eta: 0:00:03  lr: 0.000003  loss: 0.7073 (0.7075)  time: 0.7496  data: 0.0001  max mem: 14938
[21:59:24.570121] Epoch: [46]  [344/345]  eta: 0:00:00  lr: 0.000003  loss: 0.7081 (0.7076)  time: 0.7497  data: 0.0001  max mem: 14938
[21:59:24.633899] Epoch: [46] Total time: 0:04:18 (0.7507 s / it)
[21:59:24.634276] Averaged stats: lr: 0.000003  loss: 0.7081 (0.7076)
[21:59:24.968804] Test:  [  0/345]  eta: 0:01:53  loss: 0.6769 (0.6769)  time: 0.3288  data: 0.1471  max mem: 14938
[21:59:26.805158] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6798 (0.6823)  time: 0.1968  data: 0.0134  max mem: 14938
[21:59:28.643156] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6800 (0.6832)  time: 0.1837  data: 0.0001  max mem: 14938
[21:59:30.485056] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6800 (0.6819)  time: 0.1839  data: 0.0001  max mem: 14938
[21:59:32.331273] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6792 (0.6822)  time: 0.1844  data: 0.0001  max mem: 14938
[21:59:34.181912] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6792 (0.6822)  time: 0.1848  data: 0.0001  max mem: 14938
[21:59:36.036086] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6784 (0.6822)  time: 0.1852  data: 0.0001  max mem: 14938
[21:59:37.893266] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6784 (0.6821)  time: 0.1855  data: 0.0001  max mem: 14938
[21:59:39.753606] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6816 (0.6824)  time: 0.1858  data: 0.0001  max mem: 14938
[21:59:41.617727] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6818 (0.6823)  time: 0.1862  data: 0.0001  max mem: 14938
[21:59:43.486123] Test:  [100/345]  eta: 0:00:45  loss: 0.6776 (0.6820)  time: 0.1866  data: 0.0001  max mem: 14938
[21:59:45.358536] Test:  [110/345]  eta: 0:00:43  loss: 0.6787 (0.6821)  time: 0.1870  data: 0.0001  max mem: 14938
[21:59:47.232872] Test:  [120/345]  eta: 0:00:41  loss: 0.6807 (0.6819)  time: 0.1873  data: 0.0001  max mem: 14938
[21:59:49.110719] Test:  [130/345]  eta: 0:00:40  loss: 0.6738 (0.6814)  time: 0.1876  data: 0.0001  max mem: 14938
[21:59:50.992043] Test:  [140/345]  eta: 0:00:38  loss: 0.6789 (0.6820)  time: 0.1879  data: 0.0001  max mem: 14938
[21:59:52.876253] Test:  [150/345]  eta: 0:00:36  loss: 0.6856 (0.6820)  time: 0.1882  data: 0.0001  max mem: 14938
[21:59:54.762755] Test:  [160/345]  eta: 0:00:34  loss: 0.6805 (0.6818)  time: 0.1885  data: 0.0001  max mem: 14938
[21:59:56.651931] Test:  [170/345]  eta: 0:00:32  loss: 0.6811 (0.6819)  time: 0.1887  data: 0.0001  max mem: 14938
[21:59:58.548566] Test:  [180/345]  eta: 0:00:30  loss: 0.6811 (0.6822)  time: 0.1892  data: 0.0001  max mem: 14938
[22:00:00.448856] Test:  [190/345]  eta: 0:00:29  loss: 0.6839 (0.6825)  time: 0.1898  data: 0.0001  max mem: 14938
[22:00:02.351219] Test:  [200/345]  eta: 0:00:27  loss: 0.6861 (0.6829)  time: 0.1901  data: 0.0001  max mem: 14938
[22:00:04.256138] Test:  [210/345]  eta: 0:00:25  loss: 0.6839 (0.6829)  time: 0.1903  data: 0.0001  max mem: 14938
[22:00:06.165299] Test:  [220/345]  eta: 0:00:23  loss: 0.6826 (0.6830)  time: 0.1907  data: 0.0001  max mem: 14938
[22:00:08.078707] Test:  [230/345]  eta: 0:00:21  loss: 0.6852 (0.6830)  time: 0.1911  data: 0.0001  max mem: 14938
[22:00:09.995497] Test:  [240/345]  eta: 0:00:19  loss: 0.6797 (0.6830)  time: 0.1915  data: 0.0001  max mem: 14938
[22:00:11.915260] Test:  [250/345]  eta: 0:00:17  loss: 0.6857 (0.6831)  time: 0.1918  data: 0.0001  max mem: 14938
[22:00:13.841014] Test:  [260/345]  eta: 0:00:16  loss: 0.6808 (0.6829)  time: 0.1922  data: 0.0001  max mem: 14938
[22:00:15.767973] Test:  [270/345]  eta: 0:00:14  loss: 0.6800 (0.6830)  time: 0.1926  data: 0.0001  max mem: 14938
[22:00:17.699003] Test:  [280/345]  eta: 0:00:12  loss: 0.6821 (0.6830)  time: 0.1929  data: 0.0001  max mem: 14938
[22:00:19.633800] Test:  [290/345]  eta: 0:00:10  loss: 0.6821 (0.6831)  time: 0.1932  data: 0.0001  max mem: 14938
[22:00:21.570820] Test:  [300/345]  eta: 0:00:08  loss: 0.6850 (0.6833)  time: 0.1935  data: 0.0001  max mem: 14938
[22:00:23.511389] Test:  [310/345]  eta: 0:00:06  loss: 0.6847 (0.6833)  time: 0.1938  data: 0.0001  max mem: 14938
[22:00:25.456503] Test:  [320/345]  eta: 0:00:04  loss: 0.6822 (0.6833)  time: 0.1942  data: 0.0001  max mem: 14938
[22:00:27.403286] Test:  [330/345]  eta: 0:00:02  loss: 0.6853 (0.6834)  time: 0.1945  data: 0.0001  max mem: 14938
[22:00:29.353456] Test:  [340/345]  eta: 0:00:00  loss: 0.6850 (0.6836)  time: 0.1948  data: 0.0001  max mem: 14938
[22:00:30.135059] Test:  [344/345]  eta: 0:00:00  loss: 0.6842 (0.6836)  time: 0.1949  data: 0.0001  max mem: 14938
[22:00:30.194344] Test: Total time: 0:01:05 (0.1900 s / it)
[22:00:40.616695] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8597 (0.8597)  time: 0.3188  data: 0.1388  max mem: 14938
[22:00:42.432843] Test:  [10/57]  eta: 0:00:09  loss: 0.8954 (0.8880)  time: 0.1940  data: 0.0127  max mem: 14938
[22:00:44.254161] Test:  [20/57]  eta: 0:00:06  loss: 0.8954 (0.8750)  time: 0.1818  data: 0.0001  max mem: 14938
[22:00:46.079738] Test:  [30/57]  eta: 0:00:05  loss: 0.7535 (0.8319)  time: 0.1823  data: 0.0001  max mem: 14938
[22:00:47.910090] Test:  [40/57]  eta: 0:00:03  loss: 0.7391 (0.8101)  time: 0.1827  data: 0.0001  max mem: 14938
[22:00:49.745484] Test:  [50/57]  eta: 0:00:01  loss: 0.7305 (0.8017)  time: 0.1832  data: 0.0001  max mem: 14938
[22:00:50.734873] Test:  [56/57]  eta: 0:00:00  loss: 0.7550 (0.8069)  time: 0.1778  data: 0.0001  max mem: 14938
[22:00:50.794031] Test: Total time: 0:00:10 (0.1842 s / it)
[22:00:52.539014] Dice score of the network on the train images: 0.838146, val images: 0.822083
[22:00:52.543411] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:00:53.432520] Epoch: [47]  [  0/345]  eta: 0:05:06  lr: 0.000003  loss: 0.7172 (0.7172)  time: 0.8880  data: 0.1457  max mem: 14938
[22:01:08.332078] Epoch: [47]  [ 20/345]  eta: 0:04:04  lr: 0.000003  loss: 0.7013 (0.7033)  time: 0.7449  data: 0.0001  max mem: 14938
[22:01:23.277932] Epoch: [47]  [ 40/345]  eta: 0:03:48  lr: 0.000003  loss: 0.7040 (0.7051)  time: 0.7472  data: 0.0001  max mem: 14938
[22:01:38.256403] Epoch: [47]  [ 60/345]  eta: 0:03:33  lr: 0.000003  loss: 0.7079 (0.7061)  time: 0.7489  data: 0.0001  max mem: 14938
[22:01:53.257426] Epoch: [47]  [ 80/345]  eta: 0:03:18  lr: 0.000003  loss: 0.7094 (0.7071)  time: 0.7500  data: 0.0001  max mem: 14938
[22:02:08.275301] Epoch: [47]  [100/345]  eta: 0:03:03  lr: 0.000003  loss: 0.7027 (0.7068)  time: 0.7508  data: 0.0001  max mem: 14938
[22:02:23.313110] Epoch: [47]  [120/345]  eta: 0:02:48  lr: 0.000002  loss: 0.7084 (0.7069)  time: 0.7518  data: 0.0001  max mem: 14938
[22:02:38.344480] Epoch: [47]  [140/345]  eta: 0:02:33  lr: 0.000002  loss: 0.7071 (0.7071)  time: 0.7515  data: 0.0001  max mem: 14938
[22:02:53.373229] Epoch: [47]  [160/345]  eta: 0:02:18  lr: 0.000002  loss: 0.7040 (0.7067)  time: 0.7514  data: 0.0001  max mem: 14938
[22:03:08.398925] Epoch: [47]  [180/345]  eta: 0:02:03  lr: 0.000002  loss: 0.7129 (0.7073)  time: 0.7512  data: 0.0001  max mem: 14938
[22:03:23.415814] Epoch: [47]  [200/345]  eta: 0:01:48  lr: 0.000002  loss: 0.7089 (0.7075)  time: 0.7508  data: 0.0001  max mem: 14938
[22:03:38.426514] Epoch: [47]  [220/345]  eta: 0:01:33  lr: 0.000002  loss: 0.7052 (0.7072)  time: 0.7505  data: 0.0001  max mem: 14938
[22:03:53.438165] Epoch: [47]  [240/345]  eta: 0:01:18  lr: 0.000002  loss: 0.6997 (0.7069)  time: 0.7505  data: 0.0001  max mem: 14938
[22:04:08.441171] Epoch: [47]  [260/345]  eta: 0:01:03  lr: 0.000002  loss: 0.7048 (0.7071)  time: 0.7501  data: 0.0001  max mem: 14938
[22:04:23.442752] Epoch: [47]  [280/345]  eta: 0:00:48  lr: 0.000002  loss: 0.7102 (0.7073)  time: 0.7500  data: 0.0001  max mem: 14938
[22:04:38.434197] Epoch: [47]  [300/345]  eta: 0:00:33  lr: 0.000002  loss: 0.7055 (0.7072)  time: 0.7495  data: 0.0001  max mem: 14938
[22:04:53.424681] Epoch: [47]  [320/345]  eta: 0:00:18  lr: 0.000001  loss: 0.7047 (0.7072)  time: 0.7495  data: 0.0001  max mem: 14938
[22:05:08.412748] Epoch: [47]  [340/345]  eta: 0:00:03  lr: 0.000001  loss: 0.7088 (0.7072)  time: 0.7494  data: 0.0001  max mem: 14938
[22:05:11.413017] Epoch: [47]  [344/345]  eta: 0:00:00  lr: 0.000001  loss: 0.7059 (0.7072)  time: 0.7495  data: 0.0001  max mem: 14938
[22:05:11.477137] Epoch: [47] Total time: 0:04:18 (0.7505 s / it)
[22:05:11.477450] Averaged stats: lr: 0.000001  loss: 0.7059 (0.7072)
[22:05:11.812754] Test:  [  0/345]  eta: 0:01:54  loss: 0.6636 (0.6636)  time: 0.3310  data: 0.1489  max mem: 14938
[22:05:13.649464] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6831 (0.6818)  time: 0.1970  data: 0.0136  max mem: 14938
[22:05:15.489419] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6818 (0.6803)  time: 0.1838  data: 0.0001  max mem: 14938
[22:05:17.332290] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6759 (0.6789)  time: 0.1841  data: 0.0001  max mem: 14938
[22:05:19.178806] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6770 (0.6812)  time: 0.1844  data: 0.0001  max mem: 14938
[22:05:21.029226] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6835 (0.6816)  time: 0.1848  data: 0.0001  max mem: 14938
[22:05:22.886059] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6815 (0.6824)  time: 0.1853  data: 0.0001  max mem: 14938
[22:05:24.744406] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6802 (0.6821)  time: 0.1857  data: 0.0001  max mem: 14938
[22:05:26.605129] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6789 (0.6826)  time: 0.1859  data: 0.0001  max mem: 14938
[22:05:28.469974] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6903 (0.6830)  time: 0.1862  data: 0.0001  max mem: 14938
[22:05:30.338653] Test:  [100/345]  eta: 0:00:45  loss: 0.6908 (0.6834)  time: 0.1866  data: 0.0001  max mem: 14938
[22:05:32.210487] Test:  [110/345]  eta: 0:00:43  loss: 0.6791 (0.6829)  time: 0.1870  data: 0.0001  max mem: 14938
[22:05:34.086134] Test:  [120/345]  eta: 0:00:42  loss: 0.6823 (0.6835)  time: 0.1873  data: 0.0001  max mem: 14938
[22:05:35.964456] Test:  [130/345]  eta: 0:00:40  loss: 0.6831 (0.6837)  time: 0.1876  data: 0.0001  max mem: 14938
[22:05:37.846584] Test:  [140/345]  eta: 0:00:38  loss: 0.6829 (0.6840)  time: 0.1880  data: 0.0001  max mem: 14938
[22:05:39.731897] Test:  [150/345]  eta: 0:00:36  loss: 0.6829 (0.6838)  time: 0.1883  data: 0.0001  max mem: 14938
[22:05:41.619287] Test:  [160/345]  eta: 0:00:34  loss: 0.6831 (0.6839)  time: 0.1886  data: 0.0001  max mem: 14938
[22:05:43.512865] Test:  [170/345]  eta: 0:00:32  loss: 0.6917 (0.6847)  time: 0.1890  data: 0.0001  max mem: 14938
[22:05:45.408787] Test:  [180/345]  eta: 0:00:30  loss: 0.6892 (0.6847)  time: 0.1894  data: 0.0001  max mem: 14938
[22:05:47.307741] Test:  [190/345]  eta: 0:00:29  loss: 0.6838 (0.6849)  time: 0.1897  data: 0.0001  max mem: 14938
[22:05:49.210556] Test:  [200/345]  eta: 0:00:27  loss: 0.6833 (0.6846)  time: 0.1900  data: 0.0001  max mem: 14938
[22:05:51.117918] Test:  [210/345]  eta: 0:00:25  loss: 0.6823 (0.6846)  time: 0.1905  data: 0.0001  max mem: 14938
[22:05:53.028071] Test:  [220/345]  eta: 0:00:23  loss: 0.6811 (0.6846)  time: 0.1908  data: 0.0001  max mem: 14938
[22:05:54.942521] Test:  [230/345]  eta: 0:00:21  loss: 0.6809 (0.6845)  time: 0.1912  data: 0.0001  max mem: 14938
[22:05:56.860801] Test:  [240/345]  eta: 0:00:19  loss: 0.6783 (0.6842)  time: 0.1916  data: 0.0001  max mem: 14938
[22:05:58.781982] Test:  [250/345]  eta: 0:00:17  loss: 0.6767 (0.6840)  time: 0.1919  data: 0.0001  max mem: 14938
[22:06:00.706262] Test:  [260/345]  eta: 0:00:16  loss: 0.6770 (0.6840)  time: 0.1922  data: 0.0001  max mem: 14938
[22:06:02.638757] Test:  [270/345]  eta: 0:00:14  loss: 0.6765 (0.6838)  time: 0.1928  data: 0.0001  max mem: 14938
[22:06:04.570726] Test:  [280/345]  eta: 0:00:12  loss: 0.6776 (0.6837)  time: 0.1932  data: 0.0001  max mem: 14938
[22:06:06.506001] Test:  [290/345]  eta: 0:00:10  loss: 0.6819 (0.6836)  time: 0.1933  data: 0.0001  max mem: 14938
[22:06:08.444298] Test:  [300/345]  eta: 0:00:08  loss: 0.6781 (0.6835)  time: 0.1936  data: 0.0001  max mem: 14938
[22:06:10.386084] Test:  [310/345]  eta: 0:00:06  loss: 0.6781 (0.6834)  time: 0.1940  data: 0.0001  max mem: 14938
[22:06:12.330655] Test:  [320/345]  eta: 0:00:04  loss: 0.6782 (0.6834)  time: 0.1943  data: 0.0001  max mem: 14938
[22:06:14.277563] Test:  [330/345]  eta: 0:00:02  loss: 0.6803 (0.6834)  time: 0.1945  data: 0.0001  max mem: 14938
[22:06:16.227002] Test:  [340/345]  eta: 0:00:00  loss: 0.6813 (0.6834)  time: 0.1948  data: 0.0001  max mem: 14938
[22:06:17.009023] Test:  [344/345]  eta: 0:00:00  loss: 0.6810 (0.6834)  time: 0.1949  data: 0.0001  max mem: 14938
[22:06:17.064602] Test: Total time: 0:01:05 (0.1901 s / it)
[22:06:27.424738] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8609 (0.8609)  time: 0.3219  data: 0.1423  max mem: 14938
[22:06:29.241483] Test:  [10/57]  eta: 0:00:09  loss: 0.8979 (0.8900)  time: 0.1944  data: 0.0130  max mem: 14938
[22:06:31.062249] Test:  [20/57]  eta: 0:00:06  loss: 0.8979 (0.8768)  time: 0.1818  data: 0.0001  max mem: 14938
[22:06:32.886951] Test:  [30/57]  eta: 0:00:05  loss: 0.7556 (0.8334)  time: 0.1822  data: 0.0001  max mem: 14938
[22:06:34.716333] Test:  [40/57]  eta: 0:00:03  loss: 0.7408 (0.8115)  time: 0.1827  data: 0.0001  max mem: 14938
[22:06:36.549678] Test:  [50/57]  eta: 0:00:01  loss: 0.7321 (0.8030)  time: 0.1831  data: 0.0001  max mem: 14938
[22:06:37.538812] Test:  [56/57]  eta: 0:00:00  loss: 0.7539 (0.8081)  time: 0.1776  data: 0.0001  max mem: 14938
[22:06:37.576112] Test: Total time: 0:00:10 (0.1838 s / it)
[22:06:39.335727] Dice score of the network on the train images: 0.839279, val images: 0.821635
[22:06:39.339934] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:06:40.226686] Epoch: [48]  [  0/345]  eta: 0:05:05  lr: 0.000001  loss: 0.7026 (0.7026)  time: 0.8857  data: 0.1444  max mem: 14938
[22:06:55.124336] Epoch: [48]  [ 20/345]  eta: 0:04:04  lr: 0.000001  loss: 0.7032 (0.7052)  time: 0.7448  data: 0.0001  max mem: 14938
[22:07:10.089637] Epoch: [48]  [ 40/345]  eta: 0:03:48  lr: 0.000001  loss: 0.7034 (0.7044)  time: 0.7482  data: 0.0001  max mem: 14938
[22:07:25.072694] Epoch: [48]  [ 60/345]  eta: 0:03:33  lr: 0.000001  loss: 0.7040 (0.7043)  time: 0.7491  data: 0.0001  max mem: 14938
[22:07:40.072500] Epoch: [48]  [ 80/345]  eta: 0:03:18  lr: 0.000001  loss: 0.7091 (0.7059)  time: 0.7499  data: 0.0001  max mem: 14938
[22:07:55.093483] Epoch: [48]  [100/345]  eta: 0:03:03  lr: 0.000001  loss: 0.7082 (0.7060)  time: 0.7510  data: 0.0001  max mem: 14938
[22:08:10.124295] Epoch: [48]  [120/345]  eta: 0:02:48  lr: 0.000001  loss: 0.7075 (0.7064)  time: 0.7515  data: 0.0001  max mem: 14938
[22:08:25.151052] Epoch: [48]  [140/345]  eta: 0:02:33  lr: 0.000001  loss: 0.7041 (0.7063)  time: 0.7513  data: 0.0001  max mem: 14938
[22:08:40.173516] Epoch: [48]  [160/345]  eta: 0:02:18  lr: 0.000001  loss: 0.7072 (0.7067)  time: 0.7511  data: 0.0001  max mem: 14938
[22:08:55.184233] Epoch: [48]  [180/345]  eta: 0:02:03  lr: 0.000001  loss: 0.7111 (0.7071)  time: 0.7505  data: 0.0001  max mem: 14938
[22:09:10.199474] Epoch: [48]  [200/345]  eta: 0:01:48  lr: 0.000001  loss: 0.7049 (0.7071)  time: 0.7507  data: 0.0001  max mem: 14938
[22:09:25.212101] Epoch: [48]  [220/345]  eta: 0:01:33  lr: 0.000001  loss: 0.7057 (0.7071)  time: 0.7506  data: 0.0001  max mem: 14938
[22:09:40.194426] Epoch: [48]  [240/345]  eta: 0:01:18  lr: 0.000001  loss: 0.7040 (0.7072)  time: 0.7491  data: 0.0001  max mem: 14938
[22:09:55.183419] Epoch: [48]  [260/345]  eta: 0:01:03  lr: 0.000001  loss: 0.7050 (0.7070)  time: 0.7494  data: 0.0001  max mem: 14938
[22:10:10.282530] Epoch: [48]  [280/345]  eta: 0:00:48  lr: 0.000000  loss: 0.7053 (0.7069)  time: 0.7549  data: 0.0001  max mem: 14938
[22:10:25.270800] Epoch: [48]  [300/345]  eta: 0:00:33  lr: 0.000000  loss: 0.7112 (0.7071)  time: 0.7494  data: 0.0001  max mem: 14938
[22:10:40.261638] Epoch: [48]  [320/345]  eta: 0:00:18  lr: 0.000000  loss: 0.7013 (0.7070)  time: 0.7495  data: 0.0001  max mem: 14938
[22:10:55.256204] Epoch: [48]  [340/345]  eta: 0:00:03  lr: 0.000000  loss: 0.7026 (0.7070)  time: 0.7497  data: 0.0001  max mem: 14938
[22:10:58.253361] Epoch: [48]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.7026 (0.7070)  time: 0.7495  data: 0.0001  max mem: 14938
[22:10:58.315610] Epoch: [48] Total time: 0:04:18 (0.7507 s / it)
[22:10:58.316075] Averaged stats: lr: 0.000000  loss: 0.7026 (0.7070)
[22:10:58.651999] Test:  [  0/345]  eta: 0:01:54  loss: 0.6798 (0.6798)  time: 0.3315  data: 0.1497  max mem: 14938
[22:11:00.489199] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6829 (0.6869)  time: 0.1971  data: 0.0137  max mem: 14938
[22:11:02.327987] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6818 (0.6840)  time: 0.1837  data: 0.0001  max mem: 14938
[22:11:04.171358] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6818 (0.6844)  time: 0.1841  data: 0.0001  max mem: 14938
[22:11:06.018380] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6829 (0.6845)  time: 0.1845  data: 0.0001  max mem: 14938
[22:11:07.870995] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6797 (0.6835)  time: 0.1849  data: 0.0001  max mem: 14938
[22:11:09.726750] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6793 (0.6833)  time: 0.1854  data: 0.0001  max mem: 14938
[22:11:11.584087] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6779 (0.6829)  time: 0.1856  data: 0.0001  max mem: 14938
[22:11:13.444955] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6798 (0.6824)  time: 0.1859  data: 0.0001  max mem: 14938
[22:11:15.309344] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6814 (0.6827)  time: 0.1862  data: 0.0001  max mem: 14938
[22:11:17.177570] Test:  [100/345]  eta: 0:00:45  loss: 0.6826 (0.6827)  time: 0.1866  data: 0.0001  max mem: 14938
[22:11:19.050087] Test:  [110/345]  eta: 0:00:43  loss: 0.6827 (0.6833)  time: 0.1870  data: 0.0001  max mem: 14938
[22:11:20.927049] Test:  [120/345]  eta: 0:00:42  loss: 0.6828 (0.6833)  time: 0.1874  data: 0.0001  max mem: 14938
[22:11:22.805769] Test:  [130/345]  eta: 0:00:40  loss: 0.6848 (0.6836)  time: 0.1877  data: 0.0001  max mem: 14938
[22:11:24.687722] Test:  [140/345]  eta: 0:00:38  loss: 0.6885 (0.6836)  time: 0.1880  data: 0.0001  max mem: 14938
[22:11:26.572610] Test:  [150/345]  eta: 0:00:36  loss: 0.6820 (0.6835)  time: 0.1883  data: 0.0001  max mem: 14938
[22:11:28.460564] Test:  [160/345]  eta: 0:00:34  loss: 0.6837 (0.6838)  time: 0.1886  data: 0.0001  max mem: 14938
[22:11:30.352011] Test:  [170/345]  eta: 0:00:32  loss: 0.6837 (0.6836)  time: 0.1889  data: 0.0001  max mem: 14938
[22:11:32.248326] Test:  [180/345]  eta: 0:00:30  loss: 0.6818 (0.6837)  time: 0.1893  data: 0.0001  max mem: 14938
[22:11:34.148363] Test:  [190/345]  eta: 0:00:29  loss: 0.6826 (0.6837)  time: 0.1898  data: 0.0001  max mem: 14938
[22:11:36.051840] Test:  [200/345]  eta: 0:00:27  loss: 0.6809 (0.6835)  time: 0.1901  data: 0.0001  max mem: 14938
[22:11:37.960592] Test:  [210/345]  eta: 0:00:25  loss: 0.6809 (0.6836)  time: 0.1906  data: 0.0001  max mem: 14938
[22:11:39.871779] Test:  [220/345]  eta: 0:00:23  loss: 0.6848 (0.6836)  time: 0.1909  data: 0.0001  max mem: 14938
[22:11:41.787253] Test:  [230/345]  eta: 0:00:21  loss: 0.6854 (0.6835)  time: 0.1913  data: 0.0001  max mem: 14938
[22:11:43.706136] Test:  [240/345]  eta: 0:00:19  loss: 0.6790 (0.6834)  time: 0.1917  data: 0.0001  max mem: 14938
[22:11:45.629467] Test:  [250/345]  eta: 0:00:17  loss: 0.6790 (0.6834)  time: 0.1921  data: 0.0001  max mem: 14938
[22:11:47.554983] Test:  [260/345]  eta: 0:00:16  loss: 0.6802 (0.6833)  time: 0.1924  data: 0.0001  max mem: 14938
[22:11:49.482116] Test:  [270/345]  eta: 0:00:14  loss: 0.6795 (0.6832)  time: 0.1926  data: 0.0001  max mem: 14938
[22:11:51.413985] Test:  [280/345]  eta: 0:00:12  loss: 0.6810 (0.6834)  time: 0.1929  data: 0.0001  max mem: 14938
[22:11:53.351336] Test:  [290/345]  eta: 0:00:10  loss: 0.6874 (0.6835)  time: 0.1934  data: 0.0001  max mem: 14938
[22:11:55.290737] Test:  [300/345]  eta: 0:00:08  loss: 0.6849 (0.6835)  time: 0.1938  data: 0.0001  max mem: 14938
[22:11:57.231788] Test:  [310/345]  eta: 0:00:06  loss: 0.6837 (0.6834)  time: 0.1940  data: 0.0001  max mem: 14938
[22:11:59.175205] Test:  [320/345]  eta: 0:00:04  loss: 0.6840 (0.6835)  time: 0.1942  data: 0.0001  max mem: 14938
[22:12:01.122105] Test:  [330/345]  eta: 0:00:02  loss: 0.6833 (0.6835)  time: 0.1945  data: 0.0001  max mem: 14938
[22:12:03.072625] Test:  [340/345]  eta: 0:00:00  loss: 0.6801 (0.6833)  time: 0.1948  data: 0.0001  max mem: 14938
[22:12:03.854712] Test:  [344/345]  eta: 0:00:00  loss: 0.6787 (0.6834)  time: 0.1950  data: 0.0001  max mem: 14938
[22:12:03.913673] Test: Total time: 0:01:05 (0.1901 s / it)
[22:12:14.306503] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8599 (0.8599)  time: 0.3190  data: 0.1392  max mem: 14938
[22:12:16.123061] Test:  [10/57]  eta: 0:00:09  loss: 0.8972 (0.8898)  time: 0.1941  data: 0.0127  max mem: 14938
[22:12:17.945839] Test:  [20/57]  eta: 0:00:06  loss: 0.8972 (0.8766)  time: 0.1819  data: 0.0001  max mem: 14938
[22:12:19.771344] Test:  [30/57]  eta: 0:00:05  loss: 0.7553 (0.8332)  time: 0.1824  data: 0.0001  max mem: 14938
[22:12:21.602395] Test:  [40/57]  eta: 0:00:03  loss: 0.7399 (0.8113)  time: 0.1828  data: 0.0001  max mem: 14938
[22:12:23.437129] Test:  [50/57]  eta: 0:00:01  loss: 0.7318 (0.8028)  time: 0.1832  data: 0.0001  max mem: 14938
[22:12:24.427817] Test:  [56/57]  eta: 0:00:00  loss: 0.7544 (0.8080)  time: 0.1778  data: 0.0001  max mem: 14938
[22:12:24.487072] Test: Total time: 0:00:10 (0.1842 s / it)
[22:12:26.246774] Dice score of the network on the train images: 0.839193, val images: 0.821684
[22:12:26.250785] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:12:27.132841] Epoch: [49]  [  0/345]  eta: 0:05:03  lr: 0.000000  loss: 0.7234 (0.7234)  time: 0.8810  data: 0.1408  max mem: 14938
[22:12:42.009669] Epoch: [49]  [ 20/345]  eta: 0:04:03  lr: 0.000000  loss: 0.7073 (0.7090)  time: 0.7438  data: 0.0001  max mem: 14938
[22:12:56.949167] Epoch: [49]  [ 40/345]  eta: 0:03:48  lr: 0.000000  loss: 0.7098 (0.7100)  time: 0.7469  data: 0.0001  max mem: 14938
[22:13:11.905481] Epoch: [49]  [ 60/345]  eta: 0:03:33  lr: 0.000000  loss: 0.7090 (0.7092)  time: 0.7478  data: 0.0001  max mem: 14938
[22:13:26.901396] Epoch: [49]  [ 80/345]  eta: 0:03:18  lr: 0.000000  loss: 0.7058 (0.7081)  time: 0.7497  data: 0.0001  max mem: 14938
[22:13:41.935204] Epoch: [49]  [100/345]  eta: 0:03:03  lr: 0.000000  loss: 0.7074 (0.7084)  time: 0.7516  data: 0.0001  max mem: 14938
[22:13:56.953233] Epoch: [49]  [120/345]  eta: 0:02:48  lr: 0.000000  loss: 0.7023 (0.7076)  time: 0.7509  data: 0.0001  max mem: 14938
[22:14:11.976267] Epoch: [49]  [140/345]  eta: 0:02:33  lr: 0.000000  loss: 0.7092 (0.7078)  time: 0.7511  data: 0.0001  max mem: 14938
[22:14:26.988795] Epoch: [49]  [160/345]  eta: 0:02:18  lr: 0.000000  loss: 0.7027 (0.7076)  time: 0.7506  data: 0.0001  max mem: 14938
[22:14:41.996188] Epoch: [49]  [180/345]  eta: 0:02:03  lr: 0.000000  loss: 0.7065 (0.7075)  time: 0.7503  data: 0.0001  max mem: 14938
[22:14:57.002706] Epoch: [49]  [200/345]  eta: 0:01:48  lr: 0.000000  loss: 0.6997 (0.7070)  time: 0.7503  data: 0.0001  max mem: 14938
[22:15:11.997496] Epoch: [49]  [220/345]  eta: 0:01:33  lr: 0.000000  loss: 0.7009 (0.7068)  time: 0.7497  data: 0.0001  max mem: 14938
[22:15:26.988860] Epoch: [49]  [240/345]  eta: 0:01:18  lr: 0.000000  loss: 0.7061 (0.7067)  time: 0.7495  data: 0.0001  max mem: 14938
[22:15:41.976128] Epoch: [49]  [260/345]  eta: 0:01:03  lr: 0.000000  loss: 0.7033 (0.7067)  time: 0.7493  data: 0.0001  max mem: 14938
[22:15:56.957684] Epoch: [49]  [280/345]  eta: 0:00:48  lr: 0.000000  loss: 0.7051 (0.7068)  time: 0.7490  data: 0.0001  max mem: 14938
[22:16:11.947309] Epoch: [49]  [300/345]  eta: 0:00:33  lr: 0.000000  loss: 0.7033 (0.7068)  time: 0.7494  data: 0.0001  max mem: 14938
[22:16:26.942671] Epoch: [49]  [320/345]  eta: 0:00:18  lr: 0.000000  loss: 0.7071 (0.7069)  time: 0.7497  data: 0.0001  max mem: 14938
[22:16:41.941576] Epoch: [49]  [340/345]  eta: 0:00:03  lr: 0.000000  loss: 0.7006 (0.7069)  time: 0.7499  data: 0.0001  max mem: 14938
[22:16:44.940748] Epoch: [49]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.7038 (0.7069)  time: 0.7499  data: 0.0001  max mem: 14938
[22:16:45.004248] Epoch: [49] Total time: 0:04:18 (0.7500 s / it)
[22:16:45.004537] Averaged stats: lr: 0.000000  loss: 0.7038 (0.7069)
[22:16:45.341879] Test:  [  0/345]  eta: 0:01:55  loss: 0.6861 (0.6861)  time: 0.3334  data: 0.1517  max mem: 14938
[22:16:47.177876] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6775 (0.6792)  time: 0.1971  data: 0.0138  max mem: 14938
[22:16:49.017166] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6775 (0.6806)  time: 0.1837  data: 0.0001  max mem: 14938
[22:16:50.861714] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6844 (0.6819)  time: 0.1841  data: 0.0001  max mem: 14938
[22:16:52.708187] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6855 (0.6828)  time: 0.1845  data: 0.0001  max mem: 14938
[22:16:54.558914] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6820 (0.6826)  time: 0.1848  data: 0.0001  max mem: 14938
[22:16:56.413295] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6813 (0.6825)  time: 0.1852  data: 0.0001  max mem: 14938
[22:16:58.270619] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6801 (0.6820)  time: 0.1855  data: 0.0001  max mem: 14938
[22:17:00.131217] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6835 (0.6827)  time: 0.1858  data: 0.0001  max mem: 14938
[22:17:01.994783] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6863 (0.6833)  time: 0.1862  data: 0.0001  max mem: 14938
[22:17:03.862554] Test:  [100/345]  eta: 0:00:45  loss: 0.6850 (0.6835)  time: 0.1865  data: 0.0001  max mem: 14938
[22:17:05.733385] Test:  [110/345]  eta: 0:00:43  loss: 0.6812 (0.6836)  time: 0.1869  data: 0.0001  max mem: 14938
[22:17:07.608378] Test:  [120/345]  eta: 0:00:42  loss: 0.6783 (0.6828)  time: 0.1872  data: 0.0001  max mem: 14938
[22:17:09.485330] Test:  [130/345]  eta: 0:00:40  loss: 0.6748 (0.6827)  time: 0.1875  data: 0.0001  max mem: 14938
[22:17:11.368533] Test:  [140/345]  eta: 0:00:38  loss: 0.6822 (0.6827)  time: 0.1880  data: 0.0001  max mem: 14938
[22:17:13.253038] Test:  [150/345]  eta: 0:00:36  loss: 0.6825 (0.6827)  time: 0.1883  data: 0.0001  max mem: 14938
[22:17:15.139933] Test:  [160/345]  eta: 0:00:34  loss: 0.6787 (0.6825)  time: 0.1885  data: 0.0001  max mem: 14938
[22:17:17.030706] Test:  [170/345]  eta: 0:00:32  loss: 0.6817 (0.6825)  time: 0.1888  data: 0.0001  max mem: 14938
[22:17:18.925826] Test:  [180/345]  eta: 0:00:30  loss: 0.6846 (0.6827)  time: 0.1892  data: 0.0001  max mem: 14938
[22:17:20.824769] Test:  [190/345]  eta: 0:00:29  loss: 0.6793 (0.6826)  time: 0.1897  data: 0.0001  max mem: 14938
[22:17:22.726254] Test:  [200/345]  eta: 0:00:27  loss: 0.6790 (0.6826)  time: 0.1900  data: 0.0001  max mem: 14938
[22:17:24.635023] Test:  [210/345]  eta: 0:00:25  loss: 0.6829 (0.6827)  time: 0.1905  data: 0.0001  max mem: 14938
[22:17:26.546069] Test:  [220/345]  eta: 0:00:23  loss: 0.6832 (0.6827)  time: 0.1909  data: 0.0001  max mem: 14938
[22:17:28.460853] Test:  [230/345]  eta: 0:00:21  loss: 0.6832 (0.6829)  time: 0.1912  data: 0.0001  max mem: 14938
[22:17:30.378530] Test:  [240/345]  eta: 0:00:19  loss: 0.6862 (0.6830)  time: 0.1916  data: 0.0001  max mem: 14938
[22:17:32.300509] Test:  [250/345]  eta: 0:00:17  loss: 0.6869 (0.6831)  time: 0.1919  data: 0.0001  max mem: 14938
[22:17:34.226732] Test:  [260/345]  eta: 0:00:16  loss: 0.6817 (0.6831)  time: 0.1924  data: 0.0001  max mem: 14938
[22:17:36.156321] Test:  [270/345]  eta: 0:00:14  loss: 0.6811 (0.6831)  time: 0.1927  data: 0.0001  max mem: 14938
[22:17:38.087805] Test:  [280/345]  eta: 0:00:12  loss: 0.6811 (0.6831)  time: 0.1930  data: 0.0001  max mem: 14938
[22:17:40.022817] Test:  [290/345]  eta: 0:00:10  loss: 0.6794 (0.6830)  time: 0.1933  data: 0.0001  max mem: 14938
[22:17:41.960315] Test:  [300/345]  eta: 0:00:08  loss: 0.6797 (0.6831)  time: 0.1936  data: 0.0001  max mem: 14938
[22:17:43.901948] Test:  [310/345]  eta: 0:00:06  loss: 0.6867 (0.6832)  time: 0.1939  data: 0.0001  max mem: 14938
[22:17:45.846430] Test:  [320/345]  eta: 0:00:04  loss: 0.6771 (0.6829)  time: 0.1943  data: 0.0001  max mem: 14938
[22:17:47.793294] Test:  [330/345]  eta: 0:00:02  loss: 0.6786 (0.6832)  time: 0.1945  data: 0.0001  max mem: 14938
[22:17:49.742894] Test:  [340/345]  eta: 0:00:00  loss: 0.6849 (0.6832)  time: 0.1948  data: 0.0001  max mem: 14938
[22:17:50.524397] Test:  [344/345]  eta: 0:00:00  loss: 0.6824 (0.6832)  time: 0.1949  data: 0.0001  max mem: 14938
[22:17:50.583247] Test: Total time: 0:01:05 (0.1901 s / it)
[22:18:00.956340] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8594 (0.8594)  time: 0.3192  data: 0.1390  max mem: 14938
[22:18:02.774177] Test:  [10/57]  eta: 0:00:09  loss: 0.8966 (0.8892)  time: 0.1942  data: 0.0127  max mem: 14938
[22:18:04.597246] Test:  [20/57]  eta: 0:00:06  loss: 0.8966 (0.8761)  time: 0.1820  data: 0.0001  max mem: 14938
[22:18:06.423736] Test:  [30/57]  eta: 0:00:05  loss: 0.7549 (0.8328)  time: 0.1824  data: 0.0001  max mem: 14938
[22:18:08.256435] Test:  [40/57]  eta: 0:00:03  loss: 0.7396 (0.8109)  time: 0.1829  data: 0.0001  max mem: 14938
[22:18:10.093302] Test:  [50/57]  eta: 0:00:01  loss: 0.7314 (0.8024)  time: 0.1834  data: 0.0001  max mem: 14938
[22:18:11.083970] Test:  [56/57]  eta: 0:00:00  loss: 0.7543 (0.8076)  time: 0.1780  data: 0.0001  max mem: 14938
[22:18:11.142175] Test: Total time: 0:00:10 (0.1843 s / it)
[22:18:12.866632] Dice score of the network on the train images: 0.838597, val images: 0.821789
[22:18:12.868315] Training time 4:49:29
[22:18:14.677010] Load pre-trained checkpoint from: /root/seg_framework/MS-Mamba/output_dir/mslesseg/checkpoints_0/checkpoint-best_dice_model_0.pth
[22:18:14.698360] <All keys matched successfully>
[22:18:15.266448] Test:  [  0/246]  eta: 0:02:02    time: 0.4991  data: 0.1637  max mem: 14938
[22:18:17.951572] Test:  [ 10/246]  eta: 0:01:08    time: 0.2894  data: 0.0149  max mem: 14938
[22:18:24.150489] ---------------------------------
[22:18:24.150714] Patient 1:
[22:18:24.150795]       precision: 0.489123672246933
[22:18:24.150861]       recall: 0.5181040167808533
[22:18:24.150920]       dice_score: 0.5031969547271729
[22:18:24.153995] Test:  [ 20/246]  eta: 0:01:41    time: 0.4443  data: 0.0001  max mem: 14938
[22:18:26.832045] Test:  [ 30/246]  eta: 0:01:24    time: 0.4440  data: 0.0001  max mem: 14938
[22:18:33.023235] ---------------------------------
[22:18:33.023459] Patient 2:
[22:18:33.023538]       precision: 0.6291866302490234
[22:18:33.023601]       recall: 0.5310449004173279
[22:18:33.023659]       dice_score: 0.5759649872779846
[22:18:33.024201] Test:  [ 40/246]  eta: 0:01:31    time: 0.4435  data: 0.0001  max mem: 14938

[22:18:35.701916] Test:  [ 50/246]  eta: 0:01:20    time: 0.4434  data: 0.0001  max mem: 14938
[22:18:38.565719] Test:  [ 60/246]  eta: 0:01:12    time: 0.2770  data: 0.0001  max mem: 14938
[22:18:42.152744] ---------------------------------
[22:18:42.152988] Patient 3:
[22:18:42.153070]       precision: 0.5025906562805176
[22:18:42.153133]       recall: 0.4256719648838043
[22:18:42.153191]       dice_score: 0.4609444737434387
[22:18:44.546766] Test:  [ 70/246]  eta: 0:01:13    time: 0.4422  data: 0.0001  max mem: 14938
[22:18:47.408436] Test:  [ 80/246]  eta: 0:01:06    time: 0.4421  data: 0.0001  max mem: 14938
[22:18:50.993528] ---------------------------------
[22:18:50.993746] Patient 4:
[22:18:50.993824]       precision: 0.6488020420074463
[22:18:50.993890]       recall: 0.5194346308708191
[22:18:50.993950]       dice_score: 0.5769554376602173
[22:18:53.385077] Test:  [ 90/246]  eta: 0:01:06    time: 0.4419  data: 0.0001  max mem: 14938
[22:18:56.246257] Test:  [100/246]  eta: 0:00:59    time: 0.4418  data: 0.0001  max mem: 14938
[22:19:00.108542] ---------------------------------
[22:19:00.108753] Patient 5:
[22:19:00.108833]       precision: 0.5223880410194397
[22:19:00.108896]       recall: 0.4031815826892853
[22:19:00.108955]       dice_score: 0.4551083445549011
[22:19:02.214217] Test:  [110/246]  eta: 0:00:58    time: 0.4414  data: 0.0001  max mem: 14938
[22:19:05.076853] Test:  [120/246]  eta: 0:00:52    time: 0.4415  data: 0.0001  max mem: 14938
[22:19:08.929034] ---------------------------------
[22:19:08.929261] Patient 6:
[22:19:08.929340]       precision: 0.49426019191741943
[22:19:08.929404]       recall: 0.4251234233379364
[22:19:08.929461]       dice_score: 0.4570923149585724
[22:19:11.034906] Test:  [130/246]  eta: 0:00:49    time: 0.4410  data: 0.0001  max mem: 14938
[22:19:13.896177] Test:  [140/246]  eta: 0:00:44    time: 0.4409  data: 0.0001  max mem: 14938
[22:19:18.111163] ---------------------------------
[22:19:18.111386] Patient 7:
[22:19:18.111467]       precision: 0.8141334056854248
[22:19:18.111529]       recall: 0.7556722164154053
[22:19:18.111587]       dice_score: 0.7838142514228821
[22:19:19.931561] Test:  [150/246]  eta: 0:00:41    time: 0.4448  data: 0.0001  max mem: 14938
[22:19:22.792225] Test:  [160/246]  eta: 0:00:36    time: 0.4448  data: 0.0001  max mem: 14938
[22:19:26.981702] ---------------------------------
[22:19:26.981934] Patient 8:
[22:19:26.982015]       precision: 0.8669206500053406
[22:19:26.982078]       recall: 0.595063328742981
[22:19:26.982138]       dice_score: 0.7057158946990967
[22:19:28.801830] Test:  [170/246]  eta: 0:00:32    time: 0.4435  data: 0.0001  max mem: 14938
[22:19:31.662493] Test:  [180/246]  eta: 0:00:28    time: 0.4434  data: 0.0001  max mem: 14938
[22:19:35.772184] ---------------------------------
[22:19:35.772400] Patient 9:
[22:19:35.772473]       precision: 0.7173629999160767
[22:19:35.772535]       recall: 0.8026835322380066
[22:19:35.772594]       dice_score: 0.7576287388801575
[22:19:37.597219] Test:  [190/246]  eta: 0:00:24    time: 0.4397  data: 0.0001  max mem: 14938
[22:19:40.450632] Test:  [200/246]  eta: 0:00:19    time: 0.4394  data: 0.0001  max mem: 14938
[22:19:44.908736] ---------------------------------
[22:19:44.908945] Patient 10:
[22:19:44.909020]       precision: 0.7305795550346375
[22:19:44.909083]       recall: 0.7913909554481506
[22:19:44.909140]       dice_score: 0.7597703337669373
[22:19:46.449271] Test:  [210/246]  eta: 0:00:15    time: 0.4426  data: 0.0001  max mem: 14938
[22:19:49.303681] Test:  [220/246]  eta: 0:00:11    time: 0.4426  data: 0.0001  max mem: 14938
[22:19:53.718902] ---------------------------------
[22:19:53.719118] Patient 11:
[22:19:53.719192]       precision: 0.8766149878501892
[22:19:53.719269]       recall: 0.762573778629303
[22:19:53.719328]       dice_score: 0.8156273365020752
[22:19:55.257098] Test:  [230/246]  eta: 0:00:06    time: 0.4403  data: 0.0001  max mem: 14938
[22:19:58.112713] Test:  [240/246]  eta: 0:00:02    time: 0.4404  data: 0.0001  max mem: 14938
[22:20:02.571314] ---------------------------------
[22:20:02.571537] Patient 12:
[22:20:02.571612]       precision: 0.6899224519729614
[22:20:02.571676]       recall: 0.6821460723876953
[22:20:02.571734]       dice_score: 0.6860122680664062
[22:20:02.572088] Test:  [245/246]  eta: 0:00:00    time: 0.4371  data: 0.0001  max mem: 14938
[22:20:02.632616] Test: Total time: 0:01:47 (0.4385 s / it)
[22:20:02.632763] ================================
[22:20:02.632824] Averaged over all patients:
[22:20:02.633051]       precision: 0.6652 ± 0.1366
[22:20:02.633183]       recall: 0.6010 ± 0.1451
[22:20:02.633316]       dice_score: 0.6282 ± 0.1326
Not using distributed mode
[11:43:23.559435] job dir: /root/seg_framework/MS-Mamba/run_scripts
[11:43:23.559578] Namespace(accum_iter=1,
model='SegFormer3D',
in_channels=1,
lr=None,
blr=0.001,
min_lr=0,
dist_on_itp=False,
warmup_epochs=20,
device='cuda:0',
seed=42,
layer_decay=0.75,
clip_grad=None,
num_workers=8,
pin_mem=True,
resume='',
mask_mode='concatenate to image',
world_size=1,
embed_dim=1,
local_rank=-1,
dist_url='env://',
nb_classes=2,
data_dir='/root/MSLesSeg24/data',
datalist=None,
preprocess=False,
dim=2,
distributed=False)
[11:43:23.559691] device  cuda:0
[11:43:23.560763] Starting for fold 0
[11:43:23.756341] Elements in data_dir_paths: 11052
[11:43:23.791367] Elements in data_dir_paths: 1803
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[11:43:25.766363] number of params: 59620439
[11:43:25.766602] model: Vivim2D(
  (encoder): mamba_block(
    (downsample_layers): SegformerEncoder(
      (patch_embeddings): ModuleList(
        (0): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (1): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (2): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (3): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (block): ModuleList(
        (0): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): Identity()
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.003703703870996833)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.007407407741993666)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.011111111380159855)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.014814815483987331)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.018518518656492233)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.02222222276031971)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (2): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.025925926864147186)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.029629630967974663)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03333333507180214)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03703703731298447)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04074074327945709)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04444444552063942)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.048148151487112045)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.051851850003004074)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0555555559694767)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.05925925821065903)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06296296417713165)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06666667014360428)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07037036865949631)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07407407462596893)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07777778059244156)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08148147910833359)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08518518507480621)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08888889104127884)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (3): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.09259259700775146)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0962962955236435)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.10000000149011612)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (layer_norm): ModuleList(
        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=64, out_features=256, bias=False)
              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (act): SiLU()
              (x_proj): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_b): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_b): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_b): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_s): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_s): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_s): Linear(in_features=4, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=64, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=256, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=64, out_features=256, bias=False)
              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (act): SiLU()
              (x_proj): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_b): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_b): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_b): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_s): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_s): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_s): Linear(in_features=4, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=64, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=256, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (1): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=128, out_features=512, bias=False)
              (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (act): SiLU()
              (x_proj): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_b): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_b): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_b): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_s): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_s): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_s): Linear(in_features=8, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=128, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=128, out_features=512, bias=False)
              (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (act): SiLU()
              (x_proj): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_b): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_b): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_b): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_s): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_s): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_s): Linear(in_features=8, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=128, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (2): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=320, out_features=1280, bias=False)
              (conv1d): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (act): SiLU()
              (x_proj): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_b): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_b): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_b): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_s): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_s): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_s): Linear(in_features=20, out_features=640, bias=True)
              (out_proj): Linear(in_features=640, out_features=320, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(1280, 1280, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=320, out_features=1280, bias=False)
              (conv1d): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (act): SiLU()
              (x_proj): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_b): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_b): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_b): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_s): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_s): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_s): Linear(in_features=20, out_features=640, bias=True)
              (out_proj): Linear(in_features=640, out_features=320, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(1280, 1280, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (3): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=512, out_features=2048, bias=False)
              (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (act): SiLU()
              (x_proj): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_b): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_b): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_b): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_s): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_s): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_s): Linear(in_features=32, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=512, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=512, out_features=2048, bias=False)
              (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (act): SiLU()
              (x_proj): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_b): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_b): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_b): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_s): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_s): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_s): Linear(in_features=32, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=512, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
  )
  (decoder): SegformerDecodeHead(
    (linear_c): ModuleList(
      (0): SegformerMLP(
        (proj): Linear(in_features=64, out_features=768, bias=True)
      )
      (1): SegformerMLP(
        (proj): Linear(in_features=128, out_features=768, bias=True)
      )
      (2): SegformerMLP(
        (proj): Linear(in_features=320, out_features=768, bias=True)
      )
      (3): SegformerMLP(
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
    )
    (linear_fuse): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (batch_norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): ReLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Conv2d(768, 150, kernel_size=(1, 1), stride=(1, 1))
  )
  (out): Conv2d(768, 1, kernel_size=(1, 1), stride=(1, 1))
)
[11:43:25.769848] base lr: 1.00e-03
[11:43:25.769920] actual lr: 1.25e-04
[11:43:25.769971] accumulate grad iterations: 1
[11:43:25.770020] effective batch size: 32
[11:43:25.771625] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.000125
    maximize: False
    weight_decay: 0.01
)
[11:43:25.773788] Start training for 50 epochs
[11:43:25.773877] Number of samples in train dataloader:  345
[11:43:25.775683] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
[11:43:35.622640] Epoch: [0]  [  0/345]  eta: 0:56:36  lr: 0.000000  loss: 1.5696 (1.5696)  time: 9.8462  data: 0.2999  max mem: 15821
[11:43:47.274871] Epoch: [0]  [ 20/345]  eta: 0:05:32  lr: 0.000000  loss: 1.5682 (1.5690)  time: 0.5826  data: 0.0001  max mem: 15821
[11:43:58.992250] Epoch: [0]  [ 40/345]  eta: 0:04:07  lr: 0.000001  loss: 1.5625 (1.5672)  time: 0.5858  data: 0.0001  max mem: 15821
[11:44:10.807501] Epoch: [0]  [ 60/345]  eta: 0:03:30  lr: 0.000001  loss: 1.5453 (1.5605)  time: 0.5907  data: 0.0001  max mem: 15821
[11:44:22.687098] Epoch: [0]  [ 80/345]  eta: 0:03:06  lr: 0.000001  loss: 1.5377 (1.5551)  time: 0.5939  data: 0.0001  max mem: 15821
[11:44:34.616527] Epoch: [0]  [100/345]  eta: 0:02:46  lr: 0.000002  loss: 1.5304 (1.5500)  time: 0.5964  data: 0.0001  max mem: 15821
[11:44:46.590084] Epoch: [0]  [120/345]  eta: 0:02:30  lr: 0.000002  loss: 1.5248 (1.5457)  time: 0.5986  data: 0.0001  max mem: 15821
[11:44:58.586326] Epoch: [0]  [140/345]  eta: 0:02:14  lr: 0.000003  loss: 1.5065 (1.5403)  time: 0.5998  data: 0.0001  max mem: 15821
[11:45:10.606628] Epoch: [0]  [160/345]  eta: 0:02:00  lr: 0.000003  loss: 1.4792 (1.5329)  time: 0.6010  data: 0.0001  max mem: 15821
[11:45:22.643461] Epoch: [0]  [180/345]  eta: 0:01:46  lr: 0.000003  loss: 1.4274 (1.5217)  time: 0.6018  data: 0.0001  max mem: 15821
[11:45:34.684620] Epoch: [0]  [200/345]  eta: 0:01:32  lr: 0.000004  loss: 1.3853 (1.5083)  time: 0.6020  data: 0.0001  max mem: 15821
[11:45:46.747040] Epoch: [0]  [220/345]  eta: 0:01:19  lr: 0.000004  loss: 1.3624 (1.4953)  time: 0.6031  data: 0.0001  max mem: 15821
[11:45:58.820387] Epoch: [0]  [240/345]  eta: 0:01:06  lr: 0.000004  loss: 1.3396 (1.4825)  time: 0.6036  data: 0.0001  max mem: 15821
[11:46:10.902638] Epoch: [0]  [260/345]  eta: 0:00:53  lr: 0.000005  loss: 1.3093 (1.4694)  time: 0.6041  data: 0.0001  max mem: 15821
[11:46:23.079011] Epoch: [0]  [280/345]  eta: 0:00:41  lr: 0.000005  loss: 1.2796 (1.4560)  time: 0.6088  data: 0.0001  max mem: 15821
[11:46:35.168573] Epoch: [0]  [300/345]  eta: 0:00:28  lr: 0.000005  loss: 1.2477 (1.4424)  time: 0.6044  data: 0.0001  max mem: 15821
[11:46:47.264464] Epoch: [0]  [320/345]  eta: 0:00:15  lr: 0.000006  loss: 1.2142 (1.4286)  time: 0.6047  data: 0.0001  max mem: 15821
[11:46:59.358666] Epoch: [0]  [340/345]  eta: 0:00:03  lr: 0.000006  loss: 1.1799 (1.4143)  time: 0.6047  data: 0.0001  max mem: 15821
[11:47:01.780303] Epoch: [0]  [344/345]  eta: 0:00:00  lr: 0.000006  loss: 1.1728 (1.4112)  time: 0.6047  data: 0.0001  max mem: 15821
[11:47:01.843186] Epoch: [0] Total time: 0:03:36 (0.6263 s / it)
[11:47:01.843480] Averaged stats: lr: 0.000006  loss: 1.1728 (1.4112)
[11:47:02.320553] Test:  [  0/345]  eta: 0:02:42  loss: 1.2051 (1.2051)  time: 0.4718  data: 0.3066  max mem: 15821
[11:47:03.989297] Test:  [ 10/345]  eta: 0:01:05  loss: 1.2090 (1.2092)  time: 0.1945  data: 0.0280  max mem: 15821
[11:47:05.660992] Test:  [ 20/345]  eta: 0:00:58  loss: 1.2086 (1.2088)  time: 0.1669  data: 0.0001  max mem: 15821
[11:47:07.334864] Test:  [ 30/345]  eta: 0:00:55  loss: 1.2081 (1.2086)  time: 0.1672  data: 0.0001  max mem: 15821
[11:47:09.012928] Test:  [ 40/345]  eta: 0:00:53  loss: 1.2075 (1.2082)  time: 0.1675  data: 0.0001  max mem: 15821
[11:47:10.694348] Test:  [ 50/345]  eta: 0:00:51  loss: 1.2075 (1.2081)  time: 0.1679  data: 0.0001  max mem: 15821
[11:47:12.379758] Test:  [ 60/345]  eta: 0:00:49  loss: 1.2087 (1.2081)  time: 0.1683  data: 0.0001  max mem: 15821
[11:47:14.068594] Test:  [ 70/345]  eta: 0:00:47  loss: 1.2091 (1.2082)  time: 0.1687  data: 0.0001  max mem: 15821
[11:47:15.760293] Test:  [ 80/345]  eta: 0:00:45  loss: 1.2080 (1.2082)  time: 0.1690  data: 0.0001  max mem: 15821
[11:47:17.455363] Test:  [ 90/345]  eta: 0:00:43  loss: 1.2081 (1.2083)  time: 0.1693  data: 0.0001  max mem: 15821
[11:47:19.154500] Test:  [100/345]  eta: 0:00:41  loss: 1.2076 (1.2080)  time: 0.1696  data: 0.0001  max mem: 15821
[11:47:20.857065] Test:  [110/345]  eta: 0:00:40  loss: 1.2059 (1.2080)  time: 0.1700  data: 0.0001  max mem: 15821
[11:47:22.563278] Test:  [120/345]  eta: 0:00:38  loss: 1.2076 (1.2081)  time: 0.1704  data: 0.0001  max mem: 15821
[11:47:24.273602] Test:  [130/345]  eta: 0:00:36  loss: 1.2087 (1.2081)  time: 0.1708  data: 0.0001  max mem: 15821
[11:47:25.987395] Test:  [140/345]  eta: 0:00:35  loss: 1.2088 (1.2081)  time: 0.1711  data: 0.0001  max mem: 15821
[11:47:27.704818] Test:  [150/345]  eta: 0:00:33  loss: 1.2088 (1.2082)  time: 0.1715  data: 0.0001  max mem: 15821
[11:47:29.426309] Test:  [160/345]  eta: 0:00:31  loss: 1.2070 (1.2081)  time: 0.1719  data: 0.0001  max mem: 15821
[11:47:31.151539] Test:  [170/345]  eta: 0:00:29  loss: 1.2070 (1.2081)  time: 0.1723  data: 0.0001  max mem: 15821
[11:47:32.879705] Test:  [180/345]  eta: 0:00:28  loss: 1.2097 (1.2082)  time: 0.1726  data: 0.0001  max mem: 15821
[11:47:34.611148] Test:  [190/345]  eta: 0:00:26  loss: 1.2094 (1.2082)  time: 0.1729  data: 0.0001  max mem: 15821
[11:47:36.346889] Test:  [200/345]  eta: 0:00:24  loss: 1.2082 (1.2082)  time: 0.1733  data: 0.0001  max mem: 15821
[11:47:38.472356] Test:  [210/345]  eta: 0:00:23  loss: 1.2078 (1.2082)  time: 0.1930  data: 0.0001  max mem: 15821
[11:47:40.225691] Test:  [220/345]  eta: 0:00:21  loss: 1.2078 (1.2081)  time: 0.1939  data: 0.0001  max mem: 15821
[11:47:42.109144] Test:  [230/345]  eta: 0:00:20  loss: 1.2079 (1.2081)  time: 0.1818  data: 0.0001  max mem: 15821
[11:47:43.860906] Test:  [240/345]  eta: 0:00:18  loss: 1.2069 (1.2081)  time: 0.1817  data: 0.0001  max mem: 15821
[11:47:45.843876] Test:  [250/345]  eta: 0:00:16  loss: 1.2070 (1.2081)  time: 0.1867  data: 0.0001  max mem: 15821
[11:47:47.843949] Test:  [260/345]  eta: 0:00:14  loss: 1.2088 (1.2081)  time: 0.1991  data: 0.0001  max mem: 15821
[11:47:49.757129] Test:  [270/345]  eta: 0:00:13  loss: 1.2073 (1.2081)  time: 0.1956  data: 0.0001  max mem: 15821
[11:47:51.546420] Test:  [280/345]  eta: 0:00:11  loss: 1.2075 (1.2081)  time: 0.1851  data: 0.0001  max mem: 15821
[11:47:53.500790] Test:  [290/345]  eta: 0:00:09  loss: 1.2087 (1.2082)  time: 0.1871  data: 0.0001  max mem: 15821
[11:47:55.525782] Test:  [300/345]  eta: 0:00:08  loss: 1.2095 (1.2082)  time: 0.1989  data: 0.0001  max mem: 15821
[11:47:57.521908] Test:  [310/345]  eta: 0:00:06  loss: 1.2092 (1.2082)  time: 0.2010  data: 0.0001  max mem: 15821
[11:47:59.546640] Test:  [320/345]  eta: 0:00:04  loss: 1.2082 (1.2083)  time: 0.2010  data: 0.0001  max mem: 15821
[11:48:01.564230] Test:  [330/345]  eta: 0:00:02  loss: 1.2082 (1.2083)  time: 0.2020  data: 0.0001  max mem: 15821
[11:48:03.371296] Test:  [340/345]  eta: 0:00:00  loss: 1.2071 (1.2083)  time: 0.1912  data: 0.0001  max mem: 15821
[11:48:04.406766] Test:  [344/345]  eta: 0:00:00  loss: 1.2071 (1.2083)  time: 0.2064  data: 0.0001  max mem: 15821
[11:48:04.471301] Test: Total time: 0:01:02 (0.1815 s / it)
[11:48:14.351361] Test:  [ 0/57]  eta: 0:00:25  loss: 1.2008 (1.2008)  time: 0.4460  data: 0.2832  max mem: 15821
[11:48:16.003899] Test:  [10/57]  eta: 0:00:08  loss: 1.2117 (1.2087)  time: 0.1907  data: 0.0258  max mem: 15821
[11:48:17.660151] Test:  [20/57]  eta: 0:00:06  loss: 1.2112 (1.2072)  time: 0.1654  data: 0.0001  max mem: 15821
[11:48:19.320893] Test:  [30/57]  eta: 0:00:04  loss: 1.1873 (1.1982)  time: 0.1658  data: 0.0001  max mem: 15821
[11:48:20.986108] Test:  [40/57]  eta: 0:00:02  loss: 1.1787 (1.1929)  time: 0.1662  data: 0.0001  max mem: 15821
[11:48:22.654570] Test:  [50/57]  eta: 0:00:01  loss: 1.1826 (1.1913)  time: 0.1666  data: 0.0001  max mem: 15821
[11:48:24.332879] Test:  [56/57]  eta: 0:00:00  loss: 1.1848 (1.1917)  time: 0.2006  data: 0.0001  max mem: 15821
[11:48:24.401146] Test: Total time: 0:00:10 (0.1841 s / it)
[11:48:26.073693] Dice score of the network on the train images: 0.000000, val images: 0.000000
[11:48:26.073938] saving best_dice_model_0 @ epoch 0
[11:48:26.973689] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:48:27.864890] Epoch: [1]  [  0/345]  eta: 0:05:07  lr: 0.000006  loss: 1.1532 (1.1532)  time: 0.8901  data: 0.2898  max mem: 15821
[11:48:39.848473] Epoch: [1]  [ 20/345]  eta: 0:03:19  lr: 0.000007  loss: 1.1178 (1.1213)  time: 0.5991  data: 0.0001  max mem: 15821
[11:48:51.851216] Epoch: [1]  [ 40/345]  eta: 0:03:05  lr: 0.000007  loss: 1.0842 (1.1034)  time: 0.6001  data: 0.0001  max mem: 15821
[11:49:03.868074] Epoch: [1]  [ 60/345]  eta: 0:02:52  lr: 0.000007  loss: 1.0638 (1.0900)  time: 0.6008  data: 0.0001  max mem: 15821
[11:49:15.905894] Epoch: [1]  [ 80/345]  eta: 0:02:40  lr: 0.000008  loss: 1.0332 (1.0767)  time: 0.6018  data: 0.0001  max mem: 15821
[11:49:27.967332] Epoch: [1]  [100/345]  eta: 0:02:27  lr: 0.000008  loss: 1.0238 (1.0661)  time: 0.6030  data: 0.0001  max mem: 15821
[11:49:40.038670] Epoch: [1]  [120/345]  eta: 0:02:15  lr: 0.000008  loss: 1.0022 (1.0554)  time: 0.6035  data: 0.0001  max mem: 15821
[11:49:52.117968] Epoch: [1]  [140/345]  eta: 0:02:03  lr: 0.000009  loss: 0.9855 (1.0452)  time: 0.6039  data: 0.0001  max mem: 15821
[11:50:04.191325] Epoch: [1]  [160/345]  eta: 0:01:51  lr: 0.000009  loss: 0.9612 (1.0345)  time: 0.6036  data: 0.0001  max mem: 15821
[11:50:16.261886] Epoch: [1]  [180/345]  eta: 0:01:39  lr: 0.000010  loss: 0.9444 (1.0243)  time: 0.6035  data: 0.0001  max mem: 15821
[11:50:28.338747] Epoch: [1]  [200/345]  eta: 0:01:27  lr: 0.000010  loss: 0.9199 (1.0140)  time: 0.6038  data: 0.0001  max mem: 15821
[11:50:40.402894] Epoch: [1]  [220/345]  eta: 0:01:15  lr: 0.000010  loss: 0.9059 (1.0047)  time: 0.6032  data: 0.0001  max mem: 15821
[11:50:52.467809] Epoch: [1]  [240/345]  eta: 0:01:03  lr: 0.000011  loss: 0.9016 (0.9958)  time: 0.6032  data: 0.0001  max mem: 15821
[11:51:04.527593] Epoch: [1]  [260/345]  eta: 0:00:51  lr: 0.000011  loss: 0.8752 (0.9871)  time: 0.6029  data: 0.0001  max mem: 15821
[11:51:16.576906] Epoch: [1]  [280/345]  eta: 0:00:39  lr: 0.000011  loss: 0.8773 (0.9792)  time: 0.6024  data: 0.0001  max mem: 15821
[11:51:28.636742] Epoch: [1]  [300/345]  eta: 0:00:27  lr: 0.000012  loss: 0.8619 (0.9714)  time: 0.6029  data: 0.0001  max mem: 15821
[11:51:40.693998] Epoch: [1]  [320/345]  eta: 0:00:15  lr: 0.000012  loss: 0.8404 (0.9633)  time: 0.6028  data: 0.0001  max mem: 15821
[11:51:52.754258] Epoch: [1]  [340/345]  eta: 0:00:03  lr: 0.000012  loss: 0.8263 (0.9555)  time: 0.6030  data: 0.0001  max mem: 15821
[11:51:55.164790] Epoch: [1]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 0.8260 (0.9540)  time: 0.6028  data: 0.0001  max mem: 15821
[11:51:55.244646] Epoch: [1] Total time: 0:03:28 (0.6037 s / it)
[11:51:55.245245] Averaged stats: lr: 0.000012  loss: 0.8260 (0.9540)
[11:51:55.767024] Test:  [  0/345]  eta: 0:02:58  loss: 0.8642 (0.8642)  time: 0.5164  data: 0.3517  max mem: 15821
[11:51:57.435579] Test:  [ 10/345]  eta: 0:01:06  loss: 0.8642 (0.8577)  time: 0.1985  data: 0.0321  max mem: 15821
[11:51:59.108824] Test:  [ 20/345]  eta: 0:00:59  loss: 0.8451 (0.8458)  time: 0.1670  data: 0.0001  max mem: 15821
[11:52:00.783703] Test:  [ 30/345]  eta: 0:00:56  loss: 0.8381 (0.8457)  time: 0.1673  data: 0.0001  max mem: 15821
[11:52:02.462048] Test:  [ 40/345]  eta: 0:00:53  loss: 0.8362 (0.8431)  time: 0.1676  data: 0.0001  max mem: 15821
[11:52:04.144599] Test:  [ 50/345]  eta: 0:00:51  loss: 0.8280 (0.8420)  time: 0.1680  data: 0.0001  max mem: 15821
[11:52:05.829630] Test:  [ 60/345]  eta: 0:00:49  loss: 0.8346 (0.8402)  time: 0.1683  data: 0.0001  max mem: 15821
[11:52:07.518748] Test:  [ 70/345]  eta: 0:00:47  loss: 0.8423 (0.8396)  time: 0.1686  data: 0.0001  max mem: 15821
[11:52:09.210938] Test:  [ 80/345]  eta: 0:00:45  loss: 0.8439 (0.8409)  time: 0.1690  data: 0.0001  max mem: 15821
[11:52:10.907495] Test:  [ 90/345]  eta: 0:00:43  loss: 0.8426 (0.8400)  time: 0.1694  data: 0.0001  max mem: 15821
[11:52:12.606558] Test:  [100/345]  eta: 0:00:42  loss: 0.8389 (0.8403)  time: 0.1697  data: 0.0001  max mem: 15821
[11:52:14.309570] Test:  [110/345]  eta: 0:00:40  loss: 0.8389 (0.8407)  time: 0.1700  data: 0.0001  max mem: 15821
[11:52:16.013887] Test:  [120/345]  eta: 0:00:38  loss: 0.8512 (0.8422)  time: 0.1703  data: 0.0001  max mem: 15821
[11:52:17.722903] Test:  [130/345]  eta: 0:00:36  loss: 0.8414 (0.8407)  time: 0.1706  data: 0.0001  max mem: 15821
[11:52:19.434678] Test:  [140/345]  eta: 0:00:35  loss: 0.8207 (0.8405)  time: 0.1710  data: 0.0001  max mem: 15821
[11:52:21.150449] Test:  [150/345]  eta: 0:00:33  loss: 0.8377 (0.8411)  time: 0.1713  data: 0.0001  max mem: 15821
[11:52:22.869463] Test:  [160/345]  eta: 0:00:31  loss: 0.8488 (0.8416)  time: 0.1717  data: 0.0001  max mem: 15821
[11:52:24.592836] Test:  [170/345]  eta: 0:00:30  loss: 0.8429 (0.8409)  time: 0.1721  data: 0.0001  max mem: 15821
[11:52:26.320202] Test:  [180/345]  eta: 0:00:28  loss: 0.8321 (0.8409)  time: 0.1725  data: 0.0001  max mem: 15821
[11:52:28.050028] Test:  [190/345]  eta: 0:00:26  loss: 0.8464 (0.8416)  time: 0.1728  data: 0.0001  max mem: 15821
[11:52:29.785332] Test:  [200/345]  eta: 0:00:24  loss: 0.8485 (0.8416)  time: 0.1732  data: 0.0001  max mem: 15821
[11:52:31.522443] Test:  [210/345]  eta: 0:00:23  loss: 0.8485 (0.8420)  time: 0.1736  data: 0.0001  max mem: 15821
[11:52:33.626122] Test:  [220/345]  eta: 0:00:21  loss: 0.8450 (0.8413)  time: 0.1920  data: 0.0001  max mem: 15821
[11:52:35.367203] Test:  [230/345]  eta: 0:00:19  loss: 0.8275 (0.8406)  time: 0.1922  data: 0.0001  max mem: 15821
[11:52:37.282010] Test:  [240/345]  eta: 0:00:18  loss: 0.8362 (0.8407)  time: 0.1827  data: 0.0001  max mem: 15821
[11:52:39.048291] Test:  [250/345]  eta: 0:00:16  loss: 0.8587 (0.8412)  time: 0.1840  data: 0.0001  max mem: 15821
[11:52:41.005300] Test:  [260/345]  eta: 0:00:14  loss: 0.8398 (0.8409)  time: 0.1861  data: 0.0001  max mem: 15821
[11:52:42.788210] Test:  [270/345]  eta: 0:00:13  loss: 0.8389 (0.8409)  time: 0.1869  data: 0.0001  max mem: 15821
[11:52:44.688744] Test:  [280/345]  eta: 0:00:11  loss: 0.8557 (0.8414)  time: 0.1841  data: 0.0001  max mem: 15821
[11:52:46.478245] Test:  [290/345]  eta: 0:00:09  loss: 0.8259 (0.8410)  time: 0.1844  data: 0.0001  max mem: 15821
[11:52:48.419539] Test:  [300/345]  eta: 0:00:07  loss: 0.8238 (0.8414)  time: 0.1865  data: 0.0001  max mem: 15821
[11:52:50.207860] Test:  [310/345]  eta: 0:00:06  loss: 0.8428 (0.8411)  time: 0.1864  data: 0.0001  max mem: 15821
[11:52:52.244948] Test:  [320/345]  eta: 0:00:04  loss: 0.8203 (0.8410)  time: 0.1912  data: 0.0001  max mem: 15821
[11:52:54.025574] Test:  [330/345]  eta: 0:00:02  loss: 0.8254 (0.8406)  time: 0.1908  data: 0.0001  max mem: 15821
[11:52:55.915745] Test:  [340/345]  eta: 0:00:00  loss: 0.8254 (0.8404)  time: 0.1835  data: 0.0001  max mem: 15821
[11:52:56.628063] Test:  [344/345]  eta: 0:00:00  loss: 0.8257 (0.8403)  time: 0.1834  data: 0.0001  max mem: 15821
[11:52:56.699073] Test: Total time: 0:01:01 (0.1781 s / it)
[11:53:06.602609] Test:  [ 0/57]  eta: 0:00:26  loss: 0.9308 (0.9308)  time: 0.4648  data: 0.3022  max mem: 15821
[11:53:08.250211] Test:  [10/57]  eta: 0:00:09  loss: 0.8976 (0.8957)  time: 0.1919  data: 0.0276  max mem: 15821
[11:53:09.905485] Test:  [20/57]  eta: 0:00:06  loss: 0.8577 (0.8864)  time: 0.1651  data: 0.0001  max mem: 15821
[11:53:11.563766] Test:  [30/57]  eta: 0:00:04  loss: 0.7819 (0.8212)  time: 0.1656  data: 0.0001  max mem: 15821
[11:53:13.226706] Test:  [40/57]  eta: 0:00:02  loss: 0.6829 (0.7844)  time: 0.1660  data: 0.0001  max mem: 15821
[11:53:14.893051] Test:  [50/57]  eta: 0:00:01  loss: 0.7034 (0.7752)  time: 0.1664  data: 0.0001  max mem: 15821
[11:53:15.791402] Test:  [56/57]  eta: 0:00:00  loss: 0.7621 (0.7826)  time: 0.1615  data: 0.0000  max mem: 15821
[11:53:15.857511] Test: Total time: 0:00:09 (0.1705 s / it)
[11:53:17.481486] Dice score of the network on the train images: 0.469164, val images: 0.584160
[11:53:17.481715] saving best_prec_model_0 @ epoch 1
[11:53:18.381169] saving best_rec_model_0 @ epoch 1
[11:53:19.343852] saving best_dice_model_0 @ epoch 1
[11:53:20.577835] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:53:21.475972] Epoch: [2]  [  0/345]  eta: 0:05:09  lr: 0.000013  loss: 0.8069 (0.8069)  time: 0.8970  data: 0.2978  max mem: 15821
[11:53:33.450220] Epoch: [2]  [ 20/345]  eta: 0:03:19  lr: 0.000013  loss: 0.8146 (0.8152)  time: 0.5987  data: 0.0001  max mem: 15821
[11:53:45.449916] Epoch: [2]  [ 40/345]  eta: 0:03:05  lr: 0.000013  loss: 0.7819 (0.8023)  time: 0.5999  data: 0.0001  max mem: 15821
[11:53:57.481216] Epoch: [2]  [ 60/345]  eta: 0:02:52  lr: 0.000014  loss: 0.7879 (0.7957)  time: 0.6015  data: 0.0001  max mem: 15821
[11:54:09.537950] Epoch: [2]  [ 80/345]  eta: 0:02:40  lr: 0.000014  loss: 0.7727 (0.7902)  time: 0.6028  data: 0.0001  max mem: 15821
[11:54:21.616544] Epoch: [2]  [100/345]  eta: 0:02:28  lr: 0.000014  loss: 0.7504 (0.7826)  time: 0.6039  data: 0.0001  max mem: 15821
[11:54:33.718946] Epoch: [2]  [120/345]  eta: 0:02:15  lr: 0.000015  loss: 0.7469 (0.7764)  time: 0.6051  data: 0.0001  max mem: 15821
[11:54:45.826680] Epoch: [2]  [140/345]  eta: 0:02:03  lr: 0.000015  loss: 0.7233 (0.7685)  time: 0.6053  data: 0.0001  max mem: 15821
[11:54:57.943940] Epoch: [2]  [160/345]  eta: 0:01:51  lr: 0.000015  loss: 0.7092 (0.7616)  time: 0.6058  data: 0.0001  max mem: 15821
[11:55:10.046681] Epoch: [2]  [180/345]  eta: 0:01:39  lr: 0.000016  loss: 0.6996 (0.7555)  time: 0.6051  data: 0.0001  max mem: 15821
[11:55:22.134165] Epoch: [2]  [200/345]  eta: 0:01:27  lr: 0.000016  loss: 0.6955 (0.7493)  time: 0.6043  data: 0.0001  max mem: 15821
[11:55:34.219647] Epoch: [2]  [220/345]  eta: 0:01:15  lr: 0.000016  loss: 0.6837 (0.7432)  time: 0.6042  data: 0.0001  max mem: 15821
[11:55:46.308844] Epoch: [2]  [240/345]  eta: 0:01:03  lr: 0.000017  loss: 0.6529 (0.7364)  time: 0.6044  data: 0.0001  max mem: 15821
[11:55:58.387492] Epoch: [2]  [260/345]  eta: 0:00:51  lr: 0.000017  loss: 0.6550 (0.7301)  time: 0.6039  data: 0.0001  max mem: 15821
[11:56:10.466145] Epoch: [2]  [280/345]  eta: 0:00:39  lr: 0.000018  loss: 0.6318 (0.7238)  time: 0.6039  data: 0.0001  max mem: 15821
[11:56:22.531228] Epoch: [2]  [300/345]  eta: 0:00:27  lr: 0.000018  loss: 0.6152 (0.7174)  time: 0.6032  data: 0.0001  max mem: 15821
[11:56:34.604755] Epoch: [2]  [320/345]  eta: 0:00:15  lr: 0.000018  loss: 0.6151 (0.7109)  time: 0.6036  data: 0.0001  max mem: 15821
[11:56:46.675617] Epoch: [2]  [340/345]  eta: 0:00:03  lr: 0.000019  loss: 0.6050 (0.7045)  time: 0.6035  data: 0.0001  max mem: 15821
[11:56:49.087471] Epoch: [2]  [344/345]  eta: 0:00:00  lr: 0.000019  loss: 0.6037 (0.7031)  time: 0.6032  data: 0.0001  max mem: 15821
[11:56:49.157382] Epoch: [2] Total time: 0:03:28 (0.6046 s / it)
[11:56:49.157725] Averaged stats: lr: 0.000019  loss: 0.6037 (0.7031)
[11:56:49.700195] Test:  [  0/345]  eta: 0:03:05  loss: 0.6279 (0.6279)  time: 0.5372  data: 0.3727  max mem: 15821
[11:56:51.366728] Test:  [ 10/345]  eta: 0:01:07  loss: 0.5618 (0.5689)  time: 0.2003  data: 0.0340  max mem: 15821
[11:56:53.035864] Test:  [ 20/345]  eta: 0:00:59  loss: 0.5563 (0.5639)  time: 0.1667  data: 0.0001  max mem: 15821
[11:56:54.709964] Test:  [ 30/345]  eta: 0:00:56  loss: 0.5605 (0.5646)  time: 0.1671  data: 0.0001  max mem: 15821
[11:56:56.386504] Test:  [ 40/345]  eta: 0:00:53  loss: 0.5814 (0.5740)  time: 0.1675  data: 0.0001  max mem: 15821
[11:56:58.067281] Test:  [ 50/345]  eta: 0:00:51  loss: 0.5836 (0.5759)  time: 0.1678  data: 0.0001  max mem: 15821
[11:56:59.750784] Test:  [ 60/345]  eta: 0:00:49  loss: 0.5836 (0.5773)  time: 0.1681  data: 0.0001  max mem: 15821
[11:57:01.438944] Test:  [ 70/345]  eta: 0:00:47  loss: 0.5936 (0.5786)  time: 0.1685  data: 0.0001  max mem: 15821
[11:57:03.128619] Test:  [ 80/345]  eta: 0:00:45  loss: 0.5643 (0.5778)  time: 0.1688  data: 0.0001  max mem: 15821
[11:57:04.822704] Test:  [ 90/345]  eta: 0:00:43  loss: 0.5651 (0.5778)  time: 0.1691  data: 0.0001  max mem: 15821
[11:57:06.521113] Test:  [100/345]  eta: 0:00:42  loss: 0.5669 (0.5776)  time: 0.1696  data: 0.0001  max mem: 15821
[11:57:08.221725] Test:  [110/345]  eta: 0:00:40  loss: 0.5674 (0.5769)  time: 0.1699  data: 0.0001  max mem: 15821
[11:57:09.923909] Test:  [120/345]  eta: 0:00:38  loss: 0.5807 (0.5785)  time: 0.1701  data: 0.0001  max mem: 15821
[11:57:11.631742] Test:  [130/345]  eta: 0:00:36  loss: 0.5807 (0.5770)  time: 0.1704  data: 0.0001  max mem: 15821
[11:57:13.342216] Test:  [140/345]  eta: 0:00:35  loss: 0.5608 (0.5776)  time: 0.1709  data: 0.0001  max mem: 15821
[11:57:15.055461] Test:  [150/345]  eta: 0:00:33  loss: 0.5740 (0.5770)  time: 0.1711  data: 0.0001  max mem: 15821
[11:57:16.772789] Test:  [160/345]  eta: 0:00:31  loss: 0.5818 (0.5792)  time: 0.1715  data: 0.0001  max mem: 15821
[11:57:18.494442] Test:  [170/345]  eta: 0:00:30  loss: 0.5818 (0.5789)  time: 0.1719  data: 0.0001  max mem: 15821
[11:57:20.218142] Test:  [180/345]  eta: 0:00:28  loss: 0.5784 (0.5792)  time: 0.1722  data: 0.0001  max mem: 15821
[11:57:21.945638] Test:  [190/345]  eta: 0:00:26  loss: 0.5594 (0.5777)  time: 0.1725  data: 0.0001  max mem: 15821
[11:57:23.674795] Test:  [200/345]  eta: 0:00:24  loss: 0.5594 (0.5788)  time: 0.1728  data: 0.0001  max mem: 15821
[11:57:25.408439] Test:  [210/345]  eta: 0:00:23  loss: 0.5727 (0.5777)  time: 0.1731  data: 0.0001  max mem: 15821
[11:57:27.145183] Test:  [220/345]  eta: 0:00:21  loss: 0.5625 (0.5776)  time: 0.1735  data: 0.0001  max mem: 15821
[11:57:28.886128] Test:  [230/345]  eta: 0:00:19  loss: 0.5718 (0.5777)  time: 0.1738  data: 0.0001  max mem: 15821
[11:57:30.630468] Test:  [240/345]  eta: 0:00:18  loss: 0.5718 (0.5775)  time: 0.1742  data: 0.0001  max mem: 15821
[11:57:32.377795] Test:  [250/345]  eta: 0:00:16  loss: 0.5683 (0.5771)  time: 0.1745  data: 0.0001  max mem: 15821
[11:57:34.128525] Test:  [260/345]  eta: 0:00:14  loss: 0.5576 (0.5767)  time: 0.1748  data: 0.0001  max mem: 15821
[11:57:35.882009] Test:  [270/345]  eta: 0:00:12  loss: 0.5710 (0.5767)  time: 0.1752  data: 0.0001  max mem: 15821
[11:57:37.639919] Test:  [280/345]  eta: 0:00:11  loss: 0.5803 (0.5766)  time: 0.1755  data: 0.0001  max mem: 15821
[11:57:39.401436] Test:  [290/345]  eta: 0:00:09  loss: 0.5743 (0.5760)  time: 0.1759  data: 0.0001  max mem: 15821
[11:57:41.166522] Test:  [300/345]  eta: 0:00:07  loss: 0.5743 (0.5761)  time: 0.1763  data: 0.0001  max mem: 15821
[11:57:42.935964] Test:  [310/345]  eta: 0:00:06  loss: 0.5730 (0.5758)  time: 0.1767  data: 0.0001  max mem: 15821
[11:57:44.708578] Test:  [320/345]  eta: 0:00:04  loss: 0.5708 (0.5753)  time: 0.1770  data: 0.0001  max mem: 15821
[11:57:46.484647] Test:  [330/345]  eta: 0:00:02  loss: 0.5428 (0.5746)  time: 0.1774  data: 0.0001  max mem: 15821
[11:57:48.264918] Test:  [340/345]  eta: 0:00:00  loss: 0.5624 (0.5748)  time: 0.1778  data: 0.0001  max mem: 15821
[11:57:48.978400] Test:  [344/345]  eta: 0:00:00  loss: 0.5644 (0.5750)  time: 0.1779  data: 0.0001  max mem: 15821
[11:57:49.057348] Test: Total time: 0:00:59 (0.1736 s / it)
[11:57:58.920454] Test:  [ 0/57]  eta: 0:00:25  loss: 0.6849 (0.6849)  time: 0.4532  data: 0.2908  max mem: 15821
[11:58:00.567696] Test:  [10/57]  eta: 0:00:08  loss: 0.6270 (0.6319)  time: 0.1909  data: 0.0265  max mem: 15821
[11:58:02.223179] Test:  [20/57]  eta: 0:00:06  loss: 0.5745 (0.6058)  time: 0.1651  data: 0.0001  max mem: 15821
[11:58:03.883026] Test:  [30/57]  eta: 0:00:04  loss: 0.4791 (0.5484)  time: 0.1657  data: 0.0001  max mem: 15821
[11:58:05.544699] Test:  [40/57]  eta: 0:00:02  loss: 0.4239 (0.5173)  time: 0.1660  data: 0.0001  max mem: 15821
[11:58:07.210459] Test:  [50/57]  eta: 0:00:01  loss: 0.4239 (0.5132)  time: 0.1663  data: 0.0001  max mem: 15821
[11:58:08.109502] Test:  [56/57]  eta: 0:00:00  loss: 0.5037 (0.5179)  time: 0.1614  data: 0.0000  max mem: 15821
[11:58:08.178443] Test: Total time: 0:00:09 (0.1704 s / it)
[11:58:09.830037] Dice score of the network on the train images: 0.649467, val images: 0.712362
[11:58:09.830249] saving best_prec_model_0 @ epoch 2
[11:58:11.078836] saving best_dice_model_0 @ epoch 2
[11:58:12.244740] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:58:13.141509] Epoch: [3]  [  0/345]  eta: 0:05:08  lr: 0.000019  loss: 0.6133 (0.6133)  time: 0.8955  data: 0.2966  max mem: 15821
[11:58:25.140317] Epoch: [3]  [ 20/345]  eta: 0:03:19  lr: 0.000019  loss: 0.5725 (0.5823)  time: 0.5999  data: 0.0001  max mem: 15821
[11:58:37.161855] Epoch: [3]  [ 40/345]  eta: 0:03:05  lr: 0.000019  loss: 0.5732 (0.5785)  time: 0.6010  data: 0.0001  max mem: 15821
[11:58:49.188246] Epoch: [3]  [ 60/345]  eta: 0:02:52  lr: 0.000020  loss: 0.5585 (0.5730)  time: 0.6013  data: 0.0001  max mem: 15821
[11:59:01.229827] Epoch: [3]  [ 80/345]  eta: 0:02:40  lr: 0.000020  loss: 0.5614 (0.5690)  time: 0.6020  data: 0.0001  max mem: 15821
[11:59:13.298183] Epoch: [3]  [100/345]  eta: 0:02:28  lr: 0.000021  loss: 0.5556 (0.5669)  time: 0.6034  data: 0.0001  max mem: 15821
[11:59:25.386822] Epoch: [3]  [120/345]  eta: 0:02:15  lr: 0.000021  loss: 0.5228 (0.5608)  time: 0.6044  data: 0.0001  max mem: 15821
[11:59:37.489402] Epoch: [3]  [140/345]  eta: 0:02:03  lr: 0.000021  loss: 0.5347 (0.5571)  time: 0.6051  data: 0.0001  max mem: 15821
[11:59:49.591553] Epoch: [3]  [160/345]  eta: 0:01:51  lr: 0.000022  loss: 0.5324 (0.5538)  time: 0.6051  data: 0.0001  max mem: 15821
[12:00:01.693736] Epoch: [3]  [180/345]  eta: 0:01:39  lr: 0.000022  loss: 0.5064 (0.5489)  time: 0.6051  data: 0.0001  max mem: 15821
[12:00:13.819551] Epoch: [3]  [200/345]  eta: 0:01:27  lr: 0.000022  loss: 0.4998 (0.5440)  time: 0.6062  data: 0.0001  max mem: 15821
[12:00:25.919727] Epoch: [3]  [220/345]  eta: 0:01:15  lr: 0.000023  loss: 0.5055 (0.5404)  time: 0.6050  data: 0.0001  max mem: 15821
[12:00:38.018771] Epoch: [3]  [240/345]  eta: 0:01:03  lr: 0.000023  loss: 0.4914 (0.5361)  time: 0.6049  data: 0.0001  max mem: 15821
[12:00:50.099972] Epoch: [3]  [260/345]  eta: 0:00:51  lr: 0.000023  loss: 0.4738 (0.5321)  time: 0.6040  data: 0.0001  max mem: 15821
[12:01:02.271253] Epoch: [3]  [280/345]  eta: 0:00:39  lr: 0.000024  loss: 0.4715 (0.5282)  time: 0.6085  data: 0.0001  max mem: 15821
[12:01:14.351035] Epoch: [3]  [300/345]  eta: 0:00:27  lr: 0.000024  loss: 0.4534 (0.5236)  time: 0.6040  data: 0.0001  max mem: 15821
[12:01:26.436092] Epoch: [3]  [320/345]  eta: 0:00:15  lr: 0.000025  loss: 0.4631 (0.5193)  time: 0.6042  data: 0.0001  max mem: 15821
[12:01:38.514165] Epoch: [3]  [340/345]  eta: 0:00:03  lr: 0.000025  loss: 0.4444 (0.5164)  time: 0.6039  data: 0.0001  max mem: 15821
[12:01:40.927211] Epoch: [3]  [344/345]  eta: 0:00:00  lr: 0.000025  loss: 0.4414 (0.5156)  time: 0.6037  data: 0.0001  max mem: 15821
[12:01:41.007439] Epoch: [3] Total time: 0:03:28 (0.6051 s / it)
[12:01:41.007646] Averaged stats: lr: 0.000025  loss: 0.4414 (0.5156)
[12:01:41.489925] Test:  [  0/345]  eta: 0:02:44  loss: 0.4781 (0.4781)  time: 0.4767  data: 0.3127  max mem: 15821
[12:01:43.157285] Test:  [ 10/345]  eta: 0:01:05  loss: 0.4337 (0.4362)  time: 0.1948  data: 0.0285  max mem: 15821
[12:01:44.828390] Test:  [ 20/345]  eta: 0:00:59  loss: 0.4313 (0.4306)  time: 0.1668  data: 0.0001  max mem: 15821
[12:01:46.502287] Test:  [ 30/345]  eta: 0:00:55  loss: 0.4448 (0.4386)  time: 0.1672  data: 0.0001  max mem: 15821
[12:01:48.178282] Test:  [ 40/345]  eta: 0:00:53  loss: 0.4448 (0.4386)  time: 0.1674  data: 0.0001  max mem: 15821
[12:01:49.857757] Test:  [ 50/345]  eta: 0:00:51  loss: 0.4447 (0.4391)  time: 0.1677  data: 0.0001  max mem: 15821
[12:01:51.540964] Test:  [ 60/345]  eta: 0:00:49  loss: 0.4410 (0.4362)  time: 0.1681  data: 0.0001  max mem: 15821
[12:01:53.227680] Test:  [ 70/345]  eta: 0:00:47  loss: 0.4251 (0.4354)  time: 0.1684  data: 0.0001  max mem: 15821
[12:01:54.917078] Test:  [ 80/345]  eta: 0:00:45  loss: 0.4384 (0.4359)  time: 0.1687  data: 0.0001  max mem: 15821
[12:01:56.610951] Test:  [ 90/345]  eta: 0:00:43  loss: 0.4309 (0.4354)  time: 0.1691  data: 0.0001  max mem: 15821
[12:01:58.308212] Test:  [100/345]  eta: 0:00:41  loss: 0.4240 (0.4351)  time: 0.1695  data: 0.0001  max mem: 15821
[12:02:00.007881] Test:  [110/345]  eta: 0:00:40  loss: 0.4300 (0.4351)  time: 0.1698  data: 0.0001  max mem: 15821
[12:02:01.712050] Test:  [120/345]  eta: 0:00:38  loss: 0.4300 (0.4354)  time: 0.1701  data: 0.0001  max mem: 15821
[12:02:03.417341] Test:  [130/345]  eta: 0:00:36  loss: 0.4401 (0.4350)  time: 0.1704  data: 0.0001  max mem: 15821
[12:02:05.127617] Test:  [140/345]  eta: 0:00:35  loss: 0.4505 (0.4380)  time: 0.1707  data: 0.0001  max mem: 15821
[12:02:06.840824] Test:  [150/345]  eta: 0:00:33  loss: 0.4514 (0.4378)  time: 0.1711  data: 0.0001  max mem: 15821
[12:02:08.558977] Test:  [160/345]  eta: 0:00:31  loss: 0.4377 (0.4375)  time: 0.1715  data: 0.0001  max mem: 15821
[12:02:10.280099] Test:  [170/345]  eta: 0:00:29  loss: 0.4295 (0.4368)  time: 0.1719  data: 0.0001  max mem: 15821
[12:02:12.004794] Test:  [180/345]  eta: 0:00:28  loss: 0.4205 (0.4361)  time: 0.1722  data: 0.0001  max mem: 15821
[12:02:13.733898] Test:  [190/345]  eta: 0:00:26  loss: 0.4239 (0.4371)  time: 0.1726  data: 0.0001  max mem: 15821
[12:02:15.465732] Test:  [200/345]  eta: 0:00:24  loss: 0.4419 (0.4363)  time: 0.1730  data: 0.0001  max mem: 15821
[12:02:17.200321] Test:  [210/345]  eta: 0:00:23  loss: 0.4327 (0.4366)  time: 0.1733  data: 0.0001  max mem: 15821
[12:02:18.938434] Test:  [220/345]  eta: 0:00:21  loss: 0.4394 (0.4369)  time: 0.1736  data: 0.0001  max mem: 15821
[12:02:20.679394] Test:  [230/345]  eta: 0:00:19  loss: 0.4394 (0.4372)  time: 0.1739  data: 0.0001  max mem: 15821
[12:02:22.424093] Test:  [240/345]  eta: 0:00:18  loss: 0.4483 (0.4380)  time: 0.1742  data: 0.0001  max mem: 15821
[12:02:24.171459] Test:  [250/345]  eta: 0:00:16  loss: 0.4449 (0.4381)  time: 0.1745  data: 0.0001  max mem: 15821
[12:02:25.924052] Test:  [260/345]  eta: 0:00:14  loss: 0.4449 (0.4388)  time: 0.1749  data: 0.0001  max mem: 15821
[12:02:27.680717] Test:  [270/345]  eta: 0:00:12  loss: 0.4434 (0.4389)  time: 0.1754  data: 0.0001  max mem: 15821
[12:02:29.438813] Test:  [280/345]  eta: 0:00:11  loss: 0.4226 (0.4383)  time: 0.1757  data: 0.0001  max mem: 15821
[12:02:31.201725] Test:  [290/345]  eta: 0:00:09  loss: 0.4413 (0.4389)  time: 0.1760  data: 0.0001  max mem: 15821
[12:02:32.967433] Test:  [300/345]  eta: 0:00:07  loss: 0.4413 (0.4388)  time: 0.1764  data: 0.0001  max mem: 15821
[12:02:34.736447] Test:  [310/345]  eta: 0:00:06  loss: 0.4301 (0.4386)  time: 0.1767  data: 0.0001  max mem: 15821
[12:02:36.510326] Test:  [320/345]  eta: 0:00:04  loss: 0.4310 (0.4384)  time: 0.1771  data: 0.0001  max mem: 15821
[12:02:38.288135] Test:  [330/345]  eta: 0:00:02  loss: 0.4352 (0.4389)  time: 0.1775  data: 0.0001  max mem: 15821
[12:02:40.069800] Test:  [340/345]  eta: 0:00:00  loss: 0.4293 (0.4387)  time: 0.1779  data: 0.0001  max mem: 15821
[12:02:40.783298] Test:  [344/345]  eta: 0:00:00  loss: 0.4352 (0.4387)  time: 0.1780  data: 0.0001  max mem: 15821
[12:02:40.853891] Test: Total time: 0:00:59 (0.1735 s / it)
[12:02:50.730360] Test:  [ 0/57]  eta: 0:00:29  loss: 0.5249 (0.5249)  time: 0.5094  data: 0.3469  max mem: 15821
[12:02:52.378420] Test:  [10/57]  eta: 0:00:09  loss: 0.4746 (0.4824)  time: 0.1961  data: 0.0316  max mem: 15821
[12:02:54.033606] Test:  [20/57]  eta: 0:00:06  loss: 0.4502 (0.4595)  time: 0.1651  data: 0.0001  max mem: 15821
[12:02:55.692283] Test:  [30/57]  eta: 0:00:04  loss: 0.3508 (0.4159)  time: 0.1656  data: 0.0001  max mem: 15821
[12:02:57.354359] Test:  [40/57]  eta: 0:00:02  loss: 0.3269 (0.3908)  time: 0.1660  data: 0.0001  max mem: 15821
[12:02:59.020388] Test:  [50/57]  eta: 0:00:01  loss: 0.3252 (0.3879)  time: 0.1663  data: 0.0001  max mem: 15821
[12:02:59.919139] Test:  [56/57]  eta: 0:00:00  loss: 0.3800 (0.3948)  time: 0.1614  data: 0.0000  max mem: 15821
[12:02:59.984172] Test: Total time: 0:00:09 (0.1713 s / it)
[12:03:01.613261] Dice score of the network on the train images: 0.691104, val images: 0.750570
[12:03:01.613492] saving best_prec_model_0 @ epoch 3
[12:03:02.866484] saving best_rec_model_0 @ epoch 3
[12:03:04.011736] saving best_dice_model_0 @ epoch 3
[12:03:05.139885] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:03:06.037061] Epoch: [4]  [  0/345]  eta: 0:05:09  lr: 0.000025  loss: 0.4098 (0.4098)  time: 0.8963  data: 0.2974  max mem: 15821
[12:03:18.122380] Epoch: [4]  [ 20/345]  eta: 0:03:20  lr: 0.000025  loss: 0.4553 (0.4556)  time: 0.6042  data: 0.0001  max mem: 15821
[12:03:30.121417] Epoch: [4]  [ 40/345]  eta: 0:03:05  lr: 0.000026  loss: 0.4314 (0.4485)  time: 0.5999  data: 0.0001  max mem: 15821
[12:03:42.156097] Epoch: [4]  [ 60/345]  eta: 0:02:52  lr: 0.000026  loss: 0.4193 (0.4427)  time: 0.6017  data: 0.0001  max mem: 15821
[12:03:54.209118] Epoch: [4]  [ 80/345]  eta: 0:02:40  lr: 0.000026  loss: 0.4199 (0.4393)  time: 0.6026  data: 0.0001  max mem: 15821
[12:04:06.287062] Epoch: [4]  [100/345]  eta: 0:02:28  lr: 0.000027  loss: 0.4208 (0.4366)  time: 0.6039  data: 0.0001  max mem: 15821
[12:04:18.391833] Epoch: [4]  [120/345]  eta: 0:02:16  lr: 0.000027  loss: 0.4165 (0.4331)  time: 0.6052  data: 0.0001  max mem: 15821
[12:04:30.507435] Epoch: [4]  [140/345]  eta: 0:02:04  lr: 0.000028  loss: 0.4123 (0.4315)  time: 0.6057  data: 0.0001  max mem: 15821
[12:04:42.630009] Epoch: [4]  [160/345]  eta: 0:01:52  lr: 0.000028  loss: 0.4190 (0.4296)  time: 0.6061  data: 0.0001  max mem: 15821
[12:04:54.749323] Epoch: [4]  [180/345]  eta: 0:01:39  lr: 0.000028  loss: 0.4158 (0.4281)  time: 0.6059  data: 0.0001  max mem: 15821
[12:05:06.843858] Epoch: [4]  [200/345]  eta: 0:01:27  lr: 0.000029  loss: 0.3962 (0.4250)  time: 0.6047  data: 0.0001  max mem: 15821
[12:05:18.939610] Epoch: [4]  [220/345]  eta: 0:01:15  lr: 0.000029  loss: 0.4032 (0.4239)  time: 0.6047  data: 0.0001  max mem: 15821
[12:05:31.039833] Epoch: [4]  [240/345]  eta: 0:01:03  lr: 0.000029  loss: 0.3989 (0.4224)  time: 0.6050  data: 0.0001  max mem: 15821
[12:05:43.203140] Epoch: [4]  [260/345]  eta: 0:00:51  lr: 0.000030  loss: 0.4071 (0.4210)  time: 0.6081  data: 0.0001  max mem: 15821
[12:05:55.286838] Epoch: [4]  [280/345]  eta: 0:00:39  lr: 0.000030  loss: 0.3848 (0.4176)  time: 0.6041  data: 0.0001  max mem: 15821
[12:06:07.381265] Epoch: [4]  [300/345]  eta: 0:00:27  lr: 0.000030  loss: 0.3979 (0.4171)  time: 0.6047  data: 0.0001  max mem: 15821

[12:06:19.483748] Epoch: [4]  [320/345]  eta: 0:00:15  lr: 0.000031  loss: 0.3887 (0.4155)  time: 0.6051  data: 0.0001  max mem: 15821
[12:06:31.581413] Epoch: [4]  [340/345]  eta: 0:00:03  lr: 0.000031  loss: 0.3551 (0.4125)  time: 0.6048  data: 0.0001  max mem: 15821
[12:06:34.003530] Epoch: [4]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 0.3570 (0.4121)  time: 0.6049  data: 0.0001  max mem: 15821
[12:06:34.071463] Epoch: [4] Total time: 0:03:28 (0.6056 s / it)
[12:06:34.072215] Averaged stats: lr: 0.000031  loss: 0.3570 (0.4121)
[12:06:34.619760] Test:  [  0/345]  eta: 0:03:07  loss: 0.3677 (0.3677)  time: 0.5425  data: 0.3778  max mem: 15821
[12:06:36.286791] Test:  [ 10/345]  eta: 0:01:07  loss: 0.3693 (0.3783)  time: 0.2008  data: 0.0344  max mem: 15821
[12:06:37.956977] Test:  [ 20/345]  eta: 0:01:00  loss: 0.3693 (0.3711)  time: 0.1668  data: 0.0001  max mem: 15821
[12:06:39.629547] Test:  [ 30/345]  eta: 0:00:56  loss: 0.3775 (0.3724)  time: 0.1671  data: 0.0001  max mem: 15821
[12:06:41.305869] Test:  [ 40/345]  eta: 0:00:53  loss: 0.3683 (0.3730)  time: 0.1674  data: 0.0001  max mem: 15821
[12:06:42.985281] Test:  [ 50/345]  eta: 0:00:51  loss: 0.3665 (0.3727)  time: 0.1677  data: 0.0001  max mem: 15821
[12:06:44.667536] Test:  [ 60/345]  eta: 0:00:49  loss: 0.3619 (0.3718)  time: 0.1680  data: 0.0001  max mem: 15821
[12:06:46.354747] Test:  [ 70/345]  eta: 0:00:47  loss: 0.3486 (0.3693)  time: 0.1684  data: 0.0001  max mem: 15821
[12:06:48.044436] Test:  [ 80/345]  eta: 0:00:45  loss: 0.3617 (0.3718)  time: 0.1688  data: 0.0001  max mem: 15821
[12:06:49.737970] Test:  [ 90/345]  eta: 0:00:43  loss: 0.3912 (0.3745)  time: 0.1691  data: 0.0001  max mem: 15821
[12:06:51.434234] Test:  [100/345]  eta: 0:00:42  loss: 0.3912 (0.3756)  time: 0.1694  data: 0.0001  max mem: 15821
[12:06:53.135146] Test:  [110/345]  eta: 0:00:40  loss: 0.3815 (0.3764)  time: 0.1698  data: 0.0001  max mem: 15821
[12:06:54.838289] Test:  [120/345]  eta: 0:00:38  loss: 0.3658 (0.3754)  time: 0.1701  data: 0.0001  max mem: 15821
[12:06:56.545130] Test:  [130/345]  eta: 0:00:36  loss: 0.3460 (0.3723)  time: 0.1704  data: 0.0001  max mem: 15821
[12:06:58.255437] Test:  [140/345]  eta: 0:00:35  loss: 0.3460 (0.3718)  time: 0.1708  data: 0.0001  max mem: 15821
[12:06:59.968044] Test:  [150/345]  eta: 0:00:33  loss: 0.3595 (0.3715)  time: 0.1711  data: 0.0001  max mem: 15821
[12:07:01.685542] Test:  [160/345]  eta: 0:00:31  loss: 0.3619 (0.3719)  time: 0.1714  data: 0.0001  max mem: 15821
[12:07:03.406403] Test:  [170/345]  eta: 0:00:30  loss: 0.3627 (0.3718)  time: 0.1719  data: 0.0001  max mem: 15821
[12:07:05.130917] Test:  [180/345]  eta: 0:00:28  loss: 0.3611 (0.3710)  time: 0.1722  data: 0.0001  max mem: 15821
[12:07:06.859135] Test:  [190/345]  eta: 0:00:26  loss: 0.3662 (0.3717)  time: 0.1726  data: 0.0001  max mem: 15821
[12:07:08.590169] Test:  [200/345]  eta: 0:00:24  loss: 0.3860 (0.3728)  time: 0.1729  data: 0.0001  max mem: 15821
[12:07:10.323121] Test:  [210/345]  eta: 0:00:23  loss: 0.3822 (0.3731)  time: 0.1731  data: 0.0001  max mem: 15821
[12:07:12.060253] Test:  [220/345]  eta: 0:00:21  loss: 0.3903 (0.3737)  time: 0.1734  data: 0.0001  max mem: 15821
[12:07:13.801509] Test:  [230/345]  eta: 0:00:19  loss: 0.3662 (0.3735)  time: 0.1739  data: 0.0001  max mem: 15821
[12:07:15.546331] Test:  [240/345]  eta: 0:00:18  loss: 0.3591 (0.3728)  time: 0.1742  data: 0.0001  max mem: 15821
[12:07:17.295640] Test:  [250/345]  eta: 0:00:16  loss: 0.3478 (0.3719)  time: 0.1746  data: 0.0001  max mem: 15821
[12:07:19.048821] Test:  [260/345]  eta: 0:00:14  loss: 0.3478 (0.3711)  time: 0.1751  data: 0.0001  max mem: 15821
[12:07:20.804402] Test:  [270/345]  eta: 0:00:12  loss: 0.3540 (0.3706)  time: 0.1754  data: 0.0001  max mem: 15821
[12:07:22.562001] Test:  [280/345]  eta: 0:00:11  loss: 0.3651 (0.3707)  time: 0.1756  data: 0.0001  max mem: 15821
[12:07:24.325041] Test:  [290/345]  eta: 0:00:09  loss: 0.3511 (0.3703)  time: 0.1760  data: 0.0001  max mem: 15821
[12:07:26.090338] Test:  [300/345]  eta: 0:00:07  loss: 0.3608 (0.3703)  time: 0.1764  data: 0.0001  max mem: 15821
[12:07:27.859740] Test:  [310/345]  eta: 0:00:06  loss: 0.3669 (0.3701)  time: 0.1767  data: 0.0001  max mem: 15821
[12:07:29.634153] Test:  [320/345]  eta: 0:00:04  loss: 0.3702 (0.3705)  time: 0.1771  data: 0.0001  max mem: 15821
[12:07:31.411572] Test:  [330/345]  eta: 0:00:02  loss: 0.3784 (0.3707)  time: 0.1775  data: 0.0001  max mem: 15821
[12:07:33.191718] Test:  [340/345]  eta: 0:00:00  loss: 0.3518 (0.3707)  time: 0.1778  data: 0.0001  max mem: 15821
[12:07:33.904185] Test:  [344/345]  eta: 0:00:00  loss: 0.3481 (0.3705)  time: 0.1779  data: 0.0001  max mem: 15821
[12:07:33.975485] Test: Total time: 0:00:59 (0.1736 s / it)
[12:07:43.912356] Test:  [ 0/57]  eta: 0:00:27  loss: 0.4566 (0.4566)  time: 0.4753  data: 0.3128  max mem: 15821
[12:07:45.558977] Test:  [10/57]  eta: 0:00:09  loss: 0.4144 (0.4217)  time: 0.1928  data: 0.0285  max mem: 15821
[12:07:47.213154] Test:  [20/57]  eta: 0:00:06  loss: 0.3975 (0.4030)  time: 0.1650  data: 0.0001  max mem: 15821
[12:07:48.871565] Test:  [30/57]  eta: 0:00:04  loss: 0.2976 (0.3604)  time: 0.1656  data: 0.0001  max mem: 15821
[12:07:50.533439] Test:  [40/57]  eta: 0:00:02  loss: 0.2687 (0.3398)  time: 0.1660  data: 0.0001  max mem: 15821
[12:07:52.199891] Test:  [50/57]  eta: 0:00:01  loss: 0.2733 (0.3363)  time: 0.1664  data: 0.0001  max mem: 15821
[12:07:53.098428] Test:  [56/57]  eta: 0:00:00  loss: 0.3160 (0.3409)  time: 0.1614  data: 0.0000  max mem: 15821
[12:07:53.157383] Test: Total time: 0:00:09 (0.1705 s / it)
[12:07:54.795963] Dice score of the network on the train images: 0.709452, val images: 0.774891
[12:07:54.796200] saving best_prec_model_0 @ epoch 4
[12:07:56.037532] saving best_rec_model_0 @ epoch 4
[12:07:57.154208] saving best_dice_model_0 @ epoch 4
[12:07:58.289682] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:07:59.223983] Epoch: [5]  [  0/345]  eta: 0:05:21  lr: 0.000031  loss: 0.3501 (0.3501)  time: 0.9331  data: 0.3334  max mem: 15821
[12:08:11.215914] Epoch: [5]  [ 20/345]  eta: 0:03:20  lr: 0.000032  loss: 0.3679 (0.3753)  time: 0.5995  data: 0.0001  max mem: 15821
[12:08:23.232879] Epoch: [5]  [ 40/345]  eta: 0:03:05  lr: 0.000032  loss: 0.3709 (0.3727)  time: 0.6008  data: 0.0001  max mem: 15821
[12:08:35.266572] Epoch: [5]  [ 60/345]  eta: 0:02:52  lr: 0.000032  loss: 0.3850 (0.3767)  time: 0.6016  data: 0.0001  max mem: 15821
[12:08:47.334937] Epoch: [5]  [ 80/345]  eta: 0:02:40  lr: 0.000033  loss: 0.3468 (0.3708)  time: 0.6034  data: 0.0001  max mem: 15821
[12:08:59.429802] Epoch: [5]  [100/345]  eta: 0:02:28  lr: 0.000033  loss: 0.3696 (0.3724)  time: 0.6047  data: 0.0001  max mem: 15821
[12:09:11.551096] Epoch: [5]  [120/345]  eta: 0:02:16  lr: 0.000033  loss: 0.3696 (0.3726)  time: 0.6060  data: 0.0001  max mem: 15821
[12:09:23.680806] Epoch: [5]  [140/345]  eta: 0:02:04  lr: 0.000034  loss: 0.3535 (0.3706)  time: 0.6064  data: 0.0001  max mem: 15821
[12:09:35.816663] Epoch: [5]  [160/345]  eta: 0:01:52  lr: 0.000034  loss: 0.3549 (0.3694)  time: 0.6067  data: 0.0001  max mem: 15821
[12:09:47.938672] Epoch: [5]  [180/345]  eta: 0:01:39  lr: 0.000035  loss: 0.3493 (0.3688)  time: 0.6061  data: 0.0001  max mem: 15821
[12:10:00.052490] Epoch: [5]  [200/345]  eta: 0:01:27  lr: 0.000035  loss: 0.3394 (0.3667)  time: 0.6056  data: 0.0001  max mem: 15821
[12:10:12.158362] Epoch: [5]  [220/345]  eta: 0:01:15  lr: 0.000035  loss: 0.3543 (0.3661)  time: 0.6052  data: 0.0001  max mem: 15821
[12:10:24.269941] Epoch: [5]  [240/345]  eta: 0:01:03  lr: 0.000036  loss: 0.3543 (0.3657)  time: 0.6055  data: 0.0001  max mem: 15821
[12:10:36.376295] Epoch: [5]  [260/345]  eta: 0:00:51  lr: 0.000036  loss: 0.3350 (0.3644)  time: 0.6053  data: 0.0001  max mem: 15821
[12:10:48.468082] Epoch: [5]  [280/345]  eta: 0:00:39  lr: 0.000036  loss: 0.3519 (0.3643)  time: 0.6045  data: 0.0001  max mem: 15821
[12:11:00.564938] Epoch: [5]  [300/345]  eta: 0:00:27  lr: 0.000037  loss: 0.3360 (0.3629)  time: 0.6048  data: 0.0001  max mem: 15821
[12:11:12.662751] Epoch: [5]  [320/345]  eta: 0:00:15  lr: 0.000037  loss: 0.3240 (0.3610)  time: 0.6048  data: 0.0001  max mem: 15821
[12:11:24.755854] Epoch: [5]  [340/345]  eta: 0:00:03  lr: 0.000037  loss: 0.3500 (0.3608)  time: 0.6046  data: 0.0001  max mem: 15821
[12:11:27.169769] Epoch: [5]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 0.3442 (0.3605)  time: 0.6044  data: 0.0001  max mem: 15821
[12:11:27.237420] Epoch: [5] Total time: 0:03:28 (0.6056 s / it)
[12:11:27.238127] Averaged stats: lr: 0.000037  loss: 0.3442 (0.3605)
[12:11:27.728868] Test:  [  0/345]  eta: 0:02:47  loss: 0.2929 (0.2929)  time: 0.4854  data: 0.3205  max mem: 15821
[12:11:29.397374] Test:  [ 10/345]  eta: 0:01:05  loss: 0.3550 (0.3467)  time: 0.1957  data: 0.0292  max mem: 15821
[12:11:31.067175] Test:  [ 20/345]  eta: 0:00:59  loss: 0.3220 (0.3378)  time: 0.1668  data: 0.0001  max mem: 15821
[12:11:32.740616] Test:  [ 30/345]  eta: 0:00:55  loss: 0.3238 (0.3381)  time: 0.1671  data: 0.0001  max mem: 15821
[12:11:34.416538] Test:  [ 40/345]  eta: 0:00:53  loss: 0.3319 (0.3350)  time: 0.1674  data: 0.0001  max mem: 15821
[12:11:36.097861] Test:  [ 50/345]  eta: 0:00:51  loss: 0.3319 (0.3370)  time: 0.1678  data: 0.0001  max mem: 15821
[12:11:37.780190] Test:  [ 60/345]  eta: 0:00:49  loss: 0.3308 (0.3356)  time: 0.1681  data: 0.0001  max mem: 15821
[12:11:39.467373] Test:  [ 70/345]  eta: 0:00:47  loss: 0.3191 (0.3341)  time: 0.1684  data: 0.0001  max mem: 15821
[12:11:41.157490] Test:  [ 80/345]  eta: 0:00:45  loss: 0.3315 (0.3341)  time: 0.1688  data: 0.0001  max mem: 15821
[12:11:42.851105] Test:  [ 90/345]  eta: 0:00:43  loss: 0.3315 (0.3340)  time: 0.1691  data: 0.0001  max mem: 15821
[12:11:44.547459] Test:  [100/345]  eta: 0:00:41  loss: 0.3261 (0.3323)  time: 0.1694  data: 0.0001  max mem: 15821
[12:11:46.248805] Test:  [110/345]  eta: 0:00:40  loss: 0.3197 (0.3318)  time: 0.1698  data: 0.0001  max mem: 15821
[12:11:47.952227] Test:  [120/345]  eta: 0:00:38  loss: 0.3366 (0.3334)  time: 0.1702  data: 0.0001  max mem: 15821
[12:11:49.659800] Test:  [130/345]  eta: 0:00:36  loss: 0.3419 (0.3345)  time: 0.1705  data: 0.0001  max mem: 15821
[12:11:51.371541] Test:  [140/345]  eta: 0:00:35  loss: 0.3300 (0.3337)  time: 0.1709  data: 0.0001  max mem: 15821
[12:11:53.085106] Test:  [150/345]  eta: 0:00:33  loss: 0.3216 (0.3338)  time: 0.1712  data: 0.0001  max mem: 15821
[12:11:54.803009] Test:  [160/345]  eta: 0:00:31  loss: 0.3337 (0.3345)  time: 0.1715  data: 0.0001  max mem: 15821
[12:11:56.524291] Test:  [170/345]  eta: 0:00:29  loss: 0.3331 (0.3341)  time: 0.1719  data: 0.0001  max mem: 15821
[12:11:58.248612] Test:  [180/345]  eta: 0:00:28  loss: 0.3306 (0.3343)  time: 0.1722  data: 0.0001  max mem: 15821
[12:11:59.975870] Test:  [190/345]  eta: 0:00:26  loss: 0.3306 (0.3333)  time: 0.1725  data: 0.0001  max mem: 15821
[12:12:01.706067] Test:  [200/345]  eta: 0:00:24  loss: 0.3225 (0.3335)  time: 0.1728  data: 0.0001  max mem: 15821
[12:12:03.440114] Test:  [210/345]  eta: 0:00:23  loss: 0.3240 (0.3334)  time: 0.1731  data: 0.0001  max mem: 15821
[12:12:05.177797] Test:  [220/345]  eta: 0:00:21  loss: 0.3240 (0.3336)  time: 0.1735  data: 0.0001  max mem: 15821
[12:12:06.919122] Test:  [230/345]  eta: 0:00:19  loss: 0.3202 (0.3336)  time: 0.1739  data: 0.0001  max mem: 15821
[12:12:08.664761] Test:  [240/345]  eta: 0:00:18  loss: 0.3352 (0.3340)  time: 0.1742  data: 0.0001  max mem: 15821
[12:12:10.413449] Test:  [250/345]  eta: 0:00:16  loss: 0.3357 (0.3344)  time: 0.1746  data: 0.0001  max mem: 15821
[12:12:12.164833] Test:  [260/345]  eta: 0:00:14  loss: 0.3342 (0.3345)  time: 0.1749  data: 0.0001  max mem: 15821
[12:12:13.920265] Test:  [270/345]  eta: 0:00:12  loss: 0.3342 (0.3348)  time: 0.1753  data: 0.0001  max mem: 15821
[12:12:15.678821] Test:  [280/345]  eta: 0:00:11  loss: 0.3306 (0.3343)  time: 0.1756  data: 0.0001  max mem: 15821
[12:12:17.441071] Test:  [290/345]  eta: 0:00:09  loss: 0.3135 (0.3338)  time: 0.1760  data: 0.0001  max mem: 15821
[12:12:19.207133] Test:  [300/345]  eta: 0:00:07  loss: 0.3298 (0.3345)  time: 0.1764  data: 0.0001  max mem: 15821
[12:12:20.976537] Test:  [310/345]  eta: 0:00:06  loss: 0.3405 (0.3341)  time: 0.1767  data: 0.0001  max mem: 15821
[12:12:22.749770] Test:  [320/345]  eta: 0:00:04  loss: 0.3299 (0.3339)  time: 0.1771  data: 0.0001  max mem: 15821
[12:12:24.525945] Test:  [330/345]  eta: 0:00:02  loss: 0.3174 (0.3336)  time: 0.1774  data: 0.0001  max mem: 15821
[12:12:26.305920] Test:  [340/345]  eta: 0:00:00  loss: 0.3199 (0.3338)  time: 0.1778  data: 0.0001  max mem: 15821
[12:12:27.019151] Test:  [344/345]  eta: 0:00:00  loss: 0.3323 (0.3340)  time: 0.1779  data: 0.0001  max mem: 15821
[12:12:27.086535] Test: Total time: 0:00:59 (0.1735 s / it)
[12:12:36.965304] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4610 (0.4610)  time: 0.4464  data: 0.2841  max mem: 15821
[12:12:38.613586] Test:  [10/57]  eta: 0:00:08  loss: 0.4040 (0.4153)  time: 0.1903  data: 0.0259  max mem: 15821
[12:12:40.269110] Test:  [20/57]  eta: 0:00:06  loss: 0.3804 (0.3940)  time: 0.1651  data: 0.0001  max mem: 15821
[12:12:41.929426] Test:  [30/57]  eta: 0:00:04  loss: 0.2848 (0.3502)  time: 0.1657  data: 0.0001  max mem: 15821
[12:12:43.593845] Test:  [40/57]  eta: 0:00:02  loss: 0.2676 (0.3301)  time: 0.1662  data: 0.0001  max mem: 15821
[12:12:45.261127] Test:  [50/57]  eta: 0:00:01  loss: 0.2768 (0.3289)  time: 0.1665  data: 0.0001  max mem: 15821
[12:12:46.159451] Test:  [56/57]  eta: 0:00:00  loss: 0.3177 (0.3337)  time: 0.1616  data: 0.0001  max mem: 15821
[12:12:46.226509] Test: Total time: 0:00:09 (0.1703 s / it)
[12:12:47.884949] Dice score of the network on the train images: 0.737612, val images: 0.780837
[12:12:47.885163] saving best_prec_model_0 @ epoch 5
[12:12:49.139639] saving best_dice_model_0 @ epoch 5
[12:12:50.289968] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:12:51.193828] Epoch: [6]  [  0/345]  eta: 0:05:11  lr: 0.000038  loss: 0.3167 (0.3167)  time: 0.9026  data: 0.3029  max mem: 15821
[12:13:03.190633] Epoch: [6]  [ 20/345]  eta: 0:03:19  lr: 0.000038  loss: 0.3370 (0.3351)  time: 0.5998  data: 0.0001  max mem: 15821
[12:13:15.189524] Epoch: [6]  [ 40/345]  eta: 0:03:05  lr: 0.000038  loss: 0.3341 (0.3340)  time: 0.5999  data: 0.0001  max mem: 15821
[12:13:27.203077] Epoch: [6]  [ 60/345]  eta: 0:02:52  lr: 0.000039  loss: 0.3348 (0.3345)  time: 0.6006  data: 0.0001  max mem: 15821
[12:13:39.231059] Epoch: [6]  [ 80/345]  eta: 0:02:40  lr: 0.000039  loss: 0.3434 (0.3352)  time: 0.6014  data: 0.0001  max mem: 15821
[12:13:51.316445] Epoch: [6]  [100/345]  eta: 0:02:28  lr: 0.000039  loss: 0.3405 (0.3366)  time: 0.6042  data: 0.0001  max mem: 15821
[12:14:03.422182] Epoch: [6]  [120/345]  eta: 0:02:15  lr: 0.000040  loss: 0.3409 (0.3379)  time: 0.6052  data: 0.0001  max mem: 15821
[12:14:15.544480] Epoch: [6]  [140/345]  eta: 0:02:03  lr: 0.000040  loss: 0.3254 (0.3359)  time: 0.6061  data: 0.0001  max mem: 15821
[12:14:27.671079] Epoch: [6]  [160/345]  eta: 0:01:51  lr: 0.000040  loss: 0.3182 (0.3348)  time: 0.6063  data: 0.0001  max mem: 15821
[12:14:39.797735] Epoch: [6]  [180/345]  eta: 0:01:39  lr: 0.000041  loss: 0.3289 (0.3350)  time: 0.6063  data: 0.0001  max mem: 15821
[12:14:51.914087] Epoch: [6]  [200/345]  eta: 0:01:27  lr: 0.000041  loss: 0.3183 (0.3344)  time: 0.6058  data: 0.0001  max mem: 15821
[12:15:04.020726] Epoch: [6]  [220/345]  eta: 0:01:15  lr: 0.000041  loss: 0.3145 (0.3330)  time: 0.6053  data: 0.0001  max mem: 15821

[12:15:16.129511] Epoch: [6]  [240/345]  eta: 0:01:03  lr: 0.000042  loss: 0.3190 (0.3322)  time: 0.6054  data: 0.0001  max mem: 15821
[12:15:28.236642] Epoch: [6]  [260/345]  eta: 0:00:51  lr: 0.000042  loss: 0.3328 (0.3322)  time: 0.6053  data: 0.0001  max mem: 15821
[12:15:40.345204] Epoch: [6]  [280/345]  eta: 0:00:39  lr: 0.000043  loss: 0.3123 (0.3309)  time: 0.6054  data: 0.0001  max mem: 15821
[12:15:52.438837] Epoch: [6]  [300/345]  eta: 0:00:27  lr: 0.000043  loss: 0.3261 (0.3296)  time: 0.6046  data: 0.0001  max mem: 15821
[12:16:04.533426] Epoch: [6]  [320/345]  eta: 0:00:15  lr: 0.000043  loss: 0.3272 (0.3291)  time: 0.6047  data: 0.0001  max mem: 15821
[12:16:16.627013] Epoch: [6]  [340/345]  eta: 0:00:03  lr: 0.000044  loss: 0.3365 (0.3293)  time: 0.6046  data: 0.0001  max mem: 15821
[12:16:19.045009] Epoch: [6]  [344/345]  eta: 0:00:00  lr: 0.000044  loss: 0.3279 (0.3292)  time: 0.6046  data: 0.0001  max mem: 15821
[12:16:19.115378] Epoch: [6] Total time: 0:03:28 (0.6053 s / it)
[12:16:19.115591] Averaged stats: lr: 0.000044  loss: 0.3279 (0.3292)
[12:16:19.599538] Test:  [  0/345]  eta: 0:02:44  loss: 0.3371 (0.3371)  time: 0.4774  data: 0.3132  max mem: 15821
[12:16:21.267206] Test:  [ 10/345]  eta: 0:01:05  loss: 0.3274 (0.3292)  time: 0.1949  data: 0.0286  max mem: 15821
[12:16:22.937576] Test:  [ 20/345]  eta: 0:00:59  loss: 0.3181 (0.3256)  time: 0.1668  data: 0.0001  max mem: 15821
[12:16:24.610526] Test:  [ 30/345]  eta: 0:00:55  loss: 0.3275 (0.3305)  time: 0.1671  data: 0.0001  max mem: 15821
[12:16:26.288596] Test:  [ 40/345]  eta: 0:00:53  loss: 0.3179 (0.3290)  time: 0.1675  data: 0.0001  max mem: 15821
[12:16:27.968717] Test:  [ 50/345]  eta: 0:00:51  loss: 0.3215 (0.3312)  time: 0.1679  data: 0.0001  max mem: 15821
[12:16:29.652202] Test:  [ 60/345]  eta: 0:00:49  loss: 0.3333 (0.3309)  time: 0.1681  data: 0.0001  max mem: 15821
[12:16:31.340864] Test:  [ 70/345]  eta: 0:00:47  loss: 0.3187 (0.3291)  time: 0.1685  data: 0.0001  max mem: 15821
[12:16:33.031272] Test:  [ 80/345]  eta: 0:00:45  loss: 0.3203 (0.3296)  time: 0.1689  data: 0.0001  max mem: 15821
[12:16:34.726089] Test:  [ 90/345]  eta: 0:00:43  loss: 0.3329 (0.3302)  time: 0.1692  data: 0.0001  max mem: 15821
[12:16:36.423372] Test:  [100/345]  eta: 0:00:41  loss: 0.3312 (0.3306)  time: 0.1695  data: 0.0001  max mem: 15821
[12:16:38.125069] Test:  [110/345]  eta: 0:00:40  loss: 0.3367 (0.3312)  time: 0.1699  data: 0.0001  max mem: 15821
[12:16:39.829090] Test:  [120/345]  eta: 0:00:38  loss: 0.3390 (0.3315)  time: 0.1702  data: 0.0001  max mem: 15821
[12:16:41.537431] Test:  [130/345]  eta: 0:00:36  loss: 0.3349 (0.3337)  time: 0.1706  data: 0.0001  max mem: 15821
[12:16:43.248480] Test:  [140/345]  eta: 0:00:35  loss: 0.3288 (0.3331)  time: 0.1709  data: 0.0001  max mem: 15821
[12:16:44.962635] Test:  [150/345]  eta: 0:00:33  loss: 0.3298 (0.3335)  time: 0.1712  data: 0.0001  max mem: 15821
[12:16:46.680950] Test:  [160/345]  eta: 0:00:31  loss: 0.3298 (0.3329)  time: 0.1716  data: 0.0001  max mem: 15821
[12:16:48.403565] Test:  [170/345]  eta: 0:00:29  loss: 0.3322 (0.3334)  time: 0.1720  data: 0.0001  max mem: 15821
[12:16:50.128494] Test:  [180/345]  eta: 0:00:28  loss: 0.3185 (0.3326)  time: 0.1723  data: 0.0001  max mem: 15821
[12:16:51.858994] Test:  [190/345]  eta: 0:00:26  loss: 0.3185 (0.3326)  time: 0.1727  data: 0.0001  max mem: 15821
[12:16:53.591148] Test:  [200/345]  eta: 0:00:24  loss: 0.3249 (0.3322)  time: 0.1731  data: 0.0001  max mem: 15821
[12:16:55.326039] Test:  [210/345]  eta: 0:00:23  loss: 0.3268 (0.3325)  time: 0.1733  data: 0.0001  max mem: 15821
[12:16:57.065190] Test:  [220/345]  eta: 0:00:21  loss: 0.3372 (0.3331)  time: 0.1736  data: 0.0001  max mem: 15821
[12:16:58.808562] Test:  [230/345]  eta: 0:00:19  loss: 0.3284 (0.3326)  time: 0.1741  data: 0.0001  max mem: 15821
[12:17:00.554020] Test:  [240/345]  eta: 0:00:18  loss: 0.3169 (0.3324)  time: 0.1744  data: 0.0001  max mem: 15821
[12:17:02.304055] Test:  [250/345]  eta: 0:00:16  loss: 0.3169 (0.3320)  time: 0.1747  data: 0.0001  max mem: 15821
[12:17:04.055999] Test:  [260/345]  eta: 0:00:14  loss: 0.3205 (0.3323)  time: 0.1750  data: 0.0001  max mem: 15821
[12:17:05.812759] Test:  [270/345]  eta: 0:00:12  loss: 0.3332 (0.3331)  time: 0.1754  data: 0.0001  max mem: 15821
[12:17:07.571987] Test:  [280/345]  eta: 0:00:11  loss: 0.3264 (0.3328)  time: 0.1757  data: 0.0001  max mem: 15821
[12:17:09.337097] Test:  [290/345]  eta: 0:00:09  loss: 0.3194 (0.3324)  time: 0.1762  data: 0.0001  max mem: 15821
[12:17:11.102995] Test:  [300/345]  eta: 0:00:07  loss: 0.3298 (0.3328)  time: 0.1765  data: 0.0001  max mem: 15821
[12:17:12.874639] Test:  [310/345]  eta: 0:00:06  loss: 0.3196 (0.3322)  time: 0.1768  data: 0.0001  max mem: 15821
[12:17:14.648093] Test:  [320/345]  eta: 0:00:04  loss: 0.3196 (0.3324)  time: 0.1772  data: 0.0001  max mem: 15821
[12:17:16.425583] Test:  [330/345]  eta: 0:00:02  loss: 0.3287 (0.3318)  time: 0.1775  data: 0.0001  max mem: 15821
[12:17:18.206934] Test:  [340/345]  eta: 0:00:00  loss: 0.3259 (0.3318)  time: 0.1779  data: 0.0001  max mem: 15821
[12:17:18.922017] Test:  [344/345]  eta: 0:00:00  loss: 0.3259 (0.3315)  time: 0.1781  data: 0.0001  max mem: 15821
[12:17:18.990432] Test: Total time: 0:00:59 (0.1735 s / it)
[12:17:28.906689] Test:  [ 0/57]  eta: 0:00:27  loss: 0.4788 (0.4788)  time: 0.4741  data: 0.3115  max mem: 15821
[12:17:30.555691] Test:  [10/57]  eta: 0:00:09  loss: 0.4086 (0.4288)  time: 0.1929  data: 0.0284  max mem: 15821
[12:17:32.210626] Test:  [20/57]  eta: 0:00:06  loss: 0.4058 (0.4154)  time: 0.1651  data: 0.0001  max mem: 15821
[12:17:33.870054] Test:  [30/57]  eta: 0:00:04  loss: 0.3057 (0.3729)  time: 0.1657  data: 0.0001  max mem: 15821
[12:17:35.533747] Test:  [40/57]  eta: 0:00:02  loss: 0.2967 (0.3564)  time: 0.1661  data: 0.0001  max mem: 15821
[12:17:37.201579] Test:  [50/57]  eta: 0:00:01  loss: 0.3185 (0.3549)  time: 0.1665  data: 0.0001  max mem: 15821
[12:17:38.100404] Test:  [56/57]  eta: 0:00:00  loss: 0.3327 (0.3574)  time: 0.1616  data: 0.0001  max mem: 15821
[12:17:38.172534] Test: Total time: 0:00:09 (0.1709 s / it)
[12:17:39.787233] Dice score of the network on the train images: 0.752385, val images: 0.766737
[12:17:39.791199] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:17:40.691309] Epoch: [7]  [  0/345]  eta: 0:05:10  lr: 0.000044  loss: 0.3457 (0.3457)  time: 0.8990  data: 0.2962  max mem: 15821
[12:17:52.704426] Epoch: [7]  [ 20/345]  eta: 0:03:19  lr: 0.000044  loss: 0.2986 (0.3077)  time: 0.6006  data: 0.0001  max mem: 15821
[12:18:04.743452] Epoch: [7]  [ 40/345]  eta: 0:03:05  lr: 0.000044  loss: 0.3145 (0.3132)  time: 0.6019  data: 0.0001  max mem: 15821
[12:18:16.795568] Epoch: [7]  [ 60/345]  eta: 0:02:52  lr: 0.000045  loss: 0.3065 (0.3105)  time: 0.6026  data: 0.0001  max mem: 15821
[12:18:28.866272] Epoch: [7]  [ 80/345]  eta: 0:02:40  lr: 0.000045  loss: 0.3144 (0.3112)  time: 0.6035  data: 0.0001  max mem: 15821
[12:18:41.063220] Epoch: [7]  [100/345]  eta: 0:02:28  lr: 0.000046  loss: 0.2932 (0.3081)  time: 0.6098  data: 0.0001  max mem: 15821
[12:18:53.155799] Epoch: [7]  [120/345]  eta: 0:02:16  lr: 0.000046  loss: 0.2960 (0.3073)  time: 0.6046  data: 0.0001  max mem: 15821
[12:19:05.259631] Epoch: [7]  [140/345]  eta: 0:02:04  lr: 0.000046  loss: 0.3024 (0.3072)  time: 0.6051  data: 0.0001  max mem: 15821
[12:19:17.368480] Epoch: [7]  [160/345]  eta: 0:01:52  lr: 0.000047  loss: 0.3007 (0.3068)  time: 0.6054  data: 0.0001  max mem: 15821
[12:19:29.482512] Epoch: [7]  [180/345]  eta: 0:01:39  lr: 0.000047  loss: 0.2952 (0.3059)  time: 0.6057  data: 0.0001  max mem: 15821
[12:19:41.593904] Epoch: [7]  [200/345]  eta: 0:01:27  lr: 0.000047  loss: 0.2800 (0.3050)  time: 0.6055  data: 0.0001  max mem: 15821
[12:19:53.710195] Epoch: [7]  [220/345]  eta: 0:01:15  lr: 0.000048  loss: 0.3025 (0.3050)  time: 0.6058  data: 0.0001  max mem: 15821
[12:20:05.817883] Epoch: [7]  [240/345]  eta: 0:01:03  lr: 0.000048  loss: 0.3078 (0.3053)  time: 0.6053  data: 0.0001  max mem: 15821
[12:20:17.921227] Epoch: [7]  [260/345]  eta: 0:00:51  lr: 0.000048  loss: 0.2894 (0.3045)  time: 0.6051  data: 0.0001  max mem: 15821
[12:20:30.029020] Epoch: [7]  [280/345]  eta: 0:00:39  lr: 0.000049  loss: 0.3208 (0.3050)  time: 0.6053  data: 0.0001  max mem: 15821
[12:20:42.127775] Epoch: [7]  [300/345]  eta: 0:00:27  lr: 0.000049  loss: 0.3125 (0.3050)  time: 0.6049  data: 0.0001  max mem: 15821
[12:20:54.234391] Epoch: [7]  [320/345]  eta: 0:00:15  lr: 0.000050  loss: 0.2921 (0.3043)  time: 0.6053  data: 0.0001  max mem: 15821
[12:21:06.329579] Epoch: [7]  [340/345]  eta: 0:00:03  lr: 0.000050  loss: 0.2889 (0.3037)  time: 0.6047  data: 0.0001  max mem: 15821
[12:21:08.748222] Epoch: [7]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.3071 (0.3038)  time: 0.6047  data: 0.0001  max mem: 15821
[12:21:08.820666] Epoch: [7] Total time: 0:03:29 (0.6059 s / it)
[12:21:08.820947] Averaged stats: lr: 0.000050  loss: 0.3071 (0.3038)
[12:21:09.311885] Test:  [  0/345]  eta: 0:02:46  loss: 0.2985 (0.2985)  time: 0.4840  data: 0.3192  max mem: 15821
[12:21:10.979672] Test:  [ 10/345]  eta: 0:01:05  loss: 0.2792 (0.2805)  time: 0.1955  data: 0.0291  max mem: 15821
[12:21:12.651966] Test:  [ 20/345]  eta: 0:00:59  loss: 0.2792 (0.2885)  time: 0.1669  data: 0.0001  max mem: 15821
[12:21:14.326481] Test:  [ 30/345]  eta: 0:00:55  loss: 0.2748 (0.2844)  time: 0.1673  data: 0.0001  max mem: 15821
[12:21:16.004193] Test:  [ 40/345]  eta: 0:00:53  loss: 0.2718 (0.2844)  time: 0.1676  data: 0.0001  max mem: 15821
[12:21:17.683729] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2715 (0.2814)  time: 0.1678  data: 0.0001  max mem: 15821
[12:21:19.368079] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2850 (0.2832)  time: 0.1681  data: 0.0001  max mem: 15821
[12:21:21.055380] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2730 (0.2825)  time: 0.1685  data: 0.0001  max mem: 15821
[12:21:22.746120] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2664 (0.2813)  time: 0.1688  data: 0.0001  max mem: 15821
[12:21:24.440613] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2835 (0.2822)  time: 0.1692  data: 0.0001  max mem: 15821
[12:21:26.137613] Test:  [100/345]  eta: 0:00:41  loss: 0.2977 (0.2832)  time: 0.1695  data: 0.0001  max mem: 15821
[12:21:27.839790] Test:  [110/345]  eta: 0:00:40  loss: 0.2884 (0.2834)  time: 0.1699  data: 0.0001  max mem: 15821
[12:21:29.543590] Test:  [120/345]  eta: 0:00:38  loss: 0.2911 (0.2851)  time: 0.1702  data: 0.0001  max mem: 15821
[12:21:31.251556] Test:  [130/345]  eta: 0:00:36  loss: 0.2926 (0.2846)  time: 0.1705  data: 0.0001  max mem: 15821
[12:21:32.963417] Test:  [140/345]  eta: 0:00:35  loss: 0.2723 (0.2844)  time: 0.1709  data: 0.0001  max mem: 15821
[12:21:34.679150] Test:  [150/345]  eta: 0:00:33  loss: 0.2733 (0.2843)  time: 0.1713  data: 0.0001  max mem: 15821
[12:21:36.397692] Test:  [160/345]  eta: 0:00:31  loss: 0.2774 (0.2849)  time: 0.1717  data: 0.0001  max mem: 15821
[12:21:38.119655] Test:  [170/345]  eta: 0:00:29  loss: 0.2841 (0.2853)  time: 0.1720  data: 0.0001  max mem: 15821
[12:21:39.844184] Test:  [180/345]  eta: 0:00:28  loss: 0.2872 (0.2859)  time: 0.1723  data: 0.0001  max mem: 15821
[12:21:41.572338] Test:  [190/345]  eta: 0:00:26  loss: 0.2935 (0.2867)  time: 0.1726  data: 0.0001  max mem: 15821
[12:21:43.304272] Test:  [200/345]  eta: 0:00:24  loss: 0.2760 (0.2860)  time: 0.1729  data: 0.0001  max mem: 15821
[12:21:45.037608] Test:  [210/345]  eta: 0:00:23  loss: 0.2760 (0.2858)  time: 0.1732  data: 0.0001  max mem: 15821
[12:21:46.775315] Test:  [220/345]  eta: 0:00:21  loss: 0.2724 (0.2854)  time: 0.1735  data: 0.0001  max mem: 15821
[12:21:48.518029] Test:  [230/345]  eta: 0:00:19  loss: 0.2759 (0.2855)  time: 0.1740  data: 0.0001  max mem: 15821
[12:21:50.264380] Test:  [240/345]  eta: 0:00:18  loss: 0.2887 (0.2864)  time: 0.1744  data: 0.0001  max mem: 15821
[12:21:52.013166] Test:  [250/345]  eta: 0:00:16  loss: 0.2828 (0.2861)  time: 0.1747  data: 0.0001  max mem: 15821
[12:21:53.766151] Test:  [260/345]  eta: 0:00:14  loss: 0.2828 (0.2860)  time: 0.1750  data: 0.0001  max mem: 15821
[12:21:55.522925] Test:  [270/345]  eta: 0:00:12  loss: 0.2737 (0.2856)  time: 0.1754  data: 0.0001  max mem: 15821
[12:21:57.282909] Test:  [280/345]  eta: 0:00:11  loss: 0.2678 (0.2855)  time: 0.1758  data: 0.0001  max mem: 15821
[12:21:59.045851] Test:  [290/345]  eta: 0:00:09  loss: 0.2895 (0.2855)  time: 0.1761  data: 0.0001  max mem: 15821
[12:22:00.811683] Test:  [300/345]  eta: 0:00:07  loss: 0.2844 (0.2853)  time: 0.1764  data: 0.0001  max mem: 15821
[12:22:02.583058] Test:  [310/345]  eta: 0:00:06  loss: 0.2859 (0.2860)  time: 0.1768  data: 0.0001  max mem: 15821
[12:22:04.357442] Test:  [320/345]  eta: 0:00:04  loss: 0.2852 (0.2858)  time: 0.1772  data: 0.0001  max mem: 15821
[12:22:06.135813] Test:  [330/345]  eta: 0:00:02  loss: 0.2730 (0.2859)  time: 0.1776  data: 0.0001  max mem: 15821
[12:22:07.917228] Test:  [340/345]  eta: 0:00:00  loss: 0.2903 (0.2862)  time: 0.1779  data: 0.0001  max mem: 15821
[12:22:08.629888] Test:  [344/345]  eta: 0:00:00  loss: 0.2791 (0.2861)  time: 0.1780  data: 0.0001  max mem: 15821
[12:22:08.694321] Test: Total time: 0:00:59 (0.1735 s / it)
[12:22:18.654595] Test:  [ 0/57]  eta: 0:00:28  loss: 0.4671 (0.4671)  time: 0.4947  data: 0.3324  max mem: 15821
[12:22:20.304206] Test:  [10/57]  eta: 0:00:09  loss: 0.3976 (0.4223)  time: 0.1949  data: 0.0303  max mem: 15821
[12:22:21.958876] Test:  [20/57]  eta: 0:00:06  loss: 0.3973 (0.4131)  time: 0.1651  data: 0.0001  max mem: 15821
[12:22:23.618048] Test:  [30/57]  eta: 0:00:04  loss: 0.3165 (0.3684)  time: 0.1656  data: 0.0001  max mem: 15821
[12:22:25.280952] Test:  [40/57]  eta: 0:00:02  loss: 0.2909 (0.3537)  time: 0.1660  data: 0.0001  max mem: 15821
[12:22:26.948270] Test:  [50/57]  eta: 0:00:01  loss: 0.3161 (0.3555)  time: 0.1665  data: 0.0001  max mem: 15821
[12:22:27.847579] Test:  [56/57]  eta: 0:00:00  loss: 0.3328 (0.3594)  time: 0.1616  data: 0.0000  max mem: 15821
[12:22:27.904972] Test: Total time: 0:00:09 (0.1710 s / it)
[12:22:29.536599] Dice score of the network on the train images: 0.785355, val images: 0.766972
[12:22:29.536826] saving best_prec_model_0 @ epoch 7
[12:22:30.772420] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:22:31.667466] Epoch: [8]  [  0/345]  eta: 0:05:08  lr: 0.000050  loss: 0.2915 (0.2915)  time: 0.8939  data: 0.2929  max mem: 15821
[12:22:43.681457] Epoch: [8]  [ 20/345]  eta: 0:03:19  lr: 0.000050  loss: 0.2820 (0.2900)  time: 0.6006  data: 0.0001  max mem: 15821
[12:22:55.703327] Epoch: [8]  [ 40/345]  eta: 0:03:05  lr: 0.000051  loss: 0.2793 (0.2865)  time: 0.6010  data: 0.0001  max mem: 15821
[12:23:07.752709] Epoch: [8]  [ 60/345]  eta: 0:02:52  lr: 0.000051  loss: 0.2853 (0.2882)  time: 0.6024  data: 0.0001  max mem: 15821
[12:23:19.806707] Epoch: [8]  [ 80/345]  eta: 0:02:40  lr: 0.000051  loss: 0.2717 (0.2855)  time: 0.6027  data: 0.0001  max mem: 15821
[12:23:31.885256] Epoch: [8]  [100/345]  eta: 0:02:28  lr: 0.000052  loss: 0.2980 (0.2884)  time: 0.6039  data: 0.0001  max mem: 15821
[12:23:43.987579] Epoch: [8]  [120/345]  eta: 0:02:16  lr: 0.000052  loss: 0.2912 (0.2882)  time: 0.6051  data: 0.0001  max mem: 15821
[12:23:56.088577] Epoch: [8]  [140/345]  eta: 0:02:04  lr: 0.000053  loss: 0.2701 (0.2872)  time: 0.6050  data: 0.0001  max mem: 15821
[12:24:08.306542] Epoch: [8]  [160/345]  eta: 0:01:52  lr: 0.000053  loss: 0.2737 (0.2859)  time: 0.6109  data: 0.0001  max mem: 15821
[12:24:20.412827] Epoch: [8]  [180/345]  eta: 0:01:39  lr: 0.000053  loss: 0.2625 (0.2846)  time: 0.6053  data: 0.0001  max mem: 15821
[12:24:32.512182] Epoch: [8]  [200/345]  eta: 0:01:27  lr: 0.000054  loss: 0.2657 (0.2834)  time: 0.6049  data: 0.0001  max mem: 15821
[12:24:44.612890] Epoch: [8]  [220/345]  eta: 0:01:15  lr: 0.000054  loss: 0.2747 (0.2829)  time: 0.6050  data: 0.0001  max mem: 15821
[12:24:56.706685] Epoch: [8]  [240/345]  eta: 0:01:03  lr: 0.000054  loss: 0.2703 (0.2818)  time: 0.6047  data: 0.0001  max mem: 15821
[12:25:08.807158] Epoch: [8]  [260/345]  eta: 0:00:51  lr: 0.000055  loss: 0.2828 (0.2825)  time: 0.6050  data: 0.0001  max mem: 15821
[12:25:20.907184] Epoch: [8]  [280/345]  eta: 0:00:39  lr: 0.000055  loss: 0.2899 (0.2839)  time: 0.6050  data: 0.0001  max mem: 15821
[12:25:32.990966] Epoch: [8]  [300/345]  eta: 0:00:27  lr: 0.000055  loss: 0.2822 (0.2845)  time: 0.6042  data: 0.0001  max mem: 15821
[12:25:45.077763] Epoch: [8]  [320/345]  eta: 0:00:15  lr: 0.000056  loss: 0.2619 (0.2836)  time: 0.6043  data: 0.0001  max mem: 15821
[12:25:57.154873] Epoch: [8]  [340/345]  eta: 0:00:03  lr: 0.000056  loss: 0.2701 (0.2838)  time: 0.6038  data: 0.0001  max mem: 15821
[12:25:59.569539] Epoch: [8]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.2614 (0.2835)  time: 0.6037  data: 0.0001  max mem: 15821
[12:25:59.647796] Epoch: [8] Total time: 0:03:28 (0.6054 s / it)
[12:25:59.648206] Averaged stats: lr: 0.000056  loss: 0.2614 (0.2835)
[12:26:00.128897] Test:  [  0/345]  eta: 0:02:44  loss: 0.2957 (0.2957)  time: 0.4757  data: 0.3113  max mem: 15821
[12:26:01.797060] Test:  [ 10/345]  eta: 0:01:05  loss: 0.2676 (0.2610)  time: 0.1948  data: 0.0284  max mem: 15821
[12:26:03.468105] Test:  [ 20/345]  eta: 0:00:59  loss: 0.2592 (0.2641)  time: 0.1669  data: 0.0001  max mem: 15821
[12:26:05.142348] Test:  [ 30/345]  eta: 0:00:55  loss: 0.2609 (0.2646)  time: 0.1672  data: 0.0001  max mem: 15821
[12:26:06.820019] Test:  [ 40/345]  eta: 0:00:53  loss: 0.2735 (0.2683)  time: 0.1675  data: 0.0001  max mem: 15821
[12:26:08.501489] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2768 (0.2682)  time: 0.1679  data: 0.0001  max mem: 15821
[12:26:10.186292] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2679 (0.2676)  time: 0.1682  data: 0.0001  max mem: 15821
[12:26:11.874196] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2616 (0.2677)  time: 0.1686  data: 0.0001  max mem: 15821
[12:26:13.566777] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2609 (0.2674)  time: 0.1690  data: 0.0001  max mem: 15821
[12:26:15.261954] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2695 (0.2683)  time: 0.1693  data: 0.0001  max mem: 15821
[12:26:16.960782] Test:  [100/345]  eta: 0:00:41  loss: 0.2787 (0.2711)  time: 0.1696  data: 0.0001  max mem: 15821
[12:26:18.662331] Test:  [110/345]  eta: 0:00:40  loss: 0.2813 (0.2727)  time: 0.1700  data: 0.0001  max mem: 15821
[12:26:20.368119] Test:  [120/345]  eta: 0:00:38  loss: 0.2744 (0.2723)  time: 0.1703  data: 0.0001  max mem: 15821
[12:26:22.076188] Test:  [130/345]  eta: 0:00:36  loss: 0.2708 (0.2712)  time: 0.1706  data: 0.0001  max mem: 15821
[12:26:23.787999] Test:  [140/345]  eta: 0:00:35  loss: 0.2593 (0.2701)  time: 0.1709  data: 0.0001  max mem: 15821
[12:26:25.502048] Test:  [150/345]  eta: 0:00:33  loss: 0.2593 (0.2705)  time: 0.1712  data: 0.0001  max mem: 15821
[12:26:27.220321] Test:  [160/345]  eta: 0:00:31  loss: 0.2602 (0.2704)  time: 0.1716  data: 0.0001  max mem: 15821
[12:26:28.942597] Test:  [170/345]  eta: 0:00:29  loss: 0.2705 (0.2702)  time: 0.1720  data: 0.0001  max mem: 15821
[12:26:30.667251] Test:  [180/345]  eta: 0:00:28  loss: 0.2695 (0.2701)  time: 0.1723  data: 0.0001  max mem: 15821
[12:26:32.394999] Test:  [190/345]  eta: 0:00:26  loss: 0.2773 (0.2708)  time: 0.1726  data: 0.0001  max mem: 15821
[12:26:34.126976] Test:  [200/345]  eta: 0:00:24  loss: 0.2803 (0.2709)  time: 0.1729  data: 0.0001  max mem: 15821
[12:26:35.861855] Test:  [210/345]  eta: 0:00:23  loss: 0.2720 (0.2713)  time: 0.1733  data: 0.0001  max mem: 15821
[12:26:37.600452] Test:  [220/345]  eta: 0:00:21  loss: 0.2694 (0.2713)  time: 0.1736  data: 0.0001  max mem: 15821
[12:26:39.342918] Test:  [230/345]  eta: 0:00:19  loss: 0.2686 (0.2714)  time: 0.1740  data: 0.0001  max mem: 15821
[12:26:41.089262] Test:  [240/345]  eta: 0:00:18  loss: 0.2686 (0.2712)  time: 0.1744  data: 0.0001  max mem: 15821
[12:26:42.838008] Test:  [250/345]  eta: 0:00:16  loss: 0.2675 (0.2715)  time: 0.1747  data: 0.0001  max mem: 15821
[12:26:44.591607] Test:  [260/345]  eta: 0:00:14  loss: 0.2684 (0.2720)  time: 0.1750  data: 0.0001  max mem: 15821
[12:26:46.347271] Test:  [270/345]  eta: 0:00:12  loss: 0.2657 (0.2720)  time: 0.1754  data: 0.0001  max mem: 15821
[12:26:48.106655] Test:  [280/345]  eta: 0:00:11  loss: 0.2764 (0.2722)  time: 0.1757  data: 0.0001  max mem: 15821
[12:26:49.868749] Test:  [290/345]  eta: 0:00:09  loss: 0.2790 (0.2720)  time: 0.1760  data: 0.0001  max mem: 15821
[12:26:51.633596] Test:  [300/345]  eta: 0:00:07  loss: 0.2790 (0.2722)  time: 0.1763  data: 0.0001  max mem: 15821
[12:26:53.403809] Test:  [310/345]  eta: 0:00:06  loss: 0.2734 (0.2718)  time: 0.1767  data: 0.0001  max mem: 15821
[12:26:55.177665] Test:  [320/345]  eta: 0:00:04  loss: 0.2673 (0.2718)  time: 0.1771  data: 0.0001  max mem: 15821
[12:26:56.956931] Test:  [330/345]  eta: 0:00:02  loss: 0.2693 (0.2717)  time: 0.1776  data: 0.0001  max mem: 15821
[12:26:58.739028] Test:  [340/345]  eta: 0:00:00  loss: 0.2678 (0.2717)  time: 0.1780  data: 0.0001  max mem: 15821
[12:26:59.452811] Test:  [344/345]  eta: 0:00:00  loss: 0.2767 (0.2718)  time: 0.1781  data: 0.0001  max mem: 15821
[12:26:59.530603] Test: Total time: 0:00:59 (0.1736 s / it)
[12:27:09.474421] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4467 (0.4467)  time: 0.4496  data: 0.2868  max mem: 15821
[12:27:11.124218] Test:  [10/57]  eta: 0:00:08  loss: 0.4432 (0.4310)  time: 0.1908  data: 0.0261  max mem: 15821
[12:27:12.780076] Test:  [20/57]  eta: 0:00:06  loss: 0.3763 (0.4042)  time: 0.1652  data: 0.0001  max mem: 15821
[12:27:14.440274] Test:  [30/57]  eta: 0:00:04  loss: 0.2732 (0.3513)  time: 0.1657  data: 0.0001  max mem: 15821
[12:27:16.102888] Test:  [40/57]  eta: 0:00:02  loss: 0.2503 (0.3280)  time: 0.1661  data: 0.0001  max mem: 15821
[12:27:17.769704] Test:  [50/57]  eta: 0:00:01  loss: 0.2781 (0.3299)  time: 0.1664  data: 0.0001  max mem: 15821
[12:27:18.668859] Test:  [56/57]  eta: 0:00:00  loss: 0.2969 (0.3362)  time: 0.1615  data: 0.0000  max mem: 15821
[12:27:18.745807] Test: Total time: 0:00:09 (0.1706 s / it)
[12:27:20.390980] Dice score of the network on the train images: 0.776447, val images: 0.790273
[12:27:20.391214] saving best_dice_model_0 @ epoch 8
[12:27:21.565398] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:27:22.453608] Epoch: [9]  [  0/345]  eta: 0:05:06  lr: 0.000056  loss: 0.2829 (0.2829)  time: 0.8873  data: 0.2878  max mem: 15821
[12:27:34.443204] Epoch: [9]  [ 20/345]  eta: 0:03:19  lr: 0.000057  loss: 0.2654 (0.2669)  time: 0.5994  data: 0.0001  max mem: 15821
[12:27:46.443347] Epoch: [9]  [ 40/345]  eta: 0:03:05  lr: 0.000057  loss: 0.2652 (0.2646)  time: 0.6000  data: 0.0001  max mem: 15821
[12:27:58.460861] Epoch: [9]  [ 60/345]  eta: 0:02:52  lr: 0.000057  loss: 0.2594 (0.2649)  time: 0.6008  data: 0.0001  max mem: 15821
[12:28:10.496095] Epoch: [9]  [ 80/345]  eta: 0:02:40  lr: 0.000058  loss: 0.2549 (0.2658)  time: 0.6017  data: 0.0001  max mem: 15821
[12:28:22.573101] Epoch: [9]  [100/345]  eta: 0:02:27  lr: 0.000058  loss: 0.2581 (0.2664)  time: 0.6038  data: 0.0001  max mem: 15821
[12:28:34.681457] Epoch: [9]  [120/345]  eta: 0:02:15  lr: 0.000058  loss: 0.2742 (0.2677)  time: 0.6054  data: 0.0001  max mem: 15821
[12:28:46.790693] Epoch: [9]  [140/345]  eta: 0:02:03  lr: 0.000059  loss: 0.2611 (0.2678)  time: 0.6054  data: 0.0001  max mem: 15821
[12:28:58.903623] Epoch: [9]  [160/345]  eta: 0:01:51  lr: 0.000059  loss: 0.2592 (0.2677)  time: 0.6055  data: 0.0001  max mem: 15821
[12:29:11.002489] Epoch: [9]  [180/345]  eta: 0:01:39  lr: 0.000060  loss: 0.2581 (0.2677)  time: 0.6049  data: 0.0001  max mem: 15821
[12:29:23.104396] Epoch: [9]  [200/345]  eta: 0:01:27  lr: 0.000060  loss: 0.2705 (0.2678)  time: 0.6051  data: 0.0001  max mem: 15821
[12:29:35.200210] Epoch: [9]  [220/345]  eta: 0:01:15  lr: 0.000060  loss: 0.2696 (0.2687)  time: 0.6047  data: 0.0001  max mem: 15821
[12:29:47.297569] Epoch: [9]  [240/345]  eta: 0:01:03  lr: 0.000061  loss: 0.2562 (0.2681)  time: 0.6048  data: 0.0001  max mem: 15821
[12:29:59.390620] Epoch: [9]  [260/345]  eta: 0:00:51  lr: 0.000061  loss: 0.2674 (0.2684)  time: 0.6046  data: 0.0001  max mem: 15821
[12:30:11.482880] Epoch: [9]  [280/345]  eta: 0:00:39  lr: 0.000061  loss: 0.2610 (0.2683)  time: 0.6046  data: 0.0001  max mem: 15821
[12:30:23.595335] Epoch: [9]  [300/345]  eta: 0:00:27  lr: 0.000062  loss: 0.2644 (0.2685)  time: 0.6056  data: 0.0001  max mem: 15821
[12:30:35.699081] Epoch: [9]  [320/345]  eta: 0:00:15  lr: 0.000062  loss: 0.2582 (0.2688)  time: 0.6051  data: 0.0001  max mem: 15821
[12:30:47.776671] Epoch: [9]  [340/345]  eta: 0:00:03  lr: 0.000062  loss: 0.2527 (0.2684)  time: 0.6038  data: 0.0001  max mem: 15821
[12:30:50.189111] Epoch: [9]  [344/345]  eta: 0:00:00  lr: 0.000062  loss: 0.2527 (0.2682)  time: 0.6036  data: 0.0001  max mem: 15821
[12:30:50.260833] Epoch: [9] Total time: 0:03:28 (0.6049 s / it)
[12:30:50.261197] Averaged stats: lr: 0.000062  loss: 0.2527 (0.2682)
[12:30:50.747207] Test:  [  0/345]  eta: 0:02:45  loss: 0.2998 (0.2998)  time: 0.4809  data: 0.3160  max mem: 15821
[12:30:52.415396] Test:  [ 10/345]  eta: 0:01:05  loss: 0.2606 (0.2567)  time: 0.1953  data: 0.0288  max mem: 15821
[12:30:54.087309] Test:  [ 20/345]  eta: 0:00:59  loss: 0.2442 (0.2522)  time: 0.1669  data: 0.0001  max mem: 15821
[12:30:55.761614] Test:  [ 30/345]  eta: 0:00:55  loss: 0.2463 (0.2511)  time: 0.1673  data: 0.0001  max mem: 15821
[12:30:57.439110] Test:  [ 40/345]  eta: 0:00:53  loss: 0.2602 (0.2545)  time: 0.1675  data: 0.0001  max mem: 15821
[12:30:59.120078] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2598 (0.2546)  time: 0.1679  data: 0.0001  max mem: 15821
[12:31:00.804217] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2494 (0.2540)  time: 0.1682  data: 0.0001  max mem: 15821
[12:31:02.492027] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2498 (0.2553)  time: 0.1685  data: 0.0001  max mem: 15821
[12:31:04.183488] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2515 (0.2554)  time: 0.1689  data: 0.0001  max mem: 15821
[12:31:05.877170] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2463 (0.2552)  time: 0.1692  data: 0.0001  max mem: 15821
[12:31:07.575696] Test:  [100/345]  eta: 0:00:41  loss: 0.2463 (0.2548)  time: 0.1696  data: 0.0001  max mem: 15821
[12:31:09.277205] Test:  [110/345]  eta: 0:00:40  loss: 0.2414 (0.2534)  time: 0.1699  data: 0.0001  max mem: 15821
[12:31:10.980610] Test:  [120/345]  eta: 0:00:38  loss: 0.2488 (0.2537)  time: 0.1702  data: 0.0001  max mem: 15821
[12:31:12.689848] Test:  [130/345]  eta: 0:00:36  loss: 0.2590 (0.2541)  time: 0.1706  data: 0.0001  max mem: 15821
[12:31:14.402299] Test:  [140/345]  eta: 0:00:35  loss: 0.2592 (0.2546)  time: 0.1710  data: 0.0001  max mem: 15821
[12:31:16.117325] Test:  [150/345]  eta: 0:00:33  loss: 0.2434 (0.2530)  time: 0.1713  data: 0.0001  max mem: 15821
[12:31:17.835747] Test:  [160/345]  eta: 0:00:31  loss: 0.2353 (0.2529)  time: 0.1716  data: 0.0001  max mem: 15821
[12:31:19.558922] Test:  [170/345]  eta: 0:00:29  loss: 0.2422 (0.2522)  time: 0.1720  data: 0.0001  max mem: 15821
[12:31:21.285654] Test:  [180/345]  eta: 0:00:28  loss: 0.2413 (0.2518)  time: 0.1724  data: 0.0001  max mem: 15821
[12:31:23.015071] Test:  [190/345]  eta: 0:00:26  loss: 0.2474 (0.2516)  time: 0.1727  data: 0.0001  max mem: 15821
[12:31:24.747645] Test:  [200/345]  eta: 0:00:24  loss: 0.2537 (0.2520)  time: 0.1730  data: 0.0001  max mem: 15821
[12:31:26.482374] Test:  [210/345]  eta: 0:00:23  loss: 0.2554 (0.2524)  time: 0.1733  data: 0.0001  max mem: 15821
[12:31:28.221223] Test:  [220/345]  eta: 0:00:21  loss: 0.2515 (0.2522)  time: 0.1736  data: 0.0001  max mem: 15821
[12:31:29.964284] Test:  [230/345]  eta: 0:00:19  loss: 0.2452 (0.2518)  time: 0.1740  data: 0.0001  max mem: 15821
[12:31:31.711427] Test:  [240/345]  eta: 0:00:18  loss: 0.2549 (0.2524)  time: 0.1744  data: 0.0001  max mem: 15821
[12:31:33.461865] Test:  [250/345]  eta: 0:00:16  loss: 0.2569 (0.2529)  time: 0.1748  data: 0.0001  max mem: 15821
[12:31:35.214659] Test:  [260/345]  eta: 0:00:14  loss: 0.2622 (0.2538)  time: 0.1751  data: 0.0001  max mem: 15821
[12:31:36.972086] Test:  [270/345]  eta: 0:00:12  loss: 0.2622 (0.2540)  time: 0.1755  data: 0.0001  max mem: 15821
[12:31:38.732147] Test:  [280/345]  eta: 0:00:11  loss: 0.2489 (0.2539)  time: 0.1758  data: 0.0001  max mem: 15821
[12:31:40.494398] Test:  [290/345]  eta: 0:00:09  loss: 0.2487 (0.2541)  time: 0.1761  data: 0.0001  max mem: 15821
[12:31:42.260406] Test:  [300/345]  eta: 0:00:07  loss: 0.2548 (0.2543)  time: 0.1764  data: 0.0001  max mem: 15821
[12:31:44.033075] Test:  [310/345]  eta: 0:00:06  loss: 0.2538 (0.2543)  time: 0.1769  data: 0.0001  max mem: 15821
[12:31:45.806281] Test:  [320/345]  eta: 0:00:04  loss: 0.2483 (0.2539)  time: 0.1772  data: 0.0001  max mem: 15821
[12:31:47.583186] Test:  [330/345]  eta: 0:00:02  loss: 0.2498 (0.2541)  time: 0.1774  data: 0.0001  max mem: 15821
[12:31:49.365562] Test:  [340/345]  eta: 0:00:00  loss: 0.2344 (0.2536)  time: 0.1779  data: 0.0001  max mem: 15821
[12:31:50.078693] Test:  [344/345]  eta: 0:00:00  loss: 0.2354 (0.2538)  time: 0.1780  data: 0.0001  max mem: 15821
[12:31:50.140493] Test: Total time: 0:00:59 (0.1736 s / it)
[12:32:00.070639] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4581 (0.4581)  time: 0.4508  data: 0.2882  max mem: 15821
[12:32:01.721515] Test:  [10/57]  eta: 0:00:08  loss: 0.4019 (0.4199)  time: 0.1910  data: 0.0263  max mem: 15821
[12:32:03.377501] Test:  [20/57]  eta: 0:00:06  loss: 0.4019 (0.4018)  time: 0.1653  data: 0.0001  max mem: 15821
[12:32:05.037389] Test:  [30/57]  eta: 0:00:04  loss: 0.2830 (0.3513)  time: 0.1657  data: 0.0001  max mem: 15821
[12:32:06.700941] Test:  [40/57]  eta: 0:00:02  loss: 0.2521 (0.3328)  time: 0.1661  data: 0.0001  max mem: 15821
[12:32:08.368350] Test:  [50/57]  eta: 0:00:01  loss: 0.2827 (0.3326)  time: 0.1665  data: 0.0001  max mem: 15821
[12:32:09.267447] Test:  [56/57]  eta: 0:00:00  loss: 0.3155 (0.3407)  time: 0.1616  data: 0.0001  max mem: 15821
[12:32:09.338806] Test: Total time: 0:00:09 (0.1705 s / it)
[12:32:10.991078] Dice score of the network on the train images: 0.782607, val images: 0.784160
[12:32:10.995764] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:32:11.922931] Epoch: [10]  [  0/345]  eta: 0:05:19  lr: 0.000063  loss: 0.2316 (0.2316)  time: 0.9261  data: 0.3251  max mem: 15821
[12:32:23.929943] Epoch: [10]  [ 20/345]  eta: 0:03:20  lr: 0.000063  loss: 0.2447 (0.2536)  time: 0.6003  data: 0.0001  max mem: 15821
[12:32:35.947271] Epoch: [10]  [ 40/345]  eta: 0:03:05  lr: 0.000063  loss: 0.2624 (0.2536)  time: 0.6008  data: 0.0001  max mem: 15821
[12:32:47.973379] Epoch: [10]  [ 60/345]  eta: 0:02:52  lr: 0.000064  loss: 0.2471 (0.2518)  time: 0.6013  data: 0.0001  max mem: 15821
[12:33:00.012994] Epoch: [10]  [ 80/345]  eta: 0:02:40  lr: 0.000064  loss: 0.2513 (0.2533)  time: 0.6019  data: 0.0001  max mem: 15821
[12:33:12.081067] Epoch: [10]  [100/345]  eta: 0:02:28  lr: 0.000064  loss: 0.2403 (0.2527)  time: 0.6034  data: 0.0001  max mem: 15821
[12:33:24.158924] Epoch: [10]  [120/345]  eta: 0:02:16  lr: 0.000065  loss: 0.2504 (0.2526)  time: 0.6039  data: 0.0001  max mem: 15821
[12:33:36.247395] Epoch: [10]  [140/345]  eta: 0:02:03  lr: 0.000065  loss: 0.2719 (0.2551)  time: 0.6044  data: 0.0001  max mem: 15821
[12:33:48.347656] Epoch: [10]  [160/345]  eta: 0:01:51  lr: 0.000065  loss: 0.2643 (0.2562)  time: 0.6050  data: 0.0001  max mem: 15821
[12:34:00.447689] Epoch: [10]  [180/345]  eta: 0:01:39  lr: 0.000066  loss: 0.2628 (0.2562)  time: 0.6050  data: 0.0001  max mem: 15821
[12:34:12.536168] Epoch: [10]  [200/345]  eta: 0:01:27  lr: 0.000066  loss: 0.2411 (0.2551)  time: 0.6044  data: 0.0001  max mem: 15821
[12:34:24.628472] Epoch: [10]  [220/345]  eta: 0:01:15  lr: 0.000066  loss: 0.2437 (0.2542)  time: 0.6046  data: 0.0001  max mem: 15821
[12:34:36.713333] Epoch: [10]  [240/345]  eta: 0:01:03  lr: 0.000067  loss: 0.2494 (0.2541)  time: 0.6042  data: 0.0001  max mem: 15821
[12:34:48.799172] Epoch: [10]  [260/345]  eta: 0:00:51  lr: 0.000067  loss: 0.2695 (0.2546)  time: 0.6043  data: 0.0001  max mem: 15821
[12:35:00.882698] Epoch: [10]  [280/345]  eta: 0:00:39  lr: 0.000068  loss: 0.2494 (0.2545)  time: 0.6041  data: 0.0001  max mem: 15821
[12:35:12.963940] Epoch: [10]  [300/345]  eta: 0:00:27  lr: 0.000068  loss: 0.2599 (0.2550)  time: 0.6040  data: 0.0001  max mem: 15821
[12:35:25.038262] Epoch: [10]  [320/345]  eta: 0:00:15  lr: 0.000068  loss: 0.2351 (0.2539)  time: 0.6037  data: 0.0001  max mem: 15821
[12:35:37.118808] Epoch: [10]  [340/345]  eta: 0:00:03  lr: 0.000069  loss: 0.2499 (0.2539)  time: 0.6040  data: 0.0001  max mem: 15821
[12:35:39.532303] Epoch: [10]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.2449 (0.2534)  time: 0.6039  data: 0.0001  max mem: 15821
[12:35:39.603289] Epoch: [10] Total time: 0:03:28 (0.6047 s / it)
[12:35:39.604192] Averaged stats: lr: 0.000069  loss: 0.2449 (0.2534)
[12:35:40.085159] Test:  [  0/345]  eta: 0:02:44  loss: 0.2654 (0.2654)  time: 0.4758  data: 0.3111  max mem: 15821
[12:35:41.752986] Test:  [ 10/345]  eta: 0:01:05  loss: 0.2297 (0.2344)  time: 0.1948  data: 0.0284  max mem: 15821
[12:35:43.425099] Test:  [ 20/345]  eta: 0:00:59  loss: 0.2297 (0.2369)  time: 0.1669  data: 0.0001  max mem: 15821
[12:35:45.100242] Test:  [ 30/345]  eta: 0:00:55  loss: 0.2367 (0.2365)  time: 0.1673  data: 0.0001  max mem: 15821
[12:35:46.777817] Test:  [ 40/345]  eta: 0:00:53  loss: 0.2367 (0.2388)  time: 0.1676  data: 0.0001  max mem: 15821
[12:35:48.458195] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2432 (0.2423)  time: 0.1678  data: 0.0001  max mem: 15821
[12:35:50.141679] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2383 (0.2422)  time: 0.1681  data: 0.0001  max mem: 15821
[12:35:51.830043] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2273 (0.2418)  time: 0.1685  data: 0.0001  max mem: 15821
[12:35:53.522579] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2260 (0.2414)  time: 0.1690  data: 0.0001  max mem: 15821
[12:35:55.217413] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2397 (0.2417)  time: 0.1693  data: 0.0001  max mem: 15821
[12:35:56.914797] Test:  [100/345]  eta: 0:00:41  loss: 0.2373 (0.2410)  time: 0.1695  data: 0.0001  max mem: 15821
[12:35:58.615934] Test:  [110/345]  eta: 0:00:40  loss: 0.2261 (0.2400)  time: 0.1699  data: 0.0001  max mem: 15821
[12:36:00.320722] Test:  [120/345]  eta: 0:00:38  loss: 0.2302 (0.2410)  time: 0.1702  data: 0.0001  max mem: 15821
[12:36:02.027976] Test:  [130/345]  eta: 0:00:36  loss: 0.2396 (0.2411)  time: 0.1705  data: 0.0001  max mem: 15821
[12:36:03.740420] Test:  [140/345]  eta: 0:00:35  loss: 0.2353 (0.2407)  time: 0.1709  data: 0.0001  max mem: 15821
[12:36:05.455649] Test:  [150/345]  eta: 0:00:33  loss: 0.2308 (0.2405)  time: 0.1713  data: 0.0001  max mem: 15821
[12:36:07.174111] Test:  [160/345]  eta: 0:00:31  loss: 0.2353 (0.2400)  time: 0.1716  data: 0.0001  max mem: 15821
[12:36:08.895658] Test:  [170/345]  eta: 0:00:29  loss: 0.2341 (0.2393)  time: 0.1719  data: 0.0001  max mem: 15821
[12:36:10.621725] Test:  [180/345]  eta: 0:00:28  loss: 0.2244 (0.2392)  time: 0.1723  data: 0.0001  max mem: 15821
[12:36:12.350289] Test:  [190/345]  eta: 0:00:26  loss: 0.2244 (0.2382)  time: 0.1727  data: 0.0001  max mem: 15821
[12:36:14.082264] Test:  [200/345]  eta: 0:00:24  loss: 0.2341 (0.2390)  time: 0.1730  data: 0.0001  max mem: 15821
[12:36:15.816874] Test:  [210/345]  eta: 0:00:23  loss: 0.2528 (0.2396)  time: 0.1733  data: 0.0001  max mem: 15821
[12:36:17.555838] Test:  [220/345]  eta: 0:00:21  loss: 0.2452 (0.2397)  time: 0.1736  data: 0.0001  max mem: 15821
[12:36:19.298658] Test:  [230/345]  eta: 0:00:19  loss: 0.2314 (0.2400)  time: 0.1740  data: 0.0001  max mem: 15821
[12:36:21.044064] Test:  [240/345]  eta: 0:00:18  loss: 0.2378 (0.2403)  time: 0.1744  data: 0.0001  max mem: 15821
[12:36:22.793627] Test:  [250/345]  eta: 0:00:16  loss: 0.2378 (0.2404)  time: 0.1747  data: 0.0001  max mem: 15821
[12:36:24.545448] Test:  [260/345]  eta: 0:00:14  loss: 0.2408 (0.2409)  time: 0.1750  data: 0.0001  max mem: 15821
[12:36:26.300952] Test:  [270/345]  eta: 0:00:12  loss: 0.2413 (0.2408)  time: 0.1753  data: 0.0001  max mem: 15821
[12:36:28.059188] Test:  [280/345]  eta: 0:00:11  loss: 0.2278 (0.2405)  time: 0.1756  data: 0.0001  max mem: 15821
[12:36:29.822265] Test:  [290/345]  eta: 0:00:09  loss: 0.2342 (0.2406)  time: 0.1760  data: 0.0001  max mem: 15821
[12:36:31.588871] Test:  [300/345]  eta: 0:00:07  loss: 0.2459 (0.2406)  time: 0.1764  data: 0.0001  max mem: 15821
[12:36:33.359791] Test:  [310/345]  eta: 0:00:06  loss: 0.2421 (0.2408)  time: 0.1768  data: 0.0001  max mem: 15821
[12:36:35.133485] Test:  [320/345]  eta: 0:00:04  loss: 0.2420 (0.2408)  time: 0.1772  data: 0.0001  max mem: 15821
[12:36:36.910493] Test:  [330/345]  eta: 0:00:02  loss: 0.2315 (0.2404)  time: 0.1775  data: 0.0001  max mem: 15821
[12:36:38.691920] Test:  [340/345]  eta: 0:00:00  loss: 0.2276 (0.2406)  time: 0.1779  data: 0.0001  max mem: 15821
[12:36:39.404495] Test:  [344/345]  eta: 0:00:00  loss: 0.2264 (0.2403)  time: 0.1780  data: 0.0001  max mem: 15821
[12:36:39.480336] Test: Total time: 0:00:59 (0.1735 s / it)
[12:36:49.363083] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4565 (0.4565)  time: 0.4497  data: 0.2871  max mem: 15821
[12:36:51.012657] Test:  [10/57]  eta: 0:00:08  loss: 0.4345 (0.4346)  time: 0.1907  data: 0.0262  max mem: 15821
[12:36:52.667590] Test:  [20/57]  eta: 0:00:06  loss: 0.4109 (0.4222)  time: 0.1651  data: 0.0001  max mem: 15821
[12:36:54.327026] Test:  [30/57]  eta: 0:00:04  loss: 0.3016 (0.3755)  time: 0.1657  data: 0.0001  max mem: 15821
[12:36:55.990098] Test:  [40/57]  eta: 0:00:02  loss: 0.2955 (0.3603)  time: 0.1661  data: 0.0001  max mem: 15821
[12:36:57.656790] Test:  [50/57]  eta: 0:00:01  loss: 0.3099 (0.3610)  time: 0.1664  data: 0.0001  max mem: 15821
[12:36:58.556079] Test:  [56/57]  eta: 0:00:00  loss: 0.3266 (0.3658)  time: 0.1615  data: 0.0000  max mem: 15821
[12:36:58.627074] Test: Total time: 0:00:09 (0.1704 s / it)
[12:37:00.298208] Dice score of the network on the train images: 0.812343, val images: 0.767098
[12:37:00.298441] saving best_prec_model_0 @ epoch 10
[12:37:01.545100] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:37:02.444042] Epoch: [11]  [  0/345]  eta: 0:05:09  lr: 0.000069  loss: 0.2113 (0.2113)  time: 0.8977  data: 0.2977  max mem: 15821
[12:37:14.455854] Epoch: [11]  [ 20/345]  eta: 0:03:19  lr: 0.000069  loss: 0.2339 (0.2357)  time: 0.6005  data: 0.0001  max mem: 15821
[12:37:26.476734] Epoch: [11]  [ 40/345]  eta: 0:03:05  lr: 0.000069  loss: 0.2405 (0.2361)  time: 0.6010  data: 0.0001  max mem: 15821
[12:37:38.524410] Epoch: [11]  [ 60/345]  eta: 0:02:52  lr: 0.000070  loss: 0.2445 (0.2402)  time: 0.6023  data: 0.0001  max mem: 15821
[12:37:50.586691] Epoch: [11]  [ 80/345]  eta: 0:02:40  lr: 0.000070  loss: 0.2296 (0.2402)  time: 0.6031  data: 0.0001  max mem: 15821
[12:38:02.666837] Epoch: [11]  [100/345]  eta: 0:02:28  lr: 0.000071  loss: 0.2553 (0.2427)  time: 0.6040  data: 0.0001  max mem: 15821
[12:38:14.776346] Epoch: [11]  [120/345]  eta: 0:02:16  lr: 0.000071  loss: 0.2449 (0.2431)  time: 0.6054  data: 0.0001  max mem: 15821
[12:38:26.890171] Epoch: [11]  [140/345]  eta: 0:02:04  lr: 0.000071  loss: 0.2398 (0.2429)  time: 0.6056  data: 0.0001  max mem: 15821
[12:38:39.013090] Epoch: [11]  [160/345]  eta: 0:01:51  lr: 0.000072  loss: 0.2332 (0.2425)  time: 0.6061  data: 0.0001  max mem: 15821
[12:38:51.117204] Epoch: [11]  [180/345]  eta: 0:01:39  lr: 0.000072  loss: 0.2210 (0.2412)  time: 0.6052  data: 0.0001  max mem: 15821
[12:39:03.224471] Epoch: [11]  [200/345]  eta: 0:01:27  lr: 0.000072  loss: 0.2411 (0.2413)  time: 0.6053  data: 0.0001  max mem: 15821
[12:39:15.328909] Epoch: [11]  [220/345]  eta: 0:01:15  lr: 0.000073  loss: 0.2376 (0.2411)  time: 0.6052  data: 0.0001  max mem: 15821
[12:39:27.431573] Epoch: [11]  [240/345]  eta: 0:01:03  lr: 0.000073  loss: 0.2420 (0.2407)  time: 0.6051  data: 0.0001  max mem: 15821
[12:39:39.529086] Epoch: [11]  [260/345]  eta: 0:00:51  lr: 0.000073  loss: 0.2507 (0.2415)  time: 0.6048  data: 0.0001  max mem: 15821
[12:39:51.622514] Epoch: [11]  [280/345]  eta: 0:00:39  lr: 0.000074  loss: 0.2461 (0.2420)  time: 0.6046  data: 0.0001  max mem: 15821
[12:40:03.707794] Epoch: [11]  [300/345]  eta: 0:00:27  lr: 0.000074  loss: 0.2482 (0.2425)  time: 0.6042  data: 0.0001  max mem: 15821

[12:40:15.795562] Epoch: [11]  [320/345]  eta: 0:00:15  lr: 0.000075  loss: 0.2293 (0.2420)  time: 0.6044  data: 0.0001  max mem: 15821
[12:40:27.873746] Epoch: [11]  [340/345]  eta: 0:00:03  lr: 0.000075  loss: 0.2400 (0.2423)  time: 0.6039  data: 0.0001  max mem: 15821
[12:40:30.289915] Epoch: [11]  [344/345]  eta: 0:00:00  lr: 0.000075  loss: 0.2404 (0.2422)  time: 0.6039  data: 0.0001  max mem: 15821
[12:40:30.365556] Epoch: [11] Total time: 0:03:28 (0.6053 s / it)
[12:40:30.365876] Averaged stats: lr: 0.000075  loss: 0.2404 (0.2422)
[12:40:30.889665] Test:  [  0/345]  eta: 0:02:58  loss: 0.2648 (0.2648)  time: 0.5186  data: 0.3538  max mem: 15821
[12:40:32.557457] Test:  [ 10/345]  eta: 0:01:06  loss: 0.2248 (0.2292)  time: 0.1987  data: 0.0322  max mem: 15821
[12:40:34.229120] Test:  [ 20/345]  eta: 0:00:59  loss: 0.2248 (0.2331)  time: 0.1669  data: 0.0001  max mem: 15821
[12:40:35.905946] Test:  [ 30/345]  eta: 0:00:56  loss: 0.2247 (0.2289)  time: 0.1674  data: 0.0001  max mem: 15821
[12:40:37.583433] Test:  [ 40/345]  eta: 0:00:53  loss: 0.2232 (0.2298)  time: 0.1677  data: 0.0001  max mem: 15821
[12:40:39.264197] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2204 (0.2276)  time: 0.1679  data: 0.0001  max mem: 15821
[12:40:40.947173] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2108 (0.2253)  time: 0.1681  data: 0.0001  max mem: 15821
[12:40:42.634962] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2071 (0.2248)  time: 0.1685  data: 0.0001  max mem: 15821
[12:40:44.326456] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2235 (0.2256)  time: 0.1689  data: 0.0001  max mem: 15821
[12:40:46.021532] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2286 (0.2252)  time: 0.1693  data: 0.0001  max mem: 15821
[12:40:47.719142] Test:  [100/345]  eta: 0:00:42  loss: 0.2266 (0.2251)  time: 0.1696  data: 0.0001  max mem: 15821
[12:40:49.419232] Test:  [110/345]  eta: 0:00:40  loss: 0.2254 (0.2253)  time: 0.1698  data: 0.0001  max mem: 15821
[12:40:51.123478] Test:  [120/345]  eta: 0:00:38  loss: 0.2223 (0.2254)  time: 0.1702  data: 0.0001  max mem: 15821
[12:40:52.831096] Test:  [130/345]  eta: 0:00:36  loss: 0.2187 (0.2251)  time: 0.1705  data: 0.0001  max mem: 15821
[12:40:54.542779] Test:  [140/345]  eta: 0:00:35  loss: 0.2236 (0.2254)  time: 0.1709  data: 0.0001  max mem: 15821
[12:40:56.257793] Test:  [150/345]  eta: 0:00:33  loss: 0.2329 (0.2255)  time: 0.1713  data: 0.0001  max mem: 15821
[12:40:57.977453] Test:  [160/345]  eta: 0:00:31  loss: 0.2345 (0.2254)  time: 0.1717  data: 0.0001  max mem: 15821
[12:40:59.699116] Test:  [170/345]  eta: 0:00:30  loss: 0.2203 (0.2254)  time: 0.1720  data: 0.0001  max mem: 15821
[12:41:01.425451] Test:  [180/345]  eta: 0:00:28  loss: 0.2194 (0.2251)  time: 0.1723  data: 0.0001  max mem: 15821
[12:41:03.155300] Test:  [190/345]  eta: 0:00:26  loss: 0.2197 (0.2252)  time: 0.1727  data: 0.0001  max mem: 15821
[12:41:04.886145] Test:  [200/345]  eta: 0:00:24  loss: 0.2194 (0.2250)  time: 0.1730  data: 0.0001  max mem: 15821
[12:41:06.621926] Test:  [210/345]  eta: 0:00:23  loss: 0.2236 (0.2253)  time: 0.1733  data: 0.0001  max mem: 15821
[12:41:08.360427] Test:  [220/345]  eta: 0:00:21  loss: 0.2236 (0.2254)  time: 0.1737  data: 0.0001  max mem: 15821
[12:41:10.103365] Test:  [230/345]  eta: 0:00:19  loss: 0.2183 (0.2255)  time: 0.1740  data: 0.0001  max mem: 15821
[12:41:11.849394] Test:  [240/345]  eta: 0:00:18  loss: 0.2256 (0.2259)  time: 0.1744  data: 0.0001  max mem: 15821
[12:41:13.598462] Test:  [250/345]  eta: 0:00:16  loss: 0.2256 (0.2259)  time: 0.1747  data: 0.0001  max mem: 15821
[12:41:15.350369] Test:  [260/345]  eta: 0:00:14  loss: 0.2239 (0.2259)  time: 0.1750  data: 0.0001  max mem: 15821
[12:41:17.107030] Test:  [270/345]  eta: 0:00:12  loss: 0.2160 (0.2256)  time: 0.1753  data: 0.0001  max mem: 15821
[12:41:18.866612] Test:  [280/345]  eta: 0:00:11  loss: 0.2208 (0.2261)  time: 0.1757  data: 0.0001  max mem: 15821
[12:41:20.629367] Test:  [290/345]  eta: 0:00:09  loss: 0.2379 (0.2263)  time: 0.1761  data: 0.0001  max mem: 15821
[12:41:22.396969] Test:  [300/345]  eta: 0:00:07  loss: 0.2317 (0.2262)  time: 0.1765  data: 0.0001  max mem: 15821
[12:41:24.167790] Test:  [310/345]  eta: 0:00:06  loss: 0.2187 (0.2262)  time: 0.1769  data: 0.0001  max mem: 15821
[12:41:25.942941] Test:  [320/345]  eta: 0:00:04  loss: 0.2131 (0.2261)  time: 0.1772  data: 0.0001  max mem: 15821
[12:41:27.720462] Test:  [330/345]  eta: 0:00:02  loss: 0.2131 (0.2260)  time: 0.1776  data: 0.0001  max mem: 15821
[12:41:29.502922] Test:  [340/345]  eta: 0:00:00  loss: 0.2214 (0.2261)  time: 0.1779  data: 0.0001  max mem: 15821
[12:41:30.216663] Test:  [344/345]  eta: 0:00:00  loss: 0.2214 (0.2263)  time: 0.1781  data: 0.0001  max mem: 15821
[12:41:30.271629] Test: Total time: 0:00:59 (0.1736 s / it)
[12:41:40.121477] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4561 (0.4561)  time: 0.4536  data: 0.2913  max mem: 15821
[12:41:41.770618] Test:  [10/57]  eta: 0:00:08  loss: 0.4093 (0.4226)  time: 0.1911  data: 0.0266  max mem: 15821
[12:41:43.426033] Test:  [20/57]  eta: 0:00:06  loss: 0.3769 (0.3954)  time: 0.1651  data: 0.0001  max mem: 15821
[12:41:45.085548] Test:  [30/57]  eta: 0:00:04  loss: 0.2527 (0.3399)  time: 0.1657  data: 0.0001  max mem: 15821
[12:41:46.747613] Test:  [40/57]  eta: 0:00:02  loss: 0.2320 (0.3164)  time: 0.1660  data: 0.0001  max mem: 15821
[12:41:48.413407] Test:  [50/57]  eta: 0:00:01  loss: 0.2588 (0.3126)  time: 0.1663  data: 0.0001  max mem: 15821
[12:41:49.314153] Test:  [56/57]  eta: 0:00:00  loss: 0.2710 (0.3144)  time: 0.1615  data: 0.0000  max mem: 15821
[12:41:49.379461] Test: Total time: 0:00:09 (0.1704 s / it)
[12:41:51.058521] Dice score of the network on the train images: 0.794688, val images: 0.811926
[12:41:51.058722] saving best_rec_model_0 @ epoch 11
[12:41:52.308462] saving best_dice_model_0 @ epoch 11
[12:41:53.470243] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:41:54.366640] Epoch: [12]  [  0/345]  eta: 0:05:08  lr: 0.000075  loss: 0.2271 (0.2271)  time: 0.8952  data: 0.2949  max mem: 15821
[12:42:06.363019] Epoch: [12]  [ 20/345]  eta: 0:03:19  lr: 0.000075  loss: 0.2283 (0.2377)  time: 0.5998  data: 0.0001  max mem: 15821
[12:42:18.378749] Epoch: [12]  [ 40/345]  eta: 0:03:05  lr: 0.000076  loss: 0.2333 (0.2380)  time: 0.6007  data: 0.0001  max mem: 15821
[12:42:30.406039] Epoch: [12]  [ 60/345]  eta: 0:02:52  lr: 0.000076  loss: 0.2365 (0.2394)  time: 0.6013  data: 0.0001  max mem: 15821
[12:42:42.463505] Epoch: [12]  [ 80/345]  eta: 0:02:40  lr: 0.000076  loss: 0.2217 (0.2360)  time: 0.6028  data: 0.0001  max mem: 15821
[12:42:54.552708] Epoch: [12]  [100/345]  eta: 0:02:28  lr: 0.000077  loss: 0.2283 (0.2352)  time: 0.6044  data: 0.0001  max mem: 15821
[12:43:06.667670] Epoch: [12]  [120/345]  eta: 0:02:16  lr: 0.000077  loss: 0.2336 (0.2347)  time: 0.6057  data: 0.0001  max mem: 15821
[12:43:18.803670] Epoch: [12]  [140/345]  eta: 0:02:04  lr: 0.000078  loss: 0.2306 (0.2345)  time: 0.6068  data: 0.0001  max mem: 15821
[12:43:30.943532] Epoch: [12]  [160/345]  eta: 0:01:51  lr: 0.000078  loss: 0.2397 (0.2363)  time: 0.6069  data: 0.0001  max mem: 15821
[12:43:43.070812] Epoch: [12]  [180/345]  eta: 0:01:39  lr: 0.000078  loss: 0.2330 (0.2365)  time: 0.6063  data: 0.0001  max mem: 15821
[12:43:55.189636] Epoch: [12]  [200/345]  eta: 0:01:27  lr: 0.000079  loss: 0.2343 (0.2366)  time: 0.6059  data: 0.0001  max mem: 15821
[12:44:07.297251] Epoch: [12]  [220/345]  eta: 0:01:15  lr: 0.000079  loss: 0.2225 (0.2356)  time: 0.6053  data: 0.0001  max mem: 15821
[12:44:19.400547] Epoch: [12]  [240/345]  eta: 0:01:03  lr: 0.000079  loss: 0.2317 (0.2356)  time: 0.6051  data: 0.0001  max mem: 15821
[12:44:31.497122] Epoch: [12]  [260/345]  eta: 0:00:51  lr: 0.000080  loss: 0.2258 (0.2348)  time: 0.6048  data: 0.0001  max mem: 15821
[12:44:43.673659] Epoch: [12]  [280/345]  eta: 0:00:39  lr: 0.000080  loss: 0.2232 (0.2341)  time: 0.6088  data: 0.0001  max mem: 15821
[12:44:55.762862] Epoch: [12]  [300/345]  eta: 0:00:27  lr: 0.000080  loss: 0.2179 (0.2331)  time: 0.6044  data: 0.0001  max mem: 15821
[12:45:07.852059] Epoch: [12]  [320/345]  eta: 0:00:15  lr: 0.000081  loss: 0.2176 (0.2323)  time: 0.6044  data: 0.0001  max mem: 15821
[12:45:19.934284] Epoch: [12]  [340/345]  eta: 0:00:03  lr: 0.000081  loss: 0.2242 (0.2320)  time: 0.6041  data: 0.0001  max mem: 15821
[12:45:22.353863] Epoch: [12]  [344/345]  eta: 0:00:00  lr: 0.000081  loss: 0.2248 (0.2319)  time: 0.6041  data: 0.0001  max mem: 15821
[12:45:22.422956] Epoch: [12] Total time: 0:03:28 (0.6057 s / it)
[12:45:22.423238] Averaged stats: lr: 0.000081  loss: 0.2248 (0.2319)
[12:45:22.922402] Test:  [  0/345]  eta: 0:02:50  loss: 0.2808 (0.2808)  time: 0.4941  data: 0.3293  max mem: 15821
[12:45:24.591267] Test:  [ 10/345]  eta: 0:01:05  loss: 0.2234 (0.2264)  time: 0.1966  data: 0.0300  max mem: 15821
[12:45:26.262261] Test:  [ 20/345]  eta: 0:00:59  loss: 0.2189 (0.2232)  time: 0.1669  data: 0.0001  max mem: 15821
[12:45:27.940599] Test:  [ 30/345]  eta: 0:00:55  loss: 0.2112 (0.2208)  time: 0.1673  data: 0.0001  max mem: 15821
[12:45:29.618846] Test:  [ 40/345]  eta: 0:00:53  loss: 0.2221 (0.2237)  time: 0.1677  data: 0.0001  max mem: 15821
[12:45:31.300318] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2360 (0.2239)  time: 0.1679  data: 0.0001  max mem: 15821
[12:45:32.984675] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2163 (0.2226)  time: 0.1682  data: 0.0001  max mem: 15821
[12:45:34.673609] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2134 (0.2208)  time: 0.1686  data: 0.0001  max mem: 15821
[12:45:36.365935] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2124 (0.2211)  time: 0.1690  data: 0.0001  max mem: 15821
[12:45:38.061665] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2124 (0.2203)  time: 0.1693  data: 0.0001  max mem: 15821
[12:45:39.760017] Test:  [100/345]  eta: 0:00:42  loss: 0.2099 (0.2197)  time: 0.1696  data: 0.0001  max mem: 15821
[12:45:41.463176] Test:  [110/345]  eta: 0:00:40  loss: 0.2177 (0.2210)  time: 0.1700  data: 0.0001  max mem: 15821
[12:45:43.169413] Test:  [120/345]  eta: 0:00:38  loss: 0.2200 (0.2202)  time: 0.1704  data: 0.0001  max mem: 15821
[12:45:44.877722] Test:  [130/345]  eta: 0:00:36  loss: 0.2133 (0.2209)  time: 0.1707  data: 0.0001  max mem: 15821
[12:45:46.589536] Test:  [140/345]  eta: 0:00:35  loss: 0.2251 (0.2212)  time: 0.1709  data: 0.0001  max mem: 15821
[12:45:48.305021] Test:  [150/345]  eta: 0:00:33  loss: 0.2224 (0.2213)  time: 0.1713  data: 0.0001  max mem: 15821
[12:45:50.024800] Test:  [160/345]  eta: 0:00:31  loss: 0.2332 (0.2216)  time: 0.1717  data: 0.0001  max mem: 15821
[12:45:51.748128] Test:  [170/345]  eta: 0:00:29  loss: 0.2230 (0.2213)  time: 0.1721  data: 0.0001  max mem: 15821
[12:45:53.473939] Test:  [180/345]  eta: 0:00:28  loss: 0.2097 (0.2211)  time: 0.1724  data: 0.0001  max mem: 15821
[12:45:55.204653] Test:  [190/345]  eta: 0:00:26  loss: 0.2278 (0.2218)  time: 0.1728  data: 0.0001  max mem: 15821
[12:45:56.935565] Test:  [200/345]  eta: 0:00:24  loss: 0.2098 (0.2210)  time: 0.1730  data: 0.0001  max mem: 15821
[12:45:58.672572] Test:  [210/345]  eta: 0:00:23  loss: 0.2091 (0.2210)  time: 0.1733  data: 0.0001  max mem: 15821
[12:46:00.412749] Test:  [220/345]  eta: 0:00:21  loss: 0.2156 (0.2212)  time: 0.1738  data: 0.0001  max mem: 15821
[12:46:02.155531] Test:  [230/345]  eta: 0:00:19  loss: 0.2220 (0.2215)  time: 0.1741  data: 0.0001  max mem: 15821
[12:46:03.903310] Test:  [240/345]  eta: 0:00:18  loss: 0.2242 (0.2216)  time: 0.1745  data: 0.0001  max mem: 15821
[12:46:05.652291] Test:  [250/345]  eta: 0:00:16  loss: 0.2084 (0.2211)  time: 0.1748  data: 0.0001  max mem: 15821
[12:46:07.405795] Test:  [260/345]  eta: 0:00:14  loss: 0.2065 (0.2206)  time: 0.1750  data: 0.0001  max mem: 15821
[12:46:09.163595] Test:  [270/345]  eta: 0:00:12  loss: 0.2062 (0.2204)  time: 0.1755  data: 0.0001  max mem: 15821
[12:46:10.924925] Test:  [280/345]  eta: 0:00:11  loss: 0.2224 (0.2210)  time: 0.1759  data: 0.0001  max mem: 15821
[12:46:12.687999] Test:  [290/345]  eta: 0:00:09  loss: 0.2280 (0.2210)  time: 0.1762  data: 0.0001  max mem: 15821
[12:46:14.454638] Test:  [300/345]  eta: 0:00:07  loss: 0.2234 (0.2210)  time: 0.1764  data: 0.0001  max mem: 15821
[12:46:16.227034] Test:  [310/345]  eta: 0:00:06  loss: 0.2190 (0.2211)  time: 0.1769  data: 0.0001  max mem: 15821
[12:46:18.001926] Test:  [320/345]  eta: 0:00:04  loss: 0.2201 (0.2214)  time: 0.1773  data: 0.0001  max mem: 15821
[12:46:19.781708] Test:  [330/345]  eta: 0:00:02  loss: 0.2306 (0.2218)  time: 0.1777  data: 0.0001  max mem: 15821
[12:46:21.564545] Test:  [340/345]  eta: 0:00:00  loss: 0.2251 (0.2216)  time: 0.1781  data: 0.0001  max mem: 15821
[12:46:22.277311] Test:  [344/345]  eta: 0:00:00  loss: 0.2251 (0.2217)  time: 0.1782  data: 0.0001  max mem: 15821
[12:46:22.346989] Test: Total time: 0:00:59 (0.1737 s / it)
[12:46:32.227624] Test:  [ 0/57]  eta: 0:00:27  loss: 0.4501 (0.4501)  time: 0.4861  data: 0.3235  max mem: 15821
[12:46:33.876639] Test:  [10/57]  eta: 0:00:09  loss: 0.3826 (0.4136)  time: 0.1940  data: 0.0295  max mem: 15821
[12:46:35.532224] Test:  [20/57]  eta: 0:00:06  loss: 0.3801 (0.3952)  time: 0.1651  data: 0.0001  max mem: 15821
[12:46:37.192473] Test:  [30/57]  eta: 0:00:04  loss: 0.2666 (0.3417)  time: 0.1657  data: 0.0001  max mem: 15821
[12:46:38.855392] Test:  [40/57]  eta: 0:00:02  loss: 0.2462 (0.3198)  time: 0.1661  data: 0.0001  max mem: 15821
[12:46:40.523843] Test:  [50/57]  eta: 0:00:01  loss: 0.2613 (0.3178)  time: 0.1665  data: 0.0001  max mem: 15821
[12:46:41.422925] Test:  [56/57]  eta: 0:00:00  loss: 0.2958 (0.3204)  time: 0.1616  data: 0.0000  max mem: 15821
[12:46:41.488170] Test: Total time: 0:00:09 (0.1710 s / it)
[12:46:43.137928] Dice score of the network on the train images: 0.790759, val images: 0.803366
[12:46:43.141978] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:46:44.039530] Epoch: [13]  [  0/345]  eta: 0:05:09  lr: 0.000081  loss: 0.2158 (0.2158)  time: 0.8964  data: 0.2938  max mem: 15821
[12:46:56.063036] Epoch: [13]  [ 20/345]  eta: 0:03:19  lr: 0.000082  loss: 0.2178 (0.2269)  time: 0.6011  data: 0.0001  max mem: 15821
[12:47:08.109129] Epoch: [13]  [ 40/345]  eta: 0:03:05  lr: 0.000082  loss: 0.2372 (0.2314)  time: 0.6023  data: 0.0001  max mem: 15821
[12:47:20.171398] Epoch: [13]  [ 60/345]  eta: 0:02:52  lr: 0.000082  loss: 0.2292 (0.2299)  time: 0.6031  data: 0.0001  max mem: 15821
[12:47:32.236935] Epoch: [13]  [ 80/345]  eta: 0:02:40  lr: 0.000083  loss: 0.2187 (0.2275)  time: 0.6032  data: 0.0001  max mem: 15821
[12:47:44.322267] Epoch: [13]  [100/345]  eta: 0:02:28  lr: 0.000083  loss: 0.2238 (0.2275)  time: 0.6042  data: 0.0001  max mem: 15821
[12:47:56.432323] Epoch: [13]  [120/345]  eta: 0:02:16  lr: 0.000083  loss: 0.2139 (0.2270)  time: 0.6055  data: 0.0001  max mem: 15821
[12:48:08.548026] Epoch: [13]  [140/345]  eta: 0:02:04  lr: 0.000084  loss: 0.2199 (0.2267)  time: 0.6057  data: 0.0001  max mem: 15821
[12:48:20.676359] Epoch: [13]  [160/345]  eta: 0:01:52  lr: 0.000084  loss: 0.2265 (0.2273)  time: 0.6064  data: 0.0001  max mem: 15821
[12:48:32.800196] Epoch: [13]  [180/345]  eta: 0:01:39  lr: 0.000085  loss: 0.2146 (0.2258)  time: 0.6061  data: 0.0001  max mem: 15821

[12:48:44.926953] Epoch: [13]  [200/345]  eta: 0:01:27  lr: 0.000085  loss: 0.2133 (0.2254)  time: 0.6063  data: 0.0001  max mem: 15821
[12:48:57.049386] Epoch: [13]  [220/345]  eta: 0:01:15  lr: 0.000085  loss: 0.2280 (0.2262)  time: 0.6061  data: 0.0001  max mem: 15821
[12:49:09.168828] Epoch: [13]  [240/345]  eta: 0:01:03  lr: 0.000086  loss: 0.2190 (0.2260)  time: 0.6059  data: 0.0001  max mem: 15821
[12:49:21.291073] Epoch: [13]  [260/345]  eta: 0:00:51  lr: 0.000086  loss: 0.2275 (0.2269)  time: 0.6061  data: 0.0001  max mem: 15821
[12:49:33.400717] Epoch: [13]  [280/345]  eta: 0:00:39  lr: 0.000086  loss: 0.2119 (0.2268)  time: 0.6054  data: 0.0001  max mem: 15821
[12:49:45.515197] Epoch: [13]  [300/345]  eta: 0:00:27  lr: 0.000087  loss: 0.2293 (0.2266)  time: 0.6057  data: 0.0001  max mem: 15821
[12:49:57.606376] Epoch: [13]  [320/345]  eta: 0:00:15  lr: 0.000087  loss: 0.2119 (0.2262)  time: 0.6045  data: 0.0001  max mem: 15821
[12:50:09.707684] Epoch: [13]  [340/345]  eta: 0:00:03  lr: 0.000087  loss: 0.2177 (0.2259)  time: 0.6050  data: 0.0001  max mem: 15821
[12:50:12.131806] Epoch: [13]  [344/345]  eta: 0:00:00  lr: 0.000087  loss: 0.2177 (0.2256)  time: 0.6051  data: 0.0001  max mem: 15821
[12:50:12.199621] Epoch: [13] Total time: 0:03:29 (0.6060 s / it)
[12:50:12.199829] Averaged stats: lr: 0.000087  loss: 0.2177 (0.2256)
[12:50:12.685595] Test:  [  0/345]  eta: 0:02:45  loss: 0.2013 (0.2013)  time: 0.4804  data: 0.3154  max mem: 15821
[12:50:14.354581] Test:  [ 10/345]  eta: 0:01:05  loss: 0.2013 (0.2104)  time: 0.1953  data: 0.0288  max mem: 15821
[12:50:16.025895] Test:  [ 20/345]  eta: 0:00:59  loss: 0.2022 (0.2141)  time: 0.1669  data: 0.0001  max mem: 15821
[12:50:17.701007] Test:  [ 30/345]  eta: 0:00:55  loss: 0.1957 (0.2080)  time: 0.1673  data: 0.0001  max mem: 15821
[12:50:19.378785] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1957 (0.2068)  time: 0.1676  data: 0.0001  max mem: 15821
[12:50:21.060359] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2004 (0.2064)  time: 0.1679  data: 0.0001  max mem: 15821
[12:50:22.744643] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2065 (0.2067)  time: 0.1682  data: 0.0001  max mem: 15821
[12:50:24.432710] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1981 (0.2059)  time: 0.1686  data: 0.0001  max mem: 15821
[12:50:26.123847] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1950 (0.2067)  time: 0.1689  data: 0.0001  max mem: 15821
[12:50:27.818279] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2076 (0.2091)  time: 0.1692  data: 0.0001  max mem: 15821
[12:50:29.517108] Test:  [100/345]  eta: 0:00:41  loss: 0.2142 (0.2092)  time: 0.1696  data: 0.0001  max mem: 15821
[12:50:31.217421] Test:  [110/345]  eta: 0:00:40  loss: 0.2064 (0.2092)  time: 0.1699  data: 0.0001  max mem: 15821
[12:50:32.922117] Test:  [120/345]  eta: 0:00:38  loss: 0.1953 (0.2087)  time: 0.1702  data: 0.0001  max mem: 15821
[12:50:34.630792] Test:  [130/345]  eta: 0:00:36  loss: 0.1916 (0.2084)  time: 0.1706  data: 0.0001  max mem: 15821
[12:50:36.343514] Test:  [140/345]  eta: 0:00:35  loss: 0.1874 (0.2071)  time: 0.1710  data: 0.0001  max mem: 15821
[12:50:38.059415] Test:  [150/345]  eta: 0:00:33  loss: 0.1893 (0.2066)  time: 0.1714  data: 0.0001  max mem: 15821
[12:50:39.779059] Test:  [160/345]  eta: 0:00:31  loss: 0.2011 (0.2075)  time: 0.1717  data: 0.0001  max mem: 15821
[12:50:41.502398] Test:  [170/345]  eta: 0:00:29  loss: 0.2061 (0.2071)  time: 0.1721  data: 0.0001  max mem: 15821
[12:50:43.229918] Test:  [180/345]  eta: 0:00:28  loss: 0.2051 (0.2077)  time: 0.1725  data: 0.0001  max mem: 15821
[12:50:44.958870] Test:  [190/345]  eta: 0:00:26  loss: 0.2211 (0.2083)  time: 0.1728  data: 0.0001  max mem: 15821
[12:50:46.692166] Test:  [200/345]  eta: 0:00:24  loss: 0.2153 (0.2085)  time: 0.1731  data: 0.0001  max mem: 15821
[12:50:48.427663] Test:  [210/345]  eta: 0:00:23  loss: 0.2089 (0.2088)  time: 0.1734  data: 0.0001  max mem: 15821
[12:50:50.167416] Test:  [220/345]  eta: 0:00:21  loss: 0.2089 (0.2089)  time: 0.1737  data: 0.0001  max mem: 15821
[12:50:51.910552] Test:  [230/345]  eta: 0:00:19  loss: 0.2207 (0.2098)  time: 0.1741  data: 0.0001  max mem: 15821
[12:50:53.656559] Test:  [240/345]  eta: 0:00:18  loss: 0.2125 (0.2096)  time: 0.1744  data: 0.0001  max mem: 15821
[12:50:55.405449] Test:  [250/345]  eta: 0:00:16  loss: 0.2004 (0.2094)  time: 0.1747  data: 0.0001  max mem: 15821
[12:50:57.157364] Test:  [260/345]  eta: 0:00:14  loss: 0.2081 (0.2094)  time: 0.1750  data: 0.0001  max mem: 15821
[12:50:58.913911] Test:  [270/345]  eta: 0:00:12  loss: 0.2129 (0.2094)  time: 0.1754  data: 0.0001  max mem: 15821
[12:51:00.673463] Test:  [280/345]  eta: 0:00:11  loss: 0.2158 (0.2095)  time: 0.1757  data: 0.0001  max mem: 15821
[12:51:02.436956] Test:  [290/345]  eta: 0:00:09  loss: 0.2087 (0.2093)  time: 0.1761  data: 0.0001  max mem: 15821
[12:51:04.204459] Test:  [300/345]  eta: 0:00:07  loss: 0.2088 (0.2095)  time: 0.1765  data: 0.0001  max mem: 15821
[12:51:05.975272] Test:  [310/345]  eta: 0:00:06  loss: 0.2125 (0.2096)  time: 0.1769  data: 0.0001  max mem: 15821
[12:51:07.751322] Test:  [320/345]  eta: 0:00:04  loss: 0.1989 (0.2095)  time: 0.1773  data: 0.0001  max mem: 15821
[12:51:09.531079] Test:  [330/345]  eta: 0:00:02  loss: 0.1984 (0.2094)  time: 0.1777  data: 0.0001  max mem: 15821
[12:51:11.312900] Test:  [340/345]  eta: 0:00:00  loss: 0.2109 (0.2095)  time: 0.1780  data: 0.0001  max mem: 15821
[12:51:12.027127] Test:  [344/345]  eta: 0:00:00  loss: 0.2115 (0.2096)  time: 0.1781  data: 0.0001  max mem: 15821
[12:51:12.093098] Test: Total time: 0:00:59 (0.1736 s / it)
[12:51:21.972099] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4529 (0.4529)  time: 0.4619  data: 0.2993  max mem: 15821
[12:51:23.620231] Test:  [10/57]  eta: 0:00:09  loss: 0.3806 (0.4050)  time: 0.1917  data: 0.0273  max mem: 15821
[12:51:25.274903] Test:  [20/57]  eta: 0:00:06  loss: 0.3806 (0.3882)  time: 0.1651  data: 0.0001  max mem: 15821
[12:51:26.933867] Test:  [30/57]  eta: 0:00:04  loss: 0.2637 (0.3404)  time: 0.1656  data: 0.0001  max mem: 15821
[12:51:28.596385] Test:  [40/57]  eta: 0:00:02  loss: 0.2448 (0.3220)  time: 0.1660  data: 0.0001  max mem: 15821
[12:51:30.264345] Test:  [50/57]  eta: 0:00:01  loss: 0.2757 (0.3231)  time: 0.1665  data: 0.0001  max mem: 15821
[12:51:31.163571] Test:  [56/57]  eta: 0:00:00  loss: 0.2870 (0.3291)  time: 0.1616  data: 0.0000  max mem: 15821
[12:51:31.227052] Test: Total time: 0:00:09 (0.1705 s / it)
[12:51:32.857016] Dice score of the network on the train images: 0.811279, val images: 0.788030
[12:51:32.860938] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:51:33.773943] Epoch: [14]  [  0/345]  eta: 0:05:14  lr: 0.000087  loss: 0.2419 (0.2419)  time: 0.9119  data: 0.3117  max mem: 15821
[12:51:45.771638] Epoch: [14]  [ 20/345]  eta: 0:03:19  lr: 0.000088  loss: 0.2018 (0.2109)  time: 0.5998  data: 0.0001  max mem: 15821
[12:51:57.795960] Epoch: [14]  [ 40/345]  eta: 0:03:05  lr: 0.000088  loss: 0.2209 (0.2159)  time: 0.6012  data: 0.0001  max mem: 15821
[12:52:09.851156] Epoch: [14]  [ 60/345]  eta: 0:02:52  lr: 0.000089  loss: 0.2134 (0.2158)  time: 0.6027  data: 0.0001  max mem: 15821
[12:52:21.921799] Epoch: [14]  [ 80/345]  eta: 0:02:40  lr: 0.000089  loss: 0.2206 (0.2165)  time: 0.6035  data: 0.0001  max mem: 15821
[12:52:34.001758] Epoch: [14]  [100/345]  eta: 0:02:28  lr: 0.000089  loss: 0.2169 (0.2170)  time: 0.6040  data: 0.0001  max mem: 15821
[12:52:46.108122] Epoch: [14]  [120/345]  eta: 0:02:16  lr: 0.000090  loss: 0.2062 (0.2160)  time: 0.6053  data: 0.0001  max mem: 15821
[12:52:58.224688] Epoch: [14]  [140/345]  eta: 0:02:04  lr: 0.000090  loss: 0.2152 (0.2161)  time: 0.6058  data: 0.0001  max mem: 15821
[12:53:10.346564] Epoch: [14]  [160/345]  eta: 0:01:52  lr: 0.000090  loss: 0.2125 (0.2159)  time: 0.6060  data: 0.0001  max mem: 15821
[12:53:22.461002] Epoch: [14]  [180/345]  eta: 0:01:39  lr: 0.000091  loss: 0.2021 (0.2150)  time: 0.6057  data: 0.0001  max mem: 15821
[12:53:34.580415] Epoch: [14]  [200/345]  eta: 0:01:27  lr: 0.000091  loss: 0.2113 (0.2148)  time: 0.6059  data: 0.0001  max mem: 15821
[12:53:46.690969] Epoch: [14]  [220/345]  eta: 0:01:15  lr: 0.000091  loss: 0.2240 (0.2159)  time: 0.6055  data: 0.0001  max mem: 15821
[12:53:58.808990] Epoch: [14]  [240/345]  eta: 0:01:03  lr: 0.000092  loss: 0.2093 (0.2160)  time: 0.6059  data: 0.0001  max mem: 15821
[12:54:10.917820] Epoch: [14]  [260/345]  eta: 0:00:51  lr: 0.000092  loss: 0.2217 (0.2166)  time: 0.6054  data: 0.0001  max mem: 15821
[12:54:23.018407] Epoch: [14]  [280/345]  eta: 0:00:39  lr: 0.000093  loss: 0.2232 (0.2172)  time: 0.6050  data: 0.0001  max mem: 15821
[12:54:35.131639] Epoch: [14]  [300/345]  eta: 0:00:27  lr: 0.000093  loss: 0.2161 (0.2172)  time: 0.6056  data: 0.0001  max mem: 15821
[12:54:47.226189] Epoch: [14]  [320/345]  eta: 0:00:15  lr: 0.000093  loss: 0.2069 (0.2169)  time: 0.6047  data: 0.0001  max mem: 15821
[12:54:59.307471] Epoch: [14]  [340/345]  eta: 0:00:03  lr: 0.000094  loss: 0.2199 (0.2173)  time: 0.6040  data: 0.0001  max mem: 15821
[12:55:01.725719] Epoch: [14]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.2209 (0.2172)  time: 0.6039  data: 0.0001  max mem: 15821
[12:55:01.801911] Epoch: [14] Total time: 0:03:28 (0.6056 s / it)
[12:55:01.802268] Averaged stats: lr: 0.000094  loss: 0.2209 (0.2172)
[12:55:02.297890] Test:  [  0/345]  eta: 0:02:49  loss: 0.1667 (0.1667)  time: 0.4905  data: 0.3262  max mem: 15821
[12:55:03.966217] Test:  [ 10/345]  eta: 0:01:05  loss: 0.2086 (0.2031)  time: 0.1962  data: 0.0297  max mem: 15821
[12:55:05.637123] Test:  [ 20/345]  eta: 0:00:59  loss: 0.2086 (0.2061)  time: 0.1669  data: 0.0001  max mem: 15821
[12:55:07.311896] Test:  [ 30/345]  eta: 0:00:55  loss: 0.1986 (0.2044)  time: 0.1672  data: 0.0001  max mem: 15821
[12:55:08.989977] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1945 (0.2018)  time: 0.1676  data: 0.0001  max mem: 15821
[12:55:10.672093] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1976 (0.2021)  time: 0.1679  data: 0.0001  max mem: 15821
[12:55:12.356648] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1999 (0.2009)  time: 0.1683  data: 0.0001  max mem: 15821
[12:55:14.043607] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2018 (0.2015)  time: 0.1685  data: 0.0001  max mem: 15821
[12:55:15.735466] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1968 (0.2004)  time: 0.1689  data: 0.0001  max mem: 15821
[12:55:17.430254] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1883 (0.2006)  time: 0.1693  data: 0.0001  max mem: 15821
[12:55:19.128738] Test:  [100/345]  eta: 0:00:42  loss: 0.2055 (0.2020)  time: 0.1696  data: 0.0001  max mem: 15821
[12:55:20.832476] Test:  [110/345]  eta: 0:00:40  loss: 0.2015 (0.2022)  time: 0.1700  data: 0.0001  max mem: 15821
[12:55:22.537994] Test:  [120/345]  eta: 0:00:38  loss: 0.2022 (0.2020)  time: 0.1704  data: 0.0001  max mem: 15821
[12:55:24.245730] Test:  [130/345]  eta: 0:00:36  loss: 0.1974 (0.2015)  time: 0.1706  data: 0.0001  max mem: 15821
[12:55:25.958321] Test:  [140/345]  eta: 0:00:35  loss: 0.1923 (0.2010)  time: 0.1710  data: 0.0001  max mem: 15821
[12:55:27.673867] Test:  [150/345]  eta: 0:00:33  loss: 0.1994 (0.2018)  time: 0.1713  data: 0.0001  max mem: 15821
[12:55:29.393737] Test:  [160/345]  eta: 0:00:31  loss: 0.1994 (0.2018)  time: 0.1717  data: 0.0001  max mem: 15821
[12:55:31.117434] Test:  [170/345]  eta: 0:00:29  loss: 0.1908 (0.2011)  time: 0.1721  data: 0.0001  max mem: 15821
[12:55:32.843940] Test:  [180/345]  eta: 0:00:28  loss: 0.2053 (0.2018)  time: 0.1724  data: 0.0001  max mem: 15821
[12:55:34.573890] Test:  [190/345]  eta: 0:00:26  loss: 0.2044 (0.2019)  time: 0.1728  data: 0.0001  max mem: 15821
[12:55:36.306112] Test:  [200/345]  eta: 0:00:24  loss: 0.1977 (0.2015)  time: 0.1730  data: 0.0001  max mem: 15821
[12:55:38.042332] Test:  [210/345]  eta: 0:00:23  loss: 0.1957 (0.2018)  time: 0.1734  data: 0.0001  max mem: 15821
[12:55:39.782654] Test:  [220/345]  eta: 0:00:21  loss: 0.1950 (0.2017)  time: 0.1738  data: 0.0001  max mem: 15821
[12:55:41.525803] Test:  [230/345]  eta: 0:00:19  loss: 0.2049 (0.2022)  time: 0.1741  data: 0.0001  max mem: 15821
[12:55:43.272692] Test:  [240/345]  eta: 0:00:18  loss: 0.2078 (0.2025)  time: 0.1744  data: 0.0001  max mem: 15821
[12:55:45.021577] Test:  [250/345]  eta: 0:00:16  loss: 0.1966 (0.2025)  time: 0.1747  data: 0.0001  max mem: 15821
[12:55:46.776074] Test:  [260/345]  eta: 0:00:14  loss: 0.1965 (0.2024)  time: 0.1751  data: 0.0001  max mem: 15821
[12:55:48.532910] Test:  [270/345]  eta: 0:00:12  loss: 0.1997 (0.2028)  time: 0.1755  data: 0.0001  max mem: 15821
[12:55:50.292126] Test:  [280/345]  eta: 0:00:11  loss: 0.2044 (0.2028)  time: 0.1757  data: 0.0001  max mem: 15821
[12:55:52.055317] Test:  [290/345]  eta: 0:00:09  loss: 0.1954 (0.2027)  time: 0.1761  data: 0.0001  max mem: 15821
[12:55:53.820912] Test:  [300/345]  eta: 0:00:07  loss: 0.1915 (0.2025)  time: 0.1764  data: 0.0001  max mem: 15821
[12:55:55.592109] Test:  [310/345]  eta: 0:00:06  loss: 0.1996 (0.2027)  time: 0.1768  data: 0.0001  max mem: 15821
[12:55:57.365913] Test:  [320/345]  eta: 0:00:04  loss: 0.2050 (0.2026)  time: 0.1772  data: 0.0001  max mem: 15821
[12:55:59.143254] Test:  [330/345]  eta: 0:00:02  loss: 0.1961 (0.2026)  time: 0.1775  data: 0.0001  max mem: 15821
[12:56:00.925815] Test:  [340/345]  eta: 0:00:00  loss: 0.2126 (0.2029)  time: 0.1779  data: 0.0001  max mem: 15821
[12:56:01.639465] Test:  [344/345]  eta: 0:00:00  loss: 0.2124 (0.2029)  time: 0.1781  data: 0.0001  max mem: 15821
[12:56:01.704015] Test: Total time: 0:00:59 (0.1736 s / it)
[12:56:11.594355] Test:  [ 0/57]  eta: 0:00:27  loss: 0.4452 (0.4452)  time: 0.4893  data: 0.3267  max mem: 15821
[12:56:13.244571] Test:  [10/57]  eta: 0:00:09  loss: 0.3888 (0.4097)  time: 0.1944  data: 0.0298  max mem: 15821
[12:56:14.900088] Test:  [20/57]  eta: 0:00:06  loss: 0.3916 (0.3970)  time: 0.1652  data: 0.0001  max mem: 15821
[12:56:16.560367] Test:  [30/57]  eta: 0:00:04  loss: 0.2744 (0.3497)  time: 0.1657  data: 0.0001  max mem: 15821
[12:56:18.223331] Test:  [40/57]  eta: 0:00:02  loss: 0.2532 (0.3296)  time: 0.1661  data: 0.0001  max mem: 15821
[12:56:19.891805] Test:  [50/57]  eta: 0:00:01  loss: 0.2665 (0.3289)  time: 0.1665  data: 0.0001  max mem: 15821
[12:56:20.791082] Test:  [56/57]  eta: 0:00:00  loss: 0.2922 (0.3344)  time: 0.1616  data: 0.0000  max mem: 15821
[12:56:20.855622] Test: Total time: 0:00:09 (0.1711 s / it)
[12:56:22.490245] Dice score of the network on the train images: 0.824303, val images: 0.786420
[12:56:22.493836] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:56:23.389509] Epoch: [15]  [  0/345]  eta: 0:05:08  lr: 0.000094  loss: 0.2499 (0.2499)  time: 0.8948  data: 0.2935  max mem: 15821
[12:56:35.410678] Epoch: [15]  [ 20/345]  eta: 0:03:19  lr: 0.000094  loss: 0.2102 (0.2122)  time: 0.6010  data: 0.0001  max mem: 15821
[12:56:47.444049] Epoch: [15]  [ 40/345]  eta: 0:03:05  lr: 0.000094  loss: 0.1963 (0.2069)  time: 0.6016  data: 0.0001  max mem: 15821

[12:56:59.484643] Epoch: [15]  [ 60/345]  eta: 0:02:52  lr: 0.000095  loss: 0.2007 (0.2042)  time: 0.6020  data: 0.0001  max mem: 15821
[12:57:11.538169] Epoch: [15]  [ 80/345]  eta: 0:02:40  lr: 0.000095  loss: 0.2210 (0.2077)  time: 0.6026  data: 0.0001  max mem: 15821
[12:57:23.617825] Epoch: [15]  [100/345]  eta: 0:02:28  lr: 0.000096  loss: 0.1999 (0.2072)  time: 0.6039  data: 0.0001  max mem: 15821
[12:57:35.725107] Epoch: [15]  [120/345]  eta: 0:02:16  lr: 0.000096  loss: 0.1942 (0.2071)  time: 0.6053  data: 0.0001  max mem: 15821
[12:57:47.842589] Epoch: [15]  [140/345]  eta: 0:02:04  lr: 0.000096  loss: 0.2124 (0.2089)  time: 0.6058  data: 0.0001  max mem: 15821
[12:57:59.961900] Epoch: [15]  [160/345]  eta: 0:01:51  lr: 0.000097  loss: 0.2048 (0.2089)  time: 0.6059  data: 0.0001  max mem: 15821
[12:58:12.086302] Epoch: [15]  [180/345]  eta: 0:01:39  lr: 0.000097  loss: 0.2012 (0.2082)  time: 0.6062  data: 0.0001  max mem: 15821
[12:58:24.207157] Epoch: [15]  [200/345]  eta: 0:01:27  lr: 0.000097  loss: 0.2092 (0.2095)  time: 0.6060  data: 0.0001  max mem: 15821
[12:58:36.334159] Epoch: [15]  [220/345]  eta: 0:01:15  lr: 0.000098  loss: 0.2124 (0.2105)  time: 0.6063  data: 0.0001  max mem: 15821
[12:58:48.435099] Epoch: [15]  [240/345]  eta: 0:01:03  lr: 0.000098  loss: 0.2092 (0.2107)  time: 0.6050  data: 0.0001  max mem: 15821
[12:59:00.531896] Epoch: [15]  [260/345]  eta: 0:00:51  lr: 0.000098  loss: 0.2031 (0.2106)  time: 0.6048  data: 0.0001  max mem: 15821
[12:59:12.637870] Epoch: [15]  [280/345]  eta: 0:00:39  lr: 0.000099  loss: 0.2089 (0.2106)  time: 0.6053  data: 0.0001  max mem: 15821
[12:59:24.733886] Epoch: [15]  [300/345]  eta: 0:00:27  lr: 0.000099  loss: 0.2118 (0.2113)  time: 0.6048  data: 0.0001  max mem: 15821
[12:59:36.822375] Epoch: [15]  [320/345]  eta: 0:00:15  lr: 0.000100  loss: 0.2021 (0.2113)  time: 0.6044  data: 0.0001  max mem: 15821
[12:59:48.909546] Epoch: [15]  [340/345]  eta: 0:00:03  lr: 0.000100  loss: 0.2085 (0.2115)  time: 0.6043  data: 0.0001  max mem: 15821
[12:59:51.325137] Epoch: [15]  [344/345]  eta: 0:00:00  lr: 0.000100  loss: 0.2147 (0.2115)  time: 0.6041  data: 0.0001  max mem: 15821
[12:59:51.394466] Epoch: [15] Total time: 0:03:28 (0.6055 s / it)
[12:59:51.394811] Averaged stats: lr: 0.000100  loss: 0.2147 (0.2115)
[12:59:51.923584] Test:  [  0/345]  eta: 0:03:00  loss: 0.2065 (0.2065)  time: 0.5236  data: 0.3594  max mem: 15821
[12:59:53.591895] Test:  [ 10/345]  eta: 0:01:06  loss: 0.2065 (0.2034)  time: 0.1992  data: 0.0327  max mem: 15821
[12:59:55.263275] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1912 (0.1997)  time: 0.1669  data: 0.0001  max mem: 15821
[12:59:56.937598] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1914 (0.1990)  time: 0.1672  data: 0.0001  max mem: 15821
[12:59:58.614349] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1949 (0.1991)  time: 0.1675  data: 0.0001  max mem: 15821
[13:00:00.294952] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1967 (0.1999)  time: 0.1678  data: 0.0001  max mem: 15821
[13:00:01.978558] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2083 (0.2012)  time: 0.1681  data: 0.0001  max mem: 15821
[13:00:03.665591] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2093 (0.2025)  time: 0.1685  data: 0.0001  max mem: 15821
[13:00:05.356514] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2036 (0.2009)  time: 0.1688  data: 0.0001  max mem: 15821
[13:00:07.050354] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2006 (0.2015)  time: 0.1692  data: 0.0001  max mem: 15821
[13:00:08.747625] Test:  [100/345]  eta: 0:00:42  loss: 0.2160 (0.2024)  time: 0.1695  data: 0.0001  max mem: 15821
[13:00:10.449158] Test:  [110/345]  eta: 0:00:40  loss: 0.2092 (0.2020)  time: 0.1699  data: 0.0001  max mem: 15821
[13:00:12.154135] Test:  [120/345]  eta: 0:00:38  loss: 0.1918 (0.2016)  time: 0.1703  data: 0.0001  max mem: 15821
[13:00:13.862261] Test:  [130/345]  eta: 0:00:36  loss: 0.2004 (0.2019)  time: 0.1706  data: 0.0001  max mem: 15821
[13:00:15.573647] Test:  [140/345]  eta: 0:00:35  loss: 0.2007 (0.2018)  time: 0.1709  data: 0.0001  max mem: 15821
[13:00:17.288879] Test:  [150/345]  eta: 0:00:33  loss: 0.1983 (0.2016)  time: 0.1713  data: 0.0001  max mem: 15821
[13:00:19.007293] Test:  [160/345]  eta: 0:00:31  loss: 0.1875 (0.2016)  time: 0.1716  data: 0.0001  max mem: 15821
[13:00:20.729630] Test:  [170/345]  eta: 0:00:30  loss: 0.2059 (0.2023)  time: 0.1720  data: 0.0001  max mem: 15821
[13:00:22.455128] Test:  [180/345]  eta: 0:00:28  loss: 0.1980 (0.2015)  time: 0.1723  data: 0.0001  max mem: 15821
[13:00:24.185354] Test:  [190/345]  eta: 0:00:26  loss: 0.1936 (0.2018)  time: 0.1727  data: 0.0001  max mem: 15821
[13:00:25.917562] Test:  [200/345]  eta: 0:00:24  loss: 0.2060 (0.2019)  time: 0.1731  data: 0.0001  max mem: 15821
[13:00:27.652650] Test:  [210/345]  eta: 0:00:23  loss: 0.1986 (0.2018)  time: 0.1733  data: 0.0001  max mem: 15821
[13:00:29.391372] Test:  [220/345]  eta: 0:00:21  loss: 0.1951 (0.2019)  time: 0.1736  data: 0.0001  max mem: 15821
[13:00:31.135659] Test:  [230/345]  eta: 0:00:19  loss: 0.1959 (0.2021)  time: 0.1741  data: 0.0001  max mem: 15821
[13:00:32.881364] Test:  [240/345]  eta: 0:00:18  loss: 0.1959 (0.2020)  time: 0.1744  data: 0.0001  max mem: 15821
[13:00:34.630997] Test:  [250/345]  eta: 0:00:16  loss: 0.1979 (0.2015)  time: 0.1747  data: 0.0001  max mem: 15821
[13:00:36.384282] Test:  [260/345]  eta: 0:00:14  loss: 0.1977 (0.2015)  time: 0.1751  data: 0.0001  max mem: 15821
[13:00:38.142043] Test:  [270/345]  eta: 0:00:12  loss: 0.2048 (0.2020)  time: 0.1755  data: 0.0001  max mem: 15821
[13:00:39.901528] Test:  [280/345]  eta: 0:00:11  loss: 0.2072 (0.2018)  time: 0.1758  data: 0.0001  max mem: 15821
[13:00:41.664696] Test:  [290/345]  eta: 0:00:09  loss: 0.2038 (0.2023)  time: 0.1761  data: 0.0001  max mem: 15821
[13:00:43.431368] Test:  [300/345]  eta: 0:00:07  loss: 0.2020 (0.2022)  time: 0.1764  data: 0.0001  max mem: 15821
[13:00:45.203915] Test:  [310/345]  eta: 0:00:06  loss: 0.1973 (0.2025)  time: 0.1769  data: 0.0001  max mem: 15821
[13:00:46.979315] Test:  [320/345]  eta: 0:00:04  loss: 0.1961 (0.2024)  time: 0.1773  data: 0.0001  max mem: 15821
[13:00:48.757891] Test:  [330/345]  eta: 0:00:02  loss: 0.1929 (0.2020)  time: 0.1776  data: 0.0001  max mem: 15821
[13:00:50.538747] Test:  [340/345]  eta: 0:00:00  loss: 0.1964 (0.2020)  time: 0.1779  data: 0.0001  max mem: 15821
[13:00:51.250864] Test:  [344/345]  eta: 0:00:00  loss: 0.1971 (0.2020)  time: 0.1780  data: 0.0001  max mem: 15821
[13:00:51.325603] Test: Total time: 0:00:59 (0.1737 s / it)
[13:01:01.140558] Test:  [ 0/57]  eta: 0:00:25  loss: 0.3783 (0.3783)  time: 0.4489  data: 0.2866  max mem: 15821
[13:01:02.789208] Test:  [10/57]  eta: 0:00:08  loss: 0.3563 (0.3885)  time: 0.1906  data: 0.0261  max mem: 15821
[13:01:04.443835] Test:  [20/57]  eta: 0:00:06  loss: 0.3809 (0.3836)  time: 0.1651  data: 0.0001  max mem: 15821
[13:01:06.103131] Test:  [30/57]  eta: 0:00:04  loss: 0.2692 (0.3345)  time: 0.1656  data: 0.0001  max mem: 15821
[13:01:07.766453] Test:  [40/57]  eta: 0:00:02  loss: 0.2412 (0.3130)  time: 0.1661  data: 0.0001  max mem: 15821
[13:01:09.431876] Test:  [50/57]  eta: 0:00:01  loss: 0.2664 (0.3177)  time: 0.1664  data: 0.0001  max mem: 15821
[13:01:10.331431] Test:  [56/57]  eta: 0:00:00  loss: 0.2886 (0.3330)  time: 0.1615  data: 0.0000  max mem: 15821
[13:01:10.387207] Test: Total time: 0:00:09 (0.1701 s / it)
[13:01:12.043754] Dice score of the network on the train images: 0.809458, val images: 0.776642
[13:01:12.047697] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:01:13.016159] Epoch: [16]  [  0/345]  eta: 0:05:33  lr: 0.000100  loss: 0.1973 (0.1973)  time: 0.9674  data: 0.3662  max mem: 15821
[13:01:25.021980] Epoch: [16]  [ 20/345]  eta: 0:03:20  lr: 0.000100  loss: 0.2042 (0.2103)  time: 0.6002  data: 0.0001  max mem: 15821
[13:01:37.042151] Epoch: [16]  [ 40/345]  eta: 0:03:05  lr: 0.000101  loss: 0.2073 (0.2083)  time: 0.6010  data: 0.0001  max mem: 15821
[13:01:49.082289] Epoch: [16]  [ 60/345]  eta: 0:02:53  lr: 0.000101  loss: 0.2085 (0.2086)  time: 0.6020  data: 0.0001  max mem: 15821
[13:02:01.128783] Epoch: [16]  [ 80/345]  eta: 0:02:40  lr: 0.000101  loss: 0.2040 (0.2095)  time: 0.6023  data: 0.0001  max mem: 15821
[13:02:13.191470] Epoch: [16]  [100/345]  eta: 0:02:28  lr: 0.000102  loss: 0.1971 (0.2082)  time: 0.6031  data: 0.0001  max mem: 15821
[13:02:25.286162] Epoch: [16]  [120/345]  eta: 0:02:16  lr: 0.000102  loss: 0.1896 (0.2061)  time: 0.6047  data: 0.0001  max mem: 15821
[13:02:37.386269] Epoch: [16]  [140/345]  eta: 0:02:04  lr: 0.000103  loss: 0.2080 (0.2065)  time: 0.6050  data: 0.0001  max mem: 15821
[13:02:49.496530] Epoch: [16]  [160/345]  eta: 0:01:51  lr: 0.000103  loss: 0.2123 (0.2074)  time: 0.6055  data: 0.0001  max mem: 15821
[13:03:01.602919] Epoch: [16]  [180/345]  eta: 0:01:39  lr: 0.000103  loss: 0.1973 (0.2068)  time: 0.6053  data: 0.0001  max mem: 15821
[13:03:13.708138] Epoch: [16]  [200/345]  eta: 0:01:27  lr: 0.000104  loss: 0.1971 (0.2061)  time: 0.6052  data: 0.0001  max mem: 15821
[13:03:25.810149] Epoch: [16]  [220/345]  eta: 0:01:15  lr: 0.000104  loss: 0.2111 (0.2064)  time: 0.6051  data: 0.0001  max mem: 15821
[13:03:37.911382] Epoch: [16]  [240/345]  eta: 0:01:03  lr: 0.000104  loss: 0.2088 (0.2061)  time: 0.6050  data: 0.0001  max mem: 15821
[13:03:50.027167] Epoch: [16]  [260/345]  eta: 0:00:51  lr: 0.000105  loss: 0.1981 (0.2061)  time: 0.6057  data: 0.0001  max mem: 15821
[13:04:02.140102] Epoch: [16]  [280/345]  eta: 0:00:39  lr: 0.000105  loss: 0.2061 (0.2063)  time: 0.6056  data: 0.0001  max mem: 15821
[13:04:14.255723] Epoch: [16]  [300/345]  eta: 0:00:27  lr: 0.000105  loss: 0.2125 (0.2065)  time: 0.6057  data: 0.0001  max mem: 15821
[13:04:26.369388] Epoch: [16]  [320/345]  eta: 0:00:15  lr: 0.000106  loss: 0.1920 (0.2058)  time: 0.6056  data: 0.0001  max mem: 15821
[13:04:38.463655] Epoch: [16]  [340/345]  eta: 0:00:03  lr: 0.000106  loss: 0.1865 (0.2050)  time: 0.6047  data: 0.0001  max mem: 15821
[13:04:40.883823] Epoch: [16]  [344/345]  eta: 0:00:00  lr: 0.000106  loss: 0.1974 (0.2050)  time: 0.6048  data: 0.0001  max mem: 15821
[13:04:40.954735] Epoch: [16] Total time: 0:03:28 (0.6055 s / it)
[13:04:40.955207] Averaged stats: lr: 0.000106  loss: 0.1974 (0.2050)
[13:04:41.441736] Test:  [  0/345]  eta: 0:02:46  loss: 0.1927 (0.1927)  time: 0.4812  data: 0.3161  max mem: 15821
[13:04:43.111324] Test:  [ 10/345]  eta: 0:01:05  loss: 0.1952 (0.1978)  time: 0.1954  data: 0.0288  max mem: 15821
[13:04:44.783475] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1916 (0.1931)  time: 0.1670  data: 0.0001  max mem: 15821
[13:04:46.459085] Test:  [ 30/345]  eta: 0:00:55  loss: 0.1870 (0.1932)  time: 0.1673  data: 0.0001  max mem: 15821
[13:04:48.137705] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1960 (0.1956)  time: 0.1676  data: 0.0001  max mem: 15821
[13:04:49.821105] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1936 (0.1944)  time: 0.1680  data: 0.0001  max mem: 15821
[13:04:51.505852] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1862 (0.1939)  time: 0.1683  data: 0.0001  max mem: 15821
[13:04:53.195761] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1952 (0.1956)  time: 0.1687  data: 0.0001  max mem: 15821
[13:04:54.887095] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1893 (0.1946)  time: 0.1690  data: 0.0001  max mem: 15821
[13:04:56.582360] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1890 (0.1948)  time: 0.1693  data: 0.0001  max mem: 15821
[13:04:58.280600] Test:  [100/345]  eta: 0:00:41  loss: 0.1947 (0.1945)  time: 0.1696  data: 0.0001  max mem: 15821
[13:04:59.982067] Test:  [110/345]  eta: 0:00:40  loss: 0.1982 (0.1948)  time: 0.1699  data: 0.0001  max mem: 15821
[13:05:01.688300] Test:  [120/345]  eta: 0:00:38  loss: 0.2000 (0.1957)  time: 0.1703  data: 0.0001  max mem: 15821
[13:05:03.397536] Test:  [130/345]  eta: 0:00:36  loss: 0.1878 (0.1948)  time: 0.1707  data: 0.0001  max mem: 15821
[13:05:05.110403] Test:  [140/345]  eta: 0:00:35  loss: 0.1870 (0.1956)  time: 0.1710  data: 0.0001  max mem: 15821
[13:05:06.825938] Test:  [150/345]  eta: 0:00:33  loss: 0.1875 (0.1951)  time: 0.1714  data: 0.0001  max mem: 15821
[13:05:08.543441] Test:  [160/345]  eta: 0:00:31  loss: 0.1875 (0.1954)  time: 0.1716  data: 0.0001  max mem: 15821
[13:05:10.266526] Test:  [170/345]  eta: 0:00:29  loss: 0.1927 (0.1952)  time: 0.1720  data: 0.0001  max mem: 15821
[13:05:11.992233] Test:  [180/345]  eta: 0:00:28  loss: 0.1876 (0.1949)  time: 0.1724  data: 0.0001  max mem: 15821
[13:05:13.721364] Test:  [190/345]  eta: 0:00:26  loss: 0.1891 (0.1949)  time: 0.1727  data: 0.0001  max mem: 15821
[13:05:15.454779] Test:  [200/345]  eta: 0:00:24  loss: 0.1867 (0.1942)  time: 0.1731  data: 0.0001  max mem: 15821
[13:05:17.191032] Test:  [210/345]  eta: 0:00:23  loss: 0.1867 (0.1943)  time: 0.1734  data: 0.0001  max mem: 15821
[13:05:18.929647] Test:  [220/345]  eta: 0:00:21  loss: 0.1858 (0.1938)  time: 0.1737  data: 0.0001  max mem: 15821
[13:05:20.673010] Test:  [230/345]  eta: 0:00:19  loss: 0.1858 (0.1938)  time: 0.1740  data: 0.0001  max mem: 15821
[13:05:22.419076] Test:  [240/345]  eta: 0:00:18  loss: 0.1892 (0.1937)  time: 0.1744  data: 0.0001  max mem: 15821
[13:05:24.170225] Test:  [250/345]  eta: 0:00:16  loss: 0.1891 (0.1940)  time: 0.1748  data: 0.0001  max mem: 15821
[13:05:25.922415] Test:  [260/345]  eta: 0:00:14  loss: 0.1943 (0.1941)  time: 0.1751  data: 0.0001  max mem: 15821
[13:05:27.679246] Test:  [270/345]  eta: 0:00:12  loss: 0.1970 (0.1944)  time: 0.1754  data: 0.0001  max mem: 15821
[13:05:29.438715] Test:  [280/345]  eta: 0:00:11  loss: 0.1974 (0.1945)  time: 0.1758  data: 0.0001  max mem: 15821
[13:05:31.202614] Test:  [290/345]  eta: 0:00:09  loss: 0.1934 (0.1944)  time: 0.1761  data: 0.0001  max mem: 15821
[13:05:32.970214] Test:  [300/345]  eta: 0:00:07  loss: 0.1887 (0.1944)  time: 0.1765  data: 0.0001  max mem: 15821
[13:05:34.742846] Test:  [310/345]  eta: 0:00:06  loss: 0.1894 (0.1943)  time: 0.1769  data: 0.0001  max mem: 15821
[13:05:36.518060] Test:  [320/345]  eta: 0:00:04  loss: 0.1923 (0.1944)  time: 0.1773  data: 0.0001  max mem: 15821
[13:05:38.296875] Test:  [330/345]  eta: 0:00:02  loss: 0.1957 (0.1945)  time: 0.1776  data: 0.0001  max mem: 15821
[13:05:40.078639] Test:  [340/345]  eta: 0:00:00  loss: 0.1957 (0.1946)  time: 0.1780  data: 0.0001  max mem: 15821
[13:05:40.793296] Test:  [344/345]  eta: 0:00:00  loss: 0.1970 (0.1947)  time: 0.1781  data: 0.0001  max mem: 15821
[13:05:40.862060] Test: Total time: 0:00:59 (0.1736 s / it)
[13:05:50.682606] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4426 (0.4426)  time: 0.4509  data: 0.2885  max mem: 15821
[13:05:52.331996] Test:  [10/57]  eta: 0:00:08  loss: 0.3781 (0.3993)  time: 0.1908  data: 0.0263  max mem: 15821
[13:05:53.987505] Test:  [20/57]  eta: 0:00:06  loss: 0.3781 (0.3908)  time: 0.1652  data: 0.0001  max mem: 15821
[13:05:55.647200] Test:  [30/57]  eta: 0:00:04  loss: 0.2865 (0.3399)  time: 0.1657  data: 0.0001  max mem: 15821
[13:05:57.309906] Test:  [40/57]  eta: 0:00:02  loss: 0.2363 (0.3190)  time: 0.1661  data: 0.0001  max mem: 15821
[13:05:58.977810] Test:  [50/57]  eta: 0:00:01  loss: 0.2695 (0.3184)  time: 0.1665  data: 0.0001  max mem: 15821
[13:05:59.876655] Test:  [56/57]  eta: 0:00:00  loss: 0.2817 (0.3227)  time: 0.1616  data: 0.0000  max mem: 15821
[13:05:59.953567] Test: Total time: 0:00:09 (0.1706 s / it)
[13:06:01.574741] Dice score of the network on the train images: 0.818595, val images: 0.802885
[13:06:01.578942] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:06:02.501501] Epoch: [17]  [  0/345]  eta: 0:05:17  lr: 0.000106  loss: 0.2219 (0.2219)  time: 0.9216  data: 0.3214  max mem: 15821
[13:06:14.515671] Epoch: [17]  [ 20/345]  eta: 0:03:20  lr: 0.000107  loss: 0.1916 (0.1979)  time: 0.6007  data: 0.0001  max mem: 15821
[13:06:26.544052] Epoch: [17]  [ 40/345]  eta: 0:03:05  lr: 0.000107  loss: 0.1979 (0.2024)  time: 0.6014  data: 0.0001  max mem: 15821
[13:06:38.589982] Epoch: [17]  [ 60/345]  eta: 0:02:52  lr: 0.000107  loss: 0.1896 (0.1999)  time: 0.6023  data: 0.0001  max mem: 15821
[13:06:50.636779] Epoch: [17]  [ 80/345]  eta: 0:02:40  lr: 0.000108  loss: 0.1938 (0.1987)  time: 0.6023  data: 0.0001  max mem: 15821
[13:07:02.723561] Epoch: [17]  [100/345]  eta: 0:02:28  lr: 0.000108  loss: 0.2024 (0.2002)  time: 0.6043  data: 0.0001  max mem: 15821
[13:07:14.816055] Epoch: [17]  [120/345]  eta: 0:02:16  lr: 0.000108  loss: 0.2064 (0.2013)  time: 0.6046  data: 0.0001  max mem: 15821
[13:07:26.925911] Epoch: [17]  [140/345]  eta: 0:02:04  lr: 0.000109  loss: 0.2034 (0.2020)  time: 0.6055  data: 0.0001  max mem: 15821
[13:07:39.042631] Epoch: [17]  [160/345]  eta: 0:01:51  lr: 0.000109  loss: 0.2004 (0.2010)  time: 0.6058  data: 0.0001  max mem: 15821
[13:07:51.155087] Epoch: [17]  [180/345]  eta: 0:01:39  lr: 0.000110  loss: 0.1882 (0.2004)  time: 0.6056  data: 0.0001  max mem: 15821
[13:08:03.266186] Epoch: [17]  [200/345]  eta: 0:01:27  lr: 0.000110  loss: 0.1935 (0.2001)  time: 0.6055  data: 0.0001  max mem: 15821
[13:08:15.390904] Epoch: [17]  [220/345]  eta: 0:01:15  lr: 0.000110  loss: 0.2061 (0.2007)  time: 0.6062  data: 0.0001  max mem: 15821
[13:08:27.506030] Epoch: [17]  [240/345]  eta: 0:01:03  lr: 0.000111  loss: 0.2119 (0.2013)  time: 0.6057  data: 0.0001  max mem: 15821
[13:08:39.614061] Epoch: [17]  [260/345]  eta: 0:00:51  lr: 0.000111  loss: 0.1971 (0.2011)  time: 0.6054  data: 0.0001  max mem: 15821
[13:08:51.723860] Epoch: [17]  [280/345]  eta: 0:00:39  lr: 0.000111  loss: 0.1929 (0.2008)  time: 0.6054  data: 0.0001  max mem: 15821
[13:09:03.837045] Epoch: [17]  [300/345]  eta: 0:00:27  lr: 0.000112  loss: 0.2144 (0.2016)  time: 0.6056  data: 0.0001  max mem: 15821
[13:09:15.949516] Epoch: [17]  [320/345]  eta: 0:00:15  lr: 0.000112  loss: 0.2000 (0.2021)  time: 0.6056  data: 0.0001  max mem: 15821
[13:09:28.045398] Epoch: [17]  [340/345]  eta: 0:00:03  lr: 0.000112  loss: 0.2172 (0.2029)  time: 0.6048  data: 0.0001  max mem: 15821
[13:09:30.464602] Epoch: [17]  [344/345]  eta: 0:00:00  lr: 0.000112  loss: 0.2172 (0.2030)  time: 0.6048  data: 0.0001  max mem: 15821
[13:09:30.528285] Epoch: [17] Total time: 0:03:28 (0.6056 s / it)
[13:09:30.528618] Averaged stats: lr: 0.000112  loss: 0.2172 (0.2030)
[13:09:31.019471] Test:  [  0/345]  eta: 0:02:47  loss: 0.1566 (0.1566)  time: 0.4856  data: 0.3209  max mem: 15821
[13:09:32.688341] Test:  [ 10/345]  eta: 0:01:05  loss: 0.1775 (0.1836)  time: 0.1958  data: 0.0293  max mem: 15821
[13:09:34.362133] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1890 (0.1910)  time: 0.1670  data: 0.0001  max mem: 15821
[13:09:36.037349] Test:  [ 30/345]  eta: 0:00:55  loss: 0.1952 (0.1941)  time: 0.1674  data: 0.0001  max mem: 15821
[13:09:37.716824] Test:  [ 40/345]  eta: 0:00:53  loss: 0.2040 (0.1975)  time: 0.1677  data: 0.0001  max mem: 15821
[13:09:39.399046] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1969 (0.1960)  time: 0.1680  data: 0.0001  max mem: 15821
[13:09:41.084827] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1890 (0.1980)  time: 0.1683  data: 0.0001  max mem: 15821
[13:09:42.773122] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1943 (0.1987)  time: 0.1686  data: 0.0001  max mem: 15821
[13:09:44.464575] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1977 (0.1993)  time: 0.1689  data: 0.0001  max mem: 15821
[13:09:46.160357] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1954 (0.1984)  time: 0.1693  data: 0.0001  max mem: 15821
[13:09:47.859614] Test:  [100/345]  eta: 0:00:42  loss: 0.1888 (0.1986)  time: 0.1697  data: 0.0001  max mem: 15821
[13:09:49.562627] Test:  [110/345]  eta: 0:00:40  loss: 0.1975 (0.1985)  time: 0.1700  data: 0.0001  max mem: 15821
[13:09:51.266962] Test:  [120/345]  eta: 0:00:38  loss: 0.1938 (0.1979)  time: 0.1703  data: 0.0001  max mem: 15821
[13:09:52.975469] Test:  [130/345]  eta: 0:00:36  loss: 0.1885 (0.1978)  time: 0.1706  data: 0.0001  max mem: 15821
[13:09:54.687577] Test:  [140/345]  eta: 0:00:35  loss: 0.1924 (0.1980)  time: 0.1710  data: 0.0001  max mem: 15821
[13:09:56.402117] Test:  [150/345]  eta: 0:00:33  loss: 0.1948 (0.1979)  time: 0.1713  data: 0.0001  max mem: 15821
[13:09:58.122165] Test:  [160/345]  eta: 0:00:31  loss: 0.1924 (0.1984)  time: 0.1717  data: 0.0001  max mem: 15821
[13:09:59.843895] Test:  [170/345]  eta: 0:00:29  loss: 0.1924 (0.1981)  time: 0.1720  data: 0.0001  max mem: 15821
[13:10:01.569725] Test:  [180/345]  eta: 0:00:28  loss: 0.1925 (0.1984)  time: 0.1723  data: 0.0001  max mem: 15821
[13:10:03.299536] Test:  [190/345]  eta: 0:00:26  loss: 0.2017 (0.1983)  time: 0.1727  data: 0.0001  max mem: 15821
[13:10:05.031927] Test:  [200/345]  eta: 0:00:24  loss: 0.2009 (0.1982)  time: 0.1731  data: 0.0001  max mem: 15821
[13:10:06.767576] Test:  [210/345]  eta: 0:00:23  loss: 0.1999 (0.1987)  time: 0.1733  data: 0.0001  max mem: 15821
[13:10:08.506202] Test:  [220/345]  eta: 0:00:21  loss: 0.2006 (0.1986)  time: 0.1737  data: 0.0001  max mem: 15821
[13:10:10.248710] Test:  [230/345]  eta: 0:00:19  loss: 0.1914 (0.1984)  time: 0.1740  data: 0.0001  max mem: 15821
[13:10:11.994527] Test:  [240/345]  eta: 0:00:18  loss: 0.1886 (0.1986)  time: 0.1743  data: 0.0001  max mem: 15821
[13:10:13.744804] Test:  [250/345]  eta: 0:00:16  loss: 0.1903 (0.1986)  time: 0.1747  data: 0.0001  max mem: 15821
[13:10:15.498770] Test:  [260/345]  eta: 0:00:14  loss: 0.2015 (0.1985)  time: 0.1751  data: 0.0001  max mem: 15821
[13:10:17.254292] Test:  [270/345]  eta: 0:00:12  loss: 0.1996 (0.1983)  time: 0.1754  data: 0.0001  max mem: 15821
[13:10:19.014058] Test:  [280/345]  eta: 0:00:11  loss: 0.1910 (0.1981)  time: 0.1757  data: 0.0001  max mem: 15821
[13:10:20.778210] Test:  [290/345]  eta: 0:00:09  loss: 0.1985 (0.1985)  time: 0.1761  data: 0.0001  max mem: 15821
[13:10:22.544691] Test:  [300/345]  eta: 0:00:07  loss: 0.2013 (0.1986)  time: 0.1765  data: 0.0001  max mem: 15821
[13:10:24.316262] Test:  [310/345]  eta: 0:00:06  loss: 0.1964 (0.1985)  time: 0.1768  data: 0.0001  max mem: 15821
[13:10:26.091444] Test:  [320/345]  eta: 0:00:04  loss: 0.1955 (0.1984)  time: 0.1772  data: 0.0001  max mem: 15821
[13:10:27.869547] Test:  [330/345]  eta: 0:00:02  loss: 0.1879 (0.1983)  time: 0.1776  data: 0.0001  max mem: 15821
[13:10:29.651961] Test:  [340/345]  eta: 0:00:00  loss: 0.1937 (0.1981)  time: 0.1780  data: 0.0001  max mem: 15821
[13:10:30.366516] Test:  [344/345]  eta: 0:00:00  loss: 0.1946 (0.1982)  time: 0.1781  data: 0.0001  max mem: 15821
[13:10:30.439131] Test: Total time: 0:00:59 (0.1736 s / it)
[13:10:40.304493] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4569 (0.4569)  time: 0.4479  data: 0.2851  max mem: 15821
[13:10:41.954023] Test:  [10/57]  eta: 0:00:08  loss: 0.4073 (0.4315)  time: 0.1906  data: 0.0260  max mem: 15821
[13:10:43.608723] Test:  [20/57]  eta: 0:00:06  loss: 0.4291 (0.4322)  time: 0.1651  data: 0.0001  max mem: 15821
[13:10:45.268725] Test:  [30/57]  eta: 0:00:04  loss: 0.3265 (0.3830)  time: 0.1657  data: 0.0001  max mem: 15821
[13:10:46.932762] Test:  [40/57]  eta: 0:00:02  loss: 0.2953 (0.3637)  time: 0.1661  data: 0.0001  max mem: 15821
[13:10:48.601428] Test:  [50/57]  eta: 0:00:01  loss: 0.2964 (0.3625)  time: 0.1666  data: 0.0001  max mem: 15821
[13:10:49.500846] Test:  [56/57]  eta: 0:00:00  loss: 0.3442 (0.3731)  time: 0.1617  data: 0.0000  max mem: 15821
[13:10:49.575388] Test: Total time: 0:00:09 (0.1705 s / it)
[13:10:51.230951] Dice score of the network on the train images: 0.842246, val images: 0.756453
[13:10:51.231182] saving best_prec_model_0 @ epoch 17
[13:10:52.462697] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:10:53.362428] Epoch: [18]  [  0/345]  eta: 0:05:09  lr: 0.000113  loss: 0.2119 (0.2119)  time: 0.8985  data: 0.2964  max mem: 15821
[13:11:05.362999] Epoch: [18]  [ 20/345]  eta: 0:03:19  lr: 0.000113  loss: 0.2025 (0.2097)  time: 0.6000  data: 0.0001  max mem: 15821
[13:11:17.382558] Epoch: [18]  [ 40/345]  eta: 0:03:05  lr: 0.000113  loss: 0.2006 (0.2042)  time: 0.6009  data: 0.0001  max mem: 15821
[13:11:29.432849] Epoch: [18]  [ 60/345]  eta: 0:02:52  lr: 0.000114  loss: 0.2061 (0.2038)  time: 0.6025  data: 0.0001  max mem: 15821
[13:11:41.507747] Epoch: [18]  [ 80/345]  eta: 0:02:40  lr: 0.000114  loss: 0.1858 (0.2022)  time: 0.6037  data: 0.0001  max mem: 15821
[13:11:53.699448] Epoch: [18]  [100/345]  eta: 0:02:28  lr: 0.000114  loss: 0.1854 (0.1994)  time: 0.6095  data: 0.0001  max mem: 15821
[13:12:05.814501] Epoch: [18]  [120/345]  eta: 0:02:16  lr: 0.000115  loss: 0.1817 (0.1974)  time: 0.6057  data: 0.0001  max mem: 15821
[13:12:17.942288] Epoch: [18]  [140/345]  eta: 0:02:04  lr: 0.000115  loss: 0.1966 (0.1980)  time: 0.6064  data: 0.0001  max mem: 15821
[13:12:30.069242] Epoch: [18]  [160/345]  eta: 0:01:52  lr: 0.000115  loss: 0.1994 (0.1984)  time: 0.6063  data: 0.0001  max mem: 15821
[13:12:42.192936] Epoch: [18]  [180/345]  eta: 0:01:40  lr: 0.000116  loss: 0.1924 (0.1979)  time: 0.6061  data: 0.0001  max mem: 15821
[13:12:54.319468] Epoch: [18]  [200/345]  eta: 0:01:27  lr: 0.000116  loss: 0.1862 (0.1978)  time: 0.6063  data: 0.0001  max mem: 15821
[13:13:06.443777] Epoch: [18]  [220/345]  eta: 0:01:15  lr: 0.000116  loss: 0.1963 (0.1980)  time: 0.6062  data: 0.0001  max mem: 15821
[13:13:18.578101] Epoch: [18]  [240/345]  eta: 0:01:03  lr: 0.000117  loss: 0.1812 (0.1973)  time: 0.6067  data: 0.0001  max mem: 15821
[13:13:30.701182] Epoch: [18]  [260/345]  eta: 0:00:51  lr: 0.000117  loss: 0.2014 (0.1975)  time: 0.6061  data: 0.0001  max mem: 15821
[13:13:42.826482] Epoch: [18]  [280/345]  eta: 0:00:39  lr: 0.000118  loss: 0.2040 (0.1980)  time: 0.6062  data: 0.0001  max mem: 15821
[13:13:54.946433] Epoch: [18]  [300/345]  eta: 0:00:27  lr: 0.000118  loss: 0.1903 (0.1979)  time: 0.6059  data: 0.0001  max mem: 15821
[13:14:07.063801] Epoch: [18]  [320/345]  eta: 0:00:15  lr: 0.000118  loss: 0.1966 (0.1976)  time: 0.6058  data: 0.0001  max mem: 15821
[13:14:19.177623] Epoch: [18]  [340/345]  eta: 0:00:03  lr: 0.000119  loss: 0.1886 (0.1974)  time: 0.6056  data: 0.0001  max mem: 15821
[13:14:21.599760] Epoch: [18]  [344/345]  eta: 0:00:00  lr: 0.000119  loss: 0.2010 (0.1975)  time: 0.6055  data: 0.0001  max mem: 15821
[13:14:21.663572] Epoch: [18] Total time: 0:03:29 (0.6064 s / it)
[13:14:21.663780] Averaged stats: lr: 0.000119  loss: 0.2010 (0.1975)
[13:14:22.150737] Test:  [  0/345]  eta: 0:02:46  loss: 0.1979 (0.1979)  time: 0.4819  data: 0.3173  max mem: 15821
[13:14:23.821716] Test:  [ 10/345]  eta: 0:01:05  loss: 0.1840 (0.1829)  time: 0.1956  data: 0.0289  max mem: 15821
[13:14:25.493285] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1802 (0.1868)  time: 0.1671  data: 0.0001  max mem: 15821
[13:14:27.168469] Test:  [ 30/345]  eta: 0:00:55  loss: 0.1711 (0.1839)  time: 0.1673  data: 0.0001  max mem: 15821
[13:14:28.848405] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1758 (0.1846)  time: 0.1677  data: 0.0001  max mem: 15821
[13:14:30.530980] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1824 (0.1849)  time: 0.1681  data: 0.0001  max mem: 15821
[13:14:32.216132] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1818 (0.1858)  time: 0.1683  data: 0.0001  max mem: 15821
[13:14:33.904398] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1804 (0.1845)  time: 0.1686  data: 0.0001  max mem: 15821
[13:14:35.596545] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1762 (0.1859)  time: 0.1690  data: 0.0001  max mem: 15821
[13:14:37.294754] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1852 (0.1856)  time: 0.1694  data: 0.0001  max mem: 15821
[13:14:38.994702] Test:  [100/345]  eta: 0:00:42  loss: 0.1748 (0.1848)  time: 0.1698  data: 0.0001  max mem: 15821
[13:14:40.697568] Test:  [110/345]  eta: 0:00:40  loss: 0.1707 (0.1849)  time: 0.1701  data: 0.0001  max mem: 15821
[13:14:42.403133] Test:  [120/345]  eta: 0:00:38  loss: 0.1818 (0.1853)  time: 0.1704  data: 0.0001  max mem: 15821
[13:14:44.113410] Test:  [130/345]  eta: 0:00:36  loss: 0.1687 (0.1839)  time: 0.1707  data: 0.0001  max mem: 15821
[13:14:45.825112] Test:  [140/345]  eta: 0:00:35  loss: 0.1687 (0.1846)  time: 0.1710  data: 0.0001  max mem: 15821
[13:14:47.540106] Test:  [150/345]  eta: 0:00:33  loss: 0.1781 (0.1845)  time: 0.1713  data: 0.0001  max mem: 15821
[13:14:49.259495] Test:  [160/345]  eta: 0:00:31  loss: 0.1845 (0.1848)  time: 0.1717  data: 0.0001  max mem: 15821
[13:14:50.982959] Test:  [170/345]  eta: 0:00:29  loss: 0.1853 (0.1849)  time: 0.1721  data: 0.0001  max mem: 15821
[13:14:52.708542] Test:  [180/345]  eta: 0:00:28  loss: 0.1762 (0.1850)  time: 0.1724  data: 0.0001  max mem: 15821
[13:14:54.438957] Test:  [190/345]  eta: 0:00:26  loss: 0.1796 (0.1849)  time: 0.1727  data: 0.0001  max mem: 15821
[13:14:56.172163] Test:  [200/345]  eta: 0:00:24  loss: 0.1859 (0.1855)  time: 0.1731  data: 0.0001  max mem: 15821
[13:14:57.909045] Test:  [210/345]  eta: 0:00:23  loss: 0.1893 (0.1856)  time: 0.1734  data: 0.0001  max mem: 15821
[13:14:59.648647] Test:  [220/345]  eta: 0:00:21  loss: 0.1857 (0.1860)  time: 0.1738  data: 0.0001  max mem: 15821
[13:15:01.391614] Test:  [230/345]  eta: 0:00:19  loss: 0.1839 (0.1860)  time: 0.1741  data: 0.0001  max mem: 15821
[13:15:03.137767] Test:  [240/345]  eta: 0:00:18  loss: 0.1774 (0.1860)  time: 0.1744  data: 0.0001  max mem: 15821
[13:15:04.890015] Test:  [250/345]  eta: 0:00:16  loss: 0.1924 (0.1865)  time: 0.1749  data: 0.0001  max mem: 15821
[13:15:06.644573] Test:  [260/345]  eta: 0:00:14  loss: 0.1924 (0.1866)  time: 0.1753  data: 0.0001  max mem: 15821
[13:15:08.401442] Test:  [270/345]  eta: 0:00:12  loss: 0.1834 (0.1868)  time: 0.1755  data: 0.0001  max mem: 15821
[13:15:10.162126] Test:  [280/345]  eta: 0:00:11  loss: 0.1834 (0.1869)  time: 0.1758  data: 0.0001  max mem: 15821
[13:15:11.926669] Test:  [290/345]  eta: 0:00:09  loss: 0.1785 (0.1869)  time: 0.1762  data: 0.0001  max mem: 15821
[13:15:13.694993] Test:  [300/345]  eta: 0:00:07  loss: 0.1736 (0.1864)  time: 0.1766  data: 0.0001  max mem: 15821
[13:15:15.466764] Test:  [310/345]  eta: 0:00:06  loss: 0.1711 (0.1859)  time: 0.1769  data: 0.0001  max mem: 15821
[13:15:17.241477] Test:  [320/345]  eta: 0:00:04  loss: 0.1739 (0.1861)  time: 0.1773  data: 0.0001  max mem: 15821
[13:15:19.020262] Test:  [330/345]  eta: 0:00:02  loss: 0.1742 (0.1856)  time: 0.1776  data: 0.0001  max mem: 15821
[13:15:20.803329] Test:  [340/345]  eta: 0:00:00  loss: 0.1799 (0.1859)  time: 0.1780  data: 0.0001  max mem: 15821
[13:15:21.517510] Test:  [344/345]  eta: 0:00:00  loss: 0.1810 (0.1857)  time: 0.1782  data: 0.0001  max mem: 15821
[13:15:21.591218] Test: Total time: 0:00:59 (0.1737 s / it)
[13:15:31.497490] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4527 (0.4527)  time: 0.4514  data: 0.2888  max mem: 15821
[13:15:33.147010] Test:  [10/57]  eta: 0:00:08  loss: 0.3887 (0.4252)  time: 0.1909  data: 0.0263  max mem: 15821
[13:15:34.802425] Test:  [20/57]  eta: 0:00:06  loss: 0.3887 (0.4125)  time: 0.1652  data: 0.0001  max mem: 15821
[13:15:36.462877] Test:  [30/57]  eta: 0:00:04  loss: 0.2875 (0.3561)  time: 0.1657  data: 0.0001  max mem: 15821
[13:15:38.127087] Test:  [40/57]  eta: 0:00:02  loss: 0.2475 (0.3330)  time: 0.1662  data: 0.0001  max mem: 15821
[13:15:39.795178] Test:  [50/57]  eta: 0:00:01  loss: 0.2703 (0.3329)  time: 0.1666  data: 0.0001  max mem: 15821
[13:15:40.695579] Test:  [56/57]  eta: 0:00:00  loss: 0.2761 (0.3367)  time: 0.1617  data: 0.0000  max mem: 15821
[13:15:40.764608] Test: Total time: 0:00:09 (0.1705 s / it)
[13:15:42.425989] Dice score of the network on the train images: 0.830652, val images: 0.810644
[13:15:42.430033] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:15:43.329031] Epoch: [19]  [  0/345]  eta: 0:05:09  lr: 0.000119  loss: 0.1866 (0.1866)  time: 0.8979  data: 0.2956  max mem: 15821
[13:15:55.331564] Epoch: [19]  [ 20/345]  eta: 0:03:19  lr: 0.000119  loss: 0.1997 (0.1947)  time: 0.6001  data: 0.0001  max mem: 15821
[13:16:07.362905] Epoch: [19]  [ 40/345]  eta: 0:03:05  lr: 0.000119  loss: 0.1800 (0.1909)  time: 0.6015  data: 0.0001  max mem: 15821
[13:16:19.426356] Epoch: [19]  [ 60/345]  eta: 0:02:52  lr: 0.000120  loss: 0.1717 (0.1877)  time: 0.6031  data: 0.0001  max mem: 15821
[13:16:31.486602] Epoch: [19]  [ 80/345]  eta: 0:02:40  lr: 0.000120  loss: 0.1769 (0.1874)  time: 0.6030  data: 0.0001  max mem: 15821
[13:16:43.555948] Epoch: [19]  [100/345]  eta: 0:02:28  lr: 0.000121  loss: 0.1887 (0.1886)  time: 0.6034  data: 0.0001  max mem: 15821
[13:16:55.637864] Epoch: [19]  [120/345]  eta: 0:02:16  lr: 0.000121  loss: 0.1979 (0.1900)  time: 0.6041  data: 0.0001  max mem: 15821
[13:17:07.729449] Epoch: [19]  [140/345]  eta: 0:02:04  lr: 0.000121  loss: 0.1791 (0.1891)  time: 0.6045  data: 0.0001  max mem: 15821
[13:17:19.828271] Epoch: [19]  [160/345]  eta: 0:01:51  lr: 0.000122  loss: 0.1742 (0.1876)  time: 0.6049  data: 0.0001  max mem: 15821
[13:17:31.958957] Epoch: [19]  [180/345]  eta: 0:01:39  lr: 0.000122  loss: 0.1924 (0.1884)  time: 0.6065  data: 0.0001  max mem: 15821
[13:17:44.085087] Epoch: [19]  [200/345]  eta: 0:01:27  lr: 0.000122  loss: 0.2006 (0.1899)  time: 0.6063  data: 0.0001  max mem: 15821
[13:17:56.207063] Epoch: [19]  [220/345]  eta: 0:01:15  lr: 0.000123  loss: 0.1864 (0.1898)  time: 0.6061  data: 0.0001  max mem: 15821
[13:18:08.334888] Epoch: [19]  [240/345]  eta: 0:01:03  lr: 0.000123  loss: 0.1766 (0.1890)  time: 0.6063  data: 0.0001  max mem: 15821
[13:18:20.452077] Epoch: [19]  [260/345]  eta: 0:00:51  lr: 0.000123  loss: 0.1891 (0.1895)  time: 0.6058  data: 0.0001  max mem: 15821
[13:18:32.571180] Epoch: [19]  [280/345]  eta: 0:00:39  lr: 0.000124  loss: 0.1999 (0.1906)  time: 0.6059  data: 0.0001  max mem: 15821
[13:18:44.679172] Epoch: [19]  [300/345]  eta: 0:00:27  lr: 0.000124  loss: 0.1917 (0.1907)  time: 0.6054  data: 0.0001  max mem: 15821
[13:18:56.789031] Epoch: [19]  [320/345]  eta: 0:00:15  lr: 0.000125  loss: 0.1981 (0.1913)  time: 0.6054  data: 0.0001  max mem: 15821
[13:19:08.894592] Epoch: [19]  [340/345]  eta: 0:00:03  lr: 0.000125  loss: 0.1920 (0.1919)  time: 0.6052  data: 0.0001  max mem: 15821
[13:19:11.316707] Epoch: [19]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.1920 (0.1921)  time: 0.6053  data: 0.0001  max mem: 15821
[13:19:11.387396] Epoch: [19] Total time: 0:03:28 (0.6057 s / it)
[13:19:11.387628] Averaged stats: lr: 0.000125  loss: 0.1920 (0.1921)
[13:19:11.887787] Test:  [  0/345]  eta: 0:02:50  loss: 0.1774 (0.1774)  time: 0.4946  data: 0.3299  max mem: 15821
[13:19:13.558508] Test:  [ 10/345]  eta: 0:01:05  loss: 0.1713 (0.1793)  time: 0.1967  data: 0.0301  max mem: 15821
[13:19:15.231699] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1752 (0.1812)  time: 0.1671  data: 0.0001  max mem: 15821
[13:19:16.908176] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1752 (0.1811)  time: 0.1674  data: 0.0001  max mem: 15821
[13:19:18.587856] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1731 (0.1810)  time: 0.1677  data: 0.0001  max mem: 15821
[13:19:20.269563] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1765 (0.1828)  time: 0.1680  data: 0.0001  max mem: 15821
[13:19:21.954486] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1867 (0.1842)  time: 0.1683  data: 0.0001  max mem: 15821
[13:19:23.643685] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1904 (0.1844)  time: 0.1686  data: 0.0001  max mem: 15821
[13:19:25.336617] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1958 (0.1871)  time: 0.1690  data: 0.0001  max mem: 15821
[13:19:27.032677] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1939 (0.1872)  time: 0.1694  data: 0.0001  max mem: 15821
[13:19:28.732396] Test:  [100/345]  eta: 0:00:42  loss: 0.1855 (0.1878)  time: 0.1697  data: 0.0001  max mem: 15821
[13:19:30.434975] Test:  [110/345]  eta: 0:00:40  loss: 0.1843 (0.1871)  time: 0.1700  data: 0.0001  max mem: 15821
[13:19:32.140335] Test:  [120/345]  eta: 0:00:38  loss: 0.1775 (0.1873)  time: 0.1703  data: 0.0001  max mem: 15821
[13:19:33.848355] Test:  [130/345]  eta: 0:00:36  loss: 0.1750 (0.1864)  time: 0.1706  data: 0.0001  max mem: 15821
[13:19:35.560471] Test:  [140/345]  eta: 0:00:35  loss: 0.1750 (0.1862)  time: 0.1709  data: 0.0001  max mem: 15821
[13:19:37.275047] Test:  [150/345]  eta: 0:00:33  loss: 0.1879 (0.1872)  time: 0.1713  data: 0.0001  max mem: 15821
[13:19:38.994382] Test:  [160/345]  eta: 0:00:31  loss: 0.1931 (0.1870)  time: 0.1716  data: 0.0001  max mem: 15821
[13:19:40.718364] Test:  [170/345]  eta: 0:00:30  loss: 0.1763 (0.1863)  time: 0.1721  data: 0.0001  max mem: 15821
[13:19:42.443363] Test:  [180/345]  eta: 0:00:28  loss: 0.1763 (0.1869)  time: 0.1724  data: 0.0001  max mem: 15821
[13:19:44.172038] Test:  [190/345]  eta: 0:00:26  loss: 0.1920 (0.1870)  time: 0.1726  data: 0.0001  max mem: 15821
[13:19:45.904155] Test:  [200/345]  eta: 0:00:24  loss: 0.1860 (0.1874)  time: 0.1730  data: 0.0001  max mem: 15821
[13:19:47.639878] Test:  [210/345]  eta: 0:00:23  loss: 0.1860 (0.1875)  time: 0.1733  data: 0.0001  max mem: 15821
[13:19:49.379854] Test:  [220/345]  eta: 0:00:21  loss: 0.1778 (0.1871)  time: 0.1737  data: 0.0001  max mem: 15821
[13:19:51.123163] Test:  [230/345]  eta: 0:00:19  loss: 0.1814 (0.1879)  time: 0.1741  data: 0.0001  max mem: 15821
[13:19:52.871881] Test:  [240/345]  eta: 0:00:18  loss: 0.2096 (0.1884)  time: 0.1745  data: 0.0001  max mem: 15821
[13:19:54.621669] Test:  [250/345]  eta: 0:00:16  loss: 0.1796 (0.1880)  time: 0.1749  data: 0.0001  max mem: 15821
[13:19:56.375555] Test:  [260/345]  eta: 0:00:14  loss: 0.1770 (0.1879)  time: 0.1751  data: 0.0001  max mem: 15821
[13:19:58.133624] Test:  [270/345]  eta: 0:00:12  loss: 0.1816 (0.1878)  time: 0.1755  data: 0.0001  max mem: 15821
[13:19:59.894912] Test:  [280/345]  eta: 0:00:11  loss: 0.1831 (0.1876)  time: 0.1759  data: 0.0001  max mem: 15821
[13:20:01.658818] Test:  [290/345]  eta: 0:00:09  loss: 0.1856 (0.1877)  time: 0.1762  data: 0.0001  max mem: 15821
[13:20:03.425210] Test:  [300/345]  eta: 0:00:07  loss: 0.1758 (0.1874)  time: 0.1765  data: 0.0001  max mem: 15821
[13:20:05.197231] Test:  [310/345]  eta: 0:00:06  loss: 0.1758 (0.1872)  time: 0.1769  data: 0.0001  max mem: 15821
[13:20:06.972293] Test:  [320/345]  eta: 0:00:04  loss: 0.1900 (0.1875)  time: 0.1773  data: 0.0001  max mem: 15821
[13:20:08.750414] Test:  [330/345]  eta: 0:00:02  loss: 0.2016 (0.1876)  time: 0.1776  data: 0.0001  max mem: 15821
[13:20:10.533977] Test:  [340/345]  eta: 0:00:00  loss: 0.1890 (0.1877)  time: 0.1780  data: 0.0001  max mem: 15821
[13:20:11.246164] Test:  [344/345]  eta: 0:00:00  loss: 0.1837 (0.1876)  time: 0.1781  data: 0.0001  max mem: 15821
[13:20:11.319299] Test: Total time: 0:00:59 (0.1737 s / it)
[13:20:21.154955] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4328 (0.4328)  time: 0.4526  data: 0.2896  max mem: 15821
[13:20:22.804430] Test:  [10/57]  eta: 0:00:08  loss: 0.3925 (0.4059)  time: 0.1910  data: 0.0264  max mem: 15821
[13:20:24.459002] Test:  [20/57]  eta: 0:00:06  loss: 0.3789 (0.3888)  time: 0.1651  data: 0.0001  max mem: 15821
[13:20:26.118742] Test:  [30/57]  eta: 0:00:04  loss: 0.2785 (0.3372)  time: 0.1657  data: 0.0001  max mem: 15821
[13:20:27.783255] Test:  [40/57]  eta: 0:00:02  loss: 0.2219 (0.3136)  time: 0.1661  data: 0.0001  max mem: 15821
[13:20:29.450701] Test:  [50/57]  eta: 0:00:01  loss: 0.2618 (0.3124)  time: 0.1665  data: 0.0001  max mem: 15821
[13:20:30.351679] Test:  [56/57]  eta: 0:00:00  loss: 0.2800 (0.3200)  time: 0.1617  data: 0.0000  max mem: 15821
[13:20:30.420580] Test: Total time: 0:00:09 (0.1705 s / it)
[13:20:32.083079] Dice score of the network on the train images: 0.821820, val images: 0.800495
[13:20:32.087817] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:20:32.991814] Epoch: [20]  [  0/345]  eta: 0:05:11  lr: 0.000125  loss: 0.1874 (0.1874)  time: 0.9028  data: 0.3005  max mem: 15821
[13:20:45.010614] Epoch: [20]  [ 20/345]  eta: 0:03:19  lr: 0.000125  loss: 0.1730 (0.1834)  time: 0.6009  data: 0.0001  max mem: 15821
[13:20:57.067559] Epoch: [20]  [ 40/345]  eta: 0:03:05  lr: 0.000125  loss: 0.1810 (0.1853)  time: 0.6028  data: 0.0001  max mem: 15821
[13:21:09.128533] Epoch: [20]  [ 60/345]  eta: 0:02:53  lr: 0.000125  loss: 0.1767 (0.1833)  time: 0.6030  data: 0.0001  max mem: 15821

[13:21:21.203138] Epoch: [20]  [ 80/345]  eta: 0:02:40  lr: 0.000125  loss: 0.1803 (0.1841)  time: 0.6037  data: 0.0001  max mem: 15821
[13:21:33.285254] Epoch: [20]  [100/345]  eta: 0:02:28  lr: 0.000125  loss: 0.1861 (0.1852)  time: 0.6041  data: 0.0001  max mem: 15821
[13:21:45.376975] Epoch: [20]  [120/345]  eta: 0:02:16  lr: 0.000125  loss: 0.1795 (0.1842)  time: 0.6045  data: 0.0001  max mem: 15821
[13:21:57.483257] Epoch: [20]  [140/345]  eta: 0:02:04  lr: 0.000125  loss: 0.1898 (0.1860)  time: 0.6053  data: 0.0001  max mem: 15821
[13:22:09.596054] Epoch: [20]  [160/345]  eta: 0:01:52  lr: 0.000125  loss: 0.1900 (0.1869)  time: 0.6056  data: 0.0001  max mem: 15821
[13:22:21.713352] Epoch: [20]  [180/345]  eta: 0:01:39  lr: 0.000125  loss: 0.1811 (0.1870)  time: 0.6058  data: 0.0001  max mem: 15821
[13:22:33.833355] Epoch: [20]  [200/345]  eta: 0:01:27  lr: 0.000125  loss: 0.1818 (0.1867)  time: 0.6060  data: 0.0001  max mem: 15821
[13:22:45.923087] Epoch: [20]  [220/345]  eta: 0:01:15  lr: 0.000125  loss: 0.1797 (0.1867)  time: 0.6044  data: 0.0001  max mem: 15821
[13:22:58.023823] Epoch: [20]  [240/345]  eta: 0:01:03  lr: 0.000125  loss: 0.1810 (0.1865)  time: 0.6050  data: 0.0001  max mem: 15821
[13:23:10.126663] Epoch: [20]  [260/345]  eta: 0:00:51  lr: 0.000125  loss: 0.1856 (0.1863)  time: 0.6051  data: 0.0001  max mem: 15821
[13:23:22.214138] Epoch: [20]  [280/345]  eta: 0:00:39  lr: 0.000125  loss: 0.1742 (0.1858)  time: 0.6043  data: 0.0001  max mem: 15821
[13:23:34.300777] Epoch: [20]  [300/345]  eta: 0:00:27  lr: 0.000125  loss: 0.1781 (0.1856)  time: 0.6043  data: 0.0001  max mem: 15821
[13:23:46.473930] Epoch: [20]  [320/345]  eta: 0:00:15  lr: 0.000125  loss: 0.2318 (0.1883)  time: 0.6086  data: 0.0001  max mem: 15821
[13:23:58.560890] Epoch: [20]  [340/345]  eta: 0:00:03  lr: 0.000125  loss: 0.1932 (0.1887)  time: 0.6043  data: 0.0001  max mem: 15821
[13:24:00.977387] Epoch: [20]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.1958 (0.1891)  time: 0.6042  data: 0.0001  max mem: 15821
[13:24:01.048586] Epoch: [20] Total time: 0:03:28 (0.6057 s / it)
[13:24:01.048800] Averaged stats: lr: 0.000125  loss: 0.1958 (0.1891)
[13:24:01.585634] Test:  [  0/345]  eta: 0:03:03  loss: 0.1745 (0.1745)  time: 0.5317  data: 0.3678  max mem: 15821
[13:24:03.252865] Test:  [ 10/345]  eta: 0:01:06  loss: 0.1808 (0.1919)  time: 0.1998  data: 0.0335  max mem: 15821
[13:24:04.923516] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1807 (0.1859)  time: 0.1668  data: 0.0001  max mem: 15821
[13:24:06.596600] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1764 (0.1885)  time: 0.1671  data: 0.0001  max mem: 15821
[13:24:08.273539] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1901 (0.1881)  time: 0.1674  data: 0.0001  max mem: 15821
[13:24:09.953056] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1901 (0.1878)  time: 0.1678  data: 0.0001  max mem: 15821
[13:24:11.635984] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1819 (0.1865)  time: 0.1681  data: 0.0001  max mem: 15821
[13:24:13.324720] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1796 (0.1861)  time: 0.1685  data: 0.0001  max mem: 15821
[13:24:15.014566] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1899 (0.1858)  time: 0.1689  data: 0.0001  max mem: 15821
[13:24:16.707958] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1899 (0.1859)  time: 0.1691  data: 0.0001  max mem: 15821
[13:24:18.405584] Test:  [100/345]  eta: 0:00:42  loss: 0.1918 (0.1870)  time: 0.1695  data: 0.0001  max mem: 15821
[13:24:20.106808] Test:  [110/345]  eta: 0:00:40  loss: 0.1877 (0.1871)  time: 0.1699  data: 0.0001  max mem: 15821
[13:24:21.811138] Test:  [120/345]  eta: 0:00:38  loss: 0.1741 (0.1861)  time: 0.1702  data: 0.0001  max mem: 15821
[13:24:23.519193] Test:  [130/345]  eta: 0:00:36  loss: 0.1755 (0.1853)  time: 0.1706  data: 0.0001  max mem: 15821
[13:24:25.230426] Test:  [140/345]  eta: 0:00:35  loss: 0.1768 (0.1848)  time: 0.1709  data: 0.0001  max mem: 15821
[13:24:26.944528] Test:  [150/345]  eta: 0:00:33  loss: 0.1789 (0.1846)  time: 0.1712  data: 0.0001  max mem: 15821
[13:24:28.662793] Test:  [160/345]  eta: 0:00:31  loss: 0.1793 (0.1842)  time: 0.1716  data: 0.0001  max mem: 15821
[13:24:30.383359] Test:  [170/345]  eta: 0:00:30  loss: 0.1797 (0.1840)  time: 0.1719  data: 0.0001  max mem: 15821
[13:24:32.108162] Test:  [180/345]  eta: 0:00:28  loss: 0.1813 (0.1847)  time: 0.1722  data: 0.0001  max mem: 15821
[13:24:33.836274] Test:  [190/345]  eta: 0:00:26  loss: 0.1873 (0.1850)  time: 0.1726  data: 0.0001  max mem: 15821
[13:24:35.566798] Test:  [200/345]  eta: 0:00:24  loss: 0.1897 (0.1856)  time: 0.1729  data: 0.0001  max mem: 15821
[13:24:37.302072] Test:  [210/345]  eta: 0:00:23  loss: 0.1907 (0.1858)  time: 0.1732  data: 0.0001  max mem: 15821
[13:24:39.039099] Test:  [220/345]  eta: 0:00:21  loss: 0.1929 (0.1864)  time: 0.1736  data: 0.0001  max mem: 15821
[13:24:40.781295] Test:  [230/345]  eta: 0:00:19  loss: 0.1912 (0.1863)  time: 0.1739  data: 0.0001  max mem: 15821
[13:24:42.526253] Test:  [240/345]  eta: 0:00:18  loss: 0.1857 (0.1861)  time: 0.1743  data: 0.0001  max mem: 15821
[13:24:44.274336] Test:  [250/345]  eta: 0:00:16  loss: 0.1825 (0.1856)  time: 0.1746  data: 0.0001  max mem: 15821
[13:24:46.025857] Test:  [260/345]  eta: 0:00:14  loss: 0.1825 (0.1860)  time: 0.1749  data: 0.0001  max mem: 15821
[13:24:47.782208] Test:  [270/345]  eta: 0:00:12  loss: 0.1810 (0.1856)  time: 0.1753  data: 0.0001  max mem: 15821
[13:24:49.541574] Test:  [280/345]  eta: 0:00:11  loss: 0.1795 (0.1855)  time: 0.1757  data: 0.0001  max mem: 15821
[13:24:51.304305] Test:  [290/345]  eta: 0:00:09  loss: 0.1890 (0.1860)  time: 0.1760  data: 0.0001  max mem: 15821
[13:24:53.069408] Test:  [300/345]  eta: 0:00:07  loss: 0.1917 (0.1859)  time: 0.1763  data: 0.0001  max mem: 15821
[13:24:54.840642] Test:  [310/345]  eta: 0:00:06  loss: 0.1790 (0.1856)  time: 0.1768  data: 0.0001  max mem: 15821
[13:24:56.612783] Test:  [320/345]  eta: 0:00:04  loss: 0.1794 (0.1855)  time: 0.1771  data: 0.0001  max mem: 15821
[13:24:58.389982] Test:  [330/345]  eta: 0:00:02  loss: 0.1773 (0.1853)  time: 0.1774  data: 0.0001  max mem: 15821
[13:25:00.170776] Test:  [340/345]  eta: 0:00:00  loss: 0.1773 (0.1855)  time: 0.1778  data: 0.0001  max mem: 15821
[13:25:00.884908] Test:  [344/345]  eta: 0:00:00  loss: 0.1773 (0.1855)  time: 0.1780  data: 0.0001  max mem: 15821
[13:25:00.944974] Test: Total time: 0:00:59 (0.1736 s / it)
[13:25:10.885852] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4391 (0.4391)  time: 0.4565  data: 0.2936  max mem: 15821
[13:25:12.536239] Test:  [10/57]  eta: 0:00:08  loss: 0.3879 (0.4045)  time: 0.1914  data: 0.0268  max mem: 15821
[13:25:14.191614] Test:  [20/57]  eta: 0:00:06  loss: 0.3945 (0.3965)  time: 0.1652  data: 0.0001  max mem: 15821
[13:25:15.850504] Test:  [30/57]  eta: 0:00:04  loss: 0.2883 (0.3439)  time: 0.1657  data: 0.0001  max mem: 15821
[13:25:17.514079] Test:  [40/57]  eta: 0:00:02  loss: 0.2293 (0.3227)  time: 0.1661  data: 0.0001  max mem: 15821
[13:25:19.181779] Test:  [50/57]  eta: 0:00:01  loss: 0.2608 (0.3190)  time: 0.1665  data: 0.0001  max mem: 15821
[13:25:20.081760] Test:  [56/57]  eta: 0:00:00  loss: 0.2735 (0.3224)  time: 0.1616  data: 0.0000  max mem: 15821
[13:25:20.152981] Test: Total time: 0:00:09 (0.1706 s / it)
[13:25:21.807807] Dice score of the network on the train images: 0.833562, val images: 0.812776
[13:25:21.808049] saving best_dice_model_0 @ epoch 20
[13:25:22.989909] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:25:23.909270] Epoch: [21]  [  0/345]  eta: 0:05:16  lr: 0.000125  loss: 0.1963 (0.1963)  time: 0.9184  data: 0.3168  max mem: 15821
[13:25:35.922943] Epoch: [21]  [ 20/345]  eta: 0:03:20  lr: 0.000125  loss: 0.1793 (0.1848)  time: 0.6006  data: 0.0001  max mem: 15821
[13:25:47.967990] Epoch: [21]  [ 40/345]  eta: 0:03:05  lr: 0.000125  loss: 0.1986 (0.1905)  time: 0.6022  data: 0.0001  max mem: 15821
[13:26:00.033353] Epoch: [21]  [ 60/345]  eta: 0:02:53  lr: 0.000125  loss: 0.1862 (0.1898)  time: 0.6032  data: 0.0001  max mem: 15821
[13:26:12.103111] Epoch: [21]  [ 80/345]  eta: 0:02:40  lr: 0.000124  loss: 0.1682 (0.1866)  time: 0.6034  data: 0.0001  max mem: 15821
[13:26:24.183950] Epoch: [21]  [100/345]  eta: 0:02:28  lr: 0.000124  loss: 0.1822 (0.1880)  time: 0.6040  data: 0.0001  max mem: 15821
[13:26:36.286954] Epoch: [21]  [120/345]  eta: 0:02:16  lr: 0.000124  loss: 0.1704 (0.1865)  time: 0.6051  data: 0.0001  max mem: 15821
[13:26:48.405458] Epoch: [21]  [140/345]  eta: 0:02:04  lr: 0.000124  loss: 0.1784 (0.1853)  time: 0.6059  data: 0.0001  max mem: 15821
[13:27:00.534479] Epoch: [21]  [160/345]  eta: 0:01:52  lr: 0.000124  loss: 0.1883 (0.1858)  time: 0.6064  data: 0.0001  max mem: 15821
[13:27:12.664525] Epoch: [21]  [180/345]  eta: 0:01:39  lr: 0.000124  loss: 0.1854 (0.1858)  time: 0.6065  data: 0.0001  max mem: 15821
[13:27:24.783922] Epoch: [21]  [200/345]  eta: 0:01:27  lr: 0.000124  loss: 0.1656 (0.1846)  time: 0.6059  data: 0.0001  max mem: 15821
[13:27:36.895244] Epoch: [21]  [220/345]  eta: 0:01:15  lr: 0.000124  loss: 0.1792 (0.1844)  time: 0.6055  data: 0.0001  max mem: 15821
[13:27:48.999791] Epoch: [21]  [240/345]  eta: 0:01:03  lr: 0.000124  loss: 0.1821 (0.1842)  time: 0.6052  data: 0.0001  max mem: 15821
[13:28:01.090809] Epoch: [21]  [260/345]  eta: 0:00:51  lr: 0.000124  loss: 0.1731 (0.1836)  time: 0.6045  data: 0.0001  max mem: 15821
[13:28:13.187372] Epoch: [21]  [280/345]  eta: 0:00:39  lr: 0.000124  loss: 0.1933 (0.1842)  time: 0.6048  data: 0.0001  max mem: 15821
[13:28:25.279434] Epoch: [21]  [300/345]  eta: 0:00:27  lr: 0.000124  loss: 0.1857 (0.1843)  time: 0.6045  data: 0.0001  max mem: 15821
[13:28:37.366469] Epoch: [21]  [320/345]  eta: 0:00:15  lr: 0.000124  loss: 0.1719 (0.1840)  time: 0.6043  data: 0.0001  max mem: 15821
[13:28:49.443244] Epoch: [21]  [340/345]  eta: 0:00:03  lr: 0.000124  loss: 0.1748 (0.1838)  time: 0.6038  data: 0.0001  max mem: 15821
[13:28:51.858658] Epoch: [21]  [344/345]  eta: 0:00:00  lr: 0.000124  loss: 0.1742 (0.1839)  time: 0.6038  data: 0.0001  max mem: 15821
[13:28:51.937535] Epoch: [21] Total time: 0:03:28 (0.6056 s / it)
[13:28:51.937962] Averaged stats: lr: 0.000124  loss: 0.1742 (0.1839)
[13:28:52.420359] Test:  [  0/345]  eta: 0:02:44  loss: 0.1433 (0.1433)  time: 0.4767  data: 0.3122  max mem: 15821
[13:28:54.088272] Test:  [ 10/345]  eta: 0:01:05  loss: 0.1683 (0.1686)  time: 0.1949  data: 0.0285  max mem: 15821
[13:28:55.759108] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1729 (0.1710)  time: 0.1669  data: 0.0001  max mem: 15821
[13:28:57.434803] Test:  [ 30/345]  eta: 0:00:55  loss: 0.1731 (0.1700)  time: 0.1673  data: 0.0001  max mem: 15821
[13:28:59.112556] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1743 (0.1715)  time: 0.1676  data: 0.0001  max mem: 15821
[13:29:00.792696] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1693 (0.1697)  time: 0.1678  data: 0.0001  max mem: 15821
[13:29:02.476898] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1676 (0.1714)  time: 0.1682  data: 0.0001  max mem: 15821
[13:29:04.164197] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1709 (0.1718)  time: 0.1685  data: 0.0001  max mem: 15821
[13:29:05.855269] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1762 (0.1730)  time: 0.1689  data: 0.0001  max mem: 15821
[13:29:07.549720] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1769 (0.1727)  time: 0.1692  data: 0.0001  max mem: 15821
[13:29:09.248326] Test:  [100/345]  eta: 0:00:41  loss: 0.1685 (0.1728)  time: 0.1696  data: 0.0001  max mem: 15821
[13:29:10.950794] Test:  [110/345]  eta: 0:00:40  loss: 0.1701 (0.1728)  time: 0.1700  data: 0.0001  max mem: 15821
[13:29:12.656037] Test:  [120/345]  eta: 0:00:38  loss: 0.1663 (0.1719)  time: 0.1703  data: 0.0001  max mem: 15821
[13:29:14.364205] Test:  [130/345]  eta: 0:00:36  loss: 0.1608 (0.1717)  time: 0.1706  data: 0.0001  max mem: 15821
[13:29:16.075587] Test:  [140/345]  eta: 0:00:35  loss: 0.1694 (0.1726)  time: 0.1709  data: 0.0001  max mem: 15821
[13:29:17.790568] Test:  [150/345]  eta: 0:00:33  loss: 0.1729 (0.1723)  time: 0.1713  data: 0.0001  max mem: 15821
[13:29:19.508664] Test:  [160/345]  eta: 0:00:31  loss: 0.1671 (0.1728)  time: 0.1716  data: 0.0001  max mem: 15821
[13:29:21.231227] Test:  [170/345]  eta: 0:00:29  loss: 0.1710 (0.1733)  time: 0.1720  data: 0.0001  max mem: 15821
[13:29:22.954882] Test:  [180/345]  eta: 0:00:28  loss: 0.1710 (0.1732)  time: 0.1723  data: 0.0001  max mem: 15821
[13:29:24.683840] Test:  [190/345]  eta: 0:00:26  loss: 0.1757 (0.1735)  time: 0.1726  data: 0.0001  max mem: 15821
[13:29:26.417177] Test:  [200/345]  eta: 0:00:24  loss: 0.1652 (0.1730)  time: 0.1731  data: 0.0001  max mem: 15821
[13:29:28.152941] Test:  [210/345]  eta: 0:00:23  loss: 0.1650 (0.1731)  time: 0.1734  data: 0.0001  max mem: 15821
[13:29:29.890530] Test:  [220/345]  eta: 0:00:21  loss: 0.1796 (0.1736)  time: 0.1736  data: 0.0001  max mem: 15821
[13:29:31.632081] Test:  [230/345]  eta: 0:00:19  loss: 0.1776 (0.1732)  time: 0.1739  data: 0.0001  max mem: 15821
[13:29:33.377734] Test:  [240/345]  eta: 0:00:18  loss: 0.1659 (0.1729)  time: 0.1743  data: 0.0001  max mem: 15821
[13:29:35.128278] Test:  [250/345]  eta: 0:00:16  loss: 0.1587 (0.1725)  time: 0.1748  data: 0.0001  max mem: 15821
[13:29:36.879518] Test:  [260/345]  eta: 0:00:14  loss: 0.1648 (0.1726)  time: 0.1750  data: 0.0001  max mem: 15821
[13:29:38.634971] Test:  [270/345]  eta: 0:00:12  loss: 0.1698 (0.1723)  time: 0.1753  data: 0.0001  max mem: 15821
[13:29:40.394604] Test:  [280/345]  eta: 0:00:11  loss: 0.1757 (0.1728)  time: 0.1757  data: 0.0001  max mem: 15821
[13:29:42.157008] Test:  [290/345]  eta: 0:00:09  loss: 0.1866 (0.1732)  time: 0.1760  data: 0.0001  max mem: 15821
[13:29:43.923316] Test:  [300/345]  eta: 0:00:07  loss: 0.1791 (0.1733)  time: 0.1764  data: 0.0001  max mem: 15821
[13:29:45.693714] Test:  [310/345]  eta: 0:00:06  loss: 0.1709 (0.1733)  time: 0.1768  data: 0.0001  max mem: 15821
[13:29:47.469626] Test:  [320/345]  eta: 0:00:04  loss: 0.1667 (0.1732)  time: 0.1773  data: 0.0001  max mem: 15821
[13:29:49.248173] Test:  [330/345]  eta: 0:00:02  loss: 0.1711 (0.1735)  time: 0.1777  data: 0.0001  max mem: 15821
[13:29:51.030349] Test:  [340/345]  eta: 0:00:00  loss: 0.1786 (0.1733)  time: 0.1780  data: 0.0001  max mem: 15821
[13:29:51.744156] Test:  [344/345]  eta: 0:00:00  loss: 0.1759 (0.1734)  time: 0.1782  data: 0.0001  max mem: 15821
[13:29:51.814468] Test: Total time: 0:00:59 (0.1735 s / it)
[13:30:01.655030] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4462 (0.4462)  time: 0.4581  data: 0.2954  max mem: 15821
[13:30:03.306046] Test:  [10/57]  eta: 0:00:09  loss: 0.3790 (0.4116)  time: 0.1916  data: 0.0269  max mem: 15821
[13:30:04.962430] Test:  [20/57]  eta: 0:00:06  loss: 0.3790 (0.3978)  time: 0.1653  data: 0.0001  max mem: 15821
[13:30:06.624166] Test:  [30/57]  eta: 0:00:04  loss: 0.2674 (0.3380)  time: 0.1658  data: 0.0001  max mem: 15821
[13:30:08.288555] Test:  [40/57]  eta: 0:00:02  loss: 0.2318 (0.3127)  time: 0.1662  data: 0.0001  max mem: 15821
[13:30:09.959299] Test:  [50/57]  eta: 0:00:01  loss: 0.2383 (0.3116)  time: 0.1667  data: 0.0001  max mem: 15821
[13:30:10.861532] Test:  [56/57]  eta: 0:00:00  loss: 0.2604 (0.3187)  time: 0.1619  data: 0.0000  max mem: 15821
[13:30:10.927289] Test: Total time: 0:00:09 (0.1707 s / it)
[13:30:12.557095] Dice score of the network on the train images: 0.831118, val images: 0.814954
[13:30:12.557315] saving best_dice_model_0 @ epoch 21
[13:30:13.808359] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:30:14.711184] Epoch: [22]  [  0/345]  eta: 0:05:11  lr: 0.000124  loss: 0.1746 (0.1746)  time: 0.9019  data: 0.3029  max mem: 15821
[13:30:26.723737] Epoch: [22]  [ 20/345]  eta: 0:03:19  lr: 0.000124  loss: 0.1654 (0.1686)  time: 0.6006  data: 0.0001  max mem: 15821
[13:30:38.764389] Epoch: [22]  [ 40/345]  eta: 0:03:05  lr: 0.000123  loss: 0.1632 (0.1709)  time: 0.6020  data: 0.0001  max mem: 15821
[13:30:50.829871] Epoch: [22]  [ 60/345]  eta: 0:02:52  lr: 0.000123  loss: 0.1720 (0.1732)  time: 0.6032  data: 0.0001  max mem: 15821
[13:31:02.901051] Epoch: [22]  [ 80/345]  eta: 0:02:40  lr: 0.000123  loss: 0.1808 (0.1753)  time: 0.6035  data: 0.0001  max mem: 15821
[13:31:14.996589] Epoch: [22]  [100/345]  eta: 0:02:28  lr: 0.000123  loss: 0.1790 (0.1752)  time: 0.6047  data: 0.0001  max mem: 15821
[13:31:27.090177] Epoch: [22]  [120/345]  eta: 0:02:16  lr: 0.000123  loss: 0.1620 (0.1749)  time: 0.6046  data: 0.0001  max mem: 15821
[13:31:39.194515] Epoch: [22]  [140/345]  eta: 0:02:04  lr: 0.000123  loss: 0.1683 (0.1757)  time: 0.6052  data: 0.0001  max mem: 15821
[13:31:51.299819] Epoch: [22]  [160/345]  eta: 0:01:52  lr: 0.000123  loss: 0.1741 (0.1754)  time: 0.6052  data: 0.0001  max mem: 15821
[13:32:03.418247] Epoch: [22]  [180/345]  eta: 0:01:39  lr: 0.000123  loss: 0.1682 (0.1749)  time: 0.6059  data: 0.0001  max mem: 15821
[13:32:15.535902] Epoch: [22]  [200/345]  eta: 0:01:27  lr: 0.000123  loss: 0.1769 (0.1752)  time: 0.6058  data: 0.0001  max mem: 15821
[13:32:27.648235] Epoch: [22]  [220/345]  eta: 0:01:15  lr: 0.000123  loss: 0.1770 (0.1754)  time: 0.6056  data: 0.0001  max mem: 15821
[13:32:39.757748] Epoch: [22]  [240/345]  eta: 0:01:03  lr: 0.000123  loss: 0.1737 (0.1755)  time: 0.6054  data: 0.0001  max mem: 15821
[13:32:51.866332] Epoch: [22]  [260/345]  eta: 0:00:51  lr: 0.000122  loss: 0.1726 (0.1752)  time: 0.6054  data: 0.0001  max mem: 15821
[13:33:03.965657] Epoch: [22]  [280/345]  eta: 0:00:39  lr: 0.000122  loss: 0.1623 (0.1750)  time: 0.6049  data: 0.0001  max mem: 15821

[13:33:16.058138] Epoch: [22]  [300/345]  eta: 0:00:27  lr: 0.000122  loss: 0.1697 (0.1752)  time: 0.6046  data: 0.0001  max mem: 15821
[13:33:28.152709] Epoch: [22]  [320/345]  eta: 0:00:15  lr: 0.000122  loss: 0.1780 (0.1754)  time: 0.6047  data: 0.0001  max mem: 15821
[13:33:40.253284] Epoch: [22]  [340/345]  eta: 0:00:03  lr: 0.000122  loss: 0.1700 (0.1756)  time: 0.6050  data: 0.0001  max mem: 15821
[13:33:42.675486] Epoch: [22]  [344/345]  eta: 0:00:00  lr: 0.000122  loss: 0.1845 (0.1757)  time: 0.6050  data: 0.0001  max mem: 15821
[13:33:42.744588] Epoch: [22] Total time: 0:03:28 (0.6056 s / it)
[13:33:42.744724] Averaged stats: lr: 0.000122  loss: 0.1845 (0.1757)
[13:33:43.254348] Test:  [  0/345]  eta: 0:02:54  loss: 0.1459 (0.1459)  time: 0.5052  data: 0.3415  max mem: 15821
[13:33:44.922977] Test:  [ 10/345]  eta: 0:01:06  loss: 0.1743 (0.1729)  time: 0.1975  data: 0.0311  max mem: 15821
[13:33:46.594628] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1641 (0.1697)  time: 0.1669  data: 0.0001  max mem: 15821
[13:33:48.269894] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1641 (0.1726)  time: 0.1673  data: 0.0001  max mem: 15821
[13:33:49.948042] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1703 (0.1734)  time: 0.1676  data: 0.0001  max mem: 15821
[13:33:51.628473] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1648 (0.1744)  time: 0.1679  data: 0.0001  max mem: 15821
[13:33:53.313419] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1648 (0.1742)  time: 0.1682  data: 0.0001  max mem: 15821
[13:33:55.000854] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1689 (0.1752)  time: 0.1686  data: 0.0001  max mem: 15821
[13:33:56.691958] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1683 (0.1751)  time: 0.1689  data: 0.0001  max mem: 15821
[13:33:58.387194] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1666 (0.1741)  time: 0.1693  data: 0.0001  max mem: 15821
[13:34:00.085191] Test:  [100/345]  eta: 0:00:42  loss: 0.1709 (0.1743)  time: 0.1696  data: 0.0001  max mem: 15821
[13:34:01.786714] Test:  [110/345]  eta: 0:00:40  loss: 0.1717 (0.1742)  time: 0.1699  data: 0.0001  max mem: 15821
[13:34:03.491603] Test:  [120/345]  eta: 0:00:38  loss: 0.1699 (0.1738)  time: 0.1703  data: 0.0001  max mem: 15821
[13:34:05.199720] Test:  [130/345]  eta: 0:00:36  loss: 0.1760 (0.1747)  time: 0.1706  data: 0.0001  max mem: 15821
[13:34:06.911432] Test:  [140/345]  eta: 0:00:35  loss: 0.1760 (0.1747)  time: 0.1709  data: 0.0001  max mem: 15821
[13:34:08.625790] Test:  [150/345]  eta: 0:00:33  loss: 0.1725 (0.1752)  time: 0.1712  data: 0.0001  max mem: 15821
[13:34:10.344835] Test:  [160/345]  eta: 0:00:31  loss: 0.1713 (0.1752)  time: 0.1716  data: 0.0001  max mem: 15821
[13:34:12.067231] Test:  [170/345]  eta: 0:00:29  loss: 0.1650 (0.1752)  time: 0.1720  data: 0.0001  max mem: 15821
[13:34:13.793820] Test:  [180/345]  eta: 0:00:28  loss: 0.1648 (0.1749)  time: 0.1724  data: 0.0001  max mem: 15821
[13:34:15.523036] Test:  [190/345]  eta: 0:00:26  loss: 0.1676 (0.1749)  time: 0.1727  data: 0.0001  max mem: 15821
[13:34:17.255450] Test:  [200/345]  eta: 0:00:24  loss: 0.1738 (0.1748)  time: 0.1730  data: 0.0001  max mem: 15821
[13:34:18.990433] Test:  [210/345]  eta: 0:00:23  loss: 0.1701 (0.1746)  time: 0.1733  data: 0.0001  max mem: 15821
[13:34:20.728182] Test:  [220/345]  eta: 0:00:21  loss: 0.1715 (0.1746)  time: 0.1736  data: 0.0001  max mem: 15821
[13:34:22.471821] Test:  [230/345]  eta: 0:00:19  loss: 0.1782 (0.1749)  time: 0.1740  data: 0.0001  max mem: 15821
[13:34:24.218544] Test:  [240/345]  eta: 0:00:18  loss: 0.1690 (0.1745)  time: 0.1745  data: 0.0001  max mem: 15821
[13:34:25.967436] Test:  [250/345]  eta: 0:00:16  loss: 0.1614 (0.1741)  time: 0.1747  data: 0.0001  max mem: 15821
[13:34:27.722211] Test:  [260/345]  eta: 0:00:14  loss: 0.1662 (0.1743)  time: 0.1751  data: 0.0001  max mem: 15821
[13:34:29.478442] Test:  [270/345]  eta: 0:00:12  loss: 0.1737 (0.1743)  time: 0.1755  data: 0.0001  max mem: 15821
[13:34:31.238773] Test:  [280/345]  eta: 0:00:11  loss: 0.1821 (0.1746)  time: 0.1758  data: 0.0001  max mem: 15821
[13:34:33.001647] Test:  [290/345]  eta: 0:00:09  loss: 0.1821 (0.1748)  time: 0.1761  data: 0.0001  max mem: 15821
[13:34:34.770044] Test:  [300/345]  eta: 0:00:07  loss: 0.1712 (0.1751)  time: 0.1765  data: 0.0001  max mem: 15821
[13:34:36.540774] Test:  [310/345]  eta: 0:00:06  loss: 0.1782 (0.1754)  time: 0.1769  data: 0.0001  max mem: 15821
[13:34:38.317938] Test:  [320/345]  eta: 0:00:04  loss: 0.1782 (0.1752)  time: 0.1773  data: 0.0001  max mem: 15821
[13:34:40.097380] Test:  [330/345]  eta: 0:00:02  loss: 0.1625 (0.1750)  time: 0.1778  data: 0.0001  max mem: 15821
[13:34:41.879334] Test:  [340/345]  eta: 0:00:00  loss: 0.1732 (0.1753)  time: 0.1780  data: 0.0001  max mem: 15821
[13:34:42.594797] Test:  [344/345]  eta: 0:00:00  loss: 0.1732 (0.1752)  time: 0.1782  data: 0.0001  max mem: 15821
[13:34:42.669867] Test: Total time: 0:00:59 (0.1737 s / it)
[13:34:52.469186] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4367 (0.4367)  time: 0.4497  data: 0.2873  max mem: 15821
[13:34:54.120806] Test:  [10/57]  eta: 0:00:08  loss: 0.3868 (0.4210)  time: 0.1910  data: 0.0262  max mem: 15821
[13:34:55.776973] Test:  [20/57]  eta: 0:00:06  loss: 0.3949 (0.4123)  time: 0.1653  data: 0.0001  max mem: 15821
[13:34:57.434887] Test:  [30/57]  eta: 0:00:04  loss: 0.2892 (0.3608)  time: 0.1656  data: 0.0001  max mem: 15821
[13:34:59.099020] Test:  [40/57]  eta: 0:00:02  loss: 0.2626 (0.3418)  time: 0.1660  data: 0.0001  max mem: 15821
[13:35:00.767356] Test:  [50/57]  eta: 0:00:01  loss: 0.2854 (0.3432)  time: 0.1666  data: 0.0001  max mem: 15821
[13:35:01.667604] Test:  [56/57]  eta: 0:00:00  loss: 0.3101 (0.3504)  time: 0.1617  data: 0.0000  max mem: 15821
[13:35:01.736014] Test: Total time: 0:00:09 (0.1705 s / it)
[13:35:03.391956] Dice score of the network on the train images: 0.850883, val images: 0.793664
[13:35:03.395948] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:35:04.430360] Epoch: [23]  [  0/345]  eta: 0:05:56  lr: 0.000122  loss: 0.2117 (0.2117)  time: 1.0333  data: 0.3137  max mem: 15821
[13:35:16.450558] Epoch: [23]  [ 20/345]  eta: 0:03:22  lr: 0.000122  loss: 0.1718 (0.1784)  time: 0.6010  data: 0.0001  max mem: 15821
[13:35:28.480122] Epoch: [23]  [ 40/345]  eta: 0:03:06  lr: 0.000122  loss: 0.1669 (0.1725)  time: 0.6014  data: 0.0001  max mem: 15821
[13:35:40.509983] Epoch: [23]  [ 60/345]  eta: 0:02:53  lr: 0.000122  loss: 0.1715 (0.1722)  time: 0.6015  data: 0.0001  max mem: 15821
[13:35:52.563525] Epoch: [23]  [ 80/345]  eta: 0:02:40  lr: 0.000121  loss: 0.1661 (0.1722)  time: 0.6026  data: 0.0001  max mem: 15821
[13:36:04.633265] Epoch: [23]  [100/345]  eta: 0:02:28  lr: 0.000121  loss: 0.1725 (0.1730)  time: 0.6035  data: 0.0001  max mem: 15821
[13:36:16.707535] Epoch: [23]  [120/345]  eta: 0:02:16  lr: 0.000121  loss: 0.1648 (0.1719)  time: 0.6037  data: 0.0001  max mem: 15821
[13:36:28.792071] Epoch: [23]  [140/345]  eta: 0:02:04  lr: 0.000121  loss: 0.1691 (0.1719)  time: 0.6042  data: 0.0001  max mem: 15821
[13:36:40.885125] Epoch: [23]  [160/345]  eta: 0:01:52  lr: 0.000121  loss: 0.1688 (0.1720)  time: 0.6046  data: 0.0001  max mem: 15821
[13:36:52.983223] Epoch: [23]  [180/345]  eta: 0:01:39  lr: 0.000121  loss: 0.1626 (0.1720)  time: 0.6049  data: 0.0001  max mem: 15821
[13:37:05.080807] Epoch: [23]  [200/345]  eta: 0:01:27  lr: 0.000121  loss: 0.1641 (0.1718)  time: 0.6048  data: 0.0001  max mem: 15821
[13:37:17.180450] Epoch: [23]  [220/345]  eta: 0:01:15  lr: 0.000121  loss: 0.1804 (0.1726)  time: 0.6049  data: 0.0001  max mem: 15821
[13:37:29.286252] Epoch: [23]  [240/345]  eta: 0:01:03  lr: 0.000120  loss: 0.1697 (0.1727)  time: 0.6052  data: 0.0001  max mem: 15821
[13:37:41.371827] Epoch: [23]  [260/345]  eta: 0:00:51  lr: 0.000120  loss: 0.1663 (0.1728)  time: 0.6042  data: 0.0001  max mem: 15821
[13:37:53.457383] Epoch: [23]  [280/345]  eta: 0:00:39  lr: 0.000120  loss: 0.1676 (0.1724)  time: 0.6042  data: 0.0001  max mem: 15821
[13:38:05.539801] Epoch: [23]  [300/345]  eta: 0:00:27  lr: 0.000120  loss: 0.1746 (0.1728)  time: 0.6041  data: 0.0001  max mem: 15821
[13:38:17.626403] Epoch: [23]  [320/345]  eta: 0:00:15  lr: 0.000120  loss: 0.1783 (0.1733)  time: 0.6043  data: 0.0001  max mem: 15821
[13:38:29.722593] Epoch: [23]  [340/345]  eta: 0:00:03  lr: 0.000120  loss: 0.1759 (0.1735)  time: 0.6048  data: 0.0001  max mem: 15821
[13:38:32.136753] Epoch: [23]  [344/345]  eta: 0:00:00  lr: 0.000120  loss: 0.1673 (0.1736)  time: 0.6045  data: 0.0001  max mem: 15821
[13:38:32.202855] Epoch: [23] Total time: 0:03:28 (0.6052 s / it)
[13:38:32.203223] Averaged stats: lr: 0.000120  loss: 0.1673 (0.1736)
[13:38:32.758224] Test:  [  0/345]  eta: 0:03:09  loss: 0.1564 (0.1564)  time: 0.5499  data: 0.3849  max mem: 15821
[13:38:34.426942] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1724 (0.1715)  time: 0.2016  data: 0.0351  max mem: 15821
[13:38:36.098609] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1633 (0.1625)  time: 0.1669  data: 0.0001  max mem: 15821
[13:38:37.774043] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1633 (0.1668)  time: 0.1673  data: 0.0001  max mem: 15821
[13:38:39.452803] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1691 (0.1666)  time: 0.1677  data: 0.0001  max mem: 15821
[13:38:41.133437] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1668 (0.1666)  time: 0.1679  data: 0.0001  max mem: 15821
[13:38:42.817592] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1577 (0.1658)  time: 0.1682  data: 0.0001  max mem: 15821
[13:38:44.505474] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1589 (0.1661)  time: 0.1685  data: 0.0001  max mem: 15821
[13:38:46.196933] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1600 (0.1664)  time: 0.1689  data: 0.0001  max mem: 15821
[13:38:47.891839] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1637 (0.1664)  time: 0.1693  data: 0.0001  max mem: 15821
[13:38:49.590852] Test:  [100/345]  eta: 0:00:42  loss: 0.1637 (0.1669)  time: 0.1696  data: 0.0001  max mem: 15821
[13:38:51.294272] Test:  [110/345]  eta: 0:00:40  loss: 0.1598 (0.1664)  time: 0.1701  data: 0.0001  max mem: 15821
[13:38:52.999524] Test:  [120/345]  eta: 0:00:38  loss: 0.1587 (0.1660)  time: 0.1704  data: 0.0001  max mem: 15821
[13:38:54.707202] Test:  [130/345]  eta: 0:00:36  loss: 0.1624 (0.1657)  time: 0.1706  data: 0.0001  max mem: 15821
[13:38:56.419530] Test:  [140/345]  eta: 0:00:35  loss: 0.1671 (0.1661)  time: 0.1709  data: 0.0001  max mem: 15821
[13:38:58.134471] Test:  [150/345]  eta: 0:00:33  loss: 0.1675 (0.1660)  time: 0.1713  data: 0.0001  max mem: 15821
[13:38:59.854000] Test:  [160/345]  eta: 0:00:31  loss: 0.1672 (0.1661)  time: 0.1717  data: 0.0001  max mem: 15821
[13:39:01.577051] Test:  [170/345]  eta: 0:00:30  loss: 0.1617 (0.1659)  time: 0.1721  data: 0.0001  max mem: 15821
[13:39:03.303269] Test:  [180/345]  eta: 0:00:28  loss: 0.1549 (0.1660)  time: 0.1724  data: 0.0001  max mem: 15821
[13:39:05.032189] Test:  [190/345]  eta: 0:00:26  loss: 0.1692 (0.1668)  time: 0.1727  data: 0.0001  max mem: 15821
[13:39:06.766039] Test:  [200/345]  eta: 0:00:24  loss: 0.1802 (0.1673)  time: 0.1731  data: 0.0001  max mem: 15821
[13:39:08.502315] Test:  [210/345]  eta: 0:00:23  loss: 0.1802 (0.1675)  time: 0.1734  data: 0.0001  max mem: 15821
[13:39:10.241915] Test:  [220/345]  eta: 0:00:21  loss: 0.1657 (0.1675)  time: 0.1737  data: 0.0001  max mem: 15821
[13:39:11.985050] Test:  [230/345]  eta: 0:00:19  loss: 0.1645 (0.1674)  time: 0.1741  data: 0.0001  max mem: 15821
[13:39:13.732323] Test:  [240/345]  eta: 0:00:18  loss: 0.1639 (0.1672)  time: 0.1744  data: 0.0001  max mem: 15821
[13:39:15.482467] Test:  [250/345]  eta: 0:00:16  loss: 0.1537 (0.1669)  time: 0.1748  data: 0.0001  max mem: 15821
[13:39:17.234978] Test:  [260/345]  eta: 0:00:14  loss: 0.1550 (0.1670)  time: 0.1751  data: 0.0001  max mem: 15821
[13:39:18.991256] Test:  [270/345]  eta: 0:00:12  loss: 0.1641 (0.1671)  time: 0.1754  data: 0.0001  max mem: 15821
[13:39:20.752416] Test:  [280/345]  eta: 0:00:11  loss: 0.1650 (0.1671)  time: 0.1758  data: 0.0001  max mem: 15821
[13:39:22.516635] Test:  [290/345]  eta: 0:00:09  loss: 0.1656 (0.1675)  time: 0.1762  data: 0.0001  max mem: 15821
[13:39:24.283015] Test:  [300/345]  eta: 0:00:07  loss: 0.1589 (0.1673)  time: 0.1765  data: 0.0001  max mem: 15821
[13:39:26.054366] Test:  [310/345]  eta: 0:00:06  loss: 0.1602 (0.1673)  time: 0.1768  data: 0.0001  max mem: 15821
[13:39:27.828033] Test:  [320/345]  eta: 0:00:04  loss: 0.1668 (0.1671)  time: 0.1772  data: 0.0001  max mem: 15821
[13:39:29.606289] Test:  [330/345]  eta: 0:00:02  loss: 0.1619 (0.1671)  time: 0.1775  data: 0.0001  max mem: 15821
[13:39:31.386937] Test:  [340/345]  eta: 0:00:00  loss: 0.1619 (0.1670)  time: 0.1779  data: 0.0001  max mem: 15821
[13:39:32.102322] Test:  [344/345]  eta: 0:00:00  loss: 0.1619 (0.1673)  time: 0.1781  data: 0.0001  max mem: 15821
[13:39:32.173569] Test: Total time: 0:00:59 (0.1738 s / it)
[13:39:42.067378] Test:  [ 0/57]  eta: 0:00:27  loss: 0.4572 (0.4572)  time: 0.4822  data: 0.3197  max mem: 15821
[13:39:43.718891] Test:  [10/57]  eta: 0:00:09  loss: 0.3861 (0.4192)  time: 0.1939  data: 0.0292  max mem: 15821
[13:39:45.373246] Test:  [20/57]  eta: 0:00:06  loss: 0.3861 (0.4067)  time: 0.1652  data: 0.0001  max mem: 15821
[13:39:47.032275] Test:  [30/57]  eta: 0:00:04  loss: 0.2800 (0.3509)  time: 0.1656  data: 0.0001  max mem: 15821
[13:39:48.696910] Test:  [40/57]  eta: 0:00:02  loss: 0.2381 (0.3293)  time: 0.1661  data: 0.0001  max mem: 15821
[13:39:50.364676] Test:  [50/57]  eta: 0:00:01  loss: 0.2734 (0.3293)  time: 0.1666  data: 0.0001  max mem: 15821
[13:39:51.265409] Test:  [56/57]  eta: 0:00:00  loss: 0.2935 (0.3371)  time: 0.1617  data: 0.0000  max mem: 15821
[13:39:51.347267] Test: Total time: 0:00:09 (0.1713 s / it)
[13:39:53.035525] Dice score of the network on the train images: 0.846588, val images: 0.802053
[13:39:53.040266] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:39:53.980788] Epoch: [24]  [  0/345]  eta: 0:05:24  lr: 0.000120  loss: 0.1942 (0.1942)  time: 0.9394  data: 0.3381  max mem: 15821
[13:40:05.987039] Epoch: [24]  [ 20/345]  eta: 0:03:20  lr: 0.000119  loss: 0.1652 (0.1712)  time: 0.6003  data: 0.0001  max mem: 15821
[13:40:18.020542] Epoch: [24]  [ 40/345]  eta: 0:03:05  lr: 0.000119  loss: 0.1632 (0.1705)  time: 0.6016  data: 0.0001  max mem: 15821
[13:40:30.088293] Epoch: [24]  [ 60/345]  eta: 0:02:53  lr: 0.000119  loss: 0.1602 (0.1673)  time: 0.6033  data: 0.0001  max mem: 15821
[13:40:42.164758] Epoch: [24]  [ 80/345]  eta: 0:02:40  lr: 0.000119  loss: 0.1790 (0.1705)  time: 0.6038  data: 0.0001  max mem: 15821
[13:40:54.254318] Epoch: [24]  [100/345]  eta: 0:02:28  lr: 0.000119  loss: 0.1684 (0.1712)  time: 0.6044  data: 0.0001  max mem: 15821
[13:41:06.480090] Epoch: [24]  [120/345]  eta: 0:02:16  lr: 0.000119  loss: 0.1666 (0.1701)  time: 0.6112  data: 0.0001  max mem: 15821
[13:41:18.576156] Epoch: [24]  [140/345]  eta: 0:02:04  lr: 0.000118  loss: 0.1499 (0.1685)  time: 0.6048  data: 0.0001  max mem: 15821
[13:41:30.688650] Epoch: [24]  [160/345]  eta: 0:01:52  lr: 0.000118  loss: 0.1638 (0.1684)  time: 0.6056  data: 0.0001  max mem: 15821
[13:41:42.803862] Epoch: [24]  [180/345]  eta: 0:01:40  lr: 0.000118  loss: 0.1542 (0.1678)  time: 0.6057  data: 0.0001  max mem: 15821
[13:41:54.920926] Epoch: [24]  [200/345]  eta: 0:01:27  lr: 0.000118  loss: 0.1700 (0.1681)  time: 0.6058  data: 0.0001  max mem: 15821
[13:42:07.037349] Epoch: [24]  [220/345]  eta: 0:01:15  lr: 0.000118  loss: 0.1521 (0.1676)  time: 0.6058  data: 0.0001  max mem: 15821
[13:42:19.146307] Epoch: [24]  [240/345]  eta: 0:01:03  lr: 0.000118  loss: 0.1667 (0.1679)  time: 0.6054  data: 0.0001  max mem: 15821
[13:42:31.258363] Epoch: [24]  [260/345]  eta: 0:00:51  lr: 0.000117  loss: 0.1601 (0.1676)  time: 0.6056  data: 0.0001  max mem: 15821
[13:42:43.360155] Epoch: [24]  [280/345]  eta: 0:00:39  lr: 0.000117  loss: 0.1648 (0.1679)  time: 0.6050  data: 0.0001  max mem: 15821
[13:42:55.457167] Epoch: [24]  [300/345]  eta: 0:00:27  lr: 0.000117  loss: 0.1525 (0.1671)  time: 0.6048  data: 0.0001  max mem: 15821
[13:43:07.549241] Epoch: [24]  [320/345]  eta: 0:00:15  lr: 0.000117  loss: 0.1614 (0.1670)  time: 0.6046  data: 0.0001  max mem: 15821
[13:43:19.652909] Epoch: [24]  [340/345]  eta: 0:00:03  lr: 0.000117  loss: 0.1723 (0.1673)  time: 0.6051  data: 0.0001  max mem: 15821
[13:43:22.072371] Epoch: [24]  [344/345]  eta: 0:00:00  lr: 0.000117  loss: 0.1727 (0.1675)  time: 0.6051  data: 0.0001  max mem: 15821
[13:43:22.145654] Epoch: [24] Total time: 0:03:29 (0.6061 s / it)
[13:43:22.146248] Averaged stats: lr: 0.000117  loss: 0.1727 (0.1675)
[13:43:22.638877] Test:  [  0/345]  eta: 0:02:48  loss: 0.1534 (0.1534)  time: 0.4876  data: 0.3234  max mem: 15821
[13:43:24.307606] Test:  [ 10/345]  eta: 0:01:05  loss: 0.1601 (0.1620)  time: 0.1960  data: 0.0295  max mem: 15821
[13:43:25.978854] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1658 (0.1629)  time: 0.1669  data: 0.0001  max mem: 15821
[13:43:27.653010] Test:  [ 30/345]  eta: 0:00:55  loss: 0.1550 (0.1601)  time: 0.1672  data: 0.0001  max mem: 15821
[13:43:29.330754] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1583 (0.1600)  time: 0.1675  data: 0.0001  max mem: 15821
[13:43:31.011116] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1594 (0.1604)  time: 0.1678  data: 0.0001  max mem: 15821
[13:43:32.695368] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1534 (0.1593)  time: 0.1682  data: 0.0001  max mem: 15821
[13:43:34.382926] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1534 (0.1596)  time: 0.1685  data: 0.0001  max mem: 15821
[13:43:36.074417] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1527 (0.1603)  time: 0.1689  data: 0.0001  max mem: 15821
[13:43:37.769369] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1527 (0.1598)  time: 0.1693  data: 0.0001  max mem: 15821
[13:43:39.469056] Test:  [100/345]  eta: 0:00:41  loss: 0.1537 (0.1591)  time: 0.1697  data: 0.0001  max mem: 15821
[13:43:41.170251] Test:  [110/345]  eta: 0:00:40  loss: 0.1604 (0.1595)  time: 0.1700  data: 0.0001  max mem: 15821
[13:43:42.875288] Test:  [120/345]  eta: 0:00:38  loss: 0.1663 (0.1602)  time: 0.1703  data: 0.0001  max mem: 15821
[13:43:44.584865] Test:  [130/345]  eta: 0:00:36  loss: 0.1578 (0.1605)  time: 0.1707  data: 0.0001  max mem: 15821
[13:43:46.297598] Test:  [140/345]  eta: 0:00:35  loss: 0.1517 (0.1598)  time: 0.1710  data: 0.0001  max mem: 15821
[13:43:48.013540] Test:  [150/345]  eta: 0:00:33  loss: 0.1467 (0.1592)  time: 0.1713  data: 0.0001  max mem: 15821
[13:43:49.733112] Test:  [160/345]  eta: 0:00:31  loss: 0.1467 (0.1590)  time: 0.1717  data: 0.0001  max mem: 15821
[13:43:51.456461] Test:  [170/345]  eta: 0:00:29  loss: 0.1602 (0.1598)  time: 0.1721  data: 0.0001  max mem: 15821
[13:43:53.182904] Test:  [180/345]  eta: 0:00:28  loss: 0.1622 (0.1597)  time: 0.1724  data: 0.0001  max mem: 15821
[13:43:54.911634] Test:  [190/345]  eta: 0:00:26  loss: 0.1456 (0.1593)  time: 0.1727  data: 0.0001  max mem: 15821
[13:43:56.644429] Test:  [200/345]  eta: 0:00:24  loss: 0.1465 (0.1592)  time: 0.1730  data: 0.0001  max mem: 15821
[13:43:58.379019] Test:  [210/345]  eta: 0:00:23  loss: 0.1453 (0.1584)  time: 0.1733  data: 0.0001  max mem: 15821
[13:44:00.119444] Test:  [220/345]  eta: 0:00:21  loss: 0.1538 (0.1588)  time: 0.1737  data: 0.0001  max mem: 15821
[13:44:01.861961] Test:  [230/345]  eta: 0:00:19  loss: 0.1611 (0.1590)  time: 0.1741  data: 0.0001  max mem: 15821
[13:44:03.608004] Test:  [240/345]  eta: 0:00:18  loss: 0.1594 (0.1589)  time: 0.1744  data: 0.0001  max mem: 15821
[13:44:05.357477] Test:  [250/345]  eta: 0:00:16  loss: 0.1583 (0.1592)  time: 0.1747  data: 0.0001  max mem: 15821
[13:44:07.109886] Test:  [260/345]  eta: 0:00:14  loss: 0.1638 (0.1594)  time: 0.1750  data: 0.0001  max mem: 15821
[13:44:08.867031] Test:  [270/345]  eta: 0:00:12  loss: 0.1603 (0.1596)  time: 0.1754  data: 0.0001  max mem: 15821
[13:44:10.626309] Test:  [280/345]  eta: 0:00:11  loss: 0.1539 (0.1594)  time: 0.1758  data: 0.0001  max mem: 15821
[13:44:12.388385] Test:  [290/345]  eta: 0:00:09  loss: 0.1604 (0.1598)  time: 0.1760  data: 0.0001  max mem: 15821
[13:44:14.155394] Test:  [300/345]  eta: 0:00:07  loss: 0.1717 (0.1600)  time: 0.1764  data: 0.0001  max mem: 15821
[13:44:15.927331] Test:  [310/345]  eta: 0:00:06  loss: 0.1549 (0.1600)  time: 0.1769  data: 0.0001  max mem: 15821
[13:44:17.702007] Test:  [320/345]  eta: 0:00:04  loss: 0.1541 (0.1600)  time: 0.1773  data: 0.0001  max mem: 15821
[13:44:19.480223] Test:  [330/345]  eta: 0:00:02  loss: 0.1495 (0.1596)  time: 0.1776  data: 0.0001  max mem: 15821
[13:44:21.261321] Test:  [340/345]  eta: 0:00:00  loss: 0.1515 (0.1596)  time: 0.1779  data: 0.0001  max mem: 15821
[13:44:21.974230] Test:  [344/345]  eta: 0:00:00  loss: 0.1515 (0.1595)  time: 0.1781  data: 0.0001  max mem: 15821
[13:44:22.040428] Test: Total time: 0:00:59 (0.1736 s / it)
[13:44:31.979735] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4562 (0.4562)  time: 0.4657  data: 0.3038  max mem: 15821
[13:44:33.629748] Test:  [10/57]  eta: 0:00:09  loss: 0.3767 (0.4246)  time: 0.1923  data: 0.0277  max mem: 15821
[13:44:35.286515] Test:  [20/57]  eta: 0:00:06  loss: 0.3767 (0.4037)  time: 0.1653  data: 0.0001  max mem: 15821
[13:44:36.945319] Test:  [30/57]  eta: 0:00:04  loss: 0.2707 (0.3483)  time: 0.1657  data: 0.0001  max mem: 15821
[13:44:38.609184] Test:  [40/57]  eta: 0:00:02  loss: 0.2288 (0.3243)  time: 0.1661  data: 0.0001  max mem: 15821
[13:44:40.278617] Test:  [50/57]  eta: 0:00:01  loss: 0.2495 (0.3234)  time: 0.1666  data: 0.0001  max mem: 15821
[13:44:41.179202] Test:  [56/57]  eta: 0:00:00  loss: 0.2763 (0.3311)  time: 0.1617  data: 0.0000  max mem: 15821
[13:44:41.246450] Test: Total time: 0:00:09 (0.1708 s / it)
[13:44:42.932360] Dice score of the network on the train images: 0.849924, val images: 0.801524
[13:44:42.937048] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:44:43.890269] Epoch: [25]  [  0/345]  eta: 0:05:28  lr: 0.000117  loss: 0.1503 (0.1503)  time: 0.9521  data: 0.3518  max mem: 15821
[13:44:55.907796] Epoch: [25]  [ 20/345]  eta: 0:03:20  lr: 0.000116  loss: 0.1669 (0.1689)  time: 0.6008  data: 0.0001  max mem: 15821
[13:45:07.944977] Epoch: [25]  [ 40/345]  eta: 0:03:06  lr: 0.000116  loss: 0.1518 (0.1610)  time: 0.6018  data: 0.0001  max mem: 15821
[13:45:20.002831] Epoch: [25]  [ 60/345]  eta: 0:02:53  lr: 0.000116  loss: 0.1646 (0.1617)  time: 0.6028  data: 0.0001  max mem: 15821
[13:45:32.073395] Epoch: [25]  [ 80/345]  eta: 0:02:40  lr: 0.000116  loss: 0.1545 (0.1620)  time: 0.6035  data: 0.0001  max mem: 15821
[13:45:44.138310] Epoch: [25]  [100/345]  eta: 0:02:28  lr: 0.000116  loss: 0.1681 (0.1635)  time: 0.6032  data: 0.0001  max mem: 15821
[13:45:56.229629] Epoch: [25]  [120/345]  eta: 0:02:16  lr: 0.000115  loss: 0.1581 (0.1631)  time: 0.6045  data: 0.0001  max mem: 15821
[13:46:08.328501] Epoch: [25]  [140/345]  eta: 0:02:04  lr: 0.000115  loss: 0.1564 (0.1635)  time: 0.6049  data: 0.0001  max mem: 15821
[13:46:20.439564] Epoch: [25]  [160/345]  eta: 0:01:52  lr: 0.000115  loss: 0.1581 (0.1632)  time: 0.6055  data: 0.0001  max mem: 15821
[13:46:32.549721] Epoch: [25]  [180/345]  eta: 0:01:39  lr: 0.000115  loss: 0.1604 (0.1636)  time: 0.6055  data: 0.0001  max mem: 15821
[13:46:44.661742] Epoch: [25]  [200/345]  eta: 0:01:27  lr: 0.000115  loss: 0.1589 (0.1635)  time: 0.6056  data: 0.0001  max mem: 15821
[13:46:56.772377] Epoch: [25]  [220/345]  eta: 0:01:15  lr: 0.000114  loss: 0.1622 (0.1637)  time: 0.6055  data: 0.0001  max mem: 15821
[13:47:08.869962] Epoch: [25]  [240/345]  eta: 0:01:03  lr: 0.000114  loss: 0.1628 (0.1638)  time: 0.6048  data: 0.0001  max mem: 15821

[13:47:21.041573] Epoch: [25]  [260/345]  eta: 0:00:51  lr: 0.000114  loss: 0.1561 (0.1635)  time: 0.6085  data: 0.0001  max mem: 15821
[13:47:33.135371] Epoch: [25]  [280/345]  eta: 0:00:39  lr: 0.000114  loss: 0.1547 (0.1634)  time: 0.6046  data: 0.0001  max mem: 15821
[13:47:45.218387] Epoch: [25]  [300/345]  eta: 0:00:27  lr: 0.000114  loss: 0.1635 (0.1633)  time: 0.6041  data: 0.0001  max mem: 15821
[13:47:57.297973] Epoch: [25]  [320/345]  eta: 0:00:15  lr: 0.000113  loss: 0.1683 (0.1639)  time: 0.6039  data: 0.0001  max mem: 15821
[13:48:09.368760] Epoch: [25]  [340/345]  eta: 0:00:03  lr: 0.000113  loss: 0.1556 (0.1637)  time: 0.6035  data: 0.0001  max mem: 15821
[13:48:11.784973] Epoch: [25]  [344/345]  eta: 0:00:00  lr: 0.000113  loss: 0.1510 (0.1638)  time: 0.6035  data: 0.0001  max mem: 15821
[13:48:11.846441] Epoch: [25] Total time: 0:03:28 (0.6055 s / it)
[13:48:11.846661] Averaged stats: lr: 0.000113  loss: 0.1510 (0.1638)
[13:48:12.353529] Test:  [  0/345]  eta: 0:02:53  loss: 0.1517 (0.1517)  time: 0.5015  data: 0.3377  max mem: 15821
[13:48:14.021242] Test:  [ 10/345]  eta: 0:01:06  loss: 0.1512 (0.1458)  time: 0.1971  data: 0.0308  max mem: 15821
[13:48:15.693528] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1507 (0.1510)  time: 0.1669  data: 0.0001  max mem: 15821
[13:48:17.366657] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1558 (0.1553)  time: 0.1672  data: 0.0001  max mem: 15821
[13:48:19.044656] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1610 (0.1597)  time: 0.1675  data: 0.0001  max mem: 15821
[13:48:20.725043] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1505 (0.1577)  time: 0.1679  data: 0.0001  max mem: 15821
[13:48:22.409306] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1488 (0.1581)  time: 0.1682  data: 0.0001  max mem: 15821
[13:48:24.097214] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1531 (0.1585)  time: 0.1685  data: 0.0001  max mem: 15821
[13:48:25.788103] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1496 (0.1579)  time: 0.1689  data: 0.0001  max mem: 15821
[13:48:27.482559] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1503 (0.1586)  time: 0.1692  data: 0.0001  max mem: 15821
[13:48:29.180077] Test:  [100/345]  eta: 0:00:42  loss: 0.1557 (0.1580)  time: 0.1695  data: 0.0001  max mem: 15821
[13:48:30.881861] Test:  [110/345]  eta: 0:00:40  loss: 0.1553 (0.1583)  time: 0.1699  data: 0.0001  max mem: 15821
[13:48:32.586408] Test:  [120/345]  eta: 0:00:38  loss: 0.1553 (0.1585)  time: 0.1703  data: 0.0001  max mem: 15821
[13:48:34.294590] Test:  [130/345]  eta: 0:00:36  loss: 0.1437 (0.1579)  time: 0.1706  data: 0.0001  max mem: 15821
[13:48:36.006237] Test:  [140/345]  eta: 0:00:35  loss: 0.1528 (0.1586)  time: 0.1709  data: 0.0001  max mem: 15821
[13:48:37.721259] Test:  [150/345]  eta: 0:00:33  loss: 0.1528 (0.1582)  time: 0.1713  data: 0.0001  max mem: 15821
[13:48:39.440460] Test:  [160/345]  eta: 0:00:31  loss: 0.1520 (0.1580)  time: 0.1716  data: 0.0001  max mem: 15821
[13:48:41.163317] Test:  [170/345]  eta: 0:00:29  loss: 0.1597 (0.1581)  time: 0.1720  data: 0.0001  max mem: 15821
[13:48:42.889781] Test:  [180/345]  eta: 0:00:28  loss: 0.1617 (0.1584)  time: 0.1724  data: 0.0001  max mem: 15821
[13:48:44.618956] Test:  [190/345]  eta: 0:00:26  loss: 0.1617 (0.1585)  time: 0.1727  data: 0.0001  max mem: 15821
[13:48:46.350928] Test:  [200/345]  eta: 0:00:24  loss: 0.1561 (0.1585)  time: 0.1730  data: 0.0001  max mem: 15821
[13:48:48.085441] Test:  [210/345]  eta: 0:00:23  loss: 0.1538 (0.1584)  time: 0.1733  data: 0.0001  max mem: 15821
[13:48:49.825075] Test:  [220/345]  eta: 0:00:21  loss: 0.1477 (0.1578)  time: 0.1736  data: 0.0001  max mem: 15821
[13:48:51.567291] Test:  [230/345]  eta: 0:00:19  loss: 0.1579 (0.1582)  time: 0.1740  data: 0.0001  max mem: 15821
[13:48:53.312674] Test:  [240/345]  eta: 0:00:18  loss: 0.1606 (0.1584)  time: 0.1743  data: 0.0001  max mem: 15821
[13:48:55.062027] Test:  [250/345]  eta: 0:00:16  loss: 0.1510 (0.1583)  time: 0.1747  data: 0.0001  max mem: 15821
[13:48:56.814155] Test:  [260/345]  eta: 0:00:14  loss: 0.1564 (0.1585)  time: 0.1750  data: 0.0001  max mem: 15821
[13:48:58.571074] Test:  [270/345]  eta: 0:00:12  loss: 0.1564 (0.1586)  time: 0.1754  data: 0.0001  max mem: 15821
[13:49:00.330989] Test:  [280/345]  eta: 0:00:11  loss: 0.1425 (0.1582)  time: 0.1758  data: 0.0001  max mem: 15821
[13:49:02.093891] Test:  [290/345]  eta: 0:00:09  loss: 0.1441 (0.1581)  time: 0.1761  data: 0.0001  max mem: 15821
[13:49:03.859852] Test:  [300/345]  eta: 0:00:07  loss: 0.1512 (0.1581)  time: 0.1764  data: 0.0001  max mem: 15821
[13:49:05.632142] Test:  [310/345]  eta: 0:00:06  loss: 0.1524 (0.1581)  time: 0.1769  data: 0.0001  max mem: 15821
[13:49:07.406662] Test:  [320/345]  eta: 0:00:04  loss: 0.1534 (0.1582)  time: 0.1773  data: 0.0001  max mem: 15821
[13:49:09.183627] Test:  [330/345]  eta: 0:00:02  loss: 0.1535 (0.1583)  time: 0.1775  data: 0.0001  max mem: 15821
[13:49:10.965794] Test:  [340/345]  eta: 0:00:00  loss: 0.1525 (0.1581)  time: 0.1779  data: 0.0001  max mem: 15821
[13:49:11.679001] Test:  [344/345]  eta: 0:00:00  loss: 0.1539 (0.1580)  time: 0.1781  data: 0.0001  max mem: 15821
[13:49:11.737008] Test: Total time: 0:00:59 (0.1736 s / it)
[13:49:21.659431] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4689 (0.4689)  time: 0.4533  data: 0.2904  max mem: 15821
[13:49:23.309756] Test:  [10/57]  eta: 0:00:08  loss: 0.3922 (0.4457)  time: 0.1912  data: 0.0265  max mem: 15821
[13:49:24.965623] Test:  [20/57]  eta: 0:00:06  loss: 0.3922 (0.4292)  time: 0.1652  data: 0.0001  max mem: 15821
[13:49:26.624958] Test:  [30/57]  eta: 0:00:04  loss: 0.2884 (0.3688)  time: 0.1657  data: 0.0001  max mem: 15821
[13:49:28.288357] Test:  [40/57]  eta: 0:00:02  loss: 0.2445 (0.3461)  time: 0.1661  data: 0.0001  max mem: 15821
[13:49:29.957607] Test:  [50/57]  eta: 0:00:01  loss: 0.2795 (0.3452)  time: 0.1666  data: 0.0001  max mem: 15821
[13:49:30.858904] Test:  [56/57]  eta: 0:00:00  loss: 0.3148 (0.3545)  time: 0.1618  data: 0.0000  max mem: 15821
[13:49:30.916679] Test: Total time: 0:00:09 (0.1704 s / it)
[13:49:32.579305] Dice score of the network on the train images: 0.865682, val images: 0.795666
[13:49:32.579511] saving best_prec_model_0 @ epoch 25
[13:49:33.829925] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:49:34.748573] Epoch: [26]  [  0/345]  eta: 0:05:16  lr: 0.000113  loss: 0.1542 (0.1542)  time: 0.9174  data: 0.3151  max mem: 15821
[13:49:46.756421] Epoch: [26]  [ 20/345]  eta: 0:03:20  lr: 0.000113  loss: 0.1584 (0.1640)  time: 0.6003  data: 0.0001  max mem: 15821
[13:49:58.791165] Epoch: [26]  [ 40/345]  eta: 0:03:05  lr: 0.000113  loss: 0.1597 (0.1603)  time: 0.6017  data: 0.0001  max mem: 15821
[13:50:10.841730] Epoch: [26]  [ 60/345]  eta: 0:02:52  lr: 0.000112  loss: 0.1504 (0.1600)  time: 0.6025  data: 0.0001  max mem: 15821
[13:50:22.909502] Epoch: [26]  [ 80/345]  eta: 0:02:40  lr: 0.000112  loss: 0.1559 (0.1599)  time: 0.6033  data: 0.0001  max mem: 15821
[13:50:35.101731] Epoch: [26]  [100/345]  eta: 0:02:28  lr: 0.000112  loss: 0.1543 (0.1595)  time: 0.6096  data: 0.0001  max mem: 15821
[13:50:47.196738] Epoch: [26]  [120/345]  eta: 0:02:16  lr: 0.000112  loss: 0.1566 (0.1601)  time: 0.6047  data: 0.0001  max mem: 15821

[13:50:59.305739] Epoch: [26]  [140/345]  eta: 0:02:04  lr: 0.000111  loss: 0.1607 (0.1603)  time: 0.6054  data: 0.0001  max mem: 15821
[13:51:11.424932] Epoch: [26]  [160/345]  eta: 0:01:52  lr: 0.000111  loss: 0.1556 (0.1602)  time: 0.6059  data: 0.0001  max mem: 15821
[13:51:23.542849] Epoch: [26]  [180/345]  eta: 0:01:40  lr: 0.000111  loss: 0.1508 (0.1599)  time: 0.6059  data: 0.0001  max mem: 15821
[13:51:35.663622] Epoch: [26]  [200/345]  eta: 0:01:27  lr: 0.000111  loss: 0.1549 (0.1597)  time: 0.6060  data: 0.0001  max mem: 15821
[13:51:47.770600] Epoch: [26]  [220/345]  eta: 0:01:15  lr: 0.000110  loss: 0.1525 (0.1594)  time: 0.6053  data: 0.0001  max mem: 15821
[13:51:59.870674] Epoch: [26]  [240/345]  eta: 0:01:03  lr: 0.000110  loss: 0.1551 (0.1596)  time: 0.6050  data: 0.0001  max mem: 15821
[13:52:11.970994] Epoch: [26]  [260/345]  eta: 0:00:51  lr: 0.000110  loss: 0.1452 (0.1589)  time: 0.6050  data: 0.0001  max mem: 15821
[13:52:24.075792] Epoch: [26]  [280/345]  eta: 0:00:39  lr: 0.000110  loss: 0.1545 (0.1586)  time: 0.6052  data: 0.0001  max mem: 15821
[13:52:36.179781] Epoch: [26]  [300/345]  eta: 0:00:27  lr: 0.000110  loss: 0.1443 (0.1582)  time: 0.6052  data: 0.0001  max mem: 15821
[13:52:48.279852] Epoch: [26]  [320/345]  eta: 0:00:15  lr: 0.000109  loss: 0.1617 (0.1586)  time: 0.6050  data: 0.0001  max mem: 15821
[13:53:00.374035] Epoch: [26]  [340/345]  eta: 0:00:03  lr: 0.000109  loss: 0.1685 (0.1596)  time: 0.6047  data: 0.0001  max mem: 15821
[13:53:02.878118] Epoch: [26]  [344/345]  eta: 0:00:00  lr: 0.000109  loss: 0.1760 (0.1597)  time: 0.6089  data: 0.0001  max mem: 15821
[13:53:02.955779] Epoch: [26] Total time: 0:03:29 (0.6062 s / it)
[13:53:02.956352] Averaged stats: lr: 0.000109  loss: 0.1760 (0.1597)
[13:53:03.502607] Test:  [  0/345]  eta: 0:03:06  loss: 0.1564 (0.1564)  time: 0.5410  data: 0.3765  max mem: 15821
[13:53:05.171141] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1546 (0.1535)  time: 0.2008  data: 0.0343  max mem: 15821
[13:53:06.842135] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1531 (0.1549)  time: 0.1669  data: 0.0001  max mem: 15821
[13:53:08.517442] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1569 (0.1584)  time: 0.1673  data: 0.0001  max mem: 15821
[13:53:10.195660] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1613 (0.1589)  time: 0.1676  data: 0.0001  max mem: 15821
[13:53:11.877489] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1581 (0.1569)  time: 0.1679  data: 0.0001  max mem: 15821
[13:53:13.561599] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1483 (0.1559)  time: 0.1682  data: 0.0001  max mem: 15821
[13:53:15.249691] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1531 (0.1567)  time: 0.1685  data: 0.0001  max mem: 15821
[13:53:16.941752] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1567 (0.1572)  time: 0.1689  data: 0.0001  max mem: 15821
[13:53:18.637287] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1560 (0.1570)  time: 0.1693  data: 0.0001  max mem: 15821
[13:53:20.335710] Test:  [100/345]  eta: 0:00:42  loss: 0.1512 (0.1557)  time: 0.1696  data: 0.0001  max mem: 15821
[13:53:22.037604] Test:  [110/345]  eta: 0:00:40  loss: 0.1391 (0.1549)  time: 0.1700  data: 0.0001  max mem: 15821
[13:53:23.743259] Test:  [120/345]  eta: 0:00:38  loss: 0.1457 (0.1545)  time: 0.1703  data: 0.0001  max mem: 15821
[13:53:25.451331] Test:  [130/345]  eta: 0:00:36  loss: 0.1515 (0.1543)  time: 0.1706  data: 0.0001  max mem: 15821
[13:53:27.164096] Test:  [140/345]  eta: 0:00:35  loss: 0.1500 (0.1548)  time: 0.1710  data: 0.0001  max mem: 15821
[13:53:28.879906] Test:  [150/345]  eta: 0:00:33  loss: 0.1540 (0.1551)  time: 0.1714  data: 0.0001  max mem: 15821
[13:53:30.599062] Test:  [160/345]  eta: 0:00:31  loss: 0.1540 (0.1557)  time: 0.1717  data: 0.0001  max mem: 15821
[13:53:32.322932] Test:  [170/345]  eta: 0:00:30  loss: 0.1592 (0.1560)  time: 0.1721  data: 0.0001  max mem: 15821
[13:53:34.049001] Test:  [180/345]  eta: 0:00:28  loss: 0.1593 (0.1560)  time: 0.1724  data: 0.0001  max mem: 15821
[13:53:35.778841] Test:  [190/345]  eta: 0:00:26  loss: 0.1540 (0.1559)  time: 0.1727  data: 0.0001  max mem: 15821
[13:53:37.511867] Test:  [200/345]  eta: 0:00:24  loss: 0.1557 (0.1560)  time: 0.1731  data: 0.0001  max mem: 15821
[13:53:39.247477] Test:  [210/345]  eta: 0:00:23  loss: 0.1520 (0.1560)  time: 0.1734  data: 0.0001  max mem: 15821
[13:53:40.987852] Test:  [220/345]  eta: 0:00:21  loss: 0.1498 (0.1561)  time: 0.1737  data: 0.0001  max mem: 15821
[13:53:42.730698] Test:  [230/345]  eta: 0:00:19  loss: 0.1500 (0.1557)  time: 0.1741  data: 0.0001  max mem: 15821
[13:53:44.477227] Test:  [240/345]  eta: 0:00:18  loss: 0.1426 (0.1552)  time: 0.1744  data: 0.0001  max mem: 15821
[13:53:46.226731] Test:  [250/345]  eta: 0:00:16  loss: 0.1421 (0.1549)  time: 0.1747  data: 0.0001  max mem: 15821
[13:53:47.980483] Test:  [260/345]  eta: 0:00:14  loss: 0.1506 (0.1553)  time: 0.1751  data: 0.0001  max mem: 15821
[13:53:49.737104] Test:  [270/345]  eta: 0:00:12  loss: 0.1542 (0.1553)  time: 0.1755  data: 0.0001  max mem: 15821
[13:53:51.497415] Test:  [280/345]  eta: 0:00:11  loss: 0.1532 (0.1554)  time: 0.1758  data: 0.0001  max mem: 15821
[13:53:53.260191] Test:  [290/345]  eta: 0:00:09  loss: 0.1519 (0.1552)  time: 0.1761  data: 0.0001  max mem: 15821
[13:53:55.027060] Test:  [300/345]  eta: 0:00:07  loss: 0.1536 (0.1553)  time: 0.1764  data: 0.0001  max mem: 15821
[13:53:56.798653] Test:  [310/345]  eta: 0:00:06  loss: 0.1567 (0.1554)  time: 0.1769  data: 0.0001  max mem: 15821
[13:53:58.574167] Test:  [320/345]  eta: 0:00:04  loss: 0.1499 (0.1552)  time: 0.1773  data: 0.0001  max mem: 15821
[13:54:00.354054] Test:  [330/345]  eta: 0:00:02  loss: 0.1540 (0.1552)  time: 0.1777  data: 0.0001  max mem: 15821
[13:54:02.136628] Test:  [340/345]  eta: 0:00:00  loss: 0.1540 (0.1551)  time: 0.1781  data: 0.0001  max mem: 15821
[13:54:02.850044] Test:  [344/345]  eta: 0:00:00  loss: 0.1462 (0.1549)  time: 0.1782  data: 0.0001  max mem: 15821
[13:54:02.908698] Test: Total time: 0:00:59 (0.1738 s / it)
[13:54:12.802636] Test:  [ 0/57]  eta: 0:00:28  loss: 0.4418 (0.4418)  time: 0.4921  data: 0.3292  max mem: 15821
[13:54:14.453957] Test:  [10/57]  eta: 0:00:09  loss: 0.3768 (0.4275)  time: 0.1948  data: 0.0300  max mem: 15821
[13:54:16.111244] Test:  [20/57]  eta: 0:00:06  loss: 0.3924 (0.4175)  time: 0.1654  data: 0.0001  max mem: 15821
[13:54:17.771313] Test:  [30/57]  eta: 0:00:04  loss: 0.2820 (0.3597)  time: 0.1658  data: 0.0001  max mem: 15821
[13:54:19.435242] Test:  [40/57]  eta: 0:00:02  loss: 0.2440 (0.3370)  time: 0.1661  data: 0.0001  max mem: 15821
[13:54:21.104971] Test:  [50/57]  eta: 0:00:01  loss: 0.2793 (0.3339)  time: 0.1666  data: 0.0001  max mem: 15821
[13:54:22.006457] Test:  [56/57]  eta: 0:00:00  loss: 0.2818 (0.3369)  time: 0.1618  data: 0.0000  max mem: 15821
[13:54:22.073726] Test: Total time: 0:00:09 (0.1713 s / it)
[13:54:23.744875] Dice score of the network on the train images: 0.856139, val images: 0.808968
[13:54:23.749277] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:54:24.653760] Epoch: [27]  [  0/345]  eta: 0:05:11  lr: 0.000109  loss: 0.1357 (0.1357)  time: 0.9034  data: 0.3021  max mem: 15821
[13:54:36.682743] Epoch: [27]  [ 20/345]  eta: 0:03:20  lr: 0.000109  loss: 0.1536 (0.1543)  time: 0.6014  data: 0.0001  max mem: 15821
[13:54:48.732637] Epoch: [27]  [ 40/345]  eta: 0:03:05  lr: 0.000108  loss: 0.1502 (0.1540)  time: 0.6025  data: 0.0001  max mem: 15821
[13:55:00.791960] Epoch: [27]  [ 60/345]  eta: 0:02:53  lr: 0.000108  loss: 0.1544 (0.1558)  time: 0.6029  data: 0.0001  max mem: 15821
[13:55:12.862507] Epoch: [27]  [ 80/345]  eta: 0:02:40  lr: 0.000108  loss: 0.1515 (0.1553)  time: 0.6035  data: 0.0001  max mem: 15821
[13:55:24.948921] Epoch: [27]  [100/345]  eta: 0:02:28  lr: 0.000108  loss: 0.1509 (0.1557)  time: 0.6043  data: 0.0001  max mem: 15821
[13:55:37.038362] Epoch: [27]  [120/345]  eta: 0:02:16  lr: 0.000107  loss: 0.1606 (0.1572)  time: 0.6044  data: 0.0001  max mem: 15821
[13:55:49.140561] Epoch: [27]  [140/345]  eta: 0:02:04  lr: 0.000107  loss: 0.1494 (0.1567)  time: 0.6051  data: 0.0001  max mem: 15821
[13:56:01.252300] Epoch: [27]  [160/345]  eta: 0:01:52  lr: 0.000107  loss: 0.1536 (0.1567)  time: 0.6055  data: 0.0001  max mem: 15821
[13:56:13.358547] Epoch: [27]  [180/345]  eta: 0:01:39  lr: 0.000107  loss: 0.1535 (0.1566)  time: 0.6053  data: 0.0001  max mem: 15821
[13:56:25.465110] Epoch: [27]  [200/345]  eta: 0:01:27  lr: 0.000106  loss: 0.1518 (0.1570)  time: 0.6053  data: 0.0001  max mem: 15821
[13:56:37.577541] Epoch: [27]  [220/345]  eta: 0:01:15  lr: 0.000106  loss: 0.1427 (0.1563)  time: 0.6056  data: 0.0001  max mem: 15821
[13:56:49.791807] Epoch: [27]  [240/345]  eta: 0:01:03  lr: 0.000106  loss: 0.1466 (0.1560)  time: 0.6107  data: 0.0001  max mem: 15821
[13:57:01.871356] Epoch: [27]  [260/345]  eta: 0:00:51  lr: 0.000106  loss: 0.1524 (0.1558)  time: 0.6039  data: 0.0001  max mem: 15821
[13:57:13.955277] Epoch: [27]  [280/345]  eta: 0:00:39  lr: 0.000105  loss: 0.1513 (0.1562)  time: 0.6042  data: 0.0001  max mem: 15821
[13:57:26.047981] Epoch: [27]  [300/345]  eta: 0:00:27  lr: 0.000105  loss: 0.1533 (0.1563)  time: 0.6046  data: 0.0001  max mem: 15821
[13:57:38.143043] Epoch: [27]  [320/345]  eta: 0:00:15  lr: 0.000105  loss: 0.1540 (0.1565)  time: 0.6047  data: 0.0001  max mem: 15821
[13:57:50.243876] Epoch: [27]  [340/345]  eta: 0:00:03  lr: 0.000104  loss: 0.1536 (0.1561)  time: 0.6050  data: 0.0001  max mem: 15821
[13:57:52.661963] Epoch: [27]  [344/345]  eta: 0:00:00  lr: 0.000104  loss: 0.1531 (0.1561)  time: 0.6050  data: 0.0001  max mem: 15821
[13:57:52.740209] Epoch: [27] Total time: 0:03:28 (0.6058 s / it)
[13:57:52.740555] Averaged stats: lr: 0.000104  loss: 0.1531 (0.1561)
[13:57:53.300582] Test:  [  0/345]  eta: 0:03:11  loss: 0.1288 (0.1288)  time: 0.5550  data: 0.3912  max mem: 15821
[13:57:54.969768] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1525 (0.1483)  time: 0.2021  data: 0.0357  max mem: 15821
[13:57:56.640697] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1525 (0.1522)  time: 0.1669  data: 0.0001  max mem: 15821
[13:57:58.316139] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1548 (0.1541)  time: 0.1673  data: 0.0001  max mem: 15821
[13:57:59.992812] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1501 (0.1524)  time: 0.1675  data: 0.0001  max mem: 15821
[13:58:01.674766] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1520 (0.1531)  time: 0.1679  data: 0.0001  max mem: 15821
[13:58:03.358424] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1557 (0.1549)  time: 0.1682  data: 0.0001  max mem: 15821
[13:58:05.044535] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1540 (0.1541)  time: 0.1684  data: 0.0001  max mem: 15821
[13:58:06.735724] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1477 (0.1534)  time: 0.1688  data: 0.0001  max mem: 15821
[13:58:08.430652] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1498 (0.1541)  time: 0.1692  data: 0.0001  max mem: 15821
[13:58:10.129942] Test:  [100/345]  eta: 0:00:42  loss: 0.1522 (0.1537)  time: 0.1696  data: 0.0001  max mem: 15821
[13:58:11.831474] Test:  [110/345]  eta: 0:00:40  loss: 0.1522 (0.1541)  time: 0.1700  data: 0.0001  max mem: 15821
[13:58:13.535787] Test:  [120/345]  eta: 0:00:38  loss: 0.1555 (0.1542)  time: 0.1702  data: 0.0001  max mem: 15821
[13:58:15.244272] Test:  [130/345]  eta: 0:00:36  loss: 0.1557 (0.1548)  time: 0.1706  data: 0.0001  max mem: 15821
[13:58:16.954981] Test:  [140/345]  eta: 0:00:35  loss: 0.1563 (0.1548)  time: 0.1709  data: 0.0001  max mem: 15821
[13:58:18.669538] Test:  [150/345]  eta: 0:00:33  loss: 0.1468 (0.1541)  time: 0.1712  data: 0.0001  max mem: 15821
[13:58:20.388486] Test:  [160/345]  eta: 0:00:31  loss: 0.1455 (0.1540)  time: 0.1716  data: 0.0001  max mem: 15821
[13:58:22.111101] Test:  [170/345]  eta: 0:00:30  loss: 0.1461 (0.1536)  time: 0.1720  data: 0.0001  max mem: 15821
[13:58:23.835164] Test:  [180/345]  eta: 0:00:28  loss: 0.1505 (0.1542)  time: 0.1723  data: 0.0001  max mem: 15821
[13:58:25.564930] Test:  [190/345]  eta: 0:00:26  loss: 0.1498 (0.1539)  time: 0.1726  data: 0.0001  max mem: 15821
[13:58:27.297599] Test:  [200/345]  eta: 0:00:24  loss: 0.1469 (0.1540)  time: 0.1731  data: 0.0001  max mem: 15821
[13:58:29.033364] Test:  [210/345]  eta: 0:00:23  loss: 0.1605 (0.1543)  time: 0.1734  data: 0.0001  max mem: 15821
[13:58:30.772394] Test:  [220/345]  eta: 0:00:21  loss: 0.1501 (0.1539)  time: 0.1737  data: 0.0001  max mem: 15821
[13:58:32.513976] Test:  [230/345]  eta: 0:00:19  loss: 0.1447 (0.1538)  time: 0.1740  data: 0.0001  max mem: 15821
[13:58:34.260626] Test:  [240/345]  eta: 0:00:18  loss: 0.1597 (0.1543)  time: 0.1744  data: 0.0001  max mem: 15821
[13:58:36.009671] Test:  [250/345]  eta: 0:00:16  loss: 0.1562 (0.1543)  time: 0.1747  data: 0.0001  max mem: 15821
[13:58:37.763416] Test:  [260/345]  eta: 0:00:14  loss: 0.1484 (0.1543)  time: 0.1751  data: 0.0001  max mem: 15821
[13:58:39.520711] Test:  [270/345]  eta: 0:00:12  loss: 0.1548 (0.1546)  time: 0.1755  data: 0.0001  max mem: 15821
[13:58:41.280689] Test:  [280/345]  eta: 0:00:11  loss: 0.1548 (0.1549)  time: 0.1758  data: 0.0001  max mem: 15821
[13:58:43.043818] Test:  [290/345]  eta: 0:00:09  loss: 0.1466 (0.1545)  time: 0.1761  data: 0.0001  max mem: 15821
[13:58:44.809664] Test:  [300/345]  eta: 0:00:07  loss: 0.1466 (0.1543)  time: 0.1764  data: 0.0001  max mem: 15821
[13:58:46.582500] Test:  [310/345]  eta: 0:00:06  loss: 0.1466 (0.1542)  time: 0.1769  data: 0.0001  max mem: 15821
[13:58:48.357350] Test:  [320/345]  eta: 0:00:04  loss: 0.1458 (0.1541)  time: 0.1773  data: 0.0001  max mem: 15821
[13:58:50.134524] Test:  [330/345]  eta: 0:00:02  loss: 0.1524 (0.1545)  time: 0.1775  data: 0.0001  max mem: 15821
[13:58:51.917577] Test:  [340/345]  eta: 0:00:00  loss: 0.1471 (0.1543)  time: 0.1780  data: 0.0001  max mem: 15821
[13:58:52.630465] Test:  [344/345]  eta: 0:00:00  loss: 0.1462 (0.1543)  time: 0.1781  data: 0.0001  max mem: 15821
[13:58:52.707970] Test: Total time: 0:00:59 (0.1738 s / it)
[13:59:02.644621] Test:  [ 0/57]  eta: 0:00:28  loss: 0.4564 (0.4564)  time: 0.5069  data: 0.3433  max mem: 15821
[13:59:04.295505] Test:  [10/57]  eta: 0:00:09  loss: 0.4048 (0.4248)  time: 0.1961  data: 0.0313  max mem: 15821
[13:59:05.951509] Test:  [20/57]  eta: 0:00:06  loss: 0.3929 (0.4020)  time: 0.1653  data: 0.0001  max mem: 15821
[13:59:07.611536] Test:  [30/57]  eta: 0:00:04  loss: 0.2482 (0.3401)  time: 0.1657  data: 0.0001  max mem: 15821
[13:59:09.275139] Test:  [40/57]  eta: 0:00:02  loss: 0.2104 (0.3123)  time: 0.1661  data: 0.0001  max mem: 15821
[13:59:10.942727] Test:  [50/57]  eta: 0:00:01  loss: 0.2420 (0.3121)  time: 0.1665  data: 0.0001  max mem: 15821
[13:59:11.842946] Test:  [56/57]  eta: 0:00:00  loss: 0.2725 (0.3244)  time: 0.1616  data: 0.0001  max mem: 15821
[13:59:11.901950] Test: Total time: 0:00:09 (0.1713 s / it)
[13:59:13.587854] Dice score of the network on the train images: 0.843218, val images: 0.812384
[13:59:13.592243] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:59:14.518111] Epoch: [28]  [  0/345]  eta: 0:05:19  lr: 0.000104  loss: 0.1555 (0.1555)  time: 0.9247  data: 0.3226  max mem: 15821
[13:59:26.543188] Epoch: [28]  [ 20/345]  eta: 0:03:20  lr: 0.000104  loss: 0.1648 (0.1651)  time: 0.6012  data: 0.0001  max mem: 15821
[13:59:38.587545] Epoch: [28]  [ 40/345]  eta: 0:03:05  lr: 0.000104  loss: 0.1473 (0.1582)  time: 0.6022  data: 0.0001  max mem: 15821
[13:59:50.637941] Epoch: [28]  [ 60/345]  eta: 0:02:53  lr: 0.000103  loss: 0.1507 (0.1564)  time: 0.6025  data: 0.0001  max mem: 15821
[14:00:02.710906] Epoch: [28]  [ 80/345]  eta: 0:02:40  lr: 0.000103  loss: 0.1472 (0.1550)  time: 0.6036  data: 0.0001  max mem: 15821
[14:00:14.796103] Epoch: [28]  [100/345]  eta: 0:02:28  lr: 0.000103  loss: 0.1575 (0.1553)  time: 0.6042  data: 0.0001  max mem: 15821
[14:00:26.883902] Epoch: [28]  [120/345]  eta: 0:02:16  lr: 0.000103  loss: 0.1481 (0.1553)  time: 0.6043  data: 0.0001  max mem: 15821
[14:00:39.003722] Epoch: [28]  [140/345]  eta: 0:02:04  lr: 0.000102  loss: 0.1441 (0.1542)  time: 0.6060  data: 0.0001  max mem: 15821
[14:00:51.123293] Epoch: [28]  [160/345]  eta: 0:01:52  lr: 0.000102  loss: 0.1606 (0.1548)  time: 0.6059  data: 0.0001  max mem: 15821
[14:01:03.239796] Epoch: [28]  [180/345]  eta: 0:01:39  lr: 0.000102  loss: 0.1392 (0.1541)  time: 0.6058  data: 0.0001  max mem: 15821
[14:01:15.356551] Epoch: [28]  [200/345]  eta: 0:01:27  lr: 0.000101  loss: 0.1473 (0.1538)  time: 0.6058  data: 0.0001  max mem: 15821
[14:01:27.472048] Epoch: [28]  [220/345]  eta: 0:01:15  lr: 0.000101  loss: 0.1569 (0.1537)  time: 0.6057  data: 0.0001  max mem: 15821
[14:01:39.580871] Epoch: [28]  [240/345]  eta: 0:01:03  lr: 0.000101  loss: 0.1589 (0.1539)  time: 0.6054  data: 0.0001  max mem: 15821
[14:01:51.688772] Epoch: [28]  [260/345]  eta: 0:00:51  lr: 0.000101  loss: 0.1531 (0.1539)  time: 0.6054  data: 0.0001  max mem: 15821
[14:02:03.788518] Epoch: [28]  [280/345]  eta: 0:00:39  lr: 0.000100  loss: 0.1479 (0.1538)  time: 0.6049  data: 0.0001  max mem: 15821
[14:02:15.900335] Epoch: [28]  [300/345]  eta: 0:00:27  lr: 0.000100  loss: 0.1464 (0.1535)  time: 0.6055  data: 0.0001  max mem: 15821
[14:02:28.021806] Epoch: [28]  [320/345]  eta: 0:00:15  lr: 0.000100  loss: 0.1480 (0.1531)  time: 0.6060  data: 0.0001  max mem: 15821
[14:02:40.138605] Epoch: [28]  [340/345]  eta: 0:00:03  lr: 0.000099  loss: 0.1461 (0.1529)  time: 0.6058  data: 0.0001  max mem: 15821
[14:02:42.563113] Epoch: [28]  [344/345]  eta: 0:00:00  lr: 0.000099  loss: 0.1505 (0.1529)  time: 0.6059  data: 0.0001  max mem: 15821
[14:02:42.631715] Epoch: [28] Total time: 0:03:29 (0.6059 s / it)
[14:02:42.632328] Averaged stats: lr: 0.000099  loss: 0.1505 (0.1529)
[14:02:43.156642] Test:  [  0/345]  eta: 0:02:58  loss: 0.1374 (0.1374)  time: 0.5188  data: 0.3542  max mem: 15821
[14:02:44.827730] Test:  [ 10/345]  eta: 0:01:06  loss: 0.1319 (0.1369)  time: 0.1990  data: 0.0323  max mem: 15821
[14:02:46.501686] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1376 (0.1401)  time: 0.1672  data: 0.0001  max mem: 15821
[14:02:48.178311] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1473 (0.1431)  time: 0.1675  data: 0.0001  max mem: 15821
[14:02:49.857676] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1415 (0.1415)  time: 0.1677  data: 0.0001  max mem: 15821
[14:02:51.540610] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1399 (0.1414)  time: 0.1681  data: 0.0001  max mem: 15821
[14:02:53.227628] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1408 (0.1413)  time: 0.1684  data: 0.0001  max mem: 15821
[14:02:54.916972] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1397 (0.1406)  time: 0.1688  data: 0.0001  max mem: 15821
[14:02:56.611138] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1329 (0.1400)  time: 0.1691  data: 0.0001  max mem: 15821
[14:02:58.307945] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1334 (0.1407)  time: 0.1695  data: 0.0001  max mem: 15821
[14:03:00.007948] Test:  [100/345]  eta: 0:00:42  loss: 0.1372 (0.1409)  time: 0.1698  data: 0.0001  max mem: 15821
[14:03:01.711571] Test:  [110/345]  eta: 0:00:40  loss: 0.1392 (0.1415)  time: 0.1701  data: 0.0001  max mem: 15821
[14:03:03.418595] Test:  [120/345]  eta: 0:00:38  loss: 0.1415 (0.1418)  time: 0.1705  data: 0.0001  max mem: 15821
[14:03:05.129224] Test:  [130/345]  eta: 0:00:36  loss: 0.1415 (0.1420)  time: 0.1708  data: 0.0001  max mem: 15821
[14:03:06.843380] Test:  [140/345]  eta: 0:00:35  loss: 0.1481 (0.1424)  time: 0.1712  data: 0.0001  max mem: 15821
[14:03:08.560036] Test:  [150/345]  eta: 0:00:33  loss: 0.1461 (0.1420)  time: 0.1715  data: 0.0001  max mem: 15821
[14:03:10.281930] Test:  [160/345]  eta: 0:00:31  loss: 0.1367 (0.1420)  time: 0.1719  data: 0.0001  max mem: 15821
[14:03:12.006298] Test:  [170/345]  eta: 0:00:30  loss: 0.1379 (0.1417)  time: 0.1723  data: 0.0001  max mem: 15821
[14:03:13.734436] Test:  [180/345]  eta: 0:00:28  loss: 0.1379 (0.1418)  time: 0.1726  data: 0.0001  max mem: 15821
[14:03:15.465689] Test:  [190/345]  eta: 0:00:26  loss: 0.1351 (0.1415)  time: 0.1729  data: 0.0001  max mem: 15821
[14:03:17.200146] Test:  [200/345]  eta: 0:00:24  loss: 0.1409 (0.1417)  time: 0.1732  data: 0.0001  max mem: 15821
[14:03:18.937814] Test:  [210/345]  eta: 0:00:23  loss: 0.1510 (0.1422)  time: 0.1735  data: 0.0001  max mem: 15821
[14:03:20.679278] Test:  [220/345]  eta: 0:00:21  loss: 0.1406 (0.1420)  time: 0.1739  data: 0.0001  max mem: 15821
[14:03:22.422792] Test:  [230/345]  eta: 0:00:19  loss: 0.1406 (0.1423)  time: 0.1742  data: 0.0001  max mem: 15821
[14:03:24.171211] Test:  [240/345]  eta: 0:00:18  loss: 0.1496 (0.1426)  time: 0.1745  data: 0.0001  max mem: 15821
[14:03:25.922538] Test:  [250/345]  eta: 0:00:16  loss: 0.1451 (0.1427)  time: 0.1749  data: 0.0001  max mem: 15821
[14:03:27.677168] Test:  [260/345]  eta: 0:00:14  loss: 0.1451 (0.1429)  time: 0.1752  data: 0.0001  max mem: 15821
[14:03:29.436312] Test:  [270/345]  eta: 0:00:12  loss: 0.1411 (0.1428)  time: 0.1756  data: 0.0001  max mem: 15821
[14:03:31.199460] Test:  [280/345]  eta: 0:00:11  loss: 0.1337 (0.1425)  time: 0.1761  data: 0.0001  max mem: 15821
[14:03:32.966237] Test:  [290/345]  eta: 0:00:09  loss: 0.1337 (0.1425)  time: 0.1764  data: 0.0001  max mem: 15821
[14:03:34.734171] Test:  [300/345]  eta: 0:00:07  loss: 0.1450 (0.1425)  time: 0.1767  data: 0.0001  max mem: 15821
[14:03:36.507655] Test:  [310/345]  eta: 0:00:06  loss: 0.1364 (0.1428)  time: 0.1770  data: 0.0001  max mem: 15821
[14:03:38.283199] Test:  [320/345]  eta: 0:00:04  loss: 0.1364 (0.1430)  time: 0.1774  data: 0.0001  max mem: 15821
[14:03:40.064901] Test:  [330/345]  eta: 0:00:02  loss: 0.1486 (0.1434)  time: 0.1778  data: 0.0001  max mem: 15821
[14:03:41.848422] Test:  [340/345]  eta: 0:00:00  loss: 0.1485 (0.1434)  time: 0.1782  data: 0.0001  max mem: 15821
[14:03:42.564006] Test:  [344/345]  eta: 0:00:00  loss: 0.1433 (0.1434)  time: 0.1784  data: 0.0001  max mem: 15821
[14:03:42.628706] Test: Total time: 0:00:59 (0.1739 s / it)
[14:03:52.522559] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4761 (0.4761)  time: 0.4658  data: 0.3035  max mem: 15821
[14:03:54.173066] Test:  [10/57]  eta: 0:00:09  loss: 0.4020 (0.4295)  time: 0.1923  data: 0.0277  max mem: 15821
[14:03:55.828956] Test:  [20/57]  eta: 0:00:06  loss: 0.4020 (0.4146)  time: 0.1652  data: 0.0001  max mem: 15821
[14:03:57.489552] Test:  [30/57]  eta: 0:00:04  loss: 0.2635 (0.3530)  time: 0.1658  data: 0.0001  max mem: 15821
[14:03:59.154799] Test:  [40/57]  eta: 0:00:02  loss: 0.2203 (0.3264)  time: 0.1662  data: 0.0001  max mem: 15821
[14:04:00.825470] Test:  [50/57]  eta: 0:00:01  loss: 0.2573 (0.3246)  time: 0.1667  data: 0.0001  max mem: 15821
[14:04:01.726199] Test:  [56/57]  eta: 0:00:00  loss: 0.2788 (0.3313)  time: 0.1619  data: 0.0000  max mem: 15821
[14:04:01.796023] Test: Total time: 0:00:09 (0.1709 s / it)
[14:04:03.448005] Dice score of the network on the train images: 0.864608, val images: 0.813489
[14:04:03.452896] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:04:04.353492] Epoch: [29]  [  0/345]  eta: 0:05:10  lr: 0.000099  loss: 0.1586 (0.1586)  time: 0.8996  data: 0.2979  max mem: 15821
[14:04:16.387086] Epoch: [29]  [ 20/345]  eta: 0:03:20  lr: 0.000099  loss: 0.1426 (0.1490)  time: 0.6016  data: 0.0001  max mem: 15821
[14:04:28.447057] Epoch: [29]  [ 40/345]  eta: 0:03:05  lr: 0.000099  loss: 0.1423 (0.1491)  time: 0.6030  data: 0.0001  max mem: 15821
[14:04:40.520145] Epoch: [29]  [ 60/345]  eta: 0:02:53  lr: 0.000098  loss: 0.1373 (0.1466)  time: 0.6036  data: 0.0001  max mem: 15821
[14:04:52.607144] Epoch: [29]  [ 80/345]  eta: 0:02:40  lr: 0.000098  loss: 0.1472 (0.1483)  time: 0.6043  data: 0.0001  max mem: 15821
[14:05:04.692105] Epoch: [29]  [100/345]  eta: 0:02:28  lr: 0.000098  loss: 0.1354 (0.1469)  time: 0.6042  data: 0.0001  max mem: 15821
[14:05:16.787302] Epoch: [29]  [120/345]  eta: 0:02:16  lr: 0.000097  loss: 0.1339 (0.1464)  time: 0.6047  data: 0.0001  max mem: 15821
[14:05:28.891058] Epoch: [29]  [140/345]  eta: 0:02:04  lr: 0.000097  loss: 0.1390 (0.1470)  time: 0.6051  data: 0.0001  max mem: 15821
[14:05:41.019505] Epoch: [29]  [160/345]  eta: 0:01:52  lr: 0.000097  loss: 0.1468 (0.1471)  time: 0.6064  data: 0.0001  max mem: 15821
[14:05:53.153828] Epoch: [29]  [180/345]  eta: 0:01:39  lr: 0.000096  loss: 0.1526 (0.1477)  time: 0.6067  data: 0.0001  max mem: 15821
[14:06:05.276109] Epoch: [29]  [200/345]  eta: 0:01:27  lr: 0.000096  loss: 0.1391 (0.1472)  time: 0.6061  data: 0.0001  max mem: 15821
[14:06:17.390533] Epoch: [29]  [220/345]  eta: 0:01:15  lr: 0.000096  loss: 0.1394 (0.1467)  time: 0.6057  data: 0.0001  max mem: 15821
[14:06:29.513097] Epoch: [29]  [240/345]  eta: 0:01:03  lr: 0.000095  loss: 0.1405 (0.1462)  time: 0.6061  data: 0.0001  max mem: 15821
[14:06:41.629481] Epoch: [29]  [260/345]  eta: 0:00:51  lr: 0.000095  loss: 0.1549 (0.1467)  time: 0.6058  data: 0.0001  max mem: 15821
[14:06:53.742224] Epoch: [29]  [280/345]  eta: 0:00:39  lr: 0.000095  loss: 0.1470 (0.1470)  time: 0.6056  data: 0.0001  max mem: 15821
[14:07:05.852431] Epoch: [29]  [300/345]  eta: 0:00:27  lr: 0.000094  loss: 0.1473 (0.1473)  time: 0.6055  data: 0.0001  max mem: 15821
[14:07:17.967485] Epoch: [29]  [320/345]  eta: 0:00:15  lr: 0.000094  loss: 0.1538 (0.1479)  time: 0.6057  data: 0.0001  max mem: 15821
[14:07:30.088796] Epoch: [29]  [340/345]  eta: 0:00:03  lr: 0.000094  loss: 0.1592 (0.1491)  time: 0.6060  data: 0.0001  max mem: 15821
[14:07:32.511819] Epoch: [29]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.1629 (0.1494)  time: 0.6059  data: 0.0001  max mem: 15821
[14:07:32.581687] Epoch: [29] Total time: 0:03:29 (0.6062 s / it)
[14:07:32.582036] Averaged stats: lr: 0.000094  loss: 0.1629 (0.1494)
[14:07:33.133051] Test:  [  0/345]  eta: 0:03:08  loss: 0.1400 (0.1400)  time: 0.5461  data: 0.3814  max mem: 15821
[14:07:34.802974] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1495 (0.1468)  time: 0.2014  data: 0.0347  max mem: 15821
[14:07:36.475912] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1482 (0.1482)  time: 0.1671  data: 0.0001  max mem: 15821
[14:07:38.152129] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1534 (0.1505)  time: 0.1674  data: 0.0001  max mem: 15821
[14:07:39.830883] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1555 (0.1536)  time: 0.1677  data: 0.0001  max mem: 15821
[14:07:41.513667] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1629 (0.1538)  time: 0.1680  data: 0.0001  max mem: 15821
[14:07:43.198822] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1521 (0.1537)  time: 0.1683  data: 0.0001  max mem: 15821
[14:07:44.887526] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1502 (0.1534)  time: 0.1686  data: 0.0001  max mem: 15821
[14:07:46.581086] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1507 (0.1539)  time: 0.1691  data: 0.0001  max mem: 15821
[14:07:48.278017] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1558 (0.1544)  time: 0.1695  data: 0.0001  max mem: 15821
[14:07:49.978283] Test:  [100/345]  eta: 0:00:42  loss: 0.1575 (0.1548)  time: 0.1698  data: 0.0001  max mem: 15821
[14:07:51.681802] Test:  [110/345]  eta: 0:00:40  loss: 0.1472 (0.1540)  time: 0.1701  data: 0.0001  max mem: 15821
[14:07:53.389749] Test:  [120/345]  eta: 0:00:38  loss: 0.1455 (0.1537)  time: 0.1705  data: 0.0001  max mem: 15821
[14:07:55.100653] Test:  [130/345]  eta: 0:00:36  loss: 0.1465 (0.1538)  time: 0.1709  data: 0.0001  max mem: 15821
[14:07:56.814418] Test:  [140/345]  eta: 0:00:35  loss: 0.1537 (0.1538)  time: 0.1712  data: 0.0001  max mem: 15821
[14:07:58.530746] Test:  [150/345]  eta: 0:00:33  loss: 0.1500 (0.1535)  time: 0.1714  data: 0.0001  max mem: 15821
[14:08:00.251714] Test:  [160/345]  eta: 0:00:31  loss: 0.1527 (0.1542)  time: 0.1718  data: 0.0001  max mem: 15821
[14:08:01.976771] Test:  [170/345]  eta: 0:00:30  loss: 0.1568 (0.1539)  time: 0.1722  data: 0.0001  max mem: 15821
[14:08:03.703274] Test:  [180/345]  eta: 0:00:28  loss: 0.1452 (0.1538)  time: 0.1725  data: 0.0001  max mem: 15821
[14:08:05.435414] Test:  [190/345]  eta: 0:00:26  loss: 0.1479 (0.1535)  time: 0.1729  data: 0.0001  max mem: 15821
[14:08:07.169439] Test:  [200/345]  eta: 0:00:24  loss: 0.1512 (0.1538)  time: 0.1732  data: 0.0001  max mem: 15821
[14:08:08.906819] Test:  [210/345]  eta: 0:00:23  loss: 0.1560 (0.1542)  time: 0.1735  data: 0.0001  max mem: 15821
[14:08:10.647281] Test:  [220/345]  eta: 0:00:21  loss: 0.1540 (0.1543)  time: 0.1738  data: 0.0001  max mem: 15821
[14:08:12.391780] Test:  [230/345]  eta: 0:00:19  loss: 0.1540 (0.1542)  time: 0.1742  data: 0.0001  max mem: 15821
[14:08:14.139663] Test:  [240/345]  eta: 0:00:18  loss: 0.1510 (0.1541)  time: 0.1746  data: 0.0001  max mem: 15821
[14:08:15.892312] Test:  [250/345]  eta: 0:00:16  loss: 0.1510 (0.1541)  time: 0.1750  data: 0.0001  max mem: 15821
[14:08:17.647387] Test:  [260/345]  eta: 0:00:14  loss: 0.1530 (0.1540)  time: 0.1753  data: 0.0001  max mem: 15821
[14:08:19.405318] Test:  [270/345]  eta: 0:00:12  loss: 0.1541 (0.1540)  time: 0.1756  data: 0.0001  max mem: 15821
[14:08:21.166800] Test:  [280/345]  eta: 0:00:11  loss: 0.1472 (0.1537)  time: 0.1759  data: 0.0001  max mem: 15821
[14:08:22.932671] Test:  [290/345]  eta: 0:00:09  loss: 0.1542 (0.1541)  time: 0.1763  data: 0.0001  max mem: 15821
[14:08:24.700778] Test:  [300/345]  eta: 0:00:07  loss: 0.1602 (0.1540)  time: 0.1766  data: 0.0001  max mem: 15821
[14:08:26.473575] Test:  [310/345]  eta: 0:00:06  loss: 0.1473 (0.1538)  time: 0.1770  data: 0.0001  max mem: 15821
[14:08:28.249354] Test:  [320/345]  eta: 0:00:04  loss: 0.1473 (0.1538)  time: 0.1774  data: 0.0001  max mem: 15821
[14:08:30.030389] Test:  [330/345]  eta: 0:00:02  loss: 0.1445 (0.1536)  time: 0.1778  data: 0.0001  max mem: 15821
[14:08:31.813675] Test:  [340/345]  eta: 0:00:00  loss: 0.1444 (0.1535)  time: 0.1782  data: 0.0001  max mem: 15821
[14:08:32.529150] Test:  [344/345]  eta: 0:00:00  loss: 0.1444 (0.1534)  time: 0.1784  data: 0.0001  max mem: 15821
[14:08:32.602538] Test: Total time: 0:01:00 (0.1740 s / it)
[14:08:42.497627] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4350 (0.4350)  time: 0.4516  data: 0.2885  max mem: 15821
[14:08:44.148086] Test:  [10/57]  eta: 0:00:08  loss: 0.3793 (0.3905)  time: 0.1910  data: 0.0263  max mem: 15821
[14:08:45.802472] Test:  [20/57]  eta: 0:00:06  loss: 0.3772 (0.3802)  time: 0.1652  data: 0.0001  max mem: 15821
[14:08:47.463693] Test:  [30/57]  eta: 0:00:04  loss: 0.2645 (0.3289)  time: 0.1657  data: 0.0001  max mem: 15821
[14:08:49.128572] Test:  [40/57]  eta: 0:00:02  loss: 0.2282 (0.3073)  time: 0.1662  data: 0.0001  max mem: 15821
[14:08:50.797744] Test:  [50/57]  eta: 0:00:01  loss: 0.2531 (0.3047)  time: 0.1666  data: 0.0001  max mem: 15821
[14:08:51.697848] Test:  [56/57]  eta: 0:00:00  loss: 0.2714 (0.3064)  time: 0.1617  data: 0.0000  max mem: 15821
[14:08:51.753635] Test: Total time: 0:00:09 (0.1703 s / it)
[14:08:53.410691] Dice score of the network on the train images: 0.834209, val images: 0.815750
[14:08:53.410902] saving best_dice_model_0 @ epoch 29
[14:08:54.680723] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:08:55.578720] Epoch: [30]  [  0/345]  eta: 0:05:09  lr: 0.000094  loss: 0.1568 (0.1568)  time: 0.8969  data: 0.2958  max mem: 15821
[14:09:07.593616] Epoch: [30]  [ 20/345]  eta: 0:03:19  lr: 0.000093  loss: 0.1401 (0.1491)  time: 0.6007  data: 0.0001  max mem: 15821
[14:09:19.637582] Epoch: [30]  [ 40/345]  eta: 0:03:05  lr: 0.000093  loss: 0.1420 (0.1486)  time: 0.6021  data: 0.0001  max mem: 15821
[14:09:31.700023] Epoch: [30]  [ 60/345]  eta: 0:02:52  lr: 0.000093  loss: 0.1477 (0.1489)  time: 0.6031  data: 0.0001  max mem: 15821
[14:09:43.782592] Epoch: [30]  [ 80/345]  eta: 0:02:40  lr: 0.000092  loss: 0.1462 (0.1484)  time: 0.6041  data: 0.0001  max mem: 15821
[14:09:55.877011] Epoch: [30]  [100/345]  eta: 0:02:28  lr: 0.000092  loss: 0.1366 (0.1473)  time: 0.6047  data: 0.0001  max mem: 15821
[14:10:07.982343] Epoch: [30]  [120/345]  eta: 0:02:16  lr: 0.000092  loss: 0.1312 (0.1462)  time: 0.6052  data: 0.0001  max mem: 15821
[14:10:20.099561] Epoch: [30]  [140/345]  eta: 0:02:04  lr: 0.000091  loss: 0.1356 (0.1459)  time: 0.6058  data: 0.0001  max mem: 15821
[14:10:32.245146] Epoch: [30]  [160/345]  eta: 0:01:52  lr: 0.000091  loss: 0.1476 (0.1462)  time: 0.6072  data: 0.0001  max mem: 15821
[14:10:44.386025] Epoch: [30]  [180/345]  eta: 0:01:39  lr: 0.000091  loss: 0.1398 (0.1460)  time: 0.6070  data: 0.0001  max mem: 15821
[14:10:56.535228] Epoch: [30]  [200/345]  eta: 0:01:27  lr: 0.000090  loss: 0.1452 (0.1459)  time: 0.6074  data: 0.0001  max mem: 15821
[14:11:08.685760] Epoch: [30]  [220/345]  eta: 0:01:15  lr: 0.000090  loss: 0.1375 (0.1453)  time: 0.6075  data: 0.0001  max mem: 15821
[14:11:20.826265] Epoch: [30]  [240/345]  eta: 0:01:03  lr: 0.000090  loss: 0.1496 (0.1462)  time: 0.6070  data: 0.0001  max mem: 15821
[14:11:32.961521] Epoch: [30]  [260/345]  eta: 0:00:51  lr: 0.000089  loss: 0.1587 (0.1472)  time: 0.6067  data: 0.0001  max mem: 15821
[14:11:45.096567] Epoch: [30]  [280/345]  eta: 0:00:39  lr: 0.000089  loss: 0.1537 (0.1477)  time: 0.6067  data: 0.0001  max mem: 15821

[14:11:57.229613] Epoch: [30]  [300/345]  eta: 0:00:27  lr: 0.000089  loss: 0.1456 (0.1477)  time: 0.6066  data: 0.0001  max mem: 15821
[14:12:09.353811] Epoch: [30]  [320/345]  eta: 0:00:15  lr: 0.000088  loss: 0.1393 (0.1476)  time: 0.6062  data: 0.0001  max mem: 15821
[14:12:21.473101] Epoch: [30]  [340/345]  eta: 0:00:03  lr: 0.000088  loss: 0.1531 (0.1480)  time: 0.6059  data: 0.0001  max mem: 15821
[14:12:23.895755] Epoch: [30]  [344/345]  eta: 0:00:00  lr: 0.000088  loss: 0.1608 (0.1481)  time: 0.6057  data: 0.0001  max mem: 15821
[14:12:23.957439] Epoch: [30] Total time: 0:03:29 (0.6066 s / it)
[14:12:23.957936] Averaged stats: lr: 0.000088  loss: 0.1608 (0.1481)
[14:12:24.504075] Test:  [  0/345]  eta: 0:03:06  loss: 0.1286 (0.1286)  time: 0.5416  data: 0.3773  max mem: 15821
[14:12:26.174653] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1545 (0.1472)  time: 0.2010  data: 0.0344  max mem: 15821
[14:12:27.847971] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1358 (0.1437)  time: 0.1671  data: 0.0001  max mem: 15821
[14:12:29.525686] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1354 (0.1438)  time: 0.1675  data: 0.0001  max mem: 15821
[14:12:31.205388] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1429 (0.1433)  time: 0.1678  data: 0.0001  max mem: 15821
[14:12:32.889146] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1395 (0.1423)  time: 0.1681  data: 0.0001  max mem: 15821
[14:12:34.575722] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1395 (0.1423)  time: 0.1684  data: 0.0001  max mem: 15821
[14:12:36.264992] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1370 (0.1417)  time: 0.1687  data: 0.0001  max mem: 15821
[14:12:37.957860] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1366 (0.1415)  time: 0.1690  data: 0.0001  max mem: 15821
[14:12:39.653586] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1343 (0.1411)  time: 0.1694  data: 0.0001  max mem: 15821
[14:12:41.353636] Test:  [100/345]  eta: 0:00:42  loss: 0.1407 (0.1422)  time: 0.1697  data: 0.0001  max mem: 15821
[14:12:43.057717] Test:  [110/345]  eta: 0:00:40  loss: 0.1324 (0.1415)  time: 0.1701  data: 0.0001  max mem: 15821
[14:12:44.764612] Test:  [120/345]  eta: 0:00:38  loss: 0.1308 (0.1413)  time: 0.1705  data: 0.0001  max mem: 15821
[14:12:46.474609] Test:  [130/345]  eta: 0:00:36  loss: 0.1333 (0.1405)  time: 0.1708  data: 0.0001  max mem: 15821
[14:12:48.187842] Test:  [140/345]  eta: 0:00:35  loss: 0.1333 (0.1407)  time: 0.1711  data: 0.0001  max mem: 15821
[14:12:49.905383] Test:  [150/345]  eta: 0:00:33  loss: 0.1374 (0.1405)  time: 0.1715  data: 0.0001  max mem: 15821
[14:12:51.627372] Test:  [160/345]  eta: 0:00:31  loss: 0.1350 (0.1400)  time: 0.1719  data: 0.0001  max mem: 15821
[14:12:53.352635] Test:  [170/345]  eta: 0:00:30  loss: 0.1276 (0.1399)  time: 0.1723  data: 0.0001  max mem: 15821
[14:12:55.081644] Test:  [180/345]  eta: 0:00:28  loss: 0.1276 (0.1400)  time: 0.1726  data: 0.0001  max mem: 15821
[14:12:56.813852] Test:  [190/345]  eta: 0:00:26  loss: 0.1353 (0.1401)  time: 0.1730  data: 0.0001  max mem: 15821
[14:12:58.548589] Test:  [200/345]  eta: 0:00:24  loss: 0.1365 (0.1398)  time: 0.1733  data: 0.0001  max mem: 15821
[14:13:00.286664] Test:  [210/345]  eta: 0:00:23  loss: 0.1365 (0.1395)  time: 0.1736  data: 0.0001  max mem: 15821
[14:13:02.027854] Test:  [220/345]  eta: 0:00:21  loss: 0.1338 (0.1395)  time: 0.1739  data: 0.0001  max mem: 15821
[14:13:03.773700] Test:  [230/345]  eta: 0:00:19  loss: 0.1405 (0.1398)  time: 0.1743  data: 0.0001  max mem: 15821
[14:13:05.520953] Test:  [240/345]  eta: 0:00:18  loss: 0.1405 (0.1401)  time: 0.1746  data: 0.0001  max mem: 15821
[14:13:07.273173] Test:  [250/345]  eta: 0:00:16  loss: 0.1316 (0.1400)  time: 0.1749  data: 0.0001  max mem: 15821
[14:13:09.027691] Test:  [260/345]  eta: 0:00:14  loss: 0.1350 (0.1399)  time: 0.1753  data: 0.0001  max mem: 15821
[14:13:10.787593] Test:  [270/345]  eta: 0:00:12  loss: 0.1356 (0.1401)  time: 0.1756  data: 0.0001  max mem: 15821
[14:13:12.549309] Test:  [280/345]  eta: 0:00:11  loss: 0.1353 (0.1397)  time: 0.1760  data: 0.0001  max mem: 15821
[14:13:14.315876] Test:  [290/345]  eta: 0:00:09  loss: 0.1335 (0.1401)  time: 0.1764  data: 0.0001  max mem: 15821
[14:13:16.084597] Test:  [300/345]  eta: 0:00:07  loss: 0.1409 (0.1400)  time: 0.1767  data: 0.0001  max mem: 15821
[14:13:17.858212] Test:  [310/345]  eta: 0:00:06  loss: 0.1376 (0.1401)  time: 0.1771  data: 0.0001  max mem: 15821
[14:13:19.634778] Test:  [320/345]  eta: 0:00:04  loss: 0.1381 (0.1401)  time: 0.1774  data: 0.0001  max mem: 15821
[14:13:21.414734] Test:  [330/345]  eta: 0:00:02  loss: 0.1381 (0.1400)  time: 0.1778  data: 0.0001  max mem: 15821
[14:13:23.198811] Test:  [340/345]  eta: 0:00:00  loss: 0.1352 (0.1399)  time: 0.1781  data: 0.0001  max mem: 15821
[14:13:23.914690] Test:  [344/345]  eta: 0:00:00  loss: 0.1330 (0.1398)  time: 0.1784  data: 0.0001  max mem: 15821
[14:13:23.990097] Test: Total time: 0:01:00 (0.1740 s / it)
[14:13:33.897729] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4549 (0.4549)  time: 0.4510  data: 0.2886  max mem: 15821
[14:13:35.549200] Test:  [10/57]  eta: 0:00:08  loss: 0.3912 (0.4247)  time: 0.1910  data: 0.0263  max mem: 15821
[14:13:37.205268] Test:  [20/57]  eta: 0:00:06  loss: 0.3912 (0.4122)  time: 0.1653  data: 0.0001  max mem: 15821
[14:13:38.866972] Test:  [30/57]  eta: 0:00:04  loss: 0.2641 (0.3508)  time: 0.1658  data: 0.0001  max mem: 15821
[14:13:40.533551] Test:  [40/57]  eta: 0:00:02  loss: 0.2130 (0.3245)  time: 0.1664  data: 0.0001  max mem: 15821
[14:13:42.201977] Test:  [50/57]  eta: 0:00:01  loss: 0.2527 (0.3209)  time: 0.1667  data: 0.0001  max mem: 15821
[14:13:43.103167] Test:  [56/57]  eta: 0:00:00  loss: 0.2561 (0.3247)  time: 0.1618  data: 0.0000  max mem: 15821
[14:13:43.177393] Test: Total time: 0:00:09 (0.1707 s / it)
[14:13:44.836619] Dice score of the network on the train images: 0.863799, val images: 0.817974
[14:13:44.836860] saving best_dice_model_0 @ epoch 30
[14:13:46.056786] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:13:47.027004] Epoch: [31]  [  0/345]  eta: 0:05:34  lr: 0.000088  loss: 0.1149 (0.1149)  time: 0.9690  data: 0.3669  max mem: 15821
[14:13:59.057279] Epoch: [31]  [ 20/345]  eta: 0:03:21  lr: 0.000088  loss: 0.1386 (0.1422)  time: 0.6015  data: 0.0001  max mem: 15821
[14:14:11.103014] Epoch: [31]  [ 40/345]  eta: 0:03:06  lr: 0.000087  loss: 0.1375 (0.1430)  time: 0.6022  data: 0.0001  max mem: 15821
[14:14:23.160730] Epoch: [31]  [ 60/345]  eta: 0:02:53  lr: 0.000087  loss: 0.1349 (0.1404)  time: 0.6028  data: 0.0001  max mem: 15821
[14:14:35.233217] Epoch: [31]  [ 80/345]  eta: 0:02:40  lr: 0.000087  loss: 0.1370 (0.1406)  time: 0.6036  data: 0.0001  max mem: 15821
[14:14:47.323227] Epoch: [31]  [100/345]  eta: 0:02:28  lr: 0.000086  loss: 0.1390 (0.1409)  time: 0.6045  data: 0.0001  max mem: 15821
[14:14:59.418613] Epoch: [31]  [120/345]  eta: 0:02:16  lr: 0.000086  loss: 0.1353 (0.1400)  time: 0.6047  data: 0.0001  max mem: 15821
[14:15:11.531176] Epoch: [31]  [140/345]  eta: 0:02:04  lr: 0.000085  loss: 0.1372 (0.1400)  time: 0.6056  data: 0.0001  max mem: 15821
[14:15:23.668947] Epoch: [31]  [160/345]  eta: 0:01:52  lr: 0.000085  loss: 0.1387 (0.1402)  time: 0.6068  data: 0.0001  max mem: 15821
[14:15:35.808287] Epoch: [31]  [180/345]  eta: 0:01:40  lr: 0.000085  loss: 0.1444 (0.1407)  time: 0.6069  data: 0.0001  max mem: 15821
[14:15:47.939028] Epoch: [31]  [200/345]  eta: 0:01:27  lr: 0.000084  loss: 0.1338 (0.1402)  time: 0.6065  data: 0.0001  max mem: 15821
[14:16:00.065013] Epoch: [31]  [220/345]  eta: 0:01:15  lr: 0.000084  loss: 0.1371 (0.1403)  time: 0.6063  data: 0.0001  max mem: 15821
[14:16:12.204334] Epoch: [31]  [240/345]  eta: 0:01:03  lr: 0.000084  loss: 0.1427 (0.1406)  time: 0.6069  data: 0.0001  max mem: 15821
[14:16:24.344896] Epoch: [31]  [260/345]  eta: 0:00:51  lr: 0.000083  loss: 0.1442 (0.1412)  time: 0.6070  data: 0.0001  max mem: 15821
[14:16:36.467500] Epoch: [31]  [280/345]  eta: 0:00:39  lr: 0.000083  loss: 0.1398 (0.1416)  time: 0.6061  data: 0.0001  max mem: 15821
[14:16:48.593250] Epoch: [31]  [300/345]  eta: 0:00:27  lr: 0.000083  loss: 0.1418 (0.1419)  time: 0.6062  data: 0.0001  max mem: 15821
[14:17:00.722300] Epoch: [31]  [320/345]  eta: 0:00:15  lr: 0.000082  loss: 0.1405 (0.1419)  time: 0.6064  data: 0.0001  max mem: 15821
[14:17:12.851813] Epoch: [31]  [340/345]  eta: 0:00:03  lr: 0.000082  loss: 0.1352 (0.1416)  time: 0.6064  data: 0.0001  max mem: 15821
[14:17:15.273694] Epoch: [31]  [344/345]  eta: 0:00:00  lr: 0.000082  loss: 0.1381 (0.1417)  time: 0.6061  data: 0.0001  max mem: 15821
[14:17:15.349533] Epoch: [31] Total time: 0:03:29 (0.6066 s / it)
[14:17:15.349675] Averaged stats: lr: 0.000082  loss: 0.1381 (0.1417)
[14:17:15.897743] Test:  [  0/345]  eta: 0:03:07  loss: 0.1284 (0.1284)  time: 0.5438  data: 0.3793  max mem: 15821
[14:17:17.567586] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1349 (0.1315)  time: 0.2012  data: 0.0346  max mem: 15821
[14:17:19.239921] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1265 (0.1263)  time: 0.1670  data: 0.0001  max mem: 15821
[14:17:20.916644] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1245 (0.1266)  time: 0.1674  data: 0.0001  max mem: 15821
[14:17:22.595833] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1290 (0.1275)  time: 0.1677  data: 0.0001  max mem: 15821
[14:17:24.278412] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1287 (0.1284)  time: 0.1680  data: 0.0001  max mem: 15821
[14:17:25.965380] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1366 (0.1310)  time: 0.1684  data: 0.0001  max mem: 15821
[14:17:27.654393] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1380 (0.1325)  time: 0.1687  data: 0.0001  max mem: 15821
[14:17:29.348290] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1344 (0.1323)  time: 0.1691  data: 0.0001  max mem: 15821
[14:17:31.046034] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1293 (0.1316)  time: 0.1695  data: 0.0001  max mem: 15821
[14:17:32.747179] Test:  [100/345]  eta: 0:00:42  loss: 0.1140 (0.1310)  time: 0.1699  data: 0.0001  max mem: 15821
[14:17:34.451075] Test:  [110/345]  eta: 0:00:40  loss: 0.1166 (0.1308)  time: 0.1702  data: 0.0001  max mem: 15821
[14:17:36.157540] Test:  [120/345]  eta: 0:00:38  loss: 0.1321 (0.1317)  time: 0.1705  data: 0.0001  max mem: 15821
[14:17:37.867850] Test:  [130/345]  eta: 0:00:36  loss: 0.1296 (0.1312)  time: 0.1708  data: 0.0001  max mem: 15821
[14:17:39.581791] Test:  [140/345]  eta: 0:00:35  loss: 0.1296 (0.1318)  time: 0.1711  data: 0.0001  max mem: 15821
[14:17:41.299171] Test:  [150/345]  eta: 0:00:33  loss: 0.1299 (0.1319)  time: 0.1715  data: 0.0001  max mem: 15821
[14:17:43.021468] Test:  [160/345]  eta: 0:00:31  loss: 0.1347 (0.1324)  time: 0.1719  data: 0.0001  max mem: 15821
[14:17:44.746138] Test:  [170/345]  eta: 0:00:30  loss: 0.1367 (0.1329)  time: 0.1723  data: 0.0001  max mem: 15821
[14:17:46.473934] Test:  [180/345]  eta: 0:00:28  loss: 0.1351 (0.1329)  time: 0.1725  data: 0.0001  max mem: 15821
[14:17:48.205682] Test:  [190/345]  eta: 0:00:26  loss: 0.1299 (0.1327)  time: 0.1729  data: 0.0001  max mem: 15821
[14:17:49.940746] Test:  [200/345]  eta: 0:00:24  loss: 0.1296 (0.1326)  time: 0.1733  data: 0.0001  max mem: 15821
[14:17:51.678226] Test:  [210/345]  eta: 0:00:23  loss: 0.1337 (0.1327)  time: 0.1736  data: 0.0001  max mem: 15821
[14:17:53.420015] Test:  [220/345]  eta: 0:00:21  loss: 0.1391 (0.1331)  time: 0.1739  data: 0.0001  max mem: 15821
[14:17:55.165195] Test:  [230/345]  eta: 0:00:19  loss: 0.1319 (0.1332)  time: 0.1743  data: 0.0001  max mem: 15821
[14:17:56.915357] Test:  [240/345]  eta: 0:00:18  loss: 0.1306 (0.1333)  time: 0.1747  data: 0.0001  max mem: 15821
[14:17:58.667772] Test:  [250/345]  eta: 0:00:16  loss: 0.1298 (0.1335)  time: 0.1751  data: 0.0001  max mem: 15821
[14:18:00.423664] Test:  [260/345]  eta: 0:00:14  loss: 0.1340 (0.1336)  time: 0.1754  data: 0.0001  max mem: 15821
[14:18:02.182119] Test:  [270/345]  eta: 0:00:12  loss: 0.1340 (0.1337)  time: 0.1757  data: 0.0001  max mem: 15821
[14:18:03.945009] Test:  [280/345]  eta: 0:00:11  loss: 0.1320 (0.1334)  time: 0.1760  data: 0.0001  max mem: 15821
[14:18:05.710091] Test:  [290/345]  eta: 0:00:09  loss: 0.1367 (0.1338)  time: 0.1763  data: 0.0001  max mem: 15821
[14:18:07.479624] Test:  [300/345]  eta: 0:00:07  loss: 0.1406 (0.1338)  time: 0.1767  data: 0.0001  max mem: 15821
[14:18:09.252245] Test:  [310/345]  eta: 0:00:06  loss: 0.1225 (0.1337)  time: 0.1771  data: 0.0001  max mem: 15821
[14:18:11.028867] Test:  [320/345]  eta: 0:00:04  loss: 0.1311 (0.1338)  time: 0.1774  data: 0.0001  max mem: 15821
[14:18:12.809800] Test:  [330/345]  eta: 0:00:02  loss: 0.1357 (0.1341)  time: 0.1778  data: 0.0001  max mem: 15821
[14:18:14.594972] Test:  [340/345]  eta: 0:00:00  loss: 0.1352 (0.1345)  time: 0.1783  data: 0.0001  max mem: 15821
[14:18:15.308970] Test:  [344/345]  eta: 0:00:00  loss: 0.1379 (0.1345)  time: 0.1783  data: 0.0001  max mem: 15821
[14:18:15.378555] Test: Total time: 0:01:00 (0.1740 s / it)
[14:18:25.267568] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4498 (0.4498)  time: 0.4522  data: 0.2890  max mem: 15821
[14:18:26.918777] Test:  [10/57]  eta: 0:00:08  loss: 0.3700 (0.4116)  time: 0.1911  data: 0.0264  max mem: 15821
[14:18:28.574094] Test:  [20/57]  eta: 0:00:06  loss: 0.3832 (0.4008)  time: 0.1653  data: 0.0001  max mem: 15821
[14:18:30.235145] Test:  [30/57]  eta: 0:00:04  loss: 0.2637 (0.3422)  time: 0.1658  data: 0.0001  max mem: 15821
[14:18:31.899851] Test:  [40/57]  eta: 0:00:02  loss: 0.2172 (0.3183)  time: 0.1662  data: 0.0001  max mem: 15821
[14:18:33.569487] Test:  [50/57]  eta: 0:00:01  loss: 0.2517 (0.3170)  time: 0.1667  data: 0.0001  max mem: 15821
[14:18:34.470070] Test:  [56/57]  eta: 0:00:00  loss: 0.2739 (0.3229)  time: 0.1618  data: 0.0000  max mem: 15821
[14:18:34.546743] Test: Total time: 0:00:09 (0.1707 s / it)
[14:18:36.211241] Dice score of the network on the train images: 0.859973, val images: 0.814532
[14:18:36.215422] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:18:37.167011] Epoch: [32]  [  0/345]  eta: 0:05:27  lr: 0.000082  loss: 0.1364 (0.1364)  time: 0.9505  data: 0.3480  max mem: 15821
[14:18:49.204180] Epoch: [32]  [ 20/345]  eta: 0:03:20  lr: 0.000081  loss: 0.1399 (0.1382)  time: 0.6018  data: 0.0001  max mem: 15821
[14:19:01.242276] Epoch: [32]  [ 40/345]  eta: 0:03:06  lr: 0.000081  loss: 0.1382 (0.1375)  time: 0.6019  data: 0.0001  max mem: 15821
[14:19:13.288132] Epoch: [32]  [ 60/345]  eta: 0:02:53  lr: 0.000081  loss: 0.1418 (0.1383)  time: 0.6022  data: 0.0001  max mem: 15821
[14:19:25.346797] Epoch: [32]  [ 80/345]  eta: 0:02:40  lr: 0.000080  loss: 0.1419 (0.1402)  time: 0.6029  data: 0.0001  max mem: 15821
[14:19:37.421853] Epoch: [32]  [100/345]  eta: 0:02:28  lr: 0.000080  loss: 0.1378 (0.1407)  time: 0.6037  data: 0.0001  max mem: 15821
[14:19:49.499875] Epoch: [32]  [120/345]  eta: 0:02:16  lr: 0.000080  loss: 0.1300 (0.1400)  time: 0.6039  data: 0.0001  max mem: 15821
[14:20:01.589701] Epoch: [32]  [140/345]  eta: 0:02:04  lr: 0.000079  loss: 0.1431 (0.1405)  time: 0.6044  data: 0.0001  max mem: 15821
[14:20:13.706282] Epoch: [32]  [160/345]  eta: 0:01:52  lr: 0.000079  loss: 0.1314 (0.1401)  time: 0.6058  data: 0.0001  max mem: 15821

[14:20:25.847880] Epoch: [32]  [180/345]  eta: 0:01:39  lr: 0.000079  loss: 0.1375 (0.1403)  time: 0.6070  data: 0.0001  max mem: 15821
[14:20:37.967824] Epoch: [32]  [200/345]  eta: 0:01:27  lr: 0.000078  loss: 0.1342 (0.1405)  time: 0.6059  data: 0.0001  max mem: 15821
[14:20:50.083461] Epoch: [32]  [220/345]  eta: 0:01:15  lr: 0.000078  loss: 0.1340 (0.1396)  time: 0.6057  data: 0.0001  max mem: 15821
[14:21:02.204299] Epoch: [32]  [240/345]  eta: 0:01:03  lr: 0.000077  loss: 0.1363 (0.1396)  time: 0.6060  data: 0.0001  max mem: 15821
[14:21:14.312520] Epoch: [32]  [260/345]  eta: 0:00:51  lr: 0.000077  loss: 0.1356 (0.1394)  time: 0.6054  data: 0.0001  max mem: 15821
[14:21:26.441700] Epoch: [32]  [280/345]  eta: 0:00:39  lr: 0.000077  loss: 0.1313 (0.1393)  time: 0.6064  data: 0.0001  max mem: 15821
[14:21:38.559649] Epoch: [32]  [300/345]  eta: 0:00:27  lr: 0.000076  loss: 0.1257 (0.1389)  time: 0.6059  data: 0.0001  max mem: 15821
[14:21:50.662500] Epoch: [32]  [320/345]  eta: 0:00:15  lr: 0.000076  loss: 0.1339 (0.1388)  time: 0.6051  data: 0.0001  max mem: 15821
[14:22:02.787789] Epoch: [32]  [340/345]  eta: 0:00:03  lr: 0.000076  loss: 0.1325 (0.1385)  time: 0.6062  data: 0.0001  max mem: 15821
[14:22:05.212644] Epoch: [32]  [344/345]  eta: 0:00:00  lr: 0.000076  loss: 0.1267 (0.1383)  time: 0.6062  data: 0.0001  max mem: 15821
[14:22:05.279308] Epoch: [32] Total time: 0:03:29 (0.6060 s / it)
[14:22:05.279720] Averaged stats: lr: 0.000076  loss: 0.1267 (0.1383)
[14:22:05.812179] Test:  [  0/345]  eta: 0:03:01  loss: 0.1314 (0.1314)  time: 0.5271  data: 0.3627  max mem: 15821
[14:22:07.482656] Test:  [ 10/345]  eta: 0:01:06  loss: 0.1385 (0.1398)  time: 0.1997  data: 0.0331  max mem: 15821
[14:22:09.157529] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1406 (0.1397)  time: 0.1672  data: 0.0001  max mem: 15821
[14:22:10.833925] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1398 (0.1357)  time: 0.1675  data: 0.0001  max mem: 15821
[14:22:12.513853] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1158 (0.1323)  time: 0.1678  data: 0.0001  max mem: 15821
[14:22:14.197567] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1237 (0.1316)  time: 0.1681  data: 0.0001  max mem: 15821
[14:22:15.883904] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1237 (0.1311)  time: 0.1684  data: 0.0001  max mem: 15821
[14:22:17.574051] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1228 (0.1309)  time: 0.1688  data: 0.0001  max mem: 15821
[14:22:19.268643] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1348 (0.1316)  time: 0.1692  data: 0.0001  max mem: 15821
[14:22:20.966255] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1326 (0.1315)  time: 0.1696  data: 0.0001  max mem: 15821
[14:22:22.666964] Test:  [100/345]  eta: 0:00:42  loss: 0.1311 (0.1324)  time: 0.1699  data: 0.0001  max mem: 15821
[14:22:24.371901] Test:  [110/345]  eta: 0:00:40  loss: 0.1366 (0.1328)  time: 0.1702  data: 0.0001  max mem: 15821
[14:22:26.077900] Test:  [120/345]  eta: 0:00:38  loss: 0.1332 (0.1328)  time: 0.1705  data: 0.0001  max mem: 15821
[14:22:27.789104] Test:  [130/345]  eta: 0:00:36  loss: 0.1270 (0.1328)  time: 0.1708  data: 0.0001  max mem: 15821
[14:22:29.503431] Test:  [140/345]  eta: 0:00:35  loss: 0.1271 (0.1328)  time: 0.1712  data: 0.0001  max mem: 15821
[14:22:31.220866] Test:  [150/345]  eta: 0:00:33  loss: 0.1271 (0.1325)  time: 0.1715  data: 0.0001  max mem: 15821
[14:22:32.942008] Test:  [160/345]  eta: 0:00:31  loss: 0.1267 (0.1321)  time: 0.1719  data: 0.0001  max mem: 15821
[14:22:34.666364] Test:  [170/345]  eta: 0:00:30  loss: 0.1256 (0.1316)  time: 0.1722  data: 0.0001  max mem: 15821
[14:22:36.394694] Test:  [180/345]  eta: 0:00:28  loss: 0.1210 (0.1312)  time: 0.1726  data: 0.0001  max mem: 15821
[14:22:38.125677] Test:  [190/345]  eta: 0:00:26  loss: 0.1218 (0.1308)  time: 0.1729  data: 0.0001  max mem: 15821
[14:22:39.859391] Test:  [200/345]  eta: 0:00:24  loss: 0.1230 (0.1305)  time: 0.1732  data: 0.0001  max mem: 15821
[14:22:41.597062] Test:  [210/345]  eta: 0:00:23  loss: 0.1178 (0.1300)  time: 0.1735  data: 0.0001  max mem: 15821
[14:22:43.337992] Test:  [220/345]  eta: 0:00:21  loss: 0.1169 (0.1297)  time: 0.1739  data: 0.0001  max mem: 15821
[14:22:45.083479] Test:  [230/345]  eta: 0:00:19  loss: 0.1219 (0.1296)  time: 0.1742  data: 0.0001  max mem: 15821
[14:22:46.831930] Test:  [240/345]  eta: 0:00:18  loss: 0.1298 (0.1299)  time: 0.1746  data: 0.0001  max mem: 15821
[14:22:48.583257] Test:  [250/345]  eta: 0:00:16  loss: 0.1298 (0.1300)  time: 0.1749  data: 0.0001  max mem: 15821
[14:22:50.338639] Test:  [260/345]  eta: 0:00:14  loss: 0.1273 (0.1300)  time: 0.1753  data: 0.0001  max mem: 15821
[14:22:52.096973] Test:  [270/345]  eta: 0:00:12  loss: 0.1216 (0.1298)  time: 0.1756  data: 0.0001  max mem: 15821
[14:22:53.858667] Test:  [280/345]  eta: 0:00:11  loss: 0.1262 (0.1294)  time: 0.1759  data: 0.0001  max mem: 15821
[14:22:55.624474] Test:  [290/345]  eta: 0:00:09  loss: 0.1279 (0.1296)  time: 0.1763  data: 0.0001  max mem: 15821
[14:22:57.392775] Test:  [300/345]  eta: 0:00:07  loss: 0.1336 (0.1298)  time: 0.1766  data: 0.0001  max mem: 15821
[14:22:59.165520] Test:  [310/345]  eta: 0:00:06  loss: 0.1268 (0.1298)  time: 0.1770  data: 0.0001  max mem: 15821
[14:23:00.941525] Test:  [320/345]  eta: 0:00:04  loss: 0.1229 (0.1298)  time: 0.1774  data: 0.0001  max mem: 15821
[14:23:02.721285] Test:  [330/345]  eta: 0:00:02  loss: 0.1332 (0.1300)  time: 0.1777  data: 0.0001  max mem: 15821
[14:23:04.504717] Test:  [340/345]  eta: 0:00:00  loss: 0.1337 (0.1300)  time: 0.1781  data: 0.0001  max mem: 15821
[14:23:05.219139] Test:  [344/345]  eta: 0:00:00  loss: 0.1329 (0.1300)  time: 0.1783  data: 0.0001  max mem: 15821
[14:23:05.292581] Test: Total time: 0:01:00 (0.1739 s / it)
[14:23:15.156904] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4550 (0.4550)  time: 0.4525  data: 0.2898  max mem: 15821
[14:23:16.808813] Test:  [10/57]  eta: 0:00:08  loss: 0.3937 (0.4222)  time: 0.1912  data: 0.0264  max mem: 15821
[14:23:18.464658] Test:  [20/57]  eta: 0:00:06  loss: 0.4130 (0.4143)  time: 0.1653  data: 0.0001  max mem: 15821
[14:23:20.124638] Test:  [30/57]  eta: 0:00:04  loss: 0.2767 (0.3554)  time: 0.1657  data: 0.0001  max mem: 15821
[14:23:21.788870] Test:  [40/57]  eta: 0:00:02  loss: 0.2312 (0.3336)  time: 0.1661  data: 0.0001  max mem: 15821
[14:23:23.458413] Test:  [50/57]  eta: 0:00:01  loss: 0.2672 (0.3350)  time: 0.1666  data: 0.0001  max mem: 15821
[14:23:24.358967] Test:  [56/57]  eta: 0:00:00  loss: 0.2925 (0.3425)  time: 0.1618  data: 0.0000  max mem: 15821
[14:23:24.424946] Test: Total time: 0:00:09 (0.1705 s / it)
[14:23:26.103439] Dice score of the network on the train images: 0.872893, val images: 0.799900
[14:23:26.107411] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:23:27.053270] Epoch: [33]  [  0/345]  eta: 0:05:26  lr: 0.000075  loss: 0.1203 (0.1203)  time: 0.9450  data: 0.3448  max mem: 15821
[14:23:39.093652] Epoch: [33]  [ 20/345]  eta: 0:03:20  lr: 0.000075  loss: 0.1295 (0.1299)  time: 0.6020  data: 0.0001  max mem: 15821
[14:23:51.145529] Epoch: [33]  [ 40/345]  eta: 0:03:06  lr: 0.000075  loss: 0.1307 (0.1340)  time: 0.6025  data: 0.0001  max mem: 15821
[14:24:03.202496] Epoch: [33]  [ 60/345]  eta: 0:02:53  lr: 0.000074  loss: 0.1301 (0.1335)  time: 0.6028  data: 0.0001  max mem: 15821
[14:24:15.284803] Epoch: [33]  [ 80/345]  eta: 0:02:40  lr: 0.000074  loss: 0.1392 (0.1356)  time: 0.6041  data: 0.0001  max mem: 15821
[14:24:27.378010] Epoch: [33]  [100/345]  eta: 0:02:28  lr: 0.000074  loss: 0.1242 (0.1355)  time: 0.6046  data: 0.0001  max mem: 15821
[14:24:39.474221] Epoch: [33]  [120/345]  eta: 0:02:16  lr: 0.000073  loss: 0.1310 (0.1352)  time: 0.6048  data: 0.0001  max mem: 15821
[14:24:51.704951] Epoch: [33]  [140/345]  eta: 0:02:04  lr: 0.000073  loss: 0.1325 (0.1355)  time: 0.6115  data: 0.0001  max mem: 15821
[14:25:03.806417] Epoch: [33]  [160/345]  eta: 0:01:52  lr: 0.000073  loss: 0.1285 (0.1352)  time: 0.6050  data: 0.0001  max mem: 15821
[14:25:15.923488] Epoch: [33]  [180/345]  eta: 0:01:40  lr: 0.000072  loss: 0.1279 (0.1351)  time: 0.6058  data: 0.0001  max mem: 15821
[14:25:28.045944] Epoch: [33]  [200/345]  eta: 0:01:27  lr: 0.000072  loss: 0.1231 (0.1345)  time: 0.6061  data: 0.0001  max mem: 15821
[14:25:40.165511] Epoch: [33]  [220/345]  eta: 0:01:15  lr: 0.000071  loss: 0.1382 (0.1347)  time: 0.6059  data: 0.0001  max mem: 15821
[14:25:52.259391] Epoch: [33]  [240/345]  eta: 0:01:03  lr: 0.000071  loss: 0.1347 (0.1346)  time: 0.6046  data: 0.0001  max mem: 15821
[14:26:04.353775] Epoch: [33]  [260/345]  eta: 0:00:51  lr: 0.000071  loss: 0.1300 (0.1342)  time: 0.6047  data: 0.0001  max mem: 15821
[14:26:16.442889] Epoch: [33]  [280/345]  eta: 0:00:39  lr: 0.000070  loss: 0.1380 (0.1346)  time: 0.6044  data: 0.0001  max mem: 15821
[14:26:28.530231] Epoch: [33]  [300/345]  eta: 0:00:27  lr: 0.000070  loss: 0.1397 (0.1352)  time: 0.6043  data: 0.0001  max mem: 15821
[14:26:40.612917] Epoch: [33]  [320/345]  eta: 0:00:15  lr: 0.000070  loss: 0.1261 (0.1349)  time: 0.6041  data: 0.0001  max mem: 15821
[14:26:52.694907] Epoch: [33]  [340/345]  eta: 0:00:03  lr: 0.000069  loss: 0.1314 (0.1349)  time: 0.6040  data: 0.0001  max mem: 15821
[14:26:55.109613] Epoch: [33]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.1314 (0.1350)  time: 0.6038  data: 0.0001  max mem: 15821
[14:26:55.179875] Epoch: [33] Total time: 0:03:29 (0.6060 s / it)
[14:26:55.180833] Averaged stats: lr: 0.000069  loss: 0.1314 (0.1350)
[14:26:55.734782] Test:  [  0/345]  eta: 0:03:09  loss: 0.1157 (0.1157)  time: 0.5488  data: 0.3849  max mem: 15821
[14:26:57.403026] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1232 (0.1311)  time: 0.2015  data: 0.0351  max mem: 15821
[14:26:59.074488] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1232 (0.1267)  time: 0.1669  data: 0.0001  max mem: 15821
[14:27:00.748120] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1259 (0.1290)  time: 0.1672  data: 0.0001  max mem: 15821
[14:27:02.425370] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1293 (0.1297)  time: 0.1675  data: 0.0001  max mem: 15821
[14:27:04.107650] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1313 (0.1308)  time: 0.1679  data: 0.0001  max mem: 15821
[14:27:05.792827] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1245 (0.1292)  time: 0.1683  data: 0.0001  max mem: 15821
[14:27:07.480143] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1170 (0.1283)  time: 0.1686  data: 0.0001  max mem: 15821
[14:27:09.171783] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1211 (0.1274)  time: 0.1689  data: 0.0001  max mem: 15821
[14:27:10.866402] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1190 (0.1263)  time: 0.1692  data: 0.0001  max mem: 15821
[14:27:12.564910] Test:  [100/345]  eta: 0:00:42  loss: 0.1210 (0.1269)  time: 0.1696  data: 0.0001  max mem: 15821
[14:27:14.266741] Test:  [110/345]  eta: 0:00:40  loss: 0.1273 (0.1272)  time: 0.1700  data: 0.0001  max mem: 15821
[14:27:15.972393] Test:  [120/345]  eta: 0:00:38  loss: 0.1294 (0.1274)  time: 0.1703  data: 0.0001  max mem: 15821
[14:27:17.679655] Test:  [130/345]  eta: 0:00:36  loss: 0.1294 (0.1275)  time: 0.1706  data: 0.0001  max mem: 15821
[14:27:19.391063] Test:  [140/345]  eta: 0:00:35  loss: 0.1185 (0.1270)  time: 0.1709  data: 0.0001  max mem: 15821
[14:27:21.105222] Test:  [150/345]  eta: 0:00:33  loss: 0.1199 (0.1269)  time: 0.1712  data: 0.0001  max mem: 15821
[14:27:22.825029] Test:  [160/345]  eta: 0:00:31  loss: 0.1259 (0.1270)  time: 0.1716  data: 0.0001  max mem: 15821
[14:27:24.547051] Test:  [170/345]  eta: 0:00:30  loss: 0.1211 (0.1270)  time: 0.1720  data: 0.0001  max mem: 15821
[14:27:26.273013] Test:  [180/345]  eta: 0:00:28  loss: 0.1226 (0.1271)  time: 0.1723  data: 0.0001  max mem: 15821
[14:27:28.002584] Test:  [190/345]  eta: 0:00:26  loss: 0.1213 (0.1270)  time: 0.1727  data: 0.0001  max mem: 15821
[14:27:29.736433] Test:  [200/345]  eta: 0:00:24  loss: 0.1213 (0.1271)  time: 0.1731  data: 0.0001  max mem: 15821
[14:27:31.471844] Test:  [210/345]  eta: 0:00:23  loss: 0.1224 (0.1273)  time: 0.1734  data: 0.0001  max mem: 15821
[14:27:33.211141] Test:  [220/345]  eta: 0:00:21  loss: 0.1224 (0.1276)  time: 0.1737  data: 0.0001  max mem: 15821
[14:27:34.954149] Test:  [230/345]  eta: 0:00:19  loss: 0.1365 (0.1280)  time: 0.1741  data: 0.0001  max mem: 15821
[14:27:36.701115] Test:  [240/345]  eta: 0:00:18  loss: 0.1327 (0.1284)  time: 0.1744  data: 0.0001  max mem: 15821
[14:27:38.452550] Test:  [250/345]  eta: 0:00:16  loss: 0.1227 (0.1285)  time: 0.1748  data: 0.0001  max mem: 15821
[14:27:40.205977] Test:  [260/345]  eta: 0:00:14  loss: 0.1233 (0.1282)  time: 0.1752  data: 0.0001  max mem: 15821
[14:27:41.963153] Test:  [270/345]  eta: 0:00:12  loss: 0.1237 (0.1286)  time: 0.1755  data: 0.0001  max mem: 15821
[14:27:43.724030] Test:  [280/345]  eta: 0:00:11  loss: 0.1255 (0.1285)  time: 0.1758  data: 0.0001  max mem: 15821
[14:27:45.487763] Test:  [290/345]  eta: 0:00:09  loss: 0.1224 (0.1285)  time: 0.1762  data: 0.0001  max mem: 15821
[14:27:47.254772] Test:  [300/345]  eta: 0:00:07  loss: 0.1236 (0.1284)  time: 0.1765  data: 0.0001  max mem: 15821
[14:27:49.025751] Test:  [310/345]  eta: 0:00:06  loss: 0.1297 (0.1286)  time: 0.1768  data: 0.0001  max mem: 15821
[14:27:50.800629] Test:  [320/345]  eta: 0:00:04  loss: 0.1243 (0.1286)  time: 0.1772  data: 0.0001  max mem: 15821
[14:27:52.579171] Test:  [330/345]  eta: 0:00:02  loss: 0.1225 (0.1284)  time: 0.1776  data: 0.0001  max mem: 15821
[14:27:54.361937] Test:  [340/345]  eta: 0:00:00  loss: 0.1249 (0.1284)  time: 0.1780  data: 0.0001  max mem: 15821
[14:27:55.076500] Test:  [344/345]  eta: 0:00:00  loss: 0.1251 (0.1284)  time: 0.1781  data: 0.0001  max mem: 15821
[14:27:55.145848] Test: Total time: 0:00:59 (0.1738 s / it)
[14:28:05.035624] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4510 (0.4510)  time: 0.4659  data: 0.3032  max mem: 15821
[14:28:06.687741] Test:  [10/57]  eta: 0:00:09  loss: 0.3739 (0.4097)  time: 0.1925  data: 0.0276  max mem: 15821
[14:28:08.344263] Test:  [20/57]  eta: 0:00:06  loss: 0.3739 (0.4010)  time: 0.1654  data: 0.0001  max mem: 15821
[14:28:10.005399] Test:  [30/57]  eta: 0:00:04  loss: 0.2662 (0.3423)  time: 0.1658  data: 0.0001  max mem: 15821
[14:28:11.670480] Test:  [40/57]  eta: 0:00:02  loss: 0.2191 (0.3175)  time: 0.1662  data: 0.0001  max mem: 15821
[14:28:13.340403] Test:  [50/57]  eta: 0:00:01  loss: 0.2433 (0.3171)  time: 0.1667  data: 0.0001  max mem: 15821
[14:28:14.241292] Test:  [56/57]  eta: 0:00:00  loss: 0.2692 (0.3239)  time: 0.1618  data: 0.0000  max mem: 15821
[14:28:14.301094] Test: Total time: 0:00:09 (0.1707 s / it)
[14:28:15.978227] Dice score of the network on the train images: 0.867332, val images: 0.813829
[14:28:15.982230] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:28:16.885699] Epoch: [34]  [  0/345]  eta: 0:05:11  lr: 0.000069  loss: 0.1030 (0.1030)  time: 0.9025  data: 0.3006  max mem: 15821
[14:28:28.926409] Epoch: [34]  [ 20/345]  eta: 0:03:20  lr: 0.000069  loss: 0.1341 (0.1343)  time: 0.6020  data: 0.0001  max mem: 15821
[14:28:40.983650] Epoch: [34]  [ 40/345]  eta: 0:03:05  lr: 0.000068  loss: 0.1295 (0.1339)  time: 0.6028  data: 0.0001  max mem: 15821
[14:28:53.049594] Epoch: [34]  [ 60/345]  eta: 0:02:53  lr: 0.000068  loss: 0.1242 (0.1322)  time: 0.6033  data: 0.0001  max mem: 15821
[14:29:05.130262] Epoch: [34]  [ 80/345]  eta: 0:02:40  lr: 0.000068  loss: 0.1335 (0.1321)  time: 0.6040  data: 0.0001  max mem: 15821
[14:29:17.214075] Epoch: [34]  [100/345]  eta: 0:02:28  lr: 0.000067  loss: 0.1291 (0.1322)  time: 0.6041  data: 0.0001  max mem: 15821
[14:29:29.322815] Epoch: [34]  [120/345]  eta: 0:02:16  lr: 0.000067  loss: 0.1248 (0.1316)  time: 0.6054  data: 0.0001  max mem: 15821
[14:29:41.437243] Epoch: [34]  [140/345]  eta: 0:02:04  lr: 0.000066  loss: 0.1360 (0.1326)  time: 0.6057  data: 0.0001  max mem: 15821
[14:29:53.559325] Epoch: [34]  [160/345]  eta: 0:01:52  lr: 0.000066  loss: 0.1294 (0.1328)  time: 0.6061  data: 0.0001  max mem: 15821
[14:30:05.679123] Epoch: [34]  [180/345]  eta: 0:01:39  lr: 0.000066  loss: 0.1270 (0.1324)  time: 0.6059  data: 0.0001  max mem: 15821
[14:30:17.803323] Epoch: [34]  [200/345]  eta: 0:01:27  lr: 0.000065  loss: 0.1260 (0.1320)  time: 0.6062  data: 0.0001  max mem: 15821
[14:30:29.923936] Epoch: [34]  [220/345]  eta: 0:01:15  lr: 0.000065  loss: 0.1257 (0.1317)  time: 0.6060  data: 0.0001  max mem: 15821
[14:30:42.037846] Epoch: [34]  [240/345]  eta: 0:01:03  lr: 0.000064  loss: 0.1210 (0.1311)  time: 0.6056  data: 0.0001  max mem: 15821
[14:30:54.152981] Epoch: [34]  [260/345]  eta: 0:00:51  lr: 0.000064  loss: 0.1330 (0.1312)  time: 0.6057  data: 0.0001  max mem: 15821
[14:31:06.268428] Epoch: [34]  [280/345]  eta: 0:00:39  lr: 0.000064  loss: 0.1270 (0.1310)  time: 0.6057  data: 0.0001  max mem: 15821
[14:31:18.379752] Epoch: [34]  [300/345]  eta: 0:00:27  lr: 0.000063  loss: 0.1168 (0.1306)  time: 0.6055  data: 0.0001  max mem: 15821
[14:31:30.484673] Epoch: [34]  [320/345]  eta: 0:00:15  lr: 0.000063  loss: 0.1366 (0.1311)  time: 0.6052  data: 0.0001  max mem: 15821

[14:31:42.593461] Epoch: [34]  [340/345]  eta: 0:00:03  lr: 0.000063  loss: 0.1301 (0.1311)  time: 0.6054  data: 0.0001  max mem: 15821
[14:31:45.019696] Epoch: [34]  [344/345]  eta: 0:00:00  lr: 0.000063  loss: 0.1369 (0.1313)  time: 0.6056  data: 0.0001  max mem: 15821
[14:31:45.090091] Epoch: [34] Total time: 0:03:29 (0.6061 s / it)
[14:31:45.090879] Averaged stats: lr: 0.000063  loss: 0.1369 (0.1313)
[14:31:45.632366] Test:  [  0/345]  eta: 0:03:05  loss: 0.1758 (0.1758)  time: 0.5362  data: 0.3715  max mem: 15821
[14:31:47.301218] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1117 (0.1202)  time: 0.2004  data: 0.0339  max mem: 15821
[14:31:48.972608] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1144 (0.1225)  time: 0.1669  data: 0.0001  max mem: 15821
[14:31:50.648015] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1289 (0.1282)  time: 0.1673  data: 0.0001  max mem: 15821
[14:31:52.326609] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1284 (0.1256)  time: 0.1676  data: 0.0001  max mem: 15821
[14:31:54.007913] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1187 (0.1252)  time: 0.1679  data: 0.0001  max mem: 15821
[14:31:55.692215] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1198 (0.1257)  time: 0.1682  data: 0.0001  max mem: 15821
[14:31:57.379707] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1208 (0.1250)  time: 0.1685  data: 0.0001  max mem: 15821
[14:31:59.071366] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1199 (0.1248)  time: 0.1689  data: 0.0001  max mem: 15821
[14:32:00.767017] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1170 (0.1247)  time: 0.1693  data: 0.0001  max mem: 15821
[14:32:02.466262] Test:  [100/345]  eta: 0:00:42  loss: 0.1184 (0.1244)  time: 0.1697  data: 0.0001  max mem: 15821
[14:32:04.167543] Test:  [110/345]  eta: 0:00:40  loss: 0.1225 (0.1243)  time: 0.1700  data: 0.0001  max mem: 15821
[14:32:05.872978] Test:  [120/345]  eta: 0:00:38  loss: 0.1215 (0.1240)  time: 0.1703  data: 0.0001  max mem: 15821
[14:32:07.581990] Test:  [130/345]  eta: 0:00:36  loss: 0.1215 (0.1238)  time: 0.1707  data: 0.0001  max mem: 15821
[14:32:09.294936] Test:  [140/345]  eta: 0:00:35  loss: 0.1262 (0.1244)  time: 0.1710  data: 0.0001  max mem: 15821
[14:32:11.010918] Test:  [150/345]  eta: 0:00:33  loss: 0.1208 (0.1243)  time: 0.1714  data: 0.0001  max mem: 15821
[14:32:12.730183] Test:  [160/345]  eta: 0:00:31  loss: 0.1188 (0.1243)  time: 0.1717  data: 0.0001  max mem: 15821
[14:32:14.454708] Test:  [170/345]  eta: 0:00:30  loss: 0.1214 (0.1238)  time: 0.1721  data: 0.0001  max mem: 15821
[14:32:16.181800] Test:  [180/345]  eta: 0:00:28  loss: 0.1131 (0.1236)  time: 0.1725  data: 0.0001  max mem: 15821
[14:32:17.913244] Test:  [190/345]  eta: 0:00:26  loss: 0.1201 (0.1238)  time: 0.1729  data: 0.0001  max mem: 15821
[14:32:19.644698] Test:  [200/345]  eta: 0:00:24  loss: 0.1222 (0.1236)  time: 0.1731  data: 0.0001  max mem: 15821
[14:32:21.381893] Test:  [210/345]  eta: 0:00:23  loss: 0.1202 (0.1233)  time: 0.1734  data: 0.0001  max mem: 15821
[14:32:23.121057] Test:  [220/345]  eta: 0:00:21  loss: 0.1156 (0.1231)  time: 0.1738  data: 0.0001  max mem: 15821
[14:32:24.864016] Test:  [230/345]  eta: 0:00:19  loss: 0.1244 (0.1236)  time: 0.1740  data: 0.0001  max mem: 15821
[14:32:26.612090] Test:  [240/345]  eta: 0:00:18  loss: 0.1244 (0.1235)  time: 0.1745  data: 0.0001  max mem: 15821
[14:32:28.361354] Test:  [250/345]  eta: 0:00:16  loss: 0.1228 (0.1236)  time: 0.1748  data: 0.0001  max mem: 15821
[14:32:30.115867] Test:  [260/345]  eta: 0:00:14  loss: 0.1231 (0.1238)  time: 0.1751  data: 0.0001  max mem: 15821
[14:32:31.872530] Test:  [270/345]  eta: 0:00:12  loss: 0.1273 (0.1239)  time: 0.1755  data: 0.0001  max mem: 15821
[14:32:33.633600] Test:  [280/345]  eta: 0:00:11  loss: 0.1237 (0.1240)  time: 0.1758  data: 0.0001  max mem: 15821
[14:32:35.396833] Test:  [290/345]  eta: 0:00:09  loss: 0.1196 (0.1239)  time: 0.1762  data: 0.0001  max mem: 15821
[14:32:37.164242] Test:  [300/345]  eta: 0:00:07  loss: 0.1175 (0.1237)  time: 0.1765  data: 0.0001  max mem: 15821
[14:32:38.937643] Test:  [310/345]  eta: 0:00:06  loss: 0.1191 (0.1238)  time: 0.1770  data: 0.0001  max mem: 15821
[14:32:40.712985] Test:  [320/345]  eta: 0:00:04  loss: 0.1216 (0.1236)  time: 0.1774  data: 0.0001  max mem: 15821
[14:32:42.493407] Test:  [330/345]  eta: 0:00:02  loss: 0.1145 (0.1237)  time: 0.1777  data: 0.0001  max mem: 15821
[14:32:44.276084] Test:  [340/345]  eta: 0:00:00  loss: 0.1242 (0.1238)  time: 0.1781  data: 0.0001  max mem: 15821
[14:32:44.989366] Test:  [344/345]  eta: 0:00:00  loss: 0.1242 (0.1238)  time: 0.1782  data: 0.0001  max mem: 15821
[14:32:45.060673] Test: Total time: 0:00:59 (0.1738 s / it)
[14:32:54.978129] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4580 (0.4580)  time: 0.4531  data: 0.2905  max mem: 15821
[14:32:56.629018] Test:  [10/57]  eta: 0:00:08  loss: 0.3962 (0.4183)  time: 0.1912  data: 0.0265  max mem: 15821
[14:32:58.285766] Test:  [20/57]  eta: 0:00:06  loss: 0.3962 (0.4095)  time: 0.1653  data: 0.0001  max mem: 15821
[14:32:59.946253] Test:  [30/57]  eta: 0:00:04  loss: 0.2774 (0.3538)  time: 0.1658  data: 0.0001  max mem: 15821
[14:33:01.609655] Test:  [40/57]  eta: 0:00:02  loss: 0.2379 (0.3329)  time: 0.1661  data: 0.0001  max mem: 15821
[14:33:03.280051] Test:  [50/57]  eta: 0:00:01  loss: 0.2657 (0.3334)  time: 0.1666  data: 0.0001  max mem: 15821
[14:33:04.181174] Test:  [56/57]  eta: 0:00:00  loss: 0.3053 (0.3431)  time: 0.1618  data: 0.0000  max mem: 15821
[14:33:04.253479] Test: Total time: 0:00:09 (0.1707 s / it)
[14:33:05.937756] Dice score of the network on the train images: 0.878116, val images: 0.799035
[14:33:05.941988] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:33:06.902649] Epoch: [35]  [  0/345]  eta: 0:05:31  lr: 0.000063  loss: 0.1318 (0.1318)  time: 0.9599  data: 0.3586  max mem: 15821
[14:33:18.922873] Epoch: [35]  [ 20/345]  eta: 0:03:20  lr: 0.000062  loss: 0.1234 (0.1315)  time: 0.6010  data: 0.0001  max mem: 15821
[14:33:30.974507] Epoch: [35]  [ 40/345]  eta: 0:03:06  lr: 0.000062  loss: 0.1248 (0.1323)  time: 0.6025  data: 0.0001  max mem: 15821
[14:33:43.049437] Epoch: [35]  [ 60/345]  eta: 0:02:53  lr: 0.000061  loss: 0.1219 (0.1295)  time: 0.6037  data: 0.0001  max mem: 15821
[14:33:55.132510] Epoch: [35]  [ 80/345]  eta: 0:02:40  lr: 0.000061  loss: 0.1283 (0.1309)  time: 0.6041  data: 0.0001  max mem: 15821
[14:34:07.206631] Epoch: [35]  [100/345]  eta: 0:02:28  lr: 0.000061  loss: 0.1166 (0.1288)  time: 0.6037  data: 0.0001  max mem: 15821
[14:34:19.305111] Epoch: [35]  [120/345]  eta: 0:02:16  lr: 0.000060  loss: 0.1204 (0.1283)  time: 0.6049  data: 0.0001  max mem: 15821
[14:34:31.406005] Epoch: [35]  [140/345]  eta: 0:02:04  lr: 0.000060  loss: 0.1362 (0.1295)  time: 0.6050  data: 0.0001  max mem: 15821
[14:34:43.516873] Epoch: [35]  [160/345]  eta: 0:01:52  lr: 0.000059  loss: 0.1199 (0.1291)  time: 0.6055  data: 0.0001  max mem: 15821
[14:34:55.644223] Epoch: [35]  [180/345]  eta: 0:01:39  lr: 0.000059  loss: 0.1216 (0.1286)  time: 0.6063  data: 0.0001  max mem: 15821
[14:35:07.766077] Epoch: [35]  [200/345]  eta: 0:01:27  lr: 0.000059  loss: 0.1220 (0.1288)  time: 0.6060  data: 0.0001  max mem: 15821
[14:35:19.884409] Epoch: [35]  [220/345]  eta: 0:01:15  lr: 0.000058  loss: 0.1264 (0.1291)  time: 0.6059  data: 0.0001  max mem: 15821
[14:35:31.975155] Epoch: [35]  [240/345]  eta: 0:01:03  lr: 0.000058  loss: 0.1204 (0.1286)  time: 0.6045  data: 0.0001  max mem: 15821
[14:35:44.082850] Epoch: [35]  [260/345]  eta: 0:00:51  lr: 0.000058  loss: 0.1268 (0.1286)  time: 0.6053  data: 0.0001  max mem: 15821
[14:35:56.193062] Epoch: [35]  [280/345]  eta: 0:00:39  lr: 0.000057  loss: 0.1201 (0.1285)  time: 0.6055  data: 0.0001  max mem: 15821
[14:36:08.301025] Epoch: [35]  [300/345]  eta: 0:00:27  lr: 0.000057  loss: 0.1226 (0.1281)  time: 0.6054  data: 0.0001  max mem: 15821
[14:36:20.405383] Epoch: [35]  [320/345]  eta: 0:00:15  lr: 0.000056  loss: 0.1233 (0.1280)  time: 0.6052  data: 0.0001  max mem: 15821
[14:36:32.488244] Epoch: [35]  [340/345]  eta: 0:00:03  lr: 0.000056  loss: 0.1270 (0.1281)  time: 0.6041  data: 0.0001  max mem: 15821
[14:36:34.900515] Epoch: [35]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.1247 (0.1280)  time: 0.6037  data: 0.0001  max mem: 15821
[14:36:34.970144] Epoch: [35] Total time: 0:03:29 (0.6059 s / it)
[14:36:34.970365] Averaged stats: lr: 0.000056  loss: 0.1247 (0.1280)
[14:36:35.485784] Test:  [  0/345]  eta: 0:02:56  loss: 0.1235 (0.1235)  time: 0.5102  data: 0.3464  max mem: 15821
[14:36:37.154528] Test:  [ 10/345]  eta: 0:01:06  loss: 0.1272 (0.1260)  time: 0.1980  data: 0.0316  max mem: 15821
[14:36:38.826711] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1249 (0.1262)  time: 0.1670  data: 0.0001  max mem: 15821
[14:36:40.501307] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1198 (0.1232)  time: 0.1673  data: 0.0001  max mem: 15821
[14:36:42.180453] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1198 (0.1247)  time: 0.1676  data: 0.0001  max mem: 15821
[14:36:43.862731] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1216 (0.1242)  time: 0.1680  data: 0.0001  max mem: 15821
[14:36:45.547523] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1200 (0.1245)  time: 0.1683  data: 0.0001  max mem: 15821
[14:36:47.236152] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1200 (0.1251)  time: 0.1686  data: 0.0001  max mem: 15821
[14:36:48.928600] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1126 (0.1234)  time: 0.1690  data: 0.0001  max mem: 15821
[14:36:50.624054] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1155 (0.1238)  time: 0.1693  data: 0.0001  max mem: 15821
[14:36:52.322515] Test:  [100/345]  eta: 0:00:42  loss: 0.1179 (0.1231)  time: 0.1696  data: 0.0001  max mem: 15821
[14:36:54.024463] Test:  [110/345]  eta: 0:00:40  loss: 0.1125 (0.1225)  time: 0.1700  data: 0.0001  max mem: 15821
[14:36:55.730362] Test:  [120/345]  eta: 0:00:38  loss: 0.1125 (0.1223)  time: 0.1703  data: 0.0001  max mem: 15821
[14:36:57.438188] Test:  [130/345]  eta: 0:00:36  loss: 0.1166 (0.1228)  time: 0.1706  data: 0.0001  max mem: 15821
[14:36:59.150240] Test:  [140/345]  eta: 0:00:35  loss: 0.1145 (0.1222)  time: 0.1709  data: 0.0001  max mem: 15821
[14:37:00.866157] Test:  [150/345]  eta: 0:00:33  loss: 0.1213 (0.1225)  time: 0.1713  data: 0.0001  max mem: 15821
[14:37:02.586415] Test:  [160/345]  eta: 0:00:31  loss: 0.1246 (0.1226)  time: 0.1717  data: 0.0001  max mem: 15821
[14:37:04.310084] Test:  [170/345]  eta: 0:00:30  loss: 0.1196 (0.1227)  time: 0.1721  data: 0.0001  max mem: 15821
[14:37:06.036018] Test:  [180/345]  eta: 0:00:28  loss: 0.1212 (0.1234)  time: 0.1724  data: 0.0001  max mem: 15821
[14:37:07.766653] Test:  [190/345]  eta: 0:00:26  loss: 0.1238 (0.1233)  time: 0.1728  data: 0.0001  max mem: 15821
[14:37:09.500065] Test:  [200/345]  eta: 0:00:24  loss: 0.1194 (0.1231)  time: 0.1731  data: 0.0001  max mem: 15821
[14:37:11.235395] Test:  [210/345]  eta: 0:00:23  loss: 0.1257 (0.1233)  time: 0.1734  data: 0.0001  max mem: 15821
[14:37:12.975233] Test:  [220/345]  eta: 0:00:21  loss: 0.1257 (0.1230)  time: 0.1737  data: 0.0001  max mem: 15821
[14:37:14.718111] Test:  [230/345]  eta: 0:00:19  loss: 0.1176 (0.1230)  time: 0.1741  data: 0.0001  max mem: 15821
[14:37:16.465187] Test:  [240/345]  eta: 0:00:18  loss: 0.1156 (0.1228)  time: 0.1744  data: 0.0001  max mem: 15821
[14:37:18.214543] Test:  [250/345]  eta: 0:00:16  loss: 0.1198 (0.1231)  time: 0.1748  data: 0.0001  max mem: 15821
[14:37:19.968888] Test:  [260/345]  eta: 0:00:14  loss: 0.1270 (0.1234)  time: 0.1751  data: 0.0001  max mem: 15821
[14:37:21.726344] Test:  [270/345]  eta: 0:00:12  loss: 0.1229 (0.1235)  time: 0.1755  data: 0.0001  max mem: 15821
[14:37:23.486608] Test:  [280/345]  eta: 0:00:11  loss: 0.1253 (0.1238)  time: 0.1758  data: 0.0001  max mem: 15821
[14:37:25.250016] Test:  [290/345]  eta: 0:00:09  loss: 0.1178 (0.1234)  time: 0.1761  data: 0.0001  max mem: 15821
[14:37:27.018183] Test:  [300/345]  eta: 0:00:07  loss: 0.1153 (0.1235)  time: 0.1765  data: 0.0001  max mem: 15821
[14:37:28.789524] Test:  [310/345]  eta: 0:00:06  loss: 0.1298 (0.1237)  time: 0.1769  data: 0.0001  max mem: 15821
[14:37:30.564386] Test:  [320/345]  eta: 0:00:04  loss: 0.1253 (0.1237)  time: 0.1773  data: 0.0001  max mem: 15821
[14:37:32.343327] Test:  [330/345]  eta: 0:00:02  loss: 0.1219 (0.1236)  time: 0.1776  data: 0.0001  max mem: 15821
[14:37:34.125106] Test:  [340/345]  eta: 0:00:00  loss: 0.1203 (0.1236)  time: 0.1780  data: 0.0001  max mem: 15821
[14:37:34.840264] Test:  [344/345]  eta: 0:00:00  loss: 0.1216 (0.1237)  time: 0.1782  data: 0.0001  max mem: 15821
[14:37:34.914928] Test: Total time: 0:00:59 (0.1737 s / it)
[14:37:44.862340] Test:  [ 0/57]  eta: 0:00:27  loss: 0.4524 (0.4524)  time: 0.4803  data: 0.3175  max mem: 15821
[14:37:46.515972] Test:  [10/57]  eta: 0:00:09  loss: 0.3794 (0.4173)  time: 0.1939  data: 0.0290  max mem: 15821
[14:37:48.173364] Test:  [20/57]  eta: 0:00:06  loss: 0.3794 (0.4062)  time: 0.1655  data: 0.0001  max mem: 15821
[14:37:49.833621] Test:  [30/57]  eta: 0:00:04  loss: 0.2654 (0.3464)  time: 0.1658  data: 0.0001  max mem: 15821
[14:37:51.498270] Test:  [40/57]  eta: 0:00:02  loss: 0.2246 (0.3220)  time: 0.1662  data: 0.0001  max mem: 15821
[14:37:53.166095] Test:  [50/57]  eta: 0:00:01  loss: 0.2519 (0.3217)  time: 0.1666  data: 0.0001  max mem: 15821
[14:37:54.067393] Test:  [56/57]  eta: 0:00:00  loss: 0.2896 (0.3294)  time: 0.1617  data: 0.0001  max mem: 15821
[14:37:54.139052] Test: Total time: 0:00:09 (0.1712 s / it)
[14:37:55.815881] Dice score of the network on the train images: 0.871709, val images: 0.811525
[14:37:55.820915] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:37:56.734802] Epoch: [36]  [  0/345]  eta: 0:05:15  lr: 0.000056  loss: 0.1507 (0.1507)  time: 0.9132  data: 0.3094  max mem: 15821
[14:38:08.769581] Epoch: [36]  [ 20/345]  eta: 0:03:20  lr: 0.000056  loss: 0.1213 (0.1259)  time: 0.6017  data: 0.0001  max mem: 15821
[14:38:20.817300] Epoch: [36]  [ 40/345]  eta: 0:03:05  lr: 0.000055  loss: 0.1296 (0.1265)  time: 0.6023  data: 0.0001  max mem: 15821
[14:38:32.878121] Epoch: [36]  [ 60/345]  eta: 0:02:53  lr: 0.000055  loss: 0.1227 (0.1245)  time: 0.6030  data: 0.0001  max mem: 15821
[14:38:44.932630] Epoch: [36]  [ 80/345]  eta: 0:02:40  lr: 0.000054  loss: 0.1141 (0.1230)  time: 0.6027  data: 0.0001  max mem: 15821
[14:38:57.003545] Epoch: [36]  [100/345]  eta: 0:02:28  lr: 0.000054  loss: 0.1207 (0.1233)  time: 0.6035  data: 0.0001  max mem: 15821
[14:39:09.082412] Epoch: [36]  [120/345]  eta: 0:02:16  lr: 0.000054  loss: 0.1271 (0.1246)  time: 0.6039  data: 0.0001  max mem: 15821
[14:39:21.175320] Epoch: [36]  [140/345]  eta: 0:02:04  lr: 0.000053  loss: 0.1224 (0.1249)  time: 0.6046  data: 0.0001  max mem: 15821
[14:39:33.266976] Epoch: [36]  [160/345]  eta: 0:01:51  lr: 0.000053  loss: 0.1272 (0.1254)  time: 0.6045  data: 0.0001  max mem: 15821
[14:39:45.370914] Epoch: [36]  [180/345]  eta: 0:01:39  lr: 0.000053  loss: 0.1196 (0.1250)  time: 0.6052  data: 0.0001  max mem: 15821
[14:39:57.480776] Epoch: [36]  [200/345]  eta: 0:01:27  lr: 0.000052  loss: 0.1261 (0.1251)  time: 0.6054  data: 0.0001  max mem: 15821
[14:40:09.594452] Epoch: [36]  [220/345]  eta: 0:01:15  lr: 0.000052  loss: 0.1281 (0.1254)  time: 0.6056  data: 0.0001  max mem: 15821
[14:40:21.702476] Epoch: [36]  [240/345]  eta: 0:01:03  lr: 0.000051  loss: 0.1259 (0.1255)  time: 0.6054  data: 0.0001  max mem: 15821
[14:40:33.802591] Epoch: [36]  [260/345]  eta: 0:00:51  lr: 0.000051  loss: 0.1181 (0.1253)  time: 0.6050  data: 0.0001  max mem: 15821
[14:40:45.909393] Epoch: [36]  [280/345]  eta: 0:00:39  lr: 0.000051  loss: 0.1189 (0.1257)  time: 0.6053  data: 0.0001  max mem: 15821
[14:40:58.011854] Epoch: [36]  [300/345]  eta: 0:00:27  lr: 0.000050  loss: 0.1181 (0.1253)  time: 0.6051  data: 0.0001  max mem: 15821
[14:41:10.112887] Epoch: [36]  [320/345]  eta: 0:00:15  lr: 0.000050  loss: 0.1221 (0.1257)  time: 0.6050  data: 0.0001  max mem: 15821
[14:41:22.206527] Epoch: [36]  [340/345]  eta: 0:00:03  lr: 0.000050  loss: 0.1240 (0.1258)  time: 0.6046  data: 0.0001  max mem: 15821
[14:41:24.626692] Epoch: [36]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.1240 (0.1258)  time: 0.6046  data: 0.0001  max mem: 15821
[14:41:24.701611] Epoch: [36] Total time: 0:03:28 (0.6055 s / it)
[14:41:24.702201] Averaged stats: lr: 0.000050  loss: 0.1240 (0.1258)
[14:41:25.230688] Test:  [  0/345]  eta: 0:03:00  loss: 0.1209 (0.1209)  time: 0.5230  data: 0.3594  max mem: 15821
[14:41:26.898261] Test:  [ 10/345]  eta: 0:01:06  loss: 0.1168 (0.1217)  time: 0.1991  data: 0.0328  max mem: 15821
[14:41:28.569520] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1137 (0.1185)  time: 0.1669  data: 0.0001  max mem: 15821
[14:41:30.243756] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1108 (0.1184)  time: 0.1672  data: 0.0001  max mem: 15821
[14:41:31.921542] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1136 (0.1184)  time: 0.1675  data: 0.0001  max mem: 15821
[14:41:33.603038] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1176 (0.1191)  time: 0.1679  data: 0.0001  max mem: 15821
[14:41:35.287579] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1170 (0.1193)  time: 0.1682  data: 0.0001  max mem: 15821
[14:41:36.975810] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1205 (0.1213)  time: 0.1686  data: 0.0001  max mem: 15821
[14:41:38.666872] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1213 (0.1208)  time: 0.1689  data: 0.0001  max mem: 15821
[14:41:40.361049] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1095 (0.1199)  time: 0.1692  data: 0.0001  max mem: 15821
[14:41:42.059786] Test:  [100/345]  eta: 0:00:42  loss: 0.1093 (0.1192)  time: 0.1696  data: 0.0001  max mem: 15821
[14:41:43.761752] Test:  [110/345]  eta: 0:00:40  loss: 0.1119 (0.1190)  time: 0.1700  data: 0.0001  max mem: 15821
[14:41:45.466970] Test:  [120/345]  eta: 0:00:38  loss: 0.1101 (0.1181)  time: 0.1703  data: 0.0001  max mem: 15821
[14:41:47.175799] Test:  [130/345]  eta: 0:00:36  loss: 0.1102 (0.1179)  time: 0.1706  data: 0.0001  max mem: 15821
[14:41:48.887599] Test:  [140/345]  eta: 0:00:35  loss: 0.1128 (0.1174)  time: 0.1710  data: 0.0001  max mem: 15821
[14:41:50.602027] Test:  [150/345]  eta: 0:00:33  loss: 0.1108 (0.1179)  time: 0.1713  data: 0.0001  max mem: 15821
[14:41:52.321215] Test:  [160/345]  eta: 0:00:31  loss: 0.1108 (0.1177)  time: 0.1716  data: 0.0001  max mem: 15821
[14:41:54.044051] Test:  [170/345]  eta: 0:00:30  loss: 0.1101 (0.1181)  time: 0.1720  data: 0.0001  max mem: 15821
[14:41:55.770261] Test:  [180/345]  eta: 0:00:28  loss: 0.1095 (0.1177)  time: 0.1724  data: 0.0001  max mem: 15821
[14:41:57.499947] Test:  [190/345]  eta: 0:00:26  loss: 0.1095 (0.1175)  time: 0.1727  data: 0.0001  max mem: 15821
[14:41:59.233350] Test:  [200/345]  eta: 0:00:24  loss: 0.1105 (0.1176)  time: 0.1731  data: 0.0001  max mem: 15821
[14:42:00.968879] Test:  [210/345]  eta: 0:00:23  loss: 0.1151 (0.1177)  time: 0.1734  data: 0.0001  max mem: 15821
[14:42:02.707384] Test:  [220/345]  eta: 0:00:21  loss: 0.1202 (0.1183)  time: 0.1736  data: 0.0001  max mem: 15821
[14:42:04.449267] Test:  [230/345]  eta: 0:00:19  loss: 0.1159 (0.1181)  time: 0.1740  data: 0.0001  max mem: 15821
[14:42:06.194693] Test:  [240/345]  eta: 0:00:18  loss: 0.1091 (0.1179)  time: 0.1743  data: 0.0001  max mem: 15821
[14:42:07.946212] Test:  [250/345]  eta: 0:00:16  loss: 0.1175 (0.1183)  time: 0.1748  data: 0.0001  max mem: 15821
[14:42:09.699187] Test:  [260/345]  eta: 0:00:14  loss: 0.1223 (0.1181)  time: 0.1752  data: 0.0001  max mem: 15821
[14:42:11.455946] Test:  [270/345]  eta: 0:00:12  loss: 0.1133 (0.1182)  time: 0.1754  data: 0.0001  max mem: 15821
[14:42:13.216386] Test:  [280/345]  eta: 0:00:11  loss: 0.1099 (0.1182)  time: 0.1758  data: 0.0001  max mem: 15821
[14:42:14.979779] Test:  [290/345]  eta: 0:00:09  loss: 0.1159 (0.1184)  time: 0.1761  data: 0.0001  max mem: 15821
[14:42:16.748697] Test:  [300/345]  eta: 0:00:07  loss: 0.1203 (0.1183)  time: 0.1766  data: 0.0001  max mem: 15821
[14:42:18.519417] Test:  [310/345]  eta: 0:00:06  loss: 0.1226 (0.1184)  time: 0.1769  data: 0.0001  max mem: 15821
[14:42:20.295396] Test:  [320/345]  eta: 0:00:04  loss: 0.1247 (0.1186)  time: 0.1773  data: 0.0001  max mem: 15821
[14:42:22.074048] Test:  [330/345]  eta: 0:00:02  loss: 0.1268 (0.1187)  time: 0.1777  data: 0.0001  max mem: 15821
[14:42:23.855732] Test:  [340/345]  eta: 0:00:00  loss: 0.1136 (0.1185)  time: 0.1780  data: 0.0001  max mem: 15821
[14:42:24.570582] Test:  [344/345]  eta: 0:00:00  loss: 0.1111 (0.1185)  time: 0.1781  data: 0.0001  max mem: 15821
[14:42:24.644659] Test: Total time: 0:00:59 (0.1737 s / it)
[14:42:34.626635] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4750 (0.4750)  time: 0.4633  data: 0.3003  max mem: 15821
[14:42:36.278328] Test:  [10/57]  eta: 0:00:09  loss: 0.4048 (0.4311)  time: 0.1922  data: 0.0274  max mem: 15821
[14:42:37.933316] Test:  [20/57]  eta: 0:00:06  loss: 0.4048 (0.4217)  time: 0.1653  data: 0.0001  max mem: 15821
[14:42:39.593673] Test:  [30/57]  eta: 0:00:04  loss: 0.2583 (0.3616)  time: 0.1657  data: 0.0001  max mem: 15821
[14:42:41.256496] Test:  [40/57]  eta: 0:00:02  loss: 0.2411 (0.3394)  time: 0.1661  data: 0.0001  max mem: 15821
[14:42:42.924970] Test:  [50/57]  eta: 0:00:01  loss: 0.2738 (0.3405)  time: 0.1665  data: 0.0001  max mem: 15821
[14:42:43.825253] Test:  [56/57]  eta: 0:00:00  loss: 0.3010 (0.3486)  time: 0.1616  data: 0.0000  max mem: 15821
[14:42:43.896411] Test: Total time: 0:00:09 (0.1708 s / it)
[14:42:45.606370] Dice score of the network on the train images: 0.881570, val images: 0.797432
[14:42:45.610711] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:42:46.568435] Epoch: [37]  [  0/345]  eta: 0:05:29  lr: 0.000050  loss: 0.1021 (0.1021)  time: 0.9565  data: 0.3532  max mem: 15821
[14:42:58.593522] Epoch: [37]  [ 20/345]  eta: 0:03:20  lr: 0.000049  loss: 0.1186 (0.1213)  time: 0.6012  data: 0.0001  max mem: 15821
[14:43:10.637020] Epoch: [37]  [ 40/345]  eta: 0:03:06  lr: 0.000049  loss: 0.1188 (0.1218)  time: 0.6021  data: 0.0001  max mem: 15821
[14:43:22.697947] Epoch: [37]  [ 60/345]  eta: 0:02:53  lr: 0.000048  loss: 0.1148 (0.1224)  time: 0.6030  data: 0.0001  max mem: 15821
[14:43:34.772990] Epoch: [37]  [ 80/345]  eta: 0:02:40  lr: 0.000048  loss: 0.1235 (0.1237)  time: 0.6037  data: 0.0001  max mem: 15821
[14:43:46.854885] Epoch: [37]  [100/345]  eta: 0:02:28  lr: 0.000048  loss: 0.1270 (0.1242)  time: 0.6040  data: 0.0001  max mem: 15821
[14:43:58.945902] Epoch: [37]  [120/345]  eta: 0:02:16  lr: 0.000047  loss: 0.1139 (0.1242)  time: 0.6045  data: 0.0001  max mem: 15821
[14:44:11.047835] Epoch: [37]  [140/345]  eta: 0:02:04  lr: 0.000047  loss: 0.1170 (0.1236)  time: 0.6051  data: 0.0001  max mem: 15821
[14:44:23.160996] Epoch: [37]  [160/345]  eta: 0:01:52  lr: 0.000047  loss: 0.1267 (0.1239)  time: 0.6056  data: 0.0001  max mem: 15821
[14:44:35.272748] Epoch: [37]  [180/345]  eta: 0:01:39  lr: 0.000046  loss: 0.1211 (0.1241)  time: 0.6055  data: 0.0001  max mem: 15821
[14:44:47.397443] Epoch: [37]  [200/345]  eta: 0:01:27  lr: 0.000046  loss: 0.1225 (0.1237)  time: 0.6062  data: 0.0001  max mem: 15821
[14:44:59.515043] Epoch: [37]  [220/345]  eta: 0:01:15  lr: 0.000045  loss: 0.1196 (0.1238)  time: 0.6058  data: 0.0001  max mem: 15821
[14:45:11.626528] Epoch: [37]  [240/345]  eta: 0:01:03  lr: 0.000045  loss: 0.1091 (0.1232)  time: 0.6055  data: 0.0001  max mem: 15821
[14:45:23.729626] Epoch: [37]  [260/345]  eta: 0:00:51  lr: 0.000045  loss: 0.1092 (0.1227)  time: 0.6051  data: 0.0001  max mem: 15821
[14:45:35.832966] Epoch: [37]  [280/345]  eta: 0:00:39  lr: 0.000044  loss: 0.1272 (0.1231)  time: 0.6051  data: 0.0001  max mem: 15821
[14:45:47.920121] Epoch: [37]  [300/345]  eta: 0:00:27  lr: 0.000044  loss: 0.1180 (0.1229)  time: 0.6043  data: 0.0001  max mem: 15821
[14:46:00.026661] Epoch: [37]  [320/345]  eta: 0:00:15  lr: 0.000044  loss: 0.1248 (0.1231)  time: 0.6053  data: 0.0001  max mem: 15821
[14:46:12.098327] Epoch: [37]  [340/345]  eta: 0:00:03  lr: 0.000043  loss: 0.1211 (0.1233)  time: 0.6035  data: 0.0001  max mem: 15821
[14:46:14.513264] Epoch: [37]  [344/345]  eta: 0:00:00  lr: 0.000043  loss: 0.1214 (0.1232)  time: 0.6040  data: 0.0001  max mem: 15821
[14:46:14.575106] Epoch: [37] Total time: 0:03:28 (0.6057 s / it)
[14:46:14.575386] Averaged stats: lr: 0.000043  loss: 0.1214 (0.1232)
[14:46:15.128145] Test:  [  0/345]  eta: 0:03:08  loss: 0.0993 (0.0993)  time: 0.5476  data: 0.3829  max mem: 15821
[14:46:16.796793] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1097 (0.1097)  time: 0.2014  data: 0.0349  max mem: 15821
[14:46:18.468692] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1161 (0.1123)  time: 0.1669  data: 0.0001  max mem: 15821
[14:46:20.143298] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1149 (0.1114)  time: 0.1672  data: 0.0001  max mem: 15821
[14:46:21.821881] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1124 (0.1126)  time: 0.1676  data: 0.0001  max mem: 15821
[14:46:23.503750] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1181 (0.1141)  time: 0.1679  data: 0.0001  max mem: 15821
[14:46:25.187558] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1103 (0.1144)  time: 0.1682  data: 0.0001  max mem: 15821
[14:46:26.876382] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1093 (0.1155)  time: 0.1686  data: 0.0001  max mem: 15821
[14:46:28.567020] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1106 (0.1152)  time: 0.1689  data: 0.0001  max mem: 15821
[14:46:30.261591] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1086 (0.1148)  time: 0.1692  data: 0.0001  max mem: 15821
[14:46:31.960377] Test:  [100/345]  eta: 0:00:42  loss: 0.1064 (0.1148)  time: 0.1696  data: 0.0001  max mem: 15821
[14:46:33.661855] Test:  [110/345]  eta: 0:00:40  loss: 0.1107 (0.1152)  time: 0.1700  data: 0.0001  max mem: 15821
[14:46:35.367326] Test:  [120/345]  eta: 0:00:38  loss: 0.1153 (0.1151)  time: 0.1703  data: 0.0001  max mem: 15821
[14:46:37.075289] Test:  [130/345]  eta: 0:00:36  loss: 0.1122 (0.1154)  time: 0.1706  data: 0.0001  max mem: 15821
[14:46:38.786832] Test:  [140/345]  eta: 0:00:35  loss: 0.1200 (0.1161)  time: 0.1709  data: 0.0001  max mem: 15821
[14:46:40.502098] Test:  [150/345]  eta: 0:00:33  loss: 0.1177 (0.1165)  time: 0.1713  data: 0.0001  max mem: 15821
[14:46:42.220941] Test:  [160/345]  eta: 0:00:31  loss: 0.1115 (0.1161)  time: 0.1716  data: 0.0001  max mem: 15821
[14:46:43.943208] Test:  [170/345]  eta: 0:00:30  loss: 0.1114 (0.1161)  time: 0.1720  data: 0.0001  max mem: 15821
[14:46:45.668192] Test:  [180/345]  eta: 0:00:28  loss: 0.1208 (0.1163)  time: 0.1723  data: 0.0001  max mem: 15821
[14:46:47.398099] Test:  [190/345]  eta: 0:00:26  loss: 0.1187 (0.1165)  time: 0.1727  data: 0.0001  max mem: 15821
[14:46:49.131194] Test:  [200/345]  eta: 0:00:24  loss: 0.1184 (0.1167)  time: 0.1731  data: 0.0001  max mem: 15821
[14:46:50.867462] Test:  [210/345]  eta: 0:00:23  loss: 0.1119 (0.1165)  time: 0.1734  data: 0.0001  max mem: 15821
[14:46:52.607012] Test:  [220/345]  eta: 0:00:21  loss: 0.1152 (0.1167)  time: 0.1737  data: 0.0001  max mem: 15821
[14:46:54.350867] Test:  [230/345]  eta: 0:00:19  loss: 0.1061 (0.1163)  time: 0.1741  data: 0.0001  max mem: 15821
[14:46:56.097277] Test:  [240/345]  eta: 0:00:18  loss: 0.1057 (0.1159)  time: 0.1745  data: 0.0001  max mem: 15821
[14:46:57.846637] Test:  [250/345]  eta: 0:00:16  loss: 0.1057 (0.1154)  time: 0.1747  data: 0.0001  max mem: 15821
[14:46:59.600669] Test:  [260/345]  eta: 0:00:14  loss: 0.1057 (0.1157)  time: 0.1751  data: 0.0001  max mem: 15821
[14:47:01.358067] Test:  [270/345]  eta: 0:00:12  loss: 0.1191 (0.1155)  time: 0.1755  data: 0.0001  max mem: 15821
[14:47:03.118620] Test:  [280/345]  eta: 0:00:11  loss: 0.1120 (0.1154)  time: 0.1758  data: 0.0001  max mem: 15821
[14:47:04.882014] Test:  [290/345]  eta: 0:00:09  loss: 0.1122 (0.1155)  time: 0.1761  data: 0.0001  max mem: 15821
[14:47:06.648798] Test:  [300/345]  eta: 0:00:07  loss: 0.1123 (0.1154)  time: 0.1764  data: 0.0001  max mem: 15821
[14:47:08.419345] Test:  [310/345]  eta: 0:00:06  loss: 0.1091 (0.1152)  time: 0.1768  data: 0.0001  max mem: 15821
[14:47:10.193683] Test:  [320/345]  eta: 0:00:04  loss: 0.1090 (0.1151)  time: 0.1772  data: 0.0001  max mem: 15821
[14:47:11.973069] Test:  [330/345]  eta: 0:00:02  loss: 0.1093 (0.1152)  time: 0.1776  data: 0.0001  max mem: 15821
[14:47:13.755000] Test:  [340/345]  eta: 0:00:00  loss: 0.1115 (0.1153)  time: 0.1780  data: 0.0001  max mem: 15821
[14:47:14.468805] Test:  [344/345]  eta: 0:00:00  loss: 0.1187 (0.1154)  time: 0.1782  data: 0.0001  max mem: 15821
[14:47:14.546876] Test: Total time: 0:00:59 (0.1738 s / it)
[14:47:24.506222] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4689 (0.4689)  time: 0.4702  data: 0.3073  max mem: 15821
[14:47:26.157301] Test:  [10/57]  eta: 0:00:09  loss: 0.3938 (0.4237)  time: 0.1928  data: 0.0280  max mem: 15821
[14:47:27.813391] Test:  [20/57]  eta: 0:00:06  loss: 0.3938 (0.4126)  time: 0.1653  data: 0.0001  max mem: 15821
[14:47:29.473964] Test:  [30/57]  eta: 0:00:04  loss: 0.2584 (0.3517)  time: 0.1658  data: 0.0001  max mem: 15821
[14:47:31.137040] Test:  [40/57]  eta: 0:00:02  loss: 0.2255 (0.3278)  time: 0.1661  data: 0.0001  max mem: 15821
[14:47:32.805147] Test:  [50/57]  eta: 0:00:01  loss: 0.2645 (0.3272)  time: 0.1665  data: 0.0001  max mem: 15821
[14:47:33.705877] Test:  [56/57]  eta: 0:00:00  loss: 0.2815 (0.3352)  time: 0.1617  data: 0.0001  max mem: 15821
[14:47:33.771145] Test: Total time: 0:00:09 (0.1708 s / it)
[14:47:35.443770] Dice score of the network on the train images: 0.881629, val images: 0.812142
[14:47:35.447883] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:47:36.368339] Epoch: [38]  [  0/345]  eta: 0:05:17  lr: 0.000043  loss: 0.1621 (0.1621)  time: 0.9192  data: 0.3150  max mem: 15821
[14:47:48.387604] Epoch: [38]  [ 20/345]  eta: 0:03:20  lr: 0.000043  loss: 0.1134 (0.1182)  time: 0.6009  data: 0.0001  max mem: 15821
[14:48:00.429223] Epoch: [38]  [ 40/345]  eta: 0:03:05  lr: 0.000042  loss: 0.1146 (0.1183)  time: 0.6020  data: 0.0001  max mem: 15821
[14:48:12.478150] Epoch: [38]  [ 60/345]  eta: 0:02:52  lr: 0.000042  loss: 0.1114 (0.1173)  time: 0.6024  data: 0.0001  max mem: 15821
[14:48:24.544844] Epoch: [38]  [ 80/345]  eta: 0:02:40  lr: 0.000042  loss: 0.1200 (0.1185)  time: 0.6033  data: 0.0001  max mem: 15821
[14:48:36.625633] Epoch: [38]  [100/345]  eta: 0:02:28  lr: 0.000041  loss: 0.1209 (0.1207)  time: 0.6040  data: 0.0001  max mem: 15821
[14:48:48.718217] Epoch: [38]  [120/345]  eta: 0:02:16  lr: 0.000041  loss: 0.1185 (0.1201)  time: 0.6046  data: 0.0001  max mem: 15821
[14:49:00.815807] Epoch: [38]  [140/345]  eta: 0:02:04  lr: 0.000041  loss: 0.1137 (0.1194)  time: 0.6048  data: 0.0001  max mem: 15821
[14:49:12.921888] Epoch: [38]  [160/345]  eta: 0:01:51  lr: 0.000040  loss: 0.1080 (0.1190)  time: 0.6053  data: 0.0001  max mem: 15821
[14:49:25.028546] Epoch: [38]  [180/345]  eta: 0:01:39  lr: 0.000040  loss: 0.1202 (0.1195)  time: 0.6053  data: 0.0001  max mem: 15821
[14:49:37.132009] Epoch: [38]  [200/345]  eta: 0:01:27  lr: 0.000040  loss: 0.1193 (0.1194)  time: 0.6051  data: 0.0001  max mem: 15821
[14:49:49.234300] Epoch: [38]  [220/345]  eta: 0:01:15  lr: 0.000039  loss: 0.1197 (0.1196)  time: 0.6051  data: 0.0001  max mem: 15821
[14:50:01.336733] Epoch: [38]  [240/345]  eta: 0:01:03  lr: 0.000039  loss: 0.1260 (0.1202)  time: 0.6051  data: 0.0001  max mem: 15821
[14:50:13.421149] Epoch: [38]  [260/345]  eta: 0:00:51  lr: 0.000039  loss: 0.1137 (0.1198)  time: 0.6042  data: 0.0001  max mem: 15821
[14:50:25.500515] Epoch: [38]  [280/345]  eta: 0:00:39  lr: 0.000038  loss: 0.1162 (0.1199)  time: 0.6039  data: 0.0001  max mem: 15821
[14:50:37.595019] Epoch: [38]  [300/345]  eta: 0:00:27  lr: 0.000038  loss: 0.1105 (0.1195)  time: 0.6047  data: 0.0001  max mem: 15821
[14:50:49.685222] Epoch: [38]  [320/345]  eta: 0:00:15  lr: 0.000038  loss: 0.1203 (0.1197)  time: 0.6045  data: 0.0001  max mem: 15821
[14:51:01.776474] Epoch: [38]  [340/345]  eta: 0:00:03  lr: 0.000037  loss: 0.1235 (0.1199)  time: 0.6045  data: 0.0001  max mem: 15821
[14:51:04.196270] Epoch: [38]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 0.1258 (0.1199)  time: 0.6047  data: 0.0001  max mem: 15821
[14:51:04.267261] Epoch: [38] Total time: 0:03:28 (0.6053 s / it)
[14:51:04.267599] Averaged stats: lr: 0.000037  loss: 0.1258 (0.1199)
[14:51:04.768555] Test:  [  0/345]  eta: 0:02:50  loss: 0.0925 (0.0925)  time: 0.4955  data: 0.3310  max mem: 15821
[14:51:06.436893] Test:  [ 10/345]  eta: 0:01:05  loss: 0.1109 (0.1084)  time: 0.1966  data: 0.0302  max mem: 15821
[14:51:08.109120] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1124 (0.1155)  time: 0.1670  data: 0.0001  max mem: 15821
[14:51:09.784447] Test:  [ 30/345]  eta: 0:00:55  loss: 0.1232 (0.1177)  time: 0.1673  data: 0.0001  max mem: 15821
[14:51:11.463625] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1204 (0.1178)  time: 0.1677  data: 0.0001  max mem: 15821
[14:51:13.145045] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1146 (0.1172)  time: 0.1680  data: 0.0001  max mem: 15821
[14:51:14.830286] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1099 (0.1161)  time: 0.1683  data: 0.0001  max mem: 15821
[14:51:16.516596] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1108 (0.1161)  time: 0.1685  data: 0.0001  max mem: 15821
[14:51:18.208366] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1129 (0.1155)  time: 0.1688  data: 0.0001  max mem: 15821
[14:51:19.903381] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1043 (0.1148)  time: 0.1693  data: 0.0001  max mem: 15821
[14:51:21.602095] Test:  [100/345]  eta: 0:00:42  loss: 0.1066 (0.1141)  time: 0.1696  data: 0.0001  max mem: 15821
[14:51:23.304333] Test:  [110/345]  eta: 0:00:40  loss: 0.1139 (0.1150)  time: 0.1700  data: 0.0001  max mem: 15821
[14:51:25.008817] Test:  [120/345]  eta: 0:00:38  loss: 0.1146 (0.1142)  time: 0.1703  data: 0.0001  max mem: 15821
[14:51:26.718022] Test:  [130/345]  eta: 0:00:36  loss: 0.1033 (0.1134)  time: 0.1706  data: 0.0001  max mem: 15821
[14:51:28.429090] Test:  [140/345]  eta: 0:00:35  loss: 0.1044 (0.1134)  time: 0.1710  data: 0.0001  max mem: 15821
[14:51:30.144383] Test:  [150/345]  eta: 0:00:33  loss: 0.1051 (0.1130)  time: 0.1713  data: 0.0001  max mem: 15821
[14:51:31.863232] Test:  [160/345]  eta: 0:00:31  loss: 0.1069 (0.1128)  time: 0.1716  data: 0.0001  max mem: 15821
[14:51:33.585622] Test:  [170/345]  eta: 0:00:29  loss: 0.1066 (0.1129)  time: 0.1720  data: 0.0001  max mem: 15821
[14:51:35.311661] Test:  [180/345]  eta: 0:00:28  loss: 0.1051 (0.1127)  time: 0.1724  data: 0.0001  max mem: 15821
[14:51:37.041231] Test:  [190/345]  eta: 0:00:26  loss: 0.1108 (0.1128)  time: 0.1727  data: 0.0001  max mem: 15821
[14:51:38.773308] Test:  [200/345]  eta: 0:00:24  loss: 0.1117 (0.1129)  time: 0.1730  data: 0.0001  max mem: 15821
[14:51:40.507737] Test:  [210/345]  eta: 0:00:23  loss: 0.1160 (0.1134)  time: 0.1733  data: 0.0001  max mem: 15821
[14:51:42.246973] Test:  [220/345]  eta: 0:00:21  loss: 0.1199 (0.1138)  time: 0.1736  data: 0.0001  max mem: 15821
[14:51:43.990198] Test:  [230/345]  eta: 0:00:19  loss: 0.1196 (0.1138)  time: 0.1741  data: 0.0001  max mem: 15821
[14:51:45.736845] Test:  [240/345]  eta: 0:00:18  loss: 0.1133 (0.1136)  time: 0.1744  data: 0.0001  max mem: 15821
[14:51:47.487111] Test:  [250/345]  eta: 0:00:16  loss: 0.1137 (0.1138)  time: 0.1748  data: 0.0001  max mem: 15821
[14:51:49.240814] Test:  [260/345]  eta: 0:00:14  loss: 0.1132 (0.1136)  time: 0.1751  data: 0.0001  max mem: 15821
[14:51:50.997480] Test:  [270/345]  eta: 0:00:12  loss: 0.1082 (0.1135)  time: 0.1755  data: 0.0001  max mem: 15821
[14:51:52.757794] Test:  [280/345]  eta: 0:00:11  loss: 0.1025 (0.1133)  time: 0.1758  data: 0.0001  max mem: 15821
[14:51:54.521020] Test:  [290/345]  eta: 0:00:09  loss: 0.1058 (0.1134)  time: 0.1761  data: 0.0001  max mem: 15821
[14:51:56.286601] Test:  [300/345]  eta: 0:00:07  loss: 0.1055 (0.1132)  time: 0.1764  data: 0.0001  max mem: 15821
[14:51:58.058228] Test:  [310/345]  eta: 0:00:06  loss: 0.1057 (0.1132)  time: 0.1768  data: 0.0001  max mem: 15821
[14:51:59.831803] Test:  [320/345]  eta: 0:00:04  loss: 0.1108 (0.1128)  time: 0.1772  data: 0.0001  max mem: 15821
[14:52:01.610389] Test:  [330/345]  eta: 0:00:02  loss: 0.1105 (0.1128)  time: 0.1775  data: 0.0001  max mem: 15821
[14:52:03.391186] Test:  [340/345]  eta: 0:00:00  loss: 0.1105 (0.1128)  time: 0.1779  data: 0.0001  max mem: 15821
[14:52:04.105086] Test:  [344/345]  eta: 0:00:00  loss: 0.1056 (0.1127)  time: 0.1780  data: 0.0001  max mem: 15821
[14:52:04.168614] Test: Total time: 0:00:59 (0.1736 s / it)
[14:52:14.065975] Test:  [ 0/57]  eta: 0:00:27  loss: 0.4818 (0.4818)  time: 0.4745  data: 0.3116  max mem: 15821
[14:52:15.716684] Test:  [10/57]  eta: 0:00:09  loss: 0.4055 (0.4296)  time: 0.1931  data: 0.0284  max mem: 15821
[14:52:17.371737] Test:  [20/57]  eta: 0:00:06  loss: 0.4098 (0.4205)  time: 0.1652  data: 0.0001  max mem: 15821
[14:52:19.031643] Test:  [30/57]  eta: 0:00:04  loss: 0.2581 (0.3574)  time: 0.1657  data: 0.0001  max mem: 15821
[14:52:20.694891] Test:  [40/57]  eta: 0:00:02  loss: 0.2274 (0.3329)  time: 0.1661  data: 0.0001  max mem: 15821
[14:52:22.361856] Test:  [50/57]  eta: 0:00:01  loss: 0.2677 (0.3315)  time: 0.1665  data: 0.0001  max mem: 15821
[14:52:23.262149] Test:  [56/57]  eta: 0:00:00  loss: 0.2852 (0.3395)  time: 0.1616  data: 0.0001  max mem: 15821
[14:52:23.335202] Test: Total time: 0:00:09 (0.1710 s / it)
[14:52:25.033707] Dice score of the network on the train images: 0.883293, val images: 0.810159
[14:52:25.038018] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:52:25.955345] Epoch: [39]  [  0/345]  eta: 0:05:16  lr: 0.000037  loss: 0.1102 (0.1102)  time: 0.9161  data: 0.3142  max mem: 15821
[14:52:37.967252] Epoch: [39]  [ 20/345]  eta: 0:03:20  lr: 0.000037  loss: 0.1148 (0.1175)  time: 0.6005  data: 0.0001  max mem: 15821
[14:52:50.012808] Epoch: [39]  [ 40/345]  eta: 0:03:05  lr: 0.000036  loss: 0.1117 (0.1170)  time: 0.6022  data: 0.0001  max mem: 15821
[14:53:02.065414] Epoch: [39]  [ 60/345]  eta: 0:02:52  lr: 0.000036  loss: 0.1138 (0.1159)  time: 0.6026  data: 0.0001  max mem: 15821
[14:53:14.134245] Epoch: [39]  [ 80/345]  eta: 0:02:40  lr: 0.000036  loss: 0.1093 (0.1155)  time: 0.6034  data: 0.0001  max mem: 15821
[14:53:26.212660] Epoch: [39]  [100/345]  eta: 0:02:28  lr: 0.000035  loss: 0.1147 (0.1155)  time: 0.6039  data: 0.0001  max mem: 15821
[14:53:38.302437] Epoch: [39]  [120/345]  eta: 0:02:16  lr: 0.000035  loss: 0.1117 (0.1152)  time: 0.6044  data: 0.0001  max mem: 15821
[14:53:50.399496] Epoch: [39]  [140/345]  eta: 0:02:04  lr: 0.000035  loss: 0.1140 (0.1156)  time: 0.6048  data: 0.0001  max mem: 15821
[14:54:02.510908] Epoch: [39]  [160/345]  eta: 0:01:51  lr: 0.000034  loss: 0.1230 (0.1169)  time: 0.6055  data: 0.0001  max mem: 15821
[14:54:14.620312] Epoch: [39]  [180/345]  eta: 0:01:39  lr: 0.000034  loss: 0.1157 (0.1170)  time: 0.6054  data: 0.0001  max mem: 15821
[14:54:26.728729] Epoch: [39]  [200/345]  eta: 0:01:27  lr: 0.000034  loss: 0.1103 (0.1165)  time: 0.6054  data: 0.0001  max mem: 15821
[14:54:38.825191] Epoch: [39]  [220/345]  eta: 0:01:15  lr: 0.000033  loss: 0.1127 (0.1164)  time: 0.6048  data: 0.0001  max mem: 15821
[14:54:50.936373] Epoch: [39]  [240/345]  eta: 0:01:03  lr: 0.000033  loss: 0.1071 (0.1160)  time: 0.6055  data: 0.0001  max mem: 15821
[14:55:03.048090] Epoch: [39]  [260/345]  eta: 0:00:51  lr: 0.000033  loss: 0.1216 (0.1166)  time: 0.6055  data: 0.0001  max mem: 15821
[14:55:15.151811] Epoch: [39]  [280/345]  eta: 0:00:39  lr: 0.000032  loss: 0.1134 (0.1167)  time: 0.6051  data: 0.0001  max mem: 15821
[14:55:27.248882] Epoch: [39]  [300/345]  eta: 0:00:27  lr: 0.000032  loss: 0.1123 (0.1169)  time: 0.6048  data: 0.0001  max mem: 15821
[14:55:39.338102] Epoch: [39]  [320/345]  eta: 0:00:15  lr: 0.000032  loss: 0.1137 (0.1167)  time: 0.6044  data: 0.0001  max mem: 15821
[14:55:51.429010] Epoch: [39]  [340/345]  eta: 0:00:03  lr: 0.000031  loss: 0.1142 (0.1168)  time: 0.6045  data: 0.0001  max mem: 15821
[14:55:53.846833] Epoch: [39]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 0.1175 (0.1172)  time: 0.6043  data: 0.0001  max mem: 15821
[14:55:53.913939] Epoch: [39] Total time: 0:03:28 (0.6054 s / it)
[14:55:53.914645] Averaged stats: lr: 0.000031  loss: 0.1175 (0.1172)
[14:55:54.444749] Test:  [  0/345]  eta: 0:03:01  loss: 0.0953 (0.0953)  time: 0.5246  data: 0.3607  max mem: 15821
[14:55:56.114199] Test:  [ 10/345]  eta: 0:01:06  loss: 0.1085 (0.1166)  time: 0.1994  data: 0.0329  max mem: 15821
[14:55:57.784246] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1085 (0.1140)  time: 0.1669  data: 0.0001  max mem: 15821
[14:55:59.459851] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1068 (0.1123)  time: 0.1672  data: 0.0001  max mem: 15821
[14:56:01.137608] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1088 (0.1125)  time: 0.1676  data: 0.0001  max mem: 15821
[14:56:02.819501] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1155 (0.1140)  time: 0.1679  data: 0.0001  max mem: 15821
[14:56:04.504060] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1098 (0.1144)  time: 0.1683  data: 0.0001  max mem: 15821
[14:56:06.192190] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1098 (0.1139)  time: 0.1686  data: 0.0001  max mem: 15821
[14:56:07.883206] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1097 (0.1132)  time: 0.1689  data: 0.0001  max mem: 15821
[14:56:09.578539] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1075 (0.1130)  time: 0.1693  data: 0.0001  max mem: 15821
[14:56:11.276333] Test:  [100/345]  eta: 0:00:42  loss: 0.1039 (0.1129)  time: 0.1696  data: 0.0001  max mem: 15821
[14:56:12.977872] Test:  [110/345]  eta: 0:00:40  loss: 0.1057 (0.1128)  time: 0.1699  data: 0.0001  max mem: 15821
[14:56:14.683730] Test:  [120/345]  eta: 0:00:38  loss: 0.1070 (0.1130)  time: 0.1703  data: 0.0001  max mem: 15821
[14:56:16.393446] Test:  [130/345]  eta: 0:00:36  loss: 0.1081 (0.1130)  time: 0.1707  data: 0.0001  max mem: 15821
[14:56:18.106100] Test:  [140/345]  eta: 0:00:35  loss: 0.1081 (0.1130)  time: 0.1711  data: 0.0001  max mem: 15821
[14:56:19.821213] Test:  [150/345]  eta: 0:00:33  loss: 0.1055 (0.1128)  time: 0.1713  data: 0.0001  max mem: 15821
[14:56:21.540159] Test:  [160/345]  eta: 0:00:31  loss: 0.1005 (0.1124)  time: 0.1716  data: 0.0001  max mem: 15821
[14:56:23.264494] Test:  [170/345]  eta: 0:00:30  loss: 0.1085 (0.1127)  time: 0.1721  data: 0.0001  max mem: 15821
[14:56:24.990263] Test:  [180/345]  eta: 0:00:28  loss: 0.1087 (0.1124)  time: 0.1724  data: 0.0001  max mem: 15821
[14:56:26.718714] Test:  [190/345]  eta: 0:00:26  loss: 0.1011 (0.1119)  time: 0.1727  data: 0.0001  max mem: 15821
[14:56:28.451765] Test:  [200/345]  eta: 0:00:24  loss: 0.1068 (0.1118)  time: 0.1730  data: 0.0001  max mem: 15821
[14:56:30.187394] Test:  [210/345]  eta: 0:00:23  loss: 0.1109 (0.1117)  time: 0.1734  data: 0.0001  max mem: 15821
[14:56:31.925912] Test:  [220/345]  eta: 0:00:21  loss: 0.1140 (0.1120)  time: 0.1736  data: 0.0001  max mem: 15821
[14:56:33.668022] Test:  [230/345]  eta: 0:00:19  loss: 0.1101 (0.1116)  time: 0.1740  data: 0.0001  max mem: 15821
[14:56:35.413077] Test:  [240/345]  eta: 0:00:18  loss: 0.1041 (0.1115)  time: 0.1743  data: 0.0001  max mem: 15821
[14:56:37.163219] Test:  [250/345]  eta: 0:00:16  loss: 0.1093 (0.1117)  time: 0.1747  data: 0.0001  max mem: 15821
[14:56:38.916152] Test:  [260/345]  eta: 0:00:14  loss: 0.1088 (0.1117)  time: 0.1751  data: 0.0001  max mem: 15821
[14:56:40.673514] Test:  [270/345]  eta: 0:00:12  loss: 0.1070 (0.1117)  time: 0.1755  data: 0.0001  max mem: 15821
[14:56:42.433196] Test:  [280/345]  eta: 0:00:11  loss: 0.1148 (0.1123)  time: 0.1758  data: 0.0001  max mem: 15821
[14:56:44.196959] Test:  [290/345]  eta: 0:00:09  loss: 0.1162 (0.1125)  time: 0.1761  data: 0.0001  max mem: 15821
[14:56:45.965663] Test:  [300/345]  eta: 0:00:07  loss: 0.1119 (0.1126)  time: 0.1766  data: 0.0001  max mem: 15821
[14:56:47.735384] Test:  [310/345]  eta: 0:00:06  loss: 0.1141 (0.1125)  time: 0.1769  data: 0.0001  max mem: 15821
[14:56:49.510274] Test:  [320/345]  eta: 0:00:04  loss: 0.1113 (0.1126)  time: 0.1772  data: 0.0001  max mem: 15821
[14:56:51.289027] Test:  [330/345]  eta: 0:00:02  loss: 0.1153 (0.1127)  time: 0.1776  data: 0.0001  max mem: 15821
[14:56:53.070077] Test:  [340/345]  eta: 0:00:00  loss: 0.1106 (0.1125)  time: 0.1779  data: 0.0001  max mem: 15821
[14:56:53.785131] Test:  [344/345]  eta: 0:00:00  loss: 0.1106 (0.1125)  time: 0.1781  data: 0.0001  max mem: 15821
[14:56:53.860597] Test: Total time: 0:00:59 (0.1737 s / it)
[14:57:03.753943] Test:  [ 0/57]  eta: 0:00:28  loss: 0.4659 (0.4659)  time: 0.5084  data: 0.3455  max mem: 15821
[14:57:05.405749] Test:  [10/57]  eta: 0:00:09  loss: 0.3882 (0.4256)  time: 0.1963  data: 0.0315  max mem: 15821
[14:57:07.062497] Test:  [20/57]  eta: 0:00:06  loss: 0.3882 (0.4166)  time: 0.1654  data: 0.0001  max mem: 15821
[14:57:08.722828] Test:  [30/57]  eta: 0:00:04  loss: 0.2684 (0.3596)  time: 0.1658  data: 0.0001  max mem: 15821
[14:57:10.385614] Test:  [40/57]  eta: 0:00:02  loss: 0.2395 (0.3388)  time: 0.1661  data: 0.0001  max mem: 15821
[14:57:12.053991] Test:  [50/57]  eta: 0:00:01  loss: 0.2794 (0.3388)  time: 0.1665  data: 0.0001  max mem: 15821
[14:57:12.954343] Test:  [56/57]  eta: 0:00:00  loss: 0.2903 (0.3456)  time: 0.1617  data: 0.0000  max mem: 15821
[14:57:13.023888] Test: Total time: 0:00:09 (0.1716 s / it)
[14:57:14.737374] Dice score of the network on the train images: 0.887643, val images: 0.801674
[14:57:14.741764] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:57:15.641467] Epoch: [40]  [  0/345]  eta: 0:05:10  lr: 0.000031  loss: 0.1382 (0.1382)  time: 0.8987  data: 0.2990  max mem: 15821
[14:57:27.664309] Epoch: [40]  [ 20/345]  eta: 0:03:19  lr: 0.000031  loss: 0.1132 (0.1189)  time: 0.6011  data: 0.0001  max mem: 15821
[14:57:39.705419] Epoch: [40]  [ 40/345]  eta: 0:03:05  lr: 0.000031  loss: 0.1103 (0.1171)  time: 0.6020  data: 0.0001  max mem: 15821
[14:57:51.760754] Epoch: [40]  [ 60/345]  eta: 0:02:52  lr: 0.000030  loss: 0.1057 (0.1156)  time: 0.6027  data: 0.0001  max mem: 15821
[14:58:03.824394] Epoch: [40]  [ 80/345]  eta: 0:02:40  lr: 0.000030  loss: 0.1157 (0.1164)  time: 0.6031  data: 0.0001  max mem: 15821
[14:58:15.895129] Epoch: [40]  [100/345]  eta: 0:02:28  lr: 0.000030  loss: 0.1101 (0.1158)  time: 0.6035  data: 0.0001  max mem: 15821
[14:58:27.981236] Epoch: [40]  [120/345]  eta: 0:02:16  lr: 0.000029  loss: 0.1133 (0.1157)  time: 0.6043  data: 0.0001  max mem: 15821
[14:58:40.075594] Epoch: [40]  [140/345]  eta: 0:02:04  lr: 0.000029  loss: 0.1073 (0.1155)  time: 0.6047  data: 0.0001  max mem: 15821
[14:58:52.175328] Epoch: [40]  [160/345]  eta: 0:01:51  lr: 0.000029  loss: 0.1149 (0.1153)  time: 0.6049  data: 0.0001  max mem: 15821
[14:59:04.277651] Epoch: [40]  [180/345]  eta: 0:01:39  lr: 0.000028  loss: 0.1053 (0.1147)  time: 0.6051  data: 0.0001  max mem: 15821
[14:59:16.369210] Epoch: [40]  [200/345]  eta: 0:01:27  lr: 0.000028  loss: 0.1128 (0.1147)  time: 0.6045  data: 0.0001  max mem: 15821
[14:59:28.453795] Epoch: [40]  [220/345]  eta: 0:01:15  lr: 0.000028  loss: 0.1134 (0.1149)  time: 0.6042  data: 0.0001  max mem: 15821
[14:59:40.551362] Epoch: [40]  [240/345]  eta: 0:01:03  lr: 0.000027  loss: 0.1119 (0.1150)  time: 0.6048  data: 0.0001  max mem: 15821

[14:59:52.641712] Epoch: [40]  [260/345]  eta: 0:00:51  lr: 0.000027  loss: 0.1175 (0.1152)  time: 0.6045  data: 0.0001  max mem: 15821
[15:00:04.747803] Epoch: [40]  [280/345]  eta: 0:00:39  lr: 0.000027  loss: 0.1118 (0.1151)  time: 0.6053  data: 0.0001  max mem: 15821
[15:00:16.842031] Epoch: [40]  [300/345]  eta: 0:00:27  lr: 0.000026  loss: 0.1130 (0.1151)  time: 0.6047  data: 0.0001  max mem: 15821
[15:00:28.930057] Epoch: [40]  [320/345]  eta: 0:00:15  lr: 0.000026  loss: 0.1164 (0.1154)  time: 0.6044  data: 0.0001  max mem: 15821
[15:00:41.003825] Epoch: [40]  [340/345]  eta: 0:00:03  lr: 0.000026  loss: 0.1118 (0.1151)  time: 0.6036  data: 0.0001  max mem: 15821
[15:00:43.419243] Epoch: [40]  [344/345]  eta: 0:00:00  lr: 0.000026  loss: 0.1130 (0.1151)  time: 0.6037  data: 0.0001  max mem: 15821
[15:00:43.488864] Epoch: [40] Total time: 0:03:28 (0.6051 s / it)
[15:00:43.489080] Averaged stats: lr: 0.000026  loss: 0.1130 (0.1151)
[15:00:44.020968] Test:  [  0/345]  eta: 0:03:01  loss: 0.1073 (0.1073)  time: 0.5265  data: 0.3623  max mem: 15821
[15:00:45.688169] Test:  [ 10/345]  eta: 0:01:06  loss: 0.1057 (0.1083)  time: 0.1993  data: 0.0330  max mem: 15821
[15:00:47.358129] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1002 (0.1030)  time: 0.1668  data: 0.0001  max mem: 15821
[15:00:49.033313] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1053 (0.1051)  time: 0.1672  data: 0.0001  max mem: 15821
[15:00:50.710483] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1103 (0.1067)  time: 0.1676  data: 0.0001  max mem: 15821
[15:00:52.390277] Test:  [ 50/345]  eta: 0:00:51  loss: 0.0982 (0.1058)  time: 0.1678  data: 0.0001  max mem: 15821
[15:00:54.074461] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1001 (0.1065)  time: 0.1681  data: 0.0001  max mem: 15821
[15:00:55.762606] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1016 (0.1060)  time: 0.1686  data: 0.0001  max mem: 15821
[15:00:57.453796] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1016 (0.1058)  time: 0.1689  data: 0.0001  max mem: 15821
[15:00:59.147828] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1044 (0.1065)  time: 0.1692  data: 0.0001  max mem: 15821
[15:01:00.845439] Test:  [100/345]  eta: 0:00:42  loss: 0.0965 (0.1059)  time: 0.1695  data: 0.0001  max mem: 15821
[15:01:02.547135] Test:  [110/345]  eta: 0:00:40  loss: 0.1070 (0.1070)  time: 0.1699  data: 0.0001  max mem: 15821
[15:01:04.251176] Test:  [120/345]  eta: 0:00:38  loss: 0.1071 (0.1070)  time: 0.1702  data: 0.0001  max mem: 15821
[15:01:05.959477] Test:  [130/345]  eta: 0:00:36  loss: 0.1019 (0.1067)  time: 0.1706  data: 0.0001  max mem: 15821
[15:01:07.671371] Test:  [140/345]  eta: 0:00:35  loss: 0.1039 (0.1066)  time: 0.1709  data: 0.0001  max mem: 15821
[15:01:09.386220] Test:  [150/345]  eta: 0:00:33  loss: 0.1038 (0.1070)  time: 0.1713  data: 0.0001  max mem: 15821
[15:01:11.106484] Test:  [160/345]  eta: 0:00:31  loss: 0.0953 (0.1066)  time: 0.1717  data: 0.0001  max mem: 15821
[15:01:12.829013] Test:  [170/345]  eta: 0:00:30  loss: 0.1014 (0.1069)  time: 0.1721  data: 0.0001  max mem: 15821
[15:01:14.555040] Test:  [180/345]  eta: 0:00:28  loss: 0.1061 (0.1068)  time: 0.1724  data: 0.0001  max mem: 15821
[15:01:16.283609] Test:  [190/345]  eta: 0:00:26  loss: 0.1054 (0.1072)  time: 0.1727  data: 0.0001  max mem: 15821
[15:01:18.016526] Test:  [200/345]  eta: 0:00:24  loss: 0.1085 (0.1072)  time: 0.1730  data: 0.0001  max mem: 15821
[15:01:19.750817] Test:  [210/345]  eta: 0:00:23  loss: 0.1013 (0.1071)  time: 0.1733  data: 0.0001  max mem: 15821
[15:01:21.489902] Test:  [220/345]  eta: 0:00:21  loss: 0.0998 (0.1072)  time: 0.1736  data: 0.0001  max mem: 15821
[15:01:23.232344] Test:  [230/345]  eta: 0:00:19  loss: 0.1038 (0.1075)  time: 0.1740  data: 0.0001  max mem: 15821
[15:01:24.978813] Test:  [240/345]  eta: 0:00:18  loss: 0.1106 (0.1076)  time: 0.1744  data: 0.0001  max mem: 15821
[15:01:26.728868] Test:  [250/345]  eta: 0:00:16  loss: 0.1097 (0.1075)  time: 0.1748  data: 0.0001  max mem: 15821
[15:01:28.481584] Test:  [260/345]  eta: 0:00:14  loss: 0.1032 (0.1073)  time: 0.1751  data: 0.0001  max mem: 15821
[15:01:30.239103] Test:  [270/345]  eta: 0:00:12  loss: 0.1035 (0.1073)  time: 0.1755  data: 0.0001  max mem: 15821
[15:01:31.998151] Test:  [280/345]  eta: 0:00:11  loss: 0.1019 (0.1072)  time: 0.1758  data: 0.0001  max mem: 15821
[15:01:33.760898] Test:  [290/345]  eta: 0:00:09  loss: 0.1006 (0.1072)  time: 0.1760  data: 0.0001  max mem: 15821
[15:01:35.526439] Test:  [300/345]  eta: 0:00:07  loss: 0.1012 (0.1070)  time: 0.1763  data: 0.0001  max mem: 15821
[15:01:37.297433] Test:  [310/345]  eta: 0:00:06  loss: 0.1038 (0.1070)  time: 0.1768  data: 0.0001  max mem: 15821
[15:01:39.071905] Test:  [320/345]  eta: 0:00:04  loss: 0.1055 (0.1071)  time: 0.1772  data: 0.0001  max mem: 15821
[15:01:40.850022] Test:  [330/345]  eta: 0:00:02  loss: 0.1041 (0.1071)  time: 0.1776  data: 0.0001  max mem: 15821
[15:01:42.631905] Test:  [340/345]  eta: 0:00:00  loss: 0.1036 (0.1070)  time: 0.1779  data: 0.0001  max mem: 15821
[15:01:43.344191] Test:  [344/345]  eta: 0:00:00  loss: 0.1038 (0.1070)  time: 0.1781  data: 0.0001  max mem: 15821
[15:01:43.417662] Test: Total time: 0:00:59 (0.1737 s / it)
[15:01:53.358903] Test:  [ 0/57]  eta: 0:00:27  loss: 0.4725 (0.4725)  time: 0.4857  data: 0.3229  max mem: 15821
[15:01:55.010051] Test:  [10/57]  eta: 0:00:09  loss: 0.3927 (0.4338)  time: 0.1942  data: 0.0294  max mem: 15821
[15:01:56.666079] Test:  [20/57]  eta: 0:00:06  loss: 0.4113 (0.4246)  time: 0.1653  data: 0.0001  max mem: 15821
[15:01:58.324601] Test:  [30/57]  eta: 0:00:04  loss: 0.2644 (0.3636)  time: 0.1657  data: 0.0001  max mem: 15821
[15:01:59.988397] Test:  [40/57]  eta: 0:00:02  loss: 0.2400 (0.3404)  time: 0.1661  data: 0.0001  max mem: 15821
[15:02:01.656315] Test:  [50/57]  eta: 0:00:01  loss: 0.2803 (0.3397)  time: 0.1665  data: 0.0001  max mem: 15821
[15:02:02.555559] Test:  [56/57]  eta: 0:00:00  loss: 0.2985 (0.3471)  time: 0.1616  data: 0.0000  max mem: 15821
[15:02:02.633332] Test: Total time: 0:00:09 (0.1712 s / it)
[15:02:04.298939] Dice score of the network on the train images: 0.891802, val images: 0.805379
[15:02:04.303155] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:02:05.202265] Epoch: [41]  [  0/345]  eta: 0:05:09  lr: 0.000026  loss: 0.1064 (0.1064)  time: 0.8981  data: 0.2982  max mem: 15821
[15:02:17.230900] Epoch: [41]  [ 20/345]  eta: 0:03:20  lr: 0.000025  loss: 0.1053 (0.1109)  time: 0.6014  data: 0.0001  max mem: 15821
[15:02:29.270123] Epoch: [41]  [ 40/345]  eta: 0:03:05  lr: 0.000025  loss: 0.1109 (0.1112)  time: 0.6019  data: 0.0001  max mem: 15821
[15:02:41.326876] Epoch: [41]  [ 60/345]  eta: 0:02:52  lr: 0.000025  loss: 0.1063 (0.1093)  time: 0.6028  data: 0.0001  max mem: 15821
[15:02:53.397051] Epoch: [41]  [ 80/345]  eta: 0:02:40  lr: 0.000025  loss: 0.1132 (0.1106)  time: 0.6035  data: 0.0001  max mem: 15821
[15:03:05.475720] Epoch: [41]  [100/345]  eta: 0:02:28  lr: 0.000024  loss: 0.1177 (0.1128)  time: 0.6039  data: 0.0001  max mem: 15821
[15:03:17.570524] Epoch: [41]  [120/345]  eta: 0:02:16  lr: 0.000024  loss: 0.1106 (0.1128)  time: 0.6047  data: 0.0001  max mem: 15821
[15:03:29.673339] Epoch: [41]  [140/345]  eta: 0:02:04  lr: 0.000024  loss: 0.1080 (0.1127)  time: 0.6051  data: 0.0001  max mem: 15821
[15:03:41.782896] Epoch: [41]  [160/345]  eta: 0:01:52  lr: 0.000023  loss: 0.1093 (0.1122)  time: 0.6054  data: 0.0001  max mem: 15821
[15:03:53.893492] Epoch: [41]  [180/345]  eta: 0:01:39  lr: 0.000023  loss: 0.1040 (0.1118)  time: 0.6055  data: 0.0001  max mem: 15821
[15:04:06.002172] Epoch: [41]  [200/345]  eta: 0:01:27  lr: 0.000023  loss: 0.1014 (0.1119)  time: 0.6054  data: 0.0001  max mem: 15821
[15:04:18.105890] Epoch: [41]  [220/345]  eta: 0:01:15  lr: 0.000022  loss: 0.1132 (0.1122)  time: 0.6051  data: 0.0001  max mem: 15821
[15:04:30.213795] Epoch: [41]  [240/345]  eta: 0:01:03  lr: 0.000022  loss: 0.1102 (0.1126)  time: 0.6054  data: 0.0001  max mem: 15821
[15:04:42.321249] Epoch: [41]  [260/345]  eta: 0:00:51  lr: 0.000022  loss: 0.1075 (0.1125)  time: 0.6053  data: 0.0001  max mem: 15821
[15:04:54.419861] Epoch: [41]  [280/345]  eta: 0:00:39  lr: 0.000022  loss: 0.1025 (0.1125)  time: 0.6049  data: 0.0001  max mem: 15821
[15:05:06.515489] Epoch: [41]  [300/345]  eta: 0:00:27  lr: 0.000021  loss: 0.1157 (0.1127)  time: 0.6047  data: 0.0001  max mem: 15821
[15:05:18.602164] Epoch: [41]  [320/345]  eta: 0:00:15  lr: 0.000021  loss: 0.1017 (0.1123)  time: 0.6043  data: 0.0001  max mem: 15821
[15:05:30.686630] Epoch: [41]  [340/345]  eta: 0:00:03  lr: 0.000021  loss: 0.1088 (0.1123)  time: 0.6042  data: 0.0001  max mem: 15821
[15:05:33.101487] Epoch: [41]  [344/345]  eta: 0:00:00  lr: 0.000021  loss: 0.1088 (0.1125)  time: 0.6040  data: 0.0001  max mem: 15821
[15:05:33.168746] Epoch: [41] Total time: 0:03:28 (0.6054 s / it)
[15:05:33.169435] Averaged stats: lr: 0.000021  loss: 0.1088 (0.1125)
[15:05:33.702499] Test:  [  0/345]  eta: 0:03:02  loss: 0.1142 (0.1142)  time: 0.5277  data: 0.3638  max mem: 15821
[15:05:35.371340] Test:  [ 10/345]  eta: 0:01:06  loss: 0.1044 (0.1064)  time: 0.1996  data: 0.0332  max mem: 15821
[15:05:37.043708] Test:  [ 20/345]  eta: 0:00:59  loss: 0.0990 (0.1027)  time: 0.1670  data: 0.0001  max mem: 15821
[15:05:38.719352] Test:  [ 30/345]  eta: 0:00:56  loss: 0.0992 (0.1033)  time: 0.1673  data: 0.0001  max mem: 15821
[15:05:40.396633] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1059 (0.1076)  time: 0.1676  data: 0.0001  max mem: 15821
[15:05:42.077928] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1092 (0.1060)  time: 0.1679  data: 0.0001  max mem: 15821
[15:05:43.762943] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1010 (0.1056)  time: 0.1683  data: 0.0001  max mem: 15821
[15:05:45.450935] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1008 (0.1056)  time: 0.1686  data: 0.0001  max mem: 15821
[15:05:47.142851] Test:  [ 80/345]  eta: 0:00:45  loss: 0.0979 (0.1052)  time: 0.1689  data: 0.0001  max mem: 15821
[15:05:48.838728] Test:  [ 90/345]  eta: 0:00:43  loss: 0.0997 (0.1063)  time: 0.1693  data: 0.0001  max mem: 15821
[15:05:50.537873] Test:  [100/345]  eta: 0:00:42  loss: 0.1013 (0.1058)  time: 0.1697  data: 0.0001  max mem: 15821
[15:05:52.239756] Test:  [110/345]  eta: 0:00:40  loss: 0.0985 (0.1055)  time: 0.1700  data: 0.0001  max mem: 15821
[15:05:53.945093] Test:  [120/345]  eta: 0:00:38  loss: 0.0985 (0.1053)  time: 0.1703  data: 0.0001  max mem: 15821
[15:05:55.653743] Test:  [130/345]  eta: 0:00:36  loss: 0.0992 (0.1056)  time: 0.1706  data: 0.0001  max mem: 15821
[15:05:57.365405] Test:  [140/345]  eta: 0:00:35  loss: 0.1025 (0.1051)  time: 0.1710  data: 0.0001  max mem: 15821
[15:05:59.079993] Test:  [150/345]  eta: 0:00:33  loss: 0.1025 (0.1054)  time: 0.1712  data: 0.0001  max mem: 15821
[15:06:00.799374] Test:  [160/345]  eta: 0:00:31  loss: 0.1046 (0.1056)  time: 0.1716  data: 0.0001  max mem: 15821
[15:06:02.523199] Test:  [170/345]  eta: 0:00:30  loss: 0.1028 (0.1056)  time: 0.1721  data: 0.0001  max mem: 15821
[15:06:04.250060] Test:  [180/345]  eta: 0:00:28  loss: 0.1027 (0.1055)  time: 0.1725  data: 0.0001  max mem: 15821
[15:06:05.980991] Test:  [190/345]  eta: 0:00:26  loss: 0.1027 (0.1056)  time: 0.1728  data: 0.0001  max mem: 15821
[15:06:07.712545] Test:  [200/345]  eta: 0:00:24  loss: 0.1035 (0.1054)  time: 0.1731  data: 0.0001  max mem: 15821
[15:06:09.449728] Test:  [210/345]  eta: 0:00:23  loss: 0.1042 (0.1060)  time: 0.1734  data: 0.0001  max mem: 15821
[15:06:11.189714] Test:  [220/345]  eta: 0:00:21  loss: 0.1048 (0.1057)  time: 0.1738  data: 0.0001  max mem: 15821
[15:06:12.933479] Test:  [230/345]  eta: 0:00:19  loss: 0.0985 (0.1055)  time: 0.1741  data: 0.0001  max mem: 15821
[15:06:14.679916] Test:  [240/345]  eta: 0:00:18  loss: 0.1007 (0.1056)  time: 0.1744  data: 0.0001  max mem: 15821
[15:06:16.430507] Test:  [250/345]  eta: 0:00:16  loss: 0.1080 (0.1058)  time: 0.1748  data: 0.0001  max mem: 15821
[15:06:18.186137] Test:  [260/345]  eta: 0:00:14  loss: 0.1019 (0.1059)  time: 0.1753  data: 0.0001  max mem: 15821
[15:06:19.943289] Test:  [270/345]  eta: 0:00:12  loss: 0.0976 (0.1058)  time: 0.1756  data: 0.0001  max mem: 15821
[15:06:21.704100] Test:  [280/345]  eta: 0:00:11  loss: 0.1000 (0.1058)  time: 0.1758  data: 0.0001  max mem: 15821
[15:06:23.468362] Test:  [290/345]  eta: 0:00:09  loss: 0.1000 (0.1058)  time: 0.1762  data: 0.0001  max mem: 15821
[15:06:25.236235] Test:  [300/345]  eta: 0:00:07  loss: 0.1012 (0.1056)  time: 0.1765  data: 0.0001  max mem: 15821
[15:06:27.007195] Test:  [310/345]  eta: 0:00:06  loss: 0.1050 (0.1058)  time: 0.1769  data: 0.0001  max mem: 15821
[15:06:28.783396] Test:  [320/345]  eta: 0:00:04  loss: 0.1030 (0.1056)  time: 0.1773  data: 0.0001  max mem: 15821
[15:06:30.561966] Test:  [330/345]  eta: 0:00:02  loss: 0.1029 (0.1059)  time: 0.1777  data: 0.0001  max mem: 15821
[15:06:32.344673] Test:  [340/345]  eta: 0:00:00  loss: 0.1089 (0.1059)  time: 0.1780  data: 0.0001  max mem: 15821
[15:06:33.060268] Test:  [344/345]  eta: 0:00:00  loss: 0.1071 (0.1061)  time: 0.1782  data: 0.0001  max mem: 15821
[15:06:33.132953] Test: Total time: 0:00:59 (0.1738 s / it)
[15:06:43.153958] Test:  [ 0/57]  eta: 0:00:28  loss: 0.4709 (0.4709)  time: 0.4984  data: 0.3360  max mem: 15821
[15:06:44.806804] Test:  [10/57]  eta: 0:00:09  loss: 0.4074 (0.4316)  time: 0.1955  data: 0.0306  max mem: 15821
[15:06:46.463232] Test:  [20/57]  eta: 0:00:06  loss: 0.4161 (0.4234)  time: 0.1654  data: 0.0001  max mem: 15821
[15:06:48.123927] Test:  [30/57]  eta: 0:00:04  loss: 0.2487 (0.3611)  time: 0.1658  data: 0.0001  max mem: 15821
[15:06:49.788450] Test:  [40/57]  eta: 0:00:02  loss: 0.2373 (0.3373)  time: 0.1662  data: 0.0001  max mem: 15821
[15:06:51.457046] Test:  [50/57]  eta: 0:00:01  loss: 0.2658 (0.3364)  time: 0.1666  data: 0.0001  max mem: 15821
[15:06:52.358196] Test:  [56/57]  eta: 0:00:00  loss: 0.2874 (0.3437)  time: 0.1617  data: 0.0000  max mem: 15821
[15:06:52.422544] Test: Total time: 0:00:09 (0.1714 s / it)
[15:06:54.099282] Dice score of the network on the train images: 0.889314, val images: 0.809292
[15:06:54.103533] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:06:55.063093] Epoch: [42]  [  0/345]  eta: 0:05:30  lr: 0.000021  loss: 0.1054 (0.1054)  time: 0.9584  data: 0.3579  max mem: 15821
[15:07:07.072722] Epoch: [42]  [ 20/345]  eta: 0:03:20  lr: 0.000020  loss: 0.1038 (0.1091)  time: 0.6004  data: 0.0001  max mem: 15821
[15:07:19.103508] Epoch: [42]  [ 40/345]  eta: 0:03:05  lr: 0.000020  loss: 0.1050 (0.1066)  time: 0.6015  data: 0.0001  max mem: 15821
[15:07:31.142109] Epoch: [42]  [ 60/345]  eta: 0:02:53  lr: 0.000020  loss: 0.1049 (0.1072)  time: 0.6019  data: 0.0001  max mem: 15821

[15:07:43.196806] Epoch: [42]  [ 80/345]  eta: 0:02:40  lr: 0.000020  loss: 0.1096 (0.1086)  time: 0.6027  data: 0.0001  max mem: 15821
[15:07:55.251992] Epoch: [42]  [100/345]  eta: 0:02:28  lr: 0.000019  loss: 0.1069 (0.1088)  time: 0.6027  data: 0.0001  max mem: 15821
[15:08:07.321620] Epoch: [42]  [120/345]  eta: 0:02:16  lr: 0.000019  loss: 0.1140 (0.1101)  time: 0.6034  data: 0.0001  max mem: 15821
[15:08:19.403522] Epoch: [42]  [140/345]  eta: 0:02:04  lr: 0.000019  loss: 0.1067 (0.1097)  time: 0.6041  data: 0.0001  max mem: 15821
[15:08:31.507040] Epoch: [42]  [160/345]  eta: 0:01:51  lr: 0.000018  loss: 0.1050 (0.1096)  time: 0.6051  data: 0.0001  max mem: 15821
[15:08:43.619373] Epoch: [42]  [180/345]  eta: 0:01:39  lr: 0.000018  loss: 0.1127 (0.1100)  time: 0.6056  data: 0.0001  max mem: 15821
[15:08:55.703161] Epoch: [42]  [200/345]  eta: 0:01:27  lr: 0.000018  loss: 0.1041 (0.1097)  time: 0.6041  data: 0.0001  max mem: 15821
[15:09:07.790744] Epoch: [42]  [220/345]  eta: 0:01:15  lr: 0.000018  loss: 0.1106 (0.1100)  time: 0.6043  data: 0.0001  max mem: 15821
[15:09:19.897638] Epoch: [42]  [240/345]  eta: 0:01:03  lr: 0.000017  loss: 0.1075 (0.1101)  time: 0.6053  data: 0.0001  max mem: 15821
[15:09:31.997371] Epoch: [42]  [260/345]  eta: 0:00:51  lr: 0.000017  loss: 0.1194 (0.1107)  time: 0.6049  data: 0.0001  max mem: 15821
[15:09:44.094650] Epoch: [42]  [280/345]  eta: 0:00:39  lr: 0.000017  loss: 0.1112 (0.1107)  time: 0.6048  data: 0.0001  max mem: 15821
[15:09:56.185194] Epoch: [42]  [300/345]  eta: 0:00:27  lr: 0.000017  loss: 0.1056 (0.1105)  time: 0.6045  data: 0.0001  max mem: 15821
[15:10:08.271523] Epoch: [42]  [320/345]  eta: 0:00:15  lr: 0.000016  loss: 0.1065 (0.1105)  time: 0.6043  data: 0.0001  max mem: 15821
[15:10:20.346692] Epoch: [42]  [340/345]  eta: 0:00:03  lr: 0.000016  loss: 0.1058 (0.1106)  time: 0.6037  data: 0.0001  max mem: 15821
[15:10:22.762742] Epoch: [42]  [344/345]  eta: 0:00:00  lr: 0.000016  loss: 0.1054 (0.1109)  time: 0.6037  data: 0.0001  max mem: 15821
[15:10:22.842738] Epoch: [42] Total time: 0:03:28 (0.6050 s / it)
[15:10:22.842973] Averaged stats: lr: 0.000016  loss: 0.1054 (0.1109)
[15:10:23.384134] Test:  [  0/345]  eta: 0:03:04  loss: 0.1358 (0.1358)  time: 0.5355  data: 0.3717  max mem: 15821
[15:10:25.052603] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1062 (0.1062)  time: 0.2003  data: 0.0339  max mem: 15821
[15:10:26.723458] Test:  [ 20/345]  eta: 0:00:59  loss: 0.1046 (0.1048)  time: 0.1669  data: 0.0001  max mem: 15821
[15:10:28.397967] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1040 (0.1058)  time: 0.1672  data: 0.0001  max mem: 15821
[15:10:30.075467] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1021 (0.1059)  time: 0.1675  data: 0.0001  max mem: 15821
[15:10:31.755330] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1040 (0.1055)  time: 0.1678  data: 0.0001  max mem: 15821
[15:10:33.439705] Test:  [ 60/345]  eta: 0:00:49  loss: 0.0979 (0.1042)  time: 0.1681  data: 0.0001  max mem: 15821
[15:10:35.129152] Test:  [ 70/345]  eta: 0:00:47  loss: 0.0958 (0.1032)  time: 0.1686  data: 0.0001  max mem: 15821
[15:10:36.819080] Test:  [ 80/345]  eta: 0:00:45  loss: 0.0980 (0.1036)  time: 0.1689  data: 0.0001  max mem: 15821
[15:10:38.513779] Test:  [ 90/345]  eta: 0:00:43  loss: 0.0982 (0.1032)  time: 0.1692  data: 0.0001  max mem: 15821
[15:10:40.212235] Test:  [100/345]  eta: 0:00:42  loss: 0.1032 (0.1039)  time: 0.1696  data: 0.0001  max mem: 15821
[15:10:41.913179] Test:  [110/345]  eta: 0:00:40  loss: 0.1008 (0.1034)  time: 0.1699  data: 0.0001  max mem: 15821
[15:10:43.617268] Test:  [120/345]  eta: 0:00:38  loss: 0.0992 (0.1032)  time: 0.1702  data: 0.0001  max mem: 15821
[15:10:45.325724] Test:  [130/345]  eta: 0:00:36  loss: 0.1010 (0.1030)  time: 0.1706  data: 0.0001  max mem: 15821
[15:10:47.036532] Test:  [140/345]  eta: 0:00:35  loss: 0.0984 (0.1029)  time: 0.1709  data: 0.0001  max mem: 15821
[15:10:48.751415] Test:  [150/345]  eta: 0:00:33  loss: 0.0984 (0.1029)  time: 0.1712  data: 0.0001  max mem: 15821
[15:10:50.470278] Test:  [160/345]  eta: 0:00:31  loss: 0.1010 (0.1028)  time: 0.1716  data: 0.0001  max mem: 15821
[15:10:52.192637] Test:  [170/345]  eta: 0:00:30  loss: 0.1010 (0.1030)  time: 0.1720  data: 0.0001  max mem: 15821
[15:10:53.917490] Test:  [180/345]  eta: 0:00:28  loss: 0.0997 (0.1031)  time: 0.1723  data: 0.0001  max mem: 15821
[15:10:55.647517] Test:  [190/345]  eta: 0:00:26  loss: 0.0997 (0.1033)  time: 0.1727  data: 0.0001  max mem: 15821
[15:10:57.379361] Test:  [200/345]  eta: 0:00:24  loss: 0.0997 (0.1035)  time: 0.1730  data: 0.0001  max mem: 15821
[15:10:59.115896] Test:  [210/345]  eta: 0:00:23  loss: 0.0972 (0.1033)  time: 0.1734  data: 0.0001  max mem: 15821
[15:11:00.854661] Test:  [220/345]  eta: 0:00:21  loss: 0.0966 (0.1029)  time: 0.1737  data: 0.0001  max mem: 15821
[15:11:02.596947] Test:  [230/345]  eta: 0:00:19  loss: 0.1012 (0.1033)  time: 0.1740  data: 0.0001  max mem: 15821
[15:11:04.343628] Test:  [240/345]  eta: 0:00:18  loss: 0.1074 (0.1033)  time: 0.1744  data: 0.0001  max mem: 15821
[15:11:06.093516] Test:  [250/345]  eta: 0:00:16  loss: 0.1015 (0.1033)  time: 0.1748  data: 0.0001  max mem: 15821
[15:11:07.846830] Test:  [260/345]  eta: 0:00:14  loss: 0.1015 (0.1033)  time: 0.1751  data: 0.0001  max mem: 15821
[15:11:09.603778] Test:  [270/345]  eta: 0:00:12  loss: 0.1050 (0.1035)  time: 0.1755  data: 0.0001  max mem: 15821
[15:11:11.363113] Test:  [280/345]  eta: 0:00:11  loss: 0.1081 (0.1037)  time: 0.1758  data: 0.0001  max mem: 15821
[15:11:13.126602] Test:  [290/345]  eta: 0:00:09  loss: 0.1057 (0.1039)  time: 0.1761  data: 0.0001  max mem: 15821
[15:11:14.893572] Test:  [300/345]  eta: 0:00:07  loss: 0.1059 (0.1042)  time: 0.1765  data: 0.0001  max mem: 15821
[15:11:16.666250] Test:  [310/345]  eta: 0:00:06  loss: 0.0989 (0.1040)  time: 0.1769  data: 0.0001  max mem: 15821
[15:11:18.440685] Test:  [320/345]  eta: 0:00:04  loss: 0.1009 (0.1043)  time: 0.1773  data: 0.0001  max mem: 15821
[15:11:20.219370] Test:  [330/345]  eta: 0:00:02  loss: 0.0990 (0.1041)  time: 0.1776  data: 0.0001  max mem: 15821
[15:11:22.000734] Test:  [340/345]  eta: 0:00:00  loss: 0.0990 (0.1041)  time: 0.1779  data: 0.0001  max mem: 15821
[15:11:22.713312] Test:  [344/345]  eta: 0:00:00  loss: 0.0990 (0.1041)  time: 0.1781  data: 0.0001  max mem: 15821
[15:11:22.784366] Test: Total time: 0:00:59 (0.1737 s / it)
[15:11:32.738339] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4751 (0.4751)  time: 0.4660  data: 0.3036  max mem: 15821
[15:11:34.390801] Test:  [10/57]  eta: 0:00:09  loss: 0.3966 (0.4335)  time: 0.1925  data: 0.0277  max mem: 15821
[15:11:36.047121] Test:  [20/57]  eta: 0:00:06  loss: 0.4155 (0.4250)  time: 0.1654  data: 0.0001  max mem: 15821
[15:11:37.706668] Test:  [30/57]  eta: 0:00:04  loss: 0.2535 (0.3634)  time: 0.1657  data: 0.0001  max mem: 15821
[15:11:39.369084] Test:  [40/57]  eta: 0:00:02  loss: 0.2407 (0.3400)  time: 0.1660  data: 0.0001  max mem: 15821
[15:11:41.036706] Test:  [50/57]  eta: 0:00:01  loss: 0.2710 (0.3393)  time: 0.1664  data: 0.0001  max mem: 15821
[15:11:41.937230] Test:  [56/57]  eta: 0:00:00  loss: 0.3012 (0.3473)  time: 0.1616  data: 0.0000  max mem: 15821
[15:11:42.008292] Test: Total time: 0:00:09 (0.1708 s / it)
[15:11:43.716718] Dice score of the network on the train images: 0.892957, val images: 0.806095
[15:11:43.720726] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:11:44.676065] Epoch: [43]  [  0/345]  eta: 0:05:29  lr: 0.000016  loss: 0.1469 (0.1469)  time: 0.9542  data: 0.3542  max mem: 15821
[15:11:56.667349] Epoch: [43]  [ 20/345]  eta: 0:03:20  lr: 0.000016  loss: 0.1102 (0.1130)  time: 0.5995  data: 0.0001  max mem: 15821
[15:12:08.682396] Epoch: [43]  [ 40/345]  eta: 0:03:05  lr: 0.000016  loss: 0.1049 (0.1118)  time: 0.6007  data: 0.0001  max mem: 15821
[15:12:20.721257] Epoch: [43]  [ 60/345]  eta: 0:02:52  lr: 0.000015  loss: 0.1020 (0.1110)  time: 0.6019  data: 0.0001  max mem: 15821
[15:12:32.769681] Epoch: [43]  [ 80/345]  eta: 0:02:40  lr: 0.000015  loss: 0.1050 (0.1105)  time: 0.6024  data: 0.0001  max mem: 15821
[15:12:44.822376] Epoch: [43]  [100/345]  eta: 0:02:28  lr: 0.000015  loss: 0.1049 (0.1099)  time: 0.6026  data: 0.0001  max mem: 15821
[15:12:56.891019] Epoch: [43]  [120/345]  eta: 0:02:16  lr: 0.000015  loss: 0.0967 (0.1090)  time: 0.6034  data: 0.0001  max mem: 15821
[15:13:08.982892] Epoch: [43]  [140/345]  eta: 0:02:03  lr: 0.000014  loss: 0.0989 (0.1088)  time: 0.6046  data: 0.0001  max mem: 15821
[15:13:21.066756] Epoch: [43]  [160/345]  eta: 0:01:51  lr: 0.000014  loss: 0.1046 (0.1086)  time: 0.6042  data: 0.0001  max mem: 15821
[15:13:33.161811] Epoch: [43]  [180/345]  eta: 0:01:39  lr: 0.000014  loss: 0.1037 (0.1084)  time: 0.6047  data: 0.0001  max mem: 15821
[15:13:45.251479] Epoch: [43]  [200/345]  eta: 0:01:27  lr: 0.000014  loss: 0.1156 (0.1091)  time: 0.6044  data: 0.0001  max mem: 15821
[15:13:57.342986] Epoch: [43]  [220/345]  eta: 0:01:15  lr: 0.000013  loss: 0.1058 (0.1091)  time: 0.6045  data: 0.0001  max mem: 15821
[15:14:09.442873] Epoch: [43]  [240/345]  eta: 0:01:03  lr: 0.000013  loss: 0.1066 (0.1089)  time: 0.6049  data: 0.0001  max mem: 15821
[15:14:21.541236] Epoch: [43]  [260/345]  eta: 0:00:51  lr: 0.000013  loss: 0.1157 (0.1094)  time: 0.6049  data: 0.0001  max mem: 15821
[15:14:33.639187] Epoch: [43]  [280/345]  eta: 0:00:39  lr: 0.000013  loss: 0.1035 (0.1091)  time: 0.6049  data: 0.0001  max mem: 15821
[15:14:45.734984] Epoch: [43]  [300/345]  eta: 0:00:27  lr: 0.000012  loss: 0.1022 (0.1091)  time: 0.6047  data: 0.0001  max mem: 15821
[15:14:57.837838] Epoch: [43]  [320/345]  eta: 0:00:15  lr: 0.000012  loss: 0.1098 (0.1093)  time: 0.6051  data: 0.0001  max mem: 15821
[15:15:09.933973] Epoch: [43]  [340/345]  eta: 0:00:03  lr: 0.000012  loss: 0.1034 (0.1090)  time: 0.6048  data: 0.0001  max mem: 15821
[15:15:12.350104] Epoch: [43]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 0.1034 (0.1089)  time: 0.6045  data: 0.0001  max mem: 15821
[15:15:12.418996] Epoch: [43] Total time: 0:03:28 (0.6049 s / it)
[15:15:12.419308] Averaged stats: lr: 0.000012  loss: 0.1034 (0.1089)
[15:15:12.979478] Test:  [  0/345]  eta: 0:03:11  loss: 0.0912 (0.0912)  time: 0.5550  data: 0.3906  max mem: 15821
[15:15:14.646568] Test:  [ 10/345]  eta: 0:01:07  loss: 0.0962 (0.0969)  time: 0.2019  data: 0.0356  max mem: 15821
[15:15:16.319005] Test:  [ 20/345]  eta: 0:01:00  loss: 0.0995 (0.1031)  time: 0.1669  data: 0.0001  max mem: 15821
[15:15:17.994315] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1022 (0.1017)  time: 0.1673  data: 0.0001  max mem: 15821
[15:15:19.672673] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1022 (0.1032)  time: 0.1676  data: 0.0001  max mem: 15821
[15:15:21.353787] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1002 (0.1026)  time: 0.1679  data: 0.0001  max mem: 15821
[15:15:23.037372] Test:  [ 60/345]  eta: 0:00:49  loss: 0.0956 (0.1027)  time: 0.1682  data: 0.0001  max mem: 15821
[15:15:24.724430] Test:  [ 70/345]  eta: 0:00:47  loss: 0.0985 (0.1028)  time: 0.1685  data: 0.0001  max mem: 15821
[15:15:26.415944] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1023 (0.1027)  time: 0.1689  data: 0.0001  max mem: 15821
[15:15:28.112211] Test:  [ 90/345]  eta: 0:00:43  loss: 0.0974 (0.1017)  time: 0.1693  data: 0.0001  max mem: 15821
[15:15:29.809803] Test:  [100/345]  eta: 0:00:42  loss: 0.0974 (0.1021)  time: 0.1696  data: 0.0001  max mem: 15821
[15:15:31.512077] Test:  [110/345]  eta: 0:00:40  loss: 0.0990 (0.1019)  time: 0.1699  data: 0.0001  max mem: 15821
[15:15:33.216812] Test:  [120/345]  eta: 0:00:38  loss: 0.0983 (0.1020)  time: 0.1703  data: 0.0001  max mem: 15821
[15:15:34.924082] Test:  [130/345]  eta: 0:00:36  loss: 0.0966 (0.1021)  time: 0.1705  data: 0.0001  max mem: 15821
[15:15:36.635783] Test:  [140/345]  eta: 0:00:35  loss: 0.0978 (0.1022)  time: 0.1709  data: 0.0001  max mem: 15821
[15:15:38.350550] Test:  [150/345]  eta: 0:00:33  loss: 0.1018 (0.1022)  time: 0.1713  data: 0.0001  max mem: 15821
[15:15:40.070426] Test:  [160/345]  eta: 0:00:31  loss: 0.0988 (0.1019)  time: 0.1717  data: 0.0001  max mem: 15821
[15:15:41.793275] Test:  [170/345]  eta: 0:00:30  loss: 0.0942 (0.1016)  time: 0.1721  data: 0.0001  max mem: 15821
[15:15:43.518427] Test:  [180/345]  eta: 0:00:28  loss: 0.0978 (0.1015)  time: 0.1723  data: 0.0001  max mem: 15821
[15:15:45.248942] Test:  [190/345]  eta: 0:00:26  loss: 0.0981 (0.1015)  time: 0.1727  data: 0.0001  max mem: 15821
[15:15:46.980450] Test:  [200/345]  eta: 0:00:24  loss: 0.1006 (0.1020)  time: 0.1730  data: 0.0001  max mem: 15821
[15:15:48.716085] Test:  [210/345]  eta: 0:00:23  loss: 0.0982 (0.1021)  time: 0.1733  data: 0.0001  max mem: 15821
[15:15:50.457149] Test:  [220/345]  eta: 0:00:21  loss: 0.0968 (0.1019)  time: 0.1738  data: 0.0001  max mem: 15821
[15:15:52.201157] Test:  [230/345]  eta: 0:00:19  loss: 0.0969 (0.1019)  time: 0.1742  data: 0.0001  max mem: 15821
[15:15:53.949336] Test:  [240/345]  eta: 0:00:18  loss: 0.0959 (0.1017)  time: 0.1745  data: 0.0001  max mem: 15821
[15:15:55.698686] Test:  [250/345]  eta: 0:00:16  loss: 0.0929 (0.1017)  time: 0.1748  data: 0.0001  max mem: 15821
[15:15:57.453683] Test:  [260/345]  eta: 0:00:14  loss: 0.0980 (0.1017)  time: 0.1752  data: 0.0001  max mem: 15821
[15:15:59.211333] Test:  [270/345]  eta: 0:00:12  loss: 0.0910 (0.1014)  time: 0.1756  data: 0.0001  max mem: 15821
[15:16:00.972119] Test:  [280/345]  eta: 0:00:11  loss: 0.0969 (0.1017)  time: 0.1759  data: 0.0001  max mem: 15821
[15:16:02.735656] Test:  [290/345]  eta: 0:00:09  loss: 0.1061 (0.1019)  time: 0.1762  data: 0.0001  max mem: 15821
[15:16:04.504032] Test:  [300/345]  eta: 0:00:07  loss: 0.1070 (0.1020)  time: 0.1765  data: 0.0001  max mem: 15821
[15:16:06.275946] Test:  [310/345]  eta: 0:00:06  loss: 0.1070 (0.1022)  time: 0.1769  data: 0.0001  max mem: 15821
[15:16:08.050745] Test:  [320/345]  eta: 0:00:04  loss: 0.1054 (0.1023)  time: 0.1773  data: 0.0001  max mem: 15821
[15:16:09.829592] Test:  [330/345]  eta: 0:00:02  loss: 0.1002 (0.1021)  time: 0.1776  data: 0.0001  max mem: 15821
[15:16:11.611525] Test:  [340/345]  eta: 0:00:00  loss: 0.0992 (0.1022)  time: 0.1780  data: 0.0001  max mem: 15821
[15:16:12.325395] Test:  [344/345]  eta: 0:00:00  loss: 0.1002 (0.1023)  time: 0.1782  data: 0.0001  max mem: 15821
[15:16:12.397227] Test: Total time: 0:00:59 (0.1738 s / it)
[15:16:22.389981] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4717 (0.4717)  time: 0.5098  data: 0.3470  max mem: 15821
[15:16:24.041306] Test:  [10/57]  eta: 0:00:09  loss: 0.3989 (0.4341)  time: 0.1964  data: 0.0316  max mem: 15821
[15:16:25.695660] Test:  [20/57]  eta: 0:00:06  loss: 0.4195 (0.4263)  time: 0.1652  data: 0.0001  max mem: 15821
[15:16:27.354544] Test:  [30/57]  eta: 0:00:04  loss: 0.2526 (0.3636)  time: 0.1656  data: 0.0001  max mem: 15821
[15:16:29.018139] Test:  [40/57]  eta: 0:00:02  loss: 0.2374 (0.3394)  time: 0.1661  data: 0.0001  max mem: 15821
[15:16:30.685499] Test:  [50/57]  eta: 0:00:01  loss: 0.2725 (0.3383)  time: 0.1665  data: 0.0001  max mem: 15821
[15:16:31.586010] Test:  [56/57]  eta: 0:00:00  loss: 0.2924 (0.3456)  time: 0.1616  data: 0.0000  max mem: 15821
[15:16:31.655723] Test: Total time: 0:00:09 (0.1715 s / it)
[15:16:33.352089] Dice score of the network on the train images: 0.893410, val images: 0.807840
[15:16:33.356331] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:16:34.268602] Epoch: [44]  [  0/345]  eta: 0:05:14  lr: 0.000012  loss: 0.0870 (0.0870)  time: 0.9111  data: 0.3101  max mem: 15821
[15:16:46.273731] Epoch: [44]  [ 20/345]  eta: 0:03:19  lr: 0.000012  loss: 0.1042 (0.1062)  time: 0.6002  data: 0.0001  max mem: 15821
[15:16:58.317298] Epoch: [44]  [ 40/345]  eta: 0:03:05  lr: 0.000011  loss: 0.1023 (0.1069)  time: 0.6021  data: 0.0001  max mem: 15821
[15:17:10.373479] Epoch: [44]  [ 60/345]  eta: 0:02:52  lr: 0.000011  loss: 0.0968 (0.1055)  time: 0.6028  data: 0.0001  max mem: 15821
[15:17:22.422654] Epoch: [44]  [ 80/345]  eta: 0:02:40  lr: 0.000011  loss: 0.1035 (0.1062)  time: 0.6024  data: 0.0001  max mem: 15821
[15:17:34.487745] Epoch: [44]  [100/345]  eta: 0:02:28  lr: 0.000011  loss: 0.1039 (0.1061)  time: 0.6032  data: 0.0001  max mem: 15821
[15:17:46.578075] Epoch: [44]  [120/345]  eta: 0:02:16  lr: 0.000011  loss: 0.1013 (0.1062)  time: 0.6045  data: 0.0001  max mem: 15821
[15:17:58.675320] Epoch: [44]  [140/345]  eta: 0:02:04  lr: 0.000010  loss: 0.1023 (0.1064)  time: 0.6048  data: 0.0001  max mem: 15821
[15:18:10.779594] Epoch: [44]  [160/345]  eta: 0:01:51  lr: 0.000010  loss: 0.1091 (0.1067)  time: 0.6052  data: 0.0001  max mem: 15821
[15:18:22.883974] Epoch: [44]  [180/345]  eta: 0:01:39  lr: 0.000010  loss: 0.1031 (0.1069)  time: 0.6052  data: 0.0001  max mem: 15821
[15:18:34.993146] Epoch: [44]  [200/345]  eta: 0:01:27  lr: 0.000010  loss: 0.1018 (0.1071)  time: 0.6054  data: 0.0001  max mem: 15821
[15:18:47.098400] Epoch: [44]  [220/345]  eta: 0:01:15  lr: 0.000010  loss: 0.1040 (0.1069)  time: 0.6052  data: 0.0001  max mem: 15821
[15:18:59.210055] Epoch: [44]  [240/345]  eta: 0:01:03  lr: 0.000009  loss: 0.1031 (0.1072)  time: 0.6055  data: 0.0001  max mem: 15821
[15:19:11.318738] Epoch: [44]  [260/345]  eta: 0:00:51  lr: 0.000009  loss: 0.1096 (0.1073)  time: 0.6054  data: 0.0001  max mem: 15821
[15:19:23.407996] Epoch: [44]  [280/345]  eta: 0:00:39  lr: 0.000009  loss: 0.0981 (0.1070)  time: 0.6044  data: 0.0001  max mem: 15821
[15:19:35.489709] Epoch: [44]  [300/345]  eta: 0:00:27  lr: 0.000009  loss: 0.1045 (0.1072)  time: 0.6040  data: 0.0001  max mem: 15821
[15:19:47.566820] Epoch: [44]  [320/345]  eta: 0:00:15  lr: 0.000009  loss: 0.1062 (0.1074)  time: 0.6038  data: 0.0001  max mem: 15821
[15:19:59.634823] Epoch: [44]  [340/345]  eta: 0:00:03  lr: 0.000008  loss: 0.1046 (0.1073)  time: 0.6034  data: 0.0001  max mem: 15821
[15:20:02.048728] Epoch: [44]  [344/345]  eta: 0:00:00  lr: 0.000008  loss: 0.1069 (0.1074)  time: 0.6035  data: 0.0001  max mem: 15821
[15:20:02.124300] Epoch: [44] Total time: 0:03:28 (0.6051 s / it)
[15:20:02.124762] Averaged stats: lr: 0.000008  loss: 0.1069 (0.1074)
[15:20:02.611142] Test:  [  0/345]  eta: 0:02:46  loss: 0.1165 (0.1165)  time: 0.4815  data: 0.3166  max mem: 15821
[15:20:04.280363] Test:  [ 10/345]  eta: 0:01:05  loss: 0.0983 (0.1042)  time: 0.1954  data: 0.0289  max mem: 15821
[15:20:05.951605] Test:  [ 20/345]  eta: 0:00:59  loss: 0.0968 (0.1001)  time: 0.1669  data: 0.0001  max mem: 15821
[15:20:07.626208] Test:  [ 30/345]  eta: 0:00:55  loss: 0.0981 (0.1016)  time: 0.1672  data: 0.0001  max mem: 15821
[15:20:09.303982] Test:  [ 40/345]  eta: 0:00:53  loss: 0.0974 (0.1007)  time: 0.1676  data: 0.0001  max mem: 15821
[15:20:10.985192] Test:  [ 50/345]  eta: 0:00:51  loss: 0.0995 (0.1012)  time: 0.1679  data: 0.0001  max mem: 15821
[15:20:12.668925] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1056 (0.1027)  time: 0.1682  data: 0.0001  max mem: 15821
[15:20:14.356923] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1030 (0.1032)  time: 0.1685  data: 0.0001  max mem: 15821
[15:20:16.048717] Test:  [ 80/345]  eta: 0:00:45  loss: 0.0983 (0.1025)  time: 0.1689  data: 0.0001  max mem: 15821
[15:20:17.743741] Test:  [ 90/345]  eta: 0:00:43  loss: 0.0955 (0.1018)  time: 0.1693  data: 0.0001  max mem: 15821
[15:20:19.442126] Test:  [100/345]  eta: 0:00:41  loss: 0.0955 (0.1017)  time: 0.1696  data: 0.0001  max mem: 15821
[15:20:21.144855] Test:  [110/345]  eta: 0:00:40  loss: 0.0972 (0.1016)  time: 0.1700  data: 0.0001  max mem: 15821
[15:20:22.850282] Test:  [120/345]  eta: 0:00:38  loss: 0.0868 (0.1002)  time: 0.1703  data: 0.0001  max mem: 15821
[15:20:24.559159] Test:  [130/345]  eta: 0:00:36  loss: 0.0886 (0.1005)  time: 0.1707  data: 0.0001  max mem: 15821
[15:20:26.269755] Test:  [140/345]  eta: 0:00:35  loss: 0.0949 (0.1006)  time: 0.1709  data: 0.0001  max mem: 15821
[15:20:27.985223] Test:  [150/345]  eta: 0:00:33  loss: 0.0943 (0.1008)  time: 0.1712  data: 0.0001  max mem: 15821
[15:20:29.704565] Test:  [160/345]  eta: 0:00:31  loss: 0.0971 (0.1005)  time: 0.1717  data: 0.0001  max mem: 15821
[15:20:31.426903] Test:  [170/345]  eta: 0:00:29  loss: 0.0971 (0.1004)  time: 0.1720  data: 0.0001  max mem: 15821
[15:20:33.151932] Test:  [180/345]  eta: 0:00:28  loss: 0.0952 (0.1006)  time: 0.1723  data: 0.0001  max mem: 15821
[15:20:34.880567] Test:  [190/345]  eta: 0:00:26  loss: 0.1003 (0.1009)  time: 0.1726  data: 0.0001  max mem: 15821
[15:20:36.613039] Test:  [200/345]  eta: 0:00:24  loss: 0.0988 (0.1007)  time: 0.1730  data: 0.0001  max mem: 15821
[15:20:38.348926] Test:  [210/345]  eta: 0:00:23  loss: 0.0921 (0.1003)  time: 0.1733  data: 0.0001  max mem: 15821
[15:20:40.087858] Test:  [220/345]  eta: 0:00:21  loss: 0.0946 (0.1004)  time: 0.1737  data: 0.0001  max mem: 15821
[15:20:41.830979] Test:  [230/345]  eta: 0:00:19  loss: 0.1029 (0.1008)  time: 0.1740  data: 0.0001  max mem: 15821
[15:20:43.577282] Test:  [240/345]  eta: 0:00:18  loss: 0.1002 (0.1006)  time: 0.1744  data: 0.0001  max mem: 15821
[15:20:45.327416] Test:  [250/345]  eta: 0:00:16  loss: 0.0964 (0.1004)  time: 0.1748  data: 0.0001  max mem: 15821
[15:20:47.080298] Test:  [260/345]  eta: 0:00:14  loss: 0.0975 (0.1004)  time: 0.1751  data: 0.0001  max mem: 15821
[15:20:48.837183] Test:  [270/345]  eta: 0:00:12  loss: 0.0992 (0.1004)  time: 0.1754  data: 0.0001  max mem: 15821
[15:20:50.598100] Test:  [280/345]  eta: 0:00:11  loss: 0.0981 (0.1005)  time: 0.1758  data: 0.0001  max mem: 15821
[15:20:52.361009] Test:  [290/345]  eta: 0:00:09  loss: 0.0985 (0.1007)  time: 0.1761  data: 0.0001  max mem: 15821
[15:20:54.128078] Test:  [300/345]  eta: 0:00:07  loss: 0.1071 (0.1011)  time: 0.1764  data: 0.0001  max mem: 15821
[15:20:55.899839] Test:  [310/345]  eta: 0:00:06  loss: 0.1022 (0.1011)  time: 0.1769  data: 0.0001  max mem: 15821
[15:20:57.674620] Test:  [320/345]  eta: 0:00:04  loss: 0.1011 (0.1014)  time: 0.1773  data: 0.0001  max mem: 15821
[15:20:59.452727] Test:  [330/345]  eta: 0:00:02  loss: 0.1024 (0.1014)  time: 0.1776  data: 0.0001  max mem: 15821
[15:21:01.234935] Test:  [340/345]  eta: 0:00:00  loss: 0.0931 (0.1011)  time: 0.1780  data: 0.0001  max mem: 15821
[15:21:01.947386] Test:  [344/345]  eta: 0:00:00  loss: 0.0920 (0.1010)  time: 0.1781  data: 0.0001  max mem: 15821
[15:21:02.015223] Test: Total time: 0:00:59 (0.1736 s / it)
[15:21:11.946693] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4770 (0.4770)  time: 0.4563  data: 0.2933  max mem: 15821
[15:21:13.599217] Test:  [10/57]  eta: 0:00:09  loss: 0.4017 (0.4363)  time: 0.1916  data: 0.0268  max mem: 15821
[15:21:15.255437] Test:  [20/57]  eta: 0:00:06  loss: 0.4248 (0.4287)  time: 0.1654  data: 0.0001  max mem: 15821
[15:21:16.915366] Test:  [30/57]  eta: 0:00:04  loss: 0.2533 (0.3666)  time: 0.1657  data: 0.0001  max mem: 15821
[15:21:18.577640] Test:  [40/57]  eta: 0:00:02  loss: 0.2388 (0.3435)  time: 0.1660  data: 0.0001  max mem: 15821
[15:21:20.245691] Test:  [50/57]  eta: 0:00:01  loss: 0.2785 (0.3431)  time: 0.1665  data: 0.0001  max mem: 15821
[15:21:21.146322] Test:  [56/57]  eta: 0:00:00  loss: 0.3071 (0.3509)  time: 0.1616  data: 0.0000  max mem: 15821
[15:21:21.218258] Test: Total time: 0:00:09 (0.1707 s / it)
[15:21:22.890334] Dice score of the network on the train images: 0.895522, val images: 0.803919
[15:21:22.894546] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:21:23.794467] Epoch: [45]  [  0/345]  eta: 0:05:10  lr: 0.000008  loss: 0.1039 (0.1039)  time: 0.8988  data: 0.2969  max mem: 15821
[15:21:35.796791] Epoch: [45]  [ 20/345]  eta: 0:03:19  lr: 0.000008  loss: 0.1011 (0.1024)  time: 0.6001  data: 0.0001  max mem: 15821
[15:21:47.841742] Epoch: [45]  [ 40/345]  eta: 0:03:05  lr: 0.000008  loss: 0.1036 (0.1047)  time: 0.6022  data: 0.0001  max mem: 15821
[15:21:59.901948] Epoch: [45]  [ 60/345]  eta: 0:02:52  lr: 0.000008  loss: 0.1081 (0.1056)  time: 0.6030  data: 0.0001  max mem: 15821
[15:22:11.981565] Epoch: [45]  [ 80/345]  eta: 0:02:40  lr: 0.000008  loss: 0.1031 (0.1058)  time: 0.6039  data: 0.0001  max mem: 15821
[15:22:24.069637] Epoch: [45]  [100/345]  eta: 0:02:28  lr: 0.000007  loss: 0.1050 (0.1061)  time: 0.6044  data: 0.0001  max mem: 15821
[15:22:36.172788] Epoch: [45]  [120/345]  eta: 0:02:16  lr: 0.000007  loss: 0.1040 (0.1064)  time: 0.6051  data: 0.0001  max mem: 15821
[15:22:48.285366] Epoch: [45]  [140/345]  eta: 0:02:04  lr: 0.000007  loss: 0.1054 (0.1066)  time: 0.6056  data: 0.0001  max mem: 15821
[15:23:00.403598] Epoch: [45]  [160/345]  eta: 0:01:52  lr: 0.000007  loss: 0.1046 (0.1068)  time: 0.6059  data: 0.0001  max mem: 15821
[15:23:12.525058] Epoch: [45]  [180/345]  eta: 0:01:39  lr: 0.000007  loss: 0.0982 (0.1064)  time: 0.6060  data: 0.0001  max mem: 15821
[15:23:24.641009] Epoch: [45]  [200/345]  eta: 0:01:27  lr: 0.000007  loss: 0.1027 (0.1065)  time: 0.6058  data: 0.0001  max mem: 15821
[15:23:36.742443] Epoch: [45]  [220/345]  eta: 0:01:15  lr: 0.000006  loss: 0.1008 (0.1065)  time: 0.6050  data: 0.0001  max mem: 15821
[15:23:48.859378] Epoch: [45]  [240/345]  eta: 0:01:03  lr: 0.000006  loss: 0.1014 (0.1064)  time: 0.6058  data: 0.0001  max mem: 15821
[15:24:00.963609] Epoch: [45]  [260/345]  eta: 0:00:51  lr: 0.000006  loss: 0.1022 (0.1064)  time: 0.6052  data: 0.0001  max mem: 15821
[15:24:13.071911] Epoch: [45]  [280/345]  eta: 0:00:39  lr: 0.000006  loss: 0.0967 (0.1062)  time: 0.6054  data: 0.0001  max mem: 15821
[15:24:25.183070] Epoch: [45]  [300/345]  eta: 0:00:27  lr: 0.000006  loss: 0.1055 (0.1064)  time: 0.6055  data: 0.0001  max mem: 15821
[15:24:37.277429] Epoch: [45]  [320/345]  eta: 0:00:15  lr: 0.000006  loss: 0.1086 (0.1066)  time: 0.6047  data: 0.0001  max mem: 15821
[15:24:49.358231] Epoch: [45]  [340/345]  eta: 0:00:03  lr: 0.000005  loss: 0.1028 (0.1068)  time: 0.6040  data: 0.0001  max mem: 15821
[15:24:51.774866] Epoch: [45]  [344/345]  eta: 0:00:00  lr: 0.000005  loss: 0.1026 (0.1068)  time: 0.6042  data: 0.0001  max mem: 15821
[15:24:51.849560] Epoch: [45] Total time: 0:03:28 (0.6057 s / it)
[15:24:51.850261] Averaged stats: lr: 0.000005  loss: 0.1026 (0.1068)
[15:24:52.373337] Test:  [  0/345]  eta: 0:02:58  loss: 0.0943 (0.0943)  time: 0.5180  data: 0.3536  max mem: 15821
[15:24:54.043238] Test:  [ 10/345]  eta: 0:01:06  loss: 0.0978 (0.1023)  time: 0.1988  data: 0.0322  max mem: 15821
[15:24:55.715155] Test:  [ 20/345]  eta: 0:00:59  loss: 0.0996 (0.1023)  time: 0.1670  data: 0.0001  max mem: 15821
[15:24:57.390115] Test:  [ 30/345]  eta: 0:00:56  loss: 0.0967 (0.1000)  time: 0.1673  data: 0.0001  max mem: 15821
[15:24:59.068667] Test:  [ 40/345]  eta: 0:00:53  loss: 0.0966 (0.1010)  time: 0.1676  data: 0.0001  max mem: 15821
[15:25:00.749402] Test:  [ 50/345]  eta: 0:00:51  loss: 0.0966 (0.0996)  time: 0.1679  data: 0.0001  max mem: 15821
[15:25:02.433226] Test:  [ 60/345]  eta: 0:00:49  loss: 0.0920 (0.1010)  time: 0.1682  data: 0.0001  max mem: 15821
[15:25:04.122041] Test:  [ 70/345]  eta: 0:00:47  loss: 0.0934 (0.1014)  time: 0.1686  data: 0.0001  max mem: 15821
[15:25:05.812752] Test:  [ 80/345]  eta: 0:00:45  loss: 0.0938 (0.1021)  time: 0.1689  data: 0.0001  max mem: 15821
[15:25:07.507573] Test:  [ 90/345]  eta: 0:00:43  loss: 0.0916 (0.1013)  time: 0.1692  data: 0.0001  max mem: 15821
[15:25:09.206421] Test:  [100/345]  eta: 0:00:42  loss: 0.0932 (0.1010)  time: 0.1696  data: 0.0001  max mem: 15821
[15:25:10.907947] Test:  [110/345]  eta: 0:00:40  loss: 0.0919 (0.1003)  time: 0.1700  data: 0.0001  max mem: 15821
[15:25:12.614198] Test:  [120/345]  eta: 0:00:38  loss: 0.0892 (0.1000)  time: 0.1703  data: 0.0001  max mem: 15821
[15:25:14.322819] Test:  [130/345]  eta: 0:00:36  loss: 0.0974 (0.1003)  time: 0.1707  data: 0.0001  max mem: 15821
[15:25:16.034423] Test:  [140/345]  eta: 0:00:35  loss: 0.1049 (0.1004)  time: 0.1710  data: 0.0001  max mem: 15821
[15:25:17.749837] Test:  [150/345]  eta: 0:00:33  loss: 0.0904 (0.1001)  time: 0.1713  data: 0.0001  max mem: 15821
[15:25:19.469199] Test:  [160/345]  eta: 0:00:31  loss: 0.0998 (0.1005)  time: 0.1717  data: 0.0001  max mem: 15821
[15:25:21.192646] Test:  [170/345]  eta: 0:00:30  loss: 0.1022 (0.1008)  time: 0.1721  data: 0.0001  max mem: 15821
[15:25:22.919357] Test:  [180/345]  eta: 0:00:28  loss: 0.0941 (0.1005)  time: 0.1724  data: 0.0001  max mem: 15821
[15:25:24.648663] Test:  [190/345]  eta: 0:00:26  loss: 0.0932 (0.1005)  time: 0.1727  data: 0.0001  max mem: 15821
[15:25:26.382493] Test:  [200/345]  eta: 0:00:24  loss: 0.0955 (0.1005)  time: 0.1731  data: 0.0001  max mem: 15821
[15:25:28.118479] Test:  [210/345]  eta: 0:00:23  loss: 0.0948 (0.1003)  time: 0.1734  data: 0.0001  max mem: 15821
[15:25:29.858613] Test:  [220/345]  eta: 0:00:21  loss: 0.0930 (0.1000)  time: 0.1737  data: 0.0001  max mem: 15821
[15:25:31.602407] Test:  [230/345]  eta: 0:00:19  loss: 0.0917 (0.1000)  time: 0.1741  data: 0.0001  max mem: 15821
[15:25:33.349045] Test:  [240/345]  eta: 0:00:18  loss: 0.0920 (0.1001)  time: 0.1745  data: 0.0001  max mem: 15821
[15:25:35.100655] Test:  [250/345]  eta: 0:00:16  loss: 0.0958 (0.1000)  time: 0.1748  data: 0.0001  max mem: 15821
[15:25:36.854431] Test:  [260/345]  eta: 0:00:14  loss: 0.0961 (0.1000)  time: 0.1752  data: 0.0001  max mem: 15821
[15:25:38.611420] Test:  [270/345]  eta: 0:00:12  loss: 0.0980 (0.1000)  time: 0.1755  data: 0.0001  max mem: 15821
[15:25:40.374632] Test:  [280/345]  eta: 0:00:11  loss: 0.0960 (0.0998)  time: 0.1759  data: 0.0001  max mem: 15821
[15:25:42.139567] Test:  [290/345]  eta: 0:00:09  loss: 0.0960 (0.0998)  time: 0.1763  data: 0.0001  max mem: 15821
[15:25:43.906995] Test:  [300/345]  eta: 0:00:07  loss: 0.1008 (0.1000)  time: 0.1766  data: 0.0001  max mem: 15821
[15:25:45.679698] Test:  [310/345]  eta: 0:00:06  loss: 0.1008 (0.1001)  time: 0.1769  data: 0.0001  max mem: 15821
[15:25:47.453654] Test:  [320/345]  eta: 0:00:04  loss: 0.0964 (0.0999)  time: 0.1773  data: 0.0001  max mem: 15821
[15:25:49.232828] Test:  [330/345]  eta: 0:00:02  loss: 0.0980 (0.1002)  time: 0.1776  data: 0.0001  max mem: 15821
[15:25:51.015152] Test:  [340/345]  eta: 0:00:00  loss: 0.1033 (0.1003)  time: 0.1780  data: 0.0001  max mem: 15821
[15:25:51.728979] Test:  [344/345]  eta: 0:00:00  loss: 0.0988 (0.1002)  time: 0.1781  data: 0.0001  max mem: 15821
[15:25:51.802887] Test: Total time: 0:00:59 (0.1738 s / it)
[15:26:01.744274] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4795 (0.4795)  time: 0.5215  data: 0.3584  max mem: 15821
[15:26:03.395087] Test:  [10/57]  eta: 0:00:09  loss: 0.4027 (0.4382)  time: 0.1974  data: 0.0327  max mem: 15821
[15:26:05.049771] Test:  [20/57]  eta: 0:00:06  loss: 0.4285 (0.4295)  time: 0.1652  data: 0.0001  max mem: 15821
[15:26:06.709313] Test:  [30/57]  eta: 0:00:04  loss: 0.2551 (0.3665)  time: 0.1657  data: 0.0001  max mem: 15821
[15:26:08.372605] Test:  [40/57]  eta: 0:00:02  loss: 0.2411 (0.3425)  time: 0.1661  data: 0.0001  max mem: 15821
[15:26:10.039560] Test:  [50/57]  eta: 0:00:01  loss: 0.2760 (0.3419)  time: 0.1665  data: 0.0001  max mem: 15821
[15:26:10.938706] Test:  [56/57]  eta: 0:00:00  loss: 0.3001 (0.3495)  time: 0.1616  data: 0.0000  max mem: 15821
[15:26:11.007983] Test: Total time: 0:00:09 (0.1717 s / it)
[15:26:12.731486] Dice score of the network on the train images: 0.895318, val images: 0.806632
[15:26:12.735767] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:26:13.647947] Epoch: [46]  [  0/345]  eta: 0:05:14  lr: 0.000005  loss: 0.1366 (0.1366)  time: 0.9110  data: 0.3091  max mem: 15821
[15:26:25.680189] Epoch: [46]  [ 20/345]  eta: 0:03:20  lr: 0.000005  loss: 0.1080 (0.1091)  time: 0.6016  data: 0.0001  max mem: 15821
[15:26:37.742180] Epoch: [46]  [ 40/345]  eta: 0:03:05  lr: 0.000005  loss: 0.1018 (0.1057)  time: 0.6031  data: 0.0001  max mem: 15821
[15:26:49.815531] Epoch: [46]  [ 60/345]  eta: 0:02:53  lr: 0.000005  loss: 0.1006 (0.1065)  time: 0.6036  data: 0.0001  max mem: 15821
[15:27:01.891826] Epoch: [46]  [ 80/345]  eta: 0:02:40  lr: 0.000005  loss: 0.1061 (0.1069)  time: 0.6038  data: 0.0001  max mem: 15821
[15:27:13.982754] Epoch: [46]  [100/345]  eta: 0:02:28  lr: 0.000005  loss: 0.1024 (0.1062)  time: 0.6045  data: 0.0001  max mem: 15821
[15:27:26.080067] Epoch: [46]  [120/345]  eta: 0:02:16  lr: 0.000005  loss: 0.1050 (0.1061)  time: 0.6048  data: 0.0001  max mem: 15821
[15:27:38.187716] Epoch: [46]  [140/345]  eta: 0:02:04  lr: 0.000004  loss: 0.1033 (0.1056)  time: 0.6053  data: 0.0001  max mem: 15821
[15:27:50.298900] Epoch: [46]  [160/345]  eta: 0:01:52  lr: 0.000004  loss: 0.1023 (0.1052)  time: 0.6055  data: 0.0001  max mem: 15821
[15:28:02.418932] Epoch: [46]  [180/345]  eta: 0:01:39  lr: 0.000004  loss: 0.1016 (0.1052)  time: 0.6060  data: 0.0001  max mem: 15821
[15:28:14.532374] Epoch: [46]  [200/345]  eta: 0:01:27  lr: 0.000004  loss: 0.0996 (0.1049)  time: 0.6056  data: 0.0001  max mem: 15821

[15:28:26.645720] Epoch: [46]  [220/345]  eta: 0:01:15  lr: 0.000004  loss: 0.1088 (0.1053)  time: 0.6056  data: 0.0001  max mem: 15821
[15:28:38.747027] Epoch: [46]  [240/345]  eta: 0:01:03  lr: 0.000004  loss: 0.1074 (0.1054)  time: 0.6050  data: 0.0001  max mem: 15821
[15:28:50.854713] Epoch: [46]  [260/345]  eta: 0:00:51  lr: 0.000004  loss: 0.1066 (0.1056)  time: 0.6053  data: 0.0001  max mem: 15821
[15:29:03.025747] Epoch: [46]  [280/345]  eta: 0:00:39  lr: 0.000003  loss: 0.1046 (0.1059)  time: 0.6085  data: 0.0001  max mem: 15821
[15:29:15.131002] Epoch: [46]  [300/345]  eta: 0:00:27  lr: 0.000003  loss: 0.1018 (0.1057)  time: 0.6052  data: 0.0001  max mem: 15821
[15:29:27.240693] Epoch: [46]  [320/345]  eta: 0:00:15  lr: 0.000003  loss: 0.1058 (0.1059)  time: 0.6054  data: 0.0001  max mem: 15821
[15:29:39.343353] Epoch: [46]  [340/345]  eta: 0:00:03  lr: 0.000003  loss: 0.0978 (0.1057)  time: 0.6051  data: 0.0001  max mem: 15821
[15:29:41.762614] Epoch: [46]  [344/345]  eta: 0:00:00  lr: 0.000003  loss: 0.1003 (0.1056)  time: 0.6049  data: 0.0001  max mem: 15821
[15:29:41.838315] Epoch: [46] Total time: 0:03:29 (0.6061 s / it)
[15:29:41.838668] Averaged stats: lr: 0.000003  loss: 0.1003 (0.1056)
[15:29:42.329441] Test:  [  0/345]  eta: 0:02:47  loss: 0.1086 (0.1086)  time: 0.4856  data: 0.3216  max mem: 15821
[15:29:43.999586] Test:  [ 10/345]  eta: 0:01:05  loss: 0.0985 (0.1020)  time: 0.1959  data: 0.0293  max mem: 15821
[15:29:45.671696] Test:  [ 20/345]  eta: 0:00:59  loss: 0.0985 (0.1028)  time: 0.1670  data: 0.0001  max mem: 15821
[15:29:47.345953] Test:  [ 30/345]  eta: 0:00:55  loss: 0.1041 (0.1017)  time: 0.1673  data: 0.0001  max mem: 15821
[15:29:49.024338] Test:  [ 40/345]  eta: 0:00:53  loss: 0.0940 (0.0997)  time: 0.1676  data: 0.0001  max mem: 15821
[15:29:50.705376] Test:  [ 50/345]  eta: 0:00:51  loss: 0.0939 (0.0984)  time: 0.1679  data: 0.0001  max mem: 15821
[15:29:52.389627] Test:  [ 60/345]  eta: 0:00:49  loss: 0.0893 (0.0980)  time: 0.1682  data: 0.0001  max mem: 15821
[15:29:54.077270] Test:  [ 70/345]  eta: 0:00:47  loss: 0.0892 (0.0980)  time: 0.1685  data: 0.0001  max mem: 15821
[15:29:55.769108] Test:  [ 80/345]  eta: 0:00:45  loss: 0.0974 (0.0984)  time: 0.1689  data: 0.0001  max mem: 15821
[15:29:57.465079] Test:  [ 90/345]  eta: 0:00:43  loss: 0.0983 (0.0986)  time: 0.1693  data: 0.0001  max mem: 15821
[15:29:59.163501] Test:  [100/345]  eta: 0:00:41  loss: 0.0997 (0.0992)  time: 0.1697  data: 0.0001  max mem: 15821
[15:30:00.866787] Test:  [110/345]  eta: 0:00:40  loss: 0.0989 (0.0991)  time: 0.1700  data: 0.0001  max mem: 15821
[15:30:02.571838] Test:  [120/345]  eta: 0:00:38  loss: 0.0962 (0.0985)  time: 0.1704  data: 0.0001  max mem: 15821
[15:30:04.281061] Test:  [130/345]  eta: 0:00:36  loss: 0.0923 (0.0986)  time: 0.1707  data: 0.0001  max mem: 15821
[15:30:05.993947] Test:  [140/345]  eta: 0:00:35  loss: 0.0923 (0.0982)  time: 0.1710  data: 0.0001  max mem: 15821
[15:30:07.709733] Test:  [150/345]  eta: 0:00:33  loss: 0.0936 (0.0986)  time: 0.1714  data: 0.0001  max mem: 15821
[15:30:09.430037] Test:  [160/345]  eta: 0:00:31  loss: 0.0941 (0.0988)  time: 0.1717  data: 0.0001  max mem: 15821
[15:30:11.153799] Test:  [170/345]  eta: 0:00:29  loss: 0.0948 (0.0986)  time: 0.1721  data: 0.0001  max mem: 15821
[15:30:12.881231] Test:  [180/345]  eta: 0:00:28  loss: 0.0980 (0.0990)  time: 0.1725  data: 0.0001  max mem: 15821
[15:30:14.611615] Test:  [190/345]  eta: 0:00:26  loss: 0.0962 (0.0988)  time: 0.1728  data: 0.0001  max mem: 15821
[15:30:16.345224] Test:  [200/345]  eta: 0:00:24  loss: 0.0926 (0.0985)  time: 0.1731  data: 0.0001  max mem: 15821
[15:30:18.081962] Test:  [210/345]  eta: 0:00:23  loss: 0.0926 (0.0986)  time: 0.1735  data: 0.0001  max mem: 15821
[15:30:19.823452] Test:  [220/345]  eta: 0:00:21  loss: 0.0964 (0.0987)  time: 0.1739  data: 0.0001  max mem: 15821
[15:30:21.568239] Test:  [230/345]  eta: 0:00:19  loss: 0.0986 (0.0992)  time: 0.1743  data: 0.0001  max mem: 15821
[15:30:23.314355] Test:  [240/345]  eta: 0:00:18  loss: 0.0999 (0.0993)  time: 0.1745  data: 0.0001  max mem: 15821
[15:30:25.065892] Test:  [250/345]  eta: 0:00:16  loss: 0.0976 (0.0994)  time: 0.1748  data: 0.0001  max mem: 15821
[15:30:26.818623] Test:  [260/345]  eta: 0:00:14  loss: 0.1027 (0.0996)  time: 0.1752  data: 0.0001  max mem: 15821
[15:30:28.576685] Test:  [270/345]  eta: 0:00:12  loss: 0.1049 (0.0998)  time: 0.1755  data: 0.0001  max mem: 15821
[15:30:30.337327] Test:  [280/345]  eta: 0:00:11  loss: 0.0964 (0.0998)  time: 0.1759  data: 0.0001  max mem: 15821
[15:30:32.102167] Test:  [290/345]  eta: 0:00:09  loss: 0.0964 (0.0998)  time: 0.1762  data: 0.0001  max mem: 15821
[15:30:33.870593] Test:  [300/345]  eta: 0:00:07  loss: 0.0967 (0.0997)  time: 0.1766  data: 0.0001  max mem: 15821
[15:30:35.641875] Test:  [310/345]  eta: 0:00:06  loss: 0.0968 (0.0998)  time: 0.1769  data: 0.0001  max mem: 15821
[15:30:37.416390] Test:  [320/345]  eta: 0:00:04  loss: 0.1021 (0.0998)  time: 0.1772  data: 0.0001  max mem: 15821
[15:30:39.194507] Test:  [330/345]  eta: 0:00:02  loss: 0.1019 (0.1000)  time: 0.1776  data: 0.0001  max mem: 15821
[15:30:40.977712] Test:  [340/345]  eta: 0:00:00  loss: 0.0947 (0.0998)  time: 0.1780  data: 0.0001  max mem: 15821
[15:30:41.692607] Test:  [344/345]  eta: 0:00:00  loss: 0.0968 (0.0998)  time: 0.1782  data: 0.0001  max mem: 15821
[15:30:41.769114] Test: Total time: 0:00:59 (0.1737 s / it)
[15:30:51.721624] Test:  [ 0/57]  eta: 0:00:27  loss: 0.4740 (0.4740)  time: 0.4819  data: 0.3196  max mem: 15821
[15:30:53.372388] Test:  [10/57]  eta: 0:00:09  loss: 0.4017 (0.4358)  time: 0.1938  data: 0.0291  max mem: 15821
[15:30:55.028745] Test:  [20/57]  eta: 0:00:06  loss: 0.4228 (0.4270)  time: 0.1653  data: 0.0001  max mem: 15821
[15:30:56.689500] Test:  [30/57]  eta: 0:00:04  loss: 0.2535 (0.3646)  time: 0.1658  data: 0.0001  max mem: 15821
[15:30:58.351932] Test:  [40/57]  eta: 0:00:02  loss: 0.2381 (0.3407)  time: 0.1661  data: 0.0001  max mem: 15821
[15:31:00.019465] Test:  [50/57]  eta: 0:00:01  loss: 0.2767 (0.3403)  time: 0.1664  data: 0.0001  max mem: 15821
[15:31:00.919026] Test:  [56/57]  eta: 0:00:00  loss: 0.3001 (0.3481)  time: 0.1615  data: 0.0000  max mem: 15821
[15:31:00.988476] Test: Total time: 0:00:09 (0.1710 s / it)
[15:31:02.664027] Dice score of the network on the train images: 0.894456, val images: 0.805765
[15:31:02.668405] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:31:03.584556] Epoch: [47]  [  0/345]  eta: 0:05:15  lr: 0.000003  loss: 0.1033 (0.1033)  time: 0.9152  data: 0.3128  max mem: 15821
[15:31:15.587116] Epoch: [47]  [ 20/345]  eta: 0:03:19  lr: 0.000003  loss: 0.0983 (0.1044)  time: 0.6001  data: 0.0001  max mem: 15821
[15:31:27.618438] Epoch: [47]  [ 40/345]  eta: 0:03:05  lr: 0.000003  loss: 0.1032 (0.1045)  time: 0.6015  data: 0.0001  max mem: 15821
[15:31:39.655907] Epoch: [47]  [ 60/345]  eta: 0:02:52  lr: 0.000003  loss: 0.0967 (0.1043)  time: 0.6018  data: 0.0001  max mem: 15821
[15:31:51.719037] Epoch: [47]  [ 80/345]  eta: 0:02:40  lr: 0.000003  loss: 0.1049 (0.1043)  time: 0.6031  data: 0.0001  max mem: 15821
[15:32:03.799080] Epoch: [47]  [100/345]  eta: 0:02:28  lr: 0.000003  loss: 0.1039 (0.1050)  time: 0.6040  data: 0.0001  max mem: 15821
[15:32:15.909466] Epoch: [47]  [120/345]  eta: 0:02:16  lr: 0.000002  loss: 0.1058 (0.1054)  time: 0.6055  data: 0.0001  max mem: 15821
[15:32:28.021866] Epoch: [47]  [140/345]  eta: 0:02:04  lr: 0.000002  loss: 0.1043 (0.1051)  time: 0.6056  data: 0.0001  max mem: 15821
[15:32:40.136479] Epoch: [47]  [160/345]  eta: 0:01:51  lr: 0.000002  loss: 0.1045 (0.1054)  time: 0.6057  data: 0.0001  max mem: 15821
[15:32:52.260479] Epoch: [47]  [180/345]  eta: 0:01:39  lr: 0.000002  loss: 0.1010 (0.1056)  time: 0.6062  data: 0.0001  max mem: 15821
[15:33:04.376786] Epoch: [47]  [200/345]  eta: 0:01:27  lr: 0.000002  loss: 0.1015 (0.1058)  time: 0.6058  data: 0.0001  max mem: 15821
[15:33:16.498602] Epoch: [47]  [220/345]  eta: 0:01:15  lr: 0.000002  loss: 0.1054 (0.1062)  time: 0.6060  data: 0.0001  max mem: 15821
[15:33:28.616120] Epoch: [47]  [240/345]  eta: 0:01:03  lr: 0.000002  loss: 0.1006 (0.1059)  time: 0.6058  data: 0.0001  max mem: 15821
[15:33:40.727279] Epoch: [47]  [260/345]  eta: 0:00:51  lr: 0.000002  loss: 0.1020 (0.1059)  time: 0.6055  data: 0.0001  max mem: 15821
[15:33:52.841745] Epoch: [47]  [280/345]  eta: 0:00:39  lr: 0.000002  loss: 0.1008 (0.1061)  time: 0.6057  data: 0.0001  max mem: 15821
[15:34:04.951445] Epoch: [47]  [300/345]  eta: 0:00:27  lr: 0.000002  loss: 0.1012 (0.1058)  time: 0.6054  data: 0.0001  max mem: 15821

[15:34:17.061924] Epoch: [47]  [320/345]  eta: 0:00:15  lr: 0.000001  loss: 0.1004 (0.1055)  time: 0.6055  data: 0.0001  max mem: 15821
[15:34:29.159612] Epoch: [47]  [340/345]  eta: 0:00:03  lr: 0.000001  loss: 0.0968 (0.1054)  time: 0.6048  data: 0.0001  max mem: 15821
[15:34:31.577820] Epoch: [47]  [344/345]  eta: 0:00:00  lr: 0.000001  loss: 0.0959 (0.1054)  time: 0.6047  data: 0.0001  max mem: 15821
[15:34:31.647082] Epoch: [47] Total time: 0:03:28 (0.6057 s / it)
[15:34:31.647432] Averaged stats: lr: 0.000001  loss: 0.0959 (0.1054)
[15:34:32.184532] Test:  [  0/345]  eta: 0:03:03  loss: 0.0815 (0.0815)  time: 0.5322  data: 0.3676  max mem: 15821
[15:34:33.854387] Test:  [ 10/345]  eta: 0:01:07  loss: 0.0902 (0.0904)  time: 0.2001  data: 0.0335  max mem: 15821
[15:34:35.526797] Test:  [ 20/345]  eta: 0:00:59  loss: 0.0933 (0.0933)  time: 0.1670  data: 0.0001  max mem: 15821
[15:34:37.202322] Test:  [ 30/345]  eta: 0:00:56  loss: 0.0935 (0.0968)  time: 0.1673  data: 0.0001  max mem: 15821
[15:34:38.881328] Test:  [ 40/345]  eta: 0:00:53  loss: 0.0976 (0.0971)  time: 0.1677  data: 0.0001  max mem: 15821
[15:34:40.562554] Test:  [ 50/345]  eta: 0:00:51  loss: 0.0913 (0.0979)  time: 0.1679  data: 0.0001  max mem: 15821
[15:34:42.246644] Test:  [ 60/345]  eta: 0:00:49  loss: 0.0923 (0.0977)  time: 0.1682  data: 0.0001  max mem: 15821
[15:34:43.935755] Test:  [ 70/345]  eta: 0:00:47  loss: 0.0938 (0.0977)  time: 0.1686  data: 0.0001  max mem: 15821
[15:34:45.627491] Test:  [ 80/345]  eta: 0:00:45  loss: 0.0936 (0.0974)  time: 0.1690  data: 0.0001  max mem: 15821
[15:34:47.323166] Test:  [ 90/345]  eta: 0:00:43  loss: 0.0938 (0.0981)  time: 0.1693  data: 0.0001  max mem: 15821
[15:34:49.022377] Test:  [100/345]  eta: 0:00:42  loss: 0.1007 (0.0985)  time: 0.1697  data: 0.0001  max mem: 15821
[15:34:50.724391] Test:  [110/345]  eta: 0:00:40  loss: 0.0939 (0.0978)  time: 0.1700  data: 0.0001  max mem: 15821
[15:34:52.430062] Test:  [120/345]  eta: 0:00:38  loss: 0.0902 (0.0974)  time: 0.1703  data: 0.0001  max mem: 15821
[15:34:54.139783] Test:  [130/345]  eta: 0:00:36  loss: 0.0917 (0.0975)  time: 0.1707  data: 0.0001  max mem: 15821
[15:34:55.853034] Test:  [140/345]  eta: 0:00:35  loss: 0.0942 (0.0975)  time: 0.1711  data: 0.0001  max mem: 15821
[15:34:57.568622] Test:  [150/345]  eta: 0:00:33  loss: 0.0956 (0.0978)  time: 0.1714  data: 0.0001  max mem: 15821
[15:34:59.289204] Test:  [160/345]  eta: 0:00:31  loss: 0.1002 (0.0983)  time: 0.1717  data: 0.0001  max mem: 15821
[15:35:01.012342] Test:  [170/345]  eta: 0:00:30  loss: 0.1030 (0.0987)  time: 0.1721  data: 0.0001  max mem: 15821
[15:35:02.738841] Test:  [180/345]  eta: 0:00:28  loss: 0.0985 (0.0990)  time: 0.1724  data: 0.0001  max mem: 15821
[15:35:04.470038] Test:  [190/345]  eta: 0:00:26  loss: 0.0985 (0.0990)  time: 0.1728  data: 0.0001  max mem: 15821
[15:35:06.203850] Test:  [200/345]  eta: 0:00:24  loss: 0.0947 (0.0993)  time: 0.1732  data: 0.0001  max mem: 15821
[15:35:07.940398] Test:  [210/345]  eta: 0:00:23  loss: 0.1036 (0.0996)  time: 0.1735  data: 0.0001  max mem: 15821
[15:35:09.680804] Test:  [220/345]  eta: 0:00:21  loss: 0.0999 (0.0995)  time: 0.1738  data: 0.0001  max mem: 15821
[15:35:11.423444] Test:  [230/345]  eta: 0:00:19  loss: 0.0970 (0.0999)  time: 0.1741  data: 0.0001  max mem: 15821
[15:35:13.171079] Test:  [240/345]  eta: 0:00:18  loss: 0.1051 (0.1000)  time: 0.1745  data: 0.0001  max mem: 15821
[15:35:14.921131] Test:  [250/345]  eta: 0:00:16  loss: 0.1055 (0.1003)  time: 0.1748  data: 0.0001  max mem: 15821
[15:35:16.675948] Test:  [260/345]  eta: 0:00:14  loss: 0.1014 (0.1003)  time: 0.1752  data: 0.0001  max mem: 15821
[15:35:18.433692] Test:  [270/345]  eta: 0:00:12  loss: 0.0953 (0.1001)  time: 0.1756  data: 0.0001  max mem: 15821
[15:35:20.195255] Test:  [280/345]  eta: 0:00:11  loss: 0.0920 (0.1002)  time: 0.1759  data: 0.0001  max mem: 15821
[15:35:21.959666] Test:  [290/345]  eta: 0:00:09  loss: 0.0916 (0.1001)  time: 0.1762  data: 0.0001  max mem: 15821
[15:35:23.728036] Test:  [300/345]  eta: 0:00:07  loss: 0.0916 (0.1001)  time: 0.1766  data: 0.0001  max mem: 15821
[15:35:25.499284] Test:  [310/345]  eta: 0:00:06  loss: 0.0931 (0.1000)  time: 0.1769  data: 0.0001  max mem: 15821
[15:35:27.275114] Test:  [320/345]  eta: 0:00:04  loss: 0.0906 (0.0996)  time: 0.1773  data: 0.0001  max mem: 15821
[15:35:29.054681] Test:  [330/345]  eta: 0:00:02  loss: 0.0916 (0.0996)  time: 0.1777  data: 0.0001  max mem: 15821
[15:35:30.837161] Test:  [340/345]  eta: 0:00:00  loss: 0.0913 (0.0994)  time: 0.1780  data: 0.0001  max mem: 15821
[15:35:31.551978] Test:  [344/345]  eta: 0:00:00  loss: 0.0916 (0.0993)  time: 0.1782  data: 0.0001  max mem: 15821
[15:35:31.625681] Test: Total time: 0:00:59 (0.1738 s / it)
[15:35:41.580961] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4758 (0.4758)  time: 0.5302  data: 0.3669  max mem: 15821
[15:35:43.233276] Test:  [10/57]  eta: 0:00:09  loss: 0.4010 (0.4371)  time: 0.1983  data: 0.0334  max mem: 15821
[15:35:44.890987] Test:  [20/57]  eta: 0:00:06  loss: 0.4268 (0.4285)  time: 0.1654  data: 0.0001  max mem: 15821
[15:35:46.552359] Test:  [30/57]  eta: 0:00:04  loss: 0.2534 (0.3660)  time: 0.1659  data: 0.0001  max mem: 15821
[15:35:48.216414] Test:  [40/57]  eta: 0:00:02  loss: 0.2389 (0.3423)  time: 0.1662  data: 0.0001  max mem: 15821
[15:35:49.885074] Test:  [50/57]  eta: 0:00:01  loss: 0.2778 (0.3418)  time: 0.1666  data: 0.0001  max mem: 15821
[15:35:50.785380] Test:  [56/57]  eta: 0:00:00  loss: 0.3024 (0.3496)  time: 0.1617  data: 0.0001  max mem: 15821
[15:35:50.854497] Test: Total time: 0:00:09 (0.1720 s / it)
[15:35:52.556017] Dice score of the network on the train images: 0.895367, val images: 0.805410
[15:35:52.560036] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:35:53.517848] Epoch: [48]  [  0/345]  eta: 0:05:30  lr: 0.000001  loss: 0.1034 (0.1034)  time: 0.9569  data: 0.3559  max mem: 15821
[15:36:05.534478] Epoch: [48]  [ 20/345]  eta: 0:03:20  lr: 0.000001  loss: 0.1014 (0.1036)  time: 0.6008  data: 0.0001  max mem: 15821
[15:36:17.584591] Epoch: [48]  [ 40/345]  eta: 0:03:06  lr: 0.000001  loss: 0.1000 (0.1033)  time: 0.6025  data: 0.0001  max mem: 15821
[15:36:29.651251] Epoch: [48]  [ 60/345]  eta: 0:02:53  lr: 0.000001  loss: 0.0931 (0.1029)  time: 0.6033  data: 0.0001  max mem: 15821

[15:36:41.724816] Epoch: [48]  [ 80/345]  eta: 0:02:40  lr: 0.000001  loss: 0.1008 (0.1026)  time: 0.6036  data: 0.0001  max mem: 15821
[15:36:53.806755] Epoch: [48]  [100/345]  eta: 0:02:28  lr: 0.000001  loss: 0.1064 (0.1040)  time: 0.6040  data: 0.0001  max mem: 15821
[15:37:05.905921] Epoch: [48]  [120/345]  eta: 0:02:16  lr: 0.000001  loss: 0.0979 (0.1038)  time: 0.6049  data: 0.0001  max mem: 15821
[15:37:18.010628] Epoch: [48]  [140/345]  eta: 0:02:04  lr: 0.000001  loss: 0.1025 (0.1041)  time: 0.6052  data: 0.0001  max mem: 15821
[15:37:30.118829] Epoch: [48]  [160/345]  eta: 0:01:52  lr: 0.000001  loss: 0.1047 (0.1043)  time: 0.6054  data: 0.0001  max mem: 15821
[15:37:42.231465] Epoch: [48]  [180/345]  eta: 0:01:39  lr: 0.000001  loss: 0.1022 (0.1049)  time: 0.6056  data: 0.0001  max mem: 15821
[15:37:54.342983] Epoch: [48]  [200/345]  eta: 0:01:27  lr: 0.000001  loss: 0.1015 (0.1050)  time: 0.6055  data: 0.0001  max mem: 15821
[15:38:06.449981] Epoch: [48]  [220/345]  eta: 0:01:15  lr: 0.000001  loss: 0.1008 (0.1051)  time: 0.6053  data: 0.0001  max mem: 15821
[15:38:18.557682] Epoch: [48]  [240/345]  eta: 0:01:03  lr: 0.000001  loss: 0.0971 (0.1050)  time: 0.6053  data: 0.0001  max mem: 15821
[15:38:30.663090] Epoch: [48]  [260/345]  eta: 0:00:51  lr: 0.000001  loss: 0.0973 (0.1048)  time: 0.6052  data: 0.0001  max mem: 15821
[15:38:42.771845] Epoch: [48]  [280/345]  eta: 0:00:39  lr: 0.000000  loss: 0.1034 (0.1048)  time: 0.6054  data: 0.0001  max mem: 15821
[15:38:54.865900] Epoch: [48]  [300/345]  eta: 0:00:27  lr: 0.000000  loss: 0.1063 (0.1050)  time: 0.6047  data: 0.0001  max mem: 15821
[15:39:06.971397] Epoch: [48]  [320/345]  eta: 0:00:15  lr: 0.000000  loss: 0.1011 (0.1049)  time: 0.6052  data: 0.0001  max mem: 15821
[15:39:19.067237] Epoch: [48]  [340/345]  eta: 0:00:03  lr: 0.000000  loss: 0.0991 (0.1046)  time: 0.6047  data: 0.0001  max mem: 15821
[15:39:21.487019] Epoch: [48]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.0991 (0.1046)  time: 0.6047  data: 0.0001  max mem: 15821
[15:39:21.559037] Epoch: [48] Total time: 0:03:28 (0.6058 s / it)
[15:39:21.559314] Averaged stats: lr: 0.000000  loss: 0.0991 (0.1046)
[15:39:22.113010] Test:  [  0/345]  eta: 0:03:09  loss: 0.0977 (0.0977)  time: 0.5482  data: 0.3836  max mem: 15821
[15:39:23.783057] Test:  [ 10/345]  eta: 0:01:07  loss: 0.0977 (0.0979)  time: 0.2016  data: 0.0350  max mem: 15821
[15:39:25.454878] Test:  [ 20/345]  eta: 0:01:00  loss: 0.0974 (0.0995)  time: 0.1670  data: 0.0001  max mem: 15821
[15:39:27.131273] Test:  [ 30/345]  eta: 0:00:56  loss: 0.0974 (0.0997)  time: 0.1673  data: 0.0001  max mem: 15821
[15:39:28.810511] Test:  [ 40/345]  eta: 0:00:53  loss: 0.0932 (0.0987)  time: 0.1677  data: 0.0001  max mem: 15821
[15:39:30.493311] Test:  [ 50/345]  eta: 0:00:51  loss: 0.0992 (0.1009)  time: 0.1680  data: 0.0001  max mem: 15821
[15:39:32.180095] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1014 (0.1012)  time: 0.1684  data: 0.0001  max mem: 15821
[15:39:33.868776] Test:  [ 70/345]  eta: 0:00:47  loss: 0.0982 (0.1002)  time: 0.1687  data: 0.0001  max mem: 15821
[15:39:35.560175] Test:  [ 80/345]  eta: 0:00:45  loss: 0.0971 (0.1009)  time: 0.1689  data: 0.0001  max mem: 15821
[15:39:37.256174] Test:  [ 90/345]  eta: 0:00:43  loss: 0.0947 (0.1001)  time: 0.1693  data: 0.0001  max mem: 15821
[15:39:38.955108] Test:  [100/345]  eta: 0:00:42  loss: 0.0906 (0.1000)  time: 0.1697  data: 0.0001  max mem: 15821
[15:39:40.658970] Test:  [110/345]  eta: 0:00:40  loss: 0.0881 (0.0994)  time: 0.1701  data: 0.0001  max mem: 15821
[15:39:42.365030] Test:  [120/345]  eta: 0:00:38  loss: 0.0864 (0.0993)  time: 0.1704  data: 0.0001  max mem: 15821
[15:39:44.073821] Test:  [130/345]  eta: 0:00:36  loss: 0.0965 (0.0994)  time: 0.1707  data: 0.0001  max mem: 15821
[15:39:45.786358] Test:  [140/345]  eta: 0:00:35  loss: 0.0956 (0.0995)  time: 0.1710  data: 0.0001  max mem: 15821
[15:39:47.502102] Test:  [150/345]  eta: 0:00:33  loss: 0.0956 (0.0994)  time: 0.1714  data: 0.0001  max mem: 15821
[15:39:49.222214] Test:  [160/345]  eta: 0:00:31  loss: 0.0951 (0.0992)  time: 0.1717  data: 0.0001  max mem: 15821
[15:39:50.945673] Test:  [170/345]  eta: 0:00:30  loss: 0.0951 (0.0992)  time: 0.1721  data: 0.0001  max mem: 15821
[15:39:52.672388] Test:  [180/345]  eta: 0:00:28  loss: 0.0990 (0.0994)  time: 0.1724  data: 0.0001  max mem: 15821
[15:39:54.402060] Test:  [190/345]  eta: 0:00:26  loss: 0.0992 (0.0992)  time: 0.1728  data: 0.0001  max mem: 15821
[15:39:56.136238] Test:  [200/345]  eta: 0:00:24  loss: 0.0960 (0.0991)  time: 0.1731  data: 0.0001  max mem: 15821
[15:39:57.873594] Test:  [210/345]  eta: 0:00:23  loss: 0.0934 (0.0988)  time: 0.1735  data: 0.0001  max mem: 15821
[15:39:59.615282] Test:  [220/345]  eta: 0:00:21  loss: 0.0934 (0.0990)  time: 0.1739  data: 0.0001  max mem: 15821
[15:40:01.359066] Test:  [230/345]  eta: 0:00:19  loss: 0.0993 (0.0988)  time: 0.1742  data: 0.0001  max mem: 15821
[15:40:03.105806] Test:  [240/345]  eta: 0:00:18  loss: 0.0943 (0.0988)  time: 0.1745  data: 0.0001  max mem: 15821
[15:40:04.856825] Test:  [250/345]  eta: 0:00:16  loss: 0.0931 (0.0991)  time: 0.1748  data: 0.0001  max mem: 15821
[15:40:06.610403] Test:  [260/345]  eta: 0:00:14  loss: 0.0883 (0.0987)  time: 0.1752  data: 0.0001  max mem: 15821
[15:40:08.369643] Test:  [270/345]  eta: 0:00:12  loss: 0.0883 (0.0986)  time: 0.1756  data: 0.0001  max mem: 15821
[15:40:10.130531] Test:  [280/345]  eta: 0:00:11  loss: 0.0968 (0.0989)  time: 0.1759  data: 0.0001  max mem: 15821
[15:40:11.895983] Test:  [290/345]  eta: 0:00:09  loss: 0.0968 (0.0989)  time: 0.1763  data: 0.0001  max mem: 15821
[15:40:13.663823] Test:  [300/345]  eta: 0:00:07  loss: 0.0942 (0.0989)  time: 0.1766  data: 0.0001  max mem: 15821
[15:40:15.436831] Test:  [310/345]  eta: 0:00:06  loss: 0.0981 (0.0991)  time: 0.1770  data: 0.0001  max mem: 15821
[15:40:17.213086] Test:  [320/345]  eta: 0:00:04  loss: 0.0981 (0.0990)  time: 0.1774  data: 0.0001  max mem: 15821
[15:40:18.993012] Test:  [330/345]  eta: 0:00:02  loss: 0.0974 (0.0991)  time: 0.1777  data: 0.0001  max mem: 15821
[15:40:20.776409] Test:  [340/345]  eta: 0:00:00  loss: 0.0980 (0.0992)  time: 0.1781  data: 0.0001  max mem: 15821
[15:40:21.490023] Test:  [344/345]  eta: 0:00:00  loss: 0.0980 (0.0992)  time: 0.1782  data: 0.0001  max mem: 15821
[15:40:21.557582] Test: Total time: 0:00:59 (0.1739 s / it)
[15:40:31.561130] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4768 (0.4768)  time: 0.4572  data: 0.2947  max mem: 15821
[15:40:33.213423] Test:  [10/57]  eta: 0:00:09  loss: 0.4004 (0.4374)  time: 0.1917  data: 0.0269  max mem: 15821
[15:40:34.869349] Test:  [20/57]  eta: 0:00:06  loss: 0.4259 (0.4288)  time: 0.1653  data: 0.0001  max mem: 15821
[15:40:36.531087] Test:  [30/57]  eta: 0:00:04  loss: 0.2532 (0.3662)  time: 0.1658  data: 0.0001  max mem: 15821
[15:40:38.196546] Test:  [40/57]  eta: 0:00:02  loss: 0.2394 (0.3424)  time: 0.1663  data: 0.0001  max mem: 15821
[15:40:39.864442] Test:  [50/57]  eta: 0:00:01  loss: 0.2779 (0.3420)  time: 0.1666  data: 0.0001  max mem: 15821
[15:40:40.764395] Test:  [56/57]  eta: 0:00:00  loss: 0.3025 (0.3498)  time: 0.1617  data: 0.0000  max mem: 15821
[15:40:40.840067] Test: Total time: 0:00:09 (0.1708 s / it)
[15:40:42.524666] Dice score of the network on the train images: 0.895556, val images: 0.805445
[15:40:42.528879] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:40:43.429248] Epoch: [49]  [  0/345]  eta: 0:05:10  lr: 0.000000  loss: 0.1173 (0.1173)  time: 0.8994  data: 0.2962  max mem: 15821
[15:40:55.451664] Epoch: [49]  [ 20/345]  eta: 0:03:19  lr: 0.000000  loss: 0.0997 (0.1088)  time: 0.6011  data: 0.0001  max mem: 15821
[15:41:07.498072] Epoch: [49]  [ 40/345]  eta: 0:03:05  lr: 0.000000  loss: 0.0970 (0.1050)  time: 0.6023  data: 0.0001  max mem: 15821
[15:41:19.556987] Epoch: [49]  [ 60/345]  eta: 0:02:52  lr: 0.000000  loss: 0.1049 (0.1067)  time: 0.6029  data: 0.0001  max mem: 15821
[15:41:31.629023] Epoch: [49]  [ 80/345]  eta: 0:02:40  lr: 0.000000  loss: 0.1015 (0.1059)  time: 0.6036  data: 0.0001  max mem: 15821
[15:41:43.718521] Epoch: [49]  [100/345]  eta: 0:02:28  lr: 0.000000  loss: 0.1024 (0.1055)  time: 0.6044  data: 0.0001  max mem: 15821
[15:41:55.820509] Epoch: [49]  [120/345]  eta: 0:02:16  lr: 0.000000  loss: 0.0996 (0.1048)  time: 0.6050  data: 0.0001  max mem: 15821
[15:42:07.936852] Epoch: [49]  [140/345]  eta: 0:02:04  lr: 0.000000  loss: 0.1014 (0.1050)  time: 0.6058  data: 0.0001  max mem: 15821
[15:42:20.056680] Epoch: [49]  [160/345]  eta: 0:01:52  lr: 0.000000  loss: 0.1025 (0.1048)  time: 0.6059  data: 0.0001  max mem: 15821
[15:42:32.182270] Epoch: [49]  [180/345]  eta: 0:01:39  lr: 0.000000  loss: 0.1047 (0.1051)  time: 0.6062  data: 0.0001  max mem: 15821
[15:42:44.306274] Epoch: [49]  [200/345]  eta: 0:01:27  lr: 0.000000  loss: 0.0973 (0.1043)  time: 0.6062  data: 0.0001  max mem: 15821
[15:42:56.437425] Epoch: [49]  [220/345]  eta: 0:01:15  lr: 0.000000  loss: 0.1023 (0.1043)  time: 0.6065  data: 0.0001  max mem: 15821
[15:43:08.557923] Epoch: [49]  [240/345]  eta: 0:01:03  lr: 0.000000  loss: 0.1103 (0.1047)  time: 0.6060  data: 0.0001  max mem: 15821
[15:43:20.675174] Epoch: [49]  [260/345]  eta: 0:00:51  lr: 0.000000  loss: 0.1034 (0.1048)  time: 0.6058  data: 0.0001  max mem: 15821
[15:43:32.795645] Epoch: [49]  [280/345]  eta: 0:00:39  lr: 0.000000  loss: 0.1044 (0.1048)  time: 0.6060  data: 0.0001  max mem: 15821
[15:43:44.909023] Epoch: [49]  [300/345]  eta: 0:00:27  lr: 0.000000  loss: 0.0972 (0.1045)  time: 0.6056  data: 0.0001  max mem: 15821
[15:43:57.016474] Epoch: [49]  [320/345]  eta: 0:00:15  lr: 0.000000  loss: 0.1025 (0.1046)  time: 0.6053  data: 0.0001  max mem: 15821
[15:44:09.123442] Epoch: [49]  [340/345]  eta: 0:00:03  lr: 0.000000  loss: 0.0990 (0.1048)  time: 0.6053  data: 0.0001  max mem: 15821
[15:44:11.547825] Epoch: [49]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.1008 (0.1048)  time: 0.6054  data: 0.0001  max mem: 15821
[15:44:11.619563] Epoch: [49] Total time: 0:03:29 (0.6061 s / it)
[15:44:11.619776] Averaged stats: lr: 0.000000  loss: 0.1008 (0.1048)
[15:44:12.126893] Test:  [  0/345]  eta: 0:02:53  loss: 0.1173 (0.1173)  time: 0.5020  data: 0.3378  max mem: 15821
[15:44:13.797158] Test:  [ 10/345]  eta: 0:01:06  loss: 0.0985 (0.1000)  time: 0.1974  data: 0.0308  max mem: 15821
[15:44:15.469847] Test:  [ 20/345]  eta: 0:00:59  loss: 0.0965 (0.1014)  time: 0.1671  data: 0.0001  max mem: 15821
[15:44:17.145099] Test:  [ 30/345]  eta: 0:00:56  loss: 0.0982 (0.1013)  time: 0.1673  data: 0.0001  max mem: 15821
[15:44:18.824270] Test:  [ 40/345]  eta: 0:00:53  loss: 0.0986 (0.1025)  time: 0.1677  data: 0.0001  max mem: 15821
[15:44:20.506128] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1068 (0.1037)  time: 0.1680  data: 0.0001  max mem: 15821
[15:44:22.191177] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1062 (0.1040)  time: 0.1683  data: 0.0001  max mem: 15821
[15:44:23.880233] Test:  [ 70/345]  eta: 0:00:47  loss: 0.0987 (0.1029)  time: 0.1686  data: 0.0001  max mem: 15821
[15:44:25.572598] Test:  [ 80/345]  eta: 0:00:45  loss: 0.0917 (0.1015)  time: 0.1690  data: 0.0001  max mem: 15821
[15:44:27.268752] Test:  [ 90/345]  eta: 0:00:43  loss: 0.0885 (0.1003)  time: 0.1694  data: 0.0001  max mem: 15821
[15:44:28.968883] Test:  [100/345]  eta: 0:00:42  loss: 0.0920 (0.1010)  time: 0.1697  data: 0.0001  max mem: 15821
[15:44:30.670860] Test:  [110/345]  eta: 0:00:40  loss: 0.1006 (0.1005)  time: 0.1700  data: 0.0001  max mem: 15821
[15:44:32.377133] Test:  [120/345]  eta: 0:00:38  loss: 0.0897 (0.1002)  time: 0.1704  data: 0.0001  max mem: 15821
[15:44:34.086584] Test:  [130/345]  eta: 0:00:36  loss: 0.0882 (0.0995)  time: 0.1707  data: 0.0001  max mem: 15821
[15:44:35.798765] Test:  [140/345]  eta: 0:00:35  loss: 0.0946 (0.0999)  time: 0.1710  data: 0.0001  max mem: 15821
[15:44:37.514829] Test:  [150/345]  eta: 0:00:33  loss: 0.0980 (0.1001)  time: 0.1713  data: 0.0001  max mem: 15821
[15:44:39.235477] Test:  [160/345]  eta: 0:00:31  loss: 0.0994 (0.1000)  time: 0.1718  data: 0.0001  max mem: 15821
[15:44:40.958908] Test:  [170/345]  eta: 0:00:30  loss: 0.0988 (0.0996)  time: 0.1721  data: 0.0001  max mem: 15821
[15:44:42.685818] Test:  [180/345]  eta: 0:00:28  loss: 0.0913 (0.0993)  time: 0.1725  data: 0.0001  max mem: 15821
[15:44:44.415259] Test:  [190/345]  eta: 0:00:26  loss: 0.0912 (0.0990)  time: 0.1728  data: 0.0001  max mem: 15821
[15:44:46.148004] Test:  [200/345]  eta: 0:00:24  loss: 0.0927 (0.0991)  time: 0.1730  data: 0.0001  max mem: 15821
[15:44:47.885250] Test:  [210/345]  eta: 0:00:23  loss: 0.0945 (0.0991)  time: 0.1734  data: 0.0001  max mem: 15821
[15:44:49.626618] Test:  [220/345]  eta: 0:00:21  loss: 0.0923 (0.0991)  time: 0.1739  data: 0.0001  max mem: 15821
[15:44:51.369763] Test:  [230/345]  eta: 0:00:19  loss: 0.0954 (0.0989)  time: 0.1742  data: 0.0001  max mem: 15821
[15:44:53.116217] Test:  [240/345]  eta: 0:00:18  loss: 0.0948 (0.0989)  time: 0.1744  data: 0.0001  max mem: 15821
[15:44:54.867274] Test:  [250/345]  eta: 0:00:16  loss: 0.0967 (0.0988)  time: 0.1748  data: 0.0001  max mem: 15821
[15:44:56.622626] Test:  [260/345]  eta: 0:00:14  loss: 0.0967 (0.0988)  time: 0.1753  data: 0.0001  max mem: 15821
[15:44:58.381682] Test:  [270/345]  eta: 0:00:12  loss: 0.0956 (0.0985)  time: 0.1757  data: 0.0001  max mem: 15821
[15:45:00.144113] Test:  [280/345]  eta: 0:00:11  loss: 0.0983 (0.0987)  time: 0.1760  data: 0.0001  max mem: 15821
[15:45:01.908879] Test:  [290/345]  eta: 0:00:09  loss: 0.1011 (0.0990)  time: 0.1763  data: 0.0001  max mem: 15821
[15:45:03.677705] Test:  [300/345]  eta: 0:00:07  loss: 0.0938 (0.0989)  time: 0.1766  data: 0.0001  max mem: 15821
[15:45:05.450389] Test:  [310/345]  eta: 0:00:06  loss: 0.0891 (0.0987)  time: 0.1770  data: 0.0001  max mem: 15821
[15:45:07.227772] Test:  [320/345]  eta: 0:00:04  loss: 0.0934 (0.0988)  time: 0.1774  data: 0.0001  max mem: 15821
[15:45:09.008009] Test:  [330/345]  eta: 0:00:02  loss: 0.0934 (0.0988)  time: 0.1778  data: 0.0001  max mem: 15821
[15:45:10.791462] Test:  [340/345]  eta: 0:00:00  loss: 0.0943 (0.0990)  time: 0.1781  data: 0.0001  max mem: 15821
[15:45:11.506914] Test:  [344/345]  eta: 0:00:00  loss: 0.0943 (0.0991)  time: 0.1783  data: 0.0001  max mem: 15821
[15:45:11.584345] Test: Total time: 0:00:59 (0.1738 s / it)
[15:45:21.596573] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4769 (0.4769)  time: 0.5094  data: 0.3465  max mem: 15821
[15:45:23.248720] Test:  [10/57]  eta: 0:00:09  loss: 0.4011 (0.4373)  time: 0.1964  data: 0.0316  max mem: 15821
[15:45:24.906452] Test:  [20/57]  eta: 0:00:06  loss: 0.4256 (0.4287)  time: 0.1654  data: 0.0001  max mem: 15821
[15:45:26.567869] Test:  [30/57]  eta: 0:00:04  loss: 0.2532 (0.3661)  time: 0.1659  data: 0.0001  max mem: 15821
[15:45:28.233609] Test:  [40/57]  eta: 0:00:02  loss: 0.2394 (0.3423)  time: 0.1663  data: 0.0001  max mem: 15821
[15:45:29.903512] Test:  [50/57]  eta: 0:00:01  loss: 0.2781 (0.3418)  time: 0.1667  data: 0.0001  max mem: 15821
[15:45:30.804224] Test:  [56/57]  eta: 0:00:00  loss: 0.3025 (0.3496)  time: 0.1618  data: 0.0000  max mem: 15821
[15:45:30.881588] Test: Total time: 0:00:09 (0.1718 s / it)
[15:45:32.573985] Dice score of the network on the train images: 0.895659, val images: 0.805615
[15:45:32.575604] Training time 4:02:06
[15:45:34.250236] Load pre-trained checkpoint from: /root/seg_framework/MS-Mamba/output_dir_test/mslesseg/checkpoints_0/checkpoint-best_dice_model_0.pth
[15:45:34.271660] <All keys matched successfully>
[15:45:37.231116] Test:  [  0/246]  eta: 0:11:49    time: 2.8855  data: 0.4055  max mem: 15821
[15:45:39.751298] Test:  [ 10/246]  eta: 0:01:55    time: 0.4914  data: 0.0369  max mem: 15821
[15:45:45.810251] ---------------------------------
[15:45:45.810467] Patient 1:
[15:45:45.810548]       precision: 0.40749895572662354
[15:45:45.810615]       recall: 0.6283354759216309
[15:45:45.810674]       dice_score: 0.737674355506897
[15:45:45.813638] Test:  [ 20/246]  eta: 0:02:03    time: 0.4291  data: 0.0001  max mem: 15821
[15:45:48.326891] Test:  [ 30/246]  eta: 0:01:37    time: 0.4287  data: 0.0001  max mem: 15821
[15:45:54.313811] ---------------------------------
[15:45:54.314028] Patient 2:
[15:45:54.314108]       precision: 0.43062061071395874
[15:45:54.314172]       recall: 0.7200195789337158
[15:45:54.314232]       dice_score: 0.7399168014526367
[15:45:54.320895] Test:  [ 40/246]  eta: 0:01:40    time: 0.4253  data: 0.0001  max mem: 15821
[15:45:56.832548] Test:  [ 50/246]  eta: 0:01:26    time: 0.4252  data: 0.0001  max mem: 15821
[15:45:59.525937] Test:  [ 60/246]  eta: 0:01:16    time: 0.2602  data: 0.0001  max mem: 15821
[15:46:03.073594] ---------------------------------
[15:46:03.073812] Patient 3:
[15:46:03.073890]       precision: 0.28549301624298096
[15:46:03.073959]       recall: 0.5836411714553833
[15:46:03.074021]       dice_score: 0.6689457297325134
[15:46:05.316756] Test:  [ 70/246]  eta: 0:01:16    time: 0.4242  data: 0.0001  max mem: 15821
[15:46:08.011860] Test:  [ 80/246]  eta: 0:01:08    time: 0.4242  data: 0.0001  max mem: 15821
[15:46:11.552407] ---------------------------------
[15:46:11.552630] Patient 4:
[15:46:11.552708]       precision: 0.48924732208251953
[15:46:11.552775]       recall: 0.5790504217147827
[15:46:11.552837]       dice_score: 0.7158249616622925
[15:46:13.796358] Test:  [ 90/246]  eta: 0:01:07    time: 0.4239  data: 0.0001  max mem: 15821
[15:46:16.490362] Test:  [100/246]  eta: 0:01:00    time: 0.4239  data: 0.0001  max mem: 15821
[15:46:20.317274] ---------------------------------
[15:46:20.317489] Patient 5:
[15:46:20.317569]       precision: 0.3280605375766754
[15:46:20.317634]       recall: 0.5034300684928894
[15:46:20.317692]       dice_score: 0.6702293157577515
[15:46:22.296050] Test:  [110/246]  eta: 0:00:58    time: 0.4249  data: 0.0001  max mem: 15821
[15:46:24.990532] Test:  [120/246]  eta: 0:00:52    time: 0.4250  data: 0.0001  max mem: 15821
[15:46:28.816787] ---------------------------------
[15:46:28.817036] Patient 6:
[15:46:28.817124]       precision: 0.34049078822135925
[15:46:28.817198]       recall: 0.5857519507408142
[15:46:28.817271]       dice_score: 0.6983269453048706
[15:46:30.788514] Test:  [130/246]  eta: 0:00:49    time: 0.4245  data: 0.0001  max mem: 15821
[15:46:33.481444] Test:  [140/246]  eta: 0:00:44    time: 0.4245  data: 0.0001  max mem: 15821
[15:46:37.629968] ---------------------------------
[15:46:37.630186] Patient 7:
[15:46:37.630265]       precision: 0.6989609599113464
[15:46:37.630331]       recall: 0.8513006567955017
[15:46:37.630391]       dice_score: 0.793940544128418
[15:46:39.333917] Test:  [150/246]  eta: 0:00:41    time: 0.4272  data: 0.0001  max mem: 15821
[15:46:42.029292] Test:  [160/246]  eta: 0:00:36    time: 0.4273  data: 0.0001  max mem: 15821
[15:46:46.152522] ---------------------------------
[15:46:46.152738] Patient 8:
[15:46:46.152815]       precision: 0.7992520928382874
[15:46:46.152884]       recall: 0.6586716771125793
[15:46:46.152944]       dice_score: 0.7738029360771179
[15:46:47.857066] Test:  [170/246]  eta: 0:00:32    time: 0.4261  data: 0.0001  max mem: 15821
[15:46:50.550938] Test:  [180/246]  eta: 0:00:27    time: 0.4260  data: 0.0001  max mem: 15821
[15:46:54.684231] ---------------------------------
[15:46:54.684444] Patient 9:
[15:46:54.684521]       precision: 0.6301031112670898
[15:46:54.684583]       recall: 0.8727937936782837
[15:46:54.684643]       dice_score: 0.7643063068389893
[15:46:56.393214] Test:  [190/246]  eta: 0:00:24    time: 0.4268  data: 0.0001  max mem: 15821
[15:46:59.084762] Test:  [200/246]  eta: 0:00:19    time: 0.4266  data: 0.0001  max mem: 15821
[15:47:03.481353] ---------------------------------
[15:47:03.481571] Patient 10:
[15:47:03.481651]       precision: 0.5603927373886108
[15:47:03.481717]       recall: 0.9163567423820496
[15:47:03.481778]       dice_score: 0.7627179622650146
[15:47:04.922115] Test:  [210/246]  eta: 0:00:15    time: 0.4264  data: 0.0001  max mem: 15821
[15:47:07.611021] Test:  [220/246]  eta: 0:00:10    time: 0.4263  data: 0.0001  max mem: 15821
[15:47:12.008259] ---------------------------------
[15:47:12.008477] Patient 11:
[15:47:12.008555]       precision: 0.8618123531341553
[15:47:12.008620]       recall: 0.8142837285995483
[15:47:12.008681]       dice_score: 0.7972046136856079
[15:47:13.448736] Test:  [230/246]  eta: 0:00:06    time: 0.4263  data: 0.0001  max mem: 15821
[15:47:16.135948] Test:  [240/246]  eta: 0:00:02    time: 0.4262  data: 0.0001  max mem: 15821
[15:47:21.389929] ---------------------------------
[15:47:21.390145] Patient 12:
[15:47:21.390222]       precision: 0.5991449952125549
[15:47:21.390285]       recall: 0.7949389219284058
[15:47:21.390345]       dice_score: 0.7971588373184204
[15:47:21.390737] Test:  [245/246]  eta: 0:00:00    time: 0.4643  data: 0.0001  max mem: 15821
[15:47:21.473691] Test: Total time: 0:01:47 (0.4355 s / it)
[15:47:21.473879] ================================
[15:47:21.473945] Averaged over all patients:
[15:47:21.474215]       precision: 0.5359 ± 0.1802
[15:47:21.474349]       recall: 0.7090 ± 0.1316
[15:47:21.474473]       dice_score: 0.7433 ± 0.0445
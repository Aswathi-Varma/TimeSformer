Not using distributed mode
[17:57:40.282304] job dir: /root/seg_framework/MS-Mamba/run_scripts
[17:57:40.282440] Namespace(accum_iter=1,
model='SegFormer3D',
in_channels=1,
lr=None,
blr=0.001,
min_lr=0,
dist_on_itp=False,
warmup_epochs=20,
device='cuda:0',
seed=42,
layer_decay=0.75,
clip_grad=None,
num_workers=8,
pin_mem=True,
resume='',
mask_mode='concatenate to image',
world_size=1,
embed_dim=1,
local_rank=-1,
dist_url='env://',
nb_classes=2,
data_dir='/root/MSLesSeg24/data',
datalist=None,
preprocess=False,
dim=2,
loss='mask tp1 tp2',
distributed=False)
[17:57:40.282548] device  cuda:0
[17:57:40.283180] Random seed set as 42
[17:57:40.283509] Starting for fold 0
[17:57:40.478185] Elements in data_dir_paths: 11052
[17:57:40.512452] Elements in data_dir_paths: 1803
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[17:57:42.484666] number of params: 59617303
[17:57:42.484906] model: Vivim2D(
  (encoder): mamba_block(
    (downsample_layers): SegformerEncoder(
      (patch_embeddings): ModuleList(
        (0): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(2, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (1): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (2): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (3): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (block): ModuleList(
        (0): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): Identity()
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.003703703870996833)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.007407407741993666)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.011111111380159855)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.014814815483987331)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.018518518656492233)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.02222222276031971)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (2): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.025925926864147186)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.029629630967974663)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03333333507180214)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03703703731298447)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04074074327945709)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04444444552063942)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.048148151487112045)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.051851850003004074)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0555555559694767)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.05925925821065903)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06296296417713165)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06666667014360428)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07037036865949631)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07407407462596893)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07777778059244156)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08148147910833359)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08518518507480621)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08888889104127884)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (3): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.09259259700775146)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0962962955236435)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.10000000149011612)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (layer_norm): ModuleList(
        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=64, out_features=256, bias=False)
              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (act): SiLU()
              (x_proj): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_b): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_b): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_b): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_s): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_s): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_s): Linear(in_features=4, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=64, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=256, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=64, out_features=256, bias=False)
              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (act): SiLU()
              (x_proj): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_b): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_b): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_b): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_s): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_s): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_s): Linear(in_features=4, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=64, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=256, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (1): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=128, out_features=512, bias=False)
              (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (act): SiLU()
              (x_proj): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_b): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_b): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_b): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_s): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_s): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_s): Linear(in_features=8, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=128, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=128, out_features=512, bias=False)
              (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (act): SiLU()
              (x_proj): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_b): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_b): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_b): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_s): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_s): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_s): Linear(in_features=8, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=128, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (2): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=320, out_features=1280, bias=False)
              (conv1d): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (act): SiLU()
              (x_proj): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_b): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_b): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_b): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_s): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_s): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_s): Linear(in_features=20, out_features=640, bias=True)
              (out_proj): Linear(in_features=640, out_features=320, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(1280, 1280, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=320, out_features=1280, bias=False)
              (conv1d): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (act): SiLU()
              (x_proj): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_b): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_b): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_b): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_s): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_s): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_s): Linear(in_features=20, out_features=640, bias=True)
              (out_proj): Linear(in_features=640, out_features=320, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(1280, 1280, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (3): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=512, out_features=2048, bias=False)
              (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (act): SiLU()
              (x_proj): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_b): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_b): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_b): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_s): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_s): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_s): Linear(in_features=32, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=512, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=512, out_features=2048, bias=False)
              (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (act): SiLU()
              (x_proj): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_b): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_b): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_b): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_s): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_s): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_s): Linear(in_features=32, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=512, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
  )
  (decoder): SegformerDecodeHead(
    (linear_c): ModuleList(
      (0): SegformerMLP(
        (proj): Linear(in_features=64, out_features=768, bias=True)
      )
      (1): SegformerMLP(
        (proj): Linear(in_features=128, out_features=768, bias=True)
      )
      (2): SegformerMLP(
        (proj): Linear(in_features=320, out_features=768, bias=True)
      )
      (3): SegformerMLP(
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
    )
    (linear_fuse): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (batch_norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): ReLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Conv2d(768, 150, kernel_size=(1, 1), stride=(1, 1))
  )
  (out): Conv2d(768, 1, kernel_size=(1, 1), stride=(1, 1))
)
[17:57:42.487932] base lr: 1.00e-03
[17:57:42.487989] actual lr: 1.25e-04
[17:57:42.488039] accumulate grad iterations: 1
[17:57:42.488091] effective batch size: 32
[17:57:42.489550] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.000125
    maximize: False
    weight_decay: 0.01
)
[17:57:42.491281] Start training for 50 epochs
[17:57:42.491370] Number of samples in train dataloader:  345
[17:57:42.493073] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
[17:57:44.522659] Epoch: [0]  [  0/345]  eta: 0:11:39  lr: 0.000000  loss: 1.6965 (1.6965)  time: 2.0285  data: 0.2941  max mem: 14473
[17:57:59.485606] Epoch: [0]  [ 20/345]  eta: 0:04:22  lr: 0.000000  loss: 1.6955 (1.6956)  time: 0.7481  data: 0.0001  max mem: 14938
[17:58:14.541155] Epoch: [0]  [ 40/345]  eta: 0:03:58  lr: 0.000001  loss: 1.6917 (1.6936)  time: 0.7527  data: 0.0001  max mem: 14938
[17:58:29.674352] Epoch: [0]  [ 60/345]  eta: 0:03:40  lr: 0.000001  loss: 1.6874 (1.6916)  time: 0.7566  data: 0.0001  max mem: 14938
[17:58:44.847374] Epoch: [0]  [ 80/345]  eta: 0:03:23  lr: 0.000001  loss: 1.6850 (1.6901)  time: 0.7586  data: 0.0001  max mem: 14938
[17:59:00.047913] Epoch: [0]  [100/345]  eta: 0:03:08  lr: 0.000002  loss: 1.6822 (1.6885)  time: 0.7600  data: 0.0001  max mem: 14938
[17:59:15.247691] Epoch: [0]  [120/345]  eta: 0:02:52  lr: 0.000002  loss: 1.6764 (1.6865)  time: 0.7599  data: 0.0001  max mem: 14938
[17:59:30.441665] Epoch: [0]  [140/345]  eta: 0:02:36  lr: 0.000003  loss: 1.6697 (1.6843)  time: 0.7596  data: 0.0001  max mem: 14938
[17:59:45.638741] Epoch: [0]  [160/345]  eta: 0:02:21  lr: 0.000003  loss: 1.6670 (1.6822)  time: 0.7598  data: 0.0001  max mem: 14938
[18:00:00.831902] Epoch: [0]  [180/345]  eta: 0:02:06  lr: 0.000003  loss: 1.6606 (1.6798)  time: 0.7596  data: 0.0001  max mem: 14938
[18:00:16.022279] Epoch: [0]  [200/345]  eta: 0:01:50  lr: 0.000004  loss: 1.6525 (1.6772)  time: 0.7595  data: 0.0001  max mem: 14938
[18:00:31.202439] Epoch: [0]  [220/345]  eta: 0:01:35  lr: 0.000004  loss: 1.6446 (1.6743)  time: 0.7590  data: 0.0001  max mem: 14938
[18:00:46.389441] Epoch: [0]  [240/345]  eta: 0:01:20  lr: 0.000004  loss: 1.6343 (1.6711)  time: 0.7593  data: 0.0001  max mem: 14938
[18:01:01.567025] Epoch: [0]  [260/345]  eta: 0:01:04  lr: 0.000005  loss: 1.6247 (1.6675)  time: 0.7588  data: 0.0001  max mem: 14938
[18:01:16.763720] Epoch: [0]  [280/345]  eta: 0:00:49  lr: 0.000005  loss: 1.6127 (1.6636)  time: 0.7598  data: 0.0001  max mem: 14938
[18:01:31.945035] Epoch: [0]  [300/345]  eta: 0:00:34  lr: 0.000005  loss: 1.5995 (1.6594)  time: 0.7590  data: 0.0001  max mem: 14938
[18:01:47.131973] Epoch: [0]  [320/345]  eta: 0:00:19  lr: 0.000006  loss: 1.5854 (1.6548)  time: 0.7593  data: 0.0001  max mem: 14938
[18:02:02.310801] Epoch: [0]  [340/345]  eta: 0:00:03  lr: 0.000006  loss: 1.5717 (1.6499)  time: 0.7589  data: 0.0001  max mem: 14938
[18:02:05.343444] Epoch: [0]  [344/345]  eta: 0:00:00  lr: 0.000006  loss: 1.5658 (1.6489)  time: 0.7584  data: 0.0001  max mem: 14938
[18:02:05.413500] Epoch: [0] Total time: 0:04:22 (0.7621 s / it)
[18:02:05.413919] Averaged stats: lr: 0.000006  loss: 1.5658 (1.6489)
[18:02:05.967451] Test:  [  0/345]  eta: 0:03:09  loss: 1.5938 (1.5938)  time: 0.5493  data: 0.3504  max mem: 14938
[18:02:07.915453] Test:  [ 10/345]  eta: 0:01:16  loss: 1.5938 (1.5936)  time: 0.2269  data: 0.0319  max mem: 14938
[18:02:09.872260] Test:  [ 20/345]  eta: 0:01:08  loss: 1.5941 (1.5938)  time: 0.1952  data: 0.0001  max mem: 14938
[18:02:11.834418] Test:  [ 30/345]  eta: 0:01:05  loss: 1.5925 (1.5932)  time: 0.1959  data: 0.0001  max mem: 14938
[18:02:13.800995] Test:  [ 40/345]  eta: 0:01:02  loss: 1.5925 (1.5931)  time: 0.1964  data: 0.0001  max mem: 14938
[18:02:15.774286] Test:  [ 50/345]  eta: 0:00:59  loss: 1.5936 (1.5932)  time: 0.1969  data: 0.0001  max mem: 14938
[18:02:17.752435] Test:  [ 60/345]  eta: 0:00:57  loss: 1.5936 (1.5931)  time: 0.1975  data: 0.0001  max mem: 14938
[18:02:19.735489] Test:  [ 70/345]  eta: 0:00:55  loss: 1.5913 (1.5929)  time: 0.1980  data: 0.0001  max mem: 14938
[18:02:21.723419] Test:  [ 80/345]  eta: 0:00:53  loss: 1.5913 (1.5928)  time: 0.1985  data: 0.0001  max mem: 14938
[18:02:23.715304] Test:  [ 90/345]  eta: 0:00:51  loss: 1.5924 (1.5927)  time: 0.1989  data: 0.0001  max mem: 14938
[18:02:25.715902] Test:  [100/345]  eta: 0:00:49  loss: 1.5928 (1.5926)  time: 0.1996  data: 0.0001  max mem: 14938
[18:02:27.719846] Test:  [110/345]  eta: 0:00:47  loss: 1.5931 (1.5927)  time: 0.2002  data: 0.0001  max mem: 14938
[18:02:29.725063] Test:  [120/345]  eta: 0:00:45  loss: 1.5936 (1.5927)  time: 0.2004  data: 0.0001  max mem: 14938
[18:02:32.135340] Test:  [130/345]  eta: 0:00:43  loss: 1.5921 (1.5926)  time: 0.2207  data: 0.0001  max mem: 14938
[18:02:34.155383] Test:  [140/345]  eta: 0:00:41  loss: 1.5925 (1.5925)  time: 0.2215  data: 0.0001  max mem: 14938
[18:02:36.291417] Test:  [150/345]  eta: 0:00:39  loss: 1.5931 (1.5926)  time: 0.2077  data: 0.0001  max mem: 14938
[18:02:38.341946] Test:  [160/345]  eta: 0:00:37  loss: 1.5938 (1.5926)  time: 0.2093  data: 0.0001  max mem: 14938
[18:02:40.375189] Test:  [170/345]  eta: 0:00:35  loss: 1.5926 (1.5926)  time: 0.2041  data: 0.0001  max mem: 14938
[18:02:42.605336] Test:  [180/345]  eta: 0:00:33  loss: 1.5931 (1.5926)  time: 0.2131  data: 0.0001  max mem: 14938
[18:02:44.648233] Test:  [190/345]  eta: 0:00:31  loss: 1.5935 (1.5926)  time: 0.2136  data: 0.0001  max mem: 14938
[18:02:46.909038] Test:  [200/345]  eta: 0:00:29  loss: 1.5923 (1.5926)  time: 0.2151  data: 0.0001  max mem: 14938
[18:02:49.143350] Test:  [210/345]  eta: 0:00:27  loss: 1.5924 (1.5926)  time: 0.2247  data: 0.0001  max mem: 14938
[18:02:51.224590] Test:  [220/345]  eta: 0:00:25  loss: 1.5940 (1.5927)  time: 0.2157  data: 0.0001  max mem: 14938
[18:02:53.507713] Test:  [230/345]  eta: 0:00:23  loss: 1.5944 (1.5927)  time: 0.2182  data: 0.0001  max mem: 14938
[18:02:55.766890] Test:  [240/345]  eta: 0:00:21  loss: 1.5927 (1.5927)  time: 0.2271  data: 0.0001  max mem: 14938
[18:02:57.874050] Test:  [250/345]  eta: 0:00:19  loss: 1.5927 (1.5927)  time: 0.2183  data: 0.0001  max mem: 14938
[18:03:00.329085] Test:  [260/345]  eta: 0:00:17  loss: 1.5921 (1.5927)  time: 0.2281  data: 0.0001  max mem: 14938
[18:03:02.795205] Test:  [270/345]  eta: 0:00:15  loss: 1.5934 (1.5927)  time: 0.2460  data: 0.0001  max mem: 14938
[18:03:05.206658] Test:  [280/345]  eta: 0:00:13  loss: 1.5934 (1.5927)  time: 0.2438  data: 0.0001  max mem: 14938
[18:03:07.316626] Test:  [290/345]  eta: 0:00:11  loss: 1.5910 (1.5926)  time: 0.2260  data: 0.0001  max mem: 14938
[18:03:09.692512] Test:  [300/345]  eta: 0:00:09  loss: 1.5934 (1.5927)  time: 0.2242  data: 0.0001  max mem: 14938
[18:03:12.070358] Test:  [310/345]  eta: 0:00:07  loss: 1.5937 (1.5927)  time: 0.2376  data: 0.0001  max mem: 14938
[18:03:14.476063] Test:  [320/345]  eta: 0:00:05  loss: 1.5932 (1.5927)  time: 0.2391  data: 0.0001  max mem: 14938
[18:03:16.874029] Test:  [330/345]  eta: 0:00:03  loss: 1.5928 (1.5927)  time: 0.2401  data: 0.0001  max mem: 14938
[18:03:19.213339] Test:  [340/345]  eta: 0:00:01  loss: 1.5917 (1.5927)  time: 0.2368  data: 0.0001  max mem: 14938
[18:03:20.272512] Test:  [344/345]  eta: 0:00:00  loss: 1.5918 (1.5927)  time: 0.2343  data: 0.0001  max mem: 14938
[18:03:20.334291] Test: Total time: 0:01:14 (0.2171 s / it)
[18:03:36.990004] Test:  [ 0/57]  eta: 0:00:28  loss: 1.6031 (1.6031)  time: 0.4947  data: 0.2994  max mem: 14938
[18:03:38.909050] Test:  [10/57]  eta: 0:00:10  loss: 1.5973 (1.5980)  time: 0.2194  data: 0.0273  max mem: 14938
[18:03:40.843621] Test:  [20/57]  eta: 0:00:07  loss: 1.5978 (1.5966)  time: 0.1926  data: 0.0001  max mem: 14938
[18:03:42.783335] Test:  [30/57]  eta: 0:00:05  loss: 1.5949 (1.5924)  time: 0.1936  data: 0.0001  max mem: 14938
[18:03:44.728305] Test:  [40/57]  eta: 0:00:03  loss: 1.5840 (1.5894)  time: 0.1942  data: 0.0001  max mem: 14938
[18:03:46.679007] Test:  [50/57]  eta: 0:00:01  loss: 1.5840 (1.5885)  time: 0.1947  data: 0.0001  max mem: 14938
[18:03:47.770767] Test:  [56/57]  eta: 0:00:00  loss: 1.5873 (1.5884)  time: 0.1910  data: 0.0000  max mem: 14938
[18:03:47.833956] Test: Total time: 0:00:11 (0.1989 s / it)
[18:03:50.650836] Dice score of the network on the train images: 0.000000, val images: 0.000000
[18:03:50.651061] saving best_dice_model_0 @ epoch 0
[18:03:51.850083] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:03:52.943662] Epoch: [1]  [  0/345]  eta: 0:06:16  lr: 0.000006  loss: 1.5589 (1.5589)  time: 1.0926  data: 0.3286  max mem: 14938
[18:04:08.101296] Epoch: [1]  [ 20/345]  eta: 0:04:11  lr: 0.000007  loss: 1.5513 (1.5526)  time: 0.7578  data: 0.0001  max mem: 14938
[18:04:23.214939] Epoch: [1]  [ 40/345]  eta: 0:03:53  lr: 0.000007  loss: 1.5421 (1.5472)  time: 0.7556  data: 0.0001  max mem: 14938
[18:04:38.365652] Epoch: [1]  [ 60/345]  eta: 0:03:37  lr: 0.000007  loss: 1.5235 (1.5400)  time: 0.7575  data: 0.0001  max mem: 14938
[18:04:53.550058] Epoch: [1]  [ 80/345]  eta: 0:03:21  lr: 0.000008  loss: 1.5102 (1.5334)  time: 0.7592  data: 0.0001  max mem: 14938
[18:05:08.752631] Epoch: [1]  [100/345]  eta: 0:03:06  lr: 0.000008  loss: 1.4967 (1.5266)  time: 0.7601  data: 0.0001  max mem: 14938
[18:05:23.945605] Epoch: [1]  [120/345]  eta: 0:02:51  lr: 0.000008  loss: 1.4868 (1.5198)  time: 0.7596  data: 0.0001  max mem: 14938
[18:05:39.138647] Epoch: [1]  [140/345]  eta: 0:02:35  lr: 0.000009  loss: 1.4720 (1.5131)  time: 0.7596  data: 0.0001  max mem: 14938
[18:05:54.332532] Epoch: [1]  [160/345]  eta: 0:02:20  lr: 0.000009  loss: 1.4666 (1.5074)  time: 0.7597  data: 0.0001  max mem: 14938
[18:06:09.504506] Epoch: [1]  [180/345]  eta: 0:02:05  lr: 0.000010  loss: 1.4543 (1.5018)  time: 0.7586  data: 0.0001  max mem: 14938
[18:06:24.659851] Epoch: [1]  [200/345]  eta: 0:01:50  lr: 0.000010  loss: 1.4464 (1.4965)  time: 0.7577  data: 0.0001  max mem: 14938
[18:06:39.855686] Epoch: [1]  [220/345]  eta: 0:01:35  lr: 0.000010  loss: 1.4327 (1.4908)  time: 0.7597  data: 0.0001  max mem: 14938
[18:06:55.003840] Epoch: [1]  [240/345]  eta: 0:01:19  lr: 0.000011  loss: 1.4221 (1.4854)  time: 0.7574  data: 0.0001  max mem: 14938
[18:07:10.169335] Epoch: [1]  [260/345]  eta: 0:01:04  lr: 0.000011  loss: 1.4219 (1.4805)  time: 0.7582  data: 0.0001  max mem: 14938
[18:07:25.358190] Epoch: [1]  [280/345]  eta: 0:00:49  lr: 0.000011  loss: 1.4123 (1.4760)  time: 0.7594  data: 0.0001  max mem: 14938
[18:07:40.534679] Epoch: [1]  [300/345]  eta: 0:00:34  lr: 0.000012  loss: 1.4043 (1.4715)  time: 0.7588  data: 0.0001  max mem: 14938
[18:07:55.697003] Epoch: [1]  [320/345]  eta: 0:00:18  lr: 0.000012  loss: 1.4006 (1.4672)  time: 0.7581  data: 0.0001  max mem: 14938
[18:08:10.846072] Epoch: [1]  [340/345]  eta: 0:00:03  lr: 0.000012  loss: 1.3953 (1.4632)  time: 0.7574  data: 0.0001  max mem: 14938
[18:08:13.871869] Epoch: [1]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 1.3953 (1.4624)  time: 0.7570  data: 0.0001  max mem: 14938
[18:08:13.943330] Epoch: [1] Total time: 0:04:22 (0.7597 s / it)
[18:08:13.943902] Averaged stats: lr: 0.000012  loss: 1.3953 (1.4624)
[18:08:14.576820] Test:  [  0/345]  eta: 0:03:36  loss: 1.3930 (1.3930)  time: 0.6265  data: 0.4265  max mem: 14938
[18:08:16.528066] Test:  [ 10/345]  eta: 0:01:18  loss: 1.3928 (1.3932)  time: 0.2343  data: 0.0389  max mem: 14938
[18:08:18.483836] Test:  [ 20/345]  eta: 0:01:10  loss: 1.3929 (1.3935)  time: 0.1953  data: 0.0001  max mem: 14938
[18:08:20.447972] Test:  [ 30/345]  eta: 0:01:06  loss: 1.3929 (1.3933)  time: 0.1959  data: 0.0001  max mem: 14938
[18:08:22.413587] Test:  [ 40/345]  eta: 0:01:02  loss: 1.3927 (1.3930)  time: 0.1964  data: 0.0001  max mem: 14938
[18:08:24.386937] Test:  [ 50/345]  eta: 0:01:00  loss: 1.3925 (1.3929)  time: 0.1969  data: 0.0001  max mem: 14938
[18:08:26.366979] Test:  [ 60/345]  eta: 0:00:57  loss: 1.3926 (1.3930)  time: 0.1976  data: 0.0001  max mem: 14938
[18:08:28.349698] Test:  [ 70/345]  eta: 0:00:55  loss: 1.3935 (1.3931)  time: 0.1981  data: 0.0001  max mem: 14938
[18:08:30.336718] Test:  [ 80/345]  eta: 0:00:53  loss: 1.3934 (1.3931)  time: 0.1984  data: 0.0001  max mem: 14938
[18:08:32.330619] Test:  [ 90/345]  eta: 0:00:51  loss: 1.3922 (1.3930)  time: 0.1990  data: 0.0001  max mem: 14938
[18:08:34.329916] Test:  [100/345]  eta: 0:00:49  loss: 1.3919 (1.3929)  time: 0.1996  data: 0.0001  max mem: 14938
[18:08:36.333591] Test:  [110/345]  eta: 0:00:47  loss: 1.3930 (1.3929)  time: 0.2001  data: 0.0001  max mem: 14938
[18:08:38.341299] Test:  [120/345]  eta: 0:00:45  loss: 1.3930 (1.3929)  time: 0.2005  data: 0.0001  max mem: 14938
[18:08:40.356091] Test:  [130/345]  eta: 0:00:43  loss: 1.3929 (1.3929)  time: 0.2011  data: 0.0001  max mem: 14938
[18:08:42.373317] Test:  [140/345]  eta: 0:00:41  loss: 1.3933 (1.3930)  time: 0.2015  data: 0.0001  max mem: 14938
[18:08:44.397495] Test:  [150/345]  eta: 0:00:39  loss: 1.3927 (1.3929)  time: 0.2020  data: 0.0001  max mem: 14938
[18:08:46.424215] Test:  [160/345]  eta: 0:00:37  loss: 1.3926 (1.3930)  time: 0.2025  data: 0.0001  max mem: 14938
[18:08:48.458564] Test:  [170/345]  eta: 0:00:35  loss: 1.3929 (1.3929)  time: 0.2030  data: 0.0001  max mem: 14938
[18:08:50.497871] Test:  [180/345]  eta: 0:00:33  loss: 1.3934 (1.3930)  time: 0.2036  data: 0.0001  max mem: 14938
[18:08:52.538957] Test:  [190/345]  eta: 0:00:31  loss: 1.3930 (1.3930)  time: 0.2040  data: 0.0001  max mem: 14938
[18:08:54.588135] Test:  [200/345]  eta: 0:00:29  loss: 1.3933 (1.3930)  time: 0.2045  data: 0.0001  max mem: 14938
[18:08:56.640724] Test:  [210/345]  eta: 0:00:27  loss: 1.3935 (1.3930)  time: 0.2050  data: 0.0001  max mem: 14938
[18:08:58.698765] Test:  [220/345]  eta: 0:00:25  loss: 1.3933 (1.3930)  time: 0.2055  data: 0.0001  max mem: 14938
[18:09:00.762692] Test:  [230/345]  eta: 0:00:23  loss: 1.3929 (1.3930)  time: 0.2060  data: 0.0001  max mem: 14938
[18:09:02.831791] Test:  [240/345]  eta: 0:00:21  loss: 1.3929 (1.3930)  time: 0.2066  data: 0.0001  max mem: 14938
[18:09:04.906171] Test:  [250/345]  eta: 0:00:19  loss: 1.3929 (1.3930)  time: 0.2071  data: 0.0001  max mem: 14938
[18:09:06.984156] Test:  [260/345]  eta: 0:00:17  loss: 1.3925 (1.3929)  time: 0.2076  data: 0.0001  max mem: 14938
[18:09:09.070046] Test:  [270/345]  eta: 0:00:15  loss: 1.3925 (1.3929)  time: 0.2081  data: 0.0001  max mem: 14938
[18:09:11.161976] Test:  [280/345]  eta: 0:00:13  loss: 1.3926 (1.3929)  time: 0.2088  data: 0.0001  max mem: 14938
[18:09:13.256611] Test:  [290/345]  eta: 0:00:11  loss: 1.3927 (1.3929)  time: 0.2093  data: 0.0001  max mem: 14938
[18:09:15.356711] Test:  [300/345]  eta: 0:00:09  loss: 1.3926 (1.3929)  time: 0.2097  data: 0.0001  max mem: 14938
[18:09:17.463746] Test:  [310/345]  eta: 0:00:07  loss: 1.3926 (1.3929)  time: 0.2103  data: 0.0001  max mem: 14938
[18:09:19.575790] Test:  [320/345]  eta: 0:00:05  loss: 1.3925 (1.3929)  time: 0.2109  data: 0.0001  max mem: 14938
[18:09:21.693740] Test:  [330/345]  eta: 0:00:03  loss: 1.3925 (1.3929)  time: 0.2114  data: 0.0001  max mem: 14938
[18:09:23.812311] Test:  [340/345]  eta: 0:00:01  loss: 1.3931 (1.3929)  time: 0.2118  data: 0.0001  max mem: 14938
[18:09:24.662204] Test:  [344/345]  eta: 0:00:00  loss: 1.3934 (1.3929)  time: 0.2119  data: 0.0001  max mem: 14938
[18:09:24.726197] Test: Total time: 0:01:10 (0.2051 s / it)
[18:09:41.432216] Test:  [ 0/57]  eta: 0:00:32  loss: 1.4002 (1.4002)  time: 0.5783  data: 0.3827  max mem: 14938
[18:09:43.355862] Test:  [10/57]  eta: 0:00:10  loss: 1.3979 (1.3969)  time: 0.2274  data: 0.0349  max mem: 14938
[18:09:45.289716] Test:  [20/57]  eta: 0:00:07  loss: 1.3979 (1.3960)  time: 0.1928  data: 0.0001  max mem: 14938
[18:09:47.230405] Test:  [30/57]  eta: 0:00:05  loss: 1.3926 (1.3927)  time: 0.1937  data: 0.0001  max mem: 14938
[18:09:49.177414] Test:  [40/57]  eta: 0:00:03  loss: 1.3871 (1.3906)  time: 0.1943  data: 0.0001  max mem: 14938
[18:09:51.128631] Test:  [50/57]  eta: 0:00:01  loss: 1.3871 (1.3899)  time: 0.1949  data: 0.0001  max mem: 14938
[18:09:52.189781] Test:  [56/57]  eta: 0:00:00  loss: 1.3899 (1.3898)  time: 0.1895  data: 0.0000  max mem: 14938
[18:09:52.261365] Test: Total time: 0:00:11 (0.2001 s / it)
[18:09:55.075734] Dice score of the network on the train images: 0.000000, val images: 0.000000
[18:09:55.079847] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:09:56.217200] Epoch: [2]  [  0/345]  eta: 0:06:32  lr: 0.000013  loss: 1.3903 (1.3903)  time: 1.1366  data: 0.3751  max mem: 14938
[18:10:11.268205] Epoch: [2]  [ 20/345]  eta: 0:04:10  lr: 0.000013  loss: 1.3872 (1.3882)  time: 0.7525  data: 0.0001  max mem: 14938
[18:10:26.387814] Epoch: [2]  [ 40/345]  eta: 0:03:52  lr: 0.000013  loss: 1.3834 (1.3868)  time: 0.7559  data: 0.0001  max mem: 14938
[18:10:41.544065] Epoch: [2]  [ 60/345]  eta: 0:03:37  lr: 0.000014  loss: 1.3799 (1.3847)  time: 0.7578  data: 0.0001  max mem: 14938
[18:10:56.702711] Epoch: [2]  [ 80/345]  eta: 0:03:21  lr: 0.000014  loss: 1.3745 (1.3833)  time: 0.7579  data: 0.0001  max mem: 14938
[18:11:11.892275] Epoch: [2]  [100/345]  eta: 0:03:06  lr: 0.000014  loss: 1.3708 (1.3813)  time: 0.7594  data: 0.0001  max mem: 14938
[18:11:27.086304] Epoch: [2]  [120/345]  eta: 0:02:51  lr: 0.000015  loss: 1.3642 (1.3789)  time: 0.7597  data: 0.0001  max mem: 14938
[18:11:42.283368] Epoch: [2]  [140/345]  eta: 0:02:35  lr: 0.000015  loss: 1.3576 (1.3760)  time: 0.7598  data: 0.0001  max mem: 14938
[18:11:57.475895] Epoch: [2]  [160/345]  eta: 0:02:20  lr: 0.000015  loss: 1.3560 (1.3741)  time: 0.7596  data: 0.0001  max mem: 14938
[18:12:12.666214] Epoch: [2]  [180/345]  eta: 0:02:05  lr: 0.000016  loss: 1.3545 (1.3721)  time: 0.7595  data: 0.0001  max mem: 14938
[18:12:27.857770] Epoch: [2]  [200/345]  eta: 0:01:50  lr: 0.000016  loss: 1.3490 (1.3699)  time: 0.7595  data: 0.0001  max mem: 14938
[18:12:43.040806] Epoch: [2]  [220/345]  eta: 0:01:34  lr: 0.000016  loss: 1.3484 (1.3680)  time: 0.7591  data: 0.0001  max mem: 14938
[18:12:58.189129] Epoch: [2]  [240/345]  eta: 0:01:19  lr: 0.000017  loss: 1.3415 (1.3660)  time: 0.7574  data: 0.0001  max mem: 14938
[18:13:13.358881] Epoch: [2]  [260/345]  eta: 0:01:04  lr: 0.000017  loss: 1.3398 (1.3645)  time: 0.7584  data: 0.0001  max mem: 14938
[18:13:28.524719] Epoch: [2]  [280/345]  eta: 0:00:49  lr: 0.000018  loss: 1.3390 (1.3629)  time: 0.7582  data: 0.0001  max mem: 14938
[18:13:43.698946] Epoch: [2]  [300/345]  eta: 0:00:34  lr: 0.000018  loss: 1.3290 (1.3610)  time: 0.7587  data: 0.0001  max mem: 14938
[18:13:58.872539] Epoch: [2]  [320/345]  eta: 0:00:18  lr: 0.000018  loss: 1.3324 (1.3595)  time: 0.7586  data: 0.0001  max mem: 14938
[18:14:14.031695] Epoch: [2]  [340/345]  eta: 0:00:03  lr: 0.000019  loss: 1.3339 (1.3582)  time: 0.7579  data: 0.0001  max mem: 14938
[18:14:17.063090] Epoch: [2]  [344/345]  eta: 0:00:00  lr: 0.000019  loss: 1.3339 (1.3580)  time: 0.7578  data: 0.0001  max mem: 14938
[18:14:17.132471] Epoch: [2] Total time: 0:04:22 (0.7596 s / it)
[18:14:17.132692] Averaged stats: lr: 0.000019  loss: 1.3339 (1.3580)
[18:14:17.710699] Test:  [  0/345]  eta: 0:03:17  loss: 1.3401 (1.3401)  time: 0.5729  data: 0.3753  max mem: 14938
[18:14:19.662223] Test:  [ 10/345]  eta: 0:01:16  loss: 1.3420 (1.3417)  time: 0.2294  data: 0.0342  max mem: 14938
[18:14:21.620197] Test:  [ 20/345]  eta: 0:01:09  loss: 1.3420 (1.3415)  time: 0.1954  data: 0.0001  max mem: 14938
[18:14:23.585872] Test:  [ 30/345]  eta: 0:01:05  loss: 1.3429 (1.3418)  time: 0.1961  data: 0.0001  max mem: 14938
[18:14:25.554635] Test:  [ 40/345]  eta: 0:01:02  loss: 1.3433 (1.3422)  time: 0.1967  data: 0.0001  max mem: 14938
[18:14:27.529217] Test:  [ 50/345]  eta: 0:01:00  loss: 1.3433 (1.3425)  time: 0.1971  data: 0.0001  max mem: 14938
[18:14:29.510370] Test:  [ 60/345]  eta: 0:00:57  loss: 1.3426 (1.3427)  time: 0.1977  data: 0.0001  max mem: 14938
[18:14:31.494951] Test:  [ 70/345]  eta: 0:00:55  loss: 1.3423 (1.3426)  time: 0.1982  data: 0.0001  max mem: 14938
[18:14:33.483579] Test:  [ 80/345]  eta: 0:00:53  loss: 1.3432 (1.3427)  time: 0.1986  data: 0.0001  max mem: 14938
[18:14:35.475444] Test:  [ 90/345]  eta: 0:00:51  loss: 1.3439 (1.3428)  time: 0.1990  data: 0.0001  max mem: 14938
[18:14:37.478586] Test:  [100/345]  eta: 0:00:49  loss: 1.3436 (1.3428)  time: 0.1997  data: 0.0001  max mem: 14938
[18:14:39.482362] Test:  [110/345]  eta: 0:00:47  loss: 1.3429 (1.3428)  time: 0.2003  data: 0.0001  max mem: 14938
[18:14:41.492153] Test:  [120/345]  eta: 0:00:45  loss: 1.3423 (1.3427)  time: 0.2006  data: 0.0001  max mem: 14938
[18:14:43.505317] Test:  [130/345]  eta: 0:00:43  loss: 1.3427 (1.3429)  time: 0.2011  data: 0.0001  max mem: 14938
[18:14:45.523132] Test:  [140/345]  eta: 0:00:41  loss: 1.3431 (1.3428)  time: 0.2015  data: 0.0001  max mem: 14938
[18:14:47.546317] Test:  [150/345]  eta: 0:00:39  loss: 1.3428 (1.3428)  time: 0.2020  data: 0.0001  max mem: 14938
[18:14:49.574658] Test:  [160/345]  eta: 0:00:37  loss: 1.3429 (1.3429)  time: 0.2025  data: 0.0001  max mem: 14938
[18:14:51.608625] Test:  [170/345]  eta: 0:00:35  loss: 1.3426 (1.3428)  time: 0.2031  data: 0.0001  max mem: 14938
[18:14:53.648306] Test:  [180/345]  eta: 0:00:33  loss: 1.3412 (1.3427)  time: 0.2036  data: 0.0001  max mem: 14938
[18:14:55.693792] Test:  [190/345]  eta: 0:00:31  loss: 1.3423 (1.3427)  time: 0.2042  data: 0.0001  max mem: 14938
[18:14:57.743294] Test:  [200/345]  eta: 0:00:29  loss: 1.3428 (1.3428)  time: 0.2047  data: 0.0001  max mem: 14938
[18:14:59.799415] Test:  [210/345]  eta: 0:00:27  loss: 1.3427 (1.3427)  time: 0.2052  data: 0.0001  max mem: 14938
[18:15:01.859664] Test:  [220/345]  eta: 0:00:25  loss: 1.3418 (1.3427)  time: 0.2058  data: 0.0001  max mem: 14938
[18:15:03.926036] Test:  [230/345]  eta: 0:00:23  loss: 1.3439 (1.3428)  time: 0.2063  data: 0.0001  max mem: 14938
[18:15:05.997167] Test:  [240/345]  eta: 0:00:21  loss: 1.3441 (1.3428)  time: 0.2068  data: 0.0001  max mem: 14938
[18:15:08.074509] Test:  [250/345]  eta: 0:00:19  loss: 1.3432 (1.3428)  time: 0.2074  data: 0.0001  max mem: 14938
[18:15:10.153349] Test:  [260/345]  eta: 0:00:17  loss: 1.3429 (1.3428)  time: 0.2077  data: 0.0001  max mem: 14938
[18:15:12.240240] Test:  [270/345]  eta: 0:00:15  loss: 1.3437 (1.3429)  time: 0.2082  data: 0.0001  max mem: 14938
[18:15:14.331053] Test:  [280/345]  eta: 0:00:13  loss: 1.3448 (1.3429)  time: 0.2088  data: 0.0001  max mem: 14938
[18:15:16.425788] Test:  [290/345]  eta: 0:00:11  loss: 1.3435 (1.3429)  time: 0.2092  data: 0.0001  max mem: 14938
[18:15:18.527706] Test:  [300/345]  eta: 0:00:09  loss: 1.3427 (1.3429)  time: 0.2098  data: 0.0001  max mem: 14938
[18:15:20.635046] Test:  [310/345]  eta: 0:00:07  loss: 1.3421 (1.3429)  time: 0.2104  data: 0.0001  max mem: 14938
[18:15:22.746485] Test:  [320/345]  eta: 0:00:05  loss: 1.3428 (1.3429)  time: 0.2109  data: 0.0001  max mem: 14938
[18:15:24.866684] Test:  [330/345]  eta: 0:00:03  loss: 1.3440 (1.3429)  time: 0.2115  data: 0.0001  max mem: 14938
[18:15:26.987519] Test:  [340/345]  eta: 0:00:01  loss: 1.3432 (1.3429)  time: 0.2120  data: 0.0001  max mem: 14938
[18:15:27.837730] Test:  [344/345]  eta: 0:00:00  loss: 1.3435 (1.3429)  time: 0.2122  data: 0.0001  max mem: 14938
[18:15:27.900149] Test: Total time: 0:01:10 (0.2051 s / it)
[18:15:44.678982] Test:  [ 0/57]  eta: 0:00:29  loss: 1.3513 (1.3513)  time: 0.5107  data: 0.3142  max mem: 14938
[18:15:46.601091] Test:  [10/57]  eta: 0:00:10  loss: 1.3483 (1.3475)  time: 0.2211  data: 0.0286  max mem: 14938
[18:15:48.534350] Test:  [20/57]  eta: 0:00:07  loss: 1.3483 (1.3466)  time: 0.1927  data: 0.0001  max mem: 14938
[18:15:50.475974] Test:  [30/57]  eta: 0:00:05  loss: 1.3410 (1.3425)  time: 0.1937  data: 0.0001  max mem: 14938
[18:15:52.423836] Test:  [40/57]  eta: 0:00:03  loss: 1.3346 (1.3398)  time: 0.1944  data: 0.0001  max mem: 14938
[18:15:54.377489] Test:  [50/57]  eta: 0:00:01  loss: 1.3346 (1.3389)  time: 0.1950  data: 0.0001  max mem: 14938
[18:15:55.438317] Test:  [56/57]  eta: 0:00:00  loss: 1.3385 (1.3387)  time: 0.1896  data: 0.0001  max mem: 14938
[18:15:55.491924] Test: Total time: 0:00:11 (0.1987 s / it)
[18:15:58.336627] Dice score of the network on the train images: 0.000000, val images: 0.000000
[18:15:58.340626] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft

[18:15:59.462618] Epoch: [3]  [  0/345]  eta: 0:06:26  lr: 0.000019  loss: 1.3233 (1.3233)  time: 1.1209  data: 0.3594  max mem: 14938
[18:16:14.501376] Epoch: [3]  [ 20/345]  eta: 0:04:10  lr: 0.000019  loss: 1.3268 (1.3270)  time: 0.7519  data: 0.0001  max mem: 14938
[18:16:29.608956] Epoch: [3]  [ 40/345]  eta: 0:03:52  lr: 0.000019  loss: 1.3226 (1.3284)  time: 0.7553  data: 0.0001  max mem: 14938
[18:16:44.738122] Epoch: [3]  [ 60/345]  eta: 0:03:36  lr: 0.000020  loss: 1.3264 (1.3277)  time: 0.7564  data: 0.0001  max mem: 14938
[18:16:59.931368] Epoch: [3]  [ 80/345]  eta: 0:03:21  lr: 0.000020  loss: 1.3173 (1.3259)  time: 0.7596  data: 0.0001  max mem: 14938
[18:17:15.111056] Epoch: [3]  [100/345]  eta: 0:03:06  lr: 0.000021  loss: 1.3134 (1.3249)  time: 0.7589  data: 0.0001  max mem: 14938
[18:17:30.305420] Epoch: [3]  [120/345]  eta: 0:02:50  lr: 0.000021  loss: 1.3152 (1.3246)  time: 0.7597  data: 0.0001  max mem: 14938
[18:17:45.498931] Epoch: [3]  [140/345]  eta: 0:02:35  lr: 0.000021  loss: 1.3108 (1.3230)  time: 0.7596  data: 0.0001  max mem: 14938
[18:18:00.676030] Epoch: [3]  [160/345]  eta: 0:02:20  lr: 0.000022  loss: 1.3078 (1.3214)  time: 0.7588  data: 0.0001  max mem: 14938
[18:18:15.988575] Epoch: [3]  [180/345]  eta: 0:02:05  lr: 0.000022  loss: 1.3088 (1.3203)  time: 0.7656  data: 0.0001  max mem: 14938
[18:18:31.166099] Epoch: [3]  [200/345]  eta: 0:01:50  lr: 0.000022  loss: 1.3048 (1.3189)  time: 0.7588  data: 0.0001  max mem: 14938
[18:18:46.341243] Epoch: [3]  [220/345]  eta: 0:01:35  lr: 0.000023  loss: 1.3027 (1.3180)  time: 0.7587  data: 0.0001  max mem: 14938
[18:19:01.512502] Epoch: [3]  [240/345]  eta: 0:01:19  lr: 0.000023  loss: 1.2995 (1.3170)  time: 0.7585  data: 0.0001  max mem: 14938
[18:19:16.685731] Epoch: [3]  [260/345]  eta: 0:01:04  lr: 0.000023  loss: 1.2995 (1.3157)  time: 0.7586  data: 0.0001  max mem: 14938
[18:19:31.860988] Epoch: [3]  [280/345]  eta: 0:00:49  lr: 0.000024  loss: 1.2979 (1.3145)  time: 0.7587  data: 0.0001  max mem: 14938
[18:19:47.033776] Epoch: [3]  [300/345]  eta: 0:00:34  lr: 0.000024  loss: 1.2990 (1.3137)  time: 0.7586  data: 0.0001  max mem: 14938
[18:20:02.207936] Epoch: [3]  [320/345]  eta: 0:00:18  lr: 0.000025  loss: 1.2966 (1.3129)  time: 0.7587  data: 0.0001  max mem: 14938
[18:20:17.361434] Epoch: [3]  [340/345]  eta: 0:00:03  lr: 0.000025  loss: 1.2925 (1.3118)  time: 0.7576  data: 0.0001  max mem: 14938
[18:20:20.389924] Epoch: [3]  [344/345]  eta: 0:00:00  lr: 0.000025  loss: 1.2921 (1.3117)  time: 0.7576  data: 0.0001  max mem: 14938
[18:20:20.462996] Epoch: [3] Total time: 0:04:22 (0.7598 s / it)
[18:20:20.463235] Averaged stats: lr: 0.000025  loss: 1.2921 (1.3117)
[18:20:21.013768] Test:  [  0/345]  eta: 0:03:08  loss: 1.2997 (1.2997)  time: 0.5450  data: 0.3467  max mem: 14938
[18:20:22.966252] Test:  [ 10/345]  eta: 0:01:16  loss: 1.2923 (1.2930)  time: 0.2270  data: 0.0316  max mem: 14938
[18:20:24.923334] Test:  [ 20/345]  eta: 0:01:08  loss: 1.2913 (1.2919)  time: 0.1954  data: 0.0001  max mem: 14938
[18:20:26.886274] Test:  [ 30/345]  eta: 0:01:05  loss: 1.2906 (1.2920)  time: 0.1959  data: 0.0001  max mem: 14938
[18:20:28.852458] Test:  [ 40/345]  eta: 0:01:02  loss: 1.2919 (1.2919)  time: 0.1964  data: 0.0001  max mem: 14938
[18:20:30.827914] Test:  [ 50/345]  eta: 0:00:59  loss: 1.2920 (1.2919)  time: 0.1970  data: 0.0001  max mem: 14938
[18:20:32.806374] Test:  [ 60/345]  eta: 0:00:57  loss: 1.2908 (1.2917)  time: 0.1976  data: 0.0001  max mem: 14938
[18:20:34.786971] Test:  [ 70/345]  eta: 0:00:55  loss: 1.2919 (1.2918)  time: 0.1979  data: 0.0001  max mem: 14938
[18:20:36.774547] Test:  [ 80/345]  eta: 0:00:53  loss: 1.2919 (1.2916)  time: 0.1983  data: 0.0001  max mem: 14938
[18:20:38.769481] Test:  [ 90/345]  eta: 0:00:51  loss: 1.2894 (1.2914)  time: 0.1991  data: 0.0001  max mem: 14938
[18:20:40.768558] Test:  [100/345]  eta: 0:00:49  loss: 1.2891 (1.2913)  time: 0.1996  data: 0.0001  max mem: 14938
[18:20:42.772900] Test:  [110/345]  eta: 0:00:47  loss: 1.2893 (1.2913)  time: 0.2001  data: 0.0001  max mem: 14938
[18:20:44.781148] Test:  [120/345]  eta: 0:00:45  loss: 1.2916 (1.2913)  time: 0.2006  data: 0.0001  max mem: 14938
[18:20:46.794877] Test:  [130/345]  eta: 0:00:43  loss: 1.2901 (1.2910)  time: 0.2010  data: 0.0001  max mem: 14938
[18:20:48.814464] Test:  [140/345]  eta: 0:00:41  loss: 1.2901 (1.2911)  time: 0.2016  data: 0.0001  max mem: 14938
[18:20:50.840927] Test:  [150/345]  eta: 0:00:39  loss: 1.2919 (1.2910)  time: 0.2022  data: 0.0001  max mem: 14938
[18:20:52.869974] Test:  [160/345]  eta: 0:00:37  loss: 1.2914 (1.2911)  time: 0.2027  data: 0.0001  max mem: 14938
[18:20:54.904563] Test:  [170/345]  eta: 0:00:35  loss: 1.2905 (1.2911)  time: 0.2031  data: 0.0001  max mem: 14938
[18:20:56.942629] Test:  [180/345]  eta: 0:00:33  loss: 1.2898 (1.2910)  time: 0.2036  data: 0.0001  max mem: 14938
[18:20:58.987911] Test:  [190/345]  eta: 0:00:31  loss: 1.2908 (1.2910)  time: 0.2041  data: 0.0001  max mem: 14938
[18:21:01.037039] Test:  [200/345]  eta: 0:00:29  loss: 1.2921 (1.2911)  time: 0.2047  data: 0.0001  max mem: 14938
[18:21:03.092305] Test:  [210/345]  eta: 0:00:27  loss: 1.2921 (1.2910)  time: 0.2052  data: 0.0001  max mem: 14938
[18:21:05.153197] Test:  [220/345]  eta: 0:00:25  loss: 1.2897 (1.2910)  time: 0.2058  data: 0.0001  max mem: 14938
[18:21:07.218375] Test:  [230/345]  eta: 0:00:23  loss: 1.2896 (1.2909)  time: 0.2062  data: 0.0001  max mem: 14938
[18:21:09.288168] Test:  [240/345]  eta: 0:00:21  loss: 1.2870 (1.2909)  time: 0.2067  data: 0.0001  max mem: 14938
[18:21:11.362654] Test:  [250/345]  eta: 0:00:19  loss: 1.2916 (1.2910)  time: 0.2072  data: 0.0001  max mem: 14938
[18:21:13.444200] Test:  [260/345]  eta: 0:00:17  loss: 1.2918 (1.2910)  time: 0.2077  data: 0.0001  max mem: 14938
[18:21:15.528740] Test:  [270/345]  eta: 0:00:15  loss: 1.2911 (1.2910)  time: 0.2082  data: 0.0001  max mem: 14938
[18:21:17.622223] Test:  [280/345]  eta: 0:00:13  loss: 1.2900 (1.2909)  time: 0.2088  data: 0.0001  max mem: 14938
[18:21:19.715878] Test:  [290/345]  eta: 0:00:11  loss: 1.2917 (1.2909)  time: 0.2093  data: 0.0001  max mem: 14938
[18:21:21.815676] Test:  [300/345]  eta: 0:00:09  loss: 1.2930 (1.2910)  time: 0.2096  data: 0.0001  max mem: 14938
[18:21:23.919657] Test:  [310/345]  eta: 0:00:07  loss: 1.2930 (1.2910)  time: 0.2101  data: 0.0001  max mem: 14938
[18:21:26.032996] Test:  [320/345]  eta: 0:00:05  loss: 1.2897 (1.2910)  time: 0.2108  data: 0.0001  max mem: 14938
[18:21:28.148216] Test:  [330/345]  eta: 0:00:03  loss: 1.2894 (1.2909)  time: 0.2114  data: 0.0001  max mem: 14938
[18:21:30.266724] Test:  [340/345]  eta: 0:00:01  loss: 1.2907 (1.2910)  time: 0.2116  data: 0.0001  max mem: 14938
[18:21:31.117472] Test:  [344/345]  eta: 0:00:00  loss: 1.2895 (1.2909)  time: 0.2119  data: 0.0001  max mem: 14938
[18:21:31.180131] Test: Total time: 0:01:10 (0.2050 s / it)
[18:21:47.829314] Test:  [ 0/57]  eta: 0:00:30  loss: 1.3046 (1.3046)  time: 0.5381  data: 0.3421  max mem: 14938
[18:21:49.752081] Test:  [10/57]  eta: 0:00:10  loss: 1.2991 (1.2982)  time: 0.2236  data: 0.0312  max mem: 14938
[18:21:51.688088] Test:  [20/57]  eta: 0:00:07  loss: 1.2991 (1.2975)  time: 0.1929  data: 0.0001  max mem: 14938
[18:21:53.626580] Test:  [30/57]  eta: 0:00:05  loss: 1.2836 (1.2898)  time: 0.1937  data: 0.0001  max mem: 14938
[18:21:55.572071] Test:  [40/57]  eta: 0:00:03  loss: 1.2723 (1.2847)  time: 0.1941  data: 0.0001  max mem: 14938
[18:21:57.523624] Test:  [50/57]  eta: 0:00:01  loss: 1.2723 (1.2829)  time: 0.1948  data: 0.0001  max mem: 14938
[18:21:58.584920] Test:  [56/57]  eta: 0:00:00  loss: 1.2797 (1.2826)  time: 0.1895  data: 0.0000  max mem: 14938
[18:21:58.649816] Test: Total time: 0:00:11 (0.1993 s / it)
[18:22:01.460600] Dice score of the network on the train images: 0.000000, val images: 0.000000
[18:22:01.464674] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:22:02.561275] Epoch: [4]  [  0/345]  eta: 0:06:17  lr: 0.000025  loss: 1.2985 (1.2985)  time: 1.0955  data: 0.3316  max mem: 14938
[18:22:17.580998] Epoch: [4]  [ 20/345]  eta: 0:04:09  lr: 0.000025  loss: 1.2864 (1.2910)  time: 0.7509  data: 0.0001  max mem: 14938
[18:22:32.690391] Epoch: [4]  [ 40/345]  eta: 0:03:52  lr: 0.000026  loss: 1.2881 (1.2895)  time: 0.7554  data: 0.0001  max mem: 14938
[18:22:47.819126] Epoch: [4]  [ 60/345]  eta: 0:03:36  lr: 0.000026  loss: 1.2772 (1.2875)  time: 0.7564  data: 0.0001  max mem: 14938
[18:23:02.994400] Epoch: [4]  [ 80/345]  eta: 0:03:21  lr: 0.000026  loss: 1.2739 (1.2849)  time: 0.7587  data: 0.0001  max mem: 14938
[18:23:18.181673] Epoch: [4]  [100/345]  eta: 0:03:06  lr: 0.000027  loss: 1.2696 (1.2826)  time: 0.7593  data: 0.0001  max mem: 14938
[18:23:33.367454] Epoch: [4]  [120/345]  eta: 0:02:50  lr: 0.000027  loss: 1.2637 (1.2795)  time: 0.7593  data: 0.0001  max mem: 14938
[18:23:48.560783] Epoch: [4]  [140/345]  eta: 0:02:35  lr: 0.000028  loss: 1.2582 (1.2768)  time: 0.7596  data: 0.0001  max mem: 14938
[18:24:03.729743] Epoch: [4]  [160/345]  eta: 0:02:20  lr: 0.000028  loss: 1.2646 (1.2751)  time: 0.7584  data: 0.0001  max mem: 14938
[18:24:18.925138] Epoch: [4]  [180/345]  eta: 0:02:05  lr: 0.000028  loss: 1.2414 (1.2719)  time: 0.7597  data: 0.0001  max mem: 14938
[18:24:34.088968] Epoch: [4]  [200/345]  eta: 0:01:50  lr: 0.000029  loss: 1.2340 (1.2682)  time: 0.7581  data: 0.0001  max mem: 14938
[18:24:49.237651] Epoch: [4]  [220/345]  eta: 0:01:34  lr: 0.000029  loss: 1.2286 (1.2650)  time: 0.7574  data: 0.0001  max mem: 14938
[18:25:04.387814] Epoch: [4]  [240/345]  eta: 0:01:19  lr: 0.000029  loss: 1.2204 (1.2613)  time: 0.7575  data: 0.0001  max mem: 14938
[18:25:19.542463] Epoch: [4]  [260/345]  eta: 0:01:04  lr: 0.000030  loss: 1.2115 (1.2577)  time: 0.7577  data: 0.0001  max mem: 14938
[18:25:34.712437] Epoch: [4]  [280/345]  eta: 0:00:49  lr: 0.000030  loss: 1.2044 (1.2539)  time: 0.7585  data: 0.0001  max mem: 14938
[18:25:49.881419] Epoch: [4]  [300/345]  eta: 0:00:34  lr: 0.000030  loss: 1.1858 (1.2498)  time: 0.7584  data: 0.0001  max mem: 14938
[18:26:05.049730] Epoch: [4]  [320/345]  eta: 0:00:18  lr: 0.000031  loss: 1.1772 (1.2456)  time: 0.7584  data: 0.0001  max mem: 14938
[18:26:20.190822] Epoch: [4]  [340/345]  eta: 0:00:03  lr: 0.000031  loss: 1.1820 (1.2419)  time: 0.7570  data: 0.0001  max mem: 14938
[18:26:23.218437] Epoch: [4]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 1.1820 (1.2414)  time: 0.7564  data: 0.0001  max mem: 14938
[18:26:23.288904] Epoch: [4] Total time: 0:04:21 (0.7589 s / it)
[18:26:23.289530] Averaged stats: lr: 0.000031  loss: 1.1820 (1.2414)
[18:26:23.851265] Test:  [  0/345]  eta: 0:03:12  loss: 1.1810 (1.1810)  time: 0.5567  data: 0.3586  max mem: 14938
[18:26:25.802531] Test:  [ 10/345]  eta: 0:01:16  loss: 1.1654 (1.1609)  time: 0.2279  data: 0.0327  max mem: 14938
[18:26:27.761632] Test:  [ 20/345]  eta: 0:01:09  loss: 1.1552 (1.1595)  time: 0.1954  data: 0.0001  max mem: 14938
[18:26:29.726180] Test:  [ 30/345]  eta: 0:01:05  loss: 1.1525 (1.1535)  time: 0.1961  data: 0.0001  max mem: 14938
[18:26:31.693953] Test:  [ 40/345]  eta: 0:01:02  loss: 1.1525 (1.1557)  time: 0.1966  data: 0.0001  max mem: 14938
[18:26:33.668070] Test:  [ 50/345]  eta: 0:00:59  loss: 1.1540 (1.1538)  time: 0.1970  data: 0.0001  max mem: 14938
[18:26:35.649126] Test:  [ 60/345]  eta: 0:00:57  loss: 1.1503 (1.1540)  time: 0.1977  data: 0.0001  max mem: 14938
[18:26:37.631537] Test:  [ 70/345]  eta: 0:00:55  loss: 1.1500 (1.1533)  time: 0.1981  data: 0.0001  max mem: 14938
[18:26:39.617364] Test:  [ 80/345]  eta: 0:00:53  loss: 1.1454 (1.1525)  time: 0.1984  data: 0.0001  max mem: 14938
[18:26:41.612750] Test:  [ 90/345]  eta: 0:00:51  loss: 1.1498 (1.1528)  time: 0.1990  data: 0.0001  max mem: 14938
[18:26:43.611308] Test:  [100/345]  eta: 0:00:49  loss: 1.1518 (1.1521)  time: 0.1996  data: 0.0001  max mem: 14938
[18:26:45.616846] Test:  [110/345]  eta: 0:00:47  loss: 1.1518 (1.1527)  time: 0.2001  data: 0.0001  max mem: 14938
[18:26:47.622048] Test:  [120/345]  eta: 0:00:45  loss: 1.1478 (1.1521)  time: 0.2005  data: 0.0001  max mem: 14938
[18:26:49.634655] Test:  [130/345]  eta: 0:00:43  loss: 1.1433 (1.1508)  time: 0.2008  data: 0.0001  max mem: 14938
[18:26:51.651641] Test:  [140/345]  eta: 0:00:41  loss: 1.1492 (1.1512)  time: 0.2014  data: 0.0001  max mem: 14938
[18:26:53.674762] Test:  [150/345]  eta: 0:00:39  loss: 1.1551 (1.1516)  time: 0.2019  data: 0.0001  max mem: 14938
[18:26:55.702170] Test:  [160/345]  eta: 0:00:37  loss: 1.1493 (1.1503)  time: 0.2025  data: 0.0001  max mem: 14938
[18:26:57.734999] Test:  [170/345]  eta: 0:00:35  loss: 1.1455 (1.1508)  time: 0.2030  data: 0.0001  max mem: 14938
[18:26:59.773320] Test:  [180/345]  eta: 0:00:33  loss: 1.1460 (1.1504)  time: 0.2035  data: 0.0001  max mem: 14938
[18:27:01.814339] Test:  [190/345]  eta: 0:00:31  loss: 1.1446 (1.1501)  time: 0.2039  data: 0.0001  max mem: 14938
[18:27:03.864974] Test:  [200/345]  eta: 0:00:29  loss: 1.1537 (1.1505)  time: 0.2045  data: 0.0001  max mem: 14938
[18:27:05.916803] Test:  [210/345]  eta: 0:00:27  loss: 1.1621 (1.1512)  time: 0.2051  data: 0.0001  max mem: 14938
[18:27:07.976366] Test:  [220/345]  eta: 0:00:25  loss: 1.1644 (1.1517)  time: 0.2055  data: 0.0001  max mem: 14938
[18:27:10.042579] Test:  [230/345]  eta: 0:00:23  loss: 1.1526 (1.1517)  time: 0.2062  data: 0.0001  max mem: 14938
[18:27:12.113166] Test:  [240/345]  eta: 0:00:21  loss: 1.1596 (1.1522)  time: 0.2068  data: 0.0001  max mem: 14938
[18:27:14.187919] Test:  [250/345]  eta: 0:00:19  loss: 1.1621 (1.1523)  time: 0.2072  data: 0.0001  max mem: 14938
[18:27:16.267096] Test:  [260/345]  eta: 0:00:17  loss: 1.1583 (1.1524)  time: 0.2076  data: 0.0001  max mem: 14938
[18:27:18.353034] Test:  [270/345]  eta: 0:00:15  loss: 1.1547 (1.1525)  time: 0.2082  data: 0.0001  max mem: 14938
[18:27:20.444134] Test:  [280/345]  eta: 0:00:13  loss: 1.1565 (1.1531)  time: 0.2088  data: 0.0001  max mem: 14938
[18:27:22.539444] Test:  [290/345]  eta: 0:00:11  loss: 1.1693 (1.1537)  time: 0.2093  data: 0.0001  max mem: 14938
[18:27:24.637147] Test:  [300/345]  eta: 0:00:09  loss: 1.1537 (1.1536)  time: 0.2096  data: 0.0001  max mem: 14938
[18:27:26.742844] Test:  [310/345]  eta: 0:00:07  loss: 1.1514 (1.1538)  time: 0.2101  data: 0.0001  max mem: 14938
[18:27:28.854859] Test:  [320/345]  eta: 0:00:05  loss: 1.1514 (1.1536)  time: 0.2108  data: 0.0001  max mem: 14938
[18:27:30.972012] Test:  [330/345]  eta: 0:00:03  loss: 1.1551 (1.1537)  time: 0.2114  data: 0.0001  max mem: 14938
[18:27:33.092632] Test:  [340/345]  eta: 0:00:01  loss: 1.1593 (1.1537)  time: 0.2118  data: 0.0001  max mem: 14938
[18:27:33.942462] Test:  [344/345]  eta: 0:00:00  loss: 1.1551 (1.1535)  time: 0.2121  data: 0.0001  max mem: 14938
[18:27:34.004473] Test: Total time: 0:01:10 (0.2050 s / it)
[18:27:50.959571] Test:  [ 0/57]  eta: 0:00:31  loss: 1.2301 (1.2301)  time: 0.5472  data: 0.3523  max mem: 14938
[18:27:52.879516] Test:  [10/57]  eta: 0:00:10  loss: 1.2047 (1.1939)  time: 0.2242  data: 0.0321  max mem: 14938
[18:27:54.813842] Test:  [20/57]  eta: 0:00:07  loss: 1.2152 (1.1954)  time: 0.1926  data: 0.0001  max mem: 14938
[18:27:56.753753] Test:  [30/57]  eta: 0:00:05  loss: 1.1274 (1.1483)  time: 0.1936  data: 0.0001  max mem: 14938
[18:27:58.698602] Test:  [40/57]  eta: 0:00:03  loss: 1.0376 (1.1185)  time: 0.1942  data: 0.0001  max mem: 14938
[18:28:00.650248] Test:  [50/57]  eta: 0:00:01  loss: 1.0402 (1.1100)  time: 0.1948  data: 0.0001  max mem: 14938
[18:28:01.710488] Test:  [56/57]  eta: 0:00:00  loss: 1.0973 (1.1140)  time: 0.1895  data: 0.0001  max mem: 14938
[18:28:01.774292] Test: Total time: 0:00:11 (0.1993 s / it)
[18:28:04.592871] Dice score of the network on the train images: 0.503894, val images: 0.604222
[18:28:04.593081] saving best_prec_model_0 @ epoch 4
[18:28:05.310662] saving best_rec_model_0 @ epoch 4
[18:28:06.000411] saving best_dice_model_0 @ epoch 4
[18:28:07.043870] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:28:08.147300] Epoch: [5]  [  0/345]  eta: 0:06:20  lr: 0.000031  loss: 1.2067 (1.2067)  time: 1.1025  data: 0.3413  max mem: 14938
[18:28:23.176571] Epoch: [5]  [ 20/345]  eta: 0:04:09  lr: 0.000032  loss: 1.1559 (1.1633)  time: 0.7514  data: 0.0001  max mem: 14938
[18:28:38.276804] Epoch: [5]  [ 40/345]  eta: 0:03:52  lr: 0.000032  loss: 1.1516 (1.1596)  time: 0.7550  data: 0.0001  max mem: 14938
[18:28:53.433649] Epoch: [5]  [ 60/345]  eta: 0:03:36  lr: 0.000032  loss: 1.1607 (1.1604)  time: 0.7578  data: 0.0001  max mem: 14938
[18:29:08.606051] Epoch: [5]  [ 80/345]  eta: 0:03:21  lr: 0.000033  loss: 1.1415 (1.1572)  time: 0.7586  data: 0.0001  max mem: 14938
[18:29:23.789649] Epoch: [5]  [100/345]  eta: 0:03:06  lr: 0.000033  loss: 1.1394 (1.1538)  time: 0.7591  data: 0.0001  max mem: 14938
[18:29:38.989074] Epoch: [5]  [120/345]  eta: 0:02:50  lr: 0.000033  loss: 1.1145 (1.1488)  time: 0.7599  data: 0.0001  max mem: 14938
[18:29:54.181711] Epoch: [5]  [140/345]  eta: 0:02:35  lr: 0.000034  loss: 1.1219 (1.1450)  time: 0.7596  data: 0.0001  max mem: 14938
[18:30:09.371481] Epoch: [5]  [160/345]  eta: 0:02:20  lr: 0.000034  loss: 1.1243 (1.1421)  time: 0.7594  data: 0.0001  max mem: 14938
[18:30:24.565913] Epoch: [5]  [180/345]  eta: 0:02:05  lr: 0.000035  loss: 1.1249 (1.1398)  time: 0.7597  data: 0.0001  max mem: 14938
[18:30:39.750494] Epoch: [5]  [200/345]  eta: 0:01:50  lr: 0.000035  loss: 1.0985 (1.1364)  time: 0.7592  data: 0.0001  max mem: 14938
[18:30:54.924852] Epoch: [5]  [220/345]  eta: 0:01:34  lr: 0.000035  loss: 1.0900 (1.1322)  time: 0.7587  data: 0.0001  max mem: 14938
[18:31:10.106251] Epoch: [5]  [240/345]  eta: 0:01:19  lr: 0.000036  loss: 1.0830 (1.1285)  time: 0.7590  data: 0.0001  max mem: 14938
[18:31:25.271631] Epoch: [5]  [260/345]  eta: 0:01:04  lr: 0.000036  loss: 1.0778 (1.1251)  time: 0.7582  data: 0.0001  max mem: 14938
[18:31:40.437318] Epoch: [5]  [280/345]  eta: 0:00:49  lr: 0.000036  loss: 1.0883 (1.1231)  time: 0.7582  data: 0.0001  max mem: 14938
[18:31:55.698904] Epoch: [5]  [300/345]  eta: 0:00:34  lr: 0.000037  loss: 1.0670 (1.1192)  time: 0.7630  data: 0.0001  max mem: 14938
[18:32:10.870313] Epoch: [5]  [320/345]  eta: 0:00:18  lr: 0.000037  loss: 1.0665 (1.1165)  time: 0.7585  data: 0.0001  max mem: 14938
[18:32:26.030642] Epoch: [5]  [340/345]  eta: 0:00:03  lr: 0.000037  loss: 1.0663 (1.1136)  time: 0.7580  data: 0.0001  max mem: 14938
[18:32:29.063852] Epoch: [5]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 1.0669 (1.1129)  time: 0.7579  data: 0.0001  max mem: 14938
[18:32:29.126136] Epoch: [5] Total time: 0:04:22 (0.7597 s / it)
[18:32:29.126439] Averaged stats: lr: 0.000037  loss: 1.0669 (1.1129)
[18:32:29.726714] Test:  [  0/345]  eta: 0:03:25  loss: 0.9758 (0.9758)  time: 0.5961  data: 0.3975  max mem: 14938
[18:32:31.676712] Test:  [ 10/345]  eta: 0:01:17  loss: 1.0169 (1.0126)  time: 0.2314  data: 0.0362  max mem: 14938
[18:32:33.635808] Test:  [ 20/345]  eta: 0:01:09  loss: 1.0177 (1.0166)  time: 0.1954  data: 0.0001  max mem: 14938
[18:32:35.598126] Test:  [ 30/345]  eta: 0:01:05  loss: 1.0218 (1.0212)  time: 0.1960  data: 0.0001  max mem: 14938
[18:32:37.567518] Test:  [ 40/345]  eta: 0:01:02  loss: 1.0181 (1.0198)  time: 0.1965  data: 0.0001  max mem: 14938
[18:32:39.540264] Test:  [ 50/345]  eta: 0:01:00  loss: 1.0149 (1.0204)  time: 0.1970  data: 0.0001  max mem: 14938
[18:32:41.517949] Test:  [ 60/345]  eta: 0:00:57  loss: 1.0092 (1.0188)  time: 0.1975  data: 0.0001  max mem: 14938
[18:32:43.500792] Test:  [ 70/345]  eta: 0:00:55  loss: 1.0140 (1.0201)  time: 0.1980  data: 0.0001  max mem: 14938
[18:32:45.489326] Test:  [ 80/345]  eta: 0:00:53  loss: 1.0203 (1.0202)  time: 0.1985  data: 0.0001  max mem: 14938
[18:32:47.480415] Test:  [ 90/345]  eta: 0:00:51  loss: 1.0116 (1.0194)  time: 0.1989  data: 0.0001  max mem: 14938
[18:32:49.477008] Test:  [100/345]  eta: 0:00:49  loss: 1.0116 (1.0187)  time: 0.1993  data: 0.0001  max mem: 14938
[18:32:51.480274] Test:  [110/345]  eta: 0:00:47  loss: 1.0093 (1.0182)  time: 0.1999  data: 0.0001  max mem: 14938
[18:32:53.483157] Test:  [120/345]  eta: 0:00:45  loss: 1.0158 (1.0181)  time: 0.2002  data: 0.0001  max mem: 14938
[18:32:55.496426] Test:  [130/345]  eta: 0:00:43  loss: 1.0223 (1.0189)  time: 0.2007  data: 0.0001  max mem: 14938
[18:32:57.518188] Test:  [140/345]  eta: 0:00:41  loss: 1.0289 (1.0197)  time: 0.2017  data: 0.0001  max mem: 14938
[18:32:59.539585] Test:  [150/345]  eta: 0:00:39  loss: 1.0289 (1.0199)  time: 0.2021  data: 0.0001  max mem: 14938
[18:33:01.565563] Test:  [160/345]  eta: 0:00:37  loss: 1.0264 (1.0196)  time: 0.2023  data: 0.0001  max mem: 14938
[18:33:03.597810] Test:  [170/345]  eta: 0:00:35  loss: 1.0148 (1.0195)  time: 0.2029  data: 0.0001  max mem: 14938
[18:33:05.637386] Test:  [180/345]  eta: 0:00:33  loss: 1.0176 (1.0195)  time: 0.2035  data: 0.0001  max mem: 14938
[18:33:07.679107] Test:  [190/345]  eta: 0:00:31  loss: 1.0168 (1.0192)  time: 0.2040  data: 0.0001  max mem: 14938
[18:33:09.729229] Test:  [200/345]  eta: 0:00:29  loss: 1.0264 (1.0199)  time: 0.2045  data: 0.0001  max mem: 14938
[18:33:11.783426] Test:  [210/345]  eta: 0:00:27  loss: 1.0285 (1.0199)  time: 0.2052  data: 0.0001  max mem: 14938
[18:33:13.845832] Test:  [220/345]  eta: 0:00:25  loss: 1.0044 (1.0190)  time: 0.2058  data: 0.0001  max mem: 14938
[18:33:15.910762] Test:  [230/345]  eta: 0:00:23  loss: 1.0045 (1.0186)  time: 0.2063  data: 0.0001  max mem: 14938
[18:33:17.978179] Test:  [240/345]  eta: 0:00:21  loss: 1.0182 (1.0192)  time: 0.2066  data: 0.0001  max mem: 14938
[18:33:20.055702] Test:  [250/345]  eta: 0:00:19  loss: 1.0276 (1.0192)  time: 0.2072  data: 0.0001  max mem: 14938
[18:33:22.136492] Test:  [260/345]  eta: 0:00:17  loss: 1.0274 (1.0197)  time: 0.2078  data: 0.0001  max mem: 14938
[18:33:24.222764] Test:  [270/345]  eta: 0:00:15  loss: 1.0288 (1.0198)  time: 0.2083  data: 0.0001  max mem: 14938
[18:33:26.312173] Test:  [280/345]  eta: 0:00:13  loss: 1.0288 (1.0201)  time: 0.2087  data: 0.0001  max mem: 14938
[18:33:28.406890] Test:  [290/345]  eta: 0:00:11  loss: 1.0125 (1.0204)  time: 0.2091  data: 0.0001  max mem: 14938
[18:33:30.507533] Test:  [300/345]  eta: 0:00:09  loss: 1.0257 (1.0210)  time: 0.2097  data: 0.0001  max mem: 14938
[18:33:32.609522] Test:  [310/345]  eta: 0:00:07  loss: 1.0219 (1.0208)  time: 0.2101  data: 0.0001  max mem: 14938
[18:33:34.719052] Test:  [320/345]  eta: 0:00:05  loss: 1.0131 (1.0207)  time: 0.2105  data: 0.0001  max mem: 14938
[18:33:36.836433] Test:  [330/345]  eta: 0:00:03  loss: 1.0143 (1.0207)  time: 0.2113  data: 0.0001  max mem: 14938
[18:33:38.956564] Test:  [340/345]  eta: 0:00:01  loss: 1.0148 (1.0203)  time: 0.2118  data: 0.0001  max mem: 14938
[18:33:39.806901] Test:  [344/345]  eta: 0:00:00  loss: 1.0148 (1.0204)  time: 0.2120  data: 0.0001  max mem: 14938
[18:33:39.863107] Test: Total time: 0:01:10 (0.2050 s / it)
[18:33:56.480559] Test:  [ 0/57]  eta: 0:00:29  loss: 1.1072 (1.1072)  time: 0.5112  data: 0.3148  max mem: 14938
[18:33:58.401559] Test:  [10/57]  eta: 0:00:10  loss: 1.0802 (1.0730)  time: 0.2210  data: 0.0287  max mem: 14938
[18:34:00.336379] Test:  [20/57]  eta: 0:00:07  loss: 1.1058 (1.0794)  time: 0.1927  data: 0.0001  max mem: 14938
[18:34:02.275229] Test:  [30/57]  eta: 0:00:05  loss: 0.9617 (1.0229)  time: 0.1936  data: 0.0001  max mem: 14938
[18:34:04.220045] Test:  [40/57]  eta: 0:00:03  loss: 0.8892 (0.9889)  time: 0.1941  data: 0.0001  max mem: 14938
[18:34:06.170333] Test:  [50/57]  eta: 0:00:01  loss: 0.8892 (0.9791)  time: 0.1947  data: 0.0001  max mem: 14938
[18:34:07.232481] Test:  [56/57]  eta: 0:00:00  loss: 0.9669 (0.9842)  time: 0.1895  data: 0.0001  max mem: 14938
[18:34:07.293765] Test: Total time: 0:00:11 (0.1987 s / it)
[18:34:10.061046] Dice score of the network on the train images: 0.628202, val images: 0.692939
[18:34:10.061282] saving best_prec_model_0 @ epoch 5
[18:34:11.146877] saving best_dice_model_0 @ epoch 5
[18:34:12.173008] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:34:13.296835] Epoch: [6]  [  0/345]  eta: 0:06:27  lr: 0.000038  loss: 1.0378 (1.0378)  time: 1.1230  data: 0.3652  max mem: 14938
[18:34:28.339904] Epoch: [6]  [ 20/345]  eta: 0:04:10  lr: 0.000038  loss: 1.0475 (1.0480)  time: 0.7521  data: 0.0001  max mem: 14938
[18:34:43.414038] Epoch: [6]  [ 40/345]  eta: 0:03:52  lr: 0.000038  loss: 1.0442 (1.0500)  time: 0.7537  data: 0.0001  max mem: 14938
[18:34:58.550461] Epoch: [6]  [ 60/345]  eta: 0:03:36  lr: 0.000039  loss: 1.0405 (1.0453)  time: 0.7568  data: 0.0001  max mem: 14938
[18:35:13.717052] Epoch: [6]  [ 80/345]  eta: 0:03:21  lr: 0.000039  loss: 1.0378 (1.0424)  time: 0.7583  data: 0.0001  max mem: 14938
[18:35:28.909275] Epoch: [6]  [100/345]  eta: 0:03:06  lr: 0.000039  loss: 1.0325 (1.0420)  time: 0.7596  data: 0.0001  max mem: 14938
[18:35:44.098845] Epoch: [6]  [120/345]  eta: 0:02:50  lr: 0.000040  loss: 1.0199 (1.0392)  time: 0.7594  data: 0.0001  max mem: 14938
[18:35:59.292394] Epoch: [6]  [140/345]  eta: 0:02:35  lr: 0.000040  loss: 1.0411 (1.0393)  time: 0.7596  data: 0.0001  max mem: 14938
[18:36:14.497847] Epoch: [6]  [160/345]  eta: 0:02:20  lr: 0.000040  loss: 1.0084 (1.0355)  time: 0.7602  data: 0.0001  max mem: 14938
[18:36:29.684607] Epoch: [6]  [180/345]  eta: 0:02:05  lr: 0.000041  loss: 1.0078 (1.0327)  time: 0.7593  data: 0.0001  max mem: 14938
[18:36:44.867304] Epoch: [6]  [200/345]  eta: 0:01:50  lr: 0.000041  loss: 1.0064 (1.0305)  time: 0.7591  data: 0.0001  max mem: 14938
[18:37:00.063511] Epoch: [6]  [220/345]  eta: 0:01:34  lr: 0.000041  loss: 1.0109 (1.0290)  time: 0.7598  data: 0.0001  max mem: 14938
[18:37:15.252943] Epoch: [6]  [240/345]  eta: 0:01:19  lr: 0.000042  loss: 0.9969 (1.0263)  time: 0.7594  data: 0.0001  max mem: 14938
[18:37:30.437073] Epoch: [6]  [260/345]  eta: 0:01:04  lr: 0.000042  loss: 0.9859 (1.0245)  time: 0.7592  data: 0.0001  max mem: 14938
[18:37:45.605061] Epoch: [6]  [280/345]  eta: 0:00:49  lr: 0.000043  loss: 0.9757 (1.0211)  time: 0.7584  data: 0.0001  max mem: 14938
[18:38:00.795189] Epoch: [6]  [300/345]  eta: 0:00:34  lr: 0.000043  loss: 0.9781 (1.0188)  time: 0.7595  data: 0.0001  max mem: 14938
[18:38:15.975610] Epoch: [6]  [320/345]  eta: 0:00:18  lr: 0.000043  loss: 0.9759 (1.0167)  time: 0.7590  data: 0.0001  max mem: 14938
[18:38:31.155801] Epoch: [6]  [340/345]  eta: 0:00:03  lr: 0.000044  loss: 0.9708 (1.0147)  time: 0.7590  data: 0.0001  max mem: 14938
[18:38:34.191504] Epoch: [6]  [344/345]  eta: 0:00:00  lr: 0.000044  loss: 0.9840 (1.0146)  time: 0.7588  data: 0.0001  max mem: 14938
[18:38:34.255838] Epoch: [6] Total time: 0:04:22 (0.7597 s / it)
[18:38:34.256207] Averaged stats: lr: 0.000044  loss: 0.9840 (1.0146)
[18:38:34.833831] Test:  [  0/345]  eta: 0:03:17  loss: 0.9601 (0.9601)  time: 0.5721  data: 0.3742  max mem: 14938
[18:38:36.789150] Test:  [ 10/345]  eta: 0:01:16  loss: 0.9504 (0.9510)  time: 0.2297  data: 0.0341  max mem: 14938
[18:38:38.747249] Test:  [ 20/345]  eta: 0:01:09  loss: 0.9615 (0.9614)  time: 0.1956  data: 0.0001  max mem: 14938
[18:38:40.710423] Test:  [ 30/345]  eta: 0:01:05  loss: 0.9633 (0.9599)  time: 0.1960  data: 0.0001  max mem: 14938
[18:38:42.678119] Test:  [ 40/345]  eta: 0:01:02  loss: 0.9649 (0.9636)  time: 0.1965  data: 0.0001  max mem: 14938
[18:38:44.651293] Test:  [ 50/345]  eta: 0:01:00  loss: 0.9653 (0.9608)  time: 0.1970  data: 0.0001  max mem: 14938
[18:38:46.632967] Test:  [ 60/345]  eta: 0:00:57  loss: 0.9484 (0.9595)  time: 0.1977  data: 0.0001  max mem: 14938
[18:38:48.616496] Test:  [ 70/345]  eta: 0:00:55  loss: 0.9711 (0.9629)  time: 0.1982  data: 0.0001  max mem: 14938
[18:38:50.604254] Test:  [ 80/345]  eta: 0:00:53  loss: 0.9804 (0.9652)  time: 0.1985  data: 0.0001  max mem: 14938
[18:38:52.596567] Test:  [ 90/345]  eta: 0:00:51  loss: 0.9672 (0.9653)  time: 0.1989  data: 0.0001  max mem: 14938
[18:38:54.596108] Test:  [100/345]  eta: 0:00:49  loss: 0.9514 (0.9639)  time: 0.1995  data: 0.0001  max mem: 14938
[18:38:56.600044] Test:  [110/345]  eta: 0:00:47  loss: 0.9504 (0.9631)  time: 0.2001  data: 0.0001  max mem: 14938
[18:38:58.607758] Test:  [120/345]  eta: 0:00:45  loss: 0.9513 (0.9628)  time: 0.2005  data: 0.0001  max mem: 14938
[18:39:00.623628] Test:  [130/345]  eta: 0:00:43  loss: 0.9429 (0.9622)  time: 0.2011  data: 0.0001  max mem: 14938
[18:39:02.643857] Test:  [140/345]  eta: 0:00:41  loss: 0.9429 (0.9611)  time: 0.2017  data: 0.0001  max mem: 14938
[18:39:04.666300] Test:  [150/345]  eta: 0:00:39  loss: 0.9535 (0.9616)  time: 0.2021  data: 0.0001  max mem: 14938
[18:39:06.696419] Test:  [160/345]  eta: 0:00:37  loss: 0.9460 (0.9612)  time: 0.2026  data: 0.0001  max mem: 14938
[18:39:08.733893] Test:  [170/345]  eta: 0:00:35  loss: 0.9430 (0.9618)  time: 0.2033  data: 0.0001  max mem: 14938
[18:39:10.774463] Test:  [180/345]  eta: 0:00:33  loss: 0.9692 (0.9612)  time: 0.2038  data: 0.0001  max mem: 14938
[18:39:12.821148] Test:  [190/345]  eta: 0:00:31  loss: 0.9455 (0.9602)  time: 0.2043  data: 0.0001  max mem: 14938
[18:39:14.870753] Test:  [200/345]  eta: 0:00:29  loss: 0.9456 (0.9599)  time: 0.2047  data: 0.0001  max mem: 14938
[18:39:16.927105] Test:  [210/345]  eta: 0:00:27  loss: 0.9630 (0.9609)  time: 0.2052  data: 0.0001  max mem: 14938
[18:39:18.987864] Test:  [220/345]  eta: 0:00:25  loss: 0.9623 (0.9604)  time: 0.2058  data: 0.0001  max mem: 14938
[18:39:21.055174] Test:  [230/345]  eta: 0:00:23  loss: 0.9461 (0.9600)  time: 0.2063  data: 0.0001  max mem: 14938
[18:39:23.125994] Test:  [240/345]  eta: 0:00:21  loss: 0.9577 (0.9600)  time: 0.2068  data: 0.0001  max mem: 14938
[18:39:25.201245] Test:  [250/345]  eta: 0:00:19  loss: 0.9594 (0.9597)  time: 0.2072  data: 0.0001  max mem: 14938
[18:39:27.282361] Test:  [260/345]  eta: 0:00:17  loss: 0.9329 (0.9590)  time: 0.2078  data: 0.0001  max mem: 14938
[18:39:29.367079] Test:  [270/345]  eta: 0:00:15  loss: 0.9503 (0.9592)  time: 0.2082  data: 0.0001  max mem: 14938
[18:39:31.458117] Test:  [280/345]  eta: 0:00:13  loss: 0.9677 (0.9594)  time: 0.2087  data: 0.0001  max mem: 14938
[18:39:33.555478] Test:  [290/345]  eta: 0:00:11  loss: 0.9555 (0.9588)  time: 0.2094  data: 0.0001  max mem: 14938

[18:39:35.658509] Test:  [300/345]  eta: 0:00:09  loss: 0.9473 (0.9587)  time: 0.2100  data: 0.0001  max mem: 14938
[18:39:37.767987] Test:  [310/345]  eta: 0:00:07  loss: 0.9576 (0.9584)  time: 0.2106  data: 0.0001  max mem: 14938
[18:39:39.882227] Test:  [320/345]  eta: 0:00:05  loss: 0.9576 (0.9586)  time: 0.2111  data: 0.0001  max mem: 14938
[18:39:42.001046] Test:  [330/345]  eta: 0:00:03  loss: 0.9558 (0.9583)  time: 0.2116  data: 0.0001  max mem: 14938
[18:39:44.121988] Test:  [340/345]  eta: 0:00:01  loss: 0.9505 (0.9580)  time: 0.2119  data: 0.0001  max mem: 14938
[18:39:44.971854] Test:  [344/345]  eta: 0:00:00  loss: 0.9505 (0.9578)  time: 0.2121  data: 0.0001  max mem: 14938
[18:39:45.033380] Test: Total time: 0:01:10 (0.2051 s / it)
[18:40:01.612091] Test:  [ 0/57]  eta: 0:00:31  loss: 1.0563 (1.0563)  time: 0.5510  data: 0.3570  max mem: 14938
[18:40:03.536735] Test:  [10/57]  eta: 0:00:10  loss: 1.0176 (1.0172)  time: 0.2250  data: 0.0325  max mem: 14938
[18:40:05.471533] Test:  [20/57]  eta: 0:00:07  loss: 0.9996 (1.0069)  time: 0.1929  data: 0.0001  max mem: 14938
[18:40:07.410286] Test:  [30/57]  eta: 0:00:05  loss: 0.9140 (0.9585)  time: 0.1936  data: 0.0001  max mem: 14938
[18:40:09.357993] Test:  [40/57]  eta: 0:00:03  loss: 0.8352 (0.9290)  time: 0.1943  data: 0.0001  max mem: 14938
[18:40:11.307763] Test:  [50/57]  eta: 0:00:01  loss: 0.8352 (0.9200)  time: 0.1948  data: 0.0001  max mem: 14938
[18:40:12.370180] Test:  [56/57]  eta: 0:00:00  loss: 0.8972 (0.9247)  time: 0.1895  data: 0.0000  max mem: 14938
[18:40:12.439443] Test: Total time: 0:00:11 (0.1996 s / it)
[18:40:15.220161] Dice score of the network on the train images: 0.638874, val images: 0.711040
[18:40:15.220383] saving best_prec_model_0 @ epoch 6
[18:40:16.236024] saving best_dice_model_0 @ epoch 6
[18:40:17.356126] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:40:18.472328] Epoch: [7]  [  0/345]  eta: 0:06:24  lr: 0.000044  loss: 0.9419 (0.9419)  time: 1.1152  data: 0.3545  max mem: 14938
[18:40:33.487626] Epoch: [7]  [ 20/345]  eta: 0:04:09  lr: 0.000044  loss: 0.9616 (0.9690)  time: 0.7507  data: 0.0001  max mem: 14938
[18:40:48.571933] Epoch: [7]  [ 40/345]  eta: 0:03:52  lr: 0.000044  loss: 0.9687 (0.9698)  time: 0.7542  data: 0.0001  max mem: 14938

[18:41:03.732802] Epoch: [7]  [ 60/345]  eta: 0:03:36  lr: 0.000045  loss: 0.9564 (0.9662)  time: 0.7580  data: 0.0001  max mem: 14938
[18:41:18.887974] Epoch: [7]  [ 80/345]  eta: 0:03:21  lr: 0.000045  loss: 0.9632 (0.9649)  time: 0.7577  data: 0.0001  max mem: 14938
[18:41:34.088816] Epoch: [7]  [100/345]  eta: 0:03:06  lr: 0.000046  loss: 0.9730 (0.9694)  time: 0.7600  data: 0.0001  max mem: 14938
[18:41:49.290674] Epoch: [7]  [120/345]  eta: 0:02:50  lr: 0.000046  loss: 0.9696 (0.9692)  time: 0.7601  data: 0.0001  max mem: 14938
[18:42:04.478329] Epoch: [7]  [140/345]  eta: 0:02:35  lr: 0.000046  loss: 0.9589 (0.9675)  time: 0.7593  data: 0.0001  max mem: 14938
[18:42:19.661001] Epoch: [7]  [160/345]  eta: 0:02:20  lr: 0.000047  loss: 0.9562 (0.9661)  time: 0.7591  data: 0.0001  max mem: 14938
[18:42:34.843963] Epoch: [7]  [180/345]  eta: 0:02:05  lr: 0.000047  loss: 0.9496 (0.9657)  time: 0.7591  data: 0.0001  max mem: 14938
[18:42:50.045831] Epoch: [7]  [200/345]  eta: 0:01:50  lr: 0.000047  loss: 0.9423 (0.9635)  time: 0.7601  data: 0.0001  max mem: 14938
[18:43:05.326865] Epoch: [7]  [220/345]  eta: 0:01:35  lr: 0.000048  loss: 0.9392 (0.9619)  time: 0.7640  data: 0.0001  max mem: 14938
[18:43:20.497931] Epoch: [7]  [240/345]  eta: 0:01:19  lr: 0.000048  loss: 0.9356 (0.9595)  time: 0.7585  data: 0.0001  max mem: 14938
[18:43:35.689739] Epoch: [7]  [260/345]  eta: 0:01:04  lr: 0.000048  loss: 0.9234 (0.9569)  time: 0.7595  data: 0.0001  max mem: 14938
[18:43:50.885221] Epoch: [7]  [280/345]  eta: 0:00:49  lr: 0.000049  loss: 0.9302 (0.9554)  time: 0.7597  data: 0.0001  max mem: 14938
[18:44:06.069789] Epoch: [7]  [300/345]  eta: 0:00:34  lr: 0.000049  loss: 0.9289 (0.9536)  time: 0.7591  data: 0.0001  max mem: 14938
[18:44:21.259092] Epoch: [7]  [320/345]  eta: 0:00:18  lr: 0.000050  loss: 0.9348 (0.9527)  time: 0.7594  data: 0.0001  max mem: 14938
[18:44:36.438859] Epoch: [7]  [340/345]  eta: 0:00:03  lr: 0.000050  loss: 0.9231 (0.9513)  time: 0.7589  data: 0.0001  max mem: 14938
[18:44:39.473385] Epoch: [7]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.9197 (0.9509)  time: 0.7589  data: 0.0001  max mem: 14938
[18:44:39.538241] Epoch: [7] Total time: 0:04:22 (0.7599 s / it)
[18:44:39.538675] Averaged stats: lr: 0.000050  loss: 0.9197 (0.9509)
[18:44:40.126975] Test:  [  0/345]  eta: 0:03:21  loss: 0.8658 (0.8658)  time: 0.5829  data: 0.3846  max mem: 14938
[18:44:42.078657] Test:  [ 10/345]  eta: 0:01:17  loss: 0.8658 (0.8651)  time: 0.2303  data: 0.0350  max mem: 14938
[18:44:44.038824] Test:  [ 20/345]  eta: 0:01:09  loss: 0.8691 (0.8743)  time: 0.1955  data: 0.0001  max mem: 14938
[18:44:46.001069] Test:  [ 30/345]  eta: 0:01:05  loss: 0.8691 (0.8726)  time: 0.1961  data: 0.0001  max mem: 14938
[18:44:47.969835] Test:  [ 40/345]  eta: 0:01:02  loss: 0.8565 (0.8659)  time: 0.1965  data: 0.0001  max mem: 14938
[18:44:49.942499] Test:  [ 50/345]  eta: 0:01:00  loss: 0.8658 (0.8676)  time: 0.1970  data: 0.0001  max mem: 14938
[18:44:51.922170] Test:  [ 60/345]  eta: 0:00:57  loss: 0.8658 (0.8690)  time: 0.1976  data: 0.0001  max mem: 14938
[18:44:53.906388] Test:  [ 70/345]  eta: 0:00:55  loss: 0.8612 (0.8679)  time: 0.1981  data: 0.0001  max mem: 14938
[18:44:55.895791] Test:  [ 80/345]  eta: 0:00:53  loss: 0.8619 (0.8681)  time: 0.1986  data: 0.0001  max mem: 14938
[18:44:57.891946] Test:  [ 90/345]  eta: 0:00:51  loss: 0.8619 (0.8685)  time: 0.1992  data: 0.0001  max mem: 14938
[18:44:59.893521] Test:  [100/345]  eta: 0:00:49  loss: 0.8681 (0.8691)  time: 0.1998  data: 0.0001  max mem: 14938
[18:45:01.899994] Test:  [110/345]  eta: 0:00:47  loss: 0.8769 (0.8701)  time: 0.2003  data: 0.0001  max mem: 14938
[18:45:03.906436] Test:  [120/345]  eta: 0:00:45  loss: 0.8804 (0.8705)  time: 0.2006  data: 0.0001  max mem: 14938
[18:45:05.922799] Test:  [130/345]  eta: 0:00:43  loss: 0.8745 (0.8707)  time: 0.2011  data: 0.0001  max mem: 14938
[18:45:07.940502] Test:  [140/345]  eta: 0:00:41  loss: 0.8636 (0.8692)  time: 0.2016  data: 0.0001  max mem: 14938
[18:45:09.963605] Test:  [150/345]  eta: 0:00:39  loss: 0.8712 (0.8706)  time: 0.2020  data: 0.0001  max mem: 14938
[18:45:11.993271] Test:  [160/345]  eta: 0:00:37  loss: 0.8867 (0.8709)  time: 0.2026  data: 0.0001  max mem: 14938

[18:45:14.027298] Test:  [170/345]  eta: 0:00:35  loss: 0.8737 (0.8710)  time: 0.2031  data: 0.0001  max mem: 14938
[18:45:16.065338] Test:  [180/345]  eta: 0:00:33  loss: 0.8737 (0.8715)  time: 0.2035  data: 0.0001  max mem: 14938
[18:45:18.109043] Test:  [190/345]  eta: 0:00:31  loss: 0.8712 (0.8708)  time: 0.2040  data: 0.0001  max mem: 14938
[18:45:20.160028] Test:  [200/345]  eta: 0:00:29  loss: 0.8597 (0.8706)  time: 0.2047  data: 0.0001  max mem: 14938
[18:45:22.215905] Test:  [210/345]  eta: 0:00:27  loss: 0.8662 (0.8705)  time: 0.2053  data: 0.0001  max mem: 14938
[18:45:24.274526] Test:  [220/345]  eta: 0:00:25  loss: 0.8674 (0.8707)  time: 0.2057  data: 0.0001  max mem: 14938
[18:45:26.340655] Test:  [230/345]  eta: 0:00:23  loss: 0.8719 (0.8710)  time: 0.2062  data: 0.0001  max mem: 14938
[18:45:28.412592] Test:  [240/345]  eta: 0:00:21  loss: 0.8761 (0.8715)  time: 0.2068  data: 0.0001  max mem: 14938
[18:45:30.487798] Test:  [250/345]  eta: 0:00:19  loss: 0.8695 (0.8708)  time: 0.2073  data: 0.0001  max mem: 14938
[18:45:32.569132] Test:  [260/345]  eta: 0:00:17  loss: 0.8588 (0.8707)  time: 0.2078  data: 0.0001  max mem: 14938
[18:45:34.653900] Test:  [270/345]  eta: 0:00:15  loss: 0.8619 (0.8709)  time: 0.2082  data: 0.0001  max mem: 14938
[18:45:36.745506] Test:  [280/345]  eta: 0:00:13  loss: 0.8648 (0.8710)  time: 0.2088  data: 0.0001  max mem: 14938
[18:45:38.843924] Test:  [290/345]  eta: 0:00:11  loss: 0.8708 (0.8712)  time: 0.2094  data: 0.0001  max mem: 14938
[18:45:40.949797] Test:  [300/345]  eta: 0:00:09  loss: 0.8754 (0.8713)  time: 0.2102  data: 0.0001  max mem: 14938
[18:45:43.057744] Test:  [310/345]  eta: 0:00:07  loss: 0.8754 (0.8716)  time: 0.2106  data: 0.0001  max mem: 14938
[18:45:45.173433] Test:  [320/345]  eta: 0:00:05  loss: 0.8752 (0.8719)  time: 0.2111  data: 0.0001  max mem: 14938
[18:45:47.291126] Test:  [330/345]  eta: 0:00:03  loss: 0.8674 (0.8717)  time: 0.2116  data: 0.0001  max mem: 14938
[18:45:49.411806] Test:  [340/345]  eta: 0:00:01  loss: 0.8718 (0.8717)  time: 0.2119  data: 0.0001  max mem: 14938
[18:45:50.261372] Test:  [344/345]  eta: 0:00:00  loss: 0.8759 (0.8719)  time: 0.2120  data: 0.0001  max mem: 14938
[18:45:50.325631] Test: Total time: 0:01:10 (0.2052 s / it)
[18:46:07.065882] Test:  [ 0/57]  eta: 0:00:33  loss: 0.9785 (0.9785)  time: 0.5854  data: 0.3913  max mem: 14938
[18:46:08.991980] Test:  [10/57]  eta: 0:00:10  loss: 0.9305 (0.9364)  time: 0.2282  data: 0.0356  max mem: 14938
[18:46:10.926288] Test:  [20/57]  eta: 0:00:07  loss: 0.9305 (0.9329)  time: 0.1930  data: 0.0001  max mem: 14938
[18:46:12.867366] Test:  [30/57]  eta: 0:00:05  loss: 0.8253 (0.8885)  time: 0.1937  data: 0.0001  max mem: 14938
[18:46:14.814666] Test:  [40/57]  eta: 0:00:03  loss: 0.7918 (0.8620)  time: 0.1944  data: 0.0001  max mem: 14938
[18:46:16.767027] Test:  [50/57]  eta: 0:00:01  loss: 0.7918 (0.8539)  time: 0.1949  data: 0.0001  max mem: 14938
[18:46:17.829269] Test:  [56/57]  eta: 0:00:00  loss: 0.8265 (0.8587)  time: 0.1897  data: 0.0001  max mem: 14938
[18:46:17.880173] Test: Total time: 0:00:11 (0.2000 s / it)
[18:46:20.669615] Dice score of the network on the train images: 0.670574, val images: 0.739594
[18:46:20.669832] saving best_prec_model_0 @ epoch 7
[18:46:21.685690] saving best_dice_model_0 @ epoch 7
[18:46:22.707234] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:46:23.857968] Epoch: [8]  [  0/345]  eta: 0:06:36  lr: 0.000050  loss: 0.9390 (0.9390)  time: 1.1497  data: 0.3894  max mem: 14938
[18:46:38.894899] Epoch: [8]  [ 20/345]  eta: 0:04:10  lr: 0.000050  loss: 0.9128 (0.9225)  time: 0.7518  data: 0.0001  max mem: 14938
[18:46:53.973974] Epoch: [8]  [ 40/345]  eta: 0:03:52  lr: 0.000051  loss: 0.9069 (0.9199)  time: 0.7539  data: 0.0001  max mem: 14938
[18:47:09.127334] Epoch: [8]  [ 60/345]  eta: 0:03:36  lr: 0.000051  loss: 0.9222 (0.9234)  time: 0.7576  data: 0.0001  max mem: 14938
[18:47:24.315858] Epoch: [8]  [ 80/345]  eta: 0:03:21  lr: 0.000051  loss: 0.9206 (0.9216)  time: 0.7594  data: 0.0001  max mem: 14938
[18:47:39.516908] Epoch: [8]  [100/345]  eta: 0:03:06  lr: 0.000052  loss: 0.9157 (0.9212)  time: 0.7600  data: 0.0001  max mem: 14938
[18:47:54.711008] Epoch: [8]  [120/345]  eta: 0:02:51  lr: 0.000052  loss: 0.9197 (0.9206)  time: 0.7597  data: 0.0001  max mem: 14938
[18:48:09.903593] Epoch: [8]  [140/345]  eta: 0:02:35  lr: 0.000053  loss: 0.9314 (0.9218)  time: 0.7596  data: 0.0001  max mem: 14938
[18:48:25.099983] Epoch: [8]  [160/345]  eta: 0:02:20  lr: 0.000053  loss: 0.9126 (0.9209)  time: 0.7598  data: 0.0001  max mem: 14938

[18:48:40.296812] Epoch: [8]  [180/345]  eta: 0:02:05  lr: 0.000053  loss: 0.8998 (0.9199)  time: 0.7598  data: 0.0001  max mem: 14938
[18:48:55.494499] Epoch: [8]  [200/345]  eta: 0:01:50  lr: 0.000054  loss: 0.8899 (0.9174)  time: 0.7598  data: 0.0001  max mem: 14938
[18:49:10.684898] Epoch: [8]  [220/345]  eta: 0:01:35  lr: 0.000054  loss: 0.8890 (0.9153)  time: 0.7595  data: 0.0001  max mem: 14938
[18:49:25.876206] Epoch: [8]  [240/345]  eta: 0:01:19  lr: 0.000054  loss: 0.9003 (0.9142)  time: 0.7595  data: 0.0001  max mem: 14938
[18:49:41.058738] Epoch: [8]  [260/345]  eta: 0:01:04  lr: 0.000055  loss: 0.8973 (0.9137)  time: 0.7591  data: 0.0001  max mem: 14938
[18:49:56.245665] Epoch: [8]  [280/345]  eta: 0:00:49  lr: 0.000055  loss: 0.9022 (0.9127)  time: 0.7593  data: 0.0001  max mem: 14938
[18:50:11.433879] Epoch: [8]  [300/345]  eta: 0:00:34  lr: 0.000055  loss: 0.8902 (0.9114)  time: 0.7594  data: 0.0001  max mem: 14938
[18:50:26.621258] Epoch: [8]  [320/345]  eta: 0:00:18  lr: 0.000056  loss: 0.8824 (0.9103)  time: 0.7593  data: 0.0001  max mem: 14938
[18:50:41.812166] Epoch: [8]  [340/345]  eta: 0:00:03  lr: 0.000056  loss: 0.8808 (0.9086)  time: 0.7595  data: 0.0001  max mem: 14938
[18:50:44.850630] Epoch: [8]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.8808 (0.9083)  time: 0.7594  data: 0.0001  max mem: 14938
[18:50:44.918023] Epoch: [8] Total time: 0:04:22 (0.7600 s / it)
[18:50:44.918433] Averaged stats: lr: 0.000056  loss: 0.8808 (0.9083)
[18:50:45.472869] Test:  [  0/345]  eta: 0:03:09  loss: 0.8720 (0.8720)  time: 0.5493  data: 0.3508  max mem: 14938
[18:50:47.427093] Test:  [ 10/345]  eta: 0:01:16  loss: 0.8446 (0.8457)  time: 0.2275  data: 0.0320  max mem: 14938
[18:50:49.387774] Test:  [ 20/345]  eta: 0:01:09  loss: 0.8334 (0.8364)  time: 0.1957  data: 0.0001  max mem: 14938
[18:50:51.356264] Test:  [ 30/345]  eta: 0:01:05  loss: 0.8403 (0.8404)  time: 0.1964  data: 0.0001  max mem: 14938
[18:50:53.329762] Test:  [ 40/345]  eta: 0:01:02  loss: 0.8495 (0.8435)  time: 0.1970  data: 0.0001  max mem: 14938
[18:50:55.304254] Test:  [ 50/345]  eta: 0:01:00  loss: 0.8459 (0.8427)  time: 0.1973  data: 0.0001  max mem: 14938
[18:50:57.286439] Test:  [ 60/345]  eta: 0:00:57  loss: 0.8398 (0.8442)  time: 0.1978  data: 0.0001  max mem: 14938
[18:50:59.270886] Test:  [ 70/345]  eta: 0:00:55  loss: 0.8478 (0.8453)  time: 0.1983  data: 0.0001  max mem: 14938
[18:51:01.262036] Test:  [ 80/345]  eta: 0:00:53  loss: 0.8497 (0.8455)  time: 0.1987  data: 0.0001  max mem: 14938
[18:51:03.261309] Test:  [ 90/345]  eta: 0:00:51  loss: 0.8497 (0.8470)  time: 0.1995  data: 0.0001  max mem: 14938
[18:51:05.264803] Test:  [100/345]  eta: 0:00:49  loss: 0.8463 (0.8467)  time: 0.2001  data: 0.0001  max mem: 14938
[18:51:07.271070] Test:  [110/345]  eta: 0:00:47  loss: 0.8463 (0.8473)  time: 0.2004  data: 0.0001  max mem: 14938
[18:51:09.281226] Test:  [120/345]  eta: 0:00:45  loss: 0.8585 (0.8474)  time: 0.2008  data: 0.0001  max mem: 14938
[18:51:11.295532] Test:  [130/345]  eta: 0:00:43  loss: 0.8283 (0.8466)  time: 0.2012  data: 0.0001  max mem: 14938
[18:51:13.315245] Test:  [140/345]  eta: 0:00:41  loss: 0.8424 (0.8471)  time: 0.2016  data: 0.0001  max mem: 14938
[18:51:15.341860] Test:  [150/345]  eta: 0:00:39  loss: 0.8424 (0.8469)  time: 0.2023  data: 0.0001  max mem: 14938
[18:51:17.372498] Test:  [160/345]  eta: 0:00:37  loss: 0.8373 (0.8470)  time: 0.2028  data: 0.0001  max mem: 14938
[18:51:19.410915] Test:  [170/345]  eta: 0:00:35  loss: 0.8594 (0.8479)  time: 0.2034  data: 0.0001  max mem: 14938
[18:51:21.450172] Test:  [180/345]  eta: 0:00:33  loss: 0.8516 (0.8474)  time: 0.2038  data: 0.0001  max mem: 14938
[18:51:23.495438] Test:  [190/345]  eta: 0:00:31  loss: 0.8488 (0.8478)  time: 0.2042  data: 0.0001  max mem: 14938
[18:51:25.549755] Test:  [200/345]  eta: 0:00:29  loss: 0.8453 (0.8472)  time: 0.2049  data: 0.0001  max mem: 14938
[18:51:27.607073] Test:  [210/345]  eta: 0:00:27  loss: 0.8453 (0.8474)  time: 0.2055  data: 0.0001  max mem: 14938
[18:51:29.670943] Test:  [220/345]  eta: 0:00:25  loss: 0.8483 (0.8473)  time: 0.2060  data: 0.0001  max mem: 14938
[18:51:31.738697] Test:  [230/345]  eta: 0:00:23  loss: 0.8472 (0.8480)  time: 0.2065  data: 0.0001  max mem: 14938
[18:51:33.810176] Test:  [240/345]  eta: 0:00:21  loss: 0.8527 (0.8479)  time: 0.2069  data: 0.0001  max mem: 14938
[18:51:35.886823] Test:  [250/345]  eta: 0:00:19  loss: 0.8413 (0.8474)  time: 0.2073  data: 0.0001  max mem: 14938
[18:51:37.969163] Test:  [260/345]  eta: 0:00:17  loss: 0.8515 (0.8480)  time: 0.2079  data: 0.0001  max mem: 14938
[18:51:40.054245] Test:  [270/345]  eta: 0:00:15  loss: 0.8567 (0.8479)  time: 0.2083  data: 0.0001  max mem: 14938
[18:51:42.146040] Test:  [280/345]  eta: 0:00:13  loss: 0.8567 (0.8487)  time: 0.2088  data: 0.0001  max mem: 14938
[18:51:44.243181] Test:  [290/345]  eta: 0:00:11  loss: 0.8544 (0.8490)  time: 0.2094  data: 0.0001  max mem: 14938
[18:51:46.347267] Test:  [300/345]  eta: 0:00:09  loss: 0.8515 (0.8492)  time: 0.2100  data: 0.0001  max mem: 14938
[18:51:48.454647] Test:  [310/345]  eta: 0:00:07  loss: 0.8535 (0.8494)  time: 0.2105  data: 0.0001  max mem: 14938
[18:51:50.566478] Test:  [320/345]  eta: 0:00:05  loss: 0.8316 (0.8488)  time: 0.2109  data: 0.0001  max mem: 14938
[18:51:52.686071] Test:  [330/345]  eta: 0:00:03  loss: 0.8389 (0.8487)  time: 0.2115  data: 0.0001  max mem: 14938
[18:51:54.808478] Test:  [340/345]  eta: 0:00:01  loss: 0.8483 (0.8492)  time: 0.2120  data: 0.0001  max mem: 14938
[18:51:55.658641] Test:  [344/345]  eta: 0:00:00  loss: 0.8606 (0.8494)  time: 0.2122  data: 0.0001  max mem: 14938
[18:51:55.720398] Test: Total time: 0:01:10 (0.2052 s / it)
[18:52:12.387122] Test:  [ 0/57]  eta: 0:00:29  loss: 0.9241 (0.9241)  time: 0.5173  data: 0.3209  max mem: 14938
[18:52:14.311007] Test:  [10/57]  eta: 0:00:10  loss: 0.9034 (0.9113)  time: 0.2218  data: 0.0292  max mem: 14938
[18:52:16.244678] Test:  [20/57]  eta: 0:00:07  loss: 0.8971 (0.9036)  time: 0.1928  data: 0.0001  max mem: 14938
[18:52:18.184733] Test:  [30/57]  eta: 0:00:05  loss: 0.8241 (0.8659)  time: 0.1936  data: 0.0001  max mem: 14938
[18:52:20.132106] Test:  [40/57]  eta: 0:00:03  loss: 0.7753 (0.8431)  time: 0.1943  data: 0.0001  max mem: 14938
[18:52:22.085051] Test:  [50/57]  eta: 0:00:01  loss: 0.7753 (0.8361)  time: 0.1950  data: 0.0001  max mem: 14938
[18:52:23.148144] Test:  [56/57]  eta: 0:00:00  loss: 0.8172 (0.8422)  time: 0.1898  data: 0.0000  max mem: 14938
[18:52:23.208498] Test: Total time: 0:00:11 (0.1989 s / it)
[18:52:25.970343] Dice score of the network on the train images: 0.665125, val images: 0.745915
[18:52:25.970578] saving best_rec_model_0 @ epoch 8
[18:52:26.995472] saving best_dice_model_0 @ epoch 8
[18:52:28.012481] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:52:29.159236] Epoch: [9]  [  0/345]  eta: 0:06:35  lr: 0.000056  loss: 0.8764 (0.8764)  time: 1.1455  data: 0.3814  max mem: 14938
[18:52:44.217731] Epoch: [9]  [ 20/345]  eta: 0:04:10  lr: 0.000057  loss: 0.8676 (0.8785)  time: 0.7529  data: 0.0001  max mem: 14938
[18:52:59.342337] Epoch: [9]  [ 40/345]  eta: 0:03:53  lr: 0.000057  loss: 0.9144 (0.8905)  time: 0.7562  data: 0.0001  max mem: 14938
[18:53:14.507920] Epoch: [9]  [ 60/345]  eta: 0:03:37  lr: 0.000057  loss: 0.8905 (0.8923)  time: 0.7582  data: 0.0001  max mem: 14938
[18:53:29.708716] Epoch: [9]  [ 80/345]  eta: 0:03:21  lr: 0.000058  loss: 0.8755 (0.8898)  time: 0.7600  data: 0.0001  max mem: 14938
[18:53:44.904710] Epoch: [9]  [100/345]  eta: 0:03:06  lr: 0.000058  loss: 0.8843 (0.8884)  time: 0.7598  data: 0.0001  max mem: 14938
[18:54:00.095976] Epoch: [9]  [120/345]  eta: 0:02:51  lr: 0.000058  loss: 0.8740 (0.8879)  time: 0.7595  data: 0.0001  max mem: 14938
[18:54:15.289197] Epoch: [9]  [140/345]  eta: 0:02:35  lr: 0.000059  loss: 0.8813 (0.8866)  time: 0.7596  data: 0.0001  max mem: 14938
[18:54:30.507883] Epoch: [9]  [160/345]  eta: 0:02:20  lr: 0.000059  loss: 0.8808 (0.8853)  time: 0.7609  data: 0.0001  max mem: 14938
[18:54:45.712023] Epoch: [9]  [180/345]  eta: 0:02:05  lr: 0.000060  loss: 0.8871 (0.8858)  time: 0.7602  data: 0.0001  max mem: 14938
[18:55:00.914101] Epoch: [9]  [200/345]  eta: 0:01:50  lr: 0.000060  loss: 0.8767 (0.8846)  time: 0.7601  data: 0.0001  max mem: 14938
[18:55:16.109788] Epoch: [9]  [220/345]  eta: 0:01:35  lr: 0.000060  loss: 0.8790 (0.8844)  time: 0.7597  data: 0.0001  max mem: 14938
[18:55:31.303759] Epoch: [9]  [240/345]  eta: 0:01:19  lr: 0.000061  loss: 0.8541 (0.8827)  time: 0.7597  data: 0.0001  max mem: 14938
[18:55:46.500850] Epoch: [9]  [260/345]  eta: 0:01:04  lr: 0.000061  loss: 0.8893 (0.8835)  time: 0.7598  data: 0.0001  max mem: 14938
[18:56:01.695690] Epoch: [9]  [280/345]  eta: 0:00:49  lr: 0.000061  loss: 0.8814 (0.8832)  time: 0.7597  data: 0.0001  max mem: 14938
[18:56:16.890453] Epoch: [9]  [300/345]  eta: 0:00:34  lr: 0.000062  loss: 0.8760 (0.8825)  time: 0.7597  data: 0.0001  max mem: 14938
[18:56:32.085381] Epoch: [9]  [320/345]  eta: 0:00:19  lr: 0.000062  loss: 0.8734 (0.8821)  time: 0.7597  data: 0.0001  max mem: 14938
[18:56:47.278362] Epoch: [9]  [340/345]  eta: 0:00:03  lr: 0.000062  loss: 0.8691 (0.8816)  time: 0.7596  data: 0.0001  max mem: 14938
[18:56:50.315020] Epoch: [9]  [344/345]  eta: 0:00:00  lr: 0.000062  loss: 0.8572 (0.8814)  time: 0.7595  data: 0.0001  max mem: 14938
[18:56:50.378097] Epoch: [9] Total time: 0:04:22 (0.7605 s / it)
[18:56:50.378616] Averaged stats: lr: 0.000062  loss: 0.8572 (0.8814)
[18:56:50.959796] Test:  [  0/345]  eta: 0:03:19  loss: 0.8447 (0.8447)  time: 0.5769  data: 0.3787  max mem: 14938
[18:56:52.915072] Test:  [ 10/345]  eta: 0:01:17  loss: 0.8441 (0.8394)  time: 0.2301  data: 0.0345  max mem: 14938
[18:56:54.878244] Test:  [ 20/345]  eta: 0:01:09  loss: 0.8347 (0.8361)  time: 0.1958  data: 0.0001  max mem: 14938
[18:56:56.844063] Test:  [ 30/345]  eta: 0:01:05  loss: 0.8211 (0.8319)  time: 0.1964  data: 0.0001  max mem: 14938
[18:56:58.814561] Test:  [ 40/345]  eta: 0:01:02  loss: 0.8287 (0.8345)  time: 0.1968  data: 0.0001  max mem: 14938
[18:57:00.789935] Test:  [ 50/345]  eta: 0:01:00  loss: 0.8443 (0.8371)  time: 0.1972  data: 0.0001  max mem: 14938
[18:57:02.772573] Test:  [ 60/345]  eta: 0:00:57  loss: 0.8323 (0.8347)  time: 0.1978  data: 0.0001  max mem: 14938
[18:57:04.759257] Test:  [ 70/345]  eta: 0:00:55  loss: 0.8169 (0.8345)  time: 0.1984  data: 0.0001  max mem: 14938
[18:57:06.747847] Test:  [ 80/345]  eta: 0:00:53  loss: 0.8169 (0.8326)  time: 0.1987  data: 0.0001  max mem: 14938
[18:57:08.745066] Test:  [ 90/345]  eta: 0:00:51  loss: 0.8236 (0.8329)  time: 0.1992  data: 0.0001  max mem: 14938
[18:57:10.747282] Test:  [100/345]  eta: 0:00:49  loss: 0.8282 (0.8329)  time: 0.1999  data: 0.0001  max mem: 14938
[18:57:12.751728] Test:  [110/345]  eta: 0:00:47  loss: 0.8203 (0.8326)  time: 0.2003  data: 0.0001  max mem: 14938
[18:57:14.763937] Test:  [120/345]  eta: 0:00:45  loss: 0.8243 (0.8331)  time: 0.2008  data: 0.0001  max mem: 14938
[18:57:16.779838] Test:  [130/345]  eta: 0:00:43  loss: 0.8292 (0.8330)  time: 0.2013  data: 0.0001  max mem: 14938
[18:57:18.799851] Test:  [140/345]  eta: 0:00:41  loss: 0.8257 (0.8320)  time: 0.2017  data: 0.0001  max mem: 14938
[18:57:20.825798] Test:  [150/345]  eta: 0:00:39  loss: 0.8199 (0.8319)  time: 0.2022  data: 0.0001  max mem: 14938
[18:57:22.855860] Test:  [160/345]  eta: 0:00:37  loss: 0.8237 (0.8317)  time: 0.2027  data: 0.0001  max mem: 14938

[18:57:24.894517] Test:  [170/345]  eta: 0:00:35  loss: 0.8346 (0.8324)  time: 0.2034  data: 0.0001  max mem: 14938
[18:57:26.935893] Test:  [180/345]  eta: 0:00:33  loss: 0.8412 (0.8332)  time: 0.2039  data: 0.0001  max mem: 14938
[18:57:28.984241] Test:  [190/345]  eta: 0:00:31  loss: 0.8333 (0.8330)  time: 0.2044  data: 0.0001  max mem: 14938
[18:57:31.035991] Test:  [200/345]  eta: 0:00:29  loss: 0.8290 (0.8328)  time: 0.2049  data: 0.0001  max mem: 14938
[18:57:33.092994] Test:  [210/345]  eta: 0:00:27  loss: 0.8370 (0.8328)  time: 0.2054  data: 0.0001  max mem: 14938
[18:57:35.154766] Test:  [220/345]  eta: 0:00:25  loss: 0.8370 (0.8330)  time: 0.2059  data: 0.0001  max mem: 14938
[18:57:37.221850] Test:  [230/345]  eta: 0:00:23  loss: 0.8447 (0.8337)  time: 0.2064  data: 0.0001  max mem: 14938
[18:57:39.292825] Test:  [240/345]  eta: 0:00:21  loss: 0.8447 (0.8340)  time: 0.2068  data: 0.0001  max mem: 14938
[18:57:41.370241] Test:  [250/345]  eta: 0:00:19  loss: 0.8313 (0.8341)  time: 0.2073  data: 0.0001  max mem: 14938
[18:57:43.449623] Test:  [260/345]  eta: 0:00:17  loss: 0.8291 (0.8339)  time: 0.2078  data: 0.0001  max mem: 14938
[18:57:45.537724] Test:  [270/345]  eta: 0:00:15  loss: 0.8275 (0.8336)  time: 0.2083  data: 0.0001  max mem: 14938
[18:57:47.629586] Test:  [280/345]  eta: 0:00:13  loss: 0.8294 (0.8337)  time: 0.2089  data: 0.0001  max mem: 14938
[18:57:49.726487] Test:  [290/345]  eta: 0:00:11  loss: 0.8253 (0.8335)  time: 0.2094  data: 0.0001  max mem: 14938
[18:57:51.826951] Test:  [300/345]  eta: 0:00:09  loss: 0.8222 (0.8333)  time: 0.2098  data: 0.0001  max mem: 14938
[18:57:53.936010] Test:  [310/345]  eta: 0:00:07  loss: 0.8261 (0.8336)  time: 0.2104  data: 0.0001  max mem: 14938
[18:57:56.050841] Test:  [320/345]  eta: 0:00:05  loss: 0.8377 (0.8338)  time: 0.2111  data: 0.0001  max mem: 14938
[18:57:58.171714] Test:  [330/345]  eta: 0:00:03  loss: 0.8259 (0.8334)  time: 0.2117  data: 0.0001  max mem: 14938
[18:58:00.295861] Test:  [340/345]  eta: 0:00:01  loss: 0.8259 (0.8336)  time: 0.2122  data: 0.0001  max mem: 14938
[18:58:01.147024] Test:  [344/345]  eta: 0:00:00  loss: 0.8259 (0.8335)  time: 0.2123  data: 0.0001  max mem: 14938
[18:58:01.213461] Test: Total time: 0:01:10 (0.2053 s / it)
[18:58:17.720710] Test:  [ 0/57]  eta: 0:00:28  loss: 0.8867 (0.8867)  time: 0.5028  data: 0.3073  max mem: 14938
[18:58:19.645536] Test:  [10/57]  eta: 0:00:10  loss: 0.8836 (0.9004)  time: 0.2206  data: 0.0280  max mem: 14938
[18:58:21.579406] Test:  [20/57]  eta: 0:00:07  loss: 0.8948 (0.8951)  time: 0.1929  data: 0.0001  max mem: 14938
[18:58:23.521106] Test:  [30/57]  eta: 0:00:05  loss: 0.8113 (0.8585)  time: 0.1937  data: 0.0001  max mem: 14938
[18:58:25.469537] Test:  [40/57]  eta: 0:00:03  loss: 0.7715 (0.8369)  time: 0.1944  data: 0.0001  max mem: 14938
[18:58:27.422178] Test:  [50/57]  eta: 0:00:01  loss: 0.7715 (0.8304)  time: 0.1950  data: 0.0001  max mem: 14938
[18:58:28.484596] Test:  [56/57]  eta: 0:00:00  loss: 0.8103 (0.8362)  time: 0.1897  data: 0.0001  max mem: 14938
[18:58:28.548941] Test: Total time: 0:00:11 (0.1988 s / it)
[18:58:31.328305] Dice score of the network on the train images: 0.677991, val images: 0.749343
[18:58:31.328514] saving best_dice_model_0 @ epoch 9
[18:58:32.539620] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:58:33.664793] Epoch: [10]  [  0/345]  eta: 0:06:27  lr: 0.000063  loss: 0.8927 (0.8927)  time: 1.1241  data: 0.3635  max mem: 14938
[18:58:48.738540] Epoch: [10]  [ 20/345]  eta: 0:04:10  lr: 0.000063  loss: 0.8774 (0.8718)  time: 0.7536  data: 0.0001  max mem: 14938
[18:59:03.866820] Epoch: [10]  [ 40/345]  eta: 0:03:53  lr: 0.000063  loss: 0.8589 (0.8664)  time: 0.7564  data: 0.0001  max mem: 14938

[18:59:19.052179] Epoch: [10]  [ 60/345]  eta: 0:03:37  lr: 0.000064  loss: 0.8654 (0.8662)  time: 0.7592  data: 0.0001  max mem: 14938
[18:59:34.245396] Epoch: [10]  [ 80/345]  eta: 0:03:21  lr: 0.000064  loss: 0.8626 (0.8665)  time: 0.7596  data: 0.0001  max mem: 14938
[18:59:49.466189] Epoch: [10]  [100/345]  eta: 0:03:06  lr: 0.000064  loss: 0.8659 (0.8663)  time: 0.7610  data: 0.0001  max mem: 14938
[19:00:04.679238] Epoch: [10]  [120/345]  eta: 0:02:51  lr: 0.000065  loss: 0.8540 (0.8647)  time: 0.7606  data: 0.0001  max mem: 14938
[19:00:19.901929] Epoch: [10]  [140/345]  eta: 0:02:36  lr: 0.000065  loss: 0.8441 (0.8623)  time: 0.7611  data: 0.0001  max mem: 14938

[19:00:35.117076] Epoch: [10]  [160/345]  eta: 0:02:20  lr: 0.000065  loss: 0.8684 (0.8625)  time: 0.7607  data: 0.0001  max mem: 14938
[19:00:50.331290] Epoch: [10]  [180/345]  eta: 0:02:05  lr: 0.000066  loss: 0.8514 (0.8621)  time: 0.7607  data: 0.0001  max mem: 14938
[19:01:05.538626] Epoch: [10]  [200/345]  eta: 0:01:50  lr: 0.000066  loss: 0.8402 (0.8612)  time: 0.7603  data: 0.0001  max mem: 14938
[19:01:20.732437] Epoch: [10]  [220/345]  eta: 0:01:35  lr: 0.000066  loss: 0.8464 (0.8597)  time: 0.7597  data: 0.0001  max mem: 14938
[19:01:35.929363] Epoch: [10]  [240/345]  eta: 0:01:19  lr: 0.000067  loss: 0.8487 (0.8596)  time: 0.7598  data: 0.0001  max mem: 14938
[19:01:51.124002] Epoch: [10]  [260/345]  eta: 0:01:04  lr: 0.000067  loss: 0.8549 (0.8595)  time: 0.7597  data: 0.0001  max mem: 14938
[19:02:06.317850] Epoch: [10]  [280/345]  eta: 0:00:49  lr: 0.000068  loss: 0.8395 (0.8586)  time: 0.7596  data: 0.0001  max mem: 14938
[19:02:21.493338] Epoch: [10]  [300/345]  eta: 0:00:34  lr: 0.000068  loss: 0.8300 (0.8574)  time: 0.7587  data: 0.0001  max mem: 14938
[19:02:36.681178] Epoch: [10]  [320/345]  eta: 0:00:19  lr: 0.000068  loss: 0.8402 (0.8568)  time: 0.7594  data: 0.0001  max mem: 14938
[19:02:51.880453] Epoch: [10]  [340/345]  eta: 0:00:03  lr: 0.000069  loss: 0.8406 (0.8557)  time: 0.7599  data: 0.0001  max mem: 14938
[19:02:54.917649] Epoch: [10]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.8333 (0.8554)  time: 0.7598  data: 0.0001  max mem: 14938
[19:02:54.985277] Epoch: [10] Total time: 0:04:22 (0.7607 s / it)
[19:02:54.985719] Averaged stats: lr: 0.000069  loss: 0.8333 (0.8554)
[19:02:55.536371] Test:  [  0/345]  eta: 0:03:07  loss: 0.7691 (0.7691)  time: 0.5447  data: 0.3461  max mem: 14938
[19:02:57.489951] Test:  [ 10/345]  eta: 0:01:16  loss: 0.8160 (0.8089)  time: 0.2270  data: 0.0315  max mem: 14938
[19:02:59.450044] Test:  [ 20/345]  eta: 0:01:08  loss: 0.8160 (0.8100)  time: 0.1956  data: 0.0001  max mem: 14938
[19:03:01.416037] Test:  [ 30/345]  eta: 0:01:05  loss: 0.8086 (0.8123)  time: 0.1962  data: 0.0001  max mem: 14938
[19:03:03.384030] Test:  [ 40/345]  eta: 0:01:02  loss: 0.8126 (0.8144)  time: 0.1966  data: 0.0001  max mem: 14938
[19:03:05.360173] Test:  [ 50/345]  eta: 0:00:59  loss: 0.8107 (0.8128)  time: 0.1971  data: 0.0001  max mem: 14938
[19:03:07.340205] Test:  [ 60/345]  eta: 0:00:57  loss: 0.8032 (0.8140)  time: 0.1977  data: 0.0001  max mem: 14938
[19:03:09.322470] Test:  [ 70/345]  eta: 0:00:55  loss: 0.8111 (0.8140)  time: 0.1981  data: 0.0001  max mem: 14938
[19:03:11.312954] Test:  [ 80/345]  eta: 0:00:53  loss: 0.8005 (0.8126)  time: 0.1986  data: 0.0001  max mem: 14938
[19:03:13.307885] Test:  [ 90/345]  eta: 0:00:51  loss: 0.8005 (0.8124)  time: 0.1992  data: 0.0001  max mem: 14938
[19:03:15.309401] Test:  [100/345]  eta: 0:00:49  loss: 0.8212 (0.8134)  time: 0.1998  data: 0.0001  max mem: 14938
[19:03:17.312657] Test:  [110/345]  eta: 0:00:47  loss: 0.8207 (0.8141)  time: 0.2002  data: 0.0001  max mem: 14938
[19:03:19.322039] Test:  [120/345]  eta: 0:00:45  loss: 0.8140 (0.8138)  time: 0.2006  data: 0.0001  max mem: 14938

[19:03:21.337325] Test:  [130/345]  eta: 0:00:43  loss: 0.8056 (0.8133)  time: 0.2012  data: 0.0001  max mem: 14938
[19:03:23.358352] Test:  [140/345]  eta: 0:00:41  loss: 0.8025 (0.8127)  time: 0.2018  data: 0.0001  max mem: 14938
[19:03:25.383475] Test:  [150/345]  eta: 0:00:39  loss: 0.8052 (0.8125)  time: 0.2022  data: 0.0001  max mem: 14938
[19:03:27.414119] Test:  [160/345]  eta: 0:00:37  loss: 0.8204 (0.8131)  time: 0.2027  data: 0.0001  max mem: 14938
[19:03:29.450250] Test:  [170/345]  eta: 0:00:35  loss: 0.8215 (0.8130)  time: 0.2033  data: 0.0001  max mem: 14938
[19:03:31.490735] Test:  [180/345]  eta: 0:00:33  loss: 0.8086 (0.8132)  time: 0.2038  data: 0.0001  max mem: 14938
[19:03:33.536613] Test:  [190/345]  eta: 0:00:31  loss: 0.8230 (0.8142)  time: 0.2043  data: 0.0001  max mem: 14938
[19:03:35.589890] Test:  [200/345]  eta: 0:00:29  loss: 0.8331 (0.8152)  time: 0.2049  data: 0.0001  max mem: 14938
[19:03:37.645263] Test:  [210/345]  eta: 0:00:27  loss: 0.8272 (0.8154)  time: 0.2054  data: 0.0001  max mem: 14938
[19:03:39.706941] Test:  [220/345]  eta: 0:00:25  loss: 0.8125 (0.8157)  time: 0.2058  data: 0.0001  max mem: 14938
[19:03:41.776963] Test:  [230/345]  eta: 0:00:23  loss: 0.8118 (0.8166)  time: 0.2065  data: 0.0001  max mem: 14938
[19:03:43.848279] Test:  [240/345]  eta: 0:00:21  loss: 0.8088 (0.8161)  time: 0.2070  data: 0.0001  max mem: 14938
[19:03:45.926529] Test:  [250/345]  eta: 0:00:19  loss: 0.8111 (0.8160)  time: 0.2074  data: 0.0001  max mem: 14938
[19:03:48.007906] Test:  [260/345]  eta: 0:00:17  loss: 0.8122 (0.8160)  time: 0.2079  data: 0.0001  max mem: 14938
[19:03:50.096961] Test:  [270/345]  eta: 0:00:15  loss: 0.8093 (0.8158)  time: 0.2085  data: 0.0001  max mem: 14938
[19:03:52.191432] Test:  [280/345]  eta: 0:00:13  loss: 0.8076 (0.8158)  time: 0.2091  data: 0.0001  max mem: 14938
[19:03:54.289762] Test:  [290/345]  eta: 0:00:11  loss: 0.8103 (0.8160)  time: 0.2096  data: 0.0001  max mem: 14938
[19:03:56.394341] Test:  [300/345]  eta: 0:00:09  loss: 0.8010 (0.8159)  time: 0.2101  data: 0.0001  max mem: 14938
[19:03:58.504302] Test:  [310/345]  eta: 0:00:07  loss: 0.7944 (0.8152)  time: 0.2107  data: 0.0001  max mem: 14938
[19:04:00.619689] Test:  [320/345]  eta: 0:00:05  loss: 0.8115 (0.8154)  time: 0.2112  data: 0.0001  max mem: 14938
[19:04:02.740071] Test:  [330/345]  eta: 0:00:03  loss: 0.8142 (0.8153)  time: 0.2117  data: 0.0001  max mem: 14938
[19:04:04.861609] Test:  [340/345]  eta: 0:00:01  loss: 0.8106 (0.8156)  time: 0.2120  data: 0.0001  max mem: 14938
[19:04:05.712587] Test:  [344/345]  eta: 0:00:00  loss: 0.8143 (0.8156)  time: 0.2122  data: 0.0001  max mem: 14938
[19:04:05.780170] Test: Total time: 0:01:10 (0.2052 s / it)
[19:04:22.423919] Test:  [ 0/57]  eta: 0:00:29  loss: 0.9005 (0.9005)  time: 0.5110  data: 0.3134  max mem: 14938
[19:04:24.350357] Test:  [10/57]  eta: 0:00:10  loss: 0.9005 (0.9058)  time: 0.2215  data: 0.0286  max mem: 14938
[19:04:26.285949] Test:  [20/57]  eta: 0:00:07  loss: 0.9015 (0.9003)  time: 0.1930  data: 0.0001  max mem: 14938
[19:04:28.228683] Test:  [30/57]  eta: 0:00:05  loss: 0.8007 (0.8596)  time: 0.1939  data: 0.0001  max mem: 14938
[19:04:30.176891] Test:  [40/57]  eta: 0:00:03  loss: 0.7661 (0.8356)  time: 0.1945  data: 0.0001  max mem: 14938
[19:04:32.131385] Test:  [50/57]  eta: 0:00:01  loss: 0.7661 (0.8273)  time: 0.1951  data: 0.0001  max mem: 14938
[19:04:33.194393] Test:  [56/57]  eta: 0:00:00  loss: 0.7981 (0.8316)  time: 0.1898  data: 0.0001  max mem: 14938
[19:04:33.255413] Test: Total time: 0:00:11 (0.1990 s / it)
[19:04:36.057285] Dice score of the network on the train images: 0.698951, val images: 0.756814
[19:04:36.057496] saving best_prec_model_0 @ epoch 10
[19:04:37.075757] saving best_dice_model_0 @ epoch 10
[19:04:38.191069] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:04:39.283418] Epoch: [11]  [  0/345]  eta: 0:06:16  lr: 0.000069  loss: 0.8820 (0.8820)  time: 1.0911  data: 0.3296  max mem: 14938
[19:04:54.357055] Epoch: [11]  [ 20/345]  eta: 0:04:10  lr: 0.000069  loss: 0.8518 (0.8500)  time: 0.7536  data: 0.0001  max mem: 14938

[19:05:09.483779] Epoch: [11]  [ 40/345]  eta: 0:03:52  lr: 0.000069  loss: 0.8275 (0.8433)  time: 0.7563  data: 0.0001  max mem: 14938
[19:05:24.677252] Epoch: [11]  [ 60/345]  eta: 0:03:37  lr: 0.000070  loss: 0.8257 (0.8410)  time: 0.7596  data: 0.0001  max mem: 14938
[19:05:39.875099] Epoch: [11]  [ 80/345]  eta: 0:03:21  lr: 0.000070  loss: 0.8406 (0.8412)  time: 0.7599  data: 0.0001  max mem: 14938
[19:05:55.085791] Epoch: [11]  [100/345]  eta: 0:03:06  lr: 0.000071  loss: 0.8344 (0.8411)  time: 0.7605  data: 0.0001  max mem: 14938
[19:06:10.319978] Epoch: [11]  [120/345]  eta: 0:02:51  lr: 0.000071  loss: 0.8482 (0.8430)  time: 0.7616  data: 0.0001  max mem: 14938
[19:06:25.530264] Epoch: [11]  [140/345]  eta: 0:02:36  lr: 0.000071  loss: 0.8438 (0.8427)  time: 0.7605  data: 0.0001  max mem: 14938
[19:06:40.743573] Epoch: [11]  [160/345]  eta: 0:02:20  lr: 0.000072  loss: 0.8352 (0.8419)  time: 0.7606  data: 0.0001  max mem: 14938
[19:06:55.945760] Epoch: [11]  [180/345]  eta: 0:02:05  lr: 0.000072  loss: 0.8241 (0.8410)  time: 0.7601  data: 0.0001  max mem: 14938
[19:07:11.142198] Epoch: [11]  [200/345]  eta: 0:01:50  lr: 0.000072  loss: 0.8400 (0.8411)  time: 0.7598  data: 0.0001  max mem: 14938
[19:07:26.326669] Epoch: [11]  [220/345]  eta: 0:01:35  lr: 0.000073  loss: 0.8457 (0.8413)  time: 0.7592  data: 0.0001  max mem: 14938

[19:07:41.649945] Epoch: [11]  [240/345]  eta: 0:01:19  lr: 0.000073  loss: 0.8290 (0.8402)  time: 0.7661  data: 0.0001  max mem: 14938
[19:07:56.845913] Epoch: [11]  [260/345]  eta: 0:01:04  lr: 0.000073  loss: 0.8292 (0.8398)  time: 0.7598  data: 0.0001  max mem: 14938
[19:08:12.033069] Epoch: [11]  [280/345]  eta: 0:00:49  lr: 0.000074  loss: 0.8279 (0.8396)  time: 0.7593  data: 0.0001  max mem: 14938
[19:08:27.208865] Epoch: [11]  [300/345]  eta: 0:00:34  lr: 0.000074  loss: 0.8154 (0.8383)  time: 0.7588  data: 0.0001  max mem: 14938
[19:08:42.408675] Epoch: [11]  [320/345]  eta: 0:00:19  lr: 0.000075  loss: 0.8270 (0.8379)  time: 0.7599  data: 0.0001  max mem: 14938
[19:08:57.583891] Epoch: [11]  [340/345]  eta: 0:00:03  lr: 0.000075  loss: 0.8236 (0.8370)  time: 0.7587  data: 0.0001  max mem: 14938
[19:09:00.623335] Epoch: [11]  [344/345]  eta: 0:00:00  lr: 0.000075  loss: 0.8263 (0.8369)  time: 0.7588  data: 0.0001  max mem: 14938
[19:09:00.695277] Epoch: [11] Total time: 0:04:22 (0.7609 s / it)
[19:09:00.695589] Averaged stats: lr: 0.000075  loss: 0.8263 (0.8369)
[19:09:01.278869] Test:  [  0/345]  eta: 0:03:19  loss: 0.8095 (0.8095)  time: 0.5776  data: 0.3793  max mem: 14938
[19:09:03.232289] Test:  [ 10/345]  eta: 0:01:17  loss: 0.7994 (0.8062)  time: 0.2300  data: 0.0346  max mem: 14938
[19:09:05.193117] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7931 (0.7957)  time: 0.1956  data: 0.0001  max mem: 14938
[19:09:07.159252] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7745 (0.7925)  time: 0.1963  data: 0.0001  max mem: 14938
[19:09:09.129802] Test:  [ 40/345]  eta: 0:01:02  loss: 0.8000 (0.7982)  time: 0.1968  data: 0.0001  max mem: 14938
[19:09:11.108101] Test:  [ 50/345]  eta: 0:01:00  loss: 0.8126 (0.7988)  time: 0.1974  data: 0.0001  max mem: 14938
[19:09:13.090134] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7990 (0.7979)  time: 0.1980  data: 0.0001  max mem: 14938
[19:09:15.080305] Test:  [ 70/345]  eta: 0:00:55  loss: 0.8004 (0.7982)  time: 0.1985  data: 0.0001  max mem: 14938
[19:09:17.069385] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7961 (0.7979)  time: 0.1989  data: 0.0001  max mem: 14938
[19:09:19.066989] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7961 (0.7989)  time: 0.1993  data: 0.0001  max mem: 14938
[19:09:21.068934] Test:  [100/345]  eta: 0:00:49  loss: 0.7963 (0.7986)  time: 0.1999  data: 0.0001  max mem: 14938
[19:09:23.074771] Test:  [110/345]  eta: 0:00:47  loss: 0.7963 (0.7990)  time: 0.2003  data: 0.0001  max mem: 14938
[19:09:25.083741] Test:  [120/345]  eta: 0:00:45  loss: 0.8037 (0.7985)  time: 0.2007  data: 0.0001  max mem: 14938
[19:09:27.099204] Test:  [130/345]  eta: 0:00:43  loss: 0.7913 (0.7983)  time: 0.2012  data: 0.0001  max mem: 14938
[19:09:29.121062] Test:  [140/345]  eta: 0:00:41  loss: 0.8003 (0.7989)  time: 0.2018  data: 0.0001  max mem: 14938
[19:09:31.148750] Test:  [150/345]  eta: 0:00:39  loss: 0.8003 (0.7990)  time: 0.2024  data: 0.0001  max mem: 14938
[19:09:33.178636] Test:  [160/345]  eta: 0:00:37  loss: 0.7938 (0.7987)  time: 0.2028  data: 0.0001  max mem: 14938
[19:09:35.213138] Test:  [170/345]  eta: 0:00:35  loss: 0.7884 (0.7982)  time: 0.2032  data: 0.0001  max mem: 14938
[19:09:37.254790] Test:  [180/345]  eta: 0:00:33  loss: 0.8028 (0.7989)  time: 0.2037  data: 0.0001  max mem: 14938
[19:09:39.299395] Test:  [190/345]  eta: 0:00:31  loss: 0.8058 (0.7992)  time: 0.2043  data: 0.0001  max mem: 14938
[19:09:41.351498] Test:  [200/345]  eta: 0:00:29  loss: 0.7952 (0.7988)  time: 0.2048  data: 0.0001  max mem: 14938
[19:09:43.409290] Test:  [210/345]  eta: 0:00:27  loss: 0.7992 (0.7988)  time: 0.2054  data: 0.0001  max mem: 14938
[19:09:45.471919] Test:  [220/345]  eta: 0:00:25  loss: 0.8071 (0.7986)  time: 0.2060  data: 0.0001  max mem: 14938
[19:09:47.540291] Test:  [230/345]  eta: 0:00:23  loss: 0.7939 (0.7984)  time: 0.2065  data: 0.0001  max mem: 14938
[19:09:49.611917] Test:  [240/345]  eta: 0:00:21  loss: 0.8028 (0.7982)  time: 0.2069  data: 0.0001  max mem: 14938
[19:09:51.689052] Test:  [250/345]  eta: 0:00:19  loss: 0.7873 (0.7975)  time: 0.2074  data: 0.0001  max mem: 14938
[19:09:53.775929] Test:  [260/345]  eta: 0:00:17  loss: 0.7885 (0.7975)  time: 0.2081  data: 0.0001  max mem: 14938
[19:09:55.864161] Test:  [270/345]  eta: 0:00:15  loss: 0.7912 (0.7974)  time: 0.2087  data: 0.0001  max mem: 14938
[19:09:57.958723] Test:  [280/345]  eta: 0:00:13  loss: 0.8014 (0.7978)  time: 0.2091  data: 0.0001  max mem: 14938
[19:10:00.058416] Test:  [290/345]  eta: 0:00:11  loss: 0.8057 (0.7981)  time: 0.2096  data: 0.0001  max mem: 14938
[19:10:02.163132] Test:  [300/345]  eta: 0:00:09  loss: 0.8032 (0.7981)  time: 0.2102  data: 0.0001  max mem: 14938
[19:10:04.273152] Test:  [310/345]  eta: 0:00:07  loss: 0.7964 (0.7981)  time: 0.2107  data: 0.0001  max mem: 14938
[19:10:06.386810] Test:  [320/345]  eta: 0:00:05  loss: 0.7964 (0.7982)  time: 0.2111  data: 0.0001  max mem: 14938
[19:10:08.506951] Test:  [330/345]  eta: 0:00:03  loss: 0.7943 (0.7980)  time: 0.2116  data: 0.0001  max mem: 14938
[19:10:10.630155] Test:  [340/345]  eta: 0:00:01  loss: 0.7943 (0.7981)  time: 0.2121  data: 0.0001  max mem: 14938
[19:10:11.479591] Test:  [344/345]  eta: 0:00:00  loss: 0.7941 (0.7980)  time: 0.2122  data: 0.0001  max mem: 14938
[19:10:11.531648] Test: Total time: 0:01:10 (0.2053 s / it)
[19:10:28.445065] Test:  [ 0/57]  eta: 0:00:28  loss: 0.8474 (0.8474)  time: 0.5033  data: 0.3078  max mem: 14938
[19:10:30.369005] Test:  [10/57]  eta: 0:00:10  loss: 0.8587 (0.8764)  time: 0.2206  data: 0.0281  max mem: 14938
[19:10:32.302004] Test:  [20/57]  eta: 0:00:07  loss: 0.8687 (0.8723)  time: 0.1928  data: 0.0001  max mem: 14938
[19:10:34.240823] Test:  [30/57]  eta: 0:00:05  loss: 0.7802 (0.8393)  time: 0.1935  data: 0.0001  max mem: 14938
[19:10:36.189458] Test:  [40/57]  eta: 0:00:03  loss: 0.7637 (0.8220)  time: 0.1943  data: 0.0001  max mem: 14938
[19:10:38.144243] Test:  [50/57]  eta: 0:00:01  loss: 0.7614 (0.8157)  time: 0.1951  data: 0.0001  max mem: 14938
[19:10:39.207724] Test:  [56/57]  eta: 0:00:00  loss: 0.7927 (0.8209)  time: 0.1899  data: 0.0001  max mem: 14938
[19:10:39.273458] Test: Total time: 0:00:11 (0.1988 s / it)
[19:10:42.122539] Dice score of the network on the train images: 0.691260, val images: 0.744810
[19:10:42.122759] saving best_prec_model_0 @ epoch 11
[19:10:43.215474] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:10:44.324119] Epoch: [12]  [  0/345]  eta: 0:06:22  lr: 0.000075  loss: 0.8825 (0.8825)  time: 1.1074  data: 0.3446  max mem: 14938
[19:10:59.391530] Epoch: [12]  [ 20/345]  eta: 0:04:10  lr: 0.000075  loss: 0.8122 (0.8299)  time: 0.7533  data: 0.0001  max mem: 14938
[19:11:14.512801] Epoch: [12]  [ 40/345]  eta: 0:03:52  lr: 0.000076  loss: 0.8279 (0.8312)  time: 0.7560  data: 0.0001  max mem: 14938
[19:11:29.695850] Epoch: [12]  [ 60/345]  eta: 0:03:37  lr: 0.000076  loss: 0.8279 (0.8318)  time: 0.7591  data: 0.0001  max mem: 14938
[19:11:44.881919] Epoch: [12]  [ 80/345]  eta: 0:03:21  lr: 0.000076  loss: 0.8298 (0.8313)  time: 0.7593  data: 0.0001  max mem: 14938
[19:12:00.080479] Epoch: [12]  [100/345]  eta: 0:03:06  lr: 0.000077  loss: 0.8025 (0.8267)  time: 0.7599  data: 0.0001  max mem: 14938
[19:12:15.280028] Epoch: [12]  [120/345]  eta: 0:02:51  lr: 0.000077  loss: 0.8208 (0.8259)  time: 0.7599  data: 0.0001  max mem: 14938
[19:12:30.494892] Epoch: [12]  [140/345]  eta: 0:02:35  lr: 0.000078  loss: 0.8325 (0.8264)  time: 0.7607  data: 0.0001  max mem: 14938
[19:12:45.690958] Epoch: [12]  [160/345]  eta: 0:02:20  lr: 0.000078  loss: 0.8224 (0.8261)  time: 0.7598  data: 0.0001  max mem: 14938
[19:13:00.889858] Epoch: [12]  [180/345]  eta: 0:02:05  lr: 0.000078  loss: 0.8113 (0.8254)  time: 0.7599  data: 0.0001  max mem: 14938
[19:13:16.082251] Epoch: [12]  [200/345]  eta: 0:01:50  lr: 0.000079  loss: 0.8232 (0.8251)  time: 0.7596  data: 0.0001  max mem: 14938
[19:13:31.269047] Epoch: [12]  [220/345]  eta: 0:01:35  lr: 0.000079  loss: 0.8359 (0.8261)  time: 0.7593  data: 0.0001  max mem: 14938
[19:13:46.429633] Epoch: [12]  [240/345]  eta: 0:01:19  lr: 0.000079  loss: 0.8135 (0.8254)  time: 0.7580  data: 0.0001  max mem: 14938
[19:14:01.619065] Epoch: [12]  [260/345]  eta: 0:01:04  lr: 0.000080  loss: 0.8191 (0.8253)  time: 0.7594  data: 0.0001  max mem: 14938
[19:14:16.798655] Epoch: [12]  [280/345]  eta: 0:00:49  lr: 0.000080  loss: 0.8172 (0.8248)  time: 0.7589  data: 0.0001  max mem: 14938
[19:14:31.970757] Epoch: [12]  [300/345]  eta: 0:00:34  lr: 0.000080  loss: 0.8085 (0.8239)  time: 0.7586  data: 0.0001  max mem: 14938
[19:14:47.153085] Epoch: [12]  [320/345]  eta: 0:00:18  lr: 0.000081  loss: 0.8145 (0.8235)  time: 0.7591  data: 0.0001  max mem: 14938
[19:15:02.325784] Epoch: [12]  [340/345]  eta: 0:00:03  lr: 0.000081  loss: 0.8301 (0.8238)  time: 0.7586  data: 0.0001  max mem: 14938
[19:15:05.363147] Epoch: [12]  [344/345]  eta: 0:00:00  lr: 0.000081  loss: 0.8303 (0.8238)  time: 0.7587  data: 0.0001  max mem: 14938
[19:15:05.434576] Epoch: [12] Total time: 0:04:22 (0.7601 s / it)
[19:15:05.434813] Averaged stats: lr: 0.000081  loss: 0.8303 (0.8238)
[19:15:05.983247] Test:  [  0/345]  eta: 0:03:07  loss: 0.8253 (0.8253)  time: 0.5434  data: 0.3453  max mem: 14938
[19:15:07.939107] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7854 (0.7866)  time: 0.2271  data: 0.0315  max mem: 14938
[19:15:09.899004] Test:  [ 20/345]  eta: 0:01:08  loss: 0.7766 (0.7807)  time: 0.1957  data: 0.0001  max mem: 14938
[19:15:11.864718] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7733 (0.7804)  time: 0.1962  data: 0.0001  max mem: 14938
[19:15:13.838298] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7784 (0.7800)  time: 0.1969  data: 0.0001  max mem: 14938
[19:15:15.814920] Test:  [ 50/345]  eta: 0:00:59  loss: 0.7718 (0.7785)  time: 0.1974  data: 0.0001  max mem: 14938
[19:15:17.798584] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7808 (0.7805)  time: 0.1980  data: 0.0001  max mem: 14938
[19:15:19.786188] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7839 (0.7806)  time: 0.1985  data: 0.0001  max mem: 14938
[19:15:21.777433] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7835 (0.7810)  time: 0.1989  data: 0.0001  max mem: 14938
[19:15:23.771951] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7831 (0.7809)  time: 0.1992  data: 0.0001  max mem: 14938
[19:15:25.773627] Test:  [100/345]  eta: 0:00:49  loss: 0.7711 (0.7801)  time: 0.1997  data: 0.0001  max mem: 14938
[19:15:27.782232] Test:  [110/345]  eta: 0:00:47  loss: 0.7678 (0.7797)  time: 0.2004  data: 0.0001  max mem: 14938
[19:15:29.796196] Test:  [120/345]  eta: 0:00:45  loss: 0.7757 (0.7800)  time: 0.2011  data: 0.0001  max mem: 14938
[19:15:31.813404] Test:  [130/345]  eta: 0:00:43  loss: 0.7804 (0.7799)  time: 0.2015  data: 0.0001  max mem: 14938
[19:15:33.836917] Test:  [140/345]  eta: 0:00:41  loss: 0.7779 (0.7799)  time: 0.2020  data: 0.0001  max mem: 14938
[19:15:35.862851] Test:  [150/345]  eta: 0:00:39  loss: 0.7769 (0.7796)  time: 0.2024  data: 0.0001  max mem: 14938
[19:15:37.896938] Test:  [160/345]  eta: 0:00:37  loss: 0.7758 (0.7793)  time: 0.2029  data: 0.0001  max mem: 14938
[19:15:39.935246] Test:  [170/345]  eta: 0:00:35  loss: 0.7758 (0.7790)  time: 0.2036  data: 0.0001  max mem: 14938
[19:15:41.977308] Test:  [180/345]  eta: 0:00:33  loss: 0.7698 (0.7787)  time: 0.2040  data: 0.0001  max mem: 14938
[19:15:44.026162] Test:  [190/345]  eta: 0:00:31  loss: 0.7711 (0.7783)  time: 0.2045  data: 0.0001  max mem: 14938
[19:15:46.077498] Test:  [200/345]  eta: 0:00:29  loss: 0.7771 (0.7785)  time: 0.2049  data: 0.0001  max mem: 14938
[19:15:48.134786] Test:  [210/345]  eta: 0:00:27  loss: 0.7771 (0.7783)  time: 0.2054  data: 0.0001  max mem: 14938

[19:15:50.196726] Test:  [220/345]  eta: 0:00:25  loss: 0.7776 (0.7785)  time: 0.2059  data: 0.0001  max mem: 14938
[19:15:52.263128] Test:  [230/345]  eta: 0:00:23  loss: 0.7759 (0.7783)  time: 0.2064  data: 0.0001  max mem: 14938
[19:15:54.336715] Test:  [240/345]  eta: 0:00:21  loss: 0.7729 (0.7782)  time: 0.2069  data: 0.0001  max mem: 14938
[19:15:56.414259] Test:  [250/345]  eta: 0:00:19  loss: 0.7745 (0.7785)  time: 0.2075  data: 0.0001  max mem: 14938
[19:15:58.498997] Test:  [260/345]  eta: 0:00:17  loss: 0.7745 (0.7783)  time: 0.2081  data: 0.0001  max mem: 14938
[19:16:00.586605] Test:  [270/345]  eta: 0:00:15  loss: 0.7765 (0.7785)  time: 0.2086  data: 0.0001  max mem: 14938
[19:16:02.678204] Test:  [280/345]  eta: 0:00:13  loss: 0.7917 (0.7791)  time: 0.2089  data: 0.0001  max mem: 14938
[19:16:04.776374] Test:  [290/345]  eta: 0:00:11  loss: 0.7907 (0.7791)  time: 0.2094  data: 0.0001  max mem: 14938
[19:16:06.881094] Test:  [300/345]  eta: 0:00:09  loss: 0.7744 (0.7792)  time: 0.2101  data: 0.0001  max mem: 14938
[19:16:08.991875] Test:  [310/345]  eta: 0:00:07  loss: 0.7727 (0.7790)  time: 0.2107  data: 0.0001  max mem: 14938
[19:16:11.108738] Test:  [320/345]  eta: 0:00:05  loss: 0.7729 (0.7788)  time: 0.2113  data: 0.0001  max mem: 14938
[19:16:13.231597] Test:  [330/345]  eta: 0:00:03  loss: 0.7720 (0.7786)  time: 0.2119  data: 0.0001  max mem: 14938
[19:16:15.353941] Test:  [340/345]  eta: 0:00:01  loss: 0.7720 (0.7787)  time: 0.2122  data: 0.0001  max mem: 14938
[19:16:16.204572] Test:  [344/345]  eta: 0:00:00  loss: 0.7835 (0.7788)  time: 0.2123  data: 0.0001  max mem: 14938
[19:16:16.270851] Test: Total time: 0:01:10 (0.2053 s / it)
[19:16:33.034373] Test:  [ 0/57]  eta: 0:00:30  loss: 0.8709 (0.8709)  time: 0.5432  data: 0.3479  max mem: 14938
[19:16:34.962585] Test:  [10/57]  eta: 0:00:10  loss: 0.8981 (0.8896)  time: 0.2246  data: 0.0317  max mem: 14938
[19:16:36.896912] Test:  [20/57]  eta: 0:00:07  loss: 0.8762 (0.8749)  time: 0.1930  data: 0.0001  max mem: 14938
[19:16:38.836932] Test:  [30/57]  eta: 0:00:05  loss: 0.7759 (0.8364)  time: 0.1937  data: 0.0001  max mem: 14938
[19:16:40.784244] Test:  [40/57]  eta: 0:00:03  loss: 0.7555 (0.8156)  time: 0.1943  data: 0.0001  max mem: 14938
[19:16:42.738614] Test:  [50/57]  eta: 0:00:01  loss: 0.7454 (0.8078)  time: 0.1950  data: 0.0001  max mem: 14938
[19:16:43.800750] Test:  [56/57]  eta: 0:00:00  loss: 0.7865 (0.8137)  time: 0.1897  data: 0.0000  max mem: 14938
[19:16:43.859851] Test: Total time: 0:00:11 (0.1995 s / it)
[19:16:46.633091] Dice score of the network on the train images: 0.694780, val images: 0.759436
[19:16:46.633317] saving best_dice_model_0 @ epoch 12
[19:16:47.735299] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:16:48.885926] Epoch: [13]  [  0/345]  eta: 0:06:36  lr: 0.000081  loss: 0.8099 (0.8099)  time: 1.1495  data: 0.3850  max mem: 14938
[19:17:03.923823] Epoch: [13]  [ 20/345]  eta: 0:04:10  lr: 0.000082  loss: 0.8012 (0.8030)  time: 0.7518  data: 0.0001  max mem: 14938
[19:17:19.032159] Epoch: [13]  [ 40/345]  eta: 0:03:52  lr: 0.000082  loss: 0.8158 (0.8128)  time: 0.7554  data: 0.0001  max mem: 14938
[19:17:34.204074] Epoch: [13]  [ 60/345]  eta: 0:03:37  lr: 0.000082  loss: 0.8212 (0.8177)  time: 0.7585  data: 0.0001  max mem: 14938
[19:17:49.396624] Epoch: [13]  [ 80/345]  eta: 0:03:21  lr: 0.000083  loss: 0.8144 (0.8184)  time: 0.7596  data: 0.0001  max mem: 14938
[19:18:04.617932] Epoch: [13]  [100/345]  eta: 0:03:06  lr: 0.000083  loss: 0.8202 (0.8192)  time: 0.7610  data: 0.0001  max mem: 14938
[19:18:19.826193] Epoch: [13]  [120/345]  eta: 0:02:51  lr: 0.000083  loss: 0.8098 (0.8173)  time: 0.7604  data: 0.0001  max mem: 14938
[19:18:35.032657] Epoch: [13]  [140/345]  eta: 0:02:35  lr: 0.000084  loss: 0.8116 (0.8168)  time: 0.7603  data: 0.0001  max mem: 14938
[19:18:50.231615] Epoch: [13]  [160/345]  eta: 0:02:20  lr: 0.000084  loss: 0.8215 (0.8174)  time: 0.7599  data: 0.0001  max mem: 14938
[19:19:05.413290] Epoch: [13]  [180/345]  eta: 0:02:05  lr: 0.000085  loss: 0.8079 (0.8166)  time: 0.7590  data: 0.0001  max mem: 14938
[19:19:20.584906] Epoch: [13]  [200/345]  eta: 0:01:50  lr: 0.000085  loss: 0.8016 (0.8158)  time: 0.7585  data: 0.0001  max mem: 14938
[19:19:35.758261] Epoch: [13]  [220/345]  eta: 0:01:35  lr: 0.000085  loss: 0.8133 (0.8154)  time: 0.7586  data: 0.0001  max mem: 14938
[19:19:50.931334] Epoch: [13]  [240/345]  eta: 0:01:19  lr: 0.000086  loss: 0.8213 (0.8157)  time: 0.7586  data: 0.0001  max mem: 14938
[19:20:06.126819] Epoch: [13]  [260/345]  eta: 0:01:04  lr: 0.000086  loss: 0.8123 (0.8158)  time: 0.7597  data: 0.0001  max mem: 14938
[19:20:21.322945] Epoch: [13]  [280/345]  eta: 0:00:49  lr: 0.000086  loss: 0.8049 (0.8153)  time: 0.7598  data: 0.0001  max mem: 14938
[19:20:36.516251] Epoch: [13]  [300/345]  eta: 0:00:34  lr: 0.000087  loss: 0.8146 (0.8150)  time: 0.7596  data: 0.0001  max mem: 14938
[19:20:51.701566] Epoch: [13]  [320/345]  eta: 0:00:18  lr: 0.000087  loss: 0.8000 (0.8145)  time: 0.7592  data: 0.0001  max mem: 14938
[19:21:06.882079] Epoch: [13]  [340/345]  eta: 0:00:03  lr: 0.000087  loss: 0.7954 (0.8139)  time: 0.7590  data: 0.0001  max mem: 14938
[19:21:09.913702] Epoch: [13]  [344/345]  eta: 0:00:00  lr: 0.000087  loss: 0.8020 (0.8137)  time: 0.7586  data: 0.0001  max mem: 14938
[19:21:09.983495] Epoch: [13] Total time: 0:04:22 (0.7601 s / it)
[19:21:09.983735] Averaged stats: lr: 0.000087  loss: 0.8020 (0.8137)
[19:21:10.533054] Test:  [  0/345]  eta: 0:03:07  loss: 0.7756 (0.7756)  time: 0.5442  data: 0.3440  max mem: 14938
[19:21:12.487181] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7756 (0.7761)  time: 0.2271  data: 0.0314  max mem: 14938
[19:21:14.448320] Test:  [ 20/345]  eta: 0:01:08  loss: 0.7679 (0.7743)  time: 0.1957  data: 0.0001  max mem: 14938
[19:21:16.413669] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7693 (0.7773)  time: 0.1963  data: 0.0001  max mem: 14938
[19:21:18.384695] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7732 (0.7754)  time: 0.1968  data: 0.0001  max mem: 14938
[19:21:20.362194] Test:  [ 50/345]  eta: 0:00:59  loss: 0.7827 (0.7777)  time: 0.1974  data: 0.0001  max mem: 14938
[19:21:22.344571] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7804 (0.7772)  time: 0.1979  data: 0.0001  max mem: 14938
[19:21:24.331077] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7761 (0.7767)  time: 0.1984  data: 0.0001  max mem: 14938
[19:21:26.324009] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7767 (0.7782)  time: 0.1989  data: 0.0001  max mem: 14938
[19:21:28.320808] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7762 (0.7769)  time: 0.1994  data: 0.0001  max mem: 14938
[19:21:30.319821] Test:  [100/345]  eta: 0:00:49  loss: 0.7715 (0.7767)  time: 0.1997  data: 0.0001  max mem: 14938
[19:21:32.325824] Test:  [110/345]  eta: 0:00:47  loss: 0.7735 (0.7764)  time: 0.2002  data: 0.0001  max mem: 14938
[19:21:34.339401] Test:  [120/345]  eta: 0:00:45  loss: 0.7718 (0.7768)  time: 0.2009  data: 0.0001  max mem: 14938
[19:21:36.357274] Test:  [130/345]  eta: 0:00:43  loss: 0.7737 (0.7767)  time: 0.2015  data: 0.0001  max mem: 14938
[19:21:38.379263] Test:  [140/345]  eta: 0:00:41  loss: 0.7783 (0.7765)  time: 0.2019  data: 0.0001  max mem: 14938
[19:21:40.407493] Test:  [150/345]  eta: 0:00:39  loss: 0.7801 (0.7767)  time: 0.2024  data: 0.0001  max mem: 14938
[19:21:42.439144] Test:  [160/345]  eta: 0:00:37  loss: 0.7744 (0.7761)  time: 0.2029  data: 0.0001  max mem: 14938
[19:21:44.477177] Test:  [170/345]  eta: 0:00:35  loss: 0.7706 (0.7759)  time: 0.2034  data: 0.0001  max mem: 14938
[19:21:46.517703] Test:  [180/345]  eta: 0:00:33  loss: 0.7636 (0.7756)  time: 0.2039  data: 0.0001  max mem: 14938
[19:21:48.562681] Test:  [190/345]  eta: 0:00:31  loss: 0.7734 (0.7758)  time: 0.2042  data: 0.0001  max mem: 14938

[19:21:50.616403] Test:  [200/345]  eta: 0:00:29  loss: 0.7805 (0.7761)  time: 0.2049  data: 0.0001  max mem: 14938
[19:21:52.673488] Test:  [210/345]  eta: 0:00:27  loss: 0.7754 (0.7760)  time: 0.2055  data: 0.0001  max mem: 14938
[19:21:54.734735] Test:  [220/345]  eta: 0:00:25  loss: 0.7694 (0.7758)  time: 0.2059  data: 0.0001  max mem: 14938
[19:21:56.802704] Test:  [230/345]  eta: 0:00:23  loss: 0.7685 (0.7758)  time: 0.2064  data: 0.0001  max mem: 14938
[19:21:58.874217] Test:  [240/345]  eta: 0:00:21  loss: 0.7656 (0.7757)  time: 0.2069  data: 0.0001  max mem: 14938
[19:22:00.951005] Test:  [250/345]  eta: 0:00:19  loss: 0.7630 (0.7755)  time: 0.2074  data: 0.0001  max mem: 14938
[19:22:03.033233] Test:  [260/345]  eta: 0:00:17  loss: 0.7780 (0.7759)  time: 0.2079  data: 0.0001  max mem: 14938
[19:22:05.121882] Test:  [270/345]  eta: 0:00:15  loss: 0.7816 (0.7760)  time: 0.2085  data: 0.0001  max mem: 14938
[19:22:07.217227] Test:  [280/345]  eta: 0:00:13  loss: 0.7756 (0.7760)  time: 0.2091  data: 0.0001  max mem: 14938
[19:22:09.313893] Test:  [290/345]  eta: 0:00:11  loss: 0.7749 (0.7757)  time: 0.2095  data: 0.0001  max mem: 14938
[19:22:11.417215] Test:  [300/345]  eta: 0:00:09  loss: 0.7717 (0.7757)  time: 0.2099  data: 0.0001  max mem: 14938
[19:22:13.526816] Test:  [310/345]  eta: 0:00:07  loss: 0.7717 (0.7756)  time: 0.2106  data: 0.0001  max mem: 14938
[19:22:15.641984] Test:  [320/345]  eta: 0:00:05  loss: 0.7798 (0.7758)  time: 0.2112  data: 0.0001  max mem: 14938
[19:22:17.762179] Test:  [330/345]  eta: 0:00:03  loss: 0.7758 (0.7756)  time: 0.2117  data: 0.0001  max mem: 14938
[19:22:19.886949] Test:  [340/345]  eta: 0:00:01  loss: 0.7681 (0.7754)  time: 0.2122  data: 0.0001  max mem: 14938
[19:22:20.737501] Test:  [344/345]  eta: 0:00:00  loss: 0.7681 (0.7754)  time: 0.2123  data: 0.0001  max mem: 14938
[19:22:20.798494] Test: Total time: 0:01:10 (0.2052 s / it)
[19:22:37.406086] Test:  [ 0/57]  eta: 0:00:29  loss: 0.8888 (0.8888)  time: 0.5090  data: 0.3124  max mem: 14938
[19:22:39.329116] Test:  [10/57]  eta: 0:00:10  loss: 0.8831 (0.8798)  time: 0.2210  data: 0.0285  max mem: 14938
[19:22:41.265165] Test:  [20/57]  eta: 0:00:07  loss: 0.8831 (0.8714)  time: 0.1929  data: 0.0001  max mem: 14938
[19:22:43.204636] Test:  [30/57]  eta: 0:00:05  loss: 0.7721 (0.8329)  time: 0.1937  data: 0.0001  max mem: 14938
[19:22:45.151637] Test:  [40/57]  eta: 0:00:03  loss: 0.7500 (0.8118)  time: 0.1943  data: 0.0001  max mem: 14938
[19:22:47.106133] Test:  [50/57]  eta: 0:00:01  loss: 0.7494 (0.8064)  time: 0.1950  data: 0.0001  max mem: 14938
[19:22:48.168744] Test:  [56/57]  eta: 0:00:00  loss: 0.7823 (0.8111)  time: 0.1897  data: 0.0000  max mem: 14938
[19:22:48.228142] Test: Total time: 0:00:11 (0.1988 s / it)
[19:22:51.047636] Dice score of the network on the train images: 0.688376, val images: 0.754568
[19:22:51.051835] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:22:52.147376] Epoch: [14]  [  0/345]  eta: 0:06:17  lr: 0.000087  loss: 0.8233 (0.8233)  time: 1.0948  data: 0.3304  max mem: 14938
[19:23:07.224444] Epoch: [14]  [ 20/345]  eta: 0:04:10  lr: 0.000088  loss: 0.7979 (0.8030)  time: 0.7538  data: 0.0001  max mem: 14938
[19:23:22.351534] Epoch: [14]  [ 40/345]  eta: 0:03:52  lr: 0.000088  loss: 0.8081 (0.8076)  time: 0.7563  data: 0.0001  max mem: 14938
[19:23:37.517203] Epoch: [14]  [ 60/345]  eta: 0:03:37  lr: 0.000089  loss: 0.8165 (0.8121)  time: 0.7582  data: 0.0001  max mem: 14938
[19:23:52.719155] Epoch: [14]  [ 80/345]  eta: 0:03:21  lr: 0.000089  loss: 0.8038 (0.8109)  time: 0.7601  data: 0.0001  max mem: 14938
[19:24:07.943108] Epoch: [14]  [100/345]  eta: 0:03:06  lr: 0.000089  loss: 0.8104 (0.8114)  time: 0.7612  data: 0.0001  max mem: 14938
[19:24:23.144885] Epoch: [14]  [120/345]  eta: 0:02:51  lr: 0.000090  loss: 0.7993 (0.8102)  time: 0.7601  data: 0.0001  max mem: 14938
[19:24:38.342596] Epoch: [14]  [140/345]  eta: 0:02:35  lr: 0.000090  loss: 0.8042 (0.8099)  time: 0.7598  data: 0.0001  max mem: 14938
[19:24:53.556432] Epoch: [14]  [160/345]  eta: 0:02:20  lr: 0.000090  loss: 0.7978 (0.8091)  time: 0.7606  data: 0.0001  max mem: 14938
[19:25:08.750195] Epoch: [14]  [180/345]  eta: 0:02:05  lr: 0.000091  loss: 0.7986 (0.8083)  time: 0.7596  data: 0.0001  max mem: 14938
[19:25:23.946443] Epoch: [14]  [200/345]  eta: 0:01:50  lr: 0.000091  loss: 0.8006 (0.8074)  time: 0.7598  data: 0.0001  max mem: 14938
[19:25:39.142979] Epoch: [14]  [220/345]  eta: 0:01:35  lr: 0.000091  loss: 0.7957 (0.8062)  time: 0.7598  data: 0.0001  max mem: 14938
[19:25:54.332220] Epoch: [14]  [240/345]  eta: 0:01:19  lr: 0.000092  loss: 0.8079 (0.8062)  time: 0.7594  data: 0.0001  max mem: 14938
[19:26:09.530521] Epoch: [14]  [260/345]  eta: 0:01:04  lr: 0.000092  loss: 0.7946 (0.8057)  time: 0.7599  data: 0.0001  max mem: 14938
[19:26:24.714912] Epoch: [14]  [280/345]  eta: 0:00:49  lr: 0.000093  loss: 0.8067 (0.8063)  time: 0.7592  data: 0.0001  max mem: 14938
[19:26:39.899508] Epoch: [14]  [300/345]  eta: 0:00:34  lr: 0.000093  loss: 0.8112 (0.8069)  time: 0.7592  data: 0.0001  max mem: 14938
[19:26:55.094866] Epoch: [14]  [320/345]  eta: 0:00:19  lr: 0.000093  loss: 0.7970 (0.8066)  time: 0.7597  data: 0.0001  max mem: 14938
[19:27:10.283407] Epoch: [14]  [340/345]  eta: 0:00:03  lr: 0.000094  loss: 0.7912 (0.8062)  time: 0.7594  data: 0.0001  max mem: 14938
[19:27:13.317760] Epoch: [14]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.7901 (0.8061)  time: 0.7591  data: 0.0001  max mem: 14938
[19:27:13.386764] Epoch: [14] Total time: 0:04:22 (0.7604 s / it)
[19:27:13.386980] Averaged stats: lr: 0.000094  loss: 0.7901 (0.8061)
[19:27:13.942516] Test:  [  0/345]  eta: 0:03:09  loss: 0.7688 (0.7688)  time: 0.5504  data: 0.3507  max mem: 14938
[19:27:15.895938] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7683 (0.7653)  time: 0.2275  data: 0.0320  max mem: 14938
[19:27:17.859219] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7683 (0.7693)  time: 0.1958  data: 0.0001  max mem: 14938
[19:27:19.826711] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7642 (0.7667)  time: 0.1965  data: 0.0001  max mem: 14938
[19:27:21.794879] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7613 (0.7670)  time: 0.1967  data: 0.0001  max mem: 14938
[19:27:23.770546] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7582 (0.7660)  time: 0.1971  data: 0.0001  max mem: 14938
[19:27:25.753392] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7577 (0.7670)  time: 0.1979  data: 0.0001  max mem: 14938
[19:27:27.739629] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7676 (0.7668)  time: 0.1984  data: 0.0001  max mem: 14938
[19:27:29.730359] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7686 (0.7686)  time: 0.1988  data: 0.0001  max mem: 14938
[19:27:31.725819] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7775 (0.7687)  time: 0.1992  data: 0.0001  max mem: 14938
[19:27:33.724731] Test:  [100/345]  eta: 0:00:49  loss: 0.7677 (0.7699)  time: 0.1997  data: 0.0001  max mem: 14938
[19:27:35.736717] Test:  [110/345]  eta: 0:00:47  loss: 0.7686 (0.7697)  time: 0.2005  data: 0.0001  max mem: 14938
[19:27:37.749031] Test:  [120/345]  eta: 0:00:45  loss: 0.7662 (0.7697)  time: 0.2011  data: 0.0001  max mem: 14938
[19:27:39.765407] Test:  [130/345]  eta: 0:00:43  loss: 0.7675 (0.7697)  time: 0.2014  data: 0.0001  max mem: 14938
[19:27:41.786898] Test:  [140/345]  eta: 0:00:41  loss: 0.7689 (0.7696)  time: 0.2018  data: 0.0001  max mem: 14938
[19:27:43.811708] Test:  [150/345]  eta: 0:00:39  loss: 0.7611 (0.7691)  time: 0.2023  data: 0.0001  max mem: 14938
[19:27:45.842805] Test:  [160/345]  eta: 0:00:37  loss: 0.7611 (0.7692)  time: 0.2027  data: 0.0001  max mem: 14938
[19:27:47.881074] Test:  [170/345]  eta: 0:00:35  loss: 0.7735 (0.7688)  time: 0.2034  data: 0.0001  max mem: 14938
[19:27:49.924397] Test:  [180/345]  eta: 0:00:33  loss: 0.7643 (0.7685)  time: 0.2040  data: 0.0001  max mem: 14938
[19:27:51.973664] Test:  [190/345]  eta: 0:00:31  loss: 0.7679 (0.7687)  time: 0.2046  data: 0.0001  max mem: 14938
[19:27:54.024335] Test:  [200/345]  eta: 0:00:29  loss: 0.7746 (0.7688)  time: 0.2049  data: 0.0001  max mem: 14938
[19:27:56.082852] Test:  [210/345]  eta: 0:00:27  loss: 0.7661 (0.7685)  time: 0.2054  data: 0.0001  max mem: 14938
[19:27:58.145028] Test:  [220/345]  eta: 0:00:25  loss: 0.7634 (0.7685)  time: 0.2060  data: 0.0001  max mem: 14938
[19:28:00.214982] Test:  [230/345]  eta: 0:00:23  loss: 0.7586 (0.7679)  time: 0.2065  data: 0.0001  max mem: 14938
[19:28:02.285647] Test:  [240/345]  eta: 0:00:21  loss: 0.7606 (0.7684)  time: 0.2070  data: 0.0001  max mem: 14938
[19:28:04.361715] Test:  [250/345]  eta: 0:00:19  loss: 0.7752 (0.7685)  time: 0.2073  data: 0.0001  max mem: 14938
[19:28:06.444450] Test:  [260/345]  eta: 0:00:17  loss: 0.7714 (0.7688)  time: 0.2079  data: 0.0001  max mem: 14938
[19:28:08.533685] Test:  [270/345]  eta: 0:00:15  loss: 0.7714 (0.7689)  time: 0.2085  data: 0.0001  max mem: 14938
[19:28:10.624895] Test:  [280/345]  eta: 0:00:13  loss: 0.7678 (0.7692)  time: 0.2090  data: 0.0001  max mem: 14938
[19:28:12.724346] Test:  [290/345]  eta: 0:00:11  loss: 0.7731 (0.7692)  time: 0.2095  data: 0.0001  max mem: 14938
[19:28:14.831187] Test:  [300/345]  eta: 0:00:09  loss: 0.7650 (0.7691)  time: 0.2103  data: 0.0001  max mem: 14938
[19:28:16.940669] Test:  [310/345]  eta: 0:00:07  loss: 0.7705 (0.7690)  time: 0.2108  data: 0.0001  max mem: 14938
[19:28:19.056514] Test:  [320/345]  eta: 0:00:05  loss: 0.7749 (0.7691)  time: 0.2112  data: 0.0001  max mem: 14938
[19:28:21.178033] Test:  [330/345]  eta: 0:00:03  loss: 0.7718 (0.7692)  time: 0.2118  data: 0.0001  max mem: 14938
[19:28:23.300038] Test:  [340/345]  eta: 0:00:01  loss: 0.7600 (0.7689)  time: 0.2121  data: 0.0001  max mem: 14938
[19:28:24.150067] Test:  [344/345]  eta: 0:00:00  loss: 0.7707 (0.7690)  time: 0.2122  data: 0.0001  max mem: 14938
[19:28:24.216232] Test: Total time: 0:01:10 (0.2053 s / it)
[19:28:40.861749] Test:  [ 0/57]  eta: 0:00:30  loss: 0.8313 (0.8313)  time: 0.5277  data: 0.3307  max mem: 14938
[19:28:42.788460] Test:  [10/57]  eta: 0:00:10  loss: 0.8653 (0.8677)  time: 0.2231  data: 0.0302  max mem: 14938
[19:28:44.724012] Test:  [20/57]  eta: 0:00:07  loss: 0.8653 (0.8617)  time: 0.1930  data: 0.0001  max mem: 14938
[19:28:46.664086] Test:  [30/57]  eta: 0:00:05  loss: 0.7683 (0.8262)  time: 0.1937  data: 0.0001  max mem: 14938
[19:28:48.612891] Test:  [40/57]  eta: 0:00:03  loss: 0.7510 (0.8079)  time: 0.1944  data: 0.0001  max mem: 14938
[19:28:50.565273] Test:  [50/57]  eta: 0:00:01  loss: 0.7431 (0.8010)  time: 0.1950  data: 0.0001  max mem: 14938
[19:28:51.628400] Test:  [56/57]  eta: 0:00:00  loss: 0.7778 (0.8074)  time: 0.1897  data: 0.0001  max mem: 14938
[19:28:51.691935] Test: Total time: 0:00:11 (0.1993 s / it)
[19:28:54.508564] Dice score of the network on the train images: 0.689306, val images: 0.758312
[19:28:54.512875] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:28:55.637065] Epoch: [15]  [  0/345]  eta: 0:06:27  lr: 0.000094  loss: 0.7908 (0.7908)  time: 1.1232  data: 0.3634  max mem: 14938
[19:29:10.696064] Epoch: [15]  [ 20/345]  eta: 0:04:10  lr: 0.000094  loss: 0.7912 (0.7971)  time: 0.7529  data: 0.0001  max mem: 14938
[19:29:25.940844] Epoch: [15]  [ 40/345]  eta: 0:03:53  lr: 0.000094  loss: 0.7949 (0.7991)  time: 0.7622  data: 0.0001  max mem: 14938
[19:29:41.131497] Epoch: [15]  [ 60/345]  eta: 0:03:37  lr: 0.000095  loss: 0.7933 (0.7987)  time: 0.7595  data: 0.0001  max mem: 14938
[19:29:56.347671] Epoch: [15]  [ 80/345]  eta: 0:03:22  lr: 0.000095  loss: 0.7960 (0.7989)  time: 0.7608  data: 0.0001  max mem: 14938
[19:30:11.577815] Epoch: [15]  [100/345]  eta: 0:03:06  lr: 0.000096  loss: 0.7872 (0.7962)  time: 0.7615  data: 0.0001  max mem: 14938
[19:30:26.801861] Epoch: [15]  [120/345]  eta: 0:02:51  lr: 0.000096  loss: 0.8062 (0.7991)  time: 0.7612  data: 0.0001  max mem: 14938
[19:30:42.016073] Epoch: [15]  [140/345]  eta: 0:02:36  lr: 0.000096  loss: 0.7947 (0.7987)  time: 0.7607  data: 0.0001  max mem: 14938
[19:30:57.220172] Epoch: [15]  [160/345]  eta: 0:02:20  lr: 0.000097  loss: 0.7992 (0.7989)  time: 0.7602  data: 0.0001  max mem: 14938
[19:31:12.433106] Epoch: [15]  [180/345]  eta: 0:02:05  lr: 0.000097  loss: 0.8058 (0.8001)  time: 0.7606  data: 0.0001  max mem: 14938
[19:31:27.628402] Epoch: [15]  [200/345]  eta: 0:01:50  lr: 0.000097  loss: 0.8016 (0.8004)  time: 0.7597  data: 0.0001  max mem: 14938
[19:31:42.824613] Epoch: [15]  [220/345]  eta: 0:01:35  lr: 0.000098  loss: 0.7976 (0.8003)  time: 0.7598  data: 0.0001  max mem: 14938
[19:31:58.018743] Epoch: [15]  [240/345]  eta: 0:01:19  lr: 0.000098  loss: 0.7957 (0.8000)  time: 0.7597  data: 0.0001  max mem: 14938
[19:32:13.209792] Epoch: [15]  [260/345]  eta: 0:01:04  lr: 0.000098  loss: 0.7834 (0.7993)  time: 0.7595  data: 0.0001  max mem: 14938
[19:32:28.463192] Epoch: [15]  [280/345]  eta: 0:00:49  lr: 0.000099  loss: 0.8065 (0.7998)  time: 0.7626  data: 0.0001  max mem: 14938
[19:32:43.662397] Epoch: [15]  [300/345]  eta: 0:00:34  lr: 0.000099  loss: 0.8056 (0.8002)  time: 0.7599  data: 0.0001  max mem: 14938
[19:32:58.854312] Epoch: [15]  [320/345]  eta: 0:00:19  lr: 0.000100  loss: 0.7949 (0.8003)  time: 0.7595  data: 0.0001  max mem: 14938
[19:33:14.044858] Epoch: [15]  [340/345]  eta: 0:00:03  lr: 0.000100  loss: 0.7905 (0.7999)  time: 0.7595  data: 0.0001  max mem: 14938
[19:33:17.083702] Epoch: [15]  [344/345]  eta: 0:00:00  lr: 0.000100  loss: 0.7867 (0.7997)  time: 0.7594  data: 0.0001  max mem: 14938
[19:33:17.154180] Epoch: [15] Total time: 0:04:22 (0.7613 s / it)
[19:33:17.154548] Averaged stats: lr: 0.000100  loss: 0.7867 (0.7997)
[19:33:17.718451] Test:  [  0/345]  eta: 0:03:12  loss: 0.7580 (0.7580)  time: 0.5588  data: 0.3589  max mem: 14938
[19:33:19.673120] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7600 (0.7633)  time: 0.2284  data: 0.0327  max mem: 14938
[19:33:21.632772] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7507 (0.7583)  time: 0.1956  data: 0.0001  max mem: 14938
[19:33:23.598949] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7507 (0.7578)  time: 0.1962  data: 0.0001  max mem: 14938
[19:33:25.569062] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7513 (0.7566)  time: 0.1968  data: 0.0001  max mem: 14938
[19:33:27.544506] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7570 (0.7581)  time: 0.1972  data: 0.0001  max mem: 14938
[19:33:29.525773] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7570 (0.7582)  time: 0.1978  data: 0.0001  max mem: 14938
[19:33:31.511019] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7570 (0.7580)  time: 0.1983  data: 0.0001  max mem: 14938
[19:33:33.498518] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7507 (0.7574)  time: 0.1986  data: 0.0001  max mem: 14938
[19:33:35.495899] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7436 (0.7567)  time: 0.1992  data: 0.0001  max mem: 14938
[19:33:37.497506] Test:  [100/345]  eta: 0:00:49  loss: 0.7541 (0.7573)  time: 0.1999  data: 0.0001  max mem: 14938
[19:33:39.500665] Test:  [110/345]  eta: 0:00:47  loss: 0.7611 (0.7574)  time: 0.2002  data: 0.0001  max mem: 14938
[19:33:41.510295] Test:  [120/345]  eta: 0:00:45  loss: 0.7576 (0.7572)  time: 0.2006  data: 0.0001  max mem: 14938
[19:33:43.528254] Test:  [130/345]  eta: 0:00:43  loss: 0.7489 (0.7569)  time: 0.2013  data: 0.0001  max mem: 14938
[19:33:45.550097] Test:  [140/345]  eta: 0:00:41  loss: 0.7589 (0.7574)  time: 0.2019  data: 0.0001  max mem: 14938
[19:33:47.578920] Test:  [150/345]  eta: 0:00:39  loss: 0.7557 (0.7570)  time: 0.2025  data: 0.0001  max mem: 14938
[19:33:49.609548] Test:  [160/345]  eta: 0:00:37  loss: 0.7593 (0.7577)  time: 0.2029  data: 0.0001  max mem: 14938
[19:33:51.648744] Test:  [170/345]  eta: 0:00:35  loss: 0.7603 (0.7575)  time: 0.2034  data: 0.0001  max mem: 14938
[19:33:53.695742] Test:  [180/345]  eta: 0:00:33  loss: 0.7644 (0.7577)  time: 0.2043  data: 0.0001  max mem: 14938
[19:33:55.742570] Test:  [190/345]  eta: 0:00:31  loss: 0.7625 (0.7578)  time: 0.2046  data: 0.0001  max mem: 14938
[19:33:57.795801] Test:  [200/345]  eta: 0:00:29  loss: 0.7525 (0.7576)  time: 0.2049  data: 0.0001  max mem: 14938
[19:33:59.852841] Test:  [210/345]  eta: 0:00:27  loss: 0.7480 (0.7574)  time: 0.2055  data: 0.0001  max mem: 14938
[19:34:01.914343] Test:  [220/345]  eta: 0:00:25  loss: 0.7507 (0.7575)  time: 0.2059  data: 0.0001  max mem: 14938
[19:34:03.982114] Test:  [230/345]  eta: 0:00:23  loss: 0.7616 (0.7578)  time: 0.2064  data: 0.0001  max mem: 14938
[19:34:06.055040] Test:  [240/345]  eta: 0:00:21  loss: 0.7609 (0.7578)  time: 0.2070  data: 0.0001  max mem: 14938
[19:34:08.132816] Test:  [250/345]  eta: 0:00:19  loss: 0.7585 (0.7579)  time: 0.2075  data: 0.0001  max mem: 14938
[19:34:10.216598] Test:  [260/345]  eta: 0:00:17  loss: 0.7494 (0.7576)  time: 0.2080  data: 0.0001  max mem: 14938
[19:34:12.306265] Test:  [270/345]  eta: 0:00:15  loss: 0.7494 (0.7575)  time: 0.2086  data: 0.0001  max mem: 14938
[19:34:14.401757] Test:  [280/345]  eta: 0:00:13  loss: 0.7615 (0.7577)  time: 0.2092  data: 0.0001  max mem: 14938
[19:34:16.501969] Test:  [290/345]  eta: 0:00:11  loss: 0.7615 (0.7580)  time: 0.2097  data: 0.0001  max mem: 14938
[19:34:18.606484] Test:  [300/345]  eta: 0:00:09  loss: 0.7573 (0.7579)  time: 0.2102  data: 0.0001  max mem: 14938
[19:34:20.717850] Test:  [310/345]  eta: 0:00:07  loss: 0.7501 (0.7576)  time: 0.2107  data: 0.0001  max mem: 14938
[19:34:22.835038] Test:  [320/345]  eta: 0:00:05  loss: 0.7522 (0.7574)  time: 0.2114  data: 0.0001  max mem: 14938
[19:34:24.957056] Test:  [330/345]  eta: 0:00:03  loss: 0.7577 (0.7573)  time: 0.2119  data: 0.0001  max mem: 14938
[19:34:27.080089] Test:  [340/345]  eta: 0:00:01  loss: 0.7580 (0.7574)  time: 0.2122  data: 0.0001  max mem: 14938
[19:34:27.931088] Test:  [344/345]  eta: 0:00:00  loss: 0.7536 (0.7573)  time: 0.2123  data: 0.0001  max mem: 14938
[19:34:27.987680] Test: Total time: 0:01:10 (0.2053 s / it)
[19:34:44.640357] Test:  [ 0/57]  eta: 0:00:31  loss: 0.8165 (0.8165)  time: 0.5470  data: 0.3503  max mem: 14938
[19:34:46.564745] Test:  [10/57]  eta: 0:00:10  loss: 0.8594 (0.8693)  time: 0.2246  data: 0.0319  max mem: 14938
[19:34:48.499808] Test:  [20/57]  eta: 0:00:07  loss: 0.8594 (0.8574)  time: 0.1929  data: 0.0001  max mem: 14938
[19:34:50.442668] Test:  [30/57]  eta: 0:00:05  loss: 0.7645 (0.8224)  time: 0.1938  data: 0.0001  max mem: 14938
[19:34:52.392429] Test:  [40/57]  eta: 0:00:03  loss: 0.7523 (0.8042)  time: 0.1946  data: 0.0001  max mem: 14938
[19:34:54.347344] Test:  [50/57]  eta: 0:00:01  loss: 0.7485 (0.7982)  time: 0.1952  data: 0.0001  max mem: 14938
[19:34:55.410976] Test:  [56/57]  eta: 0:00:00  loss: 0.7683 (0.8047)  time: 0.1898  data: 0.0001  max mem: 14938
[19:34:55.483248] Test: Total time: 0:00:11 (0.1998 s / it)
[19:34:58.250452] Dice score of the network on the train images: 0.702293, val images: 0.761427
[19:34:58.250667] saving best_prec_model_0 @ epoch 15
[19:34:59.313281] saving best_dice_model_0 @ epoch 15
[19:35:00.343926] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:35:01.508397] Epoch: [16]  [  0/345]  eta: 0:06:41  lr: 0.000100  loss: 0.7610 (0.7610)  time: 1.1633  data: 0.4012  max mem: 14938
[19:35:16.565327] Epoch: [16]  [ 20/345]  eta: 0:04:10  lr: 0.000100  loss: 0.7860 (0.7863)  time: 0.7527  data: 0.0001  max mem: 14938
[19:35:31.670370] Epoch: [16]  [ 40/345]  eta: 0:03:53  lr: 0.000101  loss: 0.8013 (0.7949)  time: 0.7552  data: 0.0001  max mem: 14938
[19:35:46.841234] Epoch: [16]  [ 60/345]  eta: 0:03:37  lr: 0.000101  loss: 0.8016 (0.7958)  time: 0.7585  data: 0.0001  max mem: 14938
[19:36:02.039722] Epoch: [16]  [ 80/345]  eta: 0:03:21  lr: 0.000101  loss: 0.8059 (0.7984)  time: 0.7599  data: 0.0001  max mem: 14938
[19:36:17.229260] Epoch: [16]  [100/345]  eta: 0:03:06  lr: 0.000102  loss: 0.7930 (0.7980)  time: 0.7594  data: 0.0001  max mem: 14938
[19:36:32.406594] Epoch: [16]  [120/345]  eta: 0:02:51  lr: 0.000102  loss: 0.7842 (0.7962)  time: 0.7588  data: 0.0001  max mem: 14938
[19:36:47.610327] Epoch: [16]  [140/345]  eta: 0:02:35  lr: 0.000103  loss: 0.7873 (0.7947)  time: 0.7601  data: 0.0001  max mem: 14938
[19:37:02.837374] Epoch: [16]  [160/345]  eta: 0:02:20  lr: 0.000103  loss: 0.7959 (0.7947)  time: 0.7613  data: 0.0001  max mem: 14938
[19:37:18.037859] Epoch: [16]  [180/345]  eta: 0:02:05  lr: 0.000103  loss: 0.7998 (0.7956)  time: 0.7600  data: 0.0001  max mem: 14938
[19:37:33.258720] Epoch: [16]  [200/345]  eta: 0:01:50  lr: 0.000104  loss: 0.7889 (0.7954)  time: 0.7610  data: 0.0001  max mem: 14938
[19:37:48.475092] Epoch: [16]  [220/345]  eta: 0:01:35  lr: 0.000104  loss: 0.7923 (0.7948)  time: 0.7608  data: 0.0001  max mem: 14938
[19:38:03.680732] Epoch: [16]  [240/345]  eta: 0:01:19  lr: 0.000104  loss: 0.7826 (0.7941)  time: 0.7602  data: 0.0001  max mem: 14938
[19:38:18.878059] Epoch: [16]  [260/345]  eta: 0:01:04  lr: 0.000105  loss: 0.7898 (0.7939)  time: 0.7598  data: 0.0001  max mem: 14938
[19:38:34.068554] Epoch: [16]  [280/345]  eta: 0:00:49  lr: 0.000105  loss: 0.8000 (0.7943)  time: 0.7595  data: 0.0001  max mem: 14938
[19:38:49.267701] Epoch: [16]  [300/345]  eta: 0:00:34  lr: 0.000105  loss: 0.7940 (0.7944)  time: 0.7599  data: 0.0001  max mem: 14938
[19:39:04.545110] Epoch: [16]  [320/345]  eta: 0:00:19  lr: 0.000106  loss: 0.7963 (0.7948)  time: 0.7638  data: 0.0001  max mem: 14938
[19:39:19.730958] Epoch: [16]  [340/345]  eta: 0:00:03  lr: 0.000106  loss: 0.7983 (0.7951)  time: 0.7593  data: 0.0001  max mem: 14938
[19:39:22.769721] Epoch: [16]  [344/345]  eta: 0:00:00  lr: 0.000106  loss: 0.7876 (0.7949)  time: 0.7593  data: 0.0001  max mem: 14938
[19:39:22.846258] Epoch: [16] Total time: 0:04:22 (0.7609 s / it)
[19:39:22.846747] Averaged stats: lr: 0.000106  loss: 0.7876 (0.7949)
[19:39:23.395864] Test:  [  0/345]  eta: 0:03:07  loss: 0.7602 (0.7602)  time: 0.5435  data: 0.3437  max mem: 14938
[19:39:25.351143] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7653 (0.7687)  time: 0.2271  data: 0.0313  max mem: 14938
[19:39:27.313273] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7686 (0.7692)  time: 0.1958  data: 0.0001  max mem: 14938
[19:39:29.279269] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7705 (0.7693)  time: 0.1963  data: 0.0001  max mem: 14938
[19:39:31.251397] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7673 (0.7693)  time: 0.1968  data: 0.0001  max mem: 14938
[19:39:33.227517] Test:  [ 50/345]  eta: 0:00:59  loss: 0.7670 (0.7683)  time: 0.1974  data: 0.0001  max mem: 14938
[19:39:35.212455] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7586 (0.7676)  time: 0.1980  data: 0.0001  max mem: 14938
[19:39:37.197963] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7582 (0.7669)  time: 0.1985  data: 0.0001  max mem: 14938
[19:39:39.188749] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7609 (0.7667)  time: 0.1988  data: 0.0001  max mem: 14938
[19:39:41.185161] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7596 (0.7659)  time: 0.1993  data: 0.0001  max mem: 14938
[19:39:43.187862] Test:  [100/345]  eta: 0:00:49  loss: 0.7575 (0.7655)  time: 0.1999  data: 0.0001  max mem: 14938
[19:39:45.195281] Test:  [110/345]  eta: 0:00:47  loss: 0.7633 (0.7650)  time: 0.2004  data: 0.0001  max mem: 14938
[19:39:47.207089] Test:  [120/345]  eta: 0:00:45  loss: 0.7601 (0.7646)  time: 0.2009  data: 0.0001  max mem: 14938
[19:39:49.224931] Test:  [130/345]  eta: 0:00:43  loss: 0.7601 (0.7641)  time: 0.2014  data: 0.0001  max mem: 14938
[19:39:51.247813] Test:  [140/345]  eta: 0:00:41  loss: 0.7625 (0.7643)  time: 0.2020  data: 0.0001  max mem: 14938
[19:39:53.277095] Test:  [150/345]  eta: 0:00:39  loss: 0.7733 (0.7655)  time: 0.2025  data: 0.0001  max mem: 14938
[19:39:55.309250] Test:  [160/345]  eta: 0:00:37  loss: 0.7738 (0.7656)  time: 0.2030  data: 0.0001  max mem: 14938
[19:39:57.346688] Test:  [170/345]  eta: 0:00:35  loss: 0.7640 (0.7655)  time: 0.2034  data: 0.0001  max mem: 14938
[19:39:59.386840] Test:  [180/345]  eta: 0:00:33  loss: 0.7640 (0.7653)  time: 0.2038  data: 0.0001  max mem: 14938
[19:40:01.435441] Test:  [190/345]  eta: 0:00:31  loss: 0.7575 (0.7646)  time: 0.2044  data: 0.0001  max mem: 14938
[19:40:03.487686] Test:  [200/345]  eta: 0:00:29  loss: 0.7543 (0.7643)  time: 0.2050  data: 0.0001  max mem: 14938
[19:40:05.546515] Test:  [210/345]  eta: 0:00:27  loss: 0.7581 (0.7642)  time: 0.2055  data: 0.0001  max mem: 14938
[19:40:07.608248] Test:  [220/345]  eta: 0:00:25  loss: 0.7636 (0.7643)  time: 0.2060  data: 0.0001  max mem: 14938
[19:40:09.677292] Test:  [230/345]  eta: 0:00:23  loss: 0.7645 (0.7644)  time: 0.2065  data: 0.0001  max mem: 14938
[19:40:11.750541] Test:  [240/345]  eta: 0:00:21  loss: 0.7596 (0.7643)  time: 0.2071  data: 0.0001  max mem: 14938
[19:40:13.828173] Test:  [250/345]  eta: 0:00:19  loss: 0.7639 (0.7645)  time: 0.2075  data: 0.0001  max mem: 14938
[19:40:15.910464] Test:  [260/345]  eta: 0:00:17  loss: 0.7639 (0.7643)  time: 0.2079  data: 0.0001  max mem: 14938
[19:40:17.998472] Test:  [270/345]  eta: 0:00:15  loss: 0.7597 (0.7640)  time: 0.2085  data: 0.0001  max mem: 14938
[19:40:20.093092] Test:  [280/345]  eta: 0:00:13  loss: 0.7563 (0.7637)  time: 0.2091  data: 0.0001  max mem: 14938
[19:40:22.190364] Test:  [290/345]  eta: 0:00:11  loss: 0.7627 (0.7640)  time: 0.2095  data: 0.0001  max mem: 14938
[19:40:24.296632] Test:  [300/345]  eta: 0:00:09  loss: 0.7627 (0.7641)  time: 0.2101  data: 0.0001  max mem: 14938
[19:40:26.405453] Test:  [310/345]  eta: 0:00:07  loss: 0.7619 (0.7641)  time: 0.2107  data: 0.0001  max mem: 14938
[19:40:28.521491] Test:  [320/345]  eta: 0:00:05  loss: 0.7611 (0.7641)  time: 0.2112  data: 0.0001  max mem: 14938
[19:40:30.642737] Test:  [330/345]  eta: 0:00:03  loss: 0.7641 (0.7643)  time: 0.2118  data: 0.0001  max mem: 14938
[19:40:32.765696] Test:  [340/345]  eta: 0:00:01  loss: 0.7644 (0.7641)  time: 0.2122  data: 0.0001  max mem: 14938
[19:40:33.617535] Test:  [344/345]  eta: 0:00:00  loss: 0.7644 (0.7643)  time: 0.2124  data: 0.0001  max mem: 14938
[19:40:33.679868] Test: Total time: 0:01:10 (0.2053 s / it)
[19:40:50.431505] Test:  [ 0/57]  eta: 0:00:29  loss: 0.8445 (0.8445)  time: 0.5104  data: 0.3140  max mem: 14938
[19:40:52.359231] Test:  [10/57]  eta: 0:00:10  loss: 0.8768 (0.8830)  time: 0.2216  data: 0.0286  max mem: 14938
[19:40:54.295639] Test:  [20/57]  eta: 0:00:07  loss: 0.8768 (0.8691)  time: 0.1931  data: 0.0001  max mem: 14938
[19:40:56.237250] Test:  [30/57]  eta: 0:00:05  loss: 0.7821 (0.8373)  time: 0.1938  data: 0.0001  max mem: 14938
[19:40:58.186295] Test:  [40/57]  eta: 0:00:03  loss: 0.7738 (0.8199)  time: 0.1945  data: 0.0001  max mem: 14938
[19:41:00.142338] Test:  [50/57]  eta: 0:00:01  loss: 0.7688 (0.8139)  time: 0.1952  data: 0.0001  max mem: 14938
[19:41:01.206497] Test:  [56/57]  eta: 0:00:00  loss: 0.7841 (0.8199)  time: 0.1899  data: 0.0001  max mem: 14938
[19:41:01.272839] Test: Total time: 0:00:11 (0.1992 s / it)
[19:41:04.063813] Dice score of the network on the train images: 0.707577, val images: 0.749871
[19:41:04.064034] saving best_prec_model_0 @ epoch 16
[19:41:05.163496] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:41:06.271008] Epoch: [17]  [  0/345]  eta: 0:06:21  lr: 0.000106  loss: 0.7765 (0.7765)  time: 1.1063  data: 0.3417  max mem: 14938
[19:41:21.331686] Epoch: [17]  [ 20/345]  eta: 0:04:10  lr: 0.000107  loss: 0.7903 (0.7913)  time: 0.7530  data: 0.0001  max mem: 14938
[19:41:36.451317] Epoch: [17]  [ 40/345]  eta: 0:03:52  lr: 0.000107  loss: 0.7929 (0.7955)  time: 0.7559  data: 0.0001  max mem: 14938
[19:41:51.624818] Epoch: [17]  [ 60/345]  eta: 0:03:37  lr: 0.000107  loss: 0.7842 (0.7937)  time: 0.7586  data: 0.0001  max mem: 14938
[19:42:06.824879] Epoch: [17]  [ 80/345]  eta: 0:03:21  lr: 0.000108  loss: 0.7813 (0.7913)  time: 0.7600  data: 0.0001  max mem: 14938
[19:42:22.039719] Epoch: [17]  [100/345]  eta: 0:03:06  lr: 0.000108  loss: 0.8067 (0.7936)  time: 0.7607  data: 0.0001  max mem: 14938
[19:42:37.264161] Epoch: [17]  [120/345]  eta: 0:02:51  lr: 0.000108  loss: 0.8038 (0.7946)  time: 0.7612  data: 0.0001  max mem: 14938
[19:42:52.479712] Epoch: [17]  [140/345]  eta: 0:02:36  lr: 0.000109  loss: 0.8381 (0.7998)  time: 0.7607  data: 0.0001  max mem: 14938
[19:43:07.681607] Epoch: [17]  [160/345]  eta: 0:02:20  lr: 0.000109  loss: 0.8076 (0.8011)  time: 0.7601  data: 0.0001  max mem: 14938
[19:43:22.894441] Epoch: [17]  [180/345]  eta: 0:02:05  lr: 0.000110  loss: 0.8085 (0.8020)  time: 0.7606  data: 0.0001  max mem: 14938
[19:43:38.092388] Epoch: [17]  [200/345]  eta: 0:01:50  lr: 0.000110  loss: 0.8006 (0.8018)  time: 0.7599  data: 0.0001  max mem: 14938
[19:43:53.287980] Epoch: [17]  [220/345]  eta: 0:01:35  lr: 0.000110  loss: 0.7892 (0.8006)  time: 0.7597  data: 0.0001  max mem: 14938
[19:44:08.478827] Epoch: [17]  [240/345]  eta: 0:01:19  lr: 0.000111  loss: 0.7804 (0.7996)  time: 0.7595  data: 0.0001  max mem: 14938
[19:44:23.674021] Epoch: [17]  [260/345]  eta: 0:01:04  lr: 0.000111  loss: 0.7900 (0.7991)  time: 0.7597  data: 0.0001  max mem: 14938
[19:44:38.868267] Epoch: [17]  [280/345]  eta: 0:00:49  lr: 0.000111  loss: 0.7796 (0.7978)  time: 0.7597  data: 0.0001  max mem: 14938
[19:44:54.065074] Epoch: [17]  [300/345]  eta: 0:00:34  lr: 0.000112  loss: 0.7839 (0.7972)  time: 0.7598  data: 0.0001  max mem: 14938
[19:45:09.259429] Epoch: [17]  [320/345]  eta: 0:00:19  lr: 0.000112  loss: 0.7765 (0.7962)  time: 0.7597  data: 0.0001  max mem: 14938
[19:45:24.453268] Epoch: [17]  [340/345]  eta: 0:00:03  lr: 0.000112  loss: 0.7783 (0.7955)  time: 0.7596  data: 0.0001  max mem: 14938
[19:45:27.488160] Epoch: [17]  [344/345]  eta: 0:00:00  lr: 0.000112  loss: 0.7890 (0.7954)  time: 0.7594  data: 0.0001  max mem: 14938
[19:45:27.553937] Epoch: [17] Total time: 0:04:22 (0.7606 s / it)
[19:45:27.554267] Averaged stats: lr: 0.000112  loss: 0.7890 (0.7954)
[19:45:28.114531] Test:  [  0/345]  eta: 0:03:10  loss: 0.7669 (0.7669)  time: 0.5534  data: 0.3537  max mem: 14938
[19:45:30.070299] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7609 (0.7583)  time: 0.2280  data: 0.0322  max mem: 14938
[19:45:32.030045] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7468 (0.7507)  time: 0.1957  data: 0.0001  max mem: 14938
[19:45:33.996586] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7565 (0.7579)  time: 0.1963  data: 0.0001  max mem: 14938
[19:45:35.969755] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7666 (0.7581)  time: 0.1969  data: 0.0001  max mem: 14938
[19:45:37.945576] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7666 (0.7611)  time: 0.1974  data: 0.0001  max mem: 14938
[19:45:39.929783] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7594 (0.7592)  time: 0.1979  data: 0.0001  max mem: 14938
[19:45:41.915897] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7514 (0.7582)  time: 0.1985  data: 0.0001  max mem: 14938
[19:45:43.906552] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7525 (0.7581)  time: 0.1988  data: 0.0001  max mem: 14938
[19:45:45.901453] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7568 (0.7581)  time: 0.1992  data: 0.0001  max mem: 14938
[19:45:47.902200] Test:  [100/345]  eta: 0:00:49  loss: 0.7540 (0.7580)  time: 0.1997  data: 0.0001  max mem: 14938
[19:45:49.908103] Test:  [110/345]  eta: 0:00:47  loss: 0.7510 (0.7571)  time: 0.2003  data: 0.0001  max mem: 14938
[19:45:51.920041] Test:  [120/345]  eta: 0:00:45  loss: 0.7508 (0.7575)  time: 0.2008  data: 0.0001  max mem: 14938
[19:45:53.937845] Test:  [130/345]  eta: 0:00:43  loss: 0.7627 (0.7579)  time: 0.2014  data: 0.0001  max mem: 14938
[19:45:55.961548] Test:  [140/345]  eta: 0:00:41  loss: 0.7627 (0.7578)  time: 0.2020  data: 0.0001  max mem: 14938
[19:45:57.988787] Test:  [150/345]  eta: 0:00:39  loss: 0.7532 (0.7572)  time: 0.2025  data: 0.0001  max mem: 14938
[19:46:00.021489] Test:  [160/345]  eta: 0:00:37  loss: 0.7551 (0.7574)  time: 0.2029  data: 0.0001  max mem: 14938
[19:46:02.060221] Test:  [170/345]  eta: 0:00:35  loss: 0.7594 (0.7572)  time: 0.2035  data: 0.0001  max mem: 14938
[19:46:04.102092] Test:  [180/345]  eta: 0:00:33  loss: 0.7571 (0.7576)  time: 0.2040  data: 0.0001  max mem: 14938
[19:46:06.147504] Test:  [190/345]  eta: 0:00:31  loss: 0.7592 (0.7580)  time: 0.2043  data: 0.0001  max mem: 14938
[19:46:08.200795] Test:  [200/345]  eta: 0:00:29  loss: 0.7595 (0.7580)  time: 0.2049  data: 0.0001  max mem: 14938
[19:46:10.259257] Test:  [210/345]  eta: 0:00:27  loss: 0.7570 (0.7583)  time: 0.2055  data: 0.0001  max mem: 14938
[19:46:12.322930] Test:  [220/345]  eta: 0:00:25  loss: 0.7578 (0.7582)  time: 0.2060  data: 0.0001  max mem: 14938
[19:46:14.391656] Test:  [230/345]  eta: 0:00:23  loss: 0.7575 (0.7581)  time: 0.2066  data: 0.0001  max mem: 14938
[19:46:16.466192] Test:  [240/345]  eta: 0:00:21  loss: 0.7523 (0.7578)  time: 0.2071  data: 0.0001  max mem: 14938
[19:46:18.545986] Test:  [250/345]  eta: 0:00:19  loss: 0.7525 (0.7579)  time: 0.2077  data: 0.0001  max mem: 14938
[19:46:20.629201] Test:  [260/345]  eta: 0:00:17  loss: 0.7619 (0.7581)  time: 0.2081  data: 0.0001  max mem: 14938
[19:46:22.716853] Test:  [270/345]  eta: 0:00:15  loss: 0.7627 (0.7584)  time: 0.2085  data: 0.0001  max mem: 14938
[19:46:24.809236] Test:  [280/345]  eta: 0:00:13  loss: 0.7577 (0.7584)  time: 0.2089  data: 0.0001  max mem: 14938
[19:46:26.909882] Test:  [290/345]  eta: 0:00:11  loss: 0.7519 (0.7581)  time: 0.2096  data: 0.0001  max mem: 14938
[19:46:29.014324] Test:  [300/345]  eta: 0:00:09  loss: 0.7602 (0.7583)  time: 0.2102  data: 0.0001  max mem: 14938
[19:46:31.127179] Test:  [310/345]  eta: 0:00:07  loss: 0.7637 (0.7584)  time: 0.2108  data: 0.0001  max mem: 14938
[19:46:33.241773] Test:  [320/345]  eta: 0:00:05  loss: 0.7494 (0.7581)  time: 0.2113  data: 0.0001  max mem: 14938
[19:46:35.364375] Test:  [330/345]  eta: 0:00:03  loss: 0.7475 (0.7578)  time: 0.2118  data: 0.0001  max mem: 14938
[19:46:37.488956] Test:  [340/345]  eta: 0:00:01  loss: 0.7522 (0.7577)  time: 0.2123  data: 0.0001  max mem: 14938
[19:46:38.341365] Test:  [344/345]  eta: 0:00:00  loss: 0.7531 (0.7575)  time: 0.2125  data: 0.0001  max mem: 14938
[19:46:38.409555] Test: Total time: 0:01:10 (0.2054 s / it)
[19:46:55.047132] Test:  [ 0/57]  eta: 0:00:29  loss: 0.8217 (0.8217)  time: 0.5253  data: 0.3291  max mem: 14938
[19:46:56.977607] Test:  [10/57]  eta: 0:00:10  loss: 0.8552 (0.8821)  time: 0.2232  data: 0.0300  max mem: 14938
[19:46:58.916091] Test:  [20/57]  eta: 0:00:07  loss: 0.8821 (0.8712)  time: 0.1934  data: 0.0001  max mem: 14938
[19:47:00.859952] Test:  [30/57]  eta: 0:00:05  loss: 0.7692 (0.8345)  time: 0.1941  data: 0.0001  max mem: 14938
[19:47:02.808742] Test:  [40/57]  eta: 0:00:03  loss: 0.7674 (0.8162)  time: 0.1946  data: 0.0001  max mem: 14938
[19:47:04.764723] Test:  [50/57]  eta: 0:00:01  loss: 0.7666 (0.8096)  time: 0.1952  data: 0.0001  max mem: 14938
[19:47:05.829124] Test:  [56/57]  eta: 0:00:00  loss: 0.7810 (0.8148)  time: 0.1900  data: 0.0000  max mem: 14938
[19:47:05.892571] Test: Total time: 0:00:11 (0.1995 s / it)
[19:47:08.717896] Dice score of the network on the train images: 0.708019, val images: 0.748980
[19:47:08.721602] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:47:09.878239] Epoch: [18]  [  0/345]  eta: 0:06:38  lr: 0.000113  loss: 0.7841 (0.7841)  time: 1.1557  data: 0.3911  max mem: 14938
[19:47:24.947785] Epoch: [18]  [ 20/345]  eta: 0:04:11  lr: 0.000113  loss: 0.7691 (0.7776)  time: 0.7534  data: 0.0001  max mem: 14938
[19:47:40.070783] Epoch: [18]  [ 40/345]  eta: 0:03:53  lr: 0.000113  loss: 0.7832 (0.7813)  time: 0.7561  data: 0.0001  max mem: 14938
[19:47:55.225382] Epoch: [18]  [ 60/345]  eta: 0:03:37  lr: 0.000114  loss: 0.7866 (0.7835)  time: 0.7577  data: 0.0001  max mem: 14938
[19:48:10.422421] Epoch: [18]  [ 80/345]  eta: 0:03:21  lr: 0.000114  loss: 0.7844 (0.7855)  time: 0.7598  data: 0.0001  max mem: 14938
[19:48:25.619610] Epoch: [18]  [100/345]  eta: 0:03:06  lr: 0.000114  loss: 0.7879 (0.7871)  time: 0.7598  data: 0.0001  max mem: 14938
[19:48:40.849931] Epoch: [18]  [120/345]  eta: 0:02:51  lr: 0.000115  loss: 0.7891 (0.7877)  time: 0.7615  data: 0.0001  max mem: 14938
[19:48:56.084648] Epoch: [18]  [140/345]  eta: 0:02:36  lr: 0.000115  loss: 0.7816 (0.7863)  time: 0.7617  data: 0.0001  max mem: 14938
[19:49:11.284779] Epoch: [18]  [160/345]  eta: 0:02:20  lr: 0.000115  loss: 0.7954 (0.7872)  time: 0.7600  data: 0.0001  max mem: 14938
[19:49:26.477764] Epoch: [18]  [180/345]  eta: 0:02:05  lr: 0.000116  loss: 0.7872 (0.7870)  time: 0.7596  data: 0.0001  max mem: 14938
[19:49:41.690318] Epoch: [18]  [200/345]  eta: 0:01:50  lr: 0.000116  loss: 0.7856 (0.7869)  time: 0.7606  data: 0.0001  max mem: 14938
[19:49:56.911029] Epoch: [18]  [220/345]  eta: 0:01:35  lr: 0.000116  loss: 0.7858 (0.7867)  time: 0.7610  data: 0.0001  max mem: 14938
[19:50:12.102825] Epoch: [18]  [240/345]  eta: 0:01:19  lr: 0.000117  loss: 0.7884 (0.7869)  time: 0.7595  data: 0.0001  max mem: 14938
[19:50:27.299634] Epoch: [18]  [260/345]  eta: 0:01:04  lr: 0.000117  loss: 0.7801 (0.7864)  time: 0.7598  data: 0.0001  max mem: 14938
[19:50:42.514047] Epoch: [18]  [280/345]  eta: 0:00:49  lr: 0.000118  loss: 0.7772 (0.7861)  time: 0.7607  data: 0.0001  max mem: 14938
[19:50:57.710414] Epoch: [18]  [300/345]  eta: 0:00:34  lr: 0.000118  loss: 0.7844 (0.7860)  time: 0.7598  data: 0.0001  max mem: 14938
[19:51:12.902752] Epoch: [18]  [320/345]  eta: 0:00:19  lr: 0.000118  loss: 0.7907 (0.7862)  time: 0.7596  data: 0.0001  max mem: 14938
[19:51:28.100345] Epoch: [18]  [340/345]  eta: 0:00:03  lr: 0.000119  loss: 0.7796 (0.7858)  time: 0.7598  data: 0.0001  max mem: 14938
[19:51:31.133841] Epoch: [18]  [344/345]  eta: 0:00:00  lr: 0.000119  loss: 0.7812 (0.7858)  time: 0.7595  data: 0.0001  max mem: 14938
[19:51:31.204583] Epoch: [18] Total time: 0:04:22 (0.7608 s / it)
[19:51:31.205357] Averaged stats: lr: 0.000119  loss: 0.7812 (0.7858)
[19:51:31.759109] Test:  [  0/345]  eta: 0:03:09  loss: 0.7414 (0.7414)  time: 0.5487  data: 0.3488  max mem: 14938
[19:51:33.714734] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7370 (0.7372)  time: 0.2276  data: 0.0318  max mem: 14938
[19:51:35.677454] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7430 (0.7463)  time: 0.1958  data: 0.0001  max mem: 14938
[19:51:37.644672] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7509 (0.7480)  time: 0.1964  data: 0.0001  max mem: 14938
[19:51:39.616382] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7495 (0.7473)  time: 0.1969  data: 0.0001  max mem: 14938
[19:51:41.595259] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7464 (0.7482)  time: 0.1975  data: 0.0001  max mem: 14938
[19:51:43.580425] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7472 (0.7474)  time: 0.1981  data: 0.0001  max mem: 14938
[19:51:45.572011] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7472 (0.7465)  time: 0.1988  data: 0.0001  max mem: 14938
[19:51:47.562258] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7459 (0.7470)  time: 0.1990  data: 0.0001  max mem: 14938
[19:51:49.563774] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7452 (0.7469)  time: 0.1995  data: 0.0001  max mem: 14938
[19:51:51.565278] Test:  [100/345]  eta: 0:00:49  loss: 0.7353 (0.7457)  time: 0.2001  data: 0.0001  max mem: 14938
[19:51:53.569986] Test:  [110/345]  eta: 0:00:47  loss: 0.7404 (0.7461)  time: 0.2002  data: 0.0001  max mem: 14938
[19:51:55.585180] Test:  [120/345]  eta: 0:00:45  loss: 0.7418 (0.7462)  time: 0.2009  data: 0.0001  max mem: 14938
[19:51:57.603070] Test:  [130/345]  eta: 0:00:43  loss: 0.7439 (0.7463)  time: 0.2016  data: 0.0001  max mem: 14938
[19:51:59.625086] Test:  [140/345]  eta: 0:00:41  loss: 0.7453 (0.7463)  time: 0.2019  data: 0.0001  max mem: 14938
[19:52:01.653262] Test:  [150/345]  eta: 0:00:39  loss: 0.7324 (0.7462)  time: 0.2024  data: 0.0001  max mem: 14938
[19:52:03.687386] Test:  [160/345]  eta: 0:00:37  loss: 0.7501 (0.7469)  time: 0.2031  data: 0.0001  max mem: 14938
[19:52:05.725959] Test:  [170/345]  eta: 0:00:35  loss: 0.7544 (0.7476)  time: 0.2036  data: 0.0001  max mem: 14938
[19:52:07.768704] Test:  [180/345]  eta: 0:00:33  loss: 0.7544 (0.7481)  time: 0.2040  data: 0.0001  max mem: 14938
[19:52:09.816977] Test:  [190/345]  eta: 0:00:31  loss: 0.7509 (0.7482)  time: 0.2045  data: 0.0001  max mem: 14938
[19:52:11.869617] Test:  [200/345]  eta: 0:00:29  loss: 0.7509 (0.7481)  time: 0.2050  data: 0.0001  max mem: 14938
[19:52:13.930121] Test:  [210/345]  eta: 0:00:27  loss: 0.7412 (0.7479)  time: 0.2056  data: 0.0001  max mem: 14938
[19:52:15.994350] Test:  [220/345]  eta: 0:00:25  loss: 0.7404 (0.7476)  time: 0.2062  data: 0.0001  max mem: 14938
[19:52:18.065527] Test:  [230/345]  eta: 0:00:23  loss: 0.7443 (0.7476)  time: 0.2067  data: 0.0001  max mem: 14938
[19:52:20.138343] Test:  [240/345]  eta: 0:00:21  loss: 0.7480 (0.7476)  time: 0.2071  data: 0.0001  max mem: 14938
[19:52:22.216981] Test:  [250/345]  eta: 0:00:19  loss: 0.7428 (0.7474)  time: 0.2075  data: 0.0001  max mem: 14938
[19:52:24.299099] Test:  [260/345]  eta: 0:00:17  loss: 0.7497 (0.7480)  time: 0.2080  data: 0.0001  max mem: 14938
[19:52:26.387360] Test:  [270/345]  eta: 0:00:15  loss: 0.7497 (0.7480)  time: 0.2085  data: 0.0001  max mem: 14938
[19:52:28.479876] Test:  [280/345]  eta: 0:00:13  loss: 0.7441 (0.7481)  time: 0.2090  data: 0.0001  max mem: 14938
[19:52:30.578798] Test:  [290/345]  eta: 0:00:11  loss: 0.7471 (0.7484)  time: 0.2095  data: 0.0001  max mem: 14938
[19:52:32.684064] Test:  [300/345]  eta: 0:00:09  loss: 0.7479 (0.7485)  time: 0.2102  data: 0.0001  max mem: 14938
[19:52:34.793118] Test:  [310/345]  eta: 0:00:07  loss: 0.7454 (0.7484)  time: 0.2107  data: 0.0001  max mem: 14938
[19:52:36.910401] Test:  [320/345]  eta: 0:00:05  loss: 0.7454 (0.7483)  time: 0.2113  data: 0.0001  max mem: 14938
[19:52:39.032288] Test:  [330/345]  eta: 0:00:03  loss: 0.7508 (0.7485)  time: 0.2119  data: 0.0001  max mem: 14938
[19:52:41.155294] Test:  [340/345]  eta: 0:00:01  loss: 0.7422 (0.7482)  time: 0.2122  data: 0.0001  max mem: 14938
[19:52:42.006136] Test:  [344/345]  eta: 0:00:00  loss: 0.7394 (0.7482)  time: 0.2123  data: 0.0001  max mem: 14938
[19:52:42.074464] Test: Total time: 0:01:10 (0.2054 s / it)
[19:52:58.704853] Test:  [ 0/57]  eta: 0:00:29  loss: 0.8406 (0.8406)  time: 0.5239  data: 0.3278  max mem: 14938
[19:53:00.633378] Test:  [10/57]  eta: 0:00:10  loss: 0.8784 (0.8799)  time: 0.2229  data: 0.0299  max mem: 14938
[19:53:02.569466] Test:  [20/57]  eta: 0:00:07  loss: 0.8909 (0.8757)  time: 0.1932  data: 0.0001  max mem: 14938
[19:53:04.511750] Test:  [30/57]  eta: 0:00:05  loss: 0.7710 (0.8333)  time: 0.1939  data: 0.0001  max mem: 14938
[19:53:06.458997] Test:  [40/57]  eta: 0:00:03  loss: 0.7464 (0.8108)  time: 0.1944  data: 0.0001  max mem: 14938
[19:53:08.410525] Test:  [50/57]  eta: 0:00:01  loss: 0.7488 (0.8045)  time: 0.1949  data: 0.0001  max mem: 14938
[19:53:09.471967] Test:  [56/57]  eta: 0:00:00  loss: 0.7845 (0.8109)  time: 0.1896  data: 0.0000  max mem: 14938
[19:53:09.533022] Test: Total time: 0:00:11 (0.1992 s / it)
[19:53:12.290704] Dice score of the network on the train images: 0.705010, val images: 0.763640
[19:53:12.290923] saving best_dice_model_0 @ epoch 18
[19:53:13.401784] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:53:14.494504] Epoch: [19]  [  0/345]  eta: 0:06:16  lr: 0.000119  loss: 0.7686 (0.7686)  time: 1.0916  data: 0.3281  max mem: 14938
[19:53:29.558126] Epoch: [19]  [ 20/345]  eta: 0:04:10  lr: 0.000119  loss: 0.7715 (0.7724)  time: 0.7531  data: 0.0001  max mem: 14938
[19:53:44.680849] Epoch: [19]  [ 40/345]  eta: 0:03:52  lr: 0.000119  loss: 0.7874 (0.7798)  time: 0.7561  data: 0.0001  max mem: 14938
[19:53:59.843116] Epoch: [19]  [ 60/345]  eta: 0:03:36  lr: 0.000120  loss: 0.7854 (0.7812)  time: 0.7581  data: 0.0001  max mem: 14938
[19:54:15.050459] Epoch: [19]  [ 80/345]  eta: 0:03:21  lr: 0.000120  loss: 0.7797 (0.7806)  time: 0.7603  data: 0.0001  max mem: 14938
[19:54:30.284231] Epoch: [19]  [100/345]  eta: 0:03:06  lr: 0.000121  loss: 0.7846 (0.7828)  time: 0.7616  data: 0.0001  max mem: 14938
[19:54:45.519637] Epoch: [19]  [120/345]  eta: 0:02:51  lr: 0.000121  loss: 0.7957 (0.7849)  time: 0.7617  data: 0.0001  max mem: 14938
[19:55:00.750820] Epoch: [19]  [140/345]  eta: 0:02:36  lr: 0.000121  loss: 0.7838 (0.7853)  time: 0.7615  data: 0.0001  max mem: 14938
[19:55:15.966575] Epoch: [19]  [160/345]  eta: 0:02:20  lr: 0.000122  loss: 0.7871 (0.7858)  time: 0.7607  data: 0.0001  max mem: 14938
[19:55:31.302969] Epoch: [19]  [180/345]  eta: 0:02:05  lr: 0.000122  loss: 0.7855 (0.7860)  time: 0.7668  data: 0.0001  max mem: 14938
[19:55:46.516530] Epoch: [19]  [200/345]  eta: 0:01:50  lr: 0.000122  loss: 0.7705 (0.7849)  time: 0.7606  data: 0.0001  max mem: 14938
[19:56:01.712331] Epoch: [19]  [220/345]  eta: 0:01:35  lr: 0.000123  loss: 0.7816 (0.7848)  time: 0.7597  data: 0.0001  max mem: 14938
[19:56:16.907257] Epoch: [19]  [240/345]  eta: 0:01:19  lr: 0.000123  loss: 0.7807 (0.7848)  time: 0.7597  data: 0.0001  max mem: 14938
[19:56:32.102957] Epoch: [19]  [260/345]  eta: 0:01:04  lr: 0.000123  loss: 0.7740 (0.7841)  time: 0.7597  data: 0.0001  max mem: 14938
[19:56:47.296528] Epoch: [19]  [280/345]  eta: 0:00:49  lr: 0.000124  loss: 0.7681 (0.7830)  time: 0.7596  data: 0.0001  max mem: 14938
[19:57:02.490988] Epoch: [19]  [300/345]  eta: 0:00:34  lr: 0.000124  loss: 0.7743 (0.7827)  time: 0.7597  data: 0.0001  max mem: 14938
[19:57:17.677988] Epoch: [19]  [320/345]  eta: 0:00:19  lr: 0.000125  loss: 0.7682 (0.7820)  time: 0.7593  data: 0.0001  max mem: 14938
[19:57:32.861596] Epoch: [19]  [340/345]  eta: 0:00:03  lr: 0.000125  loss: 0.7628 (0.7813)  time: 0.7591  data: 0.0001  max mem: 14938
[19:57:35.898619] Epoch: [19]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.7628 (0.7811)  time: 0.7590  data: 0.0001  max mem: 14938
[19:57:35.966894] Epoch: [19] Total time: 0:04:22 (0.7611 s / it)
[19:57:35.967398] Averaged stats: lr: 0.000125  loss: 0.7628 (0.7811)
[19:57:36.538497] Test:  [  0/345]  eta: 0:03:15  loss: 0.7543 (0.7543)  time: 0.5658  data: 0.3680  max mem: 14938
[19:57:38.491045] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7367 (0.7381)  time: 0.2289  data: 0.0335  max mem: 14938
[19:57:40.453038] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7367 (0.7389)  time: 0.1956  data: 0.0001  max mem: 14938
[19:57:42.417807] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7334 (0.7365)  time: 0.1963  data: 0.0001  max mem: 14938
[19:57:44.386222] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7371 (0.7391)  time: 0.1966  data: 0.0001  max mem: 14938
[19:57:46.361893] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7382 (0.7394)  time: 0.1971  data: 0.0001  max mem: 14938
[19:57:48.343003] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7400 (0.7397)  time: 0.1978  data: 0.0001  max mem: 14938
[19:57:50.328554] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7392 (0.7389)  time: 0.1983  data: 0.0001  max mem: 14938
[19:57:52.320448] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7394 (0.7396)  time: 0.1988  data: 0.0001  max mem: 14938
[19:57:54.315771] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7395 (0.7398)  time: 0.1993  data: 0.0001  max mem: 14938
[19:57:56.316494] Test:  [100/345]  eta: 0:00:49  loss: 0.7383 (0.7394)  time: 0.1997  data: 0.0001  max mem: 14938
[19:57:58.324620] Test:  [110/345]  eta: 0:00:47  loss: 0.7329 (0.7390)  time: 0.2004  data: 0.0001  max mem: 14938
[19:58:00.331406] Test:  [120/345]  eta: 0:00:45  loss: 0.7359 (0.7390)  time: 0.2007  data: 0.0001  max mem: 14938
[19:58:02.349041] Test:  [130/345]  eta: 0:00:43  loss: 0.7399 (0.7390)  time: 0.2012  data: 0.0001  max mem: 14938
[19:58:04.369337] Test:  [140/345]  eta: 0:00:41  loss: 0.7406 (0.7396)  time: 0.2018  data: 0.0001  max mem: 14938
[19:58:06.394531] Test:  [150/345]  eta: 0:00:39  loss: 0.7446 (0.7398)  time: 0.2022  data: 0.0001  max mem: 14938
[19:58:08.425002] Test:  [160/345]  eta: 0:00:37  loss: 0.7495 (0.7404)  time: 0.2027  data: 0.0001  max mem: 14938
[19:58:10.460773] Test:  [170/345]  eta: 0:00:35  loss: 0.7411 (0.7404)  time: 0.2033  data: 0.0001  max mem: 14938
[19:58:12.503527] Test:  [180/345]  eta: 0:00:33  loss: 0.7332 (0.7400)  time: 0.2039  data: 0.0001  max mem: 14938
[19:58:14.550198] Test:  [190/345]  eta: 0:00:31  loss: 0.7354 (0.7400)  time: 0.2044  data: 0.0001  max mem: 14938
[19:58:16.604536] Test:  [200/345]  eta: 0:00:29  loss: 0.7393 (0.7402)  time: 0.2050  data: 0.0001  max mem: 14938
[19:58:18.662611] Test:  [210/345]  eta: 0:00:27  loss: 0.7382 (0.7399)  time: 0.2056  data: 0.0001  max mem: 14938
[19:58:20.724380] Test:  [220/345]  eta: 0:00:25  loss: 0.7379 (0.7401)  time: 0.2059  data: 0.0001  max mem: 14938
[19:58:22.791753] Test:  [230/345]  eta: 0:00:23  loss: 0.7399 (0.7401)  time: 0.2064  data: 0.0001  max mem: 14938
[19:58:24.864811] Test:  [240/345]  eta: 0:00:21  loss: 0.7393 (0.7401)  time: 0.2069  data: 0.0001  max mem: 14938
[19:58:26.943350] Test:  [250/345]  eta: 0:00:19  loss: 0.7332 (0.7402)  time: 0.2075  data: 0.0001  max mem: 14938
[19:58:29.025315] Test:  [260/345]  eta: 0:00:17  loss: 0.7376 (0.7400)  time: 0.2080  data: 0.0001  max mem: 14938
[19:58:31.112985] Test:  [270/345]  eta: 0:00:15  loss: 0.7377 (0.7401)  time: 0.2084  data: 0.0001  max mem: 14938
[19:58:33.206930] Test:  [280/345]  eta: 0:00:13  loss: 0.7474 (0.7404)  time: 0.2090  data: 0.0001  max mem: 14938
[19:58:35.304372] Test:  [290/345]  eta: 0:00:11  loss: 0.7474 (0.7405)  time: 0.2095  data: 0.0001  max mem: 14938
[19:58:37.407909] Test:  [300/345]  eta: 0:00:09  loss: 0.7447 (0.7408)  time: 0.2100  data: 0.0001  max mem: 14938
[19:58:39.516843] Test:  [310/345]  eta: 0:00:07  loss: 0.7441 (0.7408)  time: 0.2106  data: 0.0001  max mem: 14938
[19:58:41.631699] Test:  [320/345]  eta: 0:00:05  loss: 0.7323 (0.7407)  time: 0.2111  data: 0.0001  max mem: 14938

[19:58:43.751534] Test:  [330/345]  eta: 0:00:03  loss: 0.7306 (0.7403)  time: 0.2117  data: 0.0001  max mem: 14938
[19:58:45.873139] Test:  [340/345]  eta: 0:00:01  loss: 0.7351 (0.7406)  time: 0.2120  data: 0.0001  max mem: 14938
[19:58:46.722294] Test:  [344/345]  eta: 0:00:00  loss: 0.7351 (0.7405)  time: 0.2122  data: 0.0001  max mem: 14938
[19:58:46.788135] Test: Total time: 0:01:10 (0.2053 s / it)
[19:59:03.608153] Test:  [ 0/57]  eta: 0:00:29  loss: 0.8427 (0.8427)  time: 0.5202  data: 0.3240  max mem: 14938
[19:59:05.535037] Test:  [10/57]  eta: 0:00:10  loss: 0.8870 (0.8829)  time: 0.2224  data: 0.0295  max mem: 14938
[19:59:07.471023] Test:  [20/57]  eta: 0:00:07  loss: 0.8888 (0.8764)  time: 0.1931  data: 0.0001  max mem: 14938
[19:59:09.414243] Test:  [30/57]  eta: 0:00:05  loss: 0.7577 (0.8355)  time: 0.1939  data: 0.0001  max mem: 14938
[19:59:11.363849] Test:  [40/57]  eta: 0:00:03  loss: 0.7535 (0.8140)  time: 0.1946  data: 0.0001  max mem: 14938
[19:59:13.314680] Test:  [50/57]  eta: 0:00:01  loss: 0.7573 (0.8073)  time: 0.1950  data: 0.0001  max mem: 14938
[19:59:14.376006] Test:  [56/57]  eta: 0:00:00  loss: 0.7723 (0.8138)  time: 0.1895  data: 0.0000  max mem: 14938
[19:59:14.443154] Test: Total time: 0:00:11 (0.1992 s / it)
[19:59:17.268174] Dice score of the network on the train images: 0.711984, val images: 0.766177
[19:59:17.268400] saving best_prec_model_0 @ epoch 19
[19:59:18.391946] saving best_dice_model_0 @ epoch 19
[19:59:19.411702] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[19:59:20.516633] Epoch: [20]  [  0/345]  eta: 0:06:20  lr: 0.000125  loss: 0.7449 (0.7449)  time: 1.1037  data: 0.3401  max mem: 14938
[19:59:35.573018] Epoch: [20]  [ 20/345]  eta: 0:04:10  lr: 0.000125  loss: 0.7587 (0.7618)  time: 0.7528  data: 0.0001  max mem: 14938
[19:59:50.822505] Epoch: [20]  [ 40/345]  eta: 0:03:53  lr: 0.000125  loss: 0.7651 (0.7639)  time: 0.7624  data: 0.0001  max mem: 14938
[20:00:05.983487] Epoch: [20]  [ 60/345]  eta: 0:03:37  lr: 0.000125  loss: 0.7667 (0.7646)  time: 0.7580  data: 0.0001  max mem: 14938
[20:00:21.189626] Epoch: [20]  [ 80/345]  eta: 0:03:22  lr: 0.000125  loss: 0.7630 (0.7646)  time: 0.7603  data: 0.0001  max mem: 14938
[20:00:36.408086] Epoch: [20]  [100/345]  eta: 0:03:06  lr: 0.000125  loss: 0.7621 (0.7654)  time: 0.7609  data: 0.0001  max mem: 14938
[20:00:51.615480] Epoch: [20]  [120/345]  eta: 0:02:51  lr: 0.000125  loss: 0.7753 (0.7673)  time: 0.7603  data: 0.0001  max mem: 14938
[20:01:06.843563] Epoch: [20]  [140/345]  eta: 0:02:36  lr: 0.000125  loss: 0.7718 (0.7682)  time: 0.7614  data: 0.0001  max mem: 14938
[20:01:22.043133] Epoch: [20]  [160/345]  eta: 0:02:20  lr: 0.000125  loss: 0.7739 (0.7689)  time: 0.7599  data: 0.0001  max mem: 14938
[20:01:37.233306] Epoch: [20]  [180/345]  eta: 0:02:05  lr: 0.000125  loss: 0.7660 (0.7693)  time: 0.7595  data: 0.0001  max mem: 14938
[20:01:52.428804] Epoch: [20]  [200/345]  eta: 0:01:50  lr: 0.000125  loss: 0.7741 (0.7696)  time: 0.7597  data: 0.0001  max mem: 14938
[20:02:07.618561] Epoch: [20]  [220/345]  eta: 0:01:35  lr: 0.000125  loss: 0.7717 (0.7699)  time: 0.7594  data: 0.0001  max mem: 14938
[20:02:22.799259] Epoch: [20]  [240/345]  eta: 0:01:19  lr: 0.000125  loss: 0.7727 (0.7698)  time: 0.7590  data: 0.0001  max mem: 14938
[20:02:37.981420] Epoch: [20]  [260/345]  eta: 0:01:04  lr: 0.000125  loss: 0.7675 (0.7696)  time: 0.7591  data: 0.0001  max mem: 14938
[20:02:53.159144] Epoch: [20]  [280/345]  eta: 0:00:49  lr: 0.000125  loss: 0.7639 (0.7693)  time: 0.7588  data: 0.0001  max mem: 14938
[20:03:08.341587] Epoch: [20]  [300/345]  eta: 0:00:34  lr: 0.000125  loss: 0.7776 (0.7700)  time: 0.7591  data: 0.0001  max mem: 14938
[20:03:23.536616] Epoch: [20]  [320/345]  eta: 0:00:19  lr: 0.000125  loss: 0.7748 (0.7703)  time: 0.7596  data: 0.0001  max mem: 14938
[20:03:38.741323] Epoch: [20]  [340/345]  eta: 0:00:03  lr: 0.000125  loss: 0.7743 (0.7709)  time: 0.7602  data: 0.0001  max mem: 14938
[20:03:41.780726] Epoch: [20]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.7786 (0.7710)  time: 0.7599  data: 0.0001  max mem: 14938
[20:03:41.846967] Epoch: [20] Total time: 0:04:22 (0.7607 s / it)
[20:03:41.847248] Averaged stats: lr: 0.000125  loss: 0.7786 (0.7710)
[20:03:42.418748] Test:  [  0/345]  eta: 0:03:15  loss: 0.7550 (0.7550)  time: 0.5668  data: 0.3680  max mem: 14938
[20:03:44.371882] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7424 (0.7432)  time: 0.2290  data: 0.0335  max mem: 14938
[20:03:46.330856] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7424 (0.7408)  time: 0.1955  data: 0.0001  max mem: 14938
[20:03:48.295642] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7453 (0.7432)  time: 0.1961  data: 0.0001  max mem: 14938
[20:03:50.265869] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7464 (0.7434)  time: 0.1967  data: 0.0001  max mem: 14938
[20:03:52.241887] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7461 (0.7439)  time: 0.1973  data: 0.0001  max mem: 14938
[20:03:54.223365] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7423 (0.7453)  time: 0.1978  data: 0.0001  max mem: 14938
[20:03:56.208295] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7435 (0.7453)  time: 0.1983  data: 0.0001  max mem: 14938
[20:03:58.198867] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7435 (0.7446)  time: 0.1987  data: 0.0001  max mem: 14938
[20:04:00.191129] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7411 (0.7453)  time: 0.1991  data: 0.0001  max mem: 14938
[20:04:02.187231] Test:  [100/345]  eta: 0:00:49  loss: 0.7411 (0.7449)  time: 0.1994  data: 0.0001  max mem: 14938
[20:04:04.188246] Test:  [110/345]  eta: 0:00:47  loss: 0.7408 (0.7452)  time: 0.1998  data: 0.0001  max mem: 14938
[20:04:06.198178] Test:  [120/345]  eta: 0:00:45  loss: 0.7426 (0.7451)  time: 0.2005  data: 0.0001  max mem: 14938
[20:04:08.212564] Test:  [130/345]  eta: 0:00:43  loss: 0.7425 (0.7455)  time: 0.2012  data: 0.0001  max mem: 14938
[20:04:10.234274] Test:  [140/345]  eta: 0:00:41  loss: 0.7453 (0.7455)  time: 0.2017  data: 0.0001  max mem: 14938
[20:04:12.261489] Test:  [150/345]  eta: 0:00:39  loss: 0.7469 (0.7460)  time: 0.2024  data: 0.0001  max mem: 14938
[20:04:14.290996] Test:  [160/345]  eta: 0:00:37  loss: 0.7450 (0.7458)  time: 0.2028  data: 0.0001  max mem: 14938
[20:04:16.327643] Test:  [170/345]  eta: 0:00:35  loss: 0.7388 (0.7454)  time: 0.2032  data: 0.0001  max mem: 14938
[20:04:18.368626] Test:  [180/345]  eta: 0:00:33  loss: 0.7365 (0.7450)  time: 0.2038  data: 0.0001  max mem: 14938
[20:04:20.412526] Test:  [190/345]  eta: 0:00:31  loss: 0.7344 (0.7446)  time: 0.2042  data: 0.0001  max mem: 14938
[20:04:22.465530] Test:  [200/345]  eta: 0:00:29  loss: 0.7374 (0.7444)  time: 0.2048  data: 0.0001  max mem: 14938
[20:04:24.525227] Test:  [210/345]  eta: 0:00:27  loss: 0.7444 (0.7449)  time: 0.2056  data: 0.0001  max mem: 14938
[20:04:26.587607] Test:  [220/345]  eta: 0:00:25  loss: 0.7402 (0.7446)  time: 0.2060  data: 0.0001  max mem: 14938
[20:04:28.655551] Test:  [230/345]  eta: 0:00:23  loss: 0.7433 (0.7446)  time: 0.2065  data: 0.0001  max mem: 14938
[20:04:30.728694] Test:  [240/345]  eta: 0:00:21  loss: 0.7441 (0.7447)  time: 0.2070  data: 0.0001  max mem: 14938
[20:04:32.805603] Test:  [250/345]  eta: 0:00:19  loss: 0.7441 (0.7448)  time: 0.2074  data: 0.0001  max mem: 14938
[20:04:34.887439] Test:  [260/345]  eta: 0:00:17  loss: 0.7389 (0.7446)  time: 0.2079  data: 0.0001  max mem: 14938
[20:04:36.973269] Test:  [270/345]  eta: 0:00:15  loss: 0.7410 (0.7450)  time: 0.2083  data: 0.0001  max mem: 14938
[20:04:39.065448] Test:  [280/345]  eta: 0:00:13  loss: 0.7447 (0.7451)  time: 0.2088  data: 0.0001  max mem: 14938
[20:04:41.163371] Test:  [290/345]  eta: 0:00:11  loss: 0.7518 (0.7454)  time: 0.2094  data: 0.0001  max mem: 14938
[20:04:43.265672] Test:  [300/345]  eta: 0:00:09  loss: 0.7452 (0.7452)  time: 0.2100  data: 0.0001  max mem: 14938
[20:04:45.375821] Test:  [310/345]  eta: 0:00:07  loss: 0.7384 (0.7452)  time: 0.2106  data: 0.0001  max mem: 14938
[20:04:47.491106] Test:  [320/345]  eta: 0:00:05  loss: 0.7472 (0.7455)  time: 0.2112  data: 0.0001  max mem: 14938
[20:04:49.609378] Test:  [330/345]  eta: 0:00:03  loss: 0.7472 (0.7455)  time: 0.2116  data: 0.0001  max mem: 14938
[20:04:51.732779] Test:  [340/345]  eta: 0:00:01  loss: 0.7430 (0.7456)  time: 0.2120  data: 0.0001  max mem: 14938
[20:04:52.583848] Test:  [344/345]  eta: 0:00:00  loss: 0.7479 (0.7457)  time: 0.2122  data: 0.0001  max mem: 14938
[20:04:52.647357] Test: Total time: 0:01:10 (0.2052 s / it)
[20:05:09.600371] Test:  [ 0/57]  eta: 0:00:30  loss: 0.8729 (0.8729)  time: 0.5400  data: 0.3439  max mem: 14938
[20:05:11.527166] Test:  [10/57]  eta: 0:00:10  loss: 0.8729 (0.8810)  time: 0.2242  data: 0.0313  max mem: 14938
[20:05:13.465057] Test:  [20/57]  eta: 0:00:07  loss: 0.8713 (0.8692)  time: 0.1932  data: 0.0001  max mem: 14938
[20:05:15.405552] Test:  [30/57]  eta: 0:00:05  loss: 0.7667 (0.8298)  time: 0.1939  data: 0.0001  max mem: 14938
[20:05:17.352538] Test:  [40/57]  eta: 0:00:03  loss: 0.7484 (0.8082)  time: 0.1943  data: 0.0001  max mem: 14938
[20:05:19.306283] Test:  [50/57]  eta: 0:00:01  loss: 0.7484 (0.8012)  time: 0.1950  data: 0.0001  max mem: 14938
[20:05:20.369364] Test:  [56/57]  eta: 0:00:00  loss: 0.7704 (0.8061)  time: 0.1897  data: 0.0001  max mem: 14938
[20:05:20.435898] Test: Total time: 0:00:11 (0.1996 s / it)
[20:05:23.294082] Dice score of the network on the train images: 0.691815, val images: 0.768592
[20:05:23.294303] saving best_rec_model_0 @ epoch 20
[20:05:24.327854] saving best_dice_model_0 @ epoch 20
[20:05:25.414647] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:05:26.516456] Epoch: [21]  [  0/345]  eta: 0:06:19  lr: 0.000125  loss: 0.8011 (0.8011)  time: 1.1006  data: 0.3386  max mem: 14938
[20:05:41.577856] Epoch: [21]  [ 20/345]  eta: 0:04:10  lr: 0.000125  loss: 0.7574 (0.7637)  time: 0.7530  data: 0.0001  max mem: 14938
[20:05:56.709499] Epoch: [21]  [ 40/345]  eta: 0:03:52  lr: 0.000125  loss: 0.7675 (0.7675)  time: 0.7565  data: 0.0001  max mem: 14938
[20:06:11.869384] Epoch: [21]  [ 60/345]  eta: 0:03:37  lr: 0.000125  loss: 0.7679 (0.7684)  time: 0.7579  data: 0.0001  max mem: 14938
[20:06:27.071542] Epoch: [21]  [ 80/345]  eta: 0:03:21  lr: 0.000124  loss: 0.7674 (0.7683)  time: 0.7601  data: 0.0001  max mem: 14938

[20:06:42.305564] Epoch: [21]  [100/345]  eta: 0:03:06  lr: 0.000124  loss: 0.7593 (0.7671)  time: 0.7617  data: 0.0001  max mem: 14938
[20:06:57.531233] Epoch: [21]  [120/345]  eta: 0:02:51  lr: 0.000124  loss: 0.7575 (0.7659)  time: 0.7612  data: 0.0001  max mem: 14938
[20:07:12.748762] Epoch: [21]  [140/345]  eta: 0:02:36  lr: 0.000124  loss: 0.7781 (0.7669)  time: 0.7608  data: 0.0001  max mem: 14938
[20:07:27.971689] Epoch: [21]  [160/345]  eta: 0:02:20  lr: 0.000124  loss: 0.7733 (0.7676)  time: 0.7611  data: 0.0001  max mem: 14938
[20:07:43.190097] Epoch: [21]  [180/345]  eta: 0:02:05  lr: 0.000124  loss: 0.7700 (0.7679)  time: 0.7609  data: 0.0001  max mem: 14938

[20:07:58.401526] Epoch: [21]  [200/345]  eta: 0:01:50  lr: 0.000124  loss: 0.7635 (0.7681)  time: 0.7605  data: 0.0001  max mem: 14938
[20:08:13.733815] Epoch: [21]  [220/345]  eta: 0:01:35  lr: 0.000124  loss: 0.7845 (0.7696)  time: 0.7666  data: 0.0001  max mem: 14938
[20:08:28.930176] Epoch: [21]  [240/345]  eta: 0:01:19  lr: 0.000124  loss: 0.7700 (0.7703)  time: 0.7598  data: 0.0001  max mem: 14938
[20:08:44.138305] Epoch: [21]  [260/345]  eta: 0:01:04  lr: 0.000124  loss: 0.7768 (0.7711)  time: 0.7604  data: 0.0001  max mem: 14938
[20:08:59.336973] Epoch: [21]  [280/345]  eta: 0:00:49  lr: 0.000124  loss: 0.7729 (0.7715)  time: 0.7599  data: 0.0001  max mem: 14938
[20:09:14.532332] Epoch: [21]  [300/345]  eta: 0:00:34  lr: 0.000124  loss: 0.7621 (0.7712)  time: 0.7597  data: 0.0001  max mem: 14938
[20:09:29.725511] Epoch: [21]  [320/345]  eta: 0:00:19  lr: 0.000124  loss: 0.7675 (0.7710)  time: 0.7596  data: 0.0001  max mem: 14938
[20:09:44.889993] Epoch: [21]  [340/345]  eta: 0:00:03  lr: 0.000124  loss: 0.7673 (0.7709)  time: 0.7582  data: 0.0001  max mem: 14938
[20:09:47.919818] Epoch: [21]  [344/345]  eta: 0:00:00  lr: 0.000124  loss: 0.7674 (0.7709)  time: 0.7578  data: 0.0001  max mem: 14938
[20:09:47.988524] Epoch: [21] Total time: 0:04:22 (0.7611 s / it)
[20:09:47.988871] Averaged stats: lr: 0.000124  loss: 0.7674 (0.7709)
[20:09:48.555650] Test:  [  0/345]  eta: 0:03:13  loss: 0.7162 (0.7162)  time: 0.5616  data: 0.3638  max mem: 14938
[20:09:50.508652] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7354 (0.7336)  time: 0.2285  data: 0.0332  max mem: 14938
[20:09:52.469651] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7354 (0.7341)  time: 0.1956  data: 0.0001  max mem: 14938
[20:09:54.435626] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7368 (0.7370)  time: 0.1963  data: 0.0001  max mem: 14938
[20:09:56.404952] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7442 (0.7386)  time: 0.1967  data: 0.0001  max mem: 14938
[20:09:58.381695] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7410 (0.7395)  time: 0.1972  data: 0.0001  max mem: 14938
[20:10:00.363467] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7387 (0.7392)  time: 0.1979  data: 0.0001  max mem: 14938
[20:10:02.348607] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7337 (0.7387)  time: 0.1983  data: 0.0001  max mem: 14938
[20:10:04.341517] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7345 (0.7388)  time: 0.1988  data: 0.0001  max mem: 14938
[20:10:06.338883] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7466 (0.7392)  time: 0.1994  data: 0.0001  max mem: 14938
[20:10:08.341122] Test:  [100/345]  eta: 0:00:49  loss: 0.7388 (0.7391)  time: 0.1999  data: 0.0001  max mem: 14938
[20:10:10.348301] Test:  [110/345]  eta: 0:00:47  loss: 0.7427 (0.7401)  time: 0.2004  data: 0.0001  max mem: 14938
[20:10:12.356477] Test:  [120/345]  eta: 0:00:45  loss: 0.7464 (0.7403)  time: 0.2007  data: 0.0001  max mem: 14938
[20:10:14.372854] Test:  [130/345]  eta: 0:00:43  loss: 0.7382 (0.7405)  time: 0.2012  data: 0.0001  max mem: 14938
[20:10:16.395034] Test:  [140/345]  eta: 0:00:41  loss: 0.7359 (0.7407)  time: 0.2019  data: 0.0001  max mem: 14938
[20:10:18.423389] Test:  [150/345]  eta: 0:00:39  loss: 0.7387 (0.7406)  time: 0.2025  data: 0.0001  max mem: 14938
[20:10:20.453971] Test:  [160/345]  eta: 0:00:37  loss: 0.7351 (0.7404)  time: 0.2029  data: 0.0001  max mem: 14938
[20:10:22.490086] Test:  [170/345]  eta: 0:00:35  loss: 0.7339 (0.7403)  time: 0.2033  data: 0.0001  max mem: 14938
[20:10:24.530640] Test:  [180/345]  eta: 0:00:33  loss: 0.7316 (0.7398)  time: 0.2038  data: 0.0001  max mem: 14938

[20:10:26.577774] Test:  [190/345]  eta: 0:00:31  loss: 0.7275 (0.7395)  time: 0.2043  data: 0.0001  max mem: 14938
[20:10:28.630478] Test:  [200/345]  eta: 0:00:29  loss: 0.7369 (0.7398)  time: 0.2049  data: 0.0001  max mem: 14938
[20:10:30.688914] Test:  [210/345]  eta: 0:00:27  loss: 0.7384 (0.7396)  time: 0.2055  data: 0.0001  max mem: 14938
[20:10:32.750193] Test:  [220/345]  eta: 0:00:25  loss: 0.7357 (0.7395)  time: 0.2059  data: 0.0001  max mem: 14938
[20:10:34.817093] Test:  [230/345]  eta: 0:00:23  loss: 0.7316 (0.7395)  time: 0.2063  data: 0.0001  max mem: 14938
[20:10:36.889045] Test:  [240/345]  eta: 0:00:21  loss: 0.7349 (0.7394)  time: 0.2069  data: 0.0001  max mem: 14938
[20:10:38.968470] Test:  [250/345]  eta: 0:00:19  loss: 0.7348 (0.7392)  time: 0.2075  data: 0.0001  max mem: 14938
[20:10:41.052836] Test:  [260/345]  eta: 0:00:17  loss: 0.7337 (0.7391)  time: 0.2081  data: 0.0001  max mem: 14938
[20:10:43.142355] Test:  [270/345]  eta: 0:00:15  loss: 0.7363 (0.7394)  time: 0.2086  data: 0.0001  max mem: 14938
[20:10:45.234229] Test:  [280/345]  eta: 0:00:13  loss: 0.7394 (0.7393)  time: 0.2090  data: 0.0001  max mem: 14938
[20:10:47.333465] Test:  [290/345]  eta: 0:00:11  loss: 0.7298 (0.7390)  time: 0.2095  data: 0.0001  max mem: 14938
[20:10:49.436578] Test:  [300/345]  eta: 0:00:09  loss: 0.7313 (0.7389)  time: 0.2101  data: 0.0001  max mem: 14938
[20:10:51.546389] Test:  [310/345]  eta: 0:00:07  loss: 0.7354 (0.7392)  time: 0.2106  data: 0.0001  max mem: 14938
[20:10:53.660421] Test:  [320/345]  eta: 0:00:05  loss: 0.7342 (0.7391)  time: 0.2111  data: 0.0001  max mem: 14938
[20:10:55.781156] Test:  [330/345]  eta: 0:00:03  loss: 0.7342 (0.7390)  time: 0.2117  data: 0.0001  max mem: 14938
[20:10:57.903928] Test:  [340/345]  eta: 0:00:01  loss: 0.7336 (0.7389)  time: 0.2121  data: 0.0001  max mem: 14938
[20:10:58.753915] Test:  [344/345]  eta: 0:00:00  loss: 0.7336 (0.7389)  time: 0.2123  data: 0.0001  max mem: 14938
[20:10:58.819393] Test: Total time: 0:01:10 (0.2053 s / it)
[20:11:15.410996] Test:  [ 0/57]  eta: 0:00:29  loss: 0.8280 (0.8280)  time: 0.5147  data: 0.3177  max mem: 14938
[20:11:17.339416] Test:  [10/57]  eta: 0:00:10  loss: 0.8644 (0.8702)  time: 0.2220  data: 0.0290  max mem: 14938
[20:11:19.276952] Test:  [20/57]  eta: 0:00:07  loss: 0.8721 (0.8654)  time: 0.1932  data: 0.0001  max mem: 14938
[20:11:21.218591] Test:  [30/57]  eta: 0:00:05  loss: 0.7710 (0.8314)  time: 0.1939  data: 0.0001  max mem: 14938
[20:11:23.166786] Test:  [40/57]  eta: 0:00:03  loss: 0.7504 (0.8131)  time: 0.1944  data: 0.0001  max mem: 14938
[20:11:25.120145] Test:  [50/57]  eta: 0:00:01  loss: 0.7562 (0.8070)  time: 0.1950  data: 0.0001  max mem: 14938
[20:11:26.181714] Test:  [56/57]  eta: 0:00:00  loss: 0.7712 (0.8119)  time: 0.1897  data: 0.0000  max mem: 14938
[20:11:26.230147] Test: Total time: 0:00:11 (0.1988 s / it)
[20:11:29.062861] Dice score of the network on the train images: 0.715043, val images: 0.755322
[20:11:29.063084] saving best_prec_model_0 @ epoch 21
[20:11:30.147385] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:11:31.237170] Epoch: [22]  [  0/345]  eta: 0:06:15  lr: 0.000124  loss: 0.7578 (0.7578)  time: 1.0885  data: 0.3256  max mem: 14938
[20:11:46.295623] Epoch: [22]  [ 20/345]  eta: 0:04:09  lr: 0.000124  loss: 0.7600 (0.7676)  time: 0.7529  data: 0.0001  max mem: 14938
[20:12:01.419548] Epoch: [22]  [ 40/345]  eta: 0:03:52  lr: 0.000123  loss: 0.7581 (0.7641)  time: 0.7561  data: 0.0001  max mem: 14938
[20:12:16.569600] Epoch: [22]  [ 60/345]  eta: 0:03:36  lr: 0.000123  loss: 0.7611 (0.7618)  time: 0.7575  data: 0.0001  max mem: 14938
[20:12:31.769571] Epoch: [22]  [ 80/345]  eta: 0:03:21  lr: 0.000123  loss: 0.7583 (0.7618)  time: 0.7600  data: 0.0001  max mem: 14938
[20:12:47.013501] Epoch: [22]  [100/345]  eta: 0:03:06  lr: 0.000123  loss: 0.7611 (0.7627)  time: 0.7621  data: 0.0001  max mem: 14938
[20:13:02.226056] Epoch: [22]  [120/345]  eta: 0:02:51  lr: 0.000123  loss: 0.7677 (0.7644)  time: 0.7606  data: 0.0001  max mem: 14938
[20:13:17.431651] Epoch: [22]  [140/345]  eta: 0:02:35  lr: 0.000123  loss: 0.7734 (0.7663)  time: 0.7602  data: 0.0001  max mem: 14938
[20:13:32.632480] Epoch: [22]  [160/345]  eta: 0:02:20  lr: 0.000123  loss: 0.7602 (0.7657)  time: 0.7600  data: 0.0001  max mem: 14938
[20:13:47.826071] Epoch: [22]  [180/345]  eta: 0:02:05  lr: 0.000123  loss: 0.7588 (0.7649)  time: 0.7596  data: 0.0001  max mem: 14938
[20:14:03.018616] Epoch: [22]  [200/345]  eta: 0:01:50  lr: 0.000123  loss: 0.7637 (0.7653)  time: 0.7596  data: 0.0001  max mem: 14938
[20:14:18.214503] Epoch: [22]  [220/345]  eta: 0:01:35  lr: 0.000123  loss: 0.7592 (0.7647)  time: 0.7597  data: 0.0001  max mem: 14938
[20:14:33.407910] Epoch: [22]  [240/345]  eta: 0:01:19  lr: 0.000123  loss: 0.7660 (0.7650)  time: 0.7596  data: 0.0001  max mem: 14938
[20:14:48.603839] Epoch: [22]  [260/345]  eta: 0:01:04  lr: 0.000122  loss: 0.7805 (0.7662)  time: 0.7597  data: 0.0001  max mem: 14938
[20:15:03.794881] Epoch: [22]  [280/345]  eta: 0:00:49  lr: 0.000122  loss: 0.7625 (0.7661)  time: 0.7595  data: 0.0001  max mem: 14938
[20:15:18.989174] Epoch: [22]  [300/345]  eta: 0:00:34  lr: 0.000122  loss: 0.7751 (0.7667)  time: 0.7597  data: 0.0001  max mem: 14938
[20:15:34.178467] Epoch: [22]  [320/345]  eta: 0:00:19  lr: 0.000122  loss: 0.7703 (0.7671)  time: 0.7594  data: 0.0001  max mem: 14938
[20:15:49.342411] Epoch: [22]  [340/345]  eta: 0:00:03  lr: 0.000122  loss: 0.7689 (0.7673)  time: 0.7582  data: 0.0001  max mem: 14938
[20:15:52.374080] Epoch: [22]  [344/345]  eta: 0:00:00  lr: 0.000122  loss: 0.7707 (0.7673)  time: 0.7581  data: 0.0001  max mem: 14938
[20:15:52.444876] Epoch: [22] Total time: 0:04:22 (0.7603 s / it)
[20:15:52.445093] Averaged stats: lr: 0.000122  loss: 0.7707 (0.7673)
[20:15:52.998098] Test:  [  0/345]  eta: 0:03:09  loss: 0.7490 (0.7490)  time: 0.5479  data: 0.3498  max mem: 14938
[20:15:54.950797] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7524 (0.7491)  time: 0.2272  data: 0.0319  max mem: 14938
[20:15:56.911835] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7501 (0.7491)  time: 0.1956  data: 0.0001  max mem: 14938
[20:15:58.878253] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7518 (0.7505)  time: 0.1963  data: 0.0001  max mem: 14938
[20:16:00.849817] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7556 (0.7522)  time: 0.1968  data: 0.0001  max mem: 14938
[20:16:02.828955] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7496 (0.7512)  time: 0.1975  data: 0.0001  max mem: 14938
[20:16:04.811639] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7458 (0.7512)  time: 0.1980  data: 0.0001  max mem: 14938
[20:16:06.799404] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7458 (0.7507)  time: 0.1985  data: 0.0001  max mem: 14938
[20:16:08.788249] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7512 (0.7508)  time: 0.1988  data: 0.0001  max mem: 14938
[20:16:10.787154] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7479 (0.7505)  time: 0.1993  data: 0.0001  max mem: 14938
[20:16:12.790013] Test:  [100/345]  eta: 0:00:49  loss: 0.7443 (0.7508)  time: 0.2000  data: 0.0001  max mem: 14938
[20:16:14.794256] Test:  [110/345]  eta: 0:00:47  loss: 0.7569 (0.7510)  time: 0.2003  data: 0.0001  max mem: 14938
[20:16:16.808627] Test:  [120/345]  eta: 0:00:45  loss: 0.7562 (0.7510)  time: 0.2009  data: 0.0001  max mem: 14938
[20:16:18.824963] Test:  [130/345]  eta: 0:00:43  loss: 0.7584 (0.7518)  time: 0.2015  data: 0.0001  max mem: 14938
[20:16:20.845449] Test:  [140/345]  eta: 0:00:41  loss: 0.7607 (0.7523)  time: 0.2018  data: 0.0001  max mem: 14938
[20:16:22.872337] Test:  [150/345]  eta: 0:00:39  loss: 0.7457 (0.7515)  time: 0.2023  data: 0.0001  max mem: 14938
[20:16:24.903608] Test:  [160/345]  eta: 0:00:37  loss: 0.7457 (0.7518)  time: 0.2028  data: 0.0001  max mem: 14938
[20:16:26.941946] Test:  [170/345]  eta: 0:00:35  loss: 0.7500 (0.7516)  time: 0.2034  data: 0.0001  max mem: 14938
[20:16:28.981267] Test:  [180/345]  eta: 0:00:33  loss: 0.7516 (0.7519)  time: 0.2038  data: 0.0001  max mem: 14938

[20:16:31.027931] Test:  [190/345]  eta: 0:00:31  loss: 0.7550 (0.7520)  time: 0.2042  data: 0.0001  max mem: 14938
[20:16:33.079797] Test:  [200/345]  eta: 0:00:29  loss: 0.7483 (0.7520)  time: 0.2049  data: 0.0001  max mem: 14938
[20:16:35.140048] Test:  [210/345]  eta: 0:00:27  loss: 0.7474 (0.7518)  time: 0.2055  data: 0.0001  max mem: 14938
[20:16:37.204575] Test:  [220/345]  eta: 0:00:25  loss: 0.7517 (0.7519)  time: 0.2062  data: 0.0001  max mem: 14938
[20:16:39.277474] Test:  [230/345]  eta: 0:00:23  loss: 0.7516 (0.7518)  time: 0.2068  data: 0.0001  max mem: 14938
[20:16:41.355604] Test:  [240/345]  eta: 0:00:21  loss: 0.7503 (0.7518)  time: 0.2075  data: 0.0001  max mem: 14938
[20:16:43.437264] Test:  [250/345]  eta: 0:00:19  loss: 0.7551 (0.7524)  time: 0.2079  data: 0.0001  max mem: 14938
[20:16:45.521745] Test:  [260/345]  eta: 0:00:17  loss: 0.7498 (0.7523)  time: 0.2082  data: 0.0001  max mem: 14938
[20:16:47.613433] Test:  [270/345]  eta: 0:00:15  loss: 0.7526 (0.7525)  time: 0.2087  data: 0.0001  max mem: 14938
[20:16:49.707289] Test:  [280/345]  eta: 0:00:13  loss: 0.7572 (0.7527)  time: 0.2092  data: 0.0001  max mem: 14938
[20:16:51.805620] Test:  [290/345]  eta: 0:00:11  loss: 0.7489 (0.7527)  time: 0.2095  data: 0.0001  max mem: 14938
[20:16:53.909388] Test:  [300/345]  eta: 0:00:09  loss: 0.7506 (0.7528)  time: 0.2100  data: 0.0001  max mem: 14938
[20:16:56.018935] Test:  [310/345]  eta: 0:00:07  loss: 0.7511 (0.7530)  time: 0.2106  data: 0.0001  max mem: 14938
[20:16:58.133438] Test:  [320/345]  eta: 0:00:05  loss: 0.7521 (0.7532)  time: 0.2111  data: 0.0001  max mem: 14938
[20:17:00.256040] Test:  [330/345]  eta: 0:00:03  loss: 0.7607 (0.7536)  time: 0.2118  data: 0.0001  max mem: 14938
[20:17:02.377371] Test:  [340/345]  eta: 0:00:01  loss: 0.7618 (0.7538)  time: 0.2121  data: 0.0001  max mem: 14938
[20:17:03.227964] Test:  [344/345]  eta: 0:00:00  loss: 0.7604 (0.7539)  time: 0.2122  data: 0.0001  max mem: 14938
[20:17:03.298785] Test: Total time: 0:01:10 (0.2054 s / it)
[20:17:19.818564] Test:  [ 0/57]  eta: 0:00:31  loss: 0.8486 (0.8486)  time: 0.5494  data: 0.3537  max mem: 14938
[20:17:21.745812] Test:  [10/57]  eta: 0:00:10  loss: 0.8709 (0.8843)  time: 0.2251  data: 0.0322  max mem: 14938
[20:17:23.682035] Test:  [20/57]  eta: 0:00:07  loss: 0.8709 (0.8721)  time: 0.1931  data: 0.0001  max mem: 14938
[20:17:25.625899] Test:  [30/57]  eta: 0:00:05  loss: 0.7616 (0.8328)  time: 0.1939  data: 0.0001  max mem: 14938
[20:17:27.572920] Test:  [40/57]  eta: 0:00:03  loss: 0.7492 (0.8124)  time: 0.1945  data: 0.0001  max mem: 14938
[20:17:29.524511] Test:  [50/57]  eta: 0:00:01  loss: 0.7483 (0.8068)  time: 0.1949  data: 0.0001  max mem: 14938
[20:17:30.586940] Test:  [56/57]  eta: 0:00:00  loss: 0.7751 (0.8125)  time: 0.1896  data: 0.0000  max mem: 14938
[20:17:30.651618] Test: Total time: 0:00:11 (0.1997 s / it)
[20:17:33.433222] Dice score of the network on the train images: 0.703535, val images: 0.760396
[20:17:33.437989] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:17:34.535707] Epoch: [23]  [  0/345]  eta: 0:06:18  lr: 0.000122  loss: 0.7531 (0.7531)  time: 1.0966  data: 0.3335  max mem: 14938
[20:17:49.589281] Epoch: [23]  [ 20/345]  eta: 0:04:09  lr: 0.000122  loss: 0.7708 (0.7727)  time: 0.7526  data: 0.0001  max mem: 14938
[20:18:04.719002] Epoch: [23]  [ 40/345]  eta: 0:03:52  lr: 0.000122  loss: 0.7710 (0.7749)  time: 0.7564  data: 0.0001  max mem: 14938
[20:18:19.867701] Epoch: [23]  [ 60/345]  eta: 0:03:36  lr: 0.000122  loss: 0.7764 (0.7767)  time: 0.7574  data: 0.0001  max mem: 14938
[20:18:35.067291] Epoch: [23]  [ 80/345]  eta: 0:03:21  lr: 0.000121  loss: 0.7800 (0.7780)  time: 0.7599  data: 0.0001  max mem: 14938
[20:18:50.290449] Epoch: [23]  [100/345]  eta: 0:03:06  lr: 0.000121  loss: 0.7751 (0.7777)  time: 0.7611  data: 0.0001  max mem: 14938
[20:19:05.502273] Epoch: [23]  [120/345]  eta: 0:02:51  lr: 0.000121  loss: 0.7761 (0.7775)  time: 0.7605  data: 0.0001  max mem: 14938
[20:19:20.718654] Epoch: [23]  [140/345]  eta: 0:02:35  lr: 0.000121  loss: 0.7732 (0.7765)  time: 0.7608  data: 0.0001  max mem: 14938
[20:19:35.930641] Epoch: [23]  [160/345]  eta: 0:02:20  lr: 0.000121  loss: 0.7704 (0.7760)  time: 0.7606  data: 0.0001  max mem: 14938
[20:19:51.134323] Epoch: [23]  [180/345]  eta: 0:02:05  lr: 0.000121  loss: 0.7572 (0.7743)  time: 0.7601  data: 0.0001  max mem: 14938
[20:20:06.334028] Epoch: [23]  [200/345]  eta: 0:01:50  lr: 0.000121  loss: 0.7548 (0.7727)  time: 0.7599  data: 0.0001  max mem: 14938
[20:20:21.518038] Epoch: [23]  [220/345]  eta: 0:01:35  lr: 0.000121  loss: 0.7575 (0.7715)  time: 0.7592  data: 0.0001  max mem: 14938
[20:20:36.711090] Epoch: [23]  [240/345]  eta: 0:01:19  lr: 0.000120  loss: 0.7617 (0.7701)  time: 0.7596  data: 0.0001  max mem: 14938
[20:20:51.898728] Epoch: [23]  [260/345]  eta: 0:01:04  lr: 0.000120  loss: 0.7583 (0.7690)  time: 0.7593  data: 0.0001  max mem: 14938
[20:21:07.075781] Epoch: [23]  [280/345]  eta: 0:00:49  lr: 0.000120  loss: 0.7608 (0.7683)  time: 0.7588  data: 0.0001  max mem: 14938
[20:21:22.270538] Epoch: [23]  [300/345]  eta: 0:00:34  lr: 0.000120  loss: 0.7519 (0.7674)  time: 0.7597  data: 0.0001  max mem: 14938
[20:21:37.469319] Epoch: [23]  [320/345]  eta: 0:00:19  lr: 0.000120  loss: 0.7586 (0.7669)  time: 0.7599  data: 0.0001  max mem: 14938
[20:21:52.653915] Epoch: [23]  [340/345]  eta: 0:00:03  lr: 0.000120  loss: 0.7524 (0.7661)  time: 0.7592  data: 0.0001  max mem: 14938
[20:21:55.686818] Epoch: [23]  [344/345]  eta: 0:00:00  lr: 0.000120  loss: 0.7505 (0.7658)  time: 0.7590  data: 0.0001  max mem: 14938
[20:21:55.762317] Epoch: [23] Total time: 0:04:22 (0.7604 s / it)
[20:21:55.762912] Averaged stats: lr: 0.000120  loss: 0.7505 (0.7658)
[20:21:56.325801] Test:  [  0/345]  eta: 0:03:12  loss: 0.7320 (0.7320)  time: 0.5581  data: 0.3586  max mem: 14938
[20:21:58.281525] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7320 (0.7308)  time: 0.2284  data: 0.0327  max mem: 14938
[20:22:00.243726] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7253 (0.7295)  time: 0.1958  data: 0.0001  max mem: 14938
[20:22:02.208470] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7188 (0.7261)  time: 0.1963  data: 0.0001  max mem: 14938
[20:22:04.180148] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7219 (0.7260)  time: 0.1968  data: 0.0001  max mem: 14938
[20:22:06.158359] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7281 (0.7269)  time: 0.1974  data: 0.0001  max mem: 14938
[20:22:08.141615] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7281 (0.7273)  time: 0.1980  data: 0.0001  max mem: 14938
[20:22:10.129323] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7275 (0.7263)  time: 0.1985  data: 0.0001  max mem: 14938
[20:22:12.122455] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7181 (0.7260)  time: 0.1990  data: 0.0001  max mem: 14938
[20:22:14.119502] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7221 (0.7260)  time: 0.1994  data: 0.0001  max mem: 14938
[20:22:16.118478] Test:  [100/345]  eta: 0:00:49  loss: 0.7201 (0.7263)  time: 0.1997  data: 0.0001  max mem: 14938
[20:22:18.124565] Test:  [110/345]  eta: 0:00:47  loss: 0.7227 (0.7267)  time: 0.2002  data: 0.0001  max mem: 14938
[20:22:20.136549] Test:  [120/345]  eta: 0:00:45  loss: 0.7227 (0.7263)  time: 0.2008  data: 0.0001  max mem: 14938
[20:22:22.155199] Test:  [130/345]  eta: 0:00:43  loss: 0.7247 (0.7265)  time: 0.2015  data: 0.0001  max mem: 14938
[20:22:24.176069] Test:  [140/345]  eta: 0:00:41  loss: 0.7229 (0.7259)  time: 0.2019  data: 0.0001  max mem: 14938
[20:22:26.204163] Test:  [150/345]  eta: 0:00:39  loss: 0.7163 (0.7252)  time: 0.2024  data: 0.0001  max mem: 14938
[20:22:28.238610] Test:  [160/345]  eta: 0:00:37  loss: 0.7254 (0.7256)  time: 0.2031  data: 0.0001  max mem: 14938
[20:22:30.275883] Test:  [170/345]  eta: 0:00:35  loss: 0.7335 (0.7258)  time: 0.2035  data: 0.0001  max mem: 14938
[20:22:32.318556] Test:  [180/345]  eta: 0:00:33  loss: 0.7229 (0.7258)  time: 0.2039  data: 0.0001  max mem: 14938
[20:22:34.364845] Test:  [190/345]  eta: 0:00:31  loss: 0.7199 (0.7255)  time: 0.2044  data: 0.0001  max mem: 14938
[20:22:36.419900] Test:  [200/345]  eta: 0:00:29  loss: 0.7212 (0.7256)  time: 0.2050  data: 0.0001  max mem: 14938
[20:22:38.477063] Test:  [210/345]  eta: 0:00:27  loss: 0.7217 (0.7255)  time: 0.2055  data: 0.0001  max mem: 14938
[20:22:40.539559] Test:  [220/345]  eta: 0:00:25  loss: 0.7217 (0.7256)  time: 0.2059  data: 0.0001  max mem: 14938
[20:22:42.608247] Test:  [230/345]  eta: 0:00:23  loss: 0.7266 (0.7257)  time: 0.2065  data: 0.0001  max mem: 14938
[20:22:44.683530] Test:  [240/345]  eta: 0:00:21  loss: 0.7200 (0.7255)  time: 0.2071  data: 0.0001  max mem: 14938
[20:22:46.761794] Test:  [250/345]  eta: 0:00:19  loss: 0.7208 (0.7254)  time: 0.2076  data: 0.0001  max mem: 14938
[20:22:48.845150] Test:  [260/345]  eta: 0:00:17  loss: 0.7287 (0.7256)  time: 0.2080  data: 0.0001  max mem: 14938
[20:22:50.931292] Test:  [270/345]  eta: 0:00:15  loss: 0.7254 (0.7255)  time: 0.2084  data: 0.0001  max mem: 14938
[20:22:53.025779] Test:  [280/345]  eta: 0:00:13  loss: 0.7187 (0.7252)  time: 0.2090  data: 0.0001  max mem: 14938
[20:22:55.126463] Test:  [290/345]  eta: 0:00:11  loss: 0.7163 (0.7250)  time: 0.2097  data: 0.0001  max mem: 14938
[20:22:57.231283] Test:  [300/345]  eta: 0:00:09  loss: 0.7186 (0.7250)  time: 0.2102  data: 0.0001  max mem: 14938
[20:22:59.341100] Test:  [310/345]  eta: 0:00:07  loss: 0.7202 (0.7250)  time: 0.2107  data: 0.0001  max mem: 14938
[20:23:01.456312] Test:  [320/345]  eta: 0:00:05  loss: 0.7202 (0.7248)  time: 0.2112  data: 0.0001  max mem: 14938
[20:23:03.578332] Test:  [330/345]  eta: 0:00:03  loss: 0.7226 (0.7247)  time: 0.2118  data: 0.0001  max mem: 14938
[20:23:05.701567] Test:  [340/345]  eta: 0:00:01  loss: 0.7233 (0.7247)  time: 0.2122  data: 0.0001  max mem: 14938
[20:23:06.551666] Test:  [344/345]  eta: 0:00:00  loss: 0.7233 (0.7248)  time: 0.2123  data: 0.0001  max mem: 14938
[20:23:06.607064] Test: Total time: 0:01:10 (0.2053 s / it)
[20:23:23.842655] Test:  [ 0/57]  eta: 0:00:34  loss: 0.8183 (0.8183)  time: 0.6057  data: 0.4087  max mem: 14938
[20:23:25.768649] Test:  [10/57]  eta: 0:00:10  loss: 0.8723 (0.8778)  time: 0.2301  data: 0.0372  max mem: 14938
[20:23:27.704249] Test:  [20/57]  eta: 0:00:07  loss: 0.8808 (0.8654)  time: 0.1930  data: 0.0001  max mem: 14938
[20:23:29.645853] Test:  [30/57]  eta: 0:00:05  loss: 0.7559 (0.8261)  time: 0.1938  data: 0.0001  max mem: 14938
[20:23:31.593578] Test:  [40/57]  eta: 0:00:03  loss: 0.7438 (0.8054)  time: 0.1944  data: 0.0001  max mem: 14938
[20:23:33.548329] Test:  [50/57]  eta: 0:00:01  loss: 0.7425 (0.7992)  time: 0.1951  data: 0.0001  max mem: 14938
[20:23:34.608669] Test:  [56/57]  eta: 0:00:00  loss: 0.7668 (0.8046)  time: 0.1896  data: 0.0000  max mem: 14938
[20:23:34.689875] Test: Total time: 0:00:11 (0.2009 s / it)
[20:23:37.689416] Dice score of the network on the train images: 0.714994, val images: 0.765028
[20:23:37.693768] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:23:38.860867] Epoch: [24]  [  0/345]  eta: 0:06:42  lr: 0.000120  loss: 0.7380 (0.7380)  time: 1.1660  data: 0.4067  max mem: 14938
[20:23:53.916116] Epoch: [24]  [ 20/345]  eta: 0:04:11  lr: 0.000119  loss: 0.7550 (0.7591)  time: 0.7527  data: 0.0001  max mem: 14938
[20:24:09.050198] Epoch: [24]  [ 40/345]  eta: 0:03:53  lr: 0.000119  loss: 0.7595 (0.7614)  time: 0.7567  data: 0.0001  max mem: 14938
[20:24:24.236172] Epoch: [24]  [ 60/345]  eta: 0:03:37  lr: 0.000119  loss: 0.7571 (0.7609)  time: 0.7592  data: 0.0001  max mem: 14938
[20:24:39.433889] Epoch: [24]  [ 80/345]  eta: 0:03:21  lr: 0.000119  loss: 0.7551 (0.7596)  time: 0.7598  data: 0.0001  max mem: 14938
[20:24:54.648107] Epoch: [24]  [100/345]  eta: 0:03:06  lr: 0.000119  loss: 0.7558 (0.7592)  time: 0.7607  data: 0.0001  max mem: 14938
[20:25:09.861838] Epoch: [24]  [120/345]  eta: 0:02:51  lr: 0.000119  loss: 0.7586 (0.7583)  time: 0.7606  data: 0.0001  max mem: 14938
[20:25:25.056103] Epoch: [24]  [140/345]  eta: 0:02:36  lr: 0.000118  loss: 0.7625 (0.7589)  time: 0.7597  data: 0.0001  max mem: 14938
[20:25:40.252033] Epoch: [24]  [160/345]  eta: 0:02:20  lr: 0.000118  loss: 0.7518 (0.7582)  time: 0.7597  data: 0.0001  max mem: 14938
[20:25:55.462457] Epoch: [24]  [180/345]  eta: 0:02:05  lr: 0.000118  loss: 0.7562 (0.7584)  time: 0.7605  data: 0.0001  max mem: 14938
[20:26:10.641146] Epoch: [24]  [200/345]  eta: 0:01:50  lr: 0.000118  loss: 0.7504 (0.7578)  time: 0.7589  data: 0.0001  max mem: 14938
[20:26:25.834925] Epoch: [24]  [220/345]  eta: 0:01:35  lr: 0.000118  loss: 0.7517 (0.7574)  time: 0.7596  data: 0.0001  max mem: 14938
[20:26:41.005422] Epoch: [24]  [240/345]  eta: 0:01:19  lr: 0.000118  loss: 0.7521 (0.7567)  time: 0.7585  data: 0.0001  max mem: 14938
[20:26:56.194817] Epoch: [24]  [260/345]  eta: 0:01:04  lr: 0.000117  loss: 0.7542 (0.7567)  time: 0.7594  data: 0.0001  max mem: 14938
[20:27:11.367191] Epoch: [24]  [280/345]  eta: 0:00:49  lr: 0.000117  loss: 0.7519 (0.7565)  time: 0.7586  data: 0.0001  max mem: 14938
[20:27:26.530827] Epoch: [24]  [300/345]  eta: 0:00:34  lr: 0.000117  loss: 0.7528 (0.7562)  time: 0.7581  data: 0.0001  max mem: 14938
[20:27:41.712673] Epoch: [24]  [320/345]  eta: 0:00:19  lr: 0.000117  loss: 0.7477 (0.7557)  time: 0.7591  data: 0.0001  max mem: 14938
[20:27:56.885350] Epoch: [24]  [340/345]  eta: 0:00:03  lr: 0.000117  loss: 0.7570 (0.7560)  time: 0.7586  data: 0.0001  max mem: 14938
[20:27:59.918148] Epoch: [24]  [344/345]  eta: 0:00:00  lr: 0.000117  loss: 0.7570 (0.7560)  time: 0.7584  data: 0.0001  max mem: 14938
[20:27:59.986500] Epoch: [24] Total time: 0:04:22 (0.7603 s / it)
[20:27:59.986991] Averaged stats: lr: 0.000117  loss: 0.7570 (0.7560)
[20:28:00.560015] Test:  [  0/345]  eta: 0:03:15  loss: 0.7396 (0.7396)  time: 0.5678  data: 0.3685  max mem: 14938
[20:28:02.510576] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7333 (0.7322)  time: 0.2289  data: 0.0336  max mem: 14938
[20:28:04.471222] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7333 (0.7330)  time: 0.1955  data: 0.0001  max mem: 14938
[20:28:06.437160] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7218 (0.7301)  time: 0.1963  data: 0.0001  max mem: 14938
[20:28:08.407153] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7333 (0.7327)  time: 0.1967  data: 0.0001  max mem: 14938
[20:28:10.382686] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7333 (0.7310)  time: 0.1972  data: 0.0001  max mem: 14938
[20:28:12.363239] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7177 (0.7296)  time: 0.1977  data: 0.0001  max mem: 14938
[20:28:14.349723] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7209 (0.7297)  time: 0.1983  data: 0.0001  max mem: 14938
[20:28:16.343366] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7215 (0.7285)  time: 0.1989  data: 0.0001  max mem: 14938
[20:28:18.343033] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7244 (0.7293)  time: 0.1996  data: 0.0001  max mem: 14938
[20:28:20.347234] Test:  [100/345]  eta: 0:00:49  loss: 0.7308 (0.7288)  time: 0.2001  data: 0.0001  max mem: 14938
[20:28:22.355684] Test:  [110/345]  eta: 0:00:47  loss: 0.7308 (0.7294)  time: 0.2006  data: 0.0001  max mem: 14938
[20:28:24.363229] Test:  [120/345]  eta: 0:00:45  loss: 0.7329 (0.7298)  time: 0.2007  data: 0.0001  max mem: 14938
[20:28:26.378402] Test:  [130/345]  eta: 0:00:43  loss: 0.7301 (0.7297)  time: 0.2011  data: 0.0001  max mem: 14938
[20:28:28.400241] Test:  [140/345]  eta: 0:00:41  loss: 0.7266 (0.7294)  time: 0.2018  data: 0.0001  max mem: 14938
[20:28:30.424649] Test:  [150/345]  eta: 0:00:39  loss: 0.7274 (0.7290)  time: 0.2023  data: 0.0001  max mem: 14938
[20:28:32.455381] Test:  [160/345]  eta: 0:00:37  loss: 0.7281 (0.7291)  time: 0.2027  data: 0.0001  max mem: 14938
[20:28:34.492259] Test:  [170/345]  eta: 0:00:35  loss: 0.7265 (0.7289)  time: 0.2033  data: 0.0001  max mem: 14938
[20:28:36.530557] Test:  [180/345]  eta: 0:00:33  loss: 0.7248 (0.7289)  time: 0.2037  data: 0.0001  max mem: 14938
[20:28:38.575462] Test:  [190/345]  eta: 0:00:31  loss: 0.7253 (0.7289)  time: 0.2041  data: 0.0001  max mem: 14938
[20:28:40.626205] Test:  [200/345]  eta: 0:00:29  loss: 0.7288 (0.7287)  time: 0.2047  data: 0.0001  max mem: 14938
[20:28:42.681159] Test:  [210/345]  eta: 0:00:27  loss: 0.7288 (0.7289)  time: 0.2052  data: 0.0001  max mem: 14938
[20:28:44.743360] Test:  [220/345]  eta: 0:00:25  loss: 0.7219 (0.7286)  time: 0.2058  data: 0.0001  max mem: 14938
[20:28:46.810920] Test:  [230/345]  eta: 0:00:23  loss: 0.7202 (0.7282)  time: 0.2064  data: 0.0001  max mem: 14938
[20:28:48.882520] Test:  [240/345]  eta: 0:00:21  loss: 0.7275 (0.7283)  time: 0.2069  data: 0.0001  max mem: 14938
[20:28:50.959552] Test:  [250/345]  eta: 0:00:19  loss: 0.7263 (0.7282)  time: 0.2074  data: 0.0001  max mem: 14938
[20:28:53.042910] Test:  [260/345]  eta: 0:00:17  loss: 0.7201 (0.7280)  time: 0.2080  data: 0.0001  max mem: 14938
[20:28:55.131534] Test:  [270/345]  eta: 0:00:15  loss: 0.7301 (0.7283)  time: 0.2085  data: 0.0001  max mem: 14938
[20:28:57.226652] Test:  [280/345]  eta: 0:00:13  loss: 0.7306 (0.7284)  time: 0.2091  data: 0.0001  max mem: 14938
[20:28:59.325645] Test:  [290/345]  eta: 0:00:11  loss: 0.7257 (0.7284)  time: 0.2096  data: 0.0001  max mem: 14938
[20:29:01.430950] Test:  [300/345]  eta: 0:00:09  loss: 0.7220 (0.7283)  time: 0.2102  data: 0.0001  max mem: 14938
[20:29:03.537358] Test:  [310/345]  eta: 0:00:07  loss: 0.7212 (0.7282)  time: 0.2105  data: 0.0001  max mem: 14938
[20:29:05.650554] Test:  [320/345]  eta: 0:00:05  loss: 0.7182 (0.7280)  time: 0.2109  data: 0.0001  max mem: 14938
[20:29:07.768982] Test:  [330/345]  eta: 0:00:03  loss: 0.7256 (0.7283)  time: 0.2115  data: 0.0001  max mem: 14938
[20:29:09.889954] Test:  [340/345]  eta: 0:00:01  loss: 0.7336 (0.7285)  time: 0.2119  data: 0.0001  max mem: 14938
[20:29:10.740466] Test:  [344/345]  eta: 0:00:00  loss: 0.7296 (0.7284)  time: 0.2121  data: 0.0001  max mem: 14938
[20:29:10.807582] Test: Total time: 0:01:10 (0.2053 s / it)
[20:29:27.709506] Test:  [ 0/57]  eta: 0:00:30  loss: 0.8150 (0.8150)  time: 0.5354  data: 0.3365  max mem: 14938
[20:29:29.636341] Test:  [10/57]  eta: 0:00:10  loss: 0.8697 (0.8726)  time: 0.2238  data: 0.0307  max mem: 14938
[20:29:31.574567] Test:  [20/57]  eta: 0:00:07  loss: 0.8768 (0.8663)  time: 0.1932  data: 0.0001  max mem: 14938
[20:29:33.516589] Test:  [30/57]  eta: 0:00:05  loss: 0.7519 (0.8262)  time: 0.1940  data: 0.0001  max mem: 14938
[20:29:35.464969] Test:  [40/57]  eta: 0:00:03  loss: 0.7481 (0.8063)  time: 0.1945  data: 0.0001  max mem: 14938
[20:29:37.418103] Test:  [50/57]  eta: 0:00:01  loss: 0.7479 (0.8009)  time: 0.1950  data: 0.0001  max mem: 14938
[20:29:38.481207] Test:  [56/57]  eta: 0:00:00  loss: 0.7750 (0.8074)  time: 0.1897  data: 0.0001  max mem: 14938
[20:29:38.544753] Test: Total time: 0:00:11 (0.1995 s / it)
[20:29:41.577648] Dice score of the network on the train images: 0.714234, val images: 0.761322
[20:29:41.581918] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:29:42.670311] Epoch: [25]  [  0/345]  eta: 0:06:15  lr: 0.000117  loss: 0.7418 (0.7418)  time: 1.0873  data: 0.3231  max mem: 14938
[20:29:57.731092] Epoch: [25]  [ 20/345]  eta: 0:04:09  lr: 0.000116  loss: 0.7607 (0.7573)  time: 0.7530  data: 0.0001  max mem: 14938
[20:30:12.841452] Epoch: [25]  [ 40/345]  eta: 0:03:52  lr: 0.000116  loss: 0.7464 (0.7521)  time: 0.7555  data: 0.0001  max mem: 14938
[20:30:27.981008] Epoch: [25]  [ 60/345]  eta: 0:03:36  lr: 0.000116  loss: 0.7549 (0.7535)  time: 0.7569  data: 0.0001  max mem: 14938
[20:30:43.172625] Epoch: [25]  [ 80/345]  eta: 0:03:21  lr: 0.000116  loss: 0.7876 (0.7624)  time: 0.7595  data: 0.0001  max mem: 14938
[20:30:58.375358] Epoch: [25]  [100/345]  eta: 0:03:06  lr: 0.000116  loss: 0.7622 (0.7628)  time: 0.7601  data: 0.0001  max mem: 14938
[20:31:13.584963] Epoch: [25]  [120/345]  eta: 0:02:51  lr: 0.000115  loss: 0.7602 (0.7623)  time: 0.7604  data: 0.0001  max mem: 14938
[20:31:28.777912] Epoch: [25]  [140/345]  eta: 0:02:35  lr: 0.000115  loss: 0.7503 (0.7613)  time: 0.7596  data: 0.0001  max mem: 14938
[20:31:43.974138] Epoch: [25]  [160/345]  eta: 0:02:20  lr: 0.000115  loss: 0.7611 (0.7617)  time: 0.7598  data: 0.0001  max mem: 14938
[20:31:59.165824] Epoch: [25]  [180/345]  eta: 0:02:05  lr: 0.000115  loss: 0.7717 (0.7626)  time: 0.7595  data: 0.0001  max mem: 14938
[20:32:14.361922] Epoch: [25]  [200/345]  eta: 0:01:50  lr: 0.000115  loss: 0.7447 (0.7612)  time: 0.7598  data: 0.0001  max mem: 14938
[20:32:29.534395] Epoch: [25]  [220/345]  eta: 0:01:34  lr: 0.000114  loss: 0.7500 (0.7605)  time: 0.7586  data: 0.0001  max mem: 14938
[20:32:44.708763] Epoch: [25]  [240/345]  eta: 0:01:19  lr: 0.000114  loss: 0.7434 (0.7592)  time: 0.7587  data: 0.0001  max mem: 14938
[20:32:59.899833] Epoch: [25]  [260/345]  eta: 0:01:04  lr: 0.000114  loss: 0.7539 (0.7590)  time: 0.7595  data: 0.0001  max mem: 14938
[20:33:15.084360] Epoch: [25]  [280/345]  eta: 0:00:49  lr: 0.000114  loss: 0.7543 (0.7583)  time: 0.7592  data: 0.0001  max mem: 14938
[20:33:30.248976] Epoch: [25]  [300/345]  eta: 0:00:34  lr: 0.000114  loss: 0.7442 (0.7574)  time: 0.7582  data: 0.0001  max mem: 14938
[20:33:45.441468] Epoch: [25]  [320/345]  eta: 0:00:18  lr: 0.000113  loss: 0.7437 (0.7568)  time: 0.7596  data: 0.0001  max mem: 14938
[20:34:00.616657] Epoch: [25]  [340/345]  eta: 0:00:03  lr: 0.000113  loss: 0.7444 (0.7561)  time: 0.7587  data: 0.0001  max mem: 14938
[20:34:03.645831] Epoch: [25]  [344/345]  eta: 0:00:00  lr: 0.000113  loss: 0.7471 (0.7560)  time: 0.7583  data: 0.0001  max mem: 14938
[20:34:03.719912] Epoch: [25] Total time: 0:04:22 (0.7598 s / it)
[20:34:03.720832] Averaged stats: lr: 0.000113  loss: 0.7471 (0.7560)
[20:34:04.289838] Test:  [  0/345]  eta: 0:03:14  loss: 0.6978 (0.6978)  time: 0.5639  data: 0.3658  max mem: 14938
[20:34:06.242269] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7134 (0.7200)  time: 0.2287  data: 0.0333  max mem: 14938
[20:34:08.201633] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7166 (0.7179)  time: 0.1955  data: 0.0001  max mem: 14938
[20:34:10.167123] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7154 (0.7166)  time: 0.1962  data: 0.0001  max mem: 14938
[20:34:12.138465] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7172 (0.7181)  time: 0.1968  data: 0.0001  max mem: 14938
[20:34:14.111979] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7208 (0.7170)  time: 0.1972  data: 0.0001  max mem: 14938
[20:34:16.091836] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7098 (0.7180)  time: 0.1976  data: 0.0001  max mem: 14938
[20:34:18.078477] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7207 (0.7179)  time: 0.1983  data: 0.0001  max mem: 14938
[20:34:20.069226] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7185 (0.7173)  time: 0.1988  data: 0.0001  max mem: 14938
[20:34:22.065411] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7158 (0.7172)  time: 0.1993  data: 0.0001  max mem: 14938
[20:34:24.067892] Test:  [100/345]  eta: 0:00:49  loss: 0.7108 (0.7168)  time: 0.1999  data: 0.0001  max mem: 14938
[20:34:26.074814] Test:  [110/345]  eta: 0:00:47  loss: 0.7205 (0.7181)  time: 0.2004  data: 0.0001  max mem: 14938
[20:34:28.084811] Test:  [120/345]  eta: 0:00:45  loss: 0.7249 (0.7182)  time: 0.2008  data: 0.0001  max mem: 14938
[20:34:30.100802] Test:  [130/345]  eta: 0:00:43  loss: 0.7141 (0.7176)  time: 0.2012  data: 0.0001  max mem: 14938
[20:34:32.119477] Test:  [140/345]  eta: 0:00:41  loss: 0.7147 (0.7182)  time: 0.2017  data: 0.0001  max mem: 14938
[20:34:34.145346] Test:  [150/345]  eta: 0:00:39  loss: 0.7198 (0.7183)  time: 0.2022  data: 0.0001  max mem: 14938
[20:34:36.176985] Test:  [160/345]  eta: 0:00:37  loss: 0.7189 (0.7183)  time: 0.2028  data: 0.0001  max mem: 14938
[20:34:38.213014] Test:  [170/345]  eta: 0:00:35  loss: 0.7178 (0.7183)  time: 0.2033  data: 0.0001  max mem: 14938
[20:34:40.253395] Test:  [180/345]  eta: 0:00:33  loss: 0.7144 (0.7181)  time: 0.2038  data: 0.0001  max mem: 14938

[20:34:42.298626] Test:  [190/345]  eta: 0:00:31  loss: 0.7150 (0.7182)  time: 0.2042  data: 0.0001  max mem: 14938
[20:34:44.351624] Test:  [200/345]  eta: 0:00:29  loss: 0.7179 (0.7183)  time: 0.2049  data: 0.0001  max mem: 14938
[20:34:46.408984] Test:  [210/345]  eta: 0:00:27  loss: 0.7125 (0.7181)  time: 0.2055  data: 0.0001  max mem: 14938
[20:34:48.472783] Test:  [220/345]  eta: 0:00:25  loss: 0.7125 (0.7182)  time: 0.2060  data: 0.0001  max mem: 14938
[20:34:50.540638] Test:  [230/345]  eta: 0:00:23  loss: 0.7202 (0.7185)  time: 0.2065  data: 0.0001  max mem: 14938
[20:34:52.612455] Test:  [240/345]  eta: 0:00:21  loss: 0.7240 (0.7187)  time: 0.2069  data: 0.0001  max mem: 14938
[20:34:54.691614] Test:  [250/345]  eta: 0:00:19  loss: 0.7240 (0.7188)  time: 0.2075  data: 0.0001  max mem: 14938
[20:34:56.775627] Test:  [260/345]  eta: 0:00:17  loss: 0.7159 (0.7188)  time: 0.2081  data: 0.0001  max mem: 14938
[20:34:58.862235] Test:  [270/345]  eta: 0:00:15  loss: 0.7140 (0.7186)  time: 0.2085  data: 0.0001  max mem: 14938
[20:35:00.956006] Test:  [280/345]  eta: 0:00:13  loss: 0.7139 (0.7185)  time: 0.2090  data: 0.0001  max mem: 14938
[20:35:03.054197] Test:  [290/345]  eta: 0:00:11  loss: 0.7169 (0.7186)  time: 0.2095  data: 0.0001  max mem: 14938
[20:35:05.159823] Test:  [300/345]  eta: 0:00:09  loss: 0.7124 (0.7184)  time: 0.2101  data: 0.0001  max mem: 14938
[20:35:07.270612] Test:  [310/345]  eta: 0:00:07  loss: 0.7104 (0.7182)  time: 0.2108  data: 0.0001  max mem: 14938
[20:35:09.386879] Test:  [320/345]  eta: 0:00:05  loss: 0.7112 (0.7182)  time: 0.2113  data: 0.0001  max mem: 14938
[20:35:11.508120] Test:  [330/345]  eta: 0:00:03  loss: 0.7130 (0.7182)  time: 0.2118  data: 0.0001  max mem: 14938
[20:35:13.631922] Test:  [340/345]  eta: 0:00:01  loss: 0.7232 (0.7183)  time: 0.2122  data: 0.0001  max mem: 14938
[20:35:14.483198] Test:  [344/345]  eta: 0:00:00  loss: 0.7232 (0.7183)  time: 0.2124  data: 0.0001  max mem: 14938
[20:35:14.553464] Test: Total time: 0:01:10 (0.2053 s / it)
[20:35:31.640849] Test:  [ 0/57]  eta: 0:00:29  loss: 0.8325 (0.8325)  time: 0.5256  data: 0.3291  max mem: 14938
[20:35:33.567804] Test:  [10/57]  eta: 0:00:10  loss: 0.8733 (0.8772)  time: 0.2229  data: 0.0300  max mem: 14938
[20:35:35.503657] Test:  [20/57]  eta: 0:00:07  loss: 0.8733 (0.8626)  time: 0.1931  data: 0.0001  max mem: 14938
[20:35:37.448799] Test:  [30/57]  eta: 0:00:05  loss: 0.7593 (0.8247)  time: 0.1940  data: 0.0001  max mem: 14938
[20:35:39.398904] Test:  [40/57]  eta: 0:00:03  loss: 0.7433 (0.8050)  time: 0.1947  data: 0.0001  max mem: 14938
[20:35:41.354716] Test:  [50/57]  eta: 0:00:01  loss: 0.7417 (0.7987)  time: 0.1952  data: 0.0001  max mem: 14938
[20:35:42.415743] Test:  [56/57]  eta: 0:00:00  loss: 0.7600 (0.8042)  time: 0.1898  data: 0.0001  max mem: 14938
[20:35:42.486182] Test: Total time: 0:00:11 (0.1995 s / it)
[20:35:45.504091] Dice score of the network on the train images: 0.720465, val images: 0.764352
[20:35:45.505131] saving best_prec_model_0 @ epoch 25
[20:35:46.528935] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:35:47.618205] Epoch: [26]  [  0/345]  eta: 0:06:15  lr: 0.000113  loss: 0.7251 (0.7251)  time: 1.0882  data: 0.3245  max mem: 14938
[20:36:02.672323] Epoch: [26]  [ 20/345]  eta: 0:04:09  lr: 0.000113  loss: 0.7431 (0.7441)  time: 0.7526  data: 0.0001  max mem: 14938
[20:36:17.803895] Epoch: [26]  [ 40/345]  eta: 0:03:52  lr: 0.000113  loss: 0.7399 (0.7447)  time: 0.7565  data: 0.0001  max mem: 14938
[20:36:32.969083] Epoch: [26]  [ 60/345]  eta: 0:03:36  lr: 0.000112  loss: 0.7474 (0.7469)  time: 0.7582  data: 0.0001  max mem: 14938
[20:36:48.171175] Epoch: [26]  [ 80/345]  eta: 0:03:21  lr: 0.000112  loss: 0.7385 (0.7459)  time: 0.7601  data: 0.0001  max mem: 14938
[20:37:03.373274] Epoch: [26]  [100/345]  eta: 0:03:06  lr: 0.000112  loss: 0.7356 (0.7450)  time: 0.7601  data: 0.0001  max mem: 14938
[20:37:18.566289] Epoch: [26]  [120/345]  eta: 0:02:51  lr: 0.000112  loss: 0.7387 (0.7450)  time: 0.7596  data: 0.0001  max mem: 14938
[20:37:33.754754] Epoch: [26]  [140/345]  eta: 0:02:35  lr: 0.000111  loss: 0.7356 (0.7439)  time: 0.7594  data: 0.0001  max mem: 14938
[20:37:48.949497] Epoch: [26]  [160/345]  eta: 0:02:20  lr: 0.000111  loss: 0.7464 (0.7440)  time: 0.7597  data: 0.0001  max mem: 14938
[20:38:04.147388] Epoch: [26]  [180/345]  eta: 0:02:05  lr: 0.000111  loss: 0.7429 (0.7439)  time: 0.7598  data: 0.0001  max mem: 14938
[20:38:19.344357] Epoch: [26]  [200/345]  eta: 0:01:50  lr: 0.000111  loss: 0.7533 (0.7449)  time: 0.7598  data: 0.0001  max mem: 14938
[20:38:34.531393] Epoch: [26]  [220/345]  eta: 0:01:35  lr: 0.000110  loss: 0.7445 (0.7451)  time: 0.7593  data: 0.0001  max mem: 14938
[20:38:49.703142] Epoch: [26]  [240/345]  eta: 0:01:19  lr: 0.000110  loss: 0.7542 (0.7461)  time: 0.7586  data: 0.0001  max mem: 14938
[20:39:04.885965] Epoch: [26]  [260/345]  eta: 0:01:04  lr: 0.000110  loss: 0.7409 (0.7461)  time: 0.7591  data: 0.0001  max mem: 14938
[20:39:20.061907] Epoch: [26]  [280/345]  eta: 0:00:49  lr: 0.000110  loss: 0.7448 (0.7460)  time: 0.7587  data: 0.0001  max mem: 14938
[20:39:35.243133] Epoch: [26]  [300/345]  eta: 0:00:34  lr: 0.000110  loss: 0.7553 (0.7465)  time: 0.7590  data: 0.0001  max mem: 14938
[20:39:50.424586] Epoch: [26]  [320/345]  eta: 0:00:18  lr: 0.000109  loss: 0.7483 (0.7466)  time: 0.7590  data: 0.0001  max mem: 14938
[20:40:05.586104] Epoch: [26]  [340/345]  eta: 0:00:03  lr: 0.000109  loss: 0.7544 (0.7469)  time: 0.7580  data: 0.0001  max mem: 14938
[20:40:08.620819] Epoch: [26]  [344/345]  eta: 0:00:00  lr: 0.000109  loss: 0.7436 (0.7467)  time: 0.7578  data: 0.0001  max mem: 14938
[20:40:08.690983] Epoch: [26] Total time: 0:04:22 (0.7599 s / it)
[20:40:08.691344] Averaged stats: lr: 0.000109  loss: 0.7436 (0.7467)
[20:40:09.289908] Test:  [  0/345]  eta: 0:03:24  loss: 0.7279 (0.7279)  time: 0.5934  data: 0.3951  max mem: 14938
[20:40:11.242146] Test:  [ 10/345]  eta: 0:01:17  loss: 0.7200 (0.7228)  time: 0.2313  data: 0.0360  max mem: 14938
[20:40:13.204306] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7199 (0.7214)  time: 0.1956  data: 0.0001  max mem: 14938
[20:40:15.168119] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7119 (0.7195)  time: 0.1962  data: 0.0001  max mem: 14938
[20:40:17.138147] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7113 (0.7165)  time: 0.1966  data: 0.0001  max mem: 14938
[20:40:19.114109] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7143 (0.7182)  time: 0.1972  data: 0.0001  max mem: 14938
[20:40:21.095903] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7161 (0.7175)  time: 0.1978  data: 0.0001  max mem: 14938
[20:40:23.082468] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7140 (0.7181)  time: 0.1984  data: 0.0001  max mem: 14938
[20:40:25.072282] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7141 (0.7179)  time: 0.1988  data: 0.0001  max mem: 14938
[20:40:27.070692] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7141 (0.7174)  time: 0.1993  data: 0.0001  max mem: 14938
[20:40:29.073058] Test:  [100/345]  eta: 0:00:49  loss: 0.7183 (0.7180)  time: 0.2000  data: 0.0001  max mem: 14938
[20:40:31.078809] Test:  [110/345]  eta: 0:00:47  loss: 0.7211 (0.7181)  time: 0.2003  data: 0.0001  max mem: 14938
[20:40:33.091010] Test:  [120/345]  eta: 0:00:45  loss: 0.7166 (0.7179)  time: 0.2008  data: 0.0001  max mem: 14938
[20:40:35.105469] Test:  [130/345]  eta: 0:00:43  loss: 0.7206 (0.7185)  time: 0.2013  data: 0.0001  max mem: 14938
[20:40:37.127930] Test:  [140/345]  eta: 0:00:41  loss: 0.7211 (0.7184)  time: 0.2018  data: 0.0001  max mem: 14938
[20:40:39.155459] Test:  [150/345]  eta: 0:00:39  loss: 0.7179 (0.7188)  time: 0.2024  data: 0.0001  max mem: 14938
[20:40:41.186630] Test:  [160/345]  eta: 0:00:37  loss: 0.7114 (0.7182)  time: 0.2029  data: 0.0001  max mem: 14938
[20:40:43.225011] Test:  [170/345]  eta: 0:00:35  loss: 0.7114 (0.7180)  time: 0.2034  data: 0.0001  max mem: 14938
[20:40:45.266608] Test:  [180/345]  eta: 0:00:33  loss: 0.7207 (0.7182)  time: 0.2039  data: 0.0001  max mem: 14938
[20:40:47.312934] Test:  [190/345]  eta: 0:00:31  loss: 0.7155 (0.7182)  time: 0.2043  data: 0.0001  max mem: 14938
[20:40:49.367205] Test:  [200/345]  eta: 0:00:29  loss: 0.7128 (0.7181)  time: 0.2050  data: 0.0001  max mem: 14938
[20:40:51.426613] Test:  [210/345]  eta: 0:00:27  loss: 0.7169 (0.7184)  time: 0.2056  data: 0.0001  max mem: 14938
[20:40:53.489906] Test:  [220/345]  eta: 0:00:25  loss: 0.7185 (0.7185)  time: 0.2061  data: 0.0001  max mem: 14938
[20:40:55.557123] Test:  [230/345]  eta: 0:00:23  loss: 0.7142 (0.7184)  time: 0.2065  data: 0.0001  max mem: 14938
[20:40:57.628253] Test:  [240/345]  eta: 0:00:21  loss: 0.7142 (0.7183)  time: 0.2069  data: 0.0001  max mem: 14938
[20:40:59.706836] Test:  [250/345]  eta: 0:00:19  loss: 0.7093 (0.7182)  time: 0.2074  data: 0.0001  max mem: 14938
[20:41:01.790781] Test:  [260/345]  eta: 0:00:17  loss: 0.7119 (0.7181)  time: 0.2081  data: 0.0001  max mem: 14938
[20:41:03.879464] Test:  [270/345]  eta: 0:00:15  loss: 0.7162 (0.7182)  time: 0.2086  data: 0.0001  max mem: 14938
[20:41:05.970940] Test:  [280/345]  eta: 0:00:13  loss: 0.7167 (0.7181)  time: 0.2089  data: 0.0001  max mem: 14938
[20:41:08.069548] Test:  [290/345]  eta: 0:00:11  loss: 0.7159 (0.7181)  time: 0.2094  data: 0.0001  max mem: 14938
[20:41:10.173175] Test:  [300/345]  eta: 0:00:09  loss: 0.7149 (0.7181)  time: 0.2101  data: 0.0001  max mem: 14938
[20:41:12.281546] Test:  [310/345]  eta: 0:00:07  loss: 0.7173 (0.7182)  time: 0.2105  data: 0.0001  max mem: 14938
[20:41:14.396494] Test:  [320/345]  eta: 0:00:05  loss: 0.7173 (0.7182)  time: 0.2111  data: 0.0001  max mem: 14938
[20:41:16.516168] Test:  [330/345]  eta: 0:00:03  loss: 0.7158 (0.7180)  time: 0.2117  data: 0.0001  max mem: 14938
[20:41:18.638625] Test:  [340/345]  eta: 0:00:01  loss: 0.7140 (0.7180)  time: 0.2121  data: 0.0001  max mem: 14938
[20:41:19.491093] Test:  [344/345]  eta: 0:00:00  loss: 0.7140 (0.7179)  time: 0.2123  data: 0.0001  max mem: 14938
[20:41:19.561897] Test: Total time: 0:01:10 (0.2054 s / it)
[20:41:36.760287] Test:  [ 0/57]  eta: 0:00:30  loss: 0.8246 (0.8246)  time: 0.5329  data: 0.3368  max mem: 14938
[20:41:38.684961] Test:  [10/57]  eta: 0:00:10  loss: 0.8612 (0.8716)  time: 0.2233  data: 0.0307  max mem: 14938
[20:41:40.620128] Test:  [20/57]  eta: 0:00:07  loss: 0.8658 (0.8612)  time: 0.1929  data: 0.0001  max mem: 14938
[20:41:42.562500] Test:  [30/57]  eta: 0:00:05  loss: 0.7607 (0.8215)  time: 0.1938  data: 0.0001  max mem: 14938
[20:41:44.512621] Test:  [40/57]  eta: 0:00:03  loss: 0.7388 (0.8017)  time: 0.1946  data: 0.0001  max mem: 14938
[20:41:46.464822] Test:  [50/57]  eta: 0:00:01  loss: 0.7429 (0.7956)  time: 0.1951  data: 0.0001  max mem: 14938
[20:41:47.526817] Test:  [56/57]  eta: 0:00:00  loss: 0.7659 (0.8012)  time: 0.1897  data: 0.0001  max mem: 14938
[20:41:47.596050] Test: Total time: 0:00:11 (0.1995 s / it)
[20:41:50.593847] Dice score of the network on the train images: 0.714994, val images: 0.767432
[20:41:50.597898] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:41:51.687819] Epoch: [27]  [  0/345]  eta: 0:06:15  lr: 0.000109  loss: 0.7798 (0.7798)  time: 1.0887  data: 0.3261  max mem: 14938
[20:42:06.746353] Epoch: [27]  [ 20/345]  eta: 0:04:09  lr: 0.000109  loss: 0.7384 (0.7444)  time: 0.7529  data: 0.0001  max mem: 14938
[20:42:21.881274] Epoch: [27]  [ 40/345]  eta: 0:03:52  lr: 0.000108  loss: 0.7439 (0.7440)  time: 0.7567  data: 0.0001  max mem: 14938
[20:42:37.052831] Epoch: [27]  [ 60/345]  eta: 0:03:37  lr: 0.000108  loss: 0.7372 (0.7434)  time: 0.7585  data: 0.0001  max mem: 14938
[20:42:52.255572] Epoch: [27]  [ 80/345]  eta: 0:03:21  lr: 0.000108  loss: 0.7480 (0.7445)  time: 0.7601  data: 0.0001  max mem: 14938
[20:43:07.461093] Epoch: [27]  [100/345]  eta: 0:03:06  lr: 0.000108  loss: 0.7487 (0.7461)  time: 0.7602  data: 0.0001  max mem: 14938
[20:43:22.666895] Epoch: [27]  [120/345]  eta: 0:02:51  lr: 0.000107  loss: 0.7498 (0.7472)  time: 0.7602  data: 0.0001  max mem: 14938
[20:43:37.861396] Epoch: [27]  [140/345]  eta: 0:02:35  lr: 0.000107  loss: 0.7448 (0.7474)  time: 0.7597  data: 0.0001  max mem: 14938
[20:43:53.056330] Epoch: [27]  [160/345]  eta: 0:02:20  lr: 0.000107  loss: 0.7422 (0.7472)  time: 0.7597  data: 0.0001  max mem: 14938
[20:44:08.248537] Epoch: [27]  [180/345]  eta: 0:02:05  lr: 0.000107  loss: 0.7374 (0.7464)  time: 0.7596  data: 0.0001  max mem: 14938
[20:44:23.443392] Epoch: [27]  [200/345]  eta: 0:01:50  lr: 0.000106  loss: 0.7622 (0.7483)  time: 0.7597  data: 0.0001  max mem: 14938
[20:44:38.638867] Epoch: [27]  [220/345]  eta: 0:01:35  lr: 0.000106  loss: 0.7640 (0.7499)  time: 0.7597  data: 0.0001  max mem: 14938
[20:44:53.815432] Epoch: [27]  [240/345]  eta: 0:01:19  lr: 0.000106  loss: 0.7492 (0.7500)  time: 0.7588  data: 0.0001  max mem: 14938
[20:45:09.002697] Epoch: [27]  [260/345]  eta: 0:01:04  lr: 0.000106  loss: 0.7467 (0.7502)  time: 0.7593  data: 0.0001  max mem: 14938
[20:45:24.201718] Epoch: [27]  [280/345]  eta: 0:00:49  lr: 0.000105  loss: 0.7509 (0.7502)  time: 0.7599  data: 0.0001  max mem: 14938
[20:45:39.394173] Epoch: [27]  [300/345]  eta: 0:00:34  lr: 0.000105  loss: 0.7418 (0.7500)  time: 0.7596  data: 0.0001  max mem: 14938
[20:45:54.582675] Epoch: [27]  [320/345]  eta: 0:00:19  lr: 0.000105  loss: 0.7413 (0.7496)  time: 0.7594  data: 0.0001  max mem: 14938
[20:46:09.759631] Epoch: [27]  [340/345]  eta: 0:00:03  lr: 0.000104  loss: 0.7383 (0.7492)  time: 0.7588  data: 0.0001  max mem: 14938
[20:46:12.790980] Epoch: [27]  [344/345]  eta: 0:00:00  lr: 0.000104  loss: 0.7390 (0.7493)  time: 0.7587  data: 0.0001  max mem: 14938
[20:46:12.861257] Epoch: [27] Total time: 0:04:22 (0.7602 s / it)
[20:46:12.861472] Averaged stats: lr: 0.000104  loss: 0.7390 (0.7493)
[20:46:13.423458] Test:  [  0/345]  eta: 0:03:11  loss: 0.7123 (0.7123)  time: 0.5563  data: 0.3588  max mem: 14938
[20:46:15.379573] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7173 (0.7193)  time: 0.2283  data: 0.0327  max mem: 14938
[20:46:17.340891] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7101 (0.7112)  time: 0.1958  data: 0.0001  max mem: 14938
[20:46:19.307855] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7101 (0.7123)  time: 0.1963  data: 0.0001  max mem: 14938
[20:46:21.277819] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7137 (0.7125)  time: 0.1968  data: 0.0001  max mem: 14938
[20:46:23.253374] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7102 (0.7124)  time: 0.1972  data: 0.0001  max mem: 14938
[20:46:25.233603] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7102 (0.7128)  time: 0.1977  data: 0.0001  max mem: 14938
[20:46:27.219940] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7158 (0.7133)  time: 0.1983  data: 0.0001  max mem: 14938
[20:46:29.210889] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7148 (0.7134)  time: 0.1988  data: 0.0001  max mem: 14938
[20:46:31.207970] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7139 (0.7135)  time: 0.1993  data: 0.0001  max mem: 14938
[20:46:33.211048] Test:  [100/345]  eta: 0:00:49  loss: 0.7140 (0.7141)  time: 0.1999  data: 0.0001  max mem: 14938
[20:46:35.218302] Test:  [110/345]  eta: 0:00:47  loss: 0.7140 (0.7141)  time: 0.2005  data: 0.0001  max mem: 14938
[20:46:37.230363] Test:  [120/345]  eta: 0:00:45  loss: 0.7112 (0.7144)  time: 0.2009  data: 0.0001  max mem: 14938
[20:46:39.247604] Test:  [130/345]  eta: 0:00:43  loss: 0.7133 (0.7148)  time: 0.2014  data: 0.0001  max mem: 14938
[20:46:41.269730] Test:  [140/345]  eta: 0:00:41  loss: 0.7130 (0.7145)  time: 0.2019  data: 0.0001  max mem: 14938
[20:46:43.297165] Test:  [150/345]  eta: 0:00:39  loss: 0.7109 (0.7142)  time: 0.2024  data: 0.0001  max mem: 14938
[20:46:45.328185] Test:  [160/345]  eta: 0:00:37  loss: 0.7084 (0.7139)  time: 0.2029  data: 0.0001  max mem: 14938
[20:46:47.363876] Test:  [170/345]  eta: 0:00:35  loss: 0.7077 (0.7138)  time: 0.2033  data: 0.0001  max mem: 14938
[20:46:49.406410] Test:  [180/345]  eta: 0:00:33  loss: 0.7098 (0.7136)  time: 0.2038  data: 0.0001  max mem: 14938
[20:46:51.452999] Test:  [190/345]  eta: 0:00:31  loss: 0.7098 (0.7134)  time: 0.2044  data: 0.0001  max mem: 14938
[20:46:53.506085] Test:  [200/345]  eta: 0:00:29  loss: 0.7074 (0.7134)  time: 0.2049  data: 0.0001  max mem: 14938
[20:46:55.566360] Test:  [210/345]  eta: 0:00:27  loss: 0.7101 (0.7134)  time: 0.2056  data: 0.0001  max mem: 14938
[20:46:57.630602] Test:  [220/345]  eta: 0:00:25  loss: 0.7147 (0.7136)  time: 0.2062  data: 0.0001  max mem: 14938
[20:46:59.699348] Test:  [230/345]  eta: 0:00:23  loss: 0.7188 (0.7140)  time: 0.2066  data: 0.0001  max mem: 14938
[20:47:01.774133] Test:  [240/345]  eta: 0:00:21  loss: 0.7226 (0.7142)  time: 0.2071  data: 0.0001  max mem: 14938
[20:47:03.854121] Test:  [250/345]  eta: 0:00:19  loss: 0.7169 (0.7143)  time: 0.2077  data: 0.0001  max mem: 14938
[20:47:05.937281] Test:  [260/345]  eta: 0:00:17  loss: 0.7110 (0.7140)  time: 0.2081  data: 0.0001  max mem: 14938
[20:47:08.024531] Test:  [270/345]  eta: 0:00:15  loss: 0.7122 (0.7140)  time: 0.2085  data: 0.0001  max mem: 14938
[20:47:10.118549] Test:  [280/345]  eta: 0:00:13  loss: 0.7102 (0.7140)  time: 0.2090  data: 0.0001  max mem: 14938
[20:47:12.217596] Test:  [290/345]  eta: 0:00:11  loss: 0.7088 (0.7140)  time: 0.2096  data: 0.0001  max mem: 14938
[20:47:14.323272] Test:  [300/345]  eta: 0:00:09  loss: 0.7168 (0.7142)  time: 0.2102  data: 0.0001  max mem: 14938
[20:47:16.436575] Test:  [310/345]  eta: 0:00:07  loss: 0.7196 (0.7146)  time: 0.2109  data: 0.0001  max mem: 14938
[20:47:18.553651] Test:  [320/345]  eta: 0:00:05  loss: 0.7193 (0.7146)  time: 0.2115  data: 0.0001  max mem: 14938
[20:47:20.674664] Test:  [330/345]  eta: 0:00:03  loss: 0.7130 (0.7145)  time: 0.2118  data: 0.0001  max mem: 14938
[20:47:22.799980] Test:  [340/345]  eta: 0:00:01  loss: 0.7130 (0.7145)  time: 0.2123  data: 0.0001  max mem: 14938
[20:47:23.650588] Test:  [344/345]  eta: 0:00:00  loss: 0.7130 (0.7145)  time: 0.2124  data: 0.0001  max mem: 14938
[20:47:23.723393] Test: Total time: 0:01:10 (0.2054 s / it)
[20:47:40.969574] Test:  [ 0/57]  eta: 0:00:32  loss: 0.8380 (0.8380)  time: 0.5773  data: 0.3810  max mem: 14938
[20:47:42.894318] Test:  [10/57]  eta: 0:00:10  loss: 0.8653 (0.8750)  time: 0.2274  data: 0.0347  max mem: 14938
[20:47:44.827643] Test:  [20/57]  eta: 0:00:07  loss: 0.8797 (0.8630)  time: 0.1928  data: 0.0001  max mem: 14938
[20:47:46.768998] Test:  [30/57]  eta: 0:00:05  loss: 0.7588 (0.8256)  time: 0.1937  data: 0.0001  max mem: 14938
[20:47:48.718378] Test:  [40/57]  eta: 0:00:03  loss: 0.7514 (0.8063)  time: 0.1945  data: 0.0001  max mem: 14938
[20:47:50.672309] Test:  [50/57]  eta: 0:00:01  loss: 0.7400 (0.8004)  time: 0.1951  data: 0.0001  max mem: 14938
[20:47:51.734839] Test:  [56/57]  eta: 0:00:00  loss: 0.7688 (0.8063)  time: 0.1897  data: 0.0001  max mem: 14938
[20:47:51.799372] Test: Total time: 0:00:11 (0.2001 s / it)
[20:47:54.761877] Dice score of the network on the train images: 0.722198, val images: 0.758080
[20:47:54.765955] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:47:55.881355] Epoch: [28]  [  0/345]  eta: 0:06:24  lr: 0.000104  loss: 0.7298 (0.7298)  time: 1.1144  data: 0.3505  max mem: 14938
[20:48:10.937666] Epoch: [28]  [ 20/345]  eta: 0:04:10  lr: 0.000104  loss: 0.7579 (0.7595)  time: 0.7528  data: 0.0001  max mem: 14938
[20:48:26.075620] Epoch: [28]  [ 40/345]  eta: 0:03:52  lr: 0.000104  loss: 0.7522 (0.7581)  time: 0.7569  data: 0.0001  max mem: 14938
[20:48:41.242308] Epoch: [28]  [ 60/345]  eta: 0:03:37  lr: 0.000103  loss: 0.7435 (0.7545)  time: 0.7583  data: 0.0001  max mem: 14938
[20:48:56.436039] Epoch: [28]  [ 80/345]  eta: 0:03:21  lr: 0.000103  loss: 0.7437 (0.7524)  time: 0.7596  data: 0.0001  max mem: 14938
[20:49:11.654052] Epoch: [28]  [100/345]  eta: 0:03:06  lr: 0.000103  loss: 0.7495 (0.7517)  time: 0.7609  data: 0.0001  max mem: 14938
[20:49:26.869151] Epoch: [28]  [120/345]  eta: 0:02:51  lr: 0.000103  loss: 0.7441 (0.7507)  time: 0.7607  data: 0.0001  max mem: 14938
[20:49:42.066164] Epoch: [28]  [140/345]  eta: 0:02:35  lr: 0.000102  loss: 0.7481 (0.7500)  time: 0.7598  data: 0.0001  max mem: 14938
[20:49:57.275454] Epoch: [28]  [160/345]  eta: 0:02:20  lr: 0.000102  loss: 0.7379 (0.7488)  time: 0.7604  data: 0.0001  max mem: 14938
[20:50:12.474570] Epoch: [28]  [180/345]  eta: 0:02:05  lr: 0.000102  loss: 0.7410 (0.7485)  time: 0.7599  data: 0.0001  max mem: 14938
[20:50:27.682363] Epoch: [28]  [200/345]  eta: 0:01:50  lr: 0.000101  loss: 0.7384 (0.7473)  time: 0.7603  data: 0.0001  max mem: 14938
[20:50:42.879970] Epoch: [28]  [220/345]  eta: 0:01:35  lr: 0.000101  loss: 0.7362 (0.7462)  time: 0.7598  data: 0.0001  max mem: 14938
[20:50:58.092573] Epoch: [28]  [240/345]  eta: 0:01:19  lr: 0.000101  loss: 0.7358 (0.7454)  time: 0.7606  data: 0.0001  max mem: 14938
[20:51:13.285431] Epoch: [28]  [260/345]  eta: 0:01:04  lr: 0.000101  loss: 0.7387 (0.7448)  time: 0.7596  data: 0.0001  max mem: 14938
[20:51:28.484537] Epoch: [28]  [280/345]  eta: 0:00:49  lr: 0.000100  loss: 0.7357 (0.7443)  time: 0.7599  data: 0.0001  max mem: 14938
[20:51:43.676010] Epoch: [28]  [300/345]  eta: 0:00:34  lr: 0.000100  loss: 0.7325 (0.7436)  time: 0.7595  data: 0.0001  max mem: 14938
[20:51:58.873164] Epoch: [28]  [320/345]  eta: 0:00:19  lr: 0.000100  loss: 0.7425 (0.7435)  time: 0.7598  data: 0.0001  max mem: 14938
[20:52:14.048192] Epoch: [28]  [340/345]  eta: 0:00:03  lr: 0.000099  loss: 0.7437 (0.7435)  time: 0.7587  data: 0.0001  max mem: 14938
[20:52:17.087496] Epoch: [28]  [344/345]  eta: 0:00:00  lr: 0.000099  loss: 0.7437 (0.7435)  time: 0.7588  data: 0.0001  max mem: 14938
[20:52:17.155870] Epoch: [28] Total time: 0:04:22 (0.7606 s / it)
[20:52:17.156362] Averaged stats: lr: 0.000099  loss: 0.7437 (0.7435)
[20:52:17.707001] Test:  [  0/345]  eta: 0:03:08  loss: 0.7193 (0.7193)  time: 0.5450  data: 0.3460  max mem: 14938
[20:52:19.662584] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7109 (0.7157)  time: 0.2273  data: 0.0315  max mem: 14938
[20:52:21.625692] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7124 (0.7156)  time: 0.1959  data: 0.0001  max mem: 14938
[20:52:23.591416] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7187 (0.7164)  time: 0.1964  data: 0.0001  max mem: 14938
[20:52:25.564839] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7158 (0.7161)  time: 0.1969  data: 0.0001  max mem: 14938
[20:52:27.542339] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7151 (0.7159)  time: 0.1975  data: 0.0001  max mem: 14938
[20:52:29.525147] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7059 (0.7131)  time: 0.1980  data: 0.0001  max mem: 14938
[20:52:31.511419] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7036 (0.7131)  time: 0.1984  data: 0.0001  max mem: 14938
[20:52:33.500040] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7100 (0.7122)  time: 0.1987  data: 0.0001  max mem: 14938
[20:52:35.496594] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7025 (0.7113)  time: 0.1992  data: 0.0001  max mem: 14938
[20:52:37.497935] Test:  [100/345]  eta: 0:00:49  loss: 0.7076 (0.7118)  time: 0.1998  data: 0.0001  max mem: 14938
[20:52:39.501779] Test:  [110/345]  eta: 0:00:47  loss: 0.7167 (0.7119)  time: 0.2002  data: 0.0001  max mem: 14938
[20:52:41.516692] Test:  [120/345]  eta: 0:00:45  loss: 0.7125 (0.7119)  time: 0.2009  data: 0.0001  max mem: 14938
[20:52:43.534743] Test:  [130/345]  eta: 0:00:43  loss: 0.7139 (0.7126)  time: 0.2016  data: 0.0001  max mem: 14938
[20:52:45.557677] Test:  [140/345]  eta: 0:00:41  loss: 0.7124 (0.7123)  time: 0.2020  data: 0.0001  max mem: 14938
[20:52:47.585559] Test:  [150/345]  eta: 0:00:39  loss: 0.7079 (0.7122)  time: 0.2025  data: 0.0001  max mem: 14938

[20:52:49.619260] Test:  [160/345]  eta: 0:00:37  loss: 0.7132 (0.7123)  time: 0.2030  data: 0.0001  max mem: 14938
[20:52:51.655794] Test:  [170/345]  eta: 0:00:35  loss: 0.7156 (0.7127)  time: 0.2035  data: 0.0001  max mem: 14938
[20:52:53.697605] Test:  [180/345]  eta: 0:00:33  loss: 0.7151 (0.7127)  time: 0.2039  data: 0.0001  max mem: 14938
[20:52:55.745172] Test:  [190/345]  eta: 0:00:31  loss: 0.7101 (0.7125)  time: 0.2044  data: 0.0001  max mem: 14938
[20:52:57.799390] Test:  [200/345]  eta: 0:00:29  loss: 0.7101 (0.7123)  time: 0.2050  data: 0.0001  max mem: 14938
[20:52:59.857305] Test:  [210/345]  eta: 0:00:27  loss: 0.7123 (0.7127)  time: 0.2055  data: 0.0001  max mem: 14938
[20:53:01.922539] Test:  [220/345]  eta: 0:00:25  loss: 0.7194 (0.7127)  time: 0.2061  data: 0.0001  max mem: 14938
[20:53:03.991421] Test:  [230/345]  eta: 0:00:23  loss: 0.7134 (0.7128)  time: 0.2066  data: 0.0001  max mem: 14938
[20:53:06.063975] Test:  [240/345]  eta: 0:00:21  loss: 0.7141 (0.7130)  time: 0.2070  data: 0.0001  max mem: 14938
[20:53:08.141774] Test:  [250/345]  eta: 0:00:19  loss: 0.7151 (0.7130)  time: 0.2075  data: 0.0001  max mem: 14938
[20:53:10.226727] Test:  [260/345]  eta: 0:00:17  loss: 0.7069 (0.7127)  time: 0.2081  data: 0.0001  max mem: 14938
[20:53:12.314743] Test:  [270/345]  eta: 0:00:15  loss: 0.7067 (0.7125)  time: 0.2086  data: 0.0001  max mem: 14938
[20:53:14.406966] Test:  [280/345]  eta: 0:00:13  loss: 0.7068 (0.7124)  time: 0.2089  data: 0.0001  max mem: 14938
[20:53:16.505431] Test:  [290/345]  eta: 0:00:11  loss: 0.7092 (0.7125)  time: 0.2095  data: 0.0001  max mem: 14938
[20:53:18.609166] Test:  [300/345]  eta: 0:00:09  loss: 0.7090 (0.7122)  time: 0.2100  data: 0.0001  max mem: 14938
[20:53:20.718166] Test:  [310/345]  eta: 0:00:07  loss: 0.7068 (0.7122)  time: 0.2106  data: 0.0001  max mem: 14938
[20:53:22.833434] Test:  [320/345]  eta: 0:00:05  loss: 0.7070 (0.7121)  time: 0.2112  data: 0.0001  max mem: 14938
[20:53:24.956272] Test:  [330/345]  eta: 0:00:03  loss: 0.7105 (0.7122)  time: 0.2118  data: 0.0001  max mem: 14938
[20:53:27.077981] Test:  [340/345]  eta: 0:00:01  loss: 0.7128 (0.7122)  time: 0.2122  data: 0.0001  max mem: 14938
[20:53:27.928522] Test:  [344/345]  eta: 0:00:00  loss: 0.7125 (0.7122)  time: 0.2123  data: 0.0001  max mem: 14938
[20:53:27.991334] Test: Total time: 0:01:10 (0.2053 s / it)
[20:53:44.949581] Test:  [ 0/57]  eta: 0:00:29  loss: 0.8207 (0.8207)  time: 0.5236  data: 0.3271  max mem: 14938
[20:53:46.876452] Test:  [10/57]  eta: 0:00:10  loss: 0.8770 (0.8721)  time: 0.2227  data: 0.0298  max mem: 14938
[20:53:48.812257] Test:  [20/57]  eta: 0:00:07  loss: 0.8770 (0.8635)  time: 0.1931  data: 0.0001  max mem: 14938
[20:53:50.756769] Test:  [30/57]  eta: 0:00:05  loss: 0.7625 (0.8247)  time: 0.1940  data: 0.0001  max mem: 14938
[20:53:52.702948] Test:  [40/57]  eta: 0:00:03  loss: 0.7436 (0.8049)  time: 0.1945  data: 0.0001  max mem: 14938
[20:53:54.656427] Test:  [50/57]  eta: 0:00:01  loss: 0.7394 (0.7980)  time: 0.1949  data: 0.0001  max mem: 14938
[20:53:55.718537] Test:  [56/57]  eta: 0:00:00  loss: 0.7609 (0.8043)  time: 0.1897  data: 0.0000  max mem: 14938
[20:53:55.784916] Test: Total time: 0:00:11 (0.1993 s / it)
[20:53:58.797855] Dice score of the network on the train images: 0.718338, val images: 0.766064
[20:53:58.802176] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:53:59.948989] Epoch: [29]  [  0/345]  eta: 0:06:35  lr: 0.000099  loss: 0.7317 (0.7317)  time: 1.1457  data: 0.3825  max mem: 14938
[20:54:14.986821] Epoch: [29]  [ 20/345]  eta: 0:04:10  lr: 0.000099  loss: 0.7396 (0.7371)  time: 0.7518  data: 0.0001  max mem: 14938
[20:54:30.094388] Epoch: [29]  [ 40/345]  eta: 0:03:52  lr: 0.000099  loss: 0.7369 (0.7383)  time: 0.7553  data: 0.0001  max mem: 14938
[20:54:45.283116] Epoch: [29]  [ 60/345]  eta: 0:03:37  lr: 0.000098  loss: 0.7292 (0.7367)  time: 0.7594  data: 0.0001  max mem: 14938
[20:55:00.485829] Epoch: [29]  [ 80/345]  eta: 0:03:21  lr: 0.000098  loss: 0.7377 (0.7366)  time: 0.7601  data: 0.0001  max mem: 14938
[20:55:15.714534] Epoch: [29]  [100/345]  eta: 0:03:06  lr: 0.000098  loss: 0.7307 (0.7362)  time: 0.7614  data: 0.0001  max mem: 14938
[20:55:30.944727] Epoch: [29]  [120/345]  eta: 0:02:51  lr: 0.000097  loss: 0.7439 (0.7375)  time: 0.7615  data: 0.0001  max mem: 14938
[20:55:46.163775] Epoch: [29]  [140/345]  eta: 0:02:36  lr: 0.000097  loss: 0.7408 (0.7381)  time: 0.7609  data: 0.0001  max mem: 14938
[20:56:01.378697] Epoch: [29]  [160/345]  eta: 0:02:20  lr: 0.000097  loss: 0.7414 (0.7387)  time: 0.7607  data: 0.0001  max mem: 14938
[20:56:16.576056] Epoch: [29]  [180/345]  eta: 0:02:05  lr: 0.000096  loss: 0.7366 (0.7385)  time: 0.7598  data: 0.0001  max mem: 14938
[20:56:31.790832] Epoch: [29]  [200/345]  eta: 0:01:50  lr: 0.000096  loss: 0.7427 (0.7387)  time: 0.7607  data: 0.0001  max mem: 14938
[20:56:46.983253] Epoch: [29]  [220/345]  eta: 0:01:35  lr: 0.000096  loss: 0.7403 (0.7391)  time: 0.7596  data: 0.0001  max mem: 14938
[20:57:02.178374] Epoch: [29]  [240/345]  eta: 0:01:19  lr: 0.000095  loss: 0.7439 (0.7397)  time: 0.7597  data: 0.0001  max mem: 14938
[20:57:17.373958] Epoch: [29]  [260/345]  eta: 0:01:04  lr: 0.000095  loss: 0.7373 (0.7398)  time: 0.7597  data: 0.0001  max mem: 14938
[20:57:32.567744] Epoch: [29]  [280/345]  eta: 0:00:49  lr: 0.000095  loss: 0.7450 (0.7403)  time: 0.7597  data: 0.0001  max mem: 14938
[20:57:47.762466] Epoch: [29]  [300/345]  eta: 0:00:34  lr: 0.000094  loss: 0.7376 (0.7404)  time: 0.7597  data: 0.0001  max mem: 14938
[20:58:02.956089] Epoch: [29]  [320/345]  eta: 0:00:19  lr: 0.000094  loss: 0.7410 (0.7404)  time: 0.7596  data: 0.0001  max mem: 14938
[20:58:18.147995] Epoch: [29]  [340/345]  eta: 0:00:03  lr: 0.000094  loss: 0.7348 (0.7404)  time: 0.7596  data: 0.0001  max mem: 14938
[20:58:21.183998] Epoch: [29]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.7348 (0.7403)  time: 0.7593  data: 0.0001  max mem: 14938
[20:58:21.258886] Epoch: [29] Total time: 0:04:22 (0.7607 s / it)
[20:58:21.259670] Averaged stats: lr: 0.000094  loss: 0.7348 (0.7403)
[20:58:21.885171] Test:  [  0/345]  eta: 0:03:33  loss: 0.6962 (0.6962)  time: 0.6200  data: 0.4208  max mem: 14938
[20:58:23.840351] Test:  [ 10/345]  eta: 0:01:18  loss: 0.7166 (0.7147)  time: 0.2340  data: 0.0383  max mem: 14938
[20:58:25.801763] Test:  [ 20/345]  eta: 0:01:10  loss: 0.7166 (0.7145)  time: 0.1958  data: 0.0001  max mem: 14938
[20:58:27.768664] Test:  [ 30/345]  eta: 0:01:06  loss: 0.7108 (0.7137)  time: 0.1964  data: 0.0001  max mem: 14938
[20:58:29.739514] Test:  [ 40/345]  eta: 0:01:03  loss: 0.7095 (0.7151)  time: 0.1968  data: 0.0001  max mem: 14938
[20:58:31.716562] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7180 (0.7154)  time: 0.1973  data: 0.0001  max mem: 14938
[20:58:33.698921] Test:  [ 60/345]  eta: 0:00:58  loss: 0.7132 (0.7152)  time: 0.1979  data: 0.0001  max mem: 14938
[20:58:35.687357] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7118 (0.7151)  time: 0.1985  data: 0.0001  max mem: 14938
[20:58:37.677298] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7111 (0.7150)  time: 0.1989  data: 0.0001  max mem: 14938
[20:58:39.677262] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7119 (0.7149)  time: 0.1994  data: 0.0001  max mem: 14938
[20:58:41.680231] Test:  [100/345]  eta: 0:00:49  loss: 0.7154 (0.7154)  time: 0.2001  data: 0.0001  max mem: 14938
[20:58:43.684901] Test:  [110/345]  eta: 0:00:47  loss: 0.7149 (0.7146)  time: 0.2003  data: 0.0001  max mem: 14938
[20:58:45.698349] Test:  [120/345]  eta: 0:00:45  loss: 0.7049 (0.7137)  time: 0.2008  data: 0.0001  max mem: 14938
[20:58:47.713219] Test:  [130/345]  eta: 0:00:43  loss: 0.7061 (0.7137)  time: 0.2014  data: 0.0001  max mem: 14938
[20:58:49.732446] Test:  [140/345]  eta: 0:00:41  loss: 0.7081 (0.7135)  time: 0.2016  data: 0.0001  max mem: 14938
[20:58:51.760862] Test:  [150/345]  eta: 0:00:39  loss: 0.7121 (0.7135)  time: 0.2023  data: 0.0001  max mem: 14938
[20:58:53.794887] Test:  [160/345]  eta: 0:00:37  loss: 0.7097 (0.7133)  time: 0.2031  data: 0.0001  max mem: 14938
[20:58:55.835028] Test:  [170/345]  eta: 0:00:35  loss: 0.7060 (0.7132)  time: 0.2036  data: 0.0001  max mem: 14938
[20:58:57.876931] Test:  [180/345]  eta: 0:00:33  loss: 0.7049 (0.7128)  time: 0.2040  data: 0.0001  max mem: 14938
[20:58:59.924496] Test:  [190/345]  eta: 0:00:31  loss: 0.7078 (0.7130)  time: 0.2044  data: 0.0001  max mem: 14938
[20:59:01.980610] Test:  [200/345]  eta: 0:00:29  loss: 0.7099 (0.7131)  time: 0.2051  data: 0.0001  max mem: 14938
[20:59:04.038087] Test:  [210/345]  eta: 0:00:27  loss: 0.7070 (0.7130)  time: 0.2056  data: 0.0001  max mem: 14938
[20:59:06.101227] Test:  [220/345]  eta: 0:00:25  loss: 0.7125 (0.7132)  time: 0.2060  data: 0.0001  max mem: 14938
[20:59:08.169984] Test:  [230/345]  eta: 0:00:23  loss: 0.7132 (0.7130)  time: 0.2065  data: 0.0001  max mem: 14938
[20:59:10.242977] Test:  [240/345]  eta: 0:00:21  loss: 0.7072 (0.7130)  time: 0.2070  data: 0.0001  max mem: 14938
[20:59:12.320536] Test:  [250/345]  eta: 0:00:19  loss: 0.7132 (0.7131)  time: 0.2075  data: 0.0001  max mem: 14938
[20:59:14.403906] Test:  [260/345]  eta: 0:00:17  loss: 0.7119 (0.7130)  time: 0.2080  data: 0.0001  max mem: 14938
[20:59:16.492727] Test:  [270/345]  eta: 0:00:15  loss: 0.7074 (0.7129)  time: 0.2085  data: 0.0001  max mem: 14938
[20:59:18.586108] Test:  [280/345]  eta: 0:00:13  loss: 0.7064 (0.7128)  time: 0.2090  data: 0.0001  max mem: 14938
[20:59:20.686469] Test:  [290/345]  eta: 0:00:11  loss: 0.7092 (0.7129)  time: 0.2096  data: 0.0001  max mem: 14938
[20:59:22.790702] Test:  [300/345]  eta: 0:00:09  loss: 0.7090 (0.7126)  time: 0.2102  data: 0.0001  max mem: 14938
[20:59:24.903034] Test:  [310/345]  eta: 0:00:07  loss: 0.7064 (0.7126)  time: 0.2108  data: 0.0001  max mem: 14938
[20:59:27.017266] Test:  [320/345]  eta: 0:00:05  loss: 0.7124 (0.7128)  time: 0.2113  data: 0.0001  max mem: 14938
[20:59:29.137624] Test:  [330/345]  eta: 0:00:03  loss: 0.7130 (0.7130)  time: 0.2117  data: 0.0001  max mem: 14938
[20:59:31.261647] Test:  [340/345]  eta: 0:00:01  loss: 0.7121 (0.7129)  time: 0.2122  data: 0.0001  max mem: 14938
[20:59:32.113385] Test:  [344/345]  eta: 0:00:00  loss: 0.7090 (0.7128)  time: 0.2124  data: 0.0001  max mem: 14938
[20:59:32.176331] Test: Total time: 0:01:10 (0.2055 s / it)
[20:59:49.372641] Test:  [ 0/57]  eta: 0:00:33  loss: 0.8336 (0.8336)  time: 0.5804  data: 0.3855  max mem: 14938
[20:59:51.298564] Test:  [10/57]  eta: 0:00:10  loss: 0.8656 (0.8747)  time: 0.2278  data: 0.0351  max mem: 14938
[20:59:53.232918] Test:  [20/57]  eta: 0:00:07  loss: 0.8660 (0.8662)  time: 0.1929  data: 0.0001  max mem: 14938
[20:59:55.173878] Test:  [30/57]  eta: 0:00:05  loss: 0.7613 (0.8268)  time: 0.1937  data: 0.0001  max mem: 14938
[20:59:57.123431] Test:  [40/57]  eta: 0:00:03  loss: 0.7408 (0.8058)  time: 0.1945  data: 0.0001  max mem: 14938
[20:59:59.075923] Test:  [50/57]  eta: 0:00:01  loss: 0.7312 (0.7983)  time: 0.1950  data: 0.0001  max mem: 14938
[21:00:00.137825] Test:  [56/57]  eta: 0:00:00  loss: 0.7634 (0.8047)  time: 0.1896  data: 0.0000  max mem: 14938
[21:00:00.190382] Test: Total time: 0:00:11 (0.2000 s / it)
[21:00:03.154164] Dice score of the network on the train images: 0.717263, val images: 0.766370
[21:00:03.158912] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:00:04.310957] Epoch: [30]  [  0/345]  eta: 0:06:37  lr: 0.000094  loss: 0.7226 (0.7226)  time: 1.1510  data: 0.3890  max mem: 14938
[21:00:19.377857] Epoch: [30]  [ 20/345]  eta: 0:04:10  lr: 0.000093  loss: 0.7319 (0.7316)  time: 0.7533  data: 0.0001  max mem: 14938
[21:00:34.500602] Epoch: [30]  [ 40/345]  eta: 0:03:53  lr: 0.000093  loss: 0.7358 (0.7342)  time: 0.7561  data: 0.0001  max mem: 14938
[21:00:49.690986] Epoch: [30]  [ 60/345]  eta: 0:03:37  lr: 0.000093  loss: 0.7289 (0.7339)  time: 0.7595  data: 0.0001  max mem: 14938
[21:01:04.880380] Epoch: [30]  [ 80/345]  eta: 0:03:21  lr: 0.000092  loss: 0.7274 (0.7331)  time: 0.7594  data: 0.0001  max mem: 14938
[21:01:20.091252] Epoch: [30]  [100/345]  eta: 0:03:06  lr: 0.000092  loss: 0.7278 (0.7322)  time: 0.7605  data: 0.0001  max mem: 14938
[21:01:35.297311] Epoch: [30]  [120/345]  eta: 0:02:51  lr: 0.000092  loss: 0.7296 (0.7318)  time: 0.7603  data: 0.0001  max mem: 14938
[21:01:50.508528] Epoch: [30]  [140/345]  eta: 0:02:36  lr: 0.000091  loss: 0.7363 (0.7325)  time: 0.7605  data: 0.0001  max mem: 14938
[21:02:05.701481] Epoch: [30]  [160/345]  eta: 0:02:20  lr: 0.000091  loss: 0.7302 (0.7327)  time: 0.7596  data: 0.0001  max mem: 14938
[21:02:20.893700] Epoch: [30]  [180/345]  eta: 0:02:05  lr: 0.000091  loss: 0.7378 (0.7333)  time: 0.7596  data: 0.0001  max mem: 14938
[21:02:36.091056] Epoch: [30]  [200/345]  eta: 0:01:50  lr: 0.000090  loss: 0.7372 (0.7336)  time: 0.7598  data: 0.0001  max mem: 14938
[21:02:51.286463] Epoch: [30]  [220/345]  eta: 0:01:35  lr: 0.000090  loss: 0.7284 (0.7333)  time: 0.7597  data: 0.0001  max mem: 14938
[21:03:06.480675] Epoch: [30]  [240/345]  eta: 0:01:19  lr: 0.000090  loss: 0.7397 (0.7339)  time: 0.7597  data: 0.0001  max mem: 14938
[21:03:21.649415] Epoch: [30]  [260/345]  eta: 0:01:04  lr: 0.000089  loss: 0.7311 (0.7339)  time: 0.7584  data: 0.0001  max mem: 14938
[21:03:36.845151] Epoch: [30]  [280/345]  eta: 0:00:49  lr: 0.000089  loss: 0.7353 (0.7342)  time: 0.7597  data: 0.0001  max mem: 14938
[21:03:52.043524] Epoch: [30]  [300/345]  eta: 0:00:34  lr: 0.000089  loss: 0.7344 (0.7343)  time: 0.7599  data: 0.0001  max mem: 14938
[21:04:07.233803] Epoch: [30]  [320/345]  eta: 0:00:19  lr: 0.000088  loss: 0.7318 (0.7341)  time: 0.7595  data: 0.0001  max mem: 14938
[21:04:22.423031] Epoch: [30]  [340/345]  eta: 0:00:03  lr: 0.000088  loss: 0.7345 (0.7342)  time: 0.7594  data: 0.0001  max mem: 14938
[21:04:25.454265] Epoch: [30]  [344/345]  eta: 0:00:00  lr: 0.000088  loss: 0.7375 (0.7341)  time: 0.7589  data: 0.0001  max mem: 14938
[21:04:25.525018] Epoch: [30] Total time: 0:04:22 (0.7605 s / it)
[21:04:25.525453] Averaged stats: lr: 0.000088  loss: 0.7375 (0.7341)
[21:04:26.098598] Test:  [  0/345]  eta: 0:03:15  loss: 0.7226 (0.7226)  time: 0.5677  data: 0.3669  max mem: 14938
[21:04:28.054416] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7177 (0.7140)  time: 0.2293  data: 0.0334  max mem: 14938
[21:04:30.018185] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7122 (0.7118)  time: 0.1959  data: 0.0001  max mem: 14938
[21:04:31.984064] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7081 (0.7097)  time: 0.1964  data: 0.0001  max mem: 14938
[21:04:33.956616] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7052 (0.7085)  time: 0.1969  data: 0.0001  max mem: 14938
[21:04:35.934931] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7048 (0.7079)  time: 0.1975  data: 0.0001  max mem: 14938
[21:04:37.917368] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7048 (0.7086)  time: 0.1980  data: 0.0001  max mem: 14938
[21:04:39.902376] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7056 (0.7083)  time: 0.1983  data: 0.0001  max mem: 14938
[21:04:41.893888] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7077 (0.7079)  time: 0.1988  data: 0.0001  max mem: 14938
[21:04:43.891754] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7114 (0.7085)  time: 0.1994  data: 0.0001  max mem: 14938
[21:04:45.892820] Test:  [100/345]  eta: 0:00:49  loss: 0.7083 (0.7084)  time: 0.1999  data: 0.0001  max mem: 14938
[21:04:47.900994] Test:  [110/345]  eta: 0:00:47  loss: 0.7041 (0.7079)  time: 0.2004  data: 0.0001  max mem: 14938
[21:04:49.911786] Test:  [120/345]  eta: 0:00:45  loss: 0.7028 (0.7076)  time: 0.2009  data: 0.0001  max mem: 14938
[21:04:51.928808] Test:  [130/345]  eta: 0:00:43  loss: 0.7076 (0.7076)  time: 0.2013  data: 0.0001  max mem: 14938
[21:04:53.950174] Test:  [140/345]  eta: 0:00:41  loss: 0.7112 (0.7080)  time: 0.2019  data: 0.0001  max mem: 14938
[21:04:55.980110] Test:  [150/345]  eta: 0:00:39  loss: 0.7111 (0.7079)  time: 0.2025  data: 0.0001  max mem: 14938
[21:04:58.011622] Test:  [160/345]  eta: 0:00:37  loss: 0.7085 (0.7081)  time: 0.2030  data: 0.0001  max mem: 14938
[21:05:00.048682] Test:  [170/345]  eta: 0:00:35  loss: 0.7050 (0.7079)  time: 0.2034  data: 0.0001  max mem: 14938
[21:05:02.090511] Test:  [180/345]  eta: 0:00:33  loss: 0.7045 (0.7077)  time: 0.2039  data: 0.0001  max mem: 14938
[21:05:04.138802] Test:  [190/345]  eta: 0:00:31  loss: 0.7046 (0.7079)  time: 0.2044  data: 0.0001  max mem: 14938
[21:05:06.192171] Test:  [200/345]  eta: 0:00:29  loss: 0.7108 (0.7081)  time: 0.2050  data: 0.0001  max mem: 14938
[21:05:08.250074] Test:  [210/345]  eta: 0:00:27  loss: 0.7086 (0.7081)  time: 0.2055  data: 0.0001  max mem: 14938
[21:05:10.312664] Test:  [220/345]  eta: 0:00:25  loss: 0.7086 (0.7081)  time: 0.2060  data: 0.0001  max mem: 14938
[21:05:12.381942] Test:  [230/345]  eta: 0:00:23  loss: 0.7072 (0.7081)  time: 0.2065  data: 0.0001  max mem: 14938
[21:05:14.455837] Test:  [240/345]  eta: 0:00:21  loss: 0.7050 (0.7079)  time: 0.2071  data: 0.0001  max mem: 14938
[21:05:16.536142] Test:  [250/345]  eta: 0:00:19  loss: 0.7048 (0.7080)  time: 0.2076  data: 0.0001  max mem: 14938
[21:05:18.618591] Test:  [260/345]  eta: 0:00:17  loss: 0.7112 (0.7082)  time: 0.2081  data: 0.0001  max mem: 14938
[21:05:20.707304] Test:  [270/345]  eta: 0:00:15  loss: 0.7112 (0.7083)  time: 0.2085  data: 0.0001  max mem: 14938
[21:05:22.804628] Test:  [280/345]  eta: 0:00:13  loss: 0.7082 (0.7082)  time: 0.2092  data: 0.0001  max mem: 14938
[21:05:24.905402] Test:  [290/345]  eta: 0:00:11  loss: 0.7077 (0.7082)  time: 0.2098  data: 0.0001  max mem: 14938
[21:05:27.008951] Test:  [300/345]  eta: 0:00:09  loss: 0.7087 (0.7083)  time: 0.2102  data: 0.0001  max mem: 14938
[21:05:29.117560] Test:  [310/345]  eta: 0:00:07  loss: 0.7035 (0.7082)  time: 0.2105  data: 0.0001  max mem: 14938
[21:05:31.234541] Test:  [320/345]  eta: 0:00:05  loss: 0.7124 (0.7084)  time: 0.2112  data: 0.0001  max mem: 14938
[21:05:33.354895] Test:  [330/345]  eta: 0:00:03  loss: 0.7127 (0.7084)  time: 0.2118  data: 0.0001  max mem: 14938
[21:05:35.479456] Test:  [340/345]  eta: 0:00:01  loss: 0.7074 (0.7085)  time: 0.2122  data: 0.0001  max mem: 14938
[21:05:36.332090] Test:  [344/345]  eta: 0:00:00  loss: 0.7074 (0.7084)  time: 0.2124  data: 0.0001  max mem: 14938
[21:05:36.396947] Test: Total time: 0:01:10 (0.2054 s / it)
[21:05:53.372270] Test:  [ 0/57]  eta: 0:00:32  loss: 0.8881 (0.8881)  time: 0.5619  data: 0.3664  max mem: 14938
[21:05:55.297270] Test:  [10/57]  eta: 0:00:10  loss: 0.8922 (0.8933)  time: 0.2260  data: 0.0334  max mem: 14938
[21:05:57.231564] Test:  [20/57]  eta: 0:00:07  loss: 0.8923 (0.8818)  time: 0.1929  data: 0.0001  max mem: 14938
[21:05:59.174698] Test:  [30/57]  eta: 0:00:05  loss: 0.7798 (0.8437)  time: 0.1938  data: 0.0001  max mem: 14938
[21:06:01.123674] Test:  [40/57]  eta: 0:00:03  loss: 0.7618 (0.8243)  time: 0.1945  data: 0.0001  max mem: 14938
[21:06:03.076378] Test:  [50/57]  eta: 0:00:01  loss: 0.7598 (0.8170)  time: 0.1950  data: 0.0001  max mem: 14938
[21:06:04.139078] Test:  [56/57]  eta: 0:00:00  loss: 0.7633 (0.8220)  time: 0.1897  data: 0.0001  max mem: 14938
[21:06:04.209563] Test: Total time: 0:00:11 (0.2000 s / it)
[21:06:07.205862] Dice score of the network on the train images: 0.731988, val images: 0.746449
[21:06:07.206094] saving best_prec_model_0 @ epoch 30
[21:06:08.297156] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:06:09.389741] Epoch: [31]  [  0/345]  eta: 0:06:16  lr: 0.000088  loss: 0.7176 (0.7176)  time: 1.0914  data: 0.3269  max mem: 14938
[21:06:24.587090] Epoch: [31]  [ 20/345]  eta: 0:04:12  lr: 0.000088  loss: 0.7292 (0.7362)  time: 0.7598  data: 0.0001  max mem: 14938
[21:06:39.723077] Epoch: [31]  [ 40/345]  eta: 0:03:53  lr: 0.000087  loss: 0.7289 (0.7340)  time: 0.7567  data: 0.0001  max mem: 14938
[21:06:54.905531] Epoch: [31]  [ 60/345]  eta: 0:03:37  lr: 0.000087  loss: 0.7338 (0.7346)  time: 0.7591  data: 0.0001  max mem: 14938
[21:07:10.104758] Epoch: [31]  [ 80/345]  eta: 0:03:22  lr: 0.000087  loss: 0.7433 (0.7369)  time: 0.7599  data: 0.0001  max mem: 14938
[21:07:25.325869] Epoch: [31]  [100/345]  eta: 0:03:06  lr: 0.000086  loss: 0.7367 (0.7372)  time: 0.7610  data: 0.0001  max mem: 14938
[21:07:40.534347] Epoch: [31]  [120/345]  eta: 0:02:51  lr: 0.000086  loss: 0.7523 (0.7405)  time: 0.7604  data: 0.0001  max mem: 14938
[21:07:55.747013] Epoch: [31]  [140/345]  eta: 0:02:36  lr: 0.000085  loss: 0.7372 (0.7409)  time: 0.7606  data: 0.0001  max mem: 14938
[21:08:10.942513] Epoch: [31]  [160/345]  eta: 0:02:20  lr: 0.000085  loss: 0.7449 (0.7410)  time: 0.7597  data: 0.0001  max mem: 14938
[21:08:26.136128] Epoch: [31]  [180/345]  eta: 0:02:05  lr: 0.000085  loss: 0.7446 (0.7409)  time: 0.7596  data: 0.0001  max mem: 14938
[21:08:41.329982] Epoch: [31]  [200/345]  eta: 0:01:50  lr: 0.000084  loss: 0.7418 (0.7408)  time: 0.7597  data: 0.0001  max mem: 14938
[21:08:56.527667] Epoch: [31]  [220/345]  eta: 0:01:35  lr: 0.000084  loss: 0.7305 (0.7401)  time: 0.7598  data: 0.0001  max mem: 14938
[21:09:11.722588] Epoch: [31]  [240/345]  eta: 0:01:19  lr: 0.000084  loss: 0.7263 (0.7393)  time: 0.7597  data: 0.0001  max mem: 14938
[21:09:26.917800] Epoch: [31]  [260/345]  eta: 0:01:04  lr: 0.000083  loss: 0.7351 (0.7394)  time: 0.7597  data: 0.0001  max mem: 14938
[21:09:42.111954] Epoch: [31]  [280/345]  eta: 0:00:49  lr: 0.000083  loss: 0.7343 (0.7393)  time: 0.7597  data: 0.0001  max mem: 14938
[21:09:57.295241] Epoch: [31]  [300/345]  eta: 0:00:34  lr: 0.000083  loss: 0.7353 (0.7392)  time: 0.7591  data: 0.0001  max mem: 14938
[21:10:12.478329] Epoch: [31]  [320/345]  eta: 0:00:19  lr: 0.000082  loss: 0.7283 (0.7386)  time: 0.7591  data: 0.0001  max mem: 14938
[21:10:27.659699] Epoch: [31]  [340/345]  eta: 0:00:03  lr: 0.000082  loss: 0.7231 (0.7381)  time: 0.7590  data: 0.0001  max mem: 14938
[21:10:30.693148] Epoch: [31]  [344/345]  eta: 0:00:00  lr: 0.000082  loss: 0.7245 (0.7380)  time: 0.7586  data: 0.0001  max mem: 14938
[21:10:30.760518] Epoch: [31] Total time: 0:04:22 (0.7608 s / it)
[21:10:30.760843] Averaged stats: lr: 0.000082  loss: 0.7245 (0.7380)
[21:10:31.312285] Test:  [  0/345]  eta: 0:03:08  loss: 0.7302 (0.7302)  time: 0.5459  data: 0.3471  max mem: 14938
[21:10:33.266769] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7005 (0.7024)  time: 0.2272  data: 0.0316  max mem: 14938
[21:10:35.228745] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7009 (0.7031)  time: 0.1957  data: 0.0001  max mem: 14938
[21:10:37.196935] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7033 (0.7052)  time: 0.1964  data: 0.0001  max mem: 14938
[21:10:39.168455] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7064 (0.7070)  time: 0.1969  data: 0.0001  max mem: 14938
[21:10:41.144956] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7087 (0.7068)  time: 0.1973  data: 0.0001  max mem: 14938
[21:10:43.129409] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7002 (0.7056)  time: 0.1980  data: 0.0001  max mem: 14938
[21:10:45.117108] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6987 (0.7059)  time: 0.1985  data: 0.0001  max mem: 14938
[21:10:47.111463] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7009 (0.7058)  time: 0.1990  data: 0.0001  max mem: 14938
[21:10:49.108031] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7093 (0.7062)  time: 0.1995  data: 0.0001  max mem: 14938
[21:10:51.105242] Test:  [100/345]  eta: 0:00:49  loss: 0.7109 (0.7068)  time: 0.1996  data: 0.0001  max mem: 14938
[21:10:53.108548] Test:  [110/345]  eta: 0:00:47  loss: 0.7067 (0.7067)  time: 0.2000  data: 0.0001  max mem: 14938
[21:10:55.119500] Test:  [120/345]  eta: 0:00:45  loss: 0.6974 (0.7060)  time: 0.2007  data: 0.0001  max mem: 14938
[21:10:57.137356] Test:  [130/345]  eta: 0:00:43  loss: 0.6993 (0.7060)  time: 0.2014  data: 0.0001  max mem: 14938
[21:10:59.160003] Test:  [140/345]  eta: 0:00:41  loss: 0.7078 (0.7064)  time: 0.2020  data: 0.0001  max mem: 14938
[21:11:01.187895] Test:  [150/345]  eta: 0:00:39  loss: 0.7101 (0.7067)  time: 0.2025  data: 0.0001  max mem: 14938
[21:11:03.217926] Test:  [160/345]  eta: 0:00:37  loss: 0.7101 (0.7070)  time: 0.2028  data: 0.0001  max mem: 14938
[21:11:05.257841] Test:  [170/345]  eta: 0:00:35  loss: 0.7089 (0.7072)  time: 0.2034  data: 0.0001  max mem: 14938
[21:11:07.298485] Test:  [180/345]  eta: 0:00:33  loss: 0.7113 (0.7076)  time: 0.2040  data: 0.0001  max mem: 14938
[21:11:09.346226] Test:  [190/345]  eta: 0:00:31  loss: 0.7085 (0.7074)  time: 0.2044  data: 0.0001  max mem: 14938
[21:11:11.401470] Test:  [200/345]  eta: 0:00:29  loss: 0.7062 (0.7075)  time: 0.2051  data: 0.0001  max mem: 14938

[21:11:13.459442] Test:  [210/345]  eta: 0:00:27  loss: 0.7058 (0.7074)  time: 0.2056  data: 0.0001  max mem: 14938
[21:11:15.521286] Test:  [220/345]  eta: 0:00:25  loss: 0.7023 (0.7073)  time: 0.2059  data: 0.0001  max mem: 14938
[21:11:17.591637] Test:  [230/345]  eta: 0:00:23  loss: 0.7012 (0.7073)  time: 0.2065  data: 0.0001  max mem: 14938
[21:11:19.664276] Test:  [240/345]  eta: 0:00:21  loss: 0.7070 (0.7073)  time: 0.2071  data: 0.0001  max mem: 14938
[21:11:21.743771] Test:  [250/345]  eta: 0:00:19  loss: 0.7074 (0.7073)  time: 0.2075  data: 0.0001  max mem: 14938
[21:11:23.829471] Test:  [260/345]  eta: 0:00:17  loss: 0.7058 (0.7073)  time: 0.2082  data: 0.0001  max mem: 14938
[21:11:25.917313] Test:  [270/345]  eta: 0:00:15  loss: 0.7022 (0.7075)  time: 0.2086  data: 0.0001  max mem: 14938
[21:11:28.011072] Test:  [280/345]  eta: 0:00:13  loss: 0.7058 (0.7075)  time: 0.2090  data: 0.0001  max mem: 14938
[21:11:30.109537] Test:  [290/345]  eta: 0:00:11  loss: 0.7060 (0.7075)  time: 0.2096  data: 0.0001  max mem: 14938
[21:11:32.214971] Test:  [300/345]  eta: 0:00:09  loss: 0.7057 (0.7075)  time: 0.2101  data: 0.0001  max mem: 14938
[21:11:34.325869] Test:  [310/345]  eta: 0:00:07  loss: 0.7000 (0.7073)  time: 0.2108  data: 0.0001  max mem: 14938
[21:11:36.441174] Test:  [320/345]  eta: 0:00:05  loss: 0.7038 (0.7074)  time: 0.2112  data: 0.0001  max mem: 14938
[21:11:38.561597] Test:  [330/345]  eta: 0:00:03  loss: 0.7073 (0.7074)  time: 0.2117  data: 0.0001  max mem: 14938
[21:11:40.684547] Test:  [340/345]  eta: 0:00:01  loss: 0.7109 (0.7075)  time: 0.2121  data: 0.0001  max mem: 14938
[21:11:41.535580] Test:  [344/345]  eta: 0:00:00  loss: 0.7116 (0.7075)  time: 0.2123  data: 0.0001  max mem: 14938
[21:11:41.594734] Test: Total time: 0:01:10 (0.2053 s / it)
[21:11:58.720678] Test:  [ 0/57]  eta: 0:00:31  loss: 0.8563 (0.8563)  time: 0.5449  data: 0.3495  max mem: 14938
[21:12:00.647874] Test:  [10/57]  eta: 0:00:10  loss: 0.8573 (0.8739)  time: 0.2247  data: 0.0319  max mem: 14938
[21:12:02.583305] Test:  [20/57]  eta: 0:00:07  loss: 0.8625 (0.8688)  time: 0.1931  data: 0.0001  max mem: 14938
[21:12:04.525581] Test:  [30/57]  eta: 0:00:05  loss: 0.7529 (0.8261)  time: 0.1938  data: 0.0001  max mem: 14938
[21:12:06.475870] Test:  [40/57]  eta: 0:00:03  loss: 0.7384 (0.8042)  time: 0.1946  data: 0.0001  max mem: 14938
[21:12:08.428861] Test:  [50/57]  eta: 0:00:01  loss: 0.7312 (0.7963)  time: 0.1951  data: 0.0001  max mem: 14938
[21:12:09.492230] Test:  [56/57]  eta: 0:00:00  loss: 0.7565 (0.8027)  time: 0.1898  data: 0.0001  max mem: 14938
[21:12:09.556728] Test: Total time: 0:00:11 (0.1997 s / it)
[21:12:12.554484] Dice score of the network on the train images: 0.721596, val images: 0.772012
[21:12:12.554711] saving best_dice_model_0 @ epoch 31
[21:12:13.671261] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:12:14.789385] Epoch: [32]  [  0/345]  eta: 0:06:25  lr: 0.000082  loss: 0.7242 (0.7242)  time: 1.1168  data: 0.3530  max mem: 14938
[21:12:29.846298] Epoch: [32]  [ 20/345]  eta: 0:04:10  lr: 0.000081  loss: 0.7251 (0.7273)  time: 0.7528  data: 0.0001  max mem: 14938
[21:12:45.090137] Epoch: [32]  [ 40/345]  eta: 0:03:53  lr: 0.000081  loss: 0.7290 (0.7295)  time: 0.7621  data: 0.0001  max mem: 14938
[21:13:00.264571] Epoch: [32]  [ 60/345]  eta: 0:03:37  lr: 0.000081  loss: 0.7289 (0.7293)  time: 0.7587  data: 0.0001  max mem: 14938
[21:13:15.463990] Epoch: [32]  [ 80/345]  eta: 0:03:22  lr: 0.000080  loss: 0.7227 (0.7290)  time: 0.7599  data: 0.0001  max mem: 14938
[21:13:30.670765] Epoch: [32]  [100/345]  eta: 0:03:06  lr: 0.000080  loss: 0.7276 (0.7286)  time: 0.7603  data: 0.0001  max mem: 14938
[21:13:45.878555] Epoch: [32]  [120/345]  eta: 0:02:51  lr: 0.000080  loss: 0.7256 (0.7285)  time: 0.7603  data: 0.0001  max mem: 14938
[21:14:01.084673] Epoch: [32]  [140/345]  eta: 0:02:36  lr: 0.000079  loss: 0.7255 (0.7282)  time: 0.7603  data: 0.0001  max mem: 14938
[21:14:16.280908] Epoch: [32]  [160/345]  eta: 0:02:20  lr: 0.000079  loss: 0.7359 (0.7296)  time: 0.7598  data: 0.0001  max mem: 14938
[21:14:31.473548] Epoch: [32]  [180/345]  eta: 0:02:05  lr: 0.000079  loss: 0.7293 (0.7296)  time: 0.7596  data: 0.0001  max mem: 14938
[21:14:46.651121] Epoch: [32]  [200/345]  eta: 0:01:50  lr: 0.000078  loss: 0.7274 (0.7296)  time: 0.7588  data: 0.0001  max mem: 14938
[21:15:01.826673] Epoch: [32]  [220/345]  eta: 0:01:35  lr: 0.000078  loss: 0.7276 (0.7295)  time: 0.7587  data: 0.0001  max mem: 14938
[21:15:17.003678] Epoch: [32]  [240/345]  eta: 0:01:19  lr: 0.000077  loss: 0.7375 (0.7304)  time: 0.7588  data: 0.0001  max mem: 14938
[21:15:32.166161] Epoch: [32]  [260/345]  eta: 0:01:04  lr: 0.000077  loss: 0.7350 (0.7311)  time: 0.7581  data: 0.0001  max mem: 14938
[21:15:47.328921] Epoch: [32]  [280/345]  eta: 0:00:49  lr: 0.000077  loss: 0.7307 (0.7313)  time: 0.7581  data: 0.0001  max mem: 14938
[21:16:02.498439] Epoch: [32]  [300/345]  eta: 0:00:34  lr: 0.000076  loss: 0.7365 (0.7319)  time: 0.7584  data: 0.0001  max mem: 14938
[21:16:17.662573] Epoch: [32]  [320/345]  eta: 0:00:19  lr: 0.000076  loss: 0.7358 (0.7323)  time: 0.7582  data: 0.0001  max mem: 14938
[21:16:32.854780] Epoch: [32]  [340/345]  eta: 0:00:03  lr: 0.000076  loss: 0.7278 (0.7324)  time: 0.7596  data: 0.0001  max mem: 14938
[21:16:35.895038] Epoch: [32]  [344/345]  eta: 0:00:00  lr: 0.000076  loss: 0.7326 (0.7324)  time: 0.7595  data: 0.0001  max mem: 14938
[21:16:35.966207] Epoch: [32] Total time: 0:04:22 (0.7603 s / it)
[21:16:35.966474] Averaged stats: lr: 0.000076  loss: 0.7326 (0.7324)
[21:16:36.536260] Test:  [  0/345]  eta: 0:03:14  loss: 0.7038 (0.7038)  time: 0.5630  data: 0.3647  max mem: 14938
[21:16:38.491417] Test:  [ 10/345]  eta: 0:01:16  loss: 0.6999 (0.7000)  time: 0.2288  data: 0.0332  max mem: 14938
[21:16:40.454092] Test:  [ 20/345]  eta: 0:01:09  loss: 0.7027 (0.7058)  time: 0.1958  data: 0.0001  max mem: 14938
[21:16:42.422356] Test:  [ 30/345]  eta: 0:01:05  loss: 0.7036 (0.7060)  time: 0.1965  data: 0.0001  max mem: 14938
[21:16:44.394994] Test:  [ 40/345]  eta: 0:01:02  loss: 0.7036 (0.7051)  time: 0.1970  data: 0.0001  max mem: 14938
[21:16:46.372062] Test:  [ 50/345]  eta: 0:01:00  loss: 0.7043 (0.7059)  time: 0.1974  data: 0.0001  max mem: 14938
[21:16:48.355483] Test:  [ 60/345]  eta: 0:00:57  loss: 0.7053 (0.7059)  time: 0.1980  data: 0.0001  max mem: 14938
[21:16:50.342610] Test:  [ 70/345]  eta: 0:00:55  loss: 0.7101 (0.7067)  time: 0.1985  data: 0.0001  max mem: 14938
[21:16:52.337542] Test:  [ 80/345]  eta: 0:00:53  loss: 0.7106 (0.7069)  time: 0.1990  data: 0.0001  max mem: 14938
[21:16:54.336283] Test:  [ 90/345]  eta: 0:00:51  loss: 0.7086 (0.7076)  time: 0.1996  data: 0.0001  max mem: 14938
[21:16:56.339847] Test:  [100/345]  eta: 0:00:49  loss: 0.7096 (0.7076)  time: 0.2001  data: 0.0001  max mem: 14938
[21:16:58.346377] Test:  [110/345]  eta: 0:00:47  loss: 0.7095 (0.7077)  time: 0.2004  data: 0.0001  max mem: 14938
[21:17:00.355814] Test:  [120/345]  eta: 0:00:45  loss: 0.7037 (0.7074)  time: 0.2007  data: 0.0001  max mem: 14938
[21:17:02.371851] Test:  [130/345]  eta: 0:00:43  loss: 0.6993 (0.7067)  time: 0.2012  data: 0.0001  max mem: 14938
[21:17:04.392660] Test:  [140/345]  eta: 0:00:41  loss: 0.7007 (0.7069)  time: 0.2018  data: 0.0001  max mem: 14938
[21:17:06.419942] Test:  [150/345]  eta: 0:00:39  loss: 0.7052 (0.7069)  time: 0.2023  data: 0.0001  max mem: 14938
[21:17:08.453313] Test:  [160/345]  eta: 0:00:37  loss: 0.7061 (0.7070)  time: 0.2030  data: 0.0001  max mem: 14938
[21:17:10.489863] Test:  [170/345]  eta: 0:00:35  loss: 0.7082 (0.7073)  time: 0.2034  data: 0.0001  max mem: 14938
[21:17:12.533036] Test:  [180/345]  eta: 0:00:33  loss: 0.7069 (0.7072)  time: 0.2039  data: 0.0001  max mem: 14938
[21:17:14.578934] Test:  [190/345]  eta: 0:00:31  loss: 0.7028 (0.7073)  time: 0.2044  data: 0.0001  max mem: 14938
[21:17:16.631390] Test:  [200/345]  eta: 0:00:29  loss: 0.7043 (0.7072)  time: 0.2049  data: 0.0001  max mem: 14938
[21:17:18.689293] Test:  [210/345]  eta: 0:00:27  loss: 0.7049 (0.7072)  time: 0.2055  data: 0.0001  max mem: 14938
[21:17:20.751670] Test:  [220/345]  eta: 0:00:25  loss: 0.7120 (0.7075)  time: 0.2060  data: 0.0001  max mem: 14938
[21:17:22.821234] Test:  [230/345]  eta: 0:00:23  loss: 0.7099 (0.7076)  time: 0.2065  data: 0.0001  max mem: 14938
[21:17:24.895038] Test:  [240/345]  eta: 0:00:21  loss: 0.7088 (0.7076)  time: 0.2071  data: 0.0001  max mem: 14938
[21:17:26.975621] Test:  [250/345]  eta: 0:00:19  loss: 0.7073 (0.7074)  time: 0.2076  data: 0.0001  max mem: 14938
[21:17:29.059150] Test:  [260/345]  eta: 0:00:17  loss: 0.7076 (0.7075)  time: 0.2081  data: 0.0001  max mem: 14938
[21:17:31.148375] Test:  [270/345]  eta: 0:00:15  loss: 0.7060 (0.7074)  time: 0.2086  data: 0.0001  max mem: 14938
[21:17:33.242230] Test:  [280/345]  eta: 0:00:13  loss: 0.7041 (0.7073)  time: 0.2091  data: 0.0001  max mem: 14938
[21:17:35.341892] Test:  [290/345]  eta: 0:00:11  loss: 0.7067 (0.7074)  time: 0.2096  data: 0.0001  max mem: 14938
[21:17:37.446380] Test:  [300/345]  eta: 0:00:09  loss: 0.7119 (0.7074)  time: 0.2101  data: 0.0001  max mem: 14938
[21:17:39.556915] Test:  [310/345]  eta: 0:00:07  loss: 0.7017 (0.7073)  time: 0.2107  data: 0.0001  max mem: 14938
[21:17:41.672401] Test:  [320/345]  eta: 0:00:05  loss: 0.7025 (0.7073)  time: 0.2112  data: 0.0001  max mem: 14938
[21:17:43.794086] Test:  [330/345]  eta: 0:00:03  loss: 0.7074 (0.7075)  time: 0.2118  data: 0.0001  max mem: 14938
[21:17:45.918343] Test:  [340/345]  eta: 0:00:01  loss: 0.7123 (0.7074)  time: 0.2122  data: 0.0001  max mem: 14938
[21:17:46.770129] Test:  [344/345]  eta: 0:00:00  loss: 0.7013 (0.7075)  time: 0.2124  data: 0.0001  max mem: 14938
[21:17:46.835772] Test: Total time: 0:01:10 (0.2054 s / it)
[21:18:03.777708] Test:  [ 0/57]  eta: 0:00:29  loss: 0.8769 (0.8769)  time: 0.5185  data: 0.3219  max mem: 14938
[21:18:05.704823] Test:  [10/57]  eta: 0:00:10  loss: 0.8769 (0.8815)  time: 0.2222  data: 0.0293  max mem: 14938
[21:18:07.643031] Test:  [20/57]  eta: 0:00:07  loss: 0.8712 (0.8677)  time: 0.1932  data: 0.0001  max mem: 14938
[21:18:09.586414] Test:  [30/57]  eta: 0:00:05  loss: 0.7506 (0.8244)  time: 0.1940  data: 0.0001  max mem: 14938
[21:18:11.538056] Test:  [40/57]  eta: 0:00:03  loss: 0.7369 (0.8030)  time: 0.1947  data: 0.0001  max mem: 14938
[21:18:13.493778] Test:  [50/57]  eta: 0:00:01  loss: 0.7311 (0.7958)  time: 0.1953  data: 0.0001  max mem: 14938
[21:18:14.557218] Test:  [56/57]  eta: 0:00:00  loss: 0.7568 (0.8025)  time: 0.1900  data: 0.0000  max mem: 14938
[21:18:14.616891] Test: Total time: 0:00:11 (0.1993 s / it)
[21:18:17.604738] Dice score of the network on the train images: 0.721123, val images: 0.768982
[21:18:17.609724] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:18:18.733252] Epoch: [33]  [  0/345]  eta: 0:06:27  lr: 0.000075  loss: 0.7264 (0.7264)  time: 1.1224  data: 0.3588  max mem: 14938
[21:18:33.800090] Epoch: [33]  [ 20/345]  eta: 0:04:10  lr: 0.000075  loss: 0.7331 (0.7323)  time: 0.7533  data: 0.0001  max mem: 14938
[21:18:48.924453] Epoch: [33]  [ 40/345]  eta: 0:03:52  lr: 0.000075  loss: 0.7248 (0.7301)  time: 0.7562  data: 0.0001  max mem: 14938
[21:19:04.092534] Epoch: [33]  [ 60/345]  eta: 0:03:37  lr: 0.000074  loss: 0.7236 (0.7282)  time: 0.7584  data: 0.0001  max mem: 14938
[21:19:19.289651] Epoch: [33]  [ 80/345]  eta: 0:03:21  lr: 0.000074  loss: 0.7273 (0.7283)  time: 0.7598  data: 0.0001  max mem: 14938
[21:19:34.502857] Epoch: [33]  [100/345]  eta: 0:03:06  lr: 0.000074  loss: 0.7295 (0.7287)  time: 0.7606  data: 0.0001  max mem: 14938
[21:19:49.717178] Epoch: [33]  [120/345]  eta: 0:02:51  lr: 0.000073  loss: 0.7263 (0.7288)  time: 0.7607  data: 0.0001  max mem: 14938
[21:20:04.911839] Epoch: [33]  [140/345]  eta: 0:02:35  lr: 0.000073  loss: 0.7311 (0.7291)  time: 0.7597  data: 0.0001  max mem: 14938

[21:20:20.107041] Epoch: [33]  [160/345]  eta: 0:02:20  lr: 0.000073  loss: 0.7364 (0.7299)  time: 0.7597  data: 0.0001  max mem: 14938
[21:20:35.301965] Epoch: [33]  [180/345]  eta: 0:02:05  lr: 0.000072  loss: 0.7223 (0.7293)  time: 0.7597  data: 0.0001  max mem: 14938
[21:20:50.499642] Epoch: [33]  [200/345]  eta: 0:01:50  lr: 0.000072  loss: 0.7265 (0.7293)  time: 0.7598  data: 0.0001  max mem: 14938
[21:21:05.693856] Epoch: [33]  [220/345]  eta: 0:01:35  lr: 0.000071  loss: 0.7288 (0.7294)  time: 0.7597  data: 0.0001  max mem: 14938
[21:21:20.884338] Epoch: [33]  [240/345]  eta: 0:01:19  lr: 0.000071  loss: 0.7301 (0.7294)  time: 0.7595  data: 0.0001  max mem: 14938
[21:21:36.078795] Epoch: [33]  [260/345]  eta: 0:01:04  lr: 0.000071  loss: 0.7203 (0.7289)  time: 0.7597  data: 0.0001  max mem: 14938
[21:21:51.274722] Epoch: [33]  [280/345]  eta: 0:00:49  lr: 0.000070  loss: 0.7241 (0.7286)  time: 0.7598  data: 0.0001  max mem: 14938
[21:22:06.549262] Epoch: [33]  [300/345]  eta: 0:00:34  lr: 0.000070  loss: 0.7214 (0.7283)  time: 0.7637  data: 0.0001  max mem: 14938
[21:22:21.743510] Epoch: [33]  [320/345]  eta: 0:00:19  lr: 0.000070  loss: 0.7210 (0.7278)  time: 0.7597  data: 0.0001  max mem: 14938
[21:22:36.931950] Epoch: [33]  [340/345]  eta: 0:00:03  lr: 0.000069  loss: 0.7239 (0.7275)  time: 0.7594  data: 0.0001  max mem: 14938
[21:22:39.967571] Epoch: [33]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.7202 (0.7275)  time: 0.7592  data: 0.0001  max mem: 14938
[21:22:40.031602] Epoch: [33] Total time: 0:04:22 (0.7606 s / it)
[21:22:40.031828] Averaged stats: lr: 0.000069  loss: 0.7202 (0.7275)
[21:22:40.657745] Test:  [  0/345]  eta: 0:03:34  loss: 0.6975 (0.6975)  time: 0.6207  data: 0.4248  max mem: 14938
[21:22:42.613640] Test:  [ 10/345]  eta: 0:01:18  loss: 0.6975 (0.6976)  time: 0.2342  data: 0.0387  max mem: 14938
[21:22:44.577039] Test:  [ 20/345]  eta: 0:01:10  loss: 0.6979 (0.7009)  time: 0.1959  data: 0.0001  max mem: 14938
[21:22:46.542941] Test:  [ 30/345]  eta: 0:01:06  loss: 0.6955 (0.6992)  time: 0.1964  data: 0.0001  max mem: 14938
[21:22:48.516554] Test:  [ 40/345]  eta: 0:01:03  loss: 0.6955 (0.6990)  time: 0.1969  data: 0.0001  max mem: 14938
[21:22:50.494390] Test:  [ 50/345]  eta: 0:01:00  loss: 0.6977 (0.6992)  time: 0.1975  data: 0.0001  max mem: 14938
[21:22:52.478063] Test:  [ 60/345]  eta: 0:00:58  loss: 0.6975 (0.6988)  time: 0.1980  data: 0.0001  max mem: 14938
[21:22:54.463695] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6975 (0.6987)  time: 0.1984  data: 0.0001  max mem: 14938
[21:22:56.456398] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6959 (0.6987)  time: 0.1989  data: 0.0001  max mem: 14938
[21:22:58.451318] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6940 (0.6990)  time: 0.1993  data: 0.0001  max mem: 14938
[21:23:00.452646] Test:  [100/345]  eta: 0:00:49  loss: 0.6977 (0.6987)  time: 0.1997  data: 0.0001  max mem: 14938
[21:23:02.458691] Test:  [110/345]  eta: 0:00:47  loss: 0.6989 (0.6990)  time: 0.2003  data: 0.0001  max mem: 14938
[21:23:04.470618] Test:  [120/345]  eta: 0:00:45  loss: 0.6996 (0.6988)  time: 0.2008  data: 0.0001  max mem: 14938
[21:23:06.488725] Test:  [130/345]  eta: 0:00:43  loss: 0.6966 (0.6986)  time: 0.2014  data: 0.0001  max mem: 14938
[21:23:08.511802] Test:  [140/345]  eta: 0:00:41  loss: 0.6934 (0.6985)  time: 0.2020  data: 0.0001  max mem: 14938
[21:23:10.544516] Test:  [150/345]  eta: 0:00:39  loss: 0.7015 (0.6994)  time: 0.2027  data: 0.0001  max mem: 14938
[21:23:12.576124] Test:  [160/345]  eta: 0:00:37  loss: 0.6971 (0.6993)  time: 0.2032  data: 0.0001  max mem: 14938
[21:23:14.613405] Test:  [170/345]  eta: 0:00:35  loss: 0.6954 (0.6992)  time: 0.2034  data: 0.0001  max mem: 14938
[21:23:16.658217] Test:  [180/345]  eta: 0:00:33  loss: 0.6943 (0.6991)  time: 0.2040  data: 0.0001  max mem: 14938
[21:23:18.706501] Test:  [190/345]  eta: 0:00:31  loss: 0.6946 (0.6991)  time: 0.2046  data: 0.0001  max mem: 14938
[21:23:20.761975] Test:  [200/345]  eta: 0:00:29  loss: 0.6961 (0.6991)  time: 0.2051  data: 0.0001  max mem: 14938
[21:23:22.821363] Test:  [210/345]  eta: 0:00:27  loss: 0.7040 (0.6995)  time: 0.2057  data: 0.0001  max mem: 14938
[21:23:24.884287] Test:  [220/345]  eta: 0:00:25  loss: 0.6971 (0.6993)  time: 0.2061  data: 0.0001  max mem: 14938
[21:23:26.953468] Test:  [230/345]  eta: 0:00:23  loss: 0.6941 (0.6990)  time: 0.2065  data: 0.0001  max mem: 14938
[21:23:29.026994] Test:  [240/345]  eta: 0:00:21  loss: 0.6962 (0.6991)  time: 0.2071  data: 0.0001  max mem: 14938
[21:23:31.105546] Test:  [250/345]  eta: 0:00:19  loss: 0.6996 (0.6993)  time: 0.2075  data: 0.0001  max mem: 14938
[21:23:33.188915] Test:  [260/345]  eta: 0:00:17  loss: 0.7019 (0.6994)  time: 0.2080  data: 0.0001  max mem: 14938
[21:23:35.282058] Test:  [270/345]  eta: 0:00:15  loss: 0.7020 (0.6995)  time: 0.2088  data: 0.0001  max mem: 14938
[21:23:37.376511] Test:  [280/345]  eta: 0:00:13  loss: 0.7020 (0.6997)  time: 0.2093  data: 0.0001  max mem: 14938
[21:23:39.476434] Test:  [290/345]  eta: 0:00:11  loss: 0.6974 (0.6997)  time: 0.2097  data: 0.0001  max mem: 14938
[21:23:41.583571] Test:  [300/345]  eta: 0:00:09  loss: 0.6961 (0.6997)  time: 0.2103  data: 0.0001  max mem: 14938
[21:23:43.695140] Test:  [310/345]  eta: 0:00:07  loss: 0.6971 (0.6997)  time: 0.2109  data: 0.0001  max mem: 14938
[21:23:45.815265] Test:  [320/345]  eta: 0:00:05  loss: 0.6971 (0.6998)  time: 0.2115  data: 0.0001  max mem: 14938
[21:23:47.938371] Test:  [330/345]  eta: 0:00:03  loss: 0.6937 (0.6997)  time: 0.2121  data: 0.0001  max mem: 14938
[21:23:50.063079] Test:  [340/345]  eta: 0:00:01  loss: 0.6956 (0.6998)  time: 0.2123  data: 0.0001  max mem: 14938
[21:23:50.914772] Test:  [344/345]  eta: 0:00:00  loss: 0.6970 (0.6998)  time: 0.2124  data: 0.0001  max mem: 14938
[21:23:50.976573] Test: Total time: 0:01:10 (0.2056 s / it)
[21:24:08.083944] Test:  [ 0/57]  eta: 0:00:32  loss: 0.8477 (0.8477)  time: 0.5666  data: 0.3710  max mem: 14938
[21:24:10.008939] Test:  [10/57]  eta: 0:00:10  loss: 0.8652 (0.8788)  time: 0.2264  data: 0.0338  max mem: 14938
[21:24:11.945917] Test:  [20/57]  eta: 0:00:07  loss: 0.8652 (0.8664)  time: 0.1930  data: 0.0001  max mem: 14938
[21:24:13.886751] Test:  [30/57]  eta: 0:00:05  loss: 0.7554 (0.8254)  time: 0.1938  data: 0.0001  max mem: 14938
[21:24:15.837633] Test:  [40/57]  eta: 0:00:03  loss: 0.7471 (0.8056)  time: 0.1945  data: 0.0001  max mem: 14938
[21:24:17.789516] Test:  [50/57]  eta: 0:00:01  loss: 0.7392 (0.7983)  time: 0.1951  data: 0.0001  max mem: 14938
[21:24:18.852953] Test:  [56/57]  eta: 0:00:00  loss: 0.7515 (0.8046)  time: 0.1898  data: 0.0001  max mem: 14938
[21:24:18.912984] Test: Total time: 0:00:11 (0.1999 s / it)
[21:24:21.884318] Dice score of the network on the train images: 0.733180, val images: 0.761499
[21:24:21.888485] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:24:23.003768] Epoch: [34]  [  0/345]  eta: 0:06:24  lr: 0.000069  loss: 0.7110 (0.7110)  time: 1.1146  data: 0.3544  max mem: 14938
[21:24:38.076230] Epoch: [34]  [ 20/345]  eta: 0:04:10  lr: 0.000069  loss: 0.7163 (0.7220)  time: 0.7536  data: 0.0001  max mem: 14938
[21:24:53.210537] Epoch: [34]  [ 40/345]  eta: 0:03:52  lr: 0.000068  loss: 0.7223 (0.7231)  time: 0.7567  data: 0.0001  max mem: 14938
[21:25:08.390750] Epoch: [34]  [ 60/345]  eta: 0:03:37  lr: 0.000068  loss: 0.7209 (0.7222)  time: 0.7590  data: 0.0001  max mem: 14938
[21:25:23.590125] Epoch: [34]  [ 80/345]  eta: 0:03:21  lr: 0.000068  loss: 0.7224 (0.7222)  time: 0.7599  data: 0.0001  max mem: 14938
[21:25:38.806508] Epoch: [34]  [100/345]  eta: 0:03:06  lr: 0.000067  loss: 0.7268 (0.7233)  time: 0.7608  data: 0.0001  max mem: 14938
[21:25:54.005037] Epoch: [34]  [120/345]  eta: 0:02:51  lr: 0.000067  loss: 0.7163 (0.7227)  time: 0.7599  data: 0.0001  max mem: 14938
[21:26:09.212915] Epoch: [34]  [140/345]  eta: 0:02:36  lr: 0.000066  loss: 0.7149 (0.7220)  time: 0.7604  data: 0.0001  max mem: 14938
[21:26:24.427507] Epoch: [34]  [160/345]  eta: 0:02:20  lr: 0.000066  loss: 0.7260 (0.7223)  time: 0.7607  data: 0.0001  max mem: 14938
[21:26:39.625580] Epoch: [34]  [180/345]  eta: 0:02:05  lr: 0.000066  loss: 0.7184 (0.7219)  time: 0.7599  data: 0.0001  max mem: 14938
[21:26:54.952803] Epoch: [34]  [200/345]  eta: 0:01:50  lr: 0.000065  loss: 0.7243 (0.7223)  time: 0.7663  data: 0.0001  max mem: 14938
[21:27:10.150818] Epoch: [34]  [220/345]  eta: 0:01:35  lr: 0.000065  loss: 0.7177 (0.7222)  time: 0.7599  data: 0.0001  max mem: 14938
[21:27:25.345847] Epoch: [34]  [240/345]  eta: 0:01:19  lr: 0.000064  loss: 0.7154 (0.7220)  time: 0.7597  data: 0.0001  max mem: 14938
[21:27:40.538482] Epoch: [34]  [260/345]  eta: 0:01:04  lr: 0.000064  loss: 0.7175 (0.7223)  time: 0.7596  data: 0.0001  max mem: 14938
[21:27:55.717694] Epoch: [34]  [280/345]  eta: 0:00:49  lr: 0.000064  loss: 0.7198 (0.7223)  time: 0.7589  data: 0.0001  max mem: 14938
[21:28:10.912603] Epoch: [34]  [300/345]  eta: 0:00:34  lr: 0.000063  loss: 0.7195 (0.7222)  time: 0.7597  data: 0.0001  max mem: 14938
[21:28:26.102338] Epoch: [34]  [320/345]  eta: 0:00:19  lr: 0.000063  loss: 0.7185 (0.7220)  time: 0.7594  data: 0.0001  max mem: 14938
[21:28:41.278666] Epoch: [34]  [340/345]  eta: 0:00:03  lr: 0.000063  loss: 0.7203 (0.7220)  time: 0.7588  data: 0.0001  max mem: 14938
[21:28:44.316818] Epoch: [34]  [344/345]  eta: 0:00:00  lr: 0.000063  loss: 0.7196 (0.7221)  time: 0.7589  data: 0.0001  max mem: 14938
[21:28:44.387507] Epoch: [34] Total time: 0:04:22 (0.7609 s / it)
[21:28:44.387884] Averaged stats: lr: 0.000063  loss: 0.7196 (0.7221)
[21:28:44.935995] Test:  [  0/345]  eta: 0:03:07  loss: 0.7113 (0.7113)  time: 0.5432  data: 0.3450  max mem: 14938
[21:28:46.890883] Test:  [ 10/345]  eta: 0:01:16  loss: 0.6918 (0.6946)  time: 0.2270  data: 0.0314  max mem: 14938
[21:28:48.853602] Test:  [ 20/345]  eta: 0:01:09  loss: 0.6926 (0.6950)  time: 0.1958  data: 0.0001  max mem: 14938
[21:28:50.819629] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6956 (0.6959)  time: 0.1964  data: 0.0001  max mem: 14938
[21:28:52.791566] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6977 (0.6966)  time: 0.1968  data: 0.0001  max mem: 14938
[21:28:54.769025] Test:  [ 50/345]  eta: 0:00:59  loss: 0.6977 (0.6967)  time: 0.1974  data: 0.0001  max mem: 14938
[21:28:56.754911] Test:  [ 60/345]  eta: 0:00:57  loss: 0.6972 (0.6973)  time: 0.1981  data: 0.0001  max mem: 14938
[21:28:58.742091] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6981 (0.6971)  time: 0.1986  data: 0.0001  max mem: 14938
[21:29:00.733871] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6990 (0.6976)  time: 0.1989  data: 0.0001  max mem: 14938
[21:29:02.727523] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6969 (0.6977)  time: 0.1992  data: 0.0001  max mem: 14938
[21:29:04.728456] Test:  [100/345]  eta: 0:00:49  loss: 0.6988 (0.6979)  time: 0.1997  data: 0.0001  max mem: 14938
[21:29:06.733959] Test:  [110/345]  eta: 0:00:47  loss: 0.6985 (0.6976)  time: 0.2003  data: 0.0001  max mem: 14938
[21:29:08.747781] Test:  [120/345]  eta: 0:00:45  loss: 0.6962 (0.6978)  time: 0.2009  data: 0.0001  max mem: 14938
[21:29:10.764365] Test:  [130/345]  eta: 0:00:43  loss: 0.6967 (0.6975)  time: 0.2015  data: 0.0001  max mem: 14938
[21:29:12.788821] Test:  [140/345]  eta: 0:00:41  loss: 0.6968 (0.6974)  time: 0.2020  data: 0.0001  max mem: 14938
[21:29:14.816376] Test:  [150/345]  eta: 0:00:39  loss: 0.6946 (0.6974)  time: 0.2025  data: 0.0001  max mem: 14938
[21:29:16.848363] Test:  [160/345]  eta: 0:00:37  loss: 0.6919 (0.6968)  time: 0.2029  data: 0.0001  max mem: 14938
[21:29:18.885106] Test:  [170/345]  eta: 0:00:35  loss: 0.6934 (0.6971)  time: 0.2034  data: 0.0001  max mem: 14938
[21:29:20.928661] Test:  [180/345]  eta: 0:00:33  loss: 0.6986 (0.6969)  time: 0.2039  data: 0.0001  max mem: 14938
[21:29:22.977897] Test:  [190/345]  eta: 0:00:31  loss: 0.6946 (0.6971)  time: 0.2045  data: 0.0001  max mem: 14938
[21:29:25.029979] Test:  [200/345]  eta: 0:00:29  loss: 0.6944 (0.6968)  time: 0.2050  data: 0.0001  max mem: 14938
[21:29:27.086352] Test:  [210/345]  eta: 0:00:27  loss: 0.6958 (0.6968)  time: 0.2054  data: 0.0001  max mem: 14938
[21:29:29.150242] Test:  [220/345]  eta: 0:00:25  loss: 0.6938 (0.6966)  time: 0.2060  data: 0.0001  max mem: 14938
[21:29:31.220301] Test:  [230/345]  eta: 0:00:23  loss: 0.6893 (0.6967)  time: 0.2066  data: 0.0001  max mem: 14938
[21:29:33.292880] Test:  [240/345]  eta: 0:00:21  loss: 0.6956 (0.6968)  time: 0.2071  data: 0.0001  max mem: 14938
[21:29:35.370720] Test:  [250/345]  eta: 0:00:19  loss: 0.6912 (0.6967)  time: 0.2075  data: 0.0001  max mem: 14938
[21:29:37.454764] Test:  [260/345]  eta: 0:00:17  loss: 0.6898 (0.6967)  time: 0.2080  data: 0.0001  max mem: 14938
[21:29:39.543695] Test:  [270/345]  eta: 0:00:15  loss: 0.6954 (0.6967)  time: 0.2086  data: 0.0001  max mem: 14938
[21:29:41.637982] Test:  [280/345]  eta: 0:00:13  loss: 0.6921 (0.6964)  time: 0.2091  data: 0.0001  max mem: 14938
[21:29:43.736685] Test:  [290/345]  eta: 0:00:11  loss: 0.6928 (0.6962)  time: 0.2096  data: 0.0001  max mem: 14938
[21:29:45.841630] Test:  [300/345]  eta: 0:00:09  loss: 0.6928 (0.6961)  time: 0.2101  data: 0.0001  max mem: 14938
[21:29:47.951215] Test:  [310/345]  eta: 0:00:07  loss: 0.6889 (0.6961)  time: 0.2107  data: 0.0001  max mem: 14938
[21:29:50.065218] Test:  [320/345]  eta: 0:00:05  loss: 0.6889 (0.6960)  time: 0.2111  data: 0.0001  max mem: 14938
[21:29:52.185979] Test:  [330/345]  eta: 0:00:03  loss: 0.6959 (0.6960)  time: 0.2117  data: 0.0001  max mem: 14938
[21:29:54.311810] Test:  [340/345]  eta: 0:00:01  loss: 0.6971 (0.6960)  time: 0.2123  data: 0.0001  max mem: 14938
[21:29:55.162923] Test:  [344/345]  eta: 0:00:00  loss: 0.6968 (0.6960)  time: 0.2124  data: 0.0001  max mem: 14938
[21:29:55.225920] Test: Total time: 0:01:10 (0.2053 s / it)
[21:30:12.150615] Test:  [ 0/57]  eta: 0:00:30  loss: 0.8361 (0.8361)  time: 0.5393  data: 0.3422  max mem: 14938
[21:30:14.077205] Test:  [10/57]  eta: 0:00:10  loss: 0.8670 (0.8737)  time: 0.2241  data: 0.0312  max mem: 14938
[21:30:16.012947] Test:  [20/57]  eta: 0:00:07  loss: 0.8670 (0.8603)  time: 0.1930  data: 0.0001  max mem: 14938
[21:30:17.954127] Test:  [30/57]  eta: 0:00:05  loss: 0.7500 (0.8189)  time: 0.1938  data: 0.0001  max mem: 14938
[21:30:19.904797] Test:  [40/57]  eta: 0:00:03  loss: 0.7386 (0.7991)  time: 0.1945  data: 0.0001  max mem: 14938
[21:30:21.859824] Test:  [50/57]  eta: 0:00:01  loss: 0.7294 (0.7914)  time: 0.1952  data: 0.0001  max mem: 14938
[21:30:22.923047] Test:  [56/57]  eta: 0:00:00  loss: 0.7531 (0.7977)  time: 0.1899  data: 0.0001  max mem: 14938
[21:30:22.986900] Test: Total time: 0:00:11 (0.1996 s / it)
[21:30:25.923950] Dice score of the network on the train images: 0.725923, val images: 0.770009
[21:30:25.928296] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:30:27.047376] Epoch: [35]  [  0/345]  eta: 0:06:25  lr: 0.000063  loss: 0.7389 (0.7389)  time: 1.1180  data: 0.3551  max mem: 14938
[21:30:42.113878] Epoch: [35]  [ 20/345]  eta: 0:04:10  lr: 0.000062  loss: 0.7135 (0.7162)  time: 0.7533  data: 0.0001  max mem: 14938
[21:30:57.224848] Epoch: [35]  [ 40/345]  eta: 0:03:52  lr: 0.000062  loss: 0.7175 (0.7186)  time: 0.7555  data: 0.0001  max mem: 14938
[21:31:12.377712] Epoch: [35]  [ 60/345]  eta: 0:03:36  lr: 0.000061  loss: 0.7168 (0.7190)  time: 0.7576  data: 0.0001  max mem: 14938
[21:31:27.567934] Epoch: [35]  [ 80/345]  eta: 0:03:21  lr: 0.000061  loss: 0.7206 (0.7191)  time: 0.7595  data: 0.0001  max mem: 14938
[21:31:42.765026] Epoch: [35]  [100/345]  eta: 0:03:06  lr: 0.000061  loss: 0.7176 (0.7191)  time: 0.7598  data: 0.0001  max mem: 14938
[21:31:57.961352] Epoch: [35]  [120/345]  eta: 0:02:51  lr: 0.000060  loss: 0.7221 (0.7197)  time: 0.7598  data: 0.0001  max mem: 14938
[21:32:13.176373] Epoch: [35]  [140/345]  eta: 0:02:35  lr: 0.000060  loss: 0.7185 (0.7204)  time: 0.7607  data: 0.0001  max mem: 14938
[21:32:28.387396] Epoch: [35]  [160/345]  eta: 0:02:20  lr: 0.000059  loss: 0.7164 (0.7202)  time: 0.7605  data: 0.0001  max mem: 14938
[21:32:43.590045] Epoch: [35]  [180/345]  eta: 0:02:05  lr: 0.000059  loss: 0.7176 (0.7205)  time: 0.7601  data: 0.0001  max mem: 14938
[21:32:58.801146] Epoch: [35]  [200/345]  eta: 0:01:50  lr: 0.000059  loss: 0.7183 (0.7204)  time: 0.7605  data: 0.0001  max mem: 14938
[21:33:14.005663] Epoch: [35]  [220/345]  eta: 0:01:35  lr: 0.000058  loss: 0.7186 (0.7201)  time: 0.7602  data: 0.0001  max mem: 14938
[21:33:29.209028] Epoch: [35]  [240/345]  eta: 0:01:19  lr: 0.000058  loss: 0.7194 (0.7202)  time: 0.7601  data: 0.0001  max mem: 14938
[21:33:44.406622] Epoch: [35]  [260/345]  eta: 0:01:04  lr: 0.000058  loss: 0.7171 (0.7201)  time: 0.7598  data: 0.0001  max mem: 14938
[21:33:59.598307] Epoch: [35]  [280/345]  eta: 0:00:49  lr: 0.000057  loss: 0.7181 (0.7200)  time: 0.7595  data: 0.0001  max mem: 14938
[21:34:14.793674] Epoch: [35]  [300/345]  eta: 0:00:34  lr: 0.000057  loss: 0.7151 (0.7199)  time: 0.7597  data: 0.0001  max mem: 14938
[21:34:29.984508] Epoch: [35]  [320/345]  eta: 0:00:19  lr: 0.000056  loss: 0.7177 (0.7197)  time: 0.7595  data: 0.0001  max mem: 14938
[21:34:45.178503] Epoch: [35]  [340/345]  eta: 0:00:03  lr: 0.000056  loss: 0.7181 (0.7196)  time: 0.7597  data: 0.0001  max mem: 14938
[21:34:48.215566] Epoch: [35]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.7136 (0.7197)  time: 0.7595  data: 0.0001  max mem: 14938
[21:34:48.285650] Epoch: [35] Total time: 0:04:22 (0.7605 s / it)
[21:34:48.286261] Averaged stats: lr: 0.000056  loss: 0.7136 (0.7197)
[21:34:48.839581] Test:  [  0/345]  eta: 0:03:08  loss: 0.7151 (0.7151)  time: 0.5478  data: 0.3481  max mem: 14938
[21:34:50.794034] Test:  [ 10/345]  eta: 0:01:16  loss: 0.7047 (0.7015)  time: 0.2274  data: 0.0317  max mem: 14938
[21:34:52.756531] Test:  [ 20/345]  eta: 0:01:09  loss: 0.6966 (0.6972)  time: 0.1958  data: 0.0001  max mem: 14938
[21:34:54.723655] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6907 (0.6944)  time: 0.1964  data: 0.0001  max mem: 14938
[21:34:56.693804] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6903 (0.6943)  time: 0.1968  data: 0.0001  max mem: 14938
[21:34:58.672378] Test:  [ 50/345]  eta: 0:01:00  loss: 0.6942 (0.6940)  time: 0.1974  data: 0.0001  max mem: 14938
[21:35:00.656537] Test:  [ 60/345]  eta: 0:00:57  loss: 0.6936 (0.6939)  time: 0.1981  data: 0.0001  max mem: 14938
[21:35:02.643126] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6914 (0.6935)  time: 0.1985  data: 0.0001  max mem: 14938
[21:35:04.635317] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6934 (0.6943)  time: 0.1989  data: 0.0001  max mem: 14938
[21:35:06.629020] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6947 (0.6938)  time: 0.1992  data: 0.0001  max mem: 14938
[21:35:08.630705] Test:  [100/345]  eta: 0:00:49  loss: 0.6926 (0.6946)  time: 0.1997  data: 0.0001  max mem: 14938
[21:35:10.636311] Test:  [110/345]  eta: 0:00:47  loss: 0.6989 (0.6951)  time: 0.2003  data: 0.0001  max mem: 14938
[21:35:12.650537] Test:  [120/345]  eta: 0:00:45  loss: 0.6954 (0.6950)  time: 0.2009  data: 0.0001  max mem: 14938
[21:35:14.670770] Test:  [130/345]  eta: 0:00:43  loss: 0.6950 (0.6950)  time: 0.2017  data: 0.0001  max mem: 14938
[21:35:16.692878] Test:  [140/345]  eta: 0:00:41  loss: 0.6961 (0.6952)  time: 0.2021  data: 0.0001  max mem: 14938
[21:35:18.720993] Test:  [150/345]  eta: 0:00:39  loss: 0.6916 (0.6952)  time: 0.2025  data: 0.0001  max mem: 14938
[21:35:20.753441] Test:  [160/345]  eta: 0:00:37  loss: 0.6916 (0.6952)  time: 0.2030  data: 0.0001  max mem: 14938
[21:35:22.793605] Test:  [170/345]  eta: 0:00:35  loss: 0.6924 (0.6953)  time: 0.2036  data: 0.0001  max mem: 14938
[21:35:24.838045] Test:  [180/345]  eta: 0:00:33  loss: 0.6888 (0.6950)  time: 0.2042  data: 0.0001  max mem: 14938
[21:35:26.886397] Test:  [190/345]  eta: 0:00:31  loss: 0.6893 (0.6949)  time: 0.2046  data: 0.0001  max mem: 14938
[21:35:28.940831] Test:  [200/345]  eta: 0:00:29  loss: 0.6875 (0.6946)  time: 0.2051  data: 0.0001  max mem: 14938
[21:35:30.998972] Test:  [210/345]  eta: 0:00:27  loss: 0.6879 (0.6946)  time: 0.2056  data: 0.0001  max mem: 14938
[21:35:33.064371] Test:  [220/345]  eta: 0:00:25  loss: 0.6951 (0.6947)  time: 0.2061  data: 0.0001  max mem: 14938
[21:35:35.133726] Test:  [230/345]  eta: 0:00:23  loss: 0.6959 (0.6948)  time: 0.2067  data: 0.0001  max mem: 14938
[21:35:37.208647] Test:  [240/345]  eta: 0:00:21  loss: 0.6873 (0.6945)  time: 0.2072  data: 0.0001  max mem: 14938
[21:35:39.288217] Test:  [250/345]  eta: 0:00:19  loss: 0.6873 (0.6943)  time: 0.2077  data: 0.0001  max mem: 14938
[21:35:41.373772] Test:  [260/345]  eta: 0:00:17  loss: 0.6909 (0.6943)  time: 0.2082  data: 0.0001  max mem: 14938
[21:35:43.466741] Test:  [270/345]  eta: 0:00:15  loss: 0.6916 (0.6941)  time: 0.2089  data: 0.0001  max mem: 14938
[21:35:45.561651] Test:  [280/345]  eta: 0:00:13  loss: 0.6903 (0.6940)  time: 0.2093  data: 0.0001  max mem: 14938
[21:35:47.660064] Test:  [290/345]  eta: 0:00:11  loss: 0.6886 (0.6938)  time: 0.2096  data: 0.0001  max mem: 14938
[21:35:49.765271] Test:  [300/345]  eta: 0:00:09  loss: 0.6902 (0.6940)  time: 0.2101  data: 0.0001  max mem: 14938
[21:35:51.875218] Test:  [310/345]  eta: 0:00:07  loss: 0.6948 (0.6941)  time: 0.2107  data: 0.0001  max mem: 14938
[21:35:53.991767] Test:  [320/345]  eta: 0:00:05  loss: 0.6917 (0.6940)  time: 0.2112  data: 0.0001  max mem: 14938
[21:35:56.112656] Test:  [330/345]  eta: 0:00:03  loss: 0.6924 (0.6940)  time: 0.2118  data: 0.0001  max mem: 14938
[21:35:58.236664] Test:  [340/345]  eta: 0:00:01  loss: 0.6939 (0.6940)  time: 0.2122  data: 0.0001  max mem: 14938
[21:35:59.087828] Test:  [344/345]  eta: 0:00:00  loss: 0.6939 (0.6940)  time: 0.2124  data: 0.0001  max mem: 14938
[21:35:59.155229] Test: Total time: 0:01:10 (0.2054 s / it)
[21:36:16.238217] Test:  [ 0/57]  eta: 0:00:32  loss: 0.8427 (0.8427)  time: 0.5687  data: 0.3744  max mem: 14938
[21:36:18.165537] Test:  [10/57]  eta: 0:00:10  loss: 0.8720 (0.8753)  time: 0.2268  data: 0.0341  max mem: 14938
[21:36:20.100899] Test:  [20/57]  eta: 0:00:07  loss: 0.8720 (0.8642)  time: 0.1931  data: 0.0001  max mem: 14938
[21:36:22.040519] Test:  [30/57]  eta: 0:00:05  loss: 0.7499 (0.8222)  time: 0.1937  data: 0.0001  max mem: 14938
[21:36:23.987234] Test:  [40/57]  eta: 0:00:03  loss: 0.7415 (0.8023)  time: 0.1943  data: 0.0001  max mem: 14938
[21:36:25.940717] Test:  [50/57]  eta: 0:00:01  loss: 0.7378 (0.7952)  time: 0.1950  data: 0.0001  max mem: 14938
[21:36:27.002813] Test:  [56/57]  eta: 0:00:00  loss: 0.7540 (0.8011)  time: 0.1897  data: 0.0001  max mem: 14938
[21:36:27.055619] Test: Total time: 0:00:11 (0.1998 s / it)
[21:36:29.976332] Dice score of the network on the train images: 0.729869, val images: 0.766346
[21:36:29.981568] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:36:31.087380] Epoch: [36]  [  0/345]  eta: 0:06:21  lr: 0.000056  loss: 0.7062 (0.7062)  time: 1.1047  data: 0.3398  max mem: 14938
[21:36:46.159060] Epoch: [36]  [ 20/345]  eta: 0:04:10  lr: 0.000056  loss: 0.7151 (0.7171)  time: 0.7535  data: 0.0001  max mem: 14938

[21:37:01.258134] Epoch: [36]  [ 40/345]  eta: 0:03:52  lr: 0.000055  loss: 0.7136 (0.7169)  time: 0.7549  data: 0.0001  max mem: 14938
[21:37:16.459826] Epoch: [36]  [ 60/345]  eta: 0:03:37  lr: 0.000055  loss: 0.7169 (0.7191)  time: 0.7600  data: 0.0001  max mem: 14938
[21:37:31.665758] Epoch: [36]  [ 80/345]  eta: 0:03:21  lr: 0.000054  loss: 0.7187 (0.7185)  time: 0.7603  data: 0.0001  max mem: 14938
[21:37:46.891580] Epoch: [36]  [100/345]  eta: 0:03:06  lr: 0.000054  loss: 0.7142 (0.7182)  time: 0.7612  data: 0.0001  max mem: 14938
[21:38:02.104823] Epoch: [36]  [120/345]  eta: 0:02:51  lr: 0.000054  loss: 0.7169 (0.7187)  time: 0.7606  data: 0.0001  max mem: 14938
[21:38:17.319645] Epoch: [36]  [140/345]  eta: 0:02:36  lr: 0.000053  loss: 0.7137 (0.7180)  time: 0.7607  data: 0.0001  max mem: 14938
[21:38:32.543997] Epoch: [36]  [160/345]  eta: 0:02:20  lr: 0.000053  loss: 0.7193 (0.7188)  time: 0.7612  data: 0.0001  max mem: 14938
[21:38:47.746856] Epoch: [36]  [180/345]  eta: 0:02:05  lr: 0.000053  loss: 0.7260 (0.7199)  time: 0.7601  data: 0.0001  max mem: 14938
[21:39:02.943014] Epoch: [36]  [200/345]  eta: 0:01:50  lr: 0.000052  loss: 0.7167 (0.7199)  time: 0.7598  data: 0.0001  max mem: 14938
[21:39:18.137862] Epoch: [36]  [220/345]  eta: 0:01:35  lr: 0.000052  loss: 0.7168 (0.7199)  time: 0.7597  data: 0.0001  max mem: 14938
[21:39:33.332131] Epoch: [36]  [240/345]  eta: 0:01:19  lr: 0.000051  loss: 0.7149 (0.7199)  time: 0.7597  data: 0.0001  max mem: 14938
[21:39:48.527516] Epoch: [36]  [260/345]  eta: 0:01:04  lr: 0.000051  loss: 0.7197 (0.7198)  time: 0.7597  data: 0.0001  max mem: 14938
[21:40:03.723110] Epoch: [36]  [280/345]  eta: 0:00:49  lr: 0.000051  loss: 0.7164 (0.7197)  time: 0.7597  data: 0.0001  max mem: 14938
[21:40:18.916813] Epoch: [36]  [300/345]  eta: 0:00:34  lr: 0.000050  loss: 0.7129 (0.7195)  time: 0.7596  data: 0.0001  max mem: 14938
[21:40:34.094473] Epoch: [36]  [320/345]  eta: 0:00:19  lr: 0.000050  loss: 0.7157 (0.7196)  time: 0.7588  data: 0.0001  max mem: 14938
[21:40:49.259046] Epoch: [36]  [340/345]  eta: 0:00:03  lr: 0.000050  loss: 0.7266 (0.7199)  time: 0.7582  data: 0.0001  max mem: 14938
[21:40:52.292879] Epoch: [36]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.7266 (0.7200)  time: 0.7579  data: 0.0001  max mem: 14938
[21:40:52.355596] Epoch: [36] Total time: 0:04:22 (0.7605 s / it)
[21:40:52.356110] Averaged stats: lr: 0.000050  loss: 0.7266 (0.7200)
[21:40:52.962367] Test:  [  0/345]  eta: 0:03:27  loss: 0.6867 (0.6867)  time: 0.6011  data: 0.4030  max mem: 14938
[21:40:54.914600] Test:  [ 10/345]  eta: 0:01:17  loss: 0.6954 (0.6956)  time: 0.2320  data: 0.0367  max mem: 14938
[21:40:56.874880] Test:  [ 20/345]  eta: 0:01:09  loss: 0.6943 (0.6955)  time: 0.1956  data: 0.0001  max mem: 14938
[21:40:58.841429] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6942 (0.6955)  time: 0.1963  data: 0.0001  max mem: 14938
[21:41:00.810450] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6913 (0.6948)  time: 0.1967  data: 0.0001  max mem: 14938
[21:41:02.786455] Test:  [ 50/345]  eta: 0:01:00  loss: 0.6954 (0.6957)  time: 0.1972  data: 0.0001  max mem: 14938
[21:41:04.768183] Test:  [ 60/345]  eta: 0:00:57  loss: 0.6946 (0.6948)  time: 0.1978  data: 0.0001  max mem: 14938
[21:41:06.754597] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6856 (0.6940)  time: 0.1983  data: 0.0001  max mem: 14938
[21:41:08.747766] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6933 (0.6941)  time: 0.1989  data: 0.0001  max mem: 14938
[21:41:10.745548] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6940 (0.6951)  time: 0.1995  data: 0.0001  max mem: 14938
[21:41:12.749022] Test:  [100/345]  eta: 0:00:49  loss: 0.7027 (0.6954)  time: 0.2000  data: 0.0001  max mem: 14938
[21:41:14.755579] Test:  [110/345]  eta: 0:00:47  loss: 0.6972 (0.6954)  time: 0.2004  data: 0.0001  max mem: 14938
[21:41:16.767995] Test:  [120/345]  eta: 0:00:45  loss: 0.6974 (0.6957)  time: 0.2009  data: 0.0001  max mem: 14938
[21:41:18.783712] Test:  [130/345]  eta: 0:00:43  loss: 0.6976 (0.6958)  time: 0.2013  data: 0.0001  max mem: 14938
[21:41:20.804169] Test:  [140/345]  eta: 0:00:41  loss: 0.6950 (0.6957)  time: 0.2018  data: 0.0001  max mem: 14938
[21:41:22.831985] Test:  [150/345]  eta: 0:00:39  loss: 0.6927 (0.6955)  time: 0.2024  data: 0.0001  max mem: 14938
[21:41:24.862003] Test:  [160/345]  eta: 0:00:37  loss: 0.6964 (0.6959)  time: 0.2028  data: 0.0001  max mem: 14938
[21:41:26.899080] Test:  [170/345]  eta: 0:00:35  loss: 0.6964 (0.6959)  time: 0.2033  data: 0.0001  max mem: 14938
[21:41:28.940509] Test:  [180/345]  eta: 0:00:33  loss: 0.6962 (0.6962)  time: 0.2039  data: 0.0001  max mem: 14938
[21:41:30.986677] Test:  [190/345]  eta: 0:00:31  loss: 0.6942 (0.6959)  time: 0.2043  data: 0.0001  max mem: 14938
[21:41:33.040665] Test:  [200/345]  eta: 0:00:29  loss: 0.6927 (0.6957)  time: 0.2049  data: 0.0001  max mem: 14938
[21:41:35.097072] Test:  [210/345]  eta: 0:00:27  loss: 0.6920 (0.6956)  time: 0.2055  data: 0.0001  max mem: 14938
[21:41:37.158235] Test:  [220/345]  eta: 0:00:25  loss: 0.6918 (0.6955)  time: 0.2058  data: 0.0001  max mem: 14938
[21:41:39.225401] Test:  [230/345]  eta: 0:00:23  loss: 0.6907 (0.6953)  time: 0.2063  data: 0.0001  max mem: 14938
[21:41:41.297391] Test:  [240/345]  eta: 0:00:21  loss: 0.6907 (0.6952)  time: 0.2069  data: 0.0001  max mem: 14938
[21:41:43.374119] Test:  [250/345]  eta: 0:00:19  loss: 0.6933 (0.6951)  time: 0.2074  data: 0.0001  max mem: 14938
[21:41:45.457586] Test:  [260/345]  eta: 0:00:17  loss: 0.6933 (0.6952)  time: 0.2080  data: 0.0001  max mem: 14938
[21:41:47.544229] Test:  [270/345]  eta: 0:00:15  loss: 0.6968 (0.6954)  time: 0.2084  data: 0.0001  max mem: 14938
[21:41:49.637055] Test:  [280/345]  eta: 0:00:13  loss: 0.6981 (0.6955)  time: 0.2089  data: 0.0001  max mem: 14938
[21:41:51.733244] Test:  [290/345]  eta: 0:00:11  loss: 0.6993 (0.6957)  time: 0.2094  data: 0.0001  max mem: 14938
[21:41:53.835298] Test:  [300/345]  eta: 0:00:09  loss: 0.6972 (0.6955)  time: 0.2099  data: 0.0001  max mem: 14938
[21:41:55.944874] Test:  [310/345]  eta: 0:00:07  loss: 0.6918 (0.6955)  time: 0.2105  data: 0.0001  max mem: 14938
[21:41:58.060477] Test:  [320/345]  eta: 0:00:05  loss: 0.6999 (0.6957)  time: 0.2112  data: 0.0001  max mem: 14938
[21:42:00.180336] Test:  [330/345]  eta: 0:00:03  loss: 0.7014 (0.6959)  time: 0.2117  data: 0.0001  max mem: 14938
[21:42:02.302589] Test:  [340/345]  eta: 0:00:01  loss: 0.6947 (0.6957)  time: 0.2121  data: 0.0001  max mem: 14938
[21:42:03.154361] Test:  [344/345]  eta: 0:00:00  loss: 0.6947 (0.6957)  time: 0.2123  data: 0.0001  max mem: 14938
[21:42:03.216527] Test: Total time: 0:01:10 (0.2054 s / it)
[21:42:20.098178] Test:  [ 0/57]  eta: 0:00:32  loss: 0.8276 (0.8276)  time: 0.5614  data: 0.3665  max mem: 14938
[21:42:22.023015] Test:  [10/57]  eta: 0:00:10  loss: 0.8761 (0.8807)  time: 0.2259  data: 0.0334  max mem: 14938
[21:42:23.958215] Test:  [20/57]  eta: 0:00:07  loss: 0.8761 (0.8683)  time: 0.1929  data: 0.0001  max mem: 14938
[21:42:25.897868] Test:  [30/57]  eta: 0:00:05  loss: 0.7634 (0.8290)  time: 0.1937  data: 0.0001  max mem: 14938
[21:42:27.845020] Test:  [40/57]  eta: 0:00:03  loss: 0.7474 (0.8093)  time: 0.1943  data: 0.0001  max mem: 14938
[21:42:29.799147] Test:  [50/57]  eta: 0:00:01  loss: 0.7359 (0.8015)  time: 0.1950  data: 0.0001  max mem: 14938
[21:42:30.862168] Test:  [56/57]  eta: 0:00:00  loss: 0.7529 (0.8073)  time: 0.1897  data: 0.0000  max mem: 14938
[21:42:30.928125] Test: Total time: 0:00:11 (0.1999 s / it)
[21:42:33.868188] Dice score of the network on the train images: 0.731880, val images: 0.765012
[21:42:33.872370] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:42:34.960060] Epoch: [37]  [  0/345]  eta: 0:06:14  lr: 0.000050  loss: 0.7350 (0.7350)  time: 1.0865  data: 0.3237  max mem: 14938
[21:42:50.014159] Epoch: [37]  [ 20/345]  eta: 0:04:09  lr: 0.000049  loss: 0.7132 (0.7160)  time: 0.7526  data: 0.0001  max mem: 14938
[21:43:05.135998] Epoch: [37]  [ 40/345]  eta: 0:03:52  lr: 0.000049  loss: 0.7119 (0.7159)  time: 0.7560  data: 0.0001  max mem: 14938
[21:43:20.318382] Epoch: [37]  [ 60/345]  eta: 0:03:36  lr: 0.000048  loss: 0.7174 (0.7167)  time: 0.7591  data: 0.0001  max mem: 14938
[21:43:35.516989] Epoch: [37]  [ 80/345]  eta: 0:03:21  lr: 0.000048  loss: 0.7189 (0.7171)  time: 0.7599  data: 0.0001  max mem: 14938
[21:43:50.732697] Epoch: [37]  [100/345]  eta: 0:03:06  lr: 0.000048  loss: 0.7154 (0.7170)  time: 0.7607  data: 0.0001  max mem: 14938
[21:44:05.951196] Epoch: [37]  [120/345]  eta: 0:02:51  lr: 0.000047  loss: 0.7117 (0.7169)  time: 0.7609  data: 0.0001  max mem: 14938
[21:44:21.158980] Epoch: [37]  [140/345]  eta: 0:02:35  lr: 0.000047  loss: 0.7133 (0.7172)  time: 0.7604  data: 0.0001  max mem: 14938
[21:44:36.368275] Epoch: [37]  [160/345]  eta: 0:02:20  lr: 0.000047  loss: 0.7173 (0.7171)  time: 0.7604  data: 0.0001  max mem: 14938
[21:44:51.559560] Epoch: [37]  [180/345]  eta: 0:02:05  lr: 0.000046  loss: 0.7160 (0.7171)  time: 0.7595  data: 0.0001  max mem: 14938
[21:45:06.748007] Epoch: [37]  [200/345]  eta: 0:01:50  lr: 0.000046  loss: 0.7142 (0.7170)  time: 0.7594  data: 0.0001  max mem: 14938
[21:45:21.936047] Epoch: [37]  [220/345]  eta: 0:01:35  lr: 0.000045  loss: 0.7111 (0.7167)  time: 0.7594  data: 0.0001  max mem: 14938
[21:45:37.110488] Epoch: [37]  [240/345]  eta: 0:01:19  lr: 0.000045  loss: 0.7178 (0.7168)  time: 0.7587  data: 0.0001  max mem: 14938
[21:45:52.287064] Epoch: [37]  [260/345]  eta: 0:01:04  lr: 0.000045  loss: 0.7196 (0.7171)  time: 0.7588  data: 0.0001  max mem: 14938
[21:46:07.485501] Epoch: [37]  [280/345]  eta: 0:00:49  lr: 0.000044  loss: 0.7145 (0.7169)  time: 0.7599  data: 0.0001  max mem: 14938
[21:46:22.678910] Epoch: [37]  [300/345]  eta: 0:00:34  lr: 0.000044  loss: 0.7129 (0.7167)  time: 0.7596  data: 0.0001  max mem: 14938
[21:46:37.874911] Epoch: [37]  [320/345]  eta: 0:00:19  lr: 0.000044  loss: 0.7133 (0.7166)  time: 0.7598  data: 0.0001  max mem: 14938
[21:46:53.065426] Epoch: [37]  [340/345]  eta: 0:00:03  lr: 0.000043  loss: 0.7181 (0.7166)  time: 0.7595  data: 0.0001  max mem: 14938
[21:46:56.104666] Epoch: [37]  [344/345]  eta: 0:00:00  lr: 0.000043  loss: 0.7181 (0.7166)  time: 0.7595  data: 0.0001  max mem: 14938
[21:46:56.175218] Epoch: [37] Total time: 0:04:22 (0.7603 s / it)
[21:46:56.175575] Averaged stats: lr: 0.000043  loss: 0.7181 (0.7166)
[21:46:56.782510] Test:  [  0/345]  eta: 0:03:27  loss: 0.7052 (0.7052)  time: 0.6013  data: 0.4030  max mem: 14938
[21:46:58.739113] Test:  [ 10/345]  eta: 0:01:17  loss: 0.6897 (0.6919)  time: 0.2325  data: 0.0367  max mem: 14938
[21:47:00.704795] Test:  [ 20/345]  eta: 0:01:09  loss: 0.6859 (0.6902)  time: 0.1960  data: 0.0001  max mem: 14938
[21:47:02.671273] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6859 (0.6904)  time: 0.1965  data: 0.0001  max mem: 14938
[21:47:04.642652] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6874 (0.6905)  time: 0.1968  data: 0.0001  max mem: 14938
[21:47:06.618770] Test:  [ 50/345]  eta: 0:01:00  loss: 0.6928 (0.6910)  time: 0.1973  data: 0.0001  max mem: 14938
[21:47:08.599888] Test:  [ 60/345]  eta: 0:00:58  loss: 0.6903 (0.6909)  time: 0.1978  data: 0.0001  max mem: 14938
[21:47:10.586125] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6891 (0.6900)  time: 0.1983  data: 0.0001  max mem: 14938
[21:47:12.574080] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6841 (0.6897)  time: 0.1987  data: 0.0001  max mem: 14938
[21:47:14.573489] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6880 (0.6899)  time: 0.1993  data: 0.0001  max mem: 14938
[21:47:16.575958] Test:  [100/345]  eta: 0:00:49  loss: 0.6945 (0.6898)  time: 0.2000  data: 0.0001  max mem: 14938
[21:47:18.579791] Test:  [110/345]  eta: 0:00:47  loss: 0.6925 (0.6904)  time: 0.2003  data: 0.0001  max mem: 14938
[21:47:20.591221] Test:  [120/345]  eta: 0:00:45  loss: 0.6916 (0.6904)  time: 0.2007  data: 0.0001  max mem: 14938
[21:47:22.605889] Test:  [130/345]  eta: 0:00:43  loss: 0.6873 (0.6905)  time: 0.2012  data: 0.0001  max mem: 14938
[21:47:24.630153] Test:  [140/345]  eta: 0:00:41  loss: 0.6872 (0.6905)  time: 0.2019  data: 0.0001  max mem: 14938
[21:47:26.657726] Test:  [150/345]  eta: 0:00:39  loss: 0.6931 (0.6909)  time: 0.2025  data: 0.0001  max mem: 14938
[21:47:28.690407] Test:  [160/345]  eta: 0:00:37  loss: 0.6931 (0.6908)  time: 0.2030  data: 0.0001  max mem: 14938
[21:47:30.727312] Test:  [170/345]  eta: 0:00:35  loss: 0.6869 (0.6905)  time: 0.2034  data: 0.0001  max mem: 14938
[21:47:32.767631] Test:  [180/345]  eta: 0:00:33  loss: 0.6869 (0.6907)  time: 0.2038  data: 0.0001  max mem: 14938
[21:47:34.813357] Test:  [190/345]  eta: 0:00:31  loss: 0.6922 (0.6910)  time: 0.2042  data: 0.0001  max mem: 14938
[21:47:36.864455] Test:  [200/345]  eta: 0:00:29  loss: 0.6924 (0.6910)  time: 0.2048  data: 0.0001  max mem: 14938
[21:47:38.921434] Test:  [210/345]  eta: 0:00:27  loss: 0.6896 (0.6910)  time: 0.2053  data: 0.0001  max mem: 14938
[21:47:40.982973] Test:  [220/345]  eta: 0:00:25  loss: 0.6889 (0.6912)  time: 0.2059  data: 0.0001  max mem: 14938
[21:47:43.052476] Test:  [230/345]  eta: 0:00:23  loss: 0.6856 (0.6910)  time: 0.2065  data: 0.0001  max mem: 14938
[21:47:45.126727] Test:  [240/345]  eta: 0:00:21  loss: 0.6882 (0.6910)  time: 0.2071  data: 0.0001  max mem: 14938
[21:47:47.205474] Test:  [250/345]  eta: 0:00:19  loss: 0.6897 (0.6909)  time: 0.2076  data: 0.0001  max mem: 14938
[21:47:49.291298] Test:  [260/345]  eta: 0:00:17  loss: 0.6897 (0.6909)  time: 0.2082  data: 0.0001  max mem: 14938
[21:47:51.379934] Test:  [270/345]  eta: 0:00:15  loss: 0.6865 (0.6908)  time: 0.2087  data: 0.0001  max mem: 14938
[21:47:53.473893] Test:  [280/345]  eta: 0:00:13  loss: 0.6903 (0.6908)  time: 0.2091  data: 0.0001  max mem: 14938
[21:47:55.572614] Test:  [290/345]  eta: 0:00:11  loss: 0.6907 (0.6909)  time: 0.2096  data: 0.0001  max mem: 14938
[21:47:57.679181] Test:  [300/345]  eta: 0:00:09  loss: 0.6899 (0.6908)  time: 0.2102  data: 0.0001  max mem: 14938
[21:47:59.790089] Test:  [310/345]  eta: 0:00:07  loss: 0.6863 (0.6907)  time: 0.2108  data: 0.0001  max mem: 14938
[21:48:01.906203] Test:  [320/345]  eta: 0:00:05  loss: 0.6882 (0.6907)  time: 0.2113  data: 0.0001  max mem: 14938
[21:48:04.026285] Test:  [330/345]  eta: 0:00:03  loss: 0.6893 (0.6909)  time: 0.2117  data: 0.0001  max mem: 14938
[21:48:06.149163] Test:  [340/345]  eta: 0:00:01  loss: 0.6931 (0.6911)  time: 0.2121  data: 0.0001  max mem: 14938
[21:48:06.999928] Test:  [344/345]  eta: 0:00:00  loss: 0.6942 (0.6912)  time: 0.2122  data: 0.0001  max mem: 14938
[21:48:07.064219] Test: Total time: 0:01:10 (0.2055 s / it)
[21:48:23.993098] Test:  [ 0/57]  eta: 0:00:29  loss: 0.8462 (0.8462)  time: 0.5160  data: 0.3207  max mem: 14938
[21:48:25.915452] Test:  [10/57]  eta: 0:00:10  loss: 0.8721 (0.8828)  time: 0.2216  data: 0.0292  max mem: 14938
[21:48:27.848184] Test:  [20/57]  eta: 0:00:07  loss: 0.8721 (0.8691)  time: 0.1927  data: 0.0001  max mem: 14938
[21:48:29.787829] Test:  [30/57]  eta: 0:00:05  loss: 0.7612 (0.8282)  time: 0.1936  data: 0.0001  max mem: 14938
[21:48:31.736156] Test:  [40/57]  eta: 0:00:03  loss: 0.7477 (0.8081)  time: 0.1943  data: 0.0001  max mem: 14938
[21:48:33.690270] Test:  [50/57]  eta: 0:00:01  loss: 0.7374 (0.7999)  time: 0.1951  data: 0.0001  max mem: 14938
[21:48:34.752810] Test:  [56/57]  eta: 0:00:00  loss: 0.7538 (0.8053)  time: 0.1897  data: 0.0000  max mem: 14938
[21:48:34.819745] Test: Total time: 0:00:11 (0.1990 s / it)
[21:48:37.731123] Dice score of the network on the train images: 0.734760, val images: 0.764368
[21:48:37.735244] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:48:38.815824] Epoch: [38]  [  0/345]  eta: 0:06:12  lr: 0.000043  loss: 0.7102 (0.7102)  time: 1.0794  data: 0.3162  max mem: 14938
[21:48:53.885041] Epoch: [38]  [ 20/345]  eta: 0:04:09  lr: 0.000043  loss: 0.7141 (0.7135)  time: 0.7534  data: 0.0001  max mem: 14938
[21:49:09.009845] Epoch: [38]  [ 40/345]  eta: 0:03:52  lr: 0.000042  loss: 0.7140 (0.7148)  time: 0.7562  data: 0.0001  max mem: 14938
[21:49:24.197368] Epoch: [38]  [ 60/345]  eta: 0:03:37  lr: 0.000042  loss: 0.7133 (0.7150)  time: 0.7593  data: 0.0001  max mem: 14938
[21:49:39.400485] Epoch: [38]  [ 80/345]  eta: 0:03:21  lr: 0.000042  loss: 0.7116 (0.7150)  time: 0.7601  data: 0.0001  max mem: 14938
[21:49:54.617805] Epoch: [38]  [100/345]  eta: 0:03:06  lr: 0.000041  loss: 0.7132 (0.7146)  time: 0.7608  data: 0.0001  max mem: 14938
[21:50:09.843371] Epoch: [38]  [120/345]  eta: 0:02:51  lr: 0.000041  loss: 0.7188 (0.7155)  time: 0.7612  data: 0.0001  max mem: 14938
[21:50:25.042230] Epoch: [38]  [140/345]  eta: 0:02:36  lr: 0.000041  loss: 0.7172 (0.7156)  time: 0.7599  data: 0.0001  max mem: 14938
[21:50:40.335355] Epoch: [38]  [160/345]  eta: 0:02:20  lr: 0.000040  loss: 0.7110 (0.7155)  time: 0.7646  data: 0.0001  max mem: 14938
[21:50:55.524697] Epoch: [38]  [180/345]  eta: 0:02:05  lr: 0.000040  loss: 0.7114 (0.7151)  time: 0.7594  data: 0.0001  max mem: 14938
[21:51:10.727436] Epoch: [38]  [200/345]  eta: 0:01:50  lr: 0.000040  loss: 0.7121 (0.7152)  time: 0.7601  data: 0.0001  max mem: 14938
[21:51:25.921121] Epoch: [38]  [220/345]  eta: 0:01:35  lr: 0.000039  loss: 0.7110 (0.7152)  time: 0.7596  data: 0.0001  max mem: 14938
[21:51:41.114725] Epoch: [38]  [240/345]  eta: 0:01:19  lr: 0.000039  loss: 0.7100 (0.7149)  time: 0.7596  data: 0.0001  max mem: 14938

[21:51:56.311006] Epoch: [38]  [260/345]  eta: 0:01:04  lr: 0.000039  loss: 0.7064 (0.7144)  time: 0.7598  data: 0.0001  max mem: 14938
[21:52:11.483100] Epoch: [38]  [280/345]  eta: 0:00:49  lr: 0.000038  loss: 0.7144 (0.7145)  time: 0.7586  data: 0.0001  max mem: 14938
[21:52:26.641372] Epoch: [38]  [300/345]  eta: 0:00:34  lr: 0.000038  loss: 0.7136 (0.7146)  time: 0.7579  data: 0.0001  max mem: 14938
[21:52:41.803137] Epoch: [38]  [320/345]  eta: 0:00:19  lr: 0.000038  loss: 0.7121 (0.7147)  time: 0.7580  data: 0.0001  max mem: 14938
[21:52:56.954492] Epoch: [38]  [340/345]  eta: 0:00:03  lr: 0.000037  loss: 0.7135 (0.7148)  time: 0.7575  data: 0.0001  max mem: 14938
[21:52:59.986072] Epoch: [38]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 0.7135 (0.7147)  time: 0.7575  data: 0.0001  max mem: 14938
[21:53:00.057909] Epoch: [38] Total time: 0:04:22 (0.7604 s / it)
[21:53:00.058529] Averaged stats: lr: 0.000037  loss: 0.7135 (0.7147)
[21:53:00.637429] Test:  [  0/345]  eta: 0:03:17  loss: 0.6624 (0.6624)  time: 0.5735  data: 0.3751  max mem: 14938
[21:53:02.592476] Test:  [ 10/345]  eta: 0:01:16  loss: 0.6921 (0.6945)  time: 0.2298  data: 0.0342  max mem: 14938
[21:53:04.553857] Test:  [ 20/345]  eta: 0:01:09  loss: 0.6914 (0.6926)  time: 0.1958  data: 0.0001  max mem: 14938
[21:53:06.521436] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6844 (0.6911)  time: 0.1964  data: 0.0001  max mem: 14938
[21:53:08.493051] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6844 (0.6908)  time: 0.1969  data: 0.0001  max mem: 14938
[21:53:10.470995] Test:  [ 50/345]  eta: 0:01:00  loss: 0.6870 (0.6907)  time: 0.1974  data: 0.0001  max mem: 14938
[21:53:12.453311] Test:  [ 60/345]  eta: 0:00:57  loss: 0.6913 (0.6905)  time: 0.1979  data: 0.0001  max mem: 14938
[21:53:14.438946] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6898 (0.6902)  time: 0.1983  data: 0.0001  max mem: 14938
[21:53:16.433964] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6875 (0.6901)  time: 0.1990  data: 0.0001  max mem: 14938
[21:53:18.434902] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6890 (0.6901)  time: 0.1997  data: 0.0001  max mem: 14938
[21:53:20.437795] Test:  [100/345]  eta: 0:00:49  loss: 0.6932 (0.6906)  time: 0.2001  data: 0.0001  max mem: 14938
[21:53:22.441630] Test:  [110/345]  eta: 0:00:47  loss: 0.6932 (0.6907)  time: 0.2003  data: 0.0001  max mem: 14938
[21:53:24.452126] Test:  [120/345]  eta: 0:00:45  loss: 0.6877 (0.6905)  time: 0.2007  data: 0.0001  max mem: 14938
[21:53:26.469103] Test:  [130/345]  eta: 0:00:43  loss: 0.6866 (0.6901)  time: 0.2013  data: 0.0001  max mem: 14938
[21:53:28.490298] Test:  [140/345]  eta: 0:00:41  loss: 0.6859 (0.6900)  time: 0.2018  data: 0.0001  max mem: 14938
[21:53:30.518302] Test:  [150/345]  eta: 0:00:39  loss: 0.6889 (0.6900)  time: 0.2024  data: 0.0001  max mem: 14938
[21:53:32.552433] Test:  [160/345]  eta: 0:00:37  loss: 0.6880 (0.6899)  time: 0.2030  data: 0.0001  max mem: 14938
[21:53:34.587946] Test:  [170/345]  eta: 0:00:35  loss: 0.6910 (0.6902)  time: 0.2034  data: 0.0001  max mem: 14938
[21:53:36.631448] Test:  [180/345]  eta: 0:00:33  loss: 0.6844 (0.6898)  time: 0.2039  data: 0.0001  max mem: 14938
[21:53:38.676236] Test:  [190/345]  eta: 0:00:31  loss: 0.6835 (0.6898)  time: 0.2043  data: 0.0001  max mem: 14938
[21:53:40.726810] Test:  [200/345]  eta: 0:00:29  loss: 0.6903 (0.6898)  time: 0.2047  data: 0.0001  max mem: 14938
[21:53:42.786809] Test:  [210/345]  eta: 0:00:27  loss: 0.6908 (0.6899)  time: 0.2055  data: 0.0001  max mem: 14938
[21:53:44.851150] Test:  [220/345]  eta: 0:00:25  loss: 0.6868 (0.6899)  time: 0.2062  data: 0.0001  max mem: 14938
[21:53:46.918664] Test:  [230/345]  eta: 0:00:23  loss: 0.6868 (0.6899)  time: 0.2065  data: 0.0001  max mem: 14938
[21:53:48.992954] Test:  [240/345]  eta: 0:00:21  loss: 0.6880 (0.6899)  time: 0.2070  data: 0.0001  max mem: 14938
[21:53:51.072895] Test:  [250/345]  eta: 0:00:19  loss: 0.6839 (0.6896)  time: 0.2077  data: 0.0001  max mem: 14938
[21:53:53.156436] Test:  [260/345]  eta: 0:00:17  loss: 0.6839 (0.6897)  time: 0.2081  data: 0.0001  max mem: 14938
[21:53:55.246318] Test:  [270/345]  eta: 0:00:15  loss: 0.6918 (0.6898)  time: 0.2086  data: 0.0001  max mem: 14938
[21:53:57.341644] Test:  [280/345]  eta: 0:00:13  loss: 0.6878 (0.6896)  time: 0.2092  data: 0.0001  max mem: 14938
[21:53:59.438276] Test:  [290/345]  eta: 0:00:11  loss: 0.6876 (0.6895)  time: 0.2095  data: 0.0001  max mem: 14938
[21:54:01.542793] Test:  [300/345]  eta: 0:00:09  loss: 0.6874 (0.6896)  time: 0.2100  data: 0.0001  max mem: 14938
[21:54:03.654649] Test:  [310/345]  eta: 0:00:07  loss: 0.6849 (0.6894)  time: 0.2108  data: 0.0001  max mem: 14938
[21:54:05.771419] Test:  [320/345]  eta: 0:00:05  loss: 0.6874 (0.6896)  time: 0.2114  data: 0.0001  max mem: 14938
[21:54:07.891668] Test:  [330/345]  eta: 0:00:03  loss: 0.6843 (0.6894)  time: 0.2118  data: 0.0001  max mem: 14938
[21:54:10.013702] Test:  [340/345]  eta: 0:00:01  loss: 0.6836 (0.6895)  time: 0.2121  data: 0.0001  max mem: 14938
[21:54:10.864883] Test:  [344/345]  eta: 0:00:00  loss: 0.6836 (0.6894)  time: 0.2122  data: 0.0001  max mem: 14938
[21:54:10.914978] Test: Total time: 0:01:10 (0.2054 s / it)
[21:54:28.036593] Test:  [ 0/57]  eta: 0:00:30  loss: 0.8628 (0.8628)  time: 0.5355  data: 0.3401  max mem: 14938
[21:54:29.960133] Test:  [10/57]  eta: 0:00:10  loss: 0.8742 (0.8836)  time: 0.2235  data: 0.0310  max mem: 14938
[21:54:31.894554] Test:  [20/57]  eta: 0:00:07  loss: 0.8742 (0.8727)  time: 0.1928  data: 0.0001  max mem: 14938
[21:54:33.834450] Test:  [30/57]  eta: 0:00:05  loss: 0.7543 (0.8290)  time: 0.1937  data: 0.0001  max mem: 14938
[21:54:35.782290] Test:  [40/57]  eta: 0:00:03  loss: 0.7385 (0.8072)  time: 0.1943  data: 0.0001  max mem: 14938
[21:54:37.734988] Test:  [50/57]  eta: 0:00:01  loss: 0.7339 (0.7995)  time: 0.1950  data: 0.0001  max mem: 14938
[21:54:38.797435] Test:  [56/57]  eta: 0:00:00  loss: 0.7559 (0.8056)  time: 0.1897  data: 0.0001  max mem: 14938
[21:54:38.862044] Test: Total time: 0:00:11 (0.1993 s / it)
[21:54:41.809481] Dice score of the network on the train images: 0.732268, val images: 0.769109
[21:54:41.813752] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:54:42.975494] Epoch: [39]  [  0/345]  eta: 0:06:40  lr: 0.000037  loss: 0.7150 (0.7150)  time: 1.1607  data: 0.3983  max mem: 14938
[21:54:58.048879] Epoch: [39]  [ 20/345]  eta: 0:04:11  lr: 0.000037  loss: 0.7081 (0.7086)  time: 0.7536  data: 0.0001  max mem: 14938
[21:55:13.163926] Epoch: [39]  [ 40/345]  eta: 0:03:53  lr: 0.000036  loss: 0.7138 (0.7129)  time: 0.7557  data: 0.0001  max mem: 14938
[21:55:28.342525] Epoch: [39]  [ 60/345]  eta: 0:03:37  lr: 0.000036  loss: 0.7085 (0.7134)  time: 0.7589  data: 0.0001  max mem: 14938
[21:55:43.542004] Epoch: [39]  [ 80/345]  eta: 0:03:21  lr: 0.000036  loss: 0.7075 (0.7129)  time: 0.7599  data: 0.0001  max mem: 14938
[21:55:58.752455] Epoch: [39]  [100/345]  eta: 0:03:06  lr: 0.000035  loss: 0.7197 (0.7140)  time: 0.7605  data: 0.0001  max mem: 14938
[21:56:13.971620] Epoch: [39]  [120/345]  eta: 0:02:51  lr: 0.000035  loss: 0.7126 (0.7140)  time: 0.7609  data: 0.0001  max mem: 14938
[21:56:29.185325] Epoch: [39]  [140/345]  eta: 0:02:36  lr: 0.000035  loss: 0.7071 (0.7132)  time: 0.7606  data: 0.0001  max mem: 14938
[21:56:44.399689] Epoch: [39]  [160/345]  eta: 0:02:20  lr: 0.000034  loss: 0.7085 (0.7129)  time: 0.7607  data: 0.0001  max mem: 14938
[21:56:59.597419] Epoch: [39]  [180/345]  eta: 0:02:05  lr: 0.000034  loss: 0.7091 (0.7128)  time: 0.7598  data: 0.0001  max mem: 14938
[21:57:14.788896] Epoch: [39]  [200/345]  eta: 0:01:50  lr: 0.000034  loss: 0.7111 (0.7130)  time: 0.7595  data: 0.0001  max mem: 14938
[21:57:29.982648] Epoch: [39]  [220/345]  eta: 0:01:35  lr: 0.000033  loss: 0.7103 (0.7132)  time: 0.7596  data: 0.0001  max mem: 14938
[21:57:45.175077] Epoch: [39]  [240/345]  eta: 0:01:19  lr: 0.000033  loss: 0.7087 (0.7130)  time: 0.7596  data: 0.0001  max mem: 14938
[21:58:00.373931] Epoch: [39]  [260/345]  eta: 0:01:04  lr: 0.000033  loss: 0.7139 (0.7134)  time: 0.7599  data: 0.0001  max mem: 14938
[21:58:15.563965] Epoch: [39]  [280/345]  eta: 0:00:49  lr: 0.000032  loss: 0.7146 (0.7135)  time: 0.7595  data: 0.0001  max mem: 14938

[21:58:30.759660] Epoch: [39]  [300/345]  eta: 0:00:34  lr: 0.000032  loss: 0.7143 (0.7137)  time: 0.7597  data: 0.0001  max mem: 14938
[21:58:45.944176] Epoch: [39]  [320/345]  eta: 0:00:19  lr: 0.000032  loss: 0.7125 (0.7137)  time: 0.7592  data: 0.0001  max mem: 14938
[21:59:01.211299] Epoch: [39]  [340/345]  eta: 0:00:03  lr: 0.000031  loss: 0.7174 (0.7138)  time: 0.7633  data: 0.0001  max mem: 14938
[21:59:04.248533] Epoch: [39]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 0.7174 (0.7137)  time: 0.7635  data: 0.0001  max mem: 14938
[21:59:04.314323] Epoch: [39] Total time: 0:04:22 (0.7609 s / it)
[21:59:04.314542] Averaged stats: lr: 0.000031  loss: 0.7174 (0.7137)
[21:59:04.867362] Test:  [  0/345]  eta: 0:03:08  loss: 0.6843 (0.6843)  time: 0.5466  data: 0.3467  max mem: 14938
[21:59:06.822230] Test:  [ 10/345]  eta: 0:01:16  loss: 0.6867 (0.6854)  time: 0.2273  data: 0.0316  max mem: 14938
[21:59:08.786911] Test:  [ 20/345]  eta: 0:01:09  loss: 0.6867 (0.6866)  time: 0.1959  data: 0.0001  max mem: 14938
[21:59:10.753312] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6797 (0.6852)  time: 0.1965  data: 0.0001  max mem: 14938
[21:59:12.724541] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6797 (0.6850)  time: 0.1968  data: 0.0001  max mem: 14938
[21:59:14.701300] Test:  [ 50/345]  eta: 0:01:00  loss: 0.6854 (0.6865)  time: 0.1973  data: 0.0001  max mem: 14938
[21:59:16.687299] Test:  [ 60/345]  eta: 0:00:57  loss: 0.6972 (0.6881)  time: 0.1981  data: 0.0001  max mem: 14938
[21:59:18.673757] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6910 (0.6889)  time: 0.1986  data: 0.0001  max mem: 14938
[21:59:20.662918] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6877 (0.6886)  time: 0.1987  data: 0.0001  max mem: 14938
[21:59:22.660691] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6877 (0.6885)  time: 0.1993  data: 0.0001  max mem: 14938
[21:59:24.660408] Test:  [100/345]  eta: 0:00:49  loss: 0.6866 (0.6885)  time: 0.1998  data: 0.0001  max mem: 14938
[21:59:26.662940] Test:  [110/345]  eta: 0:00:47  loss: 0.6835 (0.6882)  time: 0.2001  data: 0.0001  max mem: 14938
[21:59:28.671763] Test:  [120/345]  eta: 0:00:45  loss: 0.6858 (0.6889)  time: 0.2005  data: 0.0001  max mem: 14938
[21:59:30.690522] Test:  [130/345]  eta: 0:00:43  loss: 0.6921 (0.6893)  time: 0.2013  data: 0.0001  max mem: 14938
[21:59:32.713349] Test:  [140/345]  eta: 0:00:41  loss: 0.6893 (0.6894)  time: 0.2020  data: 0.0001  max mem: 14938
[21:59:34.742298] Test:  [150/345]  eta: 0:00:39  loss: 0.6850 (0.6891)  time: 0.2025  data: 0.0001  max mem: 14938
[21:59:36.771075] Test:  [160/345]  eta: 0:00:37  loss: 0.6847 (0.6890)  time: 0.2028  data: 0.0001  max mem: 14938
[21:59:38.808092] Test:  [170/345]  eta: 0:00:35  loss: 0.6828 (0.6886)  time: 0.2032  data: 0.0001  max mem: 14938
[21:59:40.850262] Test:  [180/345]  eta: 0:00:33  loss: 0.6882 (0.6889)  time: 0.2039  data: 0.0001  max mem: 14938
[21:59:42.898771] Test:  [190/345]  eta: 0:00:31  loss: 0.6905 (0.6890)  time: 0.2045  data: 0.0001  max mem: 14938
[21:59:44.951650] Test:  [200/345]  eta: 0:00:29  loss: 0.6879 (0.6889)  time: 0.2050  data: 0.0001  max mem: 14938
[21:59:47.009901] Test:  [210/345]  eta: 0:00:27  loss: 0.6880 (0.6892)  time: 0.2055  data: 0.0001  max mem: 14938
[21:59:49.074261] Test:  [220/345]  eta: 0:00:25  loss: 0.6865 (0.6892)  time: 0.2061  data: 0.0001  max mem: 14938
[21:59:51.143208] Test:  [230/345]  eta: 0:00:23  loss: 0.6816 (0.6891)  time: 0.2066  data: 0.0001  max mem: 14938
[21:59:53.217373] Test:  [240/345]  eta: 0:00:21  loss: 0.6845 (0.6890)  time: 0.2071  data: 0.0001  max mem: 14938
[21:59:55.297445] Test:  [250/345]  eta: 0:00:19  loss: 0.6918 (0.6893)  time: 0.2076  data: 0.0001  max mem: 14938
[21:59:57.383568] Test:  [260/345]  eta: 0:00:17  loss: 0.6940 (0.6895)  time: 0.2083  data: 0.0001  max mem: 14938
[21:59:59.470921] Test:  [270/345]  eta: 0:00:15  loss: 0.6921 (0.6895)  time: 0.2086  data: 0.0001  max mem: 14938
[22:00:01.565891] Test:  [280/345]  eta: 0:00:13  loss: 0.6894 (0.6896)  time: 0.2091  data: 0.0001  max mem: 14938
[22:00:03.665473] Test:  [290/345]  eta: 0:00:11  loss: 0.6929 (0.6897)  time: 0.2097  data: 0.0001  max mem: 14938
[22:00:05.768608] Test:  [300/345]  eta: 0:00:09  loss: 0.6876 (0.6895)  time: 0.2101  data: 0.0001  max mem: 14938
[22:00:07.879441] Test:  [310/345]  eta: 0:00:07  loss: 0.6862 (0.6895)  time: 0.2106  data: 0.0001  max mem: 14938
[22:00:09.994353] Test:  [320/345]  eta: 0:00:05  loss: 0.6918 (0.6895)  time: 0.2112  data: 0.0001  max mem: 14938
[22:00:12.116237] Test:  [330/345]  eta: 0:00:03  loss: 0.6900 (0.6893)  time: 0.2118  data: 0.0001  max mem: 14938
[22:00:14.239987] Test:  [340/345]  eta: 0:00:01  loss: 0.6858 (0.6893)  time: 0.2122  data: 0.0001  max mem: 14938
[22:00:15.090668] Test:  [344/345]  eta: 0:00:00  loss: 0.6858 (0.6893)  time: 0.2123  data: 0.0001  max mem: 14938
[22:00:15.155549] Test: Total time: 0:01:10 (0.2053 s / it)
[22:00:32.171422] Test:  [ 0/57]  eta: 0:00:32  loss: 0.8629 (0.8629)  time: 0.5755  data: 0.3803  max mem: 14938
[22:00:34.097223] Test:  [10/57]  eta: 0:00:10  loss: 0.8767 (0.8811)  time: 0.2273  data: 0.0346  max mem: 14938
[22:00:36.031524] Test:  [20/57]  eta: 0:00:07  loss: 0.8767 (0.8673)  time: 0.1929  data: 0.0001  max mem: 14938
[22:00:37.971517] Test:  [30/57]  eta: 0:00:05  loss: 0.7517 (0.8245)  time: 0.1937  data: 0.0001  max mem: 14938
[22:00:39.921640] Test:  [40/57]  eta: 0:00:03  loss: 0.7358 (0.8028)  time: 0.1944  data: 0.0001  max mem: 14938
[22:00:41.873360] Test:  [50/57]  eta: 0:00:01  loss: 0.7350 (0.7955)  time: 0.1950  data: 0.0001  max mem: 14938
[22:00:42.937190] Test:  [56/57]  eta: 0:00:00  loss: 0.7552 (0.8020)  time: 0.1898  data: 0.0001  max mem: 14938
[22:00:42.997759] Test: Total time: 0:00:11 (0.2000 s / it)
[22:00:45.962711] Dice score of the network on the train images: 0.729394, val images: 0.772371
[22:00:45.962902] saving best_dice_model_0 @ epoch 39
[22:00:47.083539] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:00:48.186397] Epoch: [40]  [  0/345]  eta: 0:06:20  lr: 0.000031  loss: 0.7329 (0.7329)  time: 1.1019  data: 0.3368  max mem: 14938
[22:01:03.238784] Epoch: [40]  [ 20/345]  eta: 0:04:09  lr: 0.000031  loss: 0.7125 (0.7119)  time: 0.7526  data: 0.0001  max mem: 14938
[22:01:18.359863] Epoch: [40]  [ 40/345]  eta: 0:03:52  lr: 0.000031  loss: 0.7142 (0.7125)  time: 0.7560  data: 0.0001  max mem: 14938
[22:01:33.524319] Epoch: [40]  [ 60/345]  eta: 0:03:36  lr: 0.000030  loss: 0.7163 (0.7140)  time: 0.7582  data: 0.0001  max mem: 14938
[22:01:48.719980] Epoch: [40]  [ 80/345]  eta: 0:03:21  lr: 0.000030  loss: 0.7126 (0.7135)  time: 0.7597  data: 0.0001  max mem: 14938
[22:02:03.917316] Epoch: [40]  [100/345]  eta: 0:03:06  lr: 0.000030  loss: 0.7057 (0.7130)  time: 0.7598  data: 0.0001  max mem: 14938
[22:02:19.109602] Epoch: [40]  [120/345]  eta: 0:02:51  lr: 0.000029  loss: 0.7096 (0.7125)  time: 0.7596  data: 0.0001  max mem: 14938
[22:02:34.302318] Epoch: [40]  [140/345]  eta: 0:02:35  lr: 0.000029  loss: 0.7174 (0.7131)  time: 0.7596  data: 0.0001  max mem: 14938
[22:02:49.493833] Epoch: [40]  [160/345]  eta: 0:02:20  lr: 0.000029  loss: 0.7099 (0.7127)  time: 0.7595  data: 0.0001  max mem: 14938
[22:03:04.693999] Epoch: [40]  [180/345]  eta: 0:02:05  lr: 0.000028  loss: 0.7073 (0.7125)  time: 0.7600  data: 0.0001  max mem: 14938
[22:03:19.882917] Epoch: [40]  [200/345]  eta: 0:01:50  lr: 0.000028  loss: 0.7058 (0.7121)  time: 0.7594  data: 0.0001  max mem: 14938
[22:03:35.056435] Epoch: [40]  [220/345]  eta: 0:01:35  lr: 0.000028  loss: 0.7096 (0.7122)  time: 0.7586  data: 0.0001  max mem: 14938
[22:03:50.238745] Epoch: [40]  [240/345]  eta: 0:01:19  lr: 0.000027  loss: 0.7082 (0.7119)  time: 0.7591  data: 0.0001  max mem: 14938
[22:04:05.438114] Epoch: [40]  [260/345]  eta: 0:01:04  lr: 0.000027  loss: 0.7117 (0.7120)  time: 0.7599  data: 0.0001  max mem: 14938
[22:04:20.629773] Epoch: [40]  [280/345]  eta: 0:00:49  lr: 0.000027  loss: 0.7040 (0.7115)  time: 0.7595  data: 0.0001  max mem: 14938
[22:04:35.806923] Epoch: [40]  [300/345]  eta: 0:00:34  lr: 0.000026  loss: 0.7074 (0.7111)  time: 0.7588  data: 0.0001  max mem: 14938
[22:04:50.967201] Epoch: [40]  [320/345]  eta: 0:00:18  lr: 0.000026  loss: 0.7114 (0.7113)  time: 0.7580  data: 0.0001  max mem: 14938
[22:05:06.127583] Epoch: [40]  [340/345]  eta: 0:00:03  lr: 0.000026  loss: 0.7138 (0.7115)  time: 0.7580  data: 0.0001  max mem: 14938
[22:05:09.158613] Epoch: [40]  [344/345]  eta: 0:00:00  lr: 0.000026  loss: 0.7099 (0.7115)  time: 0.7578  data: 0.0001  max mem: 14938
[22:05:09.223335] Epoch: [40] Total time: 0:04:22 (0.7598 s / it)
[22:05:09.223976] Averaged stats: lr: 0.000026  loss: 0.7099 (0.7115)
[22:05:09.822801] Test:  [  0/345]  eta: 0:03:25  loss: 0.6872 (0.6872)  time: 0.5945  data: 0.3955  max mem: 14938
[22:05:11.777071] Test:  [ 10/345]  eta: 0:01:17  loss: 0.6877 (0.6897)  time: 0.2316  data: 0.0360  max mem: 14938
[22:05:13.739010] Test:  [ 20/345]  eta: 0:01:09  loss: 0.6877 (0.6886)  time: 0.1957  data: 0.0001  max mem: 14938
[22:05:15.703056] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6811 (0.6857)  time: 0.1962  data: 0.0001  max mem: 14938
[22:05:17.675340] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6780 (0.6840)  time: 0.1967  data: 0.0001  max mem: 14938
[22:05:19.654046] Test:  [ 50/345]  eta: 0:01:00  loss: 0.6844 (0.6847)  time: 0.1975  data: 0.0001  max mem: 14938
[22:05:21.636541] Test:  [ 60/345]  eta: 0:00:57  loss: 0.6848 (0.6848)  time: 0.1980  data: 0.0001  max mem: 14938
[22:05:23.621578] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6864 (0.6853)  time: 0.1983  data: 0.0001  max mem: 14938
[22:05:25.613751] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6864 (0.6854)  time: 0.1988  data: 0.0001  max mem: 14938
[22:05:27.610024] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6847 (0.6848)  time: 0.1994  data: 0.0001  max mem: 14938
[22:05:29.610879] Test:  [100/345]  eta: 0:00:49  loss: 0.6851 (0.6852)  time: 0.1998  data: 0.0001  max mem: 14938
[22:05:31.617028] Test:  [110/345]  eta: 0:00:47  loss: 0.6821 (0.6849)  time: 0.2003  data: 0.0001  max mem: 14938
[22:05:33.626587] Test:  [120/345]  eta: 0:00:45  loss: 0.6788 (0.6847)  time: 0.2007  data: 0.0001  max mem: 14938
[22:05:35.642134] Test:  [130/345]  eta: 0:00:43  loss: 0.6790 (0.6844)  time: 0.2012  data: 0.0001  max mem: 14938
[22:05:37.662441] Test:  [140/345]  eta: 0:00:41  loss: 0.6806 (0.6844)  time: 0.2017  data: 0.0001  max mem: 14938
[22:05:39.690329] Test:  [150/345]  eta: 0:00:39  loss: 0.6900 (0.6849)  time: 0.2023  data: 0.0001  max mem: 14938
[22:05:41.721720] Test:  [160/345]  eta: 0:00:37  loss: 0.6900 (0.6849)  time: 0.2029  data: 0.0001  max mem: 14938
[22:05:43.759811] Test:  [170/345]  eta: 0:00:35  loss: 0.6869 (0.6850)  time: 0.2034  data: 0.0001  max mem: 14938
[22:05:45.801448] Test:  [180/345]  eta: 0:00:33  loss: 0.6877 (0.6850)  time: 0.2039  data: 0.0001  max mem: 14938
[22:05:47.847747] Test:  [190/345]  eta: 0:00:31  loss: 0.6826 (0.6850)  time: 0.2043  data: 0.0001  max mem: 14938
[22:05:49.899197] Test:  [200/345]  eta: 0:00:29  loss: 0.6885 (0.6855)  time: 0.2048  data: 0.0001  max mem: 14938
[22:05:51.960261] Test:  [210/345]  eta: 0:00:27  loss: 0.6888 (0.6858)  time: 0.2056  data: 0.0001  max mem: 14938
[22:05:54.025058] Test:  [220/345]  eta: 0:00:25  loss: 0.6874 (0.6858)  time: 0.2062  data: 0.0001  max mem: 14938
[22:05:56.094230] Test:  [230/345]  eta: 0:00:23  loss: 0.6868 (0.6859)  time: 0.2066  data: 0.0001  max mem: 14938
[22:05:58.168645] Test:  [240/345]  eta: 0:00:21  loss: 0.6862 (0.6861)  time: 0.2071  data: 0.0001  max mem: 14938
[22:06:00.245869] Test:  [250/345]  eta: 0:00:19  loss: 0.6849 (0.6863)  time: 0.2075  data: 0.0001  max mem: 14938
[22:06:02.328632] Test:  [260/345]  eta: 0:00:17  loss: 0.6825 (0.6862)  time: 0.2079  data: 0.0001  max mem: 14938
[22:06:04.416616] Test:  [270/345]  eta: 0:00:15  loss: 0.6804 (0.6862)  time: 0.2085  data: 0.0001  max mem: 14938
[22:06:06.509075] Test:  [280/345]  eta: 0:00:13  loss: 0.6892 (0.6862)  time: 0.2090  data: 0.0001  max mem: 14938
[22:06:08.608924] Test:  [290/345]  eta: 0:00:11  loss: 0.6884 (0.6864)  time: 0.2096  data: 0.0001  max mem: 14938
[22:06:10.712095] Test:  [300/345]  eta: 0:00:09  loss: 0.6882 (0.6863)  time: 0.2101  data: 0.0001  max mem: 14938
[22:06:12.823839] Test:  [310/345]  eta: 0:00:07  loss: 0.6869 (0.6864)  time: 0.2107  data: 0.0001  max mem: 14938
[22:06:14.937533] Test:  [320/345]  eta: 0:00:05  loss: 0.6895 (0.6866)  time: 0.2112  data: 0.0001  max mem: 14938
[22:06:17.057928] Test:  [330/345]  eta: 0:00:03  loss: 0.6887 (0.6867)  time: 0.2116  data: 0.0001  max mem: 14938
[22:06:19.181691] Test:  [340/345]  eta: 0:00:01  loss: 0.6880 (0.6868)  time: 0.2122  data: 0.0001  max mem: 14938
[22:06:20.032134] Test:  [344/345]  eta: 0:00:00  loss: 0.6852 (0.6867)  time: 0.2123  data: 0.0001  max mem: 14938
[22:06:20.098304] Test: Total time: 0:01:10 (0.2054 s / it)
[22:06:36.856919] Test:  [ 0/57]  eta: 0:00:30  loss: 0.8624 (0.8624)  time: 0.5278  data: 0.3328  max mem: 14938
[22:06:38.784219] Test:  [10/57]  eta: 0:00:10  loss: 0.8797 (0.8854)  time: 0.2231  data: 0.0303  max mem: 14938
[22:06:40.719904] Test:  [20/57]  eta: 0:00:07  loss: 0.8797 (0.8727)  time: 0.1931  data: 0.0001  max mem: 14938
[22:06:42.661633] Test:  [30/57]  eta: 0:00:05  loss: 0.7544 (0.8299)  time: 0.1938  data: 0.0001  max mem: 14938
[22:06:44.608226] Test:  [40/57]  eta: 0:00:03  loss: 0.7455 (0.8088)  time: 0.1944  data: 0.0001  max mem: 14938
[22:06:46.563291] Test:  [50/57]  eta: 0:00:01  loss: 0.7423 (0.8011)  time: 0.1950  data: 0.0001  max mem: 14938
[22:06:47.627028] Test:  [56/57]  eta: 0:00:00  loss: 0.7549 (0.8072)  time: 0.1899  data: 0.0001  max mem: 14938
[22:06:47.690066] Test: Total time: 0:00:11 (0.1993 s / it)
[22:06:50.585092] Dice score of the network on the train images: 0.736288, val images: 0.767123
[22:06:50.589752] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:06:51.713007] Epoch: [41]  [  0/345]  eta: 0:06:27  lr: 0.000026  loss: 0.6998 (0.6998)  time: 1.1221  data: 0.3583  max mem: 14938
[22:07:06.783749] Epoch: [41]  [ 20/345]  eta: 0:04:10  lr: 0.000025  loss: 0.7039 (0.7041)  time: 0.7535  data: 0.0001  max mem: 14938
[22:07:21.905679] Epoch: [41]  [ 40/345]  eta: 0:03:52  lr: 0.000025  loss: 0.7142 (0.7088)  time: 0.7560  data: 0.0001  max mem: 14938
[22:07:37.080924] Epoch: [41]  [ 60/345]  eta: 0:03:37  lr: 0.000025  loss: 0.7105 (0.7100)  time: 0.7587  data: 0.0001  max mem: 14938
[22:07:52.291009] Epoch: [41]  [ 80/345]  eta: 0:03:21  lr: 0.000025  loss: 0.7090 (0.7109)  time: 0.7605  data: 0.0001  max mem: 14938
[22:08:07.517537] Epoch: [41]  [100/345]  eta: 0:03:06  lr: 0.000024  loss: 0.7108 (0.7112)  time: 0.7613  data: 0.0001  max mem: 14938
[22:08:22.710450] Epoch: [41]  [120/345]  eta: 0:02:51  lr: 0.000024  loss: 0.7049 (0.7105)  time: 0.7596  data: 0.0001  max mem: 14938
[22:08:37.910921] Epoch: [41]  [140/345]  eta: 0:02:36  lr: 0.000024  loss: 0.7070 (0.7104)  time: 0.7600  data: 0.0001  max mem: 14938
[22:08:53.123371] Epoch: [41]  [160/345]  eta: 0:02:20  lr: 0.000023  loss: 0.7068 (0.7103)  time: 0.7606  data: 0.0001  max mem: 14938
[22:09:08.319977] Epoch: [41]  [180/345]  eta: 0:02:05  lr: 0.000023  loss: 0.7069 (0.7100)  time: 0.7598  data: 0.0001  max mem: 14938

[22:09:23.515333] Epoch: [41]  [200/345]  eta: 0:01:50  lr: 0.000023  loss: 0.7043 (0.7098)  time: 0.7597  data: 0.0001  max mem: 14938
[22:09:38.688359] Epoch: [41]  [220/345]  eta: 0:01:35  lr: 0.000022  loss: 0.7077 (0.7099)  time: 0.7586  data: 0.0001  max mem: 14938
[22:09:53.881847] Epoch: [41]  [240/345]  eta: 0:01:19  lr: 0.000022  loss: 0.7093 (0.7099)  time: 0.7596  data: 0.0001  max mem: 14938
[22:10:09.068031] Epoch: [41]  [260/345]  eta: 0:01:04  lr: 0.000022  loss: 0.7146 (0.7104)  time: 0.7593  data: 0.0001  max mem: 14938
[22:10:24.345995] Epoch: [41]  [280/345]  eta: 0:00:49  lr: 0.000022  loss: 0.7101 (0.7104)  time: 0.7639  data: 0.0001  max mem: 14938
[22:10:39.525942] Epoch: [41]  [300/345]  eta: 0:00:34  lr: 0.000021  loss: 0.7124 (0.7106)  time: 0.7590  data: 0.0001  max mem: 14938
[22:10:54.715317] Epoch: [41]  [320/345]  eta: 0:00:19  lr: 0.000021  loss: 0.7035 (0.7105)  time: 0.7594  data: 0.0001  max mem: 14938
[22:11:09.879216] Epoch: [41]  [340/345]  eta: 0:00:03  lr: 0.000021  loss: 0.7083 (0.7104)  time: 0.7582  data: 0.0001  max mem: 14938
[22:11:12.912360] Epoch: [41]  [344/345]  eta: 0:00:00  lr: 0.000021  loss: 0.7083 (0.7104)  time: 0.7584  data: 0.0001  max mem: 14938
[22:11:12.983954] Epoch: [41] Total time: 0:04:22 (0.7606 s / it)
[22:11:12.984234] Averaged stats: lr: 0.000021  loss: 0.7083 (0.7104)
[22:11:13.554449] Test:  [  0/345]  eta: 0:03:14  loss: 0.6765 (0.6765)  time: 0.5646  data: 0.3660  max mem: 14938
[22:11:15.509132] Test:  [ 10/345]  eta: 0:01:16  loss: 0.6904 (0.6861)  time: 0.2290  data: 0.0334  max mem: 14938
[22:11:17.470145] Test:  [ 20/345]  eta: 0:01:09  loss: 0.6911 (0.6893)  time: 0.1957  data: 0.0001  max mem: 14938
[22:11:19.434460] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6909 (0.6883)  time: 0.1962  data: 0.0001  max mem: 14938
[22:11:21.403780] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6802 (0.6870)  time: 0.1966  data: 0.0001  max mem: 14938
[22:11:23.380648] Test:  [ 50/345]  eta: 0:01:00  loss: 0.6792 (0.6851)  time: 0.1972  data: 0.0001  max mem: 14938
[22:11:25.362990] Test:  [ 60/345]  eta: 0:00:57  loss: 0.6787 (0.6842)  time: 0.1979  data: 0.0001  max mem: 14938
[22:11:27.350845] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6817 (0.6846)  time: 0.1984  data: 0.0001  max mem: 14938
[22:11:29.340266] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6847 (0.6849)  time: 0.1988  data: 0.0001  max mem: 14938
[22:11:31.340317] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6828 (0.6846)  time: 0.1994  data: 0.0001  max mem: 14938
[22:11:33.343349] Test:  [100/345]  eta: 0:00:49  loss: 0.6817 (0.6848)  time: 0.2001  data: 0.0001  max mem: 14938
[22:11:35.348459] Test:  [110/345]  eta: 0:00:47  loss: 0.6855 (0.6851)  time: 0.2003  data: 0.0001  max mem: 14938
[22:11:37.361156] Test:  [120/345]  eta: 0:00:45  loss: 0.6855 (0.6852)  time: 0.2008  data: 0.0001  max mem: 14938
[22:11:39.377165] Test:  [130/345]  eta: 0:00:43  loss: 0.6863 (0.6855)  time: 0.2014  data: 0.0001  max mem: 14938
[22:11:41.399803] Test:  [140/345]  eta: 0:00:41  loss: 0.6863 (0.6858)  time: 0.2019  data: 0.0001  max mem: 14938
[22:11:43.426344] Test:  [150/345]  eta: 0:00:39  loss: 0.6855 (0.6857)  time: 0.2024  data: 0.0001  max mem: 14938
[22:11:45.457572] Test:  [160/345]  eta: 0:00:37  loss: 0.6803 (0.6854)  time: 0.2028  data: 0.0001  max mem: 14938
[22:11:47.494498] Test:  [170/345]  eta: 0:00:35  loss: 0.6803 (0.6851)  time: 0.2033  data: 0.0001  max mem: 14938
[22:11:49.535598] Test:  [180/345]  eta: 0:00:33  loss: 0.6841 (0.6852)  time: 0.2038  data: 0.0001  max mem: 14938
[22:11:51.582668] Test:  [190/345]  eta: 0:00:31  loss: 0.6862 (0.6851)  time: 0.2043  data: 0.0001  max mem: 14938
[22:11:53.635783] Test:  [200/345]  eta: 0:00:29  loss: 0.6871 (0.6852)  time: 0.2050  data: 0.0001  max mem: 14938
[22:11:55.694819] Test:  [210/345]  eta: 0:00:27  loss: 0.6806 (0.6849)  time: 0.2056  data: 0.0001  max mem: 14938
[22:11:57.758712] Test:  [220/345]  eta: 0:00:25  loss: 0.6785 (0.6848)  time: 0.2061  data: 0.0001  max mem: 14938
[22:11:59.827105] Test:  [230/345]  eta: 0:00:23  loss: 0.6822 (0.6848)  time: 0.2066  data: 0.0001  max mem: 14938
[22:12:01.901428] Test:  [240/345]  eta: 0:00:21  loss: 0.6857 (0.6851)  time: 0.2071  data: 0.0001  max mem: 14938
[22:12:03.981570] Test:  [250/345]  eta: 0:00:19  loss: 0.6862 (0.6852)  time: 0.2077  data: 0.0001  max mem: 14938
[22:12:06.063067] Test:  [260/345]  eta: 0:00:17  loss: 0.6811 (0.6850)  time: 0.2080  data: 0.0001  max mem: 14938
[22:12:08.151374] Test:  [270/345]  eta: 0:00:15  loss: 0.6776 (0.6851)  time: 0.2084  data: 0.0001  max mem: 14938
[22:12:10.246405] Test:  [280/345]  eta: 0:00:13  loss: 0.6811 (0.6851)  time: 0.2091  data: 0.0001  max mem: 14938
[22:12:12.345343] Test:  [290/345]  eta: 0:00:11  loss: 0.6834 (0.6851)  time: 0.2096  data: 0.0001  max mem: 14938
[22:12:14.450983] Test:  [300/345]  eta: 0:00:09  loss: 0.6844 (0.6851)  time: 0.2102  data: 0.0001  max mem: 14938
[22:12:16.563715] Test:  [310/345]  eta: 0:00:07  loss: 0.6830 (0.6851)  time: 0.2109  data: 0.0001  max mem: 14938
[22:12:18.678786] Test:  [320/345]  eta: 0:00:05  loss: 0.6824 (0.6850)  time: 0.2113  data: 0.0001  max mem: 14938
[22:12:20.799761] Test:  [330/345]  eta: 0:00:03  loss: 0.6845 (0.6851)  time: 0.2117  data: 0.0001  max mem: 14938
[22:12:22.922961] Test:  [340/345]  eta: 0:00:01  loss: 0.6848 (0.6851)  time: 0.2122  data: 0.0001  max mem: 14938
[22:12:23.773531] Test:  [344/345]  eta: 0:00:00  loss: 0.6854 (0.6852)  time: 0.2123  data: 0.0001  max mem: 14938
[22:12:23.842807] Test: Total time: 0:01:10 (0.2054 s / it)
[22:12:40.887130] Test:  [ 0/57]  eta: 0:00:30  loss: 0.8577 (0.8577)  time: 0.5292  data: 0.3332  max mem: 14938
[22:12:42.812322] Test:  [10/57]  eta: 0:00:10  loss: 0.8844 (0.8855)  time: 0.2231  data: 0.0304  max mem: 14938
[22:12:44.748385] Test:  [20/57]  eta: 0:00:07  loss: 0.8844 (0.8723)  time: 0.1930  data: 0.0001  max mem: 14938
[22:12:46.690415] Test:  [30/57]  eta: 0:00:05  loss: 0.7557 (0.8295)  time: 0.1938  data: 0.0001  max mem: 14938
[22:12:48.639056] Test:  [40/57]  eta: 0:00:03  loss: 0.7454 (0.8085)  time: 0.1945  data: 0.0001  max mem: 14938
[22:12:50.591502] Test:  [50/57]  eta: 0:00:01  loss: 0.7450 (0.8008)  time: 0.1950  data: 0.0001  max mem: 14938
[22:12:51.654019] Test:  [56/57]  eta: 0:00:00  loss: 0.7562 (0.8068)  time: 0.1897  data: 0.0000  max mem: 14938
[22:12:51.721306] Test: Total time: 0:00:11 (0.1994 s / it)
[22:12:54.685288] Dice score of the network on the train images: 0.735453, val images: 0.765997
[22:12:54.689345] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft

[22:12:55.786558] Epoch: [42]  [  0/345]  eta: 0:06:18  lr: 0.000021  loss: 0.6944 (0.6944)  time: 1.0964  data: 0.3334  max mem: 14938
[22:13:10.833229] Epoch: [42]  [ 20/345]  eta: 0:04:09  lr: 0.000020  loss: 0.7045 (0.7055)  time: 0.7523  data: 0.0001  max mem: 14938
[22:13:25.961797] Epoch: [42]  [ 40/345]  eta: 0:03:52  lr: 0.000020  loss: 0.7065 (0.7072)  time: 0.7564  data: 0.0001  max mem: 14938
[22:13:41.128578] Epoch: [42]  [ 60/345]  eta: 0:03:36  lr: 0.000020  loss: 0.7058 (0.7073)  time: 0.7583  data: 0.0001  max mem: 14938
[22:13:56.328014] Epoch: [42]  [ 80/345]  eta: 0:03:21  lr: 0.000020  loss: 0.7120 (0.7084)  time: 0.7599  data: 0.0001  max mem: 14938
[22:14:11.541597] Epoch: [42]  [100/345]  eta: 0:03:06  lr: 0.000019  loss: 0.7064 (0.7088)  time: 0.7606  data: 0.0001  max mem: 14938
[22:14:26.756807] Epoch: [42]  [120/345]  eta: 0:02:51  lr: 0.000019  loss: 0.7117 (0.7091)  time: 0.7607  data: 0.0001  max mem: 14938
[22:14:41.950367] Epoch: [42]  [140/345]  eta: 0:02:35  lr: 0.000019  loss: 0.7025 (0.7090)  time: 0.7596  data: 0.0001  max mem: 14938
[22:14:57.143996] Epoch: [42]  [160/345]  eta: 0:02:20  lr: 0.000018  loss: 0.7064 (0.7088)  time: 0.7596  data: 0.0001  max mem: 14938
[22:15:12.338416] Epoch: [42]  [180/345]  eta: 0:02:05  lr: 0.000018  loss: 0.7011 (0.7083)  time: 0.7597  data: 0.0001  max mem: 14938
[22:15:27.534863] Epoch: [42]  [200/345]  eta: 0:01:50  lr: 0.000018  loss: 0.7130 (0.7088)  time: 0.7598  data: 0.0001  max mem: 14938
[22:15:42.720356] Epoch: [42]  [220/345]  eta: 0:01:35  lr: 0.000018  loss: 0.7049 (0.7087)  time: 0.7592  data: 0.0001  max mem: 14938
[22:15:57.902325] Epoch: [42]  [240/345]  eta: 0:01:19  lr: 0.000017  loss: 0.7089 (0.7088)  time: 0.7591  data: 0.0001  max mem: 14938
[22:16:13.097925] Epoch: [42]  [260/345]  eta: 0:01:04  lr: 0.000017  loss: 0.7075 (0.7089)  time: 0.7597  data: 0.0001  max mem: 14938
[22:16:28.278922] Epoch: [42]  [280/345]  eta: 0:00:49  lr: 0.000017  loss: 0.7032 (0.7086)  time: 0.7590  data: 0.0001  max mem: 14938
[22:16:43.447066] Epoch: [42]  [300/345]  eta: 0:00:34  lr: 0.000017  loss: 0.7067 (0.7087)  time: 0.7584  data: 0.0001  max mem: 14938
[22:16:58.610979] Epoch: [42]  [320/345]  eta: 0:00:18  lr: 0.000016  loss: 0.7060 (0.7089)  time: 0.7582  data: 0.0001  max mem: 14938
[22:17:13.759870] Epoch: [42]  [340/345]  eta: 0:00:03  lr: 0.000016  loss: 0.7010 (0.7087)  time: 0.7574  data: 0.0001  max mem: 14938
[22:17:16.790027] Epoch: [42]  [344/345]  eta: 0:00:00  lr: 0.000016  loss: 0.7010 (0.7088)  time: 0.7574  data: 0.0001  max mem: 14938
[22:17:16.864039] Epoch: [42] Total time: 0:04:22 (0.7599 s / it)
[22:17:16.864526] Averaged stats: lr: 0.000016  loss: 0.7010 (0.7088)
[22:17:17.404158] Test:  [  0/345]  eta: 0:03:04  loss: 0.7063 (0.7063)  time: 0.5345  data: 0.3360  max mem: 14938
[22:17:19.360047] Test:  [ 10/345]  eta: 0:01:15  loss: 0.6899 (0.6886)  time: 0.2263  data: 0.0306  max mem: 14938
[22:17:21.321811] Test:  [ 20/345]  eta: 0:01:08  loss: 0.6811 (0.6846)  time: 0.1958  data: 0.0001  max mem: 14938
[22:17:23.286105] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6811 (0.6840)  time: 0.1962  data: 0.0001  max mem: 14938
[22:17:25.259430] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6839 (0.6843)  time: 0.1968  data: 0.0001  max mem: 14938
[22:17:27.237177] Test:  [ 50/345]  eta: 0:00:59  loss: 0.6873 (0.6854)  time: 0.1975  data: 0.0001  max mem: 14938
[22:17:29.220053] Test:  [ 60/345]  eta: 0:00:57  loss: 0.6847 (0.6850)  time: 0.1980  data: 0.0001  max mem: 14938
[22:17:31.206765] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6829 (0.6852)  time: 0.1984  data: 0.0001  max mem: 14938
[22:17:33.198685] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6808 (0.6846)  time: 0.1989  data: 0.0001  max mem: 14938
[22:17:35.195877] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6789 (0.6843)  time: 0.1994  data: 0.0001  max mem: 14938
[22:17:37.198301] Test:  [100/345]  eta: 0:00:49  loss: 0.6787 (0.6844)  time: 0.1999  data: 0.0001  max mem: 14938
[22:17:39.205464] Test:  [110/345]  eta: 0:00:47  loss: 0.6795 (0.6847)  time: 0.2004  data: 0.0001  max mem: 14938
[22:17:41.216948] Test:  [120/345]  eta: 0:00:45  loss: 0.6838 (0.6843)  time: 0.2009  data: 0.0001  max mem: 14938
[22:17:43.232866] Test:  [130/345]  eta: 0:00:43  loss: 0.6838 (0.6846)  time: 0.2013  data: 0.0001  max mem: 14938
[22:17:45.256435] Test:  [140/345]  eta: 0:00:41  loss: 0.6856 (0.6846)  time: 0.2019  data: 0.0001  max mem: 14938
[22:17:47.282734] Test:  [150/345]  eta: 0:00:39  loss: 0.6818 (0.6841)  time: 0.2024  data: 0.0001  max mem: 14938
[22:17:49.314287] Test:  [160/345]  eta: 0:00:37  loss: 0.6775 (0.6840)  time: 0.2028  data: 0.0001  max mem: 14938
[22:17:51.351522] Test:  [170/345]  eta: 0:00:35  loss: 0.6800 (0.6841)  time: 0.2034  data: 0.0001  max mem: 14938
[22:17:53.394033] Test:  [180/345]  eta: 0:00:33  loss: 0.6844 (0.6842)  time: 0.2039  data: 0.0001  max mem: 14938
[22:17:55.441569] Test:  [190/345]  eta: 0:00:31  loss: 0.6835 (0.6844)  time: 0.2044  data: 0.0001  max mem: 14938
[22:17:57.494636] Test:  [200/345]  eta: 0:00:29  loss: 0.6849 (0.6844)  time: 0.2050  data: 0.0001  max mem: 14938
[22:17:59.553327] Test:  [210/345]  eta: 0:00:27  loss: 0.6803 (0.6843)  time: 0.2055  data: 0.0001  max mem: 14938
[22:18:01.616660] Test:  [220/345]  eta: 0:00:25  loss: 0.6810 (0.6845)  time: 0.2060  data: 0.0001  max mem: 14938
[22:18:03.685408] Test:  [230/345]  eta: 0:00:23  loss: 0.6873 (0.6846)  time: 0.2065  data: 0.0001  max mem: 14938
[22:18:05.758768] Test:  [240/345]  eta: 0:00:21  loss: 0.6825 (0.6844)  time: 0.2070  data: 0.0001  max mem: 14938
[22:18:07.836225] Test:  [250/345]  eta: 0:00:19  loss: 0.6856 (0.6846)  time: 0.2075  data: 0.0001  max mem: 14938
[22:18:09.920936] Test:  [260/345]  eta: 0:00:17  loss: 0.6856 (0.6843)  time: 0.2080  data: 0.0001  max mem: 14938
[22:18:12.011283] Test:  [270/345]  eta: 0:00:15  loss: 0.6793 (0.6843)  time: 0.2087  data: 0.0001  max mem: 14938
[22:18:14.104934] Test:  [280/345]  eta: 0:00:13  loss: 0.6838 (0.6845)  time: 0.2091  data: 0.0001  max mem: 14938
[22:18:16.202697] Test:  [290/345]  eta: 0:00:11  loss: 0.6839 (0.6845)  time: 0.2095  data: 0.0001  max mem: 14938
[22:18:18.306356] Test:  [300/345]  eta: 0:00:09  loss: 0.6811 (0.6844)  time: 0.2100  data: 0.0001  max mem: 14938
[22:18:20.416083] Test:  [310/345]  eta: 0:00:07  loss: 0.6827 (0.6844)  time: 0.2106  data: 0.0001  max mem: 14938
[22:18:22.532566] Test:  [320/345]  eta: 0:00:05  loss: 0.6827 (0.6843)  time: 0.2113  data: 0.0001  max mem: 14938
[22:18:24.652216] Test:  [330/345]  eta: 0:00:03  loss: 0.6808 (0.6843)  time: 0.2117  data: 0.0001  max mem: 14938
[22:18:26.775537] Test:  [340/345]  eta: 0:00:01  loss: 0.6839 (0.6844)  time: 0.2121  data: 0.0001  max mem: 14938
[22:18:27.627659] Test:  [344/345]  eta: 0:00:00  loss: 0.6839 (0.6843)  time: 0.2123  data: 0.0001  max mem: 14938
[22:18:27.680170] Test: Total time: 0:01:10 (0.2053 s / it)
[22:18:44.567467] Test:  [ 0/57]  eta: 0:00:30  loss: 0.8613 (0.8613)  time: 0.5300  data: 0.3342  max mem: 14938
[22:18:46.495224] Test:  [10/57]  eta: 0:00:10  loss: 0.8812 (0.8860)  time: 0.2234  data: 0.0305  max mem: 14938
[22:18:48.429600] Test:  [20/57]  eta: 0:00:07  loss: 0.8812 (0.8729)  time: 0.1930  data: 0.0001  max mem: 14938
[22:18:50.372196] Test:  [30/57]  eta: 0:00:05  loss: 0.7558 (0.8299)  time: 0.1938  data: 0.0001  max mem: 14938
[22:18:52.320604] Test:  [40/57]  eta: 0:00:03  loss: 0.7441 (0.8088)  time: 0.1945  data: 0.0001  max mem: 14938
[22:18:54.274416] Test:  [50/57]  eta: 0:00:01  loss: 0.7422 (0.8013)  time: 0.1951  data: 0.0001  max mem: 14938
[22:18:55.336861] Test:  [56/57]  eta: 0:00:00  loss: 0.7579 (0.8073)  time: 0.1897  data: 0.0000  max mem: 14938
[22:18:55.400704] Test: Total time: 0:00:11 (0.1994 s / it)
[22:18:58.354744] Dice score of the network on the train images: 0.736559, val images: 0.765941
[22:18:58.358984] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:18:59.455223] Epoch: [43]  [  0/345]  eta: 0:06:17  lr: 0.000016  loss: 0.7036 (0.7036)  time: 1.0953  data: 0.3315  max mem: 14938
[22:19:14.510237] Epoch: [43]  [ 20/345]  eta: 0:04:09  lr: 0.000016  loss: 0.7074 (0.7076)  time: 0.7527  data: 0.0001  max mem: 14938
[22:19:29.623631] Epoch: [43]  [ 40/345]  eta: 0:03:52  lr: 0.000016  loss: 0.7107 (0.7078)  time: 0.7556  data: 0.0001  max mem: 14938
[22:19:44.792904] Epoch: [43]  [ 60/345]  eta: 0:03:36  lr: 0.000015  loss: 0.7071 (0.7083)  time: 0.7584  data: 0.0001  max mem: 14938
[22:19:59.993520] Epoch: [43]  [ 80/345]  eta: 0:03:21  lr: 0.000015  loss: 0.7069 (0.7080)  time: 0.7600  data: 0.0001  max mem: 14938
[22:20:15.213089] Epoch: [43]  [100/345]  eta: 0:03:06  lr: 0.000015  loss: 0.7022 (0.7075)  time: 0.7609  data: 0.0001  max mem: 14938
[22:20:30.421160] Epoch: [43]  [120/345]  eta: 0:02:51  lr: 0.000015  loss: 0.7055 (0.7074)  time: 0.7604  data: 0.0001  max mem: 14938
[22:20:45.643919] Epoch: [43]  [140/345]  eta: 0:02:35  lr: 0.000014  loss: 0.7048 (0.7072)  time: 0.7611  data: 0.0001  max mem: 14938

[22:21:00.857379] Epoch: [43]  [160/345]  eta: 0:02:20  lr: 0.000014  loss: 0.7101 (0.7076)  time: 0.7606  data: 0.0001  max mem: 14938
[22:21:16.183596] Epoch: [43]  [180/345]  eta: 0:02:05  lr: 0.000014  loss: 0.7048 (0.7077)  time: 0.7663  data: 0.0001  max mem: 14938
[22:21:31.376352] Epoch: [43]  [200/345]  eta: 0:01:50  lr: 0.000014  loss: 0.7047 (0.7076)  time: 0.7596  data: 0.0001  max mem: 14938
[22:21:46.570317] Epoch: [43]  [220/345]  eta: 0:01:35  lr: 0.000013  loss: 0.7076 (0.7075)  time: 0.7597  data: 0.0001  max mem: 14938
[22:22:01.760420] Epoch: [43]  [240/345]  eta: 0:01:19  lr: 0.000013  loss: 0.7049 (0.7075)  time: 0.7595  data: 0.0001  max mem: 14938
[22:22:16.960548] Epoch: [43]  [260/345]  eta: 0:01:04  lr: 0.000013  loss: 0.7017 (0.7074)  time: 0.7600  data: 0.0001  max mem: 14938
[22:22:32.152061] Epoch: [43]  [280/345]  eta: 0:00:49  lr: 0.000013  loss: 0.7095 (0.7076)  time: 0.7595  data: 0.0001  max mem: 14938
[22:22:47.340196] Epoch: [43]  [300/345]  eta: 0:00:34  lr: 0.000012  loss: 0.7088 (0.7079)  time: 0.7594  data: 0.0001  max mem: 14938
[22:23:02.503693] Epoch: [43]  [320/345]  eta: 0:00:19  lr: 0.000012  loss: 0.7103 (0.7081)  time: 0.7581  data: 0.0001  max mem: 14938
[22:23:17.681480] Epoch: [43]  [340/345]  eta: 0:00:03  lr: 0.000012  loss: 0.7044 (0.7080)  time: 0.7588  data: 0.0001  max mem: 14938
[22:23:20.714329] Epoch: [43]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 0.7073 (0.7080)  time: 0.7584  data: 0.0001  max mem: 14938
[22:23:20.784135] Epoch: [43] Total time: 0:04:22 (0.7607 s / it)
[22:23:20.784372] Averaged stats: lr: 0.000012  loss: 0.7073 (0.7080)
[22:23:21.393329] Test:  [  0/345]  eta: 0:03:28  loss: 0.6733 (0.6733)  time: 0.6038  data: 0.4051  max mem: 14938
[22:23:23.348124] Test:  [ 10/345]  eta: 0:01:17  loss: 0.6818 (0.6826)  time: 0.2325  data: 0.0369  max mem: 14938
[22:23:25.308880] Test:  [ 20/345]  eta: 0:01:09  loss: 0.6828 (0.6850)  time: 0.1957  data: 0.0001  max mem: 14938
[22:23:27.276655] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6803 (0.6833)  time: 0.1964  data: 0.0001  max mem: 14938
[22:23:29.246325] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6780 (0.6830)  time: 0.1968  data: 0.0001  max mem: 14938
[22:23:31.222560] Test:  [ 50/345]  eta: 0:01:00  loss: 0.6839 (0.6829)  time: 0.1972  data: 0.0001  max mem: 14938
[22:23:33.204530] Test:  [ 60/345]  eta: 0:00:57  loss: 0.6797 (0.6830)  time: 0.1979  data: 0.0001  max mem: 14938
[22:23:35.192095] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6797 (0.6830)  time: 0.1984  data: 0.0001  max mem: 14938
[22:23:37.182912] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6783 (0.6830)  time: 0.1989  data: 0.0001  max mem: 14938
[22:23:39.178376] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6783 (0.6826)  time: 0.1993  data: 0.0001  max mem: 14938
[22:23:41.179281] Test:  [100/345]  eta: 0:00:49  loss: 0.6822 (0.6830)  time: 0.1997  data: 0.0001  max mem: 14938
[22:23:43.187306] Test:  [110/345]  eta: 0:00:47  loss: 0.6847 (0.6834)  time: 0.2004  data: 0.0001  max mem: 14938
[22:23:45.196217] Test:  [120/345]  eta: 0:00:45  loss: 0.6902 (0.6837)  time: 0.2008  data: 0.0001  max mem: 14938
[22:23:47.213223] Test:  [130/345]  eta: 0:00:43  loss: 0.6842 (0.6835)  time: 0.2012  data: 0.0001  max mem: 14938
[22:23:49.235455] Test:  [140/345]  eta: 0:00:41  loss: 0.6812 (0.6834)  time: 0.2019  data: 0.0001  max mem: 14938
[22:23:51.264547] Test:  [150/345]  eta: 0:00:39  loss: 0.6827 (0.6837)  time: 0.2025  data: 0.0001  max mem: 14938
[22:23:53.296798] Test:  [160/345]  eta: 0:00:37  loss: 0.6816 (0.6833)  time: 0.2030  data: 0.0001  max mem: 14938
[22:23:55.336526] Test:  [170/345]  eta: 0:00:35  loss: 0.6805 (0.6838)  time: 0.2035  data: 0.0001  max mem: 14938
[22:23:57.378427] Test:  [180/345]  eta: 0:00:33  loss: 0.6825 (0.6837)  time: 0.2040  data: 0.0001  max mem: 14938
[22:23:59.424235] Test:  [190/345]  eta: 0:00:31  loss: 0.6791 (0.6834)  time: 0.2043  data: 0.0001  max mem: 14938
[22:24:01.475751] Test:  [200/345]  eta: 0:00:29  loss: 0.6812 (0.6835)  time: 0.2048  data: 0.0001  max mem: 14938
[22:24:03.532659] Test:  [210/345]  eta: 0:00:27  loss: 0.6813 (0.6834)  time: 0.2054  data: 0.0001  max mem: 14938
[22:24:05.593245] Test:  [220/345]  eta: 0:00:25  loss: 0.6810 (0.6834)  time: 0.2058  data: 0.0001  max mem: 14938
[22:24:07.663043] Test:  [230/345]  eta: 0:00:23  loss: 0.6778 (0.6834)  time: 0.2065  data: 0.0001  max mem: 14938
[22:24:09.742363] Test:  [240/345]  eta: 0:00:21  loss: 0.6758 (0.6832)  time: 0.2074  data: 0.0001  max mem: 14938
[22:24:11.821611] Test:  [250/345]  eta: 0:00:19  loss: 0.6802 (0.6833)  time: 0.2079  data: 0.0001  max mem: 14938
[22:24:13.906153] Test:  [260/345]  eta: 0:00:17  loss: 0.6880 (0.6835)  time: 0.2081  data: 0.0001  max mem: 14938
[22:24:15.993316] Test:  [270/345]  eta: 0:00:15  loss: 0.6854 (0.6833)  time: 0.2085  data: 0.0001  max mem: 14938
[22:24:18.088640] Test:  [280/345]  eta: 0:00:13  loss: 0.6820 (0.6835)  time: 0.2091  data: 0.0001  max mem: 14938
[22:24:20.188037] Test:  [290/345]  eta: 0:00:11  loss: 0.6836 (0.6835)  time: 0.2097  data: 0.0001  max mem: 14938
[22:24:22.292100] Test:  [300/345]  eta: 0:00:09  loss: 0.6813 (0.6835)  time: 0.2101  data: 0.0001  max mem: 14938
[22:24:24.401504] Test:  [310/345]  eta: 0:00:07  loss: 0.6812 (0.6835)  time: 0.2106  data: 0.0001  max mem: 14938
[22:24:26.519741] Test:  [320/345]  eta: 0:00:05  loss: 0.6815 (0.6835)  time: 0.2113  data: 0.0001  max mem: 14938
[22:24:28.639667] Test:  [330/345]  eta: 0:00:03  loss: 0.6823 (0.6835)  time: 0.2119  data: 0.0001  max mem: 14938
[22:24:30.763339] Test:  [340/345]  eta: 0:00:01  loss: 0.6823 (0.6835)  time: 0.2121  data: 0.0001  max mem: 14938
[22:24:31.614095] Test:  [344/345]  eta: 0:00:00  loss: 0.6819 (0.6834)  time: 0.2123  data: 0.0001  max mem: 14938
[22:24:31.677559] Test: Total time: 0:01:10 (0.2055 s / it)
[22:24:48.767129] Test:  [ 0/57]  eta: 0:00:32  loss: 0.8628 (0.8628)  time: 0.5643  data: 0.3678  max mem: 14938
[22:24:50.692682] Test:  [10/57]  eta: 0:00:10  loss: 0.8845 (0.8883)  time: 0.2263  data: 0.0335  max mem: 14938
[22:24:52.628720] Test:  [20/57]  eta: 0:00:07  loss: 0.8845 (0.8759)  time: 0.1930  data: 0.0001  max mem: 14938
[22:24:54.569973] Test:  [30/57]  eta: 0:00:05  loss: 0.7571 (0.8322)  time: 0.1938  data: 0.0001  max mem: 14938
[22:24:56.518750] Test:  [40/57]  eta: 0:00:03  loss: 0.7442 (0.8108)  time: 0.1944  data: 0.0001  max mem: 14938
[22:24:58.475110] Test:  [50/57]  eta: 0:00:01  loss: 0.7432 (0.8026)  time: 0.1952  data: 0.0001  max mem: 14938
[22:24:59.537059] Test:  [56/57]  eta: 0:00:00  loss: 0.7527 (0.8085)  time: 0.1899  data: 0.0001  max mem: 14938
[22:24:59.594275] Test: Total time: 0:00:11 (0.1999 s / it)
[22:25:02.494905] Dice score of the network on the train images: 0.737656, val images: 0.766145
[22:25:02.499583] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:25:03.600908] Epoch: [44]  [  0/345]  eta: 0:06:19  lr: 0.000012  loss: 0.6932 (0.6932)  time: 1.1003  data: 0.3373  max mem: 14938
[22:25:18.663882] Epoch: [44]  [ 20/345]  eta: 0:04:10  lr: 0.000012  loss: 0.7084 (0.7068)  time: 0.7531  data: 0.0001  max mem: 14938
[22:25:33.789658] Epoch: [44]  [ 40/345]  eta: 0:03:52  lr: 0.000011  loss: 0.7040 (0.7057)  time: 0.7562  data: 0.0001  max mem: 14938
[22:25:48.963090] Epoch: [44]  [ 60/345]  eta: 0:03:37  lr: 0.000011  loss: 0.7050 (0.7055)  time: 0.7586  data: 0.0001  max mem: 14938
[22:26:04.146036] Epoch: [44]  [ 80/345]  eta: 0:03:21  lr: 0.000011  loss: 0.6997 (0.7047)  time: 0.7591  data: 0.0001  max mem: 14938
[22:26:19.370463] Epoch: [44]  [100/345]  eta: 0:03:06  lr: 0.000011  loss: 0.7068 (0.7054)  time: 0.7612  data: 0.0001  max mem: 14938
[22:26:34.598365] Epoch: [44]  [120/345]  eta: 0:02:51  lr: 0.000011  loss: 0.7044 (0.7051)  time: 0.7614  data: 0.0001  max mem: 14938
[22:26:49.814885] Epoch: [44]  [140/345]  eta: 0:02:36  lr: 0.000010  loss: 0.6997 (0.7049)  time: 0.7608  data: 0.0001  max mem: 14938
[22:27:05.027314] Epoch: [44]  [160/345]  eta: 0:02:20  lr: 0.000010  loss: 0.7045 (0.7054)  time: 0.7606  data: 0.0001  max mem: 14938
[22:27:20.224095] Epoch: [44]  [180/345]  eta: 0:02:05  lr: 0.000010  loss: 0.7127 (0.7065)  time: 0.7598  data: 0.0001  max mem: 14938
[22:27:35.427662] Epoch: [44]  [200/345]  eta: 0:01:50  lr: 0.000010  loss: 0.7051 (0.7064)  time: 0.7601  data: 0.0001  max mem: 14938
[22:27:50.632900] Epoch: [44]  [220/345]  eta: 0:01:35  lr: 0.000010  loss: 0.7054 (0.7065)  time: 0.7602  data: 0.0001  max mem: 14938
[22:28:05.824561] Epoch: [44]  [240/345]  eta: 0:01:19  lr: 0.000009  loss: 0.7051 (0.7067)  time: 0.7595  data: 0.0001  max mem: 14938
[22:28:21.003716] Epoch: [44]  [260/345]  eta: 0:01:04  lr: 0.000009  loss: 0.7105 (0.7070)  time: 0.7589  data: 0.0001  max mem: 14938
[22:28:36.197564] Epoch: [44]  [280/345]  eta: 0:00:49  lr: 0.000009  loss: 0.7051 (0.7070)  time: 0.7596  data: 0.0001  max mem: 14938
[22:28:51.381704] Epoch: [44]  [300/345]  eta: 0:00:34  lr: 0.000009  loss: 0.7066 (0.7069)  time: 0.7592  data: 0.0001  max mem: 14938
[22:29:06.566170] Epoch: [44]  [320/345]  eta: 0:00:19  lr: 0.000009  loss: 0.7073 (0.7071)  time: 0.7592  data: 0.0001  max mem: 14938
[22:29:21.842117] Epoch: [44]  [340/345]  eta: 0:00:03  lr: 0.000008  loss: 0.7111 (0.7072)  time: 0.7638  data: 0.0001  max mem: 14938
[22:29:24.879689] Epoch: [44]  [344/345]  eta: 0:00:00  lr: 0.000008  loss: 0.7111 (0.7072)  time: 0.7637  data: 0.0001  max mem: 14938
[22:29:24.949542] Epoch: [44] Total time: 0:04:22 (0.7607 s / it)
[22:29:24.949668] Averaged stats: lr: 0.000008  loss: 0.7111 (0.7072)
[22:29:25.513186] Test:  [  0/345]  eta: 0:03:12  loss: 0.6882 (0.6882)  time: 0.5590  data: 0.3601  max mem: 14938
[22:29:27.468166] Test:  [ 10/345]  eta: 0:01:16  loss: 0.6827 (0.6834)  time: 0.2285  data: 0.0328  max mem: 14938
[22:29:29.428953] Test:  [ 20/345]  eta: 0:01:09  loss: 0.6806 (0.6830)  time: 0.1957  data: 0.0001  max mem: 14938
[22:29:31.397083] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6806 (0.6856)  time: 0.1964  data: 0.0001  max mem: 14938
[22:29:33.367164] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6845 (0.6851)  time: 0.1968  data: 0.0001  max mem: 14938
[22:29:35.345936] Test:  [ 50/345]  eta: 0:01:00  loss: 0.6819 (0.6845)  time: 0.1974  data: 0.0001  max mem: 14938
[22:29:37.328462] Test:  [ 60/345]  eta: 0:00:57  loss: 0.6781 (0.6834)  time: 0.1980  data: 0.0001  max mem: 14938
[22:29:39.315349] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6787 (0.6832)  time: 0.1984  data: 0.0001  max mem: 14938
[22:29:41.305310] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6852 (0.6847)  time: 0.1988  data: 0.0001  max mem: 14938
[22:29:43.306051] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6863 (0.6845)  time: 0.1995  data: 0.0001  max mem: 14938
[22:29:45.307401] Test:  [100/345]  eta: 0:00:49  loss: 0.6793 (0.6843)  time: 0.2000  data: 0.0001  max mem: 14938
[22:29:47.312375] Test:  [110/345]  eta: 0:00:47  loss: 0.6799 (0.6842)  time: 0.2003  data: 0.0001  max mem: 14938
[22:29:49.321044] Test:  [120/345]  eta: 0:00:45  loss: 0.6780 (0.6839)  time: 0.2006  data: 0.0001  max mem: 14938
[22:29:51.337153] Test:  [130/345]  eta: 0:00:43  loss: 0.6790 (0.6837)  time: 0.2012  data: 0.0001  max mem: 14938
[22:29:53.357178] Test:  [140/345]  eta: 0:00:41  loss: 0.6794 (0.6836)  time: 0.2017  data: 0.0001  max mem: 14938
[22:29:55.383658] Test:  [150/345]  eta: 0:00:39  loss: 0.6828 (0.6835)  time: 0.2023  data: 0.0001  max mem: 14938
[22:29:57.415018] Test:  [160/345]  eta: 0:00:37  loss: 0.6828 (0.6836)  time: 0.2028  data: 0.0001  max mem: 14938
[22:29:59.452107] Test:  [170/345]  eta: 0:00:35  loss: 0.6826 (0.6836)  time: 0.2034  data: 0.0001  max mem: 14938

[22:30:01.493424] Test:  [180/345]  eta: 0:00:33  loss: 0.6858 (0.6838)  time: 0.2039  data: 0.0001  max mem: 14938
[22:30:03.540429] Test:  [190/345]  eta: 0:00:31  loss: 0.6848 (0.6841)  time: 0.2043  data: 0.0001  max mem: 14938
[22:30:05.592471] Test:  [200/345]  eta: 0:00:29  loss: 0.6844 (0.6840)  time: 0.2049  data: 0.0001  max mem: 14938
[22:30:07.649696] Test:  [210/345]  eta: 0:00:27  loss: 0.6784 (0.6839)  time: 0.2054  data: 0.0001  max mem: 14938
[22:30:09.710060] Test:  [220/345]  eta: 0:00:25  loss: 0.6786 (0.6839)  time: 0.2058  data: 0.0001  max mem: 14938
[22:30:11.777948] Test:  [230/345]  eta: 0:00:23  loss: 0.6796 (0.6838)  time: 0.2064  data: 0.0001  max mem: 14938
[22:30:13.851919] Test:  [240/345]  eta: 0:00:21  loss: 0.6773 (0.6835)  time: 0.2070  data: 0.0001  max mem: 14938
[22:30:15.930584] Test:  [250/345]  eta: 0:00:19  loss: 0.6773 (0.6834)  time: 0.2076  data: 0.0001  max mem: 14938
[22:30:18.013965] Test:  [260/345]  eta: 0:00:17  loss: 0.6789 (0.6834)  time: 0.2080  data: 0.0001  max mem: 14938
[22:30:20.103818] Test:  [270/345]  eta: 0:00:15  loss: 0.6803 (0.6833)  time: 0.2086  data: 0.0001  max mem: 14938
[22:30:22.197573] Test:  [280/345]  eta: 0:00:13  loss: 0.6809 (0.6833)  time: 0.2091  data: 0.0001  max mem: 14938
[22:30:24.296398] Test:  [290/345]  eta: 0:00:11  loss: 0.6800 (0.6832)  time: 0.2096  data: 0.0001  max mem: 14938
[22:30:26.398667] Test:  [300/345]  eta: 0:00:09  loss: 0.6800 (0.6832)  time: 0.2100  data: 0.0001  max mem: 14938
[22:30:28.507677] Test:  [310/345]  eta: 0:00:07  loss: 0.6834 (0.6832)  time: 0.2105  data: 0.0001  max mem: 14938
[22:30:30.622788] Test:  [320/345]  eta: 0:00:05  loss: 0.6848 (0.6834)  time: 0.2111  data: 0.0001  max mem: 14938
[22:30:32.743309] Test:  [330/345]  eta: 0:00:03  loss: 0.6822 (0.6833)  time: 0.2117  data: 0.0001  max mem: 14938
[22:30:34.865194] Test:  [340/345]  eta: 0:00:01  loss: 0.6739 (0.6831)  time: 0.2121  data: 0.0001  max mem: 14938
[22:30:35.715771] Test:  [344/345]  eta: 0:00:00  loss: 0.6780 (0.6830)  time: 0.2122  data: 0.0001  max mem: 14938
[22:30:35.782474] Test: Total time: 0:01:10 (0.2053 s / it)
[22:30:52.690763] Test:  [ 0/57]  eta: 0:00:30  loss: 0.8641 (0.8641)  time: 0.5408  data: 0.3443  max mem: 14938
[22:30:54.616288] Test:  [10/57]  eta: 0:00:10  loss: 0.8879 (0.8885)  time: 0.2241  data: 0.0314  max mem: 14938
[22:30:56.553487] Test:  [20/57]  eta: 0:00:07  loss: 0.8879 (0.8757)  time: 0.1931  data: 0.0001  max mem: 14938
[22:30:58.493647] Test:  [30/57]  eta: 0:00:05  loss: 0.7565 (0.8318)  time: 0.1938  data: 0.0001  max mem: 14938
[22:31:00.441295] Test:  [40/57]  eta: 0:00:03  loss: 0.7435 (0.8103)  time: 0.1943  data: 0.0001  max mem: 14938
[22:31:02.393801] Test:  [50/57]  eta: 0:00:01  loss: 0.7420 (0.8024)  time: 0.1949  data: 0.0001  max mem: 14938
[22:31:03.455140] Test:  [56/57]  eta: 0:00:00  loss: 0.7540 (0.8086)  time: 0.1896  data: 0.0001  max mem: 14938
[22:31:03.529547] Test: Total time: 0:00:11 (0.1997 s / it)
[22:31:06.441681] Dice score of the network on the train images: 0.736281, val images: 0.766784
[22:31:06.445861] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft

[22:31:07.560171] Epoch: [45]  [  0/345]  eta: 0:06:24  lr: 0.000008  loss: 0.7161 (0.7161)  time: 1.1134  data: 0.3502  max mem: 14938
[22:31:22.623308] Epoch: [45]  [ 20/345]  eta: 0:04:10  lr: 0.000008  loss: 0.7005 (0.7047)  time: 0.7531  data: 0.0001  max mem: 14938
[22:31:37.749711] Epoch: [45]  [ 40/345]  eta: 0:03:52  lr: 0.000008  loss: 0.7074 (0.7062)  time: 0.7563  data: 0.0001  max mem: 14938
[22:31:52.916697] Epoch: [45]  [ 60/345]  eta: 0:03:37  lr: 0.000008  loss: 0.7009 (0.7057)  time: 0.7583  data: 0.0001  max mem: 14938
[22:32:08.111765] Epoch: [45]  [ 80/345]  eta: 0:03:21  lr: 0.000008  loss: 0.7061 (0.7058)  time: 0.7597  data: 0.0001  max mem: 14938
[22:32:23.336219] Epoch: [45]  [100/345]  eta: 0:03:06  lr: 0.000007  loss: 0.7086 (0.7063)  time: 0.7612  data: 0.0001  max mem: 14938
[22:32:38.564422] Epoch: [45]  [120/345]  eta: 0:02:51  lr: 0.000007  loss: 0.7060 (0.7065)  time: 0.7614  data: 0.0001  max mem: 14938
[22:32:53.781625] Epoch: [45]  [140/345]  eta: 0:02:36  lr: 0.000007  loss: 0.7023 (0.7064)  time: 0.7608  data: 0.0001  max mem: 14938
[22:33:09.006747] Epoch: [45]  [160/345]  eta: 0:02:20  lr: 0.000007  loss: 0.7022 (0.7064)  time: 0.7612  data: 0.0001  max mem: 14938
[22:33:24.204564] Epoch: [45]  [180/345]  eta: 0:02:05  lr: 0.000007  loss: 0.7092 (0.7066)  time: 0.7598  data: 0.0001  max mem: 14938
[22:33:39.397534] Epoch: [45]  [200/345]  eta: 0:01:50  lr: 0.000007  loss: 0.7007 (0.7067)  time: 0.7596  data: 0.0001  max mem: 14938
[22:33:54.575836] Epoch: [45]  [220/345]  eta: 0:01:35  lr: 0.000006  loss: 0.7109 (0.7069)  time: 0.7589  data: 0.0001  max mem: 14938

[22:34:09.773002] Epoch: [45]  [240/345]  eta: 0:01:19  lr: 0.000006  loss: 0.7041 (0.7070)  time: 0.7598  data: 0.0001  max mem: 14938
[22:34:24.942255] Epoch: [45]  [260/345]  eta: 0:01:04  lr: 0.000006  loss: 0.7054 (0.7068)  time: 0.7584  data: 0.0001  max mem: 14938
[22:34:40.112316] Epoch: [45]  [280/345]  eta: 0:00:49  lr: 0.000006  loss: 0.7025 (0.7068)  time: 0.7585  data: 0.0001  max mem: 14938
[22:34:55.293342] Epoch: [45]  [300/345]  eta: 0:00:34  lr: 0.000006  loss: 0.7012 (0.7066)  time: 0.7590  data: 0.0001  max mem: 14938
[22:35:10.461558] Epoch: [45]  [320/345]  eta: 0:00:19  lr: 0.000006  loss: 0.7032 (0.7065)  time: 0.7584  data: 0.0001  max mem: 14938
[22:35:25.626111] Epoch: [45]  [340/345]  eta: 0:00:03  lr: 0.000005  loss: 0.7028 (0.7064)  time: 0.7582  data: 0.0001  max mem: 14938
[22:35:28.658846] Epoch: [45]  [344/345]  eta: 0:00:00  lr: 0.000005  loss: 0.7037 (0.7063)  time: 0.7578  data: 0.0001  max mem: 14938
[22:35:28.728587] Epoch: [45] Total time: 0:04:22 (0.7602 s / it)
[22:35:28.728886] Averaged stats: lr: 0.000005  loss: 0.7037 (0.7063)
[22:35:29.292488] Test:  [  0/345]  eta: 0:03:11  loss: 0.6587 (0.6587)  time: 0.5565  data: 0.3579  max mem: 14938
[22:35:31.246411] Test:  [ 10/345]  eta: 0:01:16  loss: 0.6755 (0.6788)  time: 0.2281  data: 0.0326  max mem: 14938
[22:35:33.204431] Test:  [ 20/345]  eta: 0:01:09  loss: 0.6760 (0.6811)  time: 0.1955  data: 0.0001  max mem: 14938
[22:35:35.169613] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6774 (0.6799)  time: 0.1961  data: 0.0001  max mem: 14938
[22:35:37.139079] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6836 (0.6821)  time: 0.1967  data: 0.0001  max mem: 14938
[22:35:39.112816] Test:  [ 50/345]  eta: 0:01:00  loss: 0.6868 (0.6828)  time: 0.1971  data: 0.0001  max mem: 14938
[22:35:41.092330] Test:  [ 60/345]  eta: 0:00:57  loss: 0.6820 (0.6823)  time: 0.1976  data: 0.0001  max mem: 14938
[22:35:43.077917] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6787 (0.6821)  time: 0.1982  data: 0.0001  max mem: 14938
[22:35:45.067791] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6835 (0.6830)  time: 0.1987  data: 0.0001  max mem: 14938
[22:35:47.068338] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6867 (0.6829)  time: 0.1995  data: 0.0001  max mem: 14938
[22:35:49.070342] Test:  [100/345]  eta: 0:00:49  loss: 0.6812 (0.6828)  time: 0.2001  data: 0.0001  max mem: 14938
[22:35:51.073572] Test:  [110/345]  eta: 0:00:47  loss: 0.6775 (0.6826)  time: 0.2002  data: 0.0001  max mem: 14938
[22:35:53.082230] Test:  [120/345]  eta: 0:00:45  loss: 0.6776 (0.6825)  time: 0.2005  data: 0.0001  max mem: 14938
[22:35:55.097913] Test:  [130/345]  eta: 0:00:43  loss: 0.6764 (0.6820)  time: 0.2012  data: 0.0001  max mem: 14938
[22:35:57.119758] Test:  [140/345]  eta: 0:00:41  loss: 0.6764 (0.6819)  time: 0.2018  data: 0.0001  max mem: 14938
[22:35:59.146522] Test:  [150/345]  eta: 0:00:39  loss: 0.6809 (0.6820)  time: 0.2024  data: 0.0001  max mem: 14938
[22:36:01.176854] Test:  [160/345]  eta: 0:00:37  loss: 0.6801 (0.6817)  time: 0.2028  data: 0.0001  max mem: 14938
[22:36:03.213418] Test:  [170/345]  eta: 0:00:35  loss: 0.6753 (0.6818)  time: 0.2033  data: 0.0001  max mem: 14938
[22:36:05.254040] Test:  [180/345]  eta: 0:00:33  loss: 0.6821 (0.6821)  time: 0.2038  data: 0.0001  max mem: 14938
[22:36:07.300086] Test:  [190/345]  eta: 0:00:31  loss: 0.6858 (0.6823)  time: 0.2043  data: 0.0001  max mem: 14938
[22:36:09.353441] Test:  [200/345]  eta: 0:00:29  loss: 0.6812 (0.6824)  time: 0.2049  data: 0.0001  max mem: 14938
[22:36:11.410634] Test:  [210/345]  eta: 0:00:27  loss: 0.6817 (0.6824)  time: 0.2055  data: 0.0001  max mem: 14938
[22:36:13.471589] Test:  [220/345]  eta: 0:00:25  loss: 0.6802 (0.6824)  time: 0.2058  data: 0.0001  max mem: 14938
[22:36:15.538738] Test:  [230/345]  eta: 0:00:23  loss: 0.6799 (0.6824)  time: 0.2063  data: 0.0001  max mem: 14938
[22:36:17.611672] Test:  [240/345]  eta: 0:00:21  loss: 0.6764 (0.6821)  time: 0.2069  data: 0.0001  max mem: 14938
[22:36:19.688896] Test:  [250/345]  eta: 0:00:19  loss: 0.6785 (0.6821)  time: 0.2074  data: 0.0001  max mem: 14938
[22:36:21.769515] Test:  [260/345]  eta: 0:00:17  loss: 0.6810 (0.6821)  time: 0.2078  data: 0.0001  max mem: 14938
[22:36:23.856322] Test:  [270/345]  eta: 0:00:15  loss: 0.6790 (0.6818)  time: 0.2083  data: 0.0001  max mem: 14938

[22:36:25.948101] Test:  [280/345]  eta: 0:00:13  loss: 0.6794 (0.6820)  time: 0.2089  data: 0.0001  max mem: 14938
[22:36:28.045300] Test:  [290/345]  eta: 0:00:11  loss: 0.6801 (0.6820)  time: 0.2094  data: 0.0001  max mem: 14938
[22:36:30.148940] Test:  [300/345]  eta: 0:00:09  loss: 0.6843 (0.6822)  time: 0.2100  data: 0.0001  max mem: 14938
[22:36:32.256700] Test:  [310/345]  eta: 0:00:07  loss: 0.6843 (0.6822)  time: 0.2105  data: 0.0001  max mem: 14938
[22:36:34.369353] Test:  [320/345]  eta: 0:00:05  loss: 0.6825 (0.6825)  time: 0.2110  data: 0.0001  max mem: 14938
[22:36:36.486675] Test:  [330/345]  eta: 0:00:03  loss: 0.6814 (0.6823)  time: 0.2114  data: 0.0001  max mem: 14938
[22:36:38.608689] Test:  [340/345]  eta: 0:00:01  loss: 0.6768 (0.6822)  time: 0.2119  data: 0.0001  max mem: 14938
[22:36:39.458335] Test:  [344/345]  eta: 0:00:00  loss: 0.6768 (0.6821)  time: 0.2121  data: 0.0001  max mem: 14938
[22:36:39.522239] Test: Total time: 0:01:10 (0.2052 s / it)
[22:36:56.321913] Test:  [ 0/57]  eta: 0:00:30  loss: 0.8613 (0.8613)  time: 0.5268  data: 0.3301  max mem: 14938
[22:36:58.247289] Test:  [10/57]  eta: 0:00:10  loss: 0.8893 (0.8903)  time: 0.2229  data: 0.0301  max mem: 14938
[22:37:00.183032] Test:  [20/57]  eta: 0:00:07  loss: 0.8893 (0.8777)  time: 0.1930  data: 0.0001  max mem: 14938
[22:37:02.126595] Test:  [30/57]  eta: 0:00:05  loss: 0.7569 (0.8334)  time: 0.1939  data: 0.0001  max mem: 14938
[22:37:04.074124] Test:  [40/57]  eta: 0:00:03  loss: 0.7431 (0.8117)  time: 0.1945  data: 0.0001  max mem: 14938
[22:37:06.027023] Test:  [50/57]  eta: 0:00:01  loss: 0.7425 (0.8037)  time: 0.1950  data: 0.0001  max mem: 14938
[22:37:07.088397] Test:  [56/57]  eta: 0:00:00  loss: 0.7545 (0.8098)  time: 0.1896  data: 0.0000  max mem: 14938
[22:37:07.156620] Test: Total time: 0:00:11 (0.1993 s / it)
[22:37:10.112372] Dice score of the network on the train images: 0.737653, val images: 0.766241
[22:37:10.117019] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:37:11.249886] Epoch: [46]  [  0/345]  eta: 0:06:30  lr: 0.000005  loss: 0.7031 (0.7031)  time: 1.1319  data: 0.3703  max mem: 14938
[22:37:26.322396] Epoch: [46]  [ 20/345]  eta: 0:04:10  lr: 0.000005  loss: 0.7030 (0.7057)  time: 0.7536  data: 0.0001  max mem: 14938
[22:37:41.453314] Epoch: [46]  [ 40/345]  eta: 0:03:53  lr: 0.000005  loss: 0.7064 (0.7054)  time: 0.7565  data: 0.0001  max mem: 14938
[22:37:56.631089] Epoch: [46]  [ 60/345]  eta: 0:03:37  lr: 0.000005  loss: 0.7016 (0.7049)  time: 0.7589  data: 0.0001  max mem: 14938
[22:38:11.836981] Epoch: [46]  [ 80/345]  eta: 0:03:21  lr: 0.000005  loss: 0.7100 (0.7066)  time: 0.7602  data: 0.0001  max mem: 14938
[22:38:27.064609] Epoch: [46]  [100/345]  eta: 0:03:06  lr: 0.000005  loss: 0.7010 (0.7061)  time: 0.7613  data: 0.0001  max mem: 14938
[22:38:42.298452] Epoch: [46]  [120/345]  eta: 0:02:51  lr: 0.000005  loss: 0.7026 (0.7063)  time: 0.7616  data: 0.0001  max mem: 14938
[22:38:57.519246] Epoch: [46]  [140/345]  eta: 0:02:36  lr: 0.000004  loss: 0.7022 (0.7060)  time: 0.7610  data: 0.0001  max mem: 14938
[22:39:12.728037] Epoch: [46]  [160/345]  eta: 0:02:20  lr: 0.000004  loss: 0.7096 (0.7063)  time: 0.7604  data: 0.0001  max mem: 14938
[22:39:27.924203] Epoch: [46]  [180/345]  eta: 0:02:05  lr: 0.000004  loss: 0.7040 (0.7060)  time: 0.7598  data: 0.0001  max mem: 14938
[22:39:43.115993] Epoch: [46]  [200/345]  eta: 0:01:50  lr: 0.000004  loss: 0.7026 (0.7061)  time: 0.7596  data: 0.0001  max mem: 14938
[22:39:58.293054] Epoch: [46]  [220/345]  eta: 0:01:35  lr: 0.000004  loss: 0.7046 (0.7061)  time: 0.7588  data: 0.0001  max mem: 14938
[22:40:13.472459] Epoch: [46]  [240/345]  eta: 0:01:19  lr: 0.000004  loss: 0.7110 (0.7064)  time: 0.7589  data: 0.0001  max mem: 14938
[22:40:28.667905] Epoch: [46]  [260/345]  eta: 0:01:04  lr: 0.000004  loss: 0.7023 (0.7060)  time: 0.7597  data: 0.0001  max mem: 14938
[22:40:43.844864] Epoch: [46]  [280/345]  eta: 0:00:49  lr: 0.000003  loss: 0.7026 (0.7058)  time: 0.7588  data: 0.0001  max mem: 14938
[22:40:59.037505] Epoch: [46]  [300/345]  eta: 0:00:34  lr: 0.000003  loss: 0.7050 (0.7057)  time: 0.7596  data: 0.0001  max mem: 14938
[22:41:14.229624] Epoch: [46]  [320/345]  eta: 0:00:19  lr: 0.000003  loss: 0.7058 (0.7058)  time: 0.7596  data: 0.0001  max mem: 14938
[22:41:29.421515] Epoch: [46]  [340/345]  eta: 0:00:03  lr: 0.000003  loss: 0.7043 (0.7058)  time: 0.7596  data: 0.0001  max mem: 14938
[22:41:32.453466] Epoch: [46]  [344/345]  eta: 0:00:00  lr: 0.000003  loss: 0.7082 (0.7060)  time: 0.7590  data: 0.0001  max mem: 14938
[22:41:32.521624] Epoch: [46] Total time: 0:04:22 (0.7606 s / it)
[22:41:32.521969] Averaged stats: lr: 0.000003  loss: 0.7082 (0.7060)
[22:41:33.126915] Test:  [  0/345]  eta: 0:03:26  loss: 0.6780 (0.6780)  time: 0.5999  data: 0.4021  max mem: 14938
[22:41:35.079097] Test:  [ 10/345]  eta: 0:01:17  loss: 0.6780 (0.6804)  time: 0.2319  data: 0.0366  max mem: 14938
[22:41:37.039428] Test:  [ 20/345]  eta: 0:01:09  loss: 0.6800 (0.6815)  time: 0.1956  data: 0.0001  max mem: 14938
[22:41:39.006205] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6789 (0.6805)  time: 0.1963  data: 0.0001  max mem: 14938
[22:41:40.977327] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6789 (0.6807)  time: 0.1968  data: 0.0001  max mem: 14938
[22:41:42.952920] Test:  [ 50/345]  eta: 0:01:00  loss: 0.6791 (0.6807)  time: 0.1973  data: 0.0001  max mem: 14938
[22:41:44.938195] Test:  [ 60/345]  eta: 0:00:57  loss: 0.6771 (0.6808)  time: 0.1980  data: 0.0001  max mem: 14938
[22:41:46.924133] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6777 (0.6805)  time: 0.1985  data: 0.0001  max mem: 14938
[22:41:48.911542] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6784 (0.6810)  time: 0.1986  data: 0.0001  max mem: 14938
[22:41:50.907546] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6784 (0.6811)  time: 0.1991  data: 0.0001  max mem: 14938
[22:41:52.910589] Test:  [100/345]  eta: 0:00:49  loss: 0.6765 (0.6807)  time: 0.1999  data: 0.0001  max mem: 14938
[22:41:54.914645] Test:  [110/345]  eta: 0:00:47  loss: 0.6786 (0.6809)  time: 0.2003  data: 0.0001  max mem: 14938
[22:41:56.921282] Test:  [120/345]  eta: 0:00:45  loss: 0.6790 (0.6806)  time: 0.2005  data: 0.0001  max mem: 14938
[22:41:58.936292] Test:  [130/345]  eta: 0:00:43  loss: 0.6765 (0.6803)  time: 0.2010  data: 0.0001  max mem: 14938
[22:42:00.956788] Test:  [140/345]  eta: 0:00:41  loss: 0.6818 (0.6808)  time: 0.2017  data: 0.0001  max mem: 14938
[22:42:02.981921] Test:  [150/345]  eta: 0:00:39  loss: 0.6839 (0.6808)  time: 0.2022  data: 0.0001  max mem: 14938
[22:42:05.012327] Test:  [160/345]  eta: 0:00:37  loss: 0.6795 (0.6806)  time: 0.2027  data: 0.0001  max mem: 14938
[22:42:07.048011] Test:  [170/345]  eta: 0:00:35  loss: 0.6785 (0.6807)  time: 0.2032  data: 0.0001  max mem: 14938
[22:42:09.089416] Test:  [180/345]  eta: 0:00:33  loss: 0.6785 (0.6810)  time: 0.2038  data: 0.0001  max mem: 14938
[22:42:11.135115] Test:  [190/345]  eta: 0:00:31  loss: 0.6826 (0.6813)  time: 0.2043  data: 0.0001  max mem: 14938
[22:42:13.189287] Test:  [200/345]  eta: 0:00:29  loss: 0.6858 (0.6815)  time: 0.2049  data: 0.0001  max mem: 14938
[22:42:15.244982] Test:  [210/345]  eta: 0:00:27  loss: 0.6805 (0.6814)  time: 0.2054  data: 0.0001  max mem: 14938
[22:42:17.307226] Test:  [220/345]  eta: 0:00:25  loss: 0.6767 (0.6815)  time: 0.2058  data: 0.0001  max mem: 14938
[22:42:19.374958] Test:  [230/345]  eta: 0:00:23  loss: 0.6809 (0.6814)  time: 0.2064  data: 0.0001  max mem: 14938
[22:42:21.446030] Test:  [240/345]  eta: 0:00:21  loss: 0.6779 (0.6815)  time: 0.2069  data: 0.0001  max mem: 14938
[22:42:23.523169] Test:  [250/345]  eta: 0:00:19  loss: 0.6859 (0.6816)  time: 0.2073  data: 0.0001  max mem: 14938
[22:42:25.604406] Test:  [260/345]  eta: 0:00:17  loss: 0.6847 (0.6815)  time: 0.2078  data: 0.0001  max mem: 14938
[22:42:27.692069] Test:  [270/345]  eta: 0:00:15  loss: 0.6784 (0.6816)  time: 0.2084  data: 0.0001  max mem: 14938
[22:42:29.786622] Test:  [280/345]  eta: 0:00:13  loss: 0.6819 (0.6815)  time: 0.2090  data: 0.0001  max mem: 14938
[22:42:31.887342] Test:  [290/345]  eta: 0:00:11  loss: 0.6832 (0.6816)  time: 0.2097  data: 0.0001  max mem: 14938
[22:42:33.990686] Test:  [300/345]  eta: 0:00:09  loss: 0.6833 (0.6818)  time: 0.2101  data: 0.0001  max mem: 14938
[22:42:36.098702] Test:  [310/345]  eta: 0:00:07  loss: 0.6821 (0.6818)  time: 0.2105  data: 0.0001  max mem: 14938
[22:42:38.211301] Test:  [320/345]  eta: 0:00:05  loss: 0.6797 (0.6818)  time: 0.2110  data: 0.0001  max mem: 14938
[22:42:40.331368] Test:  [330/345]  eta: 0:00:03  loss: 0.6808 (0.6818)  time: 0.2116  data: 0.0001  max mem: 14938
[22:42:42.453902] Test:  [340/345]  eta: 0:00:01  loss: 0.6808 (0.6819)  time: 0.2121  data: 0.0001  max mem: 14938
[22:42:43.303944] Test:  [344/345]  eta: 0:00:00  loss: 0.6817 (0.6820)  time: 0.2122  data: 0.0001  max mem: 14938
[22:42:43.366973] Test: Total time: 0:01:10 (0.2053 s / it)
[22:43:00.347113] Test:  [ 0/57]  eta: 0:00:30  loss: 0.8581 (0.8581)  time: 0.5383  data: 0.3430  max mem: 14938
[22:43:02.273115] Test:  [10/57]  eta: 0:00:10  loss: 0.8839 (0.8851)  time: 0.2239  data: 0.0313  max mem: 14938
[22:43:04.209777] Test:  [20/57]  eta: 0:00:07  loss: 0.8839 (0.8730)  time: 0.1931  data: 0.0001  max mem: 14938
[22:43:06.151347] Test:  [30/57]  eta: 0:00:05  loss: 0.7552 (0.8296)  time: 0.1938  data: 0.0001  max mem: 14938
[22:43:08.099260] Test:  [40/57]  eta: 0:00:03  loss: 0.7428 (0.8083)  time: 0.1944  data: 0.0001  max mem: 14938
[22:43:10.052259] Test:  [50/57]  eta: 0:00:01  loss: 0.7406 (0.8005)  time: 0.1950  data: 0.0001  max mem: 14938
[22:43:11.114474] Test:  [56/57]  eta: 0:00:00  loss: 0.7571 (0.8069)  time: 0.1897  data: 0.0001  max mem: 14938
[22:43:11.175686] Test: Total time: 0:00:11 (0.1994 s / it)
[22:43:14.133072] Dice score of the network on the train images: 0.736156, val images: 0.766919
[22:43:14.137299] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:43:15.239332] Epoch: [47]  [  0/345]  eta: 0:06:19  lr: 0.000003  loss: 0.7138 (0.7138)  time: 1.1011  data: 0.3354  max mem: 14938
[22:43:30.306788] Epoch: [47]  [ 20/345]  eta: 0:04:10  lr: 0.000003  loss: 0.6984 (0.7014)  time: 0.7533  data: 0.0001  max mem: 14938
[22:43:45.443395] Epoch: [47]  [ 40/345]  eta: 0:03:52  lr: 0.000003  loss: 0.7070 (0.7028)  time: 0.7568  data: 0.0001  max mem: 14938
[22:44:00.631765] Epoch: [47]  [ 60/345]  eta: 0:03:37  lr: 0.000003  loss: 0.7048 (0.7037)  time: 0.7594  data: 0.0001  max mem: 14938
[22:44:15.840500] Epoch: [47]  [ 80/345]  eta: 0:03:21  lr: 0.000003  loss: 0.7079 (0.7049)  time: 0.7604  data: 0.0001  max mem: 14938
[22:44:31.071446] Epoch: [47]  [100/345]  eta: 0:03:06  lr: 0.000003  loss: 0.7023 (0.7049)  time: 0.7615  data: 0.0001  max mem: 14938
[22:44:46.274022] Epoch: [47]  [120/345]  eta: 0:02:51  lr: 0.000002  loss: 0.7055 (0.7051)  time: 0.7601  data: 0.0001  max mem: 14938
[22:45:01.485137] Epoch: [47]  [140/345]  eta: 0:02:36  lr: 0.000002  loss: 0.7056 (0.7054)  time: 0.7605  data: 0.0001  max mem: 14938
[22:45:16.701507] Epoch: [47]  [160/345]  eta: 0:02:20  lr: 0.000002  loss: 0.7010 (0.7052)  time: 0.7608  data: 0.0001  max mem: 14938
[22:45:31.912849] Epoch: [47]  [180/345]  eta: 0:02:05  lr: 0.000002  loss: 0.7063 (0.7056)  time: 0.7605  data: 0.0001  max mem: 14938
[22:45:47.106703] Epoch: [47]  [200/345]  eta: 0:01:50  lr: 0.000002  loss: 0.7074 (0.7058)  time: 0.7596  data: 0.0001  max mem: 14938
[22:46:02.305197] Epoch: [47]  [220/345]  eta: 0:01:35  lr: 0.000002  loss: 0.7018 (0.7056)  time: 0.7599  data: 0.0001  max mem: 14938
[22:46:17.486564] Epoch: [47]  [240/345]  eta: 0:01:19  lr: 0.000002  loss: 0.7004 (0.7055)  time: 0.7590  data: 0.0001  max mem: 14938
[22:46:32.688594] Epoch: [47]  [260/345]  eta: 0:01:04  lr: 0.000002  loss: 0.7035 (0.7056)  time: 0.7601  data: 0.0001  max mem: 14938
[22:46:47.883192] Epoch: [47]  [280/345]  eta: 0:00:49  lr: 0.000002  loss: 0.7066 (0.7058)  time: 0.7597  data: 0.0001  max mem: 14938
[22:47:03.077758] Epoch: [47]  [300/345]  eta: 0:00:34  lr: 0.000002  loss: 0.7062 (0.7058)  time: 0.7597  data: 0.0001  max mem: 14938
[22:47:18.273254] Epoch: [47]  [320/345]  eta: 0:00:19  lr: 0.000001  loss: 0.7041 (0.7057)  time: 0.7597  data: 0.0001  max mem: 14938
[22:47:33.460056] Epoch: [47]  [340/345]  eta: 0:00:03  lr: 0.000001  loss: 0.7067 (0.7056)  time: 0.7593  data: 0.0001  max mem: 14938
[22:47:36.499157] Epoch: [47]  [344/345]  eta: 0:00:00  lr: 0.000001  loss: 0.7067 (0.7056)  time: 0.7594  data: 0.0001  max mem: 14938
[22:47:36.568963] Epoch: [47] Total time: 0:04:22 (0.7607 s / it)
[22:47:36.569318] Averaged stats: lr: 0.000001  loss: 0.7067 (0.7056)
[22:47:37.118070] Test:  [  0/345]  eta: 0:03:07  loss: 0.6634 (0.6634)  time: 0.5433  data: 0.3452  max mem: 14938
[22:47:39.072100] Test:  [ 10/345]  eta: 0:01:16  loss: 0.6836 (0.6810)  time: 0.2269  data: 0.0315  max mem: 14938
[22:47:41.033045] Test:  [ 20/345]  eta: 0:01:08  loss: 0.6796 (0.6786)  time: 0.1957  data: 0.0001  max mem: 14938
[22:47:42.997307] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6744 (0.6770)  time: 0.1962  data: 0.0001  max mem: 14938
[22:47:44.969013] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6769 (0.6796)  time: 0.1967  data: 0.0001  max mem: 14938
[22:47:46.945609] Test:  [ 50/345]  eta: 0:00:59  loss: 0.6799 (0.6795)  time: 0.1974  data: 0.0001  max mem: 14938
[22:47:48.928198] Test:  [ 60/345]  eta: 0:00:57  loss: 0.6795 (0.6801)  time: 0.1979  data: 0.0001  max mem: 14938
[22:47:50.912522] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6795 (0.6799)  time: 0.1983  data: 0.0001  max mem: 14938
[22:47:52.902456] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6798 (0.6806)  time: 0.1986  data: 0.0001  max mem: 14938
[22:47:54.895403] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6877 (0.6813)  time: 0.1991  data: 0.0001  max mem: 14938
[22:47:56.894481] Test:  [100/345]  eta: 0:00:49  loss: 0.6879 (0.6816)  time: 0.1995  data: 0.0001  max mem: 14938
[22:47:58.899145] Test:  [110/345]  eta: 0:00:47  loss: 0.6775 (0.6811)  time: 0.2001  data: 0.0001  max mem: 14938
[22:48:00.910166] Test:  [120/345]  eta: 0:00:45  loss: 0.6794 (0.6817)  time: 0.2007  data: 0.0001  max mem: 14938
[22:48:02.924958] Test:  [130/345]  eta: 0:00:43  loss: 0.6811 (0.6819)  time: 0.2012  data: 0.0001  max mem: 14938
[22:48:04.944311] Test:  [140/345]  eta: 0:00:41  loss: 0.6811 (0.6822)  time: 0.2016  data: 0.0001  max mem: 14938
[22:48:06.970190] Test:  [150/345]  eta: 0:00:39  loss: 0.6824 (0.6821)  time: 0.2022  data: 0.0001  max mem: 14938
[22:48:08.999548] Test:  [160/345]  eta: 0:00:37  loss: 0.6815 (0.6823)  time: 0.2027  data: 0.0001  max mem: 14938
[22:48:11.035222] Test:  [170/345]  eta: 0:00:35  loss: 0.6891 (0.6830)  time: 0.2032  data: 0.0001  max mem: 14938
[22:48:13.076839] Test:  [180/345]  eta: 0:00:33  loss: 0.6855 (0.6830)  time: 0.2038  data: 0.0001  max mem: 14938
[22:48:15.123459] Test:  [190/345]  eta: 0:00:31  loss: 0.6806 (0.6830)  time: 0.2043  data: 0.0001  max mem: 14938
[22:48:17.174269] Test:  [200/345]  eta: 0:00:29  loss: 0.6806 (0.6827)  time: 0.2048  data: 0.0001  max mem: 14938
[22:48:19.227862] Test:  [210/345]  eta: 0:00:27  loss: 0.6810 (0.6828)  time: 0.2052  data: 0.0001  max mem: 14938
[22:48:21.289165] Test:  [220/345]  eta: 0:00:25  loss: 0.6810 (0.6828)  time: 0.2057  data: 0.0001  max mem: 14938
[22:48:23.357531] Test:  [230/345]  eta: 0:00:23  loss: 0.6797 (0.6828)  time: 0.2064  data: 0.0001  max mem: 14938
[22:48:25.426724] Test:  [240/345]  eta: 0:00:21  loss: 0.6782 (0.6825)  time: 0.2068  data: 0.0001  max mem: 14938
[22:48:27.503993] Test:  [250/345]  eta: 0:00:19  loss: 0.6750 (0.6823)  time: 0.2073  data: 0.0001  max mem: 14938
[22:48:29.584378] Test:  [260/345]  eta: 0:00:17  loss: 0.6763 (0.6823)  time: 0.2078  data: 0.0001  max mem: 14938
[22:48:31.672740] Test:  [270/345]  eta: 0:00:15  loss: 0.6822 (0.6821)  time: 0.2084  data: 0.0001  max mem: 14938
[22:48:33.766793] Test:  [280/345]  eta: 0:00:13  loss: 0.6798 (0.6820)  time: 0.2091  data: 0.0001  max mem: 14938
[22:48:35.862756] Test:  [290/345]  eta: 0:00:11  loss: 0.6810 (0.6820)  time: 0.2094  data: 0.0001  max mem: 14938
[22:48:37.964694] Test:  [300/345]  eta: 0:00:09  loss: 0.6745 (0.6819)  time: 0.2098  data: 0.0001  max mem: 14938
[22:48:40.074549] Test:  [310/345]  eta: 0:00:07  loss: 0.6752 (0.6818)  time: 0.2105  data: 0.0001  max mem: 14938
[22:48:42.188399] Test:  [320/345]  eta: 0:00:05  loss: 0.6782 (0.6817)  time: 0.2111  data: 0.0001  max mem: 14938
[22:48:44.306485] Test:  [330/345]  eta: 0:00:03  loss: 0.6792 (0.6818)  time: 0.2115  data: 0.0001  max mem: 14938
[22:48:46.428880] Test:  [340/345]  eta: 0:00:01  loss: 0.6786 (0.6817)  time: 0.2120  data: 0.0001  max mem: 14938
[22:48:47.279918] Test:  [344/345]  eta: 0:00:00  loss: 0.6784 (0.6818)  time: 0.2122  data: 0.0001  max mem: 14938
[22:48:47.346819] Test: Total time: 0:01:10 (0.2051 s / it)
[22:49:04.233365] Test:  [ 0/57]  eta: 0:00:31  loss: 0.8621 (0.8621)  time: 0.5440  data: 0.3483  max mem: 14938
[22:49:06.156419] Test:  [10/57]  eta: 0:00:10  loss: 0.8878 (0.8886)  time: 0.2242  data: 0.0317  max mem: 14938
[22:49:08.094924] Test:  [20/57]  eta: 0:00:07  loss: 0.8878 (0.8760)  time: 0.1930  data: 0.0001  max mem: 14938
[22:49:10.036123] Test:  [30/57]  eta: 0:00:05  loss: 0.7573 (0.8321)  time: 0.1939  data: 0.0001  max mem: 14938
[22:49:11.985524] Test:  [40/57]  eta: 0:00:03  loss: 0.7432 (0.8107)  time: 0.1945  data: 0.0001  max mem: 14938
[22:49:13.937273] Test:  [50/57]  eta: 0:00:01  loss: 0.7432 (0.8027)  time: 0.1950  data: 0.0001  max mem: 14938
[22:49:15.000050] Test:  [56/57]  eta: 0:00:00  loss: 0.7560 (0.8089)  time: 0.1897  data: 0.0000  max mem: 14938
[22:49:15.062803] Test: Total time: 0:00:11 (0.1995 s / it)
[22:49:18.011438] Dice score of the network on the train images: 0.737364, val images: 0.766275
[22:49:18.015882] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:49:19.154740] Epoch: [48]  [  0/345]  eta: 0:06:32  lr: 0.000001  loss: 0.7025 (0.7025)  time: 1.1380  data: 0.3753  max mem: 14938
[22:49:34.219839] Epoch: [48]  [ 20/345]  eta: 0:04:10  lr: 0.000001  loss: 0.7025 (0.7027)  time: 0.7532  data: 0.0001  max mem: 14938
[22:49:49.344141] Epoch: [48]  [ 40/345]  eta: 0:03:53  lr: 0.000001  loss: 0.7031 (0.7026)  time: 0.7562  data: 0.0001  max mem: 14938
[22:50:04.512228] Epoch: [48]  [ 60/345]  eta: 0:03:37  lr: 0.000001  loss: 0.7018 (0.7024)  time: 0.7584  data: 0.0001  max mem: 14938
[22:50:19.728627] Epoch: [48]  [ 80/345]  eta: 0:03:21  lr: 0.000001  loss: 0.7057 (0.7042)  time: 0.7608  data: 0.0001  max mem: 14938

[22:50:34.956777] Epoch: [48]  [100/345]  eta: 0:03:06  lr: 0.000001  loss: 0.7022 (0.7043)  time: 0.7614  data: 0.0001  max mem: 14938
[22:50:50.167402] Epoch: [48]  [120/345]  eta: 0:02:51  lr: 0.000001  loss: 0.7042 (0.7046)  time: 0.7605  data: 0.0001  max mem: 14938
[22:51:05.385954] Epoch: [48]  [140/345]  eta: 0:02:36  lr: 0.000001  loss: 0.7023 (0.7046)  time: 0.7609  data: 0.0001  max mem: 14938
[22:51:20.610712] Epoch: [48]  [160/345]  eta: 0:02:20  lr: 0.000001  loss: 0.7054 (0.7052)  time: 0.7612  data: 0.0001  max mem: 14938
[22:51:35.830688] Epoch: [48]  [180/345]  eta: 0:02:05  lr: 0.000001  loss: 0.7094 (0.7055)  time: 0.7609  data: 0.0001  max mem: 14938

[22:51:51.033594] Epoch: [48]  [200/345]  eta: 0:01:50  lr: 0.000001  loss: 0.7035 (0.7055)  time: 0.7601  data: 0.0001  max mem: 14938
[22:52:06.241420] Epoch: [48]  [220/345]  eta: 0:01:35  lr: 0.000001  loss: 0.7035 (0.7054)  time: 0.7603  data: 0.0001  max mem: 14938
[22:52:21.448633] Epoch: [48]  [240/345]  eta: 0:01:19  lr: 0.000001  loss: 0.7088 (0.7057)  time: 0.7603  data: 0.0001  max mem: 14938
[22:52:36.639535] Epoch: [48]  [260/345]  eta: 0:01:04  lr: 0.000001  loss: 0.6984 (0.7055)  time: 0.7595  data: 0.0001  max mem: 14938
[22:52:51.823758] Epoch: [48]  [280/345]  eta: 0:00:49  lr: 0.000000  loss: 0.7027 (0.7054)  time: 0.7592  data: 0.0001  max mem: 14938
[22:53:07.016215] Epoch: [48]  [300/345]  eta: 0:00:34  lr: 0.000000  loss: 0.7075 (0.7056)  time: 0.7596  data: 0.0001  max mem: 14938
[22:53:22.215986] Epoch: [48]  [320/345]  eta: 0:00:19  lr: 0.000000  loss: 0.7032 (0.7055)  time: 0.7599  data: 0.0001  max mem: 14938
[22:53:37.382763] Epoch: [48]  [340/345]  eta: 0:00:03  lr: 0.000000  loss: 0.7003 (0.7054)  time: 0.7583  data: 0.0001  max mem: 14938
[22:53:40.416394] Epoch: [48]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.7004 (0.7054)  time: 0.7581  data: 0.0001  max mem: 14938
[22:53:40.488005] Epoch: [48] Total time: 0:04:22 (0.7608 s / it)
[22:53:40.488309] Averaged stats: lr: 0.000000  loss: 0.7004 (0.7054)
[22:53:41.048380] Test:  [  0/345]  eta: 0:03:10  loss: 0.6792 (0.6792)  time: 0.5534  data: 0.3524  max mem: 14938
[22:53:43.003773] Test:  [ 10/345]  eta: 0:01:16  loss: 0.6821 (0.6875)  time: 0.2280  data: 0.0321  max mem: 14938
[22:53:44.965983] Test:  [ 20/345]  eta: 0:01:09  loss: 0.6819 (0.6841)  time: 0.1958  data: 0.0001  max mem: 14938
[22:53:46.932080] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6796 (0.6840)  time: 0.1964  data: 0.0001  max mem: 14938
[22:53:48.902896] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6814 (0.6836)  time: 0.1968  data: 0.0001  max mem: 14938
[22:53:50.877025] Test:  [ 50/345]  eta: 0:01:00  loss: 0.6776 (0.6824)  time: 0.1972  data: 0.0001  max mem: 14938
[22:53:52.859042] Test:  [ 60/345]  eta: 0:00:57  loss: 0.6754 (0.6819)  time: 0.1977  data: 0.0001  max mem: 14938
[22:53:54.846119] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6754 (0.6818)  time: 0.1984  data: 0.0001  max mem: 14938
[22:53:56.836235] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6770 (0.6815)  time: 0.1988  data: 0.0001  max mem: 14938
[22:53:58.832991] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6785 (0.6815)  time: 0.1993  data: 0.0001  max mem: 14938
[22:54:00.835035] Test:  [100/345]  eta: 0:00:49  loss: 0.6794 (0.6815)  time: 0.1999  data: 0.0001  max mem: 14938
[22:54:02.836972] Test:  [110/345]  eta: 0:00:47  loss: 0.6811 (0.6820)  time: 0.2001  data: 0.0001  max mem: 14938
[22:54:04.843900] Test:  [120/345]  eta: 0:00:45  loss: 0.6827 (0.6819)  time: 0.2004  data: 0.0001  max mem: 14938
[22:54:06.860047] Test:  [130/345]  eta: 0:00:43  loss: 0.6827 (0.6821)  time: 0.2011  data: 0.0001  max mem: 14938
[22:54:08.879496] Test:  [140/345]  eta: 0:00:41  loss: 0.6839 (0.6823)  time: 0.2017  data: 0.0001  max mem: 14938
[22:54:10.906873] Test:  [150/345]  eta: 0:00:39  loss: 0.6806 (0.6822)  time: 0.2023  data: 0.0001  max mem: 14938
[22:54:12.938796] Test:  [160/345]  eta: 0:00:37  loss: 0.6845 (0.6825)  time: 0.2029  data: 0.0001  max mem: 14938
[22:54:14.973950] Test:  [170/345]  eta: 0:00:35  loss: 0.6824 (0.6822)  time: 0.2033  data: 0.0001  max mem: 14938
[22:54:17.015447] Test:  [180/345]  eta: 0:00:33  loss: 0.6764 (0.6823)  time: 0.2038  data: 0.0001  max mem: 14938
[22:54:19.061012] Test:  [190/345]  eta: 0:00:31  loss: 0.6813 (0.6822)  time: 0.2043  data: 0.0001  max mem: 14938
[22:54:21.115230] Test:  [200/345]  eta: 0:00:29  loss: 0.6792 (0.6819)  time: 0.2049  data: 0.0001  max mem: 14938
[22:54:23.171636] Test:  [210/345]  eta: 0:00:27  loss: 0.6790 (0.6820)  time: 0.2055  data: 0.0001  max mem: 14938

[22:54:25.232460] Test:  [220/345]  eta: 0:00:25  loss: 0.6822 (0.6819)  time: 0.2058  data: 0.0001  max mem: 14938
[22:54:27.301406] Test:  [230/345]  eta: 0:00:23  loss: 0.6772 (0.6817)  time: 0.2064  data: 0.0001  max mem: 14938
[22:54:29.372314] Test:  [240/345]  eta: 0:00:21  loss: 0.6757 (0.6817)  time: 0.2069  data: 0.0001  max mem: 14938
[22:54:31.449481] Test:  [250/345]  eta: 0:00:19  loss: 0.6786 (0.6817)  time: 0.2073  data: 0.0001  max mem: 14938
[22:54:33.529946] Test:  [260/345]  eta: 0:00:17  loss: 0.6793 (0.6816)  time: 0.2078  data: 0.0001  max mem: 14938
[22:54:35.614296] Test:  [270/345]  eta: 0:00:15  loss: 0.6783 (0.6816)  time: 0.2082  data: 0.0001  max mem: 14938
[22:54:37.708490] Test:  [280/345]  eta: 0:00:13  loss: 0.6814 (0.6817)  time: 0.2089  data: 0.0001  max mem: 14938
[22:54:39.806103] Test:  [290/345]  eta: 0:00:11  loss: 0.6835 (0.6818)  time: 0.2095  data: 0.0001  max mem: 14938
[22:54:41.910524] Test:  [300/345]  eta: 0:00:09  loss: 0.6799 (0.6818)  time: 0.2100  data: 0.0001  max mem: 14938
[22:54:44.017469] Test:  [310/345]  eta: 0:00:07  loss: 0.6829 (0.6817)  time: 0.2105  data: 0.0001  max mem: 14938
[22:54:46.132638] Test:  [320/345]  eta: 0:00:05  loss: 0.6833 (0.6819)  time: 0.2110  data: 0.0001  max mem: 14938
[22:54:48.255085] Test:  [330/345]  eta: 0:00:03  loss: 0.6814 (0.6818)  time: 0.2118  data: 0.0001  max mem: 14938
[22:54:50.375654] Test:  [340/345]  eta: 0:00:01  loss: 0.6793 (0.6817)  time: 0.2121  data: 0.0001  max mem: 14938
[22:54:51.225385] Test:  [344/345]  eta: 0:00:00  loss: 0.6793 (0.6817)  time: 0.2122  data: 0.0001  max mem: 14938
[22:54:51.288415] Test: Total time: 0:01:10 (0.2052 s / it)
[22:55:08.191807] Test:  [ 0/57]  eta: 0:00:29  loss: 0.8622 (0.8622)  time: 0.5258  data: 0.3302  max mem: 14938
[22:55:10.115216] Test:  [10/57]  eta: 0:00:10  loss: 0.8875 (0.8879)  time: 0.2226  data: 0.0301  max mem: 14938
[22:55:12.051832] Test:  [20/57]  eta: 0:00:07  loss: 0.8875 (0.8755)  time: 0.1929  data: 0.0001  max mem: 14938
[22:55:13.991981] Test:  [30/57]  eta: 0:00:05  loss: 0.7566 (0.8317)  time: 0.1938  data: 0.0001  max mem: 14938
[22:55:15.939998] Test:  [40/57]  eta: 0:00:03  loss: 0.7437 (0.8102)  time: 0.1943  data: 0.0001  max mem: 14938
[22:55:17.892451] Test:  [50/57]  eta: 0:00:01  loss: 0.7425 (0.8023)  time: 0.1950  data: 0.0001  max mem: 14938
[22:55:18.955255] Test:  [56/57]  eta: 0:00:00  loss: 0.7557 (0.8085)  time: 0.1897  data: 0.0001  max mem: 14938
[22:55:19.023781] Test: Total time: 0:00:11 (0.1993 s / it)
[22:55:21.969707] Dice score of the network on the train images: 0.737504, val images: 0.766361
[22:55:21.974546] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:55:23.092915] Epoch: [49]  [  0/345]  eta: 0:06:25  lr: 0.000000  loss: 0.7144 (0.7144)  time: 1.1175  data: 0.3592  max mem: 14938
[22:55:38.147891] Epoch: [49]  [ 20/345]  eta: 0:04:10  lr: 0.000000  loss: 0.7054 (0.7081)  time: 0.7527  data: 0.0001  max mem: 14938
[22:55:53.263684] Epoch: [49]  [ 40/345]  eta: 0:03:52  lr: 0.000000  loss: 0.7060 (0.7082)  time: 0.7557  data: 0.0001  max mem: 14938
[22:56:08.407565] Epoch: [49]  [ 60/345]  eta: 0:03:36  lr: 0.000000  loss: 0.7052 (0.7070)  time: 0.7572  data: 0.0001  max mem: 14938
[22:56:23.613767] Epoch: [49]  [ 80/345]  eta: 0:03:21  lr: 0.000000  loss: 0.7052 (0.7062)  time: 0.7603  data: 0.0001  max mem: 14938
[22:56:38.834557] Epoch: [49]  [100/345]  eta: 0:03:06  lr: 0.000000  loss: 0.7070 (0.7064)  time: 0.7610  data: 0.0001  max mem: 14938
[22:56:54.050191] Epoch: [49]  [120/345]  eta: 0:02:51  lr: 0.000000  loss: 0.7000 (0.7056)  time: 0.7607  data: 0.0001  max mem: 14938
[22:57:09.266719] Epoch: [49]  [140/345]  eta: 0:02:35  lr: 0.000000  loss: 0.7045 (0.7055)  time: 0.7608  data: 0.0001  max mem: 14938
[22:57:24.478096] Epoch: [49]  [160/345]  eta: 0:02:20  lr: 0.000000  loss: 0.7004 (0.7053)  time: 0.7605  data: 0.0001  max mem: 14938
[22:57:39.674491] Epoch: [49]  [180/345]  eta: 0:02:05  lr: 0.000000  loss: 0.7056 (0.7053)  time: 0.7598  data: 0.0001  max mem: 14938
[22:57:54.889782] Epoch: [49]  [200/345]  eta: 0:01:50  lr: 0.000000  loss: 0.6992 (0.7048)  time: 0.7607  data: 0.0001  max mem: 14938
[22:58:10.085861] Epoch: [49]  [220/345]  eta: 0:01:35  lr: 0.000000  loss: 0.6980 (0.7049)  time: 0.7598  data: 0.0001  max mem: 14938
[22:58:25.297220] Epoch: [49]  [240/345]  eta: 0:01:19  lr: 0.000000  loss: 0.7033 (0.7047)  time: 0.7605  data: 0.0001  max mem: 14938
[22:58:40.494663] Epoch: [49]  [260/345]  eta: 0:01:04  lr: 0.000000  loss: 0.7031 (0.7046)  time: 0.7598  data: 0.0001  max mem: 14938
[22:58:55.705652] Epoch: [49]  [280/345]  eta: 0:00:49  lr: 0.000000  loss: 0.7051 (0.7049)  time: 0.7605  data: 0.0001  max mem: 14938
[22:59:10.900114] Epoch: [49]  [300/345]  eta: 0:00:34  lr: 0.000000  loss: 0.7070 (0.7050)  time: 0.7597  data: 0.0001  max mem: 14938
[22:59:26.097794] Epoch: [49]  [320/345]  eta: 0:00:19  lr: 0.000000  loss: 0.7069 (0.7053)  time: 0.7598  data: 0.0001  max mem: 14938
[22:59:41.288022] Epoch: [49]  [340/345]  eta: 0:00:03  lr: 0.000000  loss: 0.7018 (0.7053)  time: 0.7595  data: 0.0001  max mem: 14938
[22:59:44.325389] Epoch: [49]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.7026 (0.7053)  time: 0.7593  data: 0.0001  max mem: 14938
[22:59:44.405491] Epoch: [49] Total time: 0:04:22 (0.7607 s / it)
[22:59:44.405618] Averaged stats: lr: 0.000000  loss: 0.7026 (0.7053)
[22:59:44.983550] Test:  [  0/345]  eta: 0:03:17  loss: 0.6777 (0.6777)  time: 0.5738  data: 0.3757  max mem: 14938
[22:59:46.936874] Test:  [ 10/345]  eta: 0:01:16  loss: 0.6778 (0.6798)  time: 0.2297  data: 0.0342  max mem: 14938
[22:59:48.899138] Test:  [ 20/345]  eta: 0:01:09  loss: 0.6778 (0.6803)  time: 0.1957  data: 0.0001  max mem: 14938
[22:59:50.862507] Test:  [ 30/345]  eta: 0:01:05  loss: 0.6843 (0.6815)  time: 0.1962  data: 0.0001  max mem: 14938
[22:59:52.832981] Test:  [ 40/345]  eta: 0:01:02  loss: 0.6845 (0.6819)  time: 0.1966  data: 0.0001  max mem: 14938
[22:59:54.810802] Test:  [ 50/345]  eta: 0:01:00  loss: 0.6828 (0.6812)  time: 0.1974  data: 0.0001  max mem: 14938
[22:59:56.794385] Test:  [ 60/345]  eta: 0:00:57  loss: 0.6784 (0.6808)  time: 0.1980  data: 0.0001  max mem: 14938
[22:59:58.782231] Test:  [ 70/345]  eta: 0:00:55  loss: 0.6771 (0.6802)  time: 0.1985  data: 0.0001  max mem: 14938
[23:00:00.774060] Test:  [ 80/345]  eta: 0:00:53  loss: 0.6810 (0.6809)  time: 0.1989  data: 0.0001  max mem: 14938
[23:00:02.771312] Test:  [ 90/345]  eta: 0:00:51  loss: 0.6810 (0.6811)  time: 0.1994  data: 0.0001  max mem: 14938
[23:00:04.772456] Test:  [100/345]  eta: 0:00:49  loss: 0.6793 (0.6817)  time: 0.1999  data: 0.0001  max mem: 14938
[23:00:06.778245] Test:  [110/345]  eta: 0:00:47  loss: 0.6841 (0.6817)  time: 0.2003  data: 0.0001  max mem: 14938
[23:00:08.785763] Test:  [120/345]  eta: 0:00:45  loss: 0.6768 (0.6808)  time: 0.2006  data: 0.0001  max mem: 14938
[23:00:10.801875] Test:  [130/345]  eta: 0:00:43  loss: 0.6768 (0.6810)  time: 0.2011  data: 0.0001  max mem: 14938
[23:00:12.822086] Test:  [140/345]  eta: 0:00:41  loss: 0.6801 (0.6810)  time: 0.2018  data: 0.0001  max mem: 14938
[23:00:14.847642] Test:  [150/345]  eta: 0:00:39  loss: 0.6791 (0.6811)  time: 0.2022  data: 0.0001  max mem: 14938
[23:00:16.879164] Test:  [160/345]  eta: 0:00:37  loss: 0.6783 (0.6810)  time: 0.2028  data: 0.0001  max mem: 14938
[23:00:18.916912] Test:  [170/345]  eta: 0:00:35  loss: 0.6788 (0.6810)  time: 0.2034  data: 0.0001  max mem: 14938
[23:00:20.958090] Test:  [180/345]  eta: 0:00:33  loss: 0.6807 (0.6811)  time: 0.2039  data: 0.0001  max mem: 14938
[23:00:23.002037] Test:  [190/345]  eta: 0:00:31  loss: 0.6798 (0.6811)  time: 0.2042  data: 0.0001  max mem: 14938
[23:00:25.057244] Test:  [200/345]  eta: 0:00:29  loss: 0.6791 (0.6810)  time: 0.2049  data: 0.0001  max mem: 14938
[23:00:27.115371] Test:  [210/345]  eta: 0:00:27  loss: 0.6816 (0.6812)  time: 0.2056  data: 0.0001  max mem: 14938
[23:00:29.175764] Test:  [220/345]  eta: 0:00:25  loss: 0.6833 (0.6813)  time: 0.2059  data: 0.0001  max mem: 14938
[23:00:31.244314] Test:  [230/345]  eta: 0:00:23  loss: 0.6821 (0.6816)  time: 0.2064  data: 0.0001  max mem: 14938
[23:00:33.316249] Test:  [240/345]  eta: 0:00:21  loss: 0.6821 (0.6816)  time: 0.2070  data: 0.0001  max mem: 14938
[23:00:35.392060] Test:  [250/345]  eta: 0:00:19  loss: 0.6835 (0.6817)  time: 0.2073  data: 0.0001  max mem: 14938
[23:00:37.475457] Test:  [260/345]  eta: 0:00:17  loss: 0.6842 (0.6817)  time: 0.2079  data: 0.0001  max mem: 14938
[23:00:39.562525] Test:  [270/345]  eta: 0:00:15  loss: 0.6805 (0.6817)  time: 0.2085  data: 0.0001  max mem: 14938

[23:00:41.654778] Test:  [280/345]  eta: 0:00:13  loss: 0.6795 (0.6816)  time: 0.2089  data: 0.0001  max mem: 14938
[23:00:43.753684] Test:  [290/345]  eta: 0:00:11  loss: 0.6767 (0.6815)  time: 0.2095  data: 0.0001  max mem: 14938
[23:00:45.857412] Test:  [300/345]  eta: 0:00:09  loss: 0.6781 (0.6815)  time: 0.2101  data: 0.0001  max mem: 14938
[23:00:47.967083] Test:  [310/345]  eta: 0:00:07  loss: 0.6806 (0.6816)  time: 0.2106  data: 0.0001  max mem: 14938
[23:00:50.084289] Test:  [320/345]  eta: 0:00:05  loss: 0.6749 (0.6813)  time: 0.2113  data: 0.0001  max mem: 14938
[23:00:52.206535] Test:  [330/345]  eta: 0:00:03  loss: 0.6765 (0.6815)  time: 0.2119  data: 0.0001  max mem: 14938
[23:00:54.330690] Test:  [340/345]  eta: 0:00:01  loss: 0.6830 (0.6815)  time: 0.2123  data: 0.0001  max mem: 14938
[23:00:55.181171] Test:  [344/345]  eta: 0:00:00  loss: 0.6812 (0.6815)  time: 0.2124  data: 0.0001  max mem: 14938
[23:00:55.243470] Test: Total time: 0:01:10 (0.2053 s / it)
[23:01:12.295117] Test:  [ 0/57]  eta: 0:00:33  loss: 0.8608 (0.8608)  time: 0.5855  data: 0.3916  max mem: 14938
[23:01:14.225830] Test:  [10/57]  eta: 0:00:10  loss: 0.8864 (0.8868)  time: 0.2287  data: 0.0357  max mem: 14938
[23:01:16.163032] Test:  [20/57]  eta: 0:00:07  loss: 0.8864 (0.8745)  time: 0.1933  data: 0.0001  max mem: 14938
[23:01:18.105244] Test:  [30/57]  eta: 0:00:05  loss: 0.7560 (0.8308)  time: 0.1939  data: 0.0001  max mem: 14938
[23:01:20.054546] Test:  [40/57]  eta: 0:00:03  loss: 0.7429 (0.8094)  time: 0.1945  data: 0.0001  max mem: 14938
[23:01:22.006379] Test:  [50/57]  eta: 0:00:01  loss: 0.7417 (0.8015)  time: 0.1950  data: 0.0001  max mem: 14938
[23:01:23.068518] Test:  [56/57]  eta: 0:00:00  loss: 0.7552 (0.8078)  time: 0.1896  data: 0.0001  max mem: 14938
[23:01:23.132035] Test: Total time: 0:00:11 (0.2004 s / it)
[23:01:26.079444] Dice score of the network on the train images: 0.736823, val images: 0.766675
[23:01:26.081060] Training time 5:03:43
[23:01:28.063614] Load pre-trained checkpoint from: /root/seg_framework/MS-Mamba/output_dir/mslesseg/checkpoints_0/checkpoint-best_dice_model_0.pth
[23:01:28.085342] <All keys matched successfully>
[23:01:29.013100] Test:  [  0/246]  eta: 0:03:31    time: 0.8600  data: 0.4589  max mem: 14938
[23:01:32.003624] Test:  [ 10/246]  eta: 0:01:22    time: 0.3500  data: 0.0418  max mem: 14938
[23:01:38.150897] ---------------------------------
[23:01:38.151104] Patient 1:
[23:01:38.151187]       precision: 0.4856630861759186
[23:01:38.151268]       recall: 0.5352205634117126
[23:01:38.151325]       dice_score: 0.5092389583587646
[23:01:38.154370] Test:  [ 20/246]  eta: 0:01:47    time: 0.4570  data: 0.0001  max mem: 14938
[23:01:41.144039] Test:  [ 30/246]  eta: 0:01:30    time: 0.4570  data: 0.0001  max mem: 14938
[23:01:47.265026] ---------------------------------
[23:01:47.265241] Patient 2:
[23:01:47.265333]       precision: 0.5730749368667603
[23:01:47.265401]       recall: 0.5522463321685791
[23:01:47.265463]       dice_score: 0.5624678730964661
[23:01:47.265998] Test:  [ 40/246]  eta: 0:01:36    time: 0.4555  data: 0.0001  max mem: 14938
[23:01:50.258018] Test:  [ 50/246]  eta: 0:01:24    time: 0.4556  data: 0.0001  max mem: 14938
[23:01:53.258198] Test:  [ 60/246]  eta: 0:01:16    time: 0.2996  data: 0.0001  max mem: 14938
[23:01:56.663965] ---------------------------------
[23:01:56.664192] Patient 3:
[23:01:56.664287]       precision: 0.4333333373069763
[23:01:56.664355]       recall: 0.4991771876811981
[23:01:56.664420]       dice_score: 0.4639306664466858
[23:01:59.357356] Test:  [ 70/246]  eta: 0:01:17    time: 0.4549  data: 0.0001  max mem: 14938
[23:02:02.355811] Test:  [ 80/246]  eta: 0:01:10    time: 0.4548  data: 0.0001  max mem: 14938
[23:02:05.753314] ---------------------------------
[23:02:05.753534] Patient 4:
[23:02:05.753617]       precision: 0.5912328958511353
[23:02:05.753686]       recall: 0.5446743965148926
[23:02:05.753752]       dice_score: 0.5669994950294495
[23:02:08.453296] Test:  [ 90/246]  eta: 0:01:09    time: 0.4547  data: 0.0001  max mem: 14938
[23:02:11.455654] Test:  [100/246]  eta: 0:01:02    time: 0.4549  data: 0.0001  max mem: 14938
[23:02:15.158707] ---------------------------------
[23:02:15.158926] Patient 5:
[23:02:15.159010]       precision: 0.4382566511631012
[23:02:15.159077]       recall: 0.49643445014953613
[23:02:15.159139]       dice_score: 0.4655349850654602
[23:02:17.552992] Test:  [110/246]  eta: 0:01:00    time: 0.4549  data: 0.0001  max mem: 14938
[23:02:20.551965] Test:  [120/246]  eta: 0:00:54    time: 0.4548  data: 0.0001  max mem: 14938
[23:02:24.262435] ---------------------------------
[23:02:24.262658] Patient 6:
[23:02:24.262734]       precision: 0.4341346025466919
[23:02:24.262798]       recall: 0.4953373670578003
[23:02:24.262858]       dice_score: 0.46272099018096924
[23:02:26.663515] Test:  [130/246]  eta: 0:00:51    time: 0.4555  data: 0.0001  max mem: 14938
[23:02:29.668341] Test:  [140/246]  eta: 0:00:46    time: 0.4558  data: 0.0001  max mem: 14938
[23:02:33.690446] ---------------------------------
[23:02:33.690667] Patient 7:
[23:02:33.690744]       precision: 0.7930295467376709
[23:02:33.690811]       recall: 0.7812575697898865
[23:02:33.690873]       dice_score: 0.7870995402336121
[23:02:35.785321] Test:  [150/246]  eta: 0:00:42    time: 0.4560  data: 0.0001  max mem: 14938
[23:02:38.787733] Test:  [160/246]  eta: 0:00:37    time: 0.4559  data: 0.0001  max mem: 14938
[23:02:42.813664] ---------------------------------
[23:02:42.813887] Patient 8:
[23:02:42.813963]       precision: 0.8839709758758545
[23:02:42.814029]       recall: 0.5809322595596313
[23:02:42.814088]       dice_score: 0.7011074423789978
[23:02:44.907946] Test:  [170/246]  eta: 0:00:34    time: 0.4561  data: 0.0001  max mem: 14938
[23:02:47.907452] Test:  [180/246]  eta: 0:00:29    time: 0.4559  data: 0.0001  max mem: 14938
[23:02:51.943947] ---------------------------------
[23:02:51.944163] Patient 9:
[23:02:51.944253]       precision: 0.7254058122634888
[23:02:51.944318]       recall: 0.8085119128227234
[23:02:51.944377]       dice_score: 0.7647075653076172
[23:02:54.040032] Test:  [190/246]  eta: 0:00:25    time: 0.4565  data: 0.0001  max mem: 14938
[23:02:57.042374] Test:  [200/246]  eta: 0:00:20    time: 0.4567  data: 0.0001  max mem: 14938
[23:03:01.394798] ---------------------------------
[23:03:01.395036] Patient 10:
[23:03:01.395123]       precision: 0.7362527251243591
[23:03:01.395190]       recall: 0.8023192286491394
[23:03:01.395265]       dice_score: 0.7678675055503845
[23:03:03.194391] Test:  [210/246]  eta: 0:00:16    time: 0.4577  data: 0.0001  max mem: 14938
[23:03:06.199142] Test:  [220/246]  eta: 0:00:11    time: 0.4578  data: 0.0001  max mem: 14938
[23:03:10.532598] ---------------------------------
[23:03:10.532842] Patient 11:
[23:03:10.532929]       precision: 0.875665545463562
[23:03:10.533002]       recall: 0.7763135433197021
[23:03:10.533073]       dice_score: 0.8230019807815552
[23:03:12.333808] Test:  [230/246]  eta: 0:00:07    time: 0.4569  data: 0.0001  max mem: 14938
[23:03:15.336114] Test:  [240/246]  eta: 0:00:02    time: 0.4568  data: 0.0001  max mem: 14938
[23:03:19.745160] ---------------------------------
[23:03:19.745385] Patient 12:
[23:03:19.745465]       precision: 0.6553224921226501
[23:03:19.745529]       recall: 0.7466185688972473
[23:03:19.745587]       dice_score: 0.6979978680610657
[23:03:19.745954] Test:  [245/246]  eta: 0:00:00    time: 0.4457  data: 0.0001  max mem: 14938
[23:03:19.828056] Test: Total time: 0:01:51 (0.4540 s / it)
[23:03:19.828257] ================================
[23:03:19.828322] Averaged over all patients:
[23:03:19.828590]       precision: 0.6354 ± 0.1611
[23:03:19.828724]       recall: 0.6349 ± 0.1281
[23:03:19.828849]       dice_score: 0.6311 ± 0.1337
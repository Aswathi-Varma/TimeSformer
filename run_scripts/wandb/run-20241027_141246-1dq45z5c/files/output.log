Not using distributed mode
[14:12:48.492806] job dir: /root/seg_framework/MS-Mamba/run_scripts
[14:12:48.492949] Namespace(accum_iter=1,
model='SegFormer3D',
in_channels=1,
lr=None,
blr=0.001,
min_lr=0,
dist_on_itp=False,
warmup_epochs=20,
device='cuda:0',
seed=42,
layer_decay=0.75,
clip_grad=None,
num_workers=1,
pin_mem=True,
resume='',
mask_mode='concatenate to image',
world_size=1,
embed_dim=1,
local_rank=-1,
dist_url='env://',
nb_classes=2,
data_dir='/root/MSLesSeg24/data',
datalist=None,
preprocess=False,
dim=2,
loss='mask tp1 tp2',
distributed=False)
[14:12:48.493063] device  cuda:0
[14:12:48.493757] Random seed set as 42
[14:12:48.494108] Starting for fold 0
[14:12:48.684424] Elements in data_dir_paths: 11052
[14:12:48.718519] Elements in data_dir_paths: 1803
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[14:12:50.356121] number of params: 59617303
[14:12:50.356360] model: Vivim2D(
  (encoder): mamba_block(
    (downsample_layers): SegformerEncoder(
      (patch_embeddings): ModuleList(
        (0): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(2, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (1): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (2): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (3): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (block): ModuleList(
        (0): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): Identity()
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.003703703870996833)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.007407407741993666)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.011111111380159855)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.014814815483987331)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.018518518656492233)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.02222222276031971)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (2): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.025925926864147186)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.029629630967974663)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03333333507180214)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03703703731298447)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04074074327945709)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04444444552063942)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.048148151487112045)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.051851850003004074)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0555555559694767)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.05925925821065903)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06296296417713165)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06666667014360428)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07037036865949631)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07407407462596893)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07777778059244156)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08148147910833359)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08518518507480621)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08888889104127884)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (3): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.09259259700775146)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0962962955236435)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.10000000149011612)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (layer_norm): ModuleList(
        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=64, out_features=256, bias=False)
              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (act): SiLU()
              (x_proj): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_b): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_b): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_b): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_s): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_s): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_s): Linear(in_features=4, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=64, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=256, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=64, out_features=256, bias=False)
              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (act): SiLU()
              (x_proj): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_b): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_b): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_b): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_s): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_s): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_s): Linear(in_features=4, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=64, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=256, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (1): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=128, out_features=512, bias=False)
              (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (act): SiLU()
              (x_proj): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_b): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_b): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_b): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_s): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_s): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_s): Linear(in_features=8, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=128, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=128, out_features=512, bias=False)
              (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (act): SiLU()
              (x_proj): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_b): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_b): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_b): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_s): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_s): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_s): Linear(in_features=8, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=128, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (2): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=320, out_features=1280, bias=False)
              (conv1d): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (act): SiLU()
              (x_proj): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_b): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_b): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_b): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_s): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_s): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_s): Linear(in_features=20, out_features=640, bias=True)
              (out_proj): Linear(in_features=640, out_features=320, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(1280, 1280, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=320, out_features=1280, bias=False)
              (conv1d): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (act): SiLU()
              (x_proj): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_b): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_b): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_b): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_s): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_s): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_s): Linear(in_features=20, out_features=640, bias=True)
              (out_proj): Linear(in_features=640, out_features=320, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(1280, 1280, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (3): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=512, out_features=2048, bias=False)
              (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (act): SiLU()
              (x_proj): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_b): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_b): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_b): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_s): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_s): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_s): Linear(in_features=32, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=512, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=512, out_features=2048, bias=False)
              (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (act): SiLU()
              (x_proj): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_b): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_b): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_b): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_s): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_s): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_s): Linear(in_features=32, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=512, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
  )
  (decoder): SegformerDecodeHead(
    (linear_c): ModuleList(
      (0): SegformerMLP(
        (proj): Linear(in_features=64, out_features=768, bias=True)
      )
      (1): SegformerMLP(
        (proj): Linear(in_features=128, out_features=768, bias=True)
      )
      (2): SegformerMLP(
        (proj): Linear(in_features=320, out_features=768, bias=True)
      )
      (3): SegformerMLP(
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
    )
    (linear_fuse): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (batch_norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): ReLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Conv2d(768, 150, kernel_size=(1, 1), stride=(1, 1))
  )
  (out): Conv2d(768, 1, kernel_size=(1, 1), stride=(1, 1))
)
[14:12:50.359482] base lr: 1.00e-03
[14:12:50.359542] actual lr: 1.25e-04
[14:12:50.359593] accumulate grad iterations: 1
[14:12:50.359649] effective batch size: 32
[14:12:50.361287] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.000125
    maximize: False
    weight_decay: 0.01
)
[14:12:50.363510] Start training for 50 epochs
[14:12:50.365410] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:12:51.969043] Epoch: [0]  [  0/345]  eta: 0:09:12  lr: 0.000000  loss: 1.6965 (1.6965)  time: 1.6029  data: 0.1986  max mem: 14473
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
[14:13:06.489007] Epoch: [0]  [ 20/345]  eta: 0:04:09  lr: 0.000000  loss: 1.6955 (1.6956)  time: 0.7260  data: 0.0001  max mem: 14938
[14:13:21.132871] Epoch: [0]  [ 40/345]  eta: 0:03:48  lr: 0.000001  loss: 1.6917 (1.6936)  time: 0.7322  data: 0.0001  max mem: 14938
[14:13:36.009555] Epoch: [0]  [ 60/345]  eta: 0:03:33  lr: 0.000001  loss: 1.6874 (1.6916)  time: 0.7438  data: 0.0001  max mem: 14938
[14:13:50.822414] Epoch: [0]  [ 80/345]  eta: 0:03:17  lr: 0.000001  loss: 1.6850 (1.6901)  time: 0.7406  data: 0.0001  max mem: 14938
[14:14:05.681463] Epoch: [0]  [100/345]  eta: 0:03:02  lr: 0.000002  loss: 1.6822 (1.6885)  time: 0.7429  data: 0.0001  max mem: 14938
[14:14:20.573657] Epoch: [0]  [120/345]  eta: 0:02:47  lr: 0.000002  loss: 1.6764 (1.6865)  time: 0.7446  data: 0.0001  max mem: 14938
[14:14:35.513169] Epoch: [0]  [140/345]  eta: 0:02:32  lr: 0.000003  loss: 1.6697 (1.6843)  time: 0.7469  data: 0.0001  max mem: 14938
[14:14:50.452805] Epoch: [0]  [160/345]  eta: 0:02:17  lr: 0.000003  loss: 1.6670 (1.6822)  time: 0.7469  data: 0.0001  max mem: 14938
[14:15:05.394768] Epoch: [0]  [180/345]  eta: 0:02:03  lr: 0.000003  loss: 1.6606 (1.6798)  time: 0.7470  data: 0.0001  max mem: 14938
[14:15:20.349809] Epoch: [0]  [200/345]  eta: 0:01:48  lr: 0.000004  loss: 1.6525 (1.6772)  time: 0.7477  data: 0.0001  max mem: 14938
[14:15:35.321731] Epoch: [0]  [220/345]  eta: 0:01:33  lr: 0.000004  loss: 1.6446 (1.6743)  time: 0.7486  data: 0.0001  max mem: 14938
[14:15:50.299690] Epoch: [0]  [240/345]  eta: 0:01:18  lr: 0.000004  loss: 1.6343 (1.6711)  time: 0.7489  data: 0.0001  max mem: 14938
[14:16:05.273981] Epoch: [0]  [260/345]  eta: 0:01:03  lr: 0.000005  loss: 1.6247 (1.6675)  time: 0.7487  data: 0.0001  max mem: 14938
[14:16:20.237594] Epoch: [0]  [280/345]  eta: 0:00:48  lr: 0.000005  loss: 1.6127 (1.6636)  time: 0.7481  data: 0.0001  max mem: 14938
[14:16:35.193976] Epoch: [0]  [300/345]  eta: 0:00:33  lr: 0.000005  loss: 1.5995 (1.6594)  time: 0.7478  data: 0.0001  max mem: 14938
[14:16:50.152534] Epoch: [0]  [320/345]  eta: 0:00:18  lr: 0.000006  loss: 1.5854 (1.6548)  time: 0.7479  data: 0.0001  max mem: 14938
[14:17:05.101138] Epoch: [0]  [340/345]  eta: 0:00:03  lr: 0.000006  loss: 1.5717 (1.6499)  time: 0.7474  data: 0.0001  max mem: 14938
[14:17:08.093020] Epoch: [0]  [344/345]  eta: 0:00:00  lr: 0.000006  loss: 1.5658 (1.6489)  time: 0.7475  data: 0.0001  max mem: 14938
[14:17:08.155256] Epoch: [0] Total time: 0:04:17 (0.7472 s / it)
[14:17:08.155663] Averaged stats: lr: 0.000006  loss: 1.5658 (1.6489)
[14:17:08.493618] Test:  [  0/345]  eta: 0:01:54  loss: 1.5937 (1.5937)  time: 0.3322  data: 0.1511  max mem: 14938
[14:17:10.328075] Test:  [ 10/345]  eta: 0:01:05  loss: 1.5937 (1.5936)  time: 0.1969  data: 0.0138  max mem: 14938
[14:17:12.166017] Test:  [ 20/345]  eta: 0:01:01  loss: 1.5941 (1.5938)  time: 0.1835  data: 0.0001  max mem: 14938
[14:17:14.007494] Test:  [ 30/345]  eta: 0:00:59  loss: 1.5925 (1.5932)  time: 0.1839  data: 0.0001  max mem: 14938
[14:17:15.853518] Test:  [ 40/345]  eta: 0:00:57  loss: 1.5925 (1.5930)  time: 0.1843  data: 0.0001  max mem: 14938
[14:17:17.702538] Test:  [ 50/345]  eta: 0:00:55  loss: 1.5935 (1.5932)  time: 0.1847  data: 0.0001  max mem: 14938
[14:17:19.553853] Test:  [ 60/345]  eta: 0:00:53  loss: 1.5935 (1.5931)  time: 0.1850  data: 0.0001  max mem: 14938
[14:17:21.408899] Test:  [ 70/345]  eta: 0:00:51  loss: 1.5913 (1.5928)  time: 0.1853  data: 0.0001  max mem: 14938
[14:17:23.267690] Test:  [ 80/345]  eta: 0:00:49  loss: 1.5913 (1.5927)  time: 0.1856  data: 0.0001  max mem: 14938
[14:17:25.129374] Test:  [ 90/345]  eta: 0:00:47  loss: 1.5924 (1.5926)  time: 0.1860  data: 0.0001  max mem: 14938
[14:17:26.996969] Test:  [100/345]  eta: 0:00:45  loss: 1.5927 (1.5925)  time: 0.1864  data: 0.0001  max mem: 14938
[14:17:28.866161] Test:  [110/345]  eta: 0:00:43  loss: 1.5931 (1.5926)  time: 0.1868  data: 0.0001  max mem: 14938
[14:17:30.739149] Test:  [120/345]  eta: 0:00:41  loss: 1.5936 (1.5927)  time: 0.1871  data: 0.0001  max mem: 14938
[14:17:32.614995] Test:  [130/345]  eta: 0:00:40  loss: 1.5920 (1.5925)  time: 0.1874  data: 0.0001  max mem: 14938
[14:17:34.494170] Test:  [140/345]  eta: 0:00:38  loss: 1.5925 (1.5925)  time: 0.1877  data: 0.0001  max mem: 14938
[14:17:36.377430] Test:  [150/345]  eta: 0:00:36  loss: 1.5931 (1.5925)  time: 0.1881  data: 0.0001  max mem: 14938
[14:17:38.262596] Test:  [160/345]  eta: 0:00:34  loss: 1.5937 (1.5926)  time: 0.1884  data: 0.0001  max mem: 14938
[14:17:40.153708] Test:  [170/345]  eta: 0:00:32  loss: 1.5926 (1.5926)  time: 0.1888  data: 0.0001  max mem: 14938
[14:17:42.047540] Test:  [180/345]  eta: 0:00:30  loss: 1.5930 (1.5925)  time: 0.1892  data: 0.0001  max mem: 14938
[14:17:43.943871] Test:  [190/345]  eta: 0:00:29  loss: 1.5934 (1.5925)  time: 0.1895  data: 0.0001  max mem: 14938
[14:17:45.843132] Test:  [200/345]  eta: 0:00:27  loss: 1.5923 (1.5926)  time: 0.1897  data: 0.0001  max mem: 14938
[14:17:48.154345] Test:  [210/345]  eta: 0:00:25  loss: 1.5923 (1.5925)  time: 0.2105  data: 0.0001  max mem: 14938
[14:17:50.072813] Test:  [220/345]  eta: 0:00:23  loss: 1.5940 (1.5926)  time: 0.2114  data: 0.0001  max mem: 14938
[14:17:52.120498] Test:  [230/345]  eta: 0:00:21  loss: 1.5944 (1.5927)  time: 0.1983  data: 0.0001  max mem: 14938
[14:17:54.038192] Test:  [240/345]  eta: 0:00:19  loss: 1.5926 (1.5926)  time: 0.1982  data: 0.0001  max mem: 14938
[14:17:56.129267] Test:  [250/345]  eta: 0:00:18  loss: 1.5926 (1.5926)  time: 0.2004  data: 0.0001  max mem: 14938
[14:17:58.225130] Test:  [260/345]  eta: 0:00:16  loss: 1.5921 (1.5926)  time: 0.2093  data: 0.0001  max mem: 14938
[14:18:00.315415] Test:  [270/345]  eta: 0:00:14  loss: 1.5934 (1.5927)  time: 0.2093  data: 0.0001  max mem: 14938
[14:18:02.271178] Test:  [280/345]  eta: 0:00:12  loss: 1.5934 (1.5926)  time: 0.2022  data: 0.0001  max mem: 14938
[14:18:04.387720] Test:  [290/345]  eta: 0:00:10  loss: 1.5909 (1.5926)  time: 0.2036  data: 0.0001  max mem: 14938
[14:18:06.578965] Test:  [300/345]  eta: 0:00:08  loss: 1.5934 (1.5927)  time: 0.2153  data: 0.0001  max mem: 14938
[14:18:08.699153] Test:  [310/345]  eta: 0:00:06  loss: 1.5937 (1.5927)  time: 0.2155  data: 0.0001  max mem: 14938

[14:18:10.797465] Test:  [320/345]  eta: 0:00:04  loss: 1.5932 (1.5927)  time: 0.2109  data: 0.0001  max mem: 14938
[14:18:12.935127] Test:  [330/345]  eta: 0:00:02  loss: 1.5927 (1.5926)  time: 0.2117  data: 0.0001  max mem: 14938
[14:18:14.960909] Test:  [340/345]  eta: 0:00:00  loss: 1.5917 (1.5926)  time: 0.2081  data: 0.0001  max mem: 14938
[14:18:15.982720] Test:  [344/345]  eta: 0:00:00  loss: 1.5918 (1.5926)  time: 0.2191  data: 0.0001  max mem: 14938
[14:18:16.042470] Test: Total time: 0:01:07 (0.1968 s / it)
[14:18:26.843079] Test:  [ 0/57]  eta: 0:00:18  loss: 1.6031 (1.6031)  time: 0.3265  data: 0.1476  max mem: 14938
[14:18:28.654566] Test:  [10/57]  eta: 0:00:09  loss: 1.5973 (1.5979)  time: 0.1943  data: 0.0135  max mem: 14938
[14:18:30.469665] Test:  [20/57]  eta: 0:00:06  loss: 1.5978 (1.5966)  time: 0.1813  data: 0.0001  max mem: 14938
[14:18:32.289624] Test:  [30/57]  eta: 0:00:05  loss: 1.5949 (1.5923)  time: 0.1817  data: 0.0001  max mem: 14938
[14:18:34.114037] Test:  [40/57]  eta: 0:00:03  loss: 1.5839 (1.5894)  time: 0.1822  data: 0.0001  max mem: 14938
[14:18:35.944331] Test:  [50/57]  eta: 0:00:01  loss: 1.5839 (1.5884)  time: 0.1827  data: 0.0001  max mem: 14938
[14:18:36.959131] Test:  [56/57]  eta: 0:00:00  loss: 1.5872 (1.5884)  time: 0.1787  data: 0.0001  max mem: 14938
[14:18:37.020166] Test: Total time: 0:00:10 (0.1843 s / it)
[14:18:38.825794] Dice score of the network on the train images: 0.000000, val images: 0.000000
[14:18:38.826037] saving best_dice_model_0 @ epoch 0
[14:18:39.659842] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:18:40.558518] Epoch: [1]  [  0/345]  eta: 0:05:09  lr: 0.000006  loss: 1.5589 (1.5589)  time: 0.8976  data: 0.1579  max mem: 14938
[14:18:55.401406] Epoch: [1]  [ 20/345]  eta: 0:04:03  lr: 0.000007  loss: 1.5513 (1.5526)  time: 0.7421  data: 0.0001  max mem: 14938
[14:19:10.329140] Epoch: [1]  [ 40/345]  eta: 0:03:48  lr: 0.000007  loss: 1.5421 (1.5472)  time: 0.7463  data: 0.0001  max mem: 14938
[14:19:25.299997] Epoch: [1]  [ 60/345]  eta: 0:03:33  lr: 0.000007  loss: 1.5235 (1.5400)  time: 0.7485  data: 0.0001  max mem: 14938
[14:19:40.289583] Epoch: [1]  [ 80/345]  eta: 0:03:18  lr: 0.000008  loss: 1.5102 (1.5334)  time: 0.7494  data: 0.0001  max mem: 14938
[14:19:55.293191] Epoch: [1]  [100/345]  eta: 0:03:03  lr: 0.000008  loss: 1.4967 (1.5266)  time: 0.7501  data: 0.0001  max mem: 14938
[14:20:10.315925] Epoch: [1]  [120/345]  eta: 0:02:48  lr: 0.000008  loss: 1.4868 (1.5198)  time: 0.7511  data: 0.0001  max mem: 14938
[14:20:25.323010] Epoch: [1]  [140/345]  eta: 0:02:33  lr: 0.000009  loss: 1.4720 (1.5131)  time: 0.7503  data: 0.0001  max mem: 14938
[14:20:40.319146] Epoch: [1]  [160/345]  eta: 0:02:18  lr: 0.000009  loss: 1.4666 (1.5074)  time: 0.7498  data: 0.0001  max mem: 14938
[14:20:55.317267] Epoch: [1]  [180/345]  eta: 0:02:03  lr: 0.000010  loss: 1.4543 (1.5018)  time: 0.7499  data: 0.0001  max mem: 14938
[14:21:10.311950] Epoch: [1]  [200/345]  eta: 0:01:48  lr: 0.000010  loss: 1.4464 (1.4965)  time: 0.7497  data: 0.0001  max mem: 14938
[14:21:25.290260] Epoch: [1]  [220/345]  eta: 0:01:33  lr: 0.000010  loss: 1.4327 (1.4908)  time: 0.7489  data: 0.0001  max mem: 14938
[14:21:40.268145] Epoch: [1]  [240/345]  eta: 0:01:18  lr: 0.000011  loss: 1.4221 (1.4854)  time: 0.7489  data: 0.0001  max mem: 14938
[14:21:55.231189] Epoch: [1]  [260/345]  eta: 0:01:03  lr: 0.000011  loss: 1.4219 (1.4805)  time: 0.7481  data: 0.0001  max mem: 14938
[14:22:10.205191] Epoch: [1]  [280/345]  eta: 0:00:48  lr: 0.000011  loss: 1.4123 (1.4760)  time: 0.7487  data: 0.0001  max mem: 14938
[14:22:25.178783] Epoch: [1]  [300/345]  eta: 0:00:33  lr: 0.000012  loss: 1.4043 (1.4715)  time: 0.7486  data: 0.0001  max mem: 14938
[14:22:40.142053] Epoch: [1]  [320/345]  eta: 0:00:18  lr: 0.000012  loss: 1.4006 (1.4672)  time: 0.7481  data: 0.0001  max mem: 14938

[14:22:55.101127] Epoch: [1]  [340/345]  eta: 0:00:03  lr: 0.000012  loss: 1.3953 (1.4632)  time: 0.7479  data: 0.0001  max mem: 14938
[14:22:58.094238] Epoch: [1]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 1.3953 (1.4624)  time: 0.7480  data: 0.0001  max mem: 14938
[14:22:58.152680] Epoch: [1] Total time: 0:04:18 (0.7493 s / it)
[14:22:58.152972] Averaged stats: lr: 0.000012  loss: 1.3953 (1.4624)
[14:22:58.494774] Test:  [  0/345]  eta: 0:01:56  loss: 1.3930 (1.3930)  time: 0.3376  data: 0.1562  max mem: 14938
[14:23:00.327927] Test:  [ 10/345]  eta: 0:01:06  loss: 1.3928 (1.3932)  time: 0.1973  data: 0.0143  max mem: 14938
[14:23:02.163698] Test:  [ 20/345]  eta: 0:01:01  loss: 1.3929 (1.3935)  time: 0.1834  data: 0.0001  max mem: 14938
[14:23:04.003349] Test:  [ 30/345]  eta: 0:00:59  loss: 1.3929 (1.3933)  time: 0.1837  data: 0.0001  max mem: 14938
[14:23:05.845805] Test:  [ 40/345]  eta: 0:00:57  loss: 1.3927 (1.3930)  time: 0.1841  data: 0.0001  max mem: 14938
[14:23:07.692888] Test:  [ 50/345]  eta: 0:00:55  loss: 1.3925 (1.3929)  time: 0.1844  data: 0.0001  max mem: 14938
[14:23:09.542686] Test:  [ 60/345]  eta: 0:00:53  loss: 1.3926 (1.3930)  time: 0.1848  data: 0.0001  max mem: 14938
[14:23:11.395204] Test:  [ 70/345]  eta: 0:00:51  loss: 1.3935 (1.3931)  time: 0.1851  data: 0.0001  max mem: 14938
[14:23:13.250683] Test:  [ 80/345]  eta: 0:00:49  loss: 1.3934 (1.3931)  time: 0.1853  data: 0.0001  max mem: 14938
[14:23:15.111122] Test:  [ 90/345]  eta: 0:00:47  loss: 1.3922 (1.3930)  time: 0.1857  data: 0.0001  max mem: 14938
[14:23:16.974513] Test:  [100/345]  eta: 0:00:45  loss: 1.3919 (1.3929)  time: 0.1861  data: 0.0001  max mem: 14938
[14:23:18.841974] Test:  [110/345]  eta: 0:00:43  loss: 1.3930 (1.3929)  time: 0.1865  data: 0.0001  max mem: 14938
[14:23:20.711713] Test:  [120/345]  eta: 0:00:41  loss: 1.3930 (1.3929)  time: 0.1868  data: 0.0001  max mem: 14938
[14:23:22.586006] Test:  [130/345]  eta: 0:00:40  loss: 1.3929 (1.3929)  time: 0.1872  data: 0.0001  max mem: 14938
[14:23:24.463797] Test:  [140/345]  eta: 0:00:38  loss: 1.3933 (1.3930)  time: 0.1876  data: 0.0001  max mem: 14938
[14:23:26.345565] Test:  [150/345]  eta: 0:00:36  loss: 1.3927 (1.3929)  time: 0.1879  data: 0.0001  max mem: 14938
[14:23:28.229383] Test:  [160/345]  eta: 0:00:34  loss: 1.3926 (1.3930)  time: 0.1882  data: 0.0001  max mem: 14938
[14:23:30.116920] Test:  [170/345]  eta: 0:00:32  loss: 1.3929 (1.3929)  time: 0.1885  data: 0.0001  max mem: 14938
[14:23:32.009873] Test:  [180/345]  eta: 0:00:30  loss: 1.3934 (1.3930)  time: 0.1890  data: 0.0001  max mem: 14938
[14:23:33.907507] Test:  [190/345]  eta: 0:00:29  loss: 1.3930 (1.3930)  time: 0.1895  data: 0.0001  max mem: 14938
[14:23:35.805452] Test:  [200/345]  eta: 0:00:27  loss: 1.3933 (1.3930)  time: 0.1897  data: 0.0001  max mem: 14938
[14:23:37.706809] Test:  [210/345]  eta: 0:00:25  loss: 1.3935 (1.3930)  time: 0.1899  data: 0.0001  max mem: 14938
[14:23:39.612768] Test:  [220/345]  eta: 0:00:23  loss: 1.3933 (1.3930)  time: 0.1903  data: 0.0001  max mem: 14938
[14:23:41.522141] Test:  [230/345]  eta: 0:00:21  loss: 1.3929 (1.3930)  time: 0.1907  data: 0.0001  max mem: 14938
[14:23:43.434157] Test:  [240/345]  eta: 0:00:19  loss: 1.3929 (1.3930)  time: 0.1910  data: 0.0001  max mem: 14938
[14:23:45.350639] Test:  [250/345]  eta: 0:00:17  loss: 1.3929 (1.3930)  time: 0.1914  data: 0.0001  max mem: 14938
[14:23:47.269778] Test:  [260/345]  eta: 0:00:15  loss: 1.3925 (1.3929)  time: 0.1917  data: 0.0001  max mem: 14938
[14:23:49.194999] Test:  [270/345]  eta: 0:00:14  loss: 1.3925 (1.3929)  time: 0.1922  data: 0.0001  max mem: 14938
[14:23:51.123910] Test:  [280/345]  eta: 0:00:12  loss: 1.3926 (1.3929)  time: 0.1927  data: 0.0001  max mem: 14938
[14:23:53.055865] Test:  [290/345]  eta: 0:00:10  loss: 1.3927 (1.3929)  time: 0.1930  data: 0.0001  max mem: 14938
[14:23:54.990090] Test:  [300/345]  eta: 0:00:08  loss: 1.3926 (1.3929)  time: 0.1933  data: 0.0001  max mem: 14938
[14:23:56.925930] Test:  [310/345]  eta: 0:00:06  loss: 1.3926 (1.3929)  time: 0.1934  data: 0.0001  max mem: 14938
[14:23:58.866035] Test:  [320/345]  eta: 0:00:04  loss: 1.3925 (1.3929)  time: 0.1937  data: 0.0001  max mem: 14938
[14:24:00.808720] Test:  [330/345]  eta: 0:00:02  loss: 1.3925 (1.3929)  time: 0.1941  data: 0.0001  max mem: 14938
[14:24:02.756666] Test:  [340/345]  eta: 0:00:00  loss: 1.3931 (1.3929)  time: 0.1945  data: 0.0001  max mem: 14938
[14:24:03.536665] Test:  [344/345]  eta: 0:00:00  loss: 1.3934 (1.3929)  time: 0.1946  data: 0.0001  max mem: 14938
[14:24:03.596092] Test: Total time: 0:01:05 (0.1897 s / it)
[14:24:14.298424] Test:  [ 0/57]  eta: 0:00:18  loss: 1.4002 (1.4002)  time: 0.3220  data: 0.1433  max mem: 14938
[14:24:16.110256] Test:  [10/57]  eta: 0:00:09  loss: 1.3979 (1.3969)  time: 0.1939  data: 0.0131  max mem: 14938
[14:24:17.925781] Test:  [20/57]  eta: 0:00:06  loss: 1.3979 (1.3960)  time: 0.1813  data: 0.0001  max mem: 14938
[14:24:19.746292] Test:  [30/57]  eta: 0:00:05  loss: 1.3926 (1.3927)  time: 0.1818  data: 0.0001  max mem: 14938
[14:24:21.570804] Test:  [40/57]  eta: 0:00:03  loss: 1.3871 (1.3906)  time: 0.1822  data: 0.0001  max mem: 14938
[14:24:23.401626] Test:  [50/57]  eta: 0:00:01  loss: 1.3871 (1.3899)  time: 0.1827  data: 0.0001  max mem: 14938
[14:24:24.388556] Test:  [56/57]  eta: 0:00:00  loss: 1.3899 (1.3898)  time: 0.1773  data: 0.0001  max mem: 14938
[14:24:24.446573] Test: Total time: 0:00:10 (0.1837 s / it)
[14:24:26.312832] Dice score of the network on the train images: 0.000000, val images: 0.000000
[14:24:26.316933] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:24:27.205300] Epoch: [2]  [  0/345]  eta: 0:05:06  lr: 0.000013  loss: 1.3903 (1.3903)  time: 0.8876  data: 0.1470  max mem: 14938
[14:24:42.063111] Epoch: [2]  [ 20/345]  eta: 0:04:03  lr: 0.000013  loss: 1.3872 (1.3882)  time: 0.7428  data: 0.0001  max mem: 14938
[14:24:56.997477] Epoch: [2]  [ 40/345]  eta: 0:03:48  lr: 0.000013  loss: 1.3834 (1.3868)  time: 0.7467  data: 0.0001  max mem: 14938
[14:25:11.953953] Epoch: [2]  [ 60/345]  eta: 0:03:33  lr: 0.000014  loss: 1.3799 (1.3847)  time: 0.7478  data: 0.0001  max mem: 14938
[14:25:26.931549] Epoch: [2]  [ 80/345]  eta: 0:03:18  lr: 0.000014  loss: 1.3745 (1.3833)  time: 0.7488  data: 0.0001  max mem: 14938
[14:25:41.935252] Epoch: [2]  [100/345]  eta: 0:03:03  lr: 0.000014  loss: 1.3708 (1.3813)  time: 0.7501  data: 0.0001  max mem: 14938
[14:25:56.956490] Epoch: [2]  [120/345]  eta: 0:02:48  lr: 0.000015  loss: 1.3643 (1.3789)  time: 0.7510  data: 0.0001  max mem: 14938
[14:26:11.981632] Epoch: [2]  [140/345]  eta: 0:02:33  lr: 0.000015  loss: 1.3576 (1.3760)  time: 0.7512  data: 0.0001  max mem: 14938
[14:26:26.988619] Epoch: [2]  [160/345]  eta: 0:02:18  lr: 0.000015  loss: 1.3560 (1.3741)  time: 0.7503  data: 0.0001  max mem: 14938
[14:26:41.981845] Epoch: [2]  [180/345]  eta: 0:02:03  lr: 0.000016  loss: 1.3545 (1.3721)  time: 0.7496  data: 0.0001  max mem: 14938
[14:26:56.964496] Epoch: [2]  [200/345]  eta: 0:01:48  lr: 0.000016  loss: 1.3490 (1.3700)  time: 0.7491  data: 0.0001  max mem: 14938
[14:27:11.951343] Epoch: [2]  [220/345]  eta: 0:01:33  lr: 0.000016  loss: 1.3484 (1.3680)  time: 0.7493  data: 0.0001  max mem: 14938
[14:27:26.939450] Epoch: [2]  [240/345]  eta: 0:01:18  lr: 0.000017  loss: 1.3415 (1.3660)  time: 0.7494  data: 0.0001  max mem: 14938
[14:27:41.917566] Epoch: [2]  [260/345]  eta: 0:01:03  lr: 0.000017  loss: 1.3398 (1.3645)  time: 0.7489  data: 0.0001  max mem: 14938
[14:27:56.886732] Epoch: [2]  [280/345]  eta: 0:00:48  lr: 0.000018  loss: 1.3390 (1.3629)  time: 0.7484  data: 0.0001  max mem: 14938
[14:28:11.855446] Epoch: [2]  [300/345]  eta: 0:00:33  lr: 0.000018  loss: 1.3290 (1.3610)  time: 0.7484  data: 0.0001  max mem: 14938
[14:28:26.818744] Epoch: [2]  [320/345]  eta: 0:00:18  lr: 0.000018  loss: 1.3324 (1.3595)  time: 0.7481  data: 0.0001  max mem: 14938
[14:28:41.779927] Epoch: [2]  [340/345]  eta: 0:00:03  lr: 0.000019  loss: 1.3339 (1.3582)  time: 0.7480  data: 0.0001  max mem: 14938
[14:28:44.769713] Epoch: [2]  [344/345]  eta: 0:00:00  lr: 0.000019  loss: 1.3339 (1.3580)  time: 0.7479  data: 0.0001  max mem: 14938
[14:28:44.838974] Epoch: [2] Total time: 0:04:18 (0.7493 s / it)
[14:28:44.839461] Averaged stats: lr: 0.000019  loss: 1.3339 (1.3580)
[14:28:45.182334] Test:  [  0/345]  eta: 0:01:57  loss: 1.3401 (1.3401)  time: 0.3395  data: 0.1582  max mem: 14938
[14:28:47.015763] Test:  [ 10/345]  eta: 0:01:06  loss: 1.3420 (1.3418)  time: 0.1975  data: 0.0144  max mem: 14938
[14:28:48.852289] Test:  [ 20/345]  eta: 0:01:02  loss: 1.3420 (1.3415)  time: 0.1834  data: 0.0001  max mem: 14938
[14:28:50.691534] Test:  [ 30/345]  eta: 0:00:59  loss: 1.3429 (1.3418)  time: 0.1837  data: 0.0001  max mem: 14938
[14:28:52.606852] Test:  [ 40/345]  eta: 0:00:57  loss: 1.3433 (1.3423)  time: 0.1877  data: 0.0001  max mem: 14938
[14:28:54.454548] Test:  [ 50/345]  eta: 0:00:55  loss: 1.3433 (1.3425)  time: 0.1881  data: 0.0001  max mem: 14938
[14:28:56.305571] Test:  [ 60/345]  eta: 0:00:53  loss: 1.3426 (1.3427)  time: 0.1849  data: 0.0001  max mem: 14938
[14:28:58.159269] Test:  [ 70/345]  eta: 0:00:51  loss: 1.3423 (1.3426)  time: 0.1852  data: 0.0001  max mem: 14938
[14:29:00.017422] Test:  [ 80/345]  eta: 0:00:49  loss: 1.3432 (1.3427)  time: 0.1855  data: 0.0001  max mem: 14938
[14:29:01.877143] Test:  [ 90/345]  eta: 0:00:47  loss: 1.3439 (1.3428)  time: 0.1858  data: 0.0001  max mem: 14938
[14:29:03.741660] Test:  [100/345]  eta: 0:00:45  loss: 1.3436 (1.3428)  time: 0.1862  data: 0.0001  max mem: 14938
[14:29:05.609533] Test:  [110/345]  eta: 0:00:43  loss: 1.3430 (1.3428)  time: 0.1866  data: 0.0001  max mem: 14938
[14:29:07.480242] Test:  [120/345]  eta: 0:00:42  loss: 1.3423 (1.3428)  time: 0.1869  data: 0.0001  max mem: 14938
[14:29:09.356081] Test:  [130/345]  eta: 0:00:40  loss: 1.3427 (1.3429)  time: 0.1873  data: 0.0001  max mem: 14938
[14:29:11.236219] Test:  [140/345]  eta: 0:00:38  loss: 1.3431 (1.3428)  time: 0.1877  data: 0.0001  max mem: 14938
[14:29:13.119424] Test:  [150/345]  eta: 0:00:36  loss: 1.3428 (1.3428)  time: 0.1881  data: 0.0001  max mem: 14938
[14:29:15.003283] Test:  [160/345]  eta: 0:00:34  loss: 1.3430 (1.3429)  time: 0.1883  data: 0.0001  max mem: 14938
[14:29:16.891630] Test:  [170/345]  eta: 0:00:32  loss: 1.3426 (1.3428)  time: 0.1886  data: 0.0001  max mem: 14938
[14:29:18.785099] Test:  [180/345]  eta: 0:00:30  loss: 1.3412 (1.3428)  time: 0.1890  data: 0.0001  max mem: 14938
[14:29:20.680861] Test:  [190/345]  eta: 0:00:29  loss: 1.3423 (1.3428)  time: 0.1894  data: 0.0001  max mem: 14938
[14:29:22.581643] Test:  [200/345]  eta: 0:00:27  loss: 1.3428 (1.3428)  time: 0.1898  data: 0.0001  max mem: 14938
[14:29:24.485086] Test:  [210/345]  eta: 0:00:25  loss: 1.3427 (1.3427)  time: 0.1902  data: 0.0001  max mem: 14938
[14:29:26.392315] Test:  [220/345]  eta: 0:00:23  loss: 1.3419 (1.3427)  time: 0.1905  data: 0.0001  max mem: 14938
[14:29:28.304217] Test:  [230/345]  eta: 0:00:21  loss: 1.3440 (1.3428)  time: 0.1909  data: 0.0001  max mem: 14938
[14:29:30.216446] Test:  [240/345]  eta: 0:00:19  loss: 1.3441 (1.3428)  time: 0.1912  data: 0.0001  max mem: 14938
[14:29:32.133469] Test:  [250/345]  eta: 0:00:17  loss: 1.3432 (1.3428)  time: 0.1914  data: 0.0001  max mem: 14938
[14:29:34.055457] Test:  [260/345]  eta: 0:00:16  loss: 1.3430 (1.3428)  time: 0.1919  data: 0.0001  max mem: 14938
[14:29:35.979673] Test:  [270/345]  eta: 0:00:14  loss: 1.3437 (1.3429)  time: 0.1923  data: 0.0001  max mem: 14938
[14:29:37.907546] Test:  [280/345]  eta: 0:00:12  loss: 1.3448 (1.3430)  time: 0.1926  data: 0.0001  max mem: 14938
[14:29:39.839409] Test:  [290/345]  eta: 0:00:10  loss: 1.3436 (1.3429)  time: 0.1929  data: 0.0001  max mem: 14938
[14:29:41.773853] Test:  [300/345]  eta: 0:00:08  loss: 1.3427 (1.3429)  time: 0.1933  data: 0.0001  max mem: 14938
[14:29:43.713274] Test:  [310/345]  eta: 0:00:06  loss: 1.3421 (1.3429)  time: 0.1936  data: 0.0001  max mem: 14938
[14:29:45.653911] Test:  [320/345]  eta: 0:00:04  loss: 1.3428 (1.3429)  time: 0.1940  data: 0.0001  max mem: 14938
[14:29:47.597229] Test:  [330/345]  eta: 0:00:02  loss: 1.3440 (1.3429)  time: 0.1941  data: 0.0001  max mem: 14938
[14:29:49.546178] Test:  [340/345]  eta: 0:00:00  loss: 1.3432 (1.3429)  time: 0.1946  data: 0.0001  max mem: 14938
[14:29:50.327353] Test:  [344/345]  eta: 0:00:00  loss: 1.3435 (1.3430)  time: 0.1947  data: 0.0001  max mem: 14938
[14:29:50.393438] Test: Total time: 0:01:05 (0.1900 s / it)
[14:30:01.115386] Test:  [ 0/57]  eta: 0:00:18  loss: 1.3514 (1.3514)  time: 0.3251  data: 0.1459  max mem: 14938
[14:30:02.928631] Test:  [10/57]  eta: 0:00:09  loss: 1.3484 (1.3475)  time: 0.1943  data: 0.0133  max mem: 14938
[14:30:04.745838] Test:  [20/57]  eta: 0:00:06  loss: 1.3484 (1.3467)  time: 0.1815  data: 0.0001  max mem: 14938
[14:30:06.565790] Test:  [30/57]  eta: 0:00:05  loss: 1.3411 (1.3425)  time: 0.1818  data: 0.0001  max mem: 14938
[14:30:08.390439] Test:  [40/57]  eta: 0:00:03  loss: 1.3346 (1.3398)  time: 0.1822  data: 0.0001  max mem: 14938
[14:30:10.221573] Test:  [50/57]  eta: 0:00:01  loss: 1.3346 (1.3389)  time: 0.1827  data: 0.0001  max mem: 14938
[14:30:11.207984] Test:  [56/57]  eta: 0:00:00  loss: 1.3385 (1.3388)  time: 0.1773  data: 0.0001  max mem: 14938
[14:30:11.269963] Test: Total time: 0:00:10 (0.1839 s / it)
[14:30:13.134306] Dice score of the network on the train images: 0.000000, val images: 0.000000
[14:30:13.138411] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:30:14.027450] Epoch: [3]  [  0/345]  eta: 0:05:06  lr: 0.000019  loss: 1.3233 (1.3233)  time: 0.8881  data: 0.1470  max mem: 14938
[14:30:28.872463] Epoch: [3]  [ 20/345]  eta: 0:04:03  lr: 0.000019  loss: 1.3269 (1.3270)  time: 0.7422  data: 0.0001  max mem: 14938
[14:30:43.783312] Epoch: [3]  [ 40/345]  eta: 0:03:47  lr: 0.000019  loss: 1.3227 (1.3284)  time: 0.7455  data: 0.0001  max mem: 14938
[14:30:58.719827] Epoch: [3]  [ 60/345]  eta: 0:03:32  lr: 0.000020  loss: 1.3264 (1.3277)  time: 0.7468  data: 0.0001  max mem: 14938
[14:31:13.693897] Epoch: [3]  [ 80/345]  eta: 0:03:18  lr: 0.000020  loss: 1.3173 (1.3259)  time: 0.7487  data: 0.0001  max mem: 14938
[14:31:28.687027] Epoch: [3]  [100/345]  eta: 0:03:03  lr: 0.000021  loss: 1.3134 (1.3249)  time: 0.7496  data: 0.0001  max mem: 14938
[14:31:43.700151] Epoch: [3]  [120/345]  eta: 0:02:48  lr: 0.000021  loss: 1.3151 (1.3246)  time: 0.7506  data: 0.0001  max mem: 14938
[14:31:58.710359] Epoch: [3]  [140/345]  eta: 0:02:33  lr: 0.000021  loss: 1.3108 (1.3231)  time: 0.7505  data: 0.0001  max mem: 14938
[14:32:13.712723] Epoch: [3]  [160/345]  eta: 0:02:18  lr: 0.000022  loss: 1.3078 (1.3214)  time: 0.7501  data: 0.0001  max mem: 14938
[14:32:28.707035] Epoch: [3]  [180/345]  eta: 0:02:03  lr: 0.000022  loss: 1.3089 (1.3203)  time: 0.7497  data: 0.0001  max mem: 14938
[14:32:43.697294] Epoch: [3]  [200/345]  eta: 0:01:48  lr: 0.000022  loss: 1.3048 (1.3189)  time: 0.7495  data: 0.0001  max mem: 14938
[14:32:58.674527] Epoch: [3]  [220/345]  eta: 0:01:33  lr: 0.000023  loss: 1.3027 (1.3180)  time: 0.7488  data: 0.0001  max mem: 14938
[14:33:13.639906] Epoch: [3]  [240/345]  eta: 0:01:18  lr: 0.000023  loss: 1.2995 (1.3170)  time: 0.7482  data: 0.0001  max mem: 14938
[14:33:28.593297] Epoch: [3]  [260/345]  eta: 0:01:03  lr: 0.000023  loss: 1.2995 (1.3157)  time: 0.7476  data: 0.0001  max mem: 14938
[14:33:43.546702] Epoch: [3]  [280/345]  eta: 0:00:48  lr: 0.000024  loss: 1.2980 (1.3145)  time: 0.7476  data: 0.0001  max mem: 14938
[14:33:58.487681] Epoch: [3]  [300/345]  eta: 0:00:33  lr: 0.000024  loss: 1.2990 (1.3137)  time: 0.7470  data: 0.0001  max mem: 14938
[14:34:13.435884] Epoch: [3]  [320/345]  eta: 0:00:18  lr: 0.000025  loss: 1.2966 (1.3129)  time: 0.7474  data: 0.0001  max mem: 14938

[14:34:28.387648] Epoch: [3]  [340/345]  eta: 0:00:03  lr: 0.000025  loss: 1.2925 (1.3118)  time: 0.7475  data: 0.0001  max mem: 14938
[14:34:31.379190] Epoch: [3]  [344/345]  eta: 0:00:00  lr: 0.000025  loss: 1.2921 (1.3117)  time: 0.7475  data: 0.0001  max mem: 14938
[14:34:31.440745] Epoch: [3] Total time: 0:04:18 (0.7487 s / it)
[14:34:31.441175] Averaged stats: lr: 0.000025  loss: 1.2921 (1.3117)
[14:34:31.786076] Test:  [  0/345]  eta: 0:01:57  loss: 1.3001 (1.3001)  time: 0.3414  data: 0.1598  max mem: 14938
[14:34:33.621663] Test:  [ 10/345]  eta: 0:01:06  loss: 1.2927 (1.2933)  time: 0.1978  data: 0.0146  max mem: 14938
[14:34:35.458699] Test:  [ 20/345]  eta: 0:01:02  loss: 1.2916 (1.2923)  time: 0.1836  data: 0.0001  max mem: 14938
[14:34:37.298582] Test:  [ 30/345]  eta: 0:00:59  loss: 1.2909 (1.2923)  time: 0.1838  data: 0.0001  max mem: 14938
[14:34:39.142037] Test:  [ 40/345]  eta: 0:00:57  loss: 1.2922 (1.2922)  time: 0.1841  data: 0.0001  max mem: 14938
[14:34:40.991159] Test:  [ 50/345]  eta: 0:00:55  loss: 1.2924 (1.2922)  time: 0.1846  data: 0.0001  max mem: 14938
[14:34:42.843518] Test:  [ 60/345]  eta: 0:00:53  loss: 1.2911 (1.2920)  time: 0.1850  data: 0.0001  max mem: 14938
[14:34:44.698994] Test:  [ 70/345]  eta: 0:00:51  loss: 1.2923 (1.2921)  time: 0.1853  data: 0.0001  max mem: 14938
[14:34:46.557012] Test:  [ 80/345]  eta: 0:00:49  loss: 1.2923 (1.2920)  time: 0.1856  data: 0.0001  max mem: 14938
[14:34:48.416989] Test:  [ 90/345]  eta: 0:00:47  loss: 1.2897 (1.2917)  time: 0.1858  data: 0.0001  max mem: 14938
[14:34:50.279878] Test:  [100/345]  eta: 0:00:45  loss: 1.2895 (1.2916)  time: 0.1861  data: 0.0001  max mem: 14938
[14:34:52.146338] Test:  [110/345]  eta: 0:00:43  loss: 1.2896 (1.2916)  time: 0.1864  data: 0.0001  max mem: 14938
[14:34:54.019892] Test:  [120/345]  eta: 0:00:41  loss: 1.2919 (1.2916)  time: 0.1869  data: 0.0001  max mem: 14938
[14:34:55.895619] Test:  [130/345]  eta: 0:00:40  loss: 1.2904 (1.2914)  time: 0.1874  data: 0.0001  max mem: 14938
[14:34:57.773231] Test:  [140/345]  eta: 0:00:38  loss: 1.2904 (1.2914)  time: 0.1876  data: 0.0001  max mem: 14938
[14:34:59.654989] Test:  [150/345]  eta: 0:00:36  loss: 1.2922 (1.2914)  time: 0.1879  data: 0.0001  max mem: 14938
[14:35:01.540437] Test:  [160/345]  eta: 0:00:34  loss: 1.2917 (1.2915)  time: 0.1883  data: 0.0001  max mem: 14938
[14:35:03.430060] Test:  [170/345]  eta: 0:00:32  loss: 1.2909 (1.2914)  time: 0.1887  data: 0.0001  max mem: 14938
[14:35:05.325641] Test:  [180/345]  eta: 0:00:30  loss: 1.2902 (1.2913)  time: 0.1892  data: 0.0001  max mem: 14938
[14:35:07.223221] Test:  [190/345]  eta: 0:00:29  loss: 1.2911 (1.2913)  time: 0.1896  data: 0.0001  max mem: 14938
[14:35:09.123721] Test:  [200/345]  eta: 0:00:27  loss: 1.2924 (1.2914)  time: 0.1899  data: 0.0001  max mem: 14938
[14:35:11.024841] Test:  [210/345]  eta: 0:00:25  loss: 1.2924 (1.2914)  time: 0.1900  data: 0.0001  max mem: 14938
[14:35:12.932722] Test:  [220/345]  eta: 0:00:23  loss: 1.2900 (1.2914)  time: 0.1904  data: 0.0001  max mem: 14938
[14:35:14.843635] Test:  [230/345]  eta: 0:00:21  loss: 1.2900 (1.2913)  time: 0.1909  data: 0.0001  max mem: 14938
[14:35:16.758714] Test:  [240/345]  eta: 0:00:19  loss: 1.2873 (1.2912)  time: 0.1912  data: 0.0001  max mem: 14938
[14:35:18.678400] Test:  [250/345]  eta: 0:00:17  loss: 1.2919 (1.2913)  time: 0.1917  data: 0.0001  max mem: 14938
[14:35:20.598865] Test:  [260/345]  eta: 0:00:16  loss: 1.2922 (1.2913)  time: 0.1920  data: 0.0001  max mem: 14938
[14:35:22.525233] Test:  [270/345]  eta: 0:00:14  loss: 1.2914 (1.2913)  time: 0.1923  data: 0.0001  max mem: 14938
[14:35:24.454413] Test:  [280/345]  eta: 0:00:12  loss: 1.2904 (1.2913)  time: 0.1927  data: 0.0001  max mem: 14938
[14:35:26.387472] Test:  [290/345]  eta: 0:00:10  loss: 1.2920 (1.2913)  time: 0.1931  data: 0.0001  max mem: 14938
[14:35:28.322227] Test:  [300/345]  eta: 0:00:08  loss: 1.2933 (1.2913)  time: 0.1933  data: 0.0001  max mem: 14938
[14:35:30.260180] Test:  [310/345]  eta: 0:00:06  loss: 1.2933 (1.2913)  time: 0.1936  data: 0.0001  max mem: 14938
[14:35:32.201270] Test:  [320/345]  eta: 0:00:04  loss: 1.2901 (1.2913)  time: 0.1939  data: 0.0001  max mem: 14938
[14:35:34.145036] Test:  [330/345]  eta: 0:00:02  loss: 1.2897 (1.2913)  time: 0.1942  data: 0.0001  max mem: 14938
[14:35:36.092529] Test:  [340/345]  eta: 0:00:00  loss: 1.2910 (1.2913)  time: 0.1945  data: 0.0001  max mem: 14938
[14:35:36.873285] Test:  [344/345]  eta: 0:00:00  loss: 1.2898 (1.2913)  time: 0.1947  data: 0.0001  max mem: 14938
[14:35:36.935101] Test: Total time: 0:01:05 (0.1898 s / it)
[14:35:47.589686] Test:  [ 0/57]  eta: 0:00:18  loss: 1.3050 (1.3050)  time: 0.3254  data: 0.1460  max mem: 14938
[14:35:49.404413] Test:  [10/57]  eta: 0:00:09  loss: 1.2994 (1.2985)  time: 0.1945  data: 0.0133  max mem: 14938
[14:35:51.223162] Test:  [20/57]  eta: 0:00:06  loss: 1.2994 (1.2979)  time: 0.1816  data: 0.0001  max mem: 14938
[14:35:53.046652] Test:  [30/57]  eta: 0:00:05  loss: 1.2839 (1.2901)  time: 0.1821  data: 0.0001  max mem: 14938
[14:35:54.875068] Test:  [40/57]  eta: 0:00:03  loss: 1.2726 (1.2851)  time: 0.1825  data: 0.0001  max mem: 14938
[14:35:56.706969] Test:  [50/57]  eta: 0:00:01  loss: 1.2726 (1.2832)  time: 0.1830  data: 0.0001  max mem: 14938
[14:35:57.694857] Test:  [56/57]  eta: 0:00:00  loss: 1.2800 (1.2829)  time: 0.1775  data: 0.0001  max mem: 14938
[14:35:57.755794] Test: Total time: 0:00:10 (0.1841 s / it)
[14:35:59.602361] Dice score of the network on the train images: 0.000000, val images: 0.000000
[14:35:59.606628] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:36:00.498926] Epoch: [4]  [  0/345]  eta: 0:05:07  lr: 0.000025  loss: 1.2984 (1.2984)  time: 0.8914  data: 0.1504  max mem: 14938
[14:36:15.387264] Epoch: [4]  [ 20/345]  eta: 0:04:04  lr: 0.000025  loss: 1.2864 (1.2910)  time: 0.7444  data: 0.0001  max mem: 14938
[14:36:30.324101] Epoch: [4]  [ 40/345]  eta: 0:03:48  lr: 0.000026  loss: 1.2881 (1.2895)  time: 0.7468  data: 0.0001  max mem: 14938
[14:36:45.303987] Epoch: [4]  [ 60/345]  eta: 0:03:33  lr: 0.000026  loss: 1.2772 (1.2875)  time: 0.7489  data: 0.0001  max mem: 14938
[14:37:00.301883] Epoch: [4]  [ 80/345]  eta: 0:03:18  lr: 0.000026  loss: 1.2740 (1.2849)  time: 0.7498  data: 0.0001  max mem: 14938
[14:37:15.308122] Epoch: [4]  [100/345]  eta: 0:03:03  lr: 0.000027  loss: 1.2696 (1.2826)  time: 0.7503  data: 0.0001  max mem: 14938
[14:37:30.453398] Epoch: [4]  [120/345]  eta: 0:02:48  lr: 0.000027  loss: 1.2637 (1.2796)  time: 0.7572  data: 0.0001  max mem: 14938
[14:37:45.488578] Epoch: [4]  [140/345]  eta: 0:02:33  lr: 0.000028  loss: 1.2583 (1.2768)  time: 0.7517  data: 0.0001  max mem: 14938
[14:38:00.512002] Epoch: [4]  [160/345]  eta: 0:02:18  lr: 0.000028  loss: 1.2646 (1.2751)  time: 0.7511  data: 0.0001  max mem: 14938
[14:38:15.518870] Epoch: [4]  [180/345]  eta: 0:02:03  lr: 0.000028  loss: 1.2414 (1.2719)  time: 0.7503  data: 0.0001  max mem: 14938
[14:38:30.513222] Epoch: [4]  [200/345]  eta: 0:01:48  lr: 0.000029  loss: 1.2341 (1.2682)  time: 0.7497  data: 0.0001  max mem: 14938
[14:38:45.500579] Epoch: [4]  [220/345]  eta: 0:01:33  lr: 0.000029  loss: 1.2287 (1.2650)  time: 0.7493  data: 0.0001  max mem: 14938
[14:39:00.484235] Epoch: [4]  [240/345]  eta: 0:01:18  lr: 0.000029  loss: 1.2205 (1.2614)  time: 0.7491  data: 0.0001  max mem: 14938
[14:39:15.467520] Epoch: [4]  [260/345]  eta: 0:01:03  lr: 0.000030  loss: 1.2116 (1.2577)  time: 0.7491  data: 0.0001  max mem: 14938
[14:39:30.449352] Epoch: [4]  [280/345]  eta: 0:00:48  lr: 0.000030  loss: 1.2046 (1.2539)  time: 0.7490  data: 0.0001  max mem: 14938
[14:39:45.417524] Epoch: [4]  [300/345]  eta: 0:00:33  lr: 0.000030  loss: 1.1858 (1.2498)  time: 0.7484  data: 0.0001  max mem: 14938
[14:40:00.391737] Epoch: [4]  [320/345]  eta: 0:00:18  lr: 0.000031  loss: 1.1773 (1.2456)  time: 0.7487  data: 0.0001  max mem: 14938
[14:40:15.372427] Epoch: [4]  [340/345]  eta: 0:00:03  lr: 0.000031  loss: 1.1820 (1.2419)  time: 0.7490  data: 0.0001  max mem: 14938
[14:40:18.374846] Epoch: [4]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 1.1820 (1.2414)  time: 0.7494  data: 0.0001  max mem: 14938
[14:40:18.443580] Epoch: [4] Total time: 0:04:18 (0.7503 s / it)
[14:40:18.444000] Averaged stats: lr: 0.000031  loss: 1.1820 (1.2414)
[14:40:18.792929] Test:  [  0/345]  eta: 0:01:59  loss: 1.1807 (1.1807)  time: 0.3449  data: 0.1630  max mem: 14938
[14:40:20.627399] Test:  [ 10/345]  eta: 0:01:06  loss: 1.1651 (1.1607)  time: 0.1981  data: 0.0149  max mem: 14938
[14:40:22.463774] Test:  [ 20/345]  eta: 0:01:02  loss: 1.1549 (1.1593)  time: 0.1835  data: 0.0001  max mem: 14938
[14:40:24.303550] Test:  [ 30/345]  eta: 0:00:59  loss: 1.1523 (1.1532)  time: 0.1837  data: 0.0001  max mem: 14938
[14:40:26.145241] Test:  [ 40/345]  eta: 0:00:57  loss: 1.1523 (1.1555)  time: 0.1840  data: 0.0001  max mem: 14938
[14:40:27.993219] Test:  [ 50/345]  eta: 0:00:55  loss: 1.1538 (1.1535)  time: 0.1844  data: 0.0001  max mem: 14938
[14:40:29.844778] Test:  [ 60/345]  eta: 0:00:53  loss: 1.1501 (1.1537)  time: 0.1849  data: 0.0001  max mem: 14938
[14:40:31.697714] Test:  [ 70/345]  eta: 0:00:51  loss: 1.1498 (1.1531)  time: 0.1852  data: 0.0001  max mem: 14938
[14:40:33.555613] Test:  [ 80/345]  eta: 0:00:49  loss: 1.1452 (1.1523)  time: 0.1855  data: 0.0001  max mem: 14938
[14:40:35.416094] Test:  [ 90/345]  eta: 0:00:47  loss: 1.1496 (1.1525)  time: 0.1859  data: 0.0001  max mem: 14938
[14:40:37.280296] Test:  [100/345]  eta: 0:00:45  loss: 1.1516 (1.1519)  time: 0.1862  data: 0.0001  max mem: 14938
[14:40:39.148381] Test:  [110/345]  eta: 0:00:43  loss: 1.1516 (1.1524)  time: 0.1866  data: 0.0001  max mem: 14938
[14:40:41.018300] Test:  [120/345]  eta: 0:00:41  loss: 1.1476 (1.1518)  time: 0.1868  data: 0.0001  max mem: 14938
[14:40:42.891583] Test:  [130/345]  eta: 0:00:40  loss: 1.1432 (1.1506)  time: 0.1871  data: 0.0001  max mem: 14938
[14:40:44.768538] Test:  [140/345]  eta: 0:00:38  loss: 1.1490 (1.1510)  time: 0.1875  data: 0.0001  max mem: 14938
[14:40:46.648755] Test:  [150/345]  eta: 0:00:36  loss: 1.1549 (1.1514)  time: 0.1878  data: 0.0001  max mem: 14938
[14:40:48.532144] Test:  [160/345]  eta: 0:00:34  loss: 1.1491 (1.1501)  time: 0.1881  data: 0.0001  max mem: 14938
[14:40:50.419799] Test:  [170/345]  eta: 0:00:32  loss: 1.1453 (1.1505)  time: 0.1885  data: 0.0001  max mem: 14938
[14:40:52.314498] Test:  [180/345]  eta: 0:00:30  loss: 1.1458 (1.1502)  time: 0.1891  data: 0.0001  max mem: 14938
[14:40:54.209711] Test:  [190/345]  eta: 0:00:29  loss: 1.1444 (1.1499)  time: 0.1894  data: 0.0001  max mem: 14938
[14:40:56.109790] Test:  [200/345]  eta: 0:00:27  loss: 1.1535 (1.1503)  time: 0.1897  data: 0.0001  max mem: 14938
[14:40:58.010315] Test:  [210/345]  eta: 0:00:25  loss: 1.1619 (1.1510)  time: 0.1900  data: 0.0001  max mem: 14938
[14:40:59.915218] Test:  [220/345]  eta: 0:00:23  loss: 1.1642 (1.1514)  time: 0.1902  data: 0.0001  max mem: 14938
[14:41:01.824831] Test:  [230/345]  eta: 0:00:21  loss: 1.1524 (1.1515)  time: 0.1907  data: 0.0001  max mem: 14938
[14:41:03.736775] Test:  [240/345]  eta: 0:00:19  loss: 1.1593 (1.1519)  time: 0.1910  data: 0.0001  max mem: 14938
[14:41:05.654679] Test:  [250/345]  eta: 0:00:17  loss: 1.1619 (1.1521)  time: 0.1914  data: 0.0001  max mem: 14938
[14:41:07.572830] Test:  [260/345]  eta: 0:00:15  loss: 1.1581 (1.1522)  time: 0.1918  data: 0.0001  max mem: 14938
[14:41:09.498290] Test:  [270/345]  eta: 0:00:14  loss: 1.1545 (1.1523)  time: 0.1921  data: 0.0001  max mem: 14938
[14:41:11.424610] Test:  [280/345]  eta: 0:00:12  loss: 1.1563 (1.1528)  time: 0.1925  data: 0.0001  max mem: 14938
[14:41:13.354660] Test:  [290/345]  eta: 0:00:10  loss: 1.1691 (1.1534)  time: 0.1928  data: 0.0001  max mem: 14938
[14:41:15.287132] Test:  [300/345]  eta: 0:00:08  loss: 1.1535 (1.1534)  time: 0.1931  data: 0.0001  max mem: 14938
[14:41:17.224356] Test:  [310/345]  eta: 0:00:06  loss: 1.1511 (1.1536)  time: 0.1934  data: 0.0001  max mem: 14938
[14:41:19.167308] Test:  [320/345]  eta: 0:00:04  loss: 1.1511 (1.1534)  time: 0.1940  data: 0.0001  max mem: 14938
[14:41:21.109151] Test:  [330/345]  eta: 0:00:02  loss: 1.1548 (1.1535)  time: 0.1942  data: 0.0001  max mem: 14938
[14:41:23.053527] Test:  [340/345]  eta: 0:00:00  loss: 1.1591 (1.1534)  time: 0.1943  data: 0.0001  max mem: 14938
[14:41:23.833635] Test:  [344/345]  eta: 0:00:00  loss: 1.1548 (1.1533)  time: 0.1944  data: 0.0001  max mem: 14938
[14:41:23.895781] Test: Total time: 0:01:05 (0.1897 s / it)
[14:41:34.522975] Test:  [ 0/57]  eta: 0:00:18  loss: 1.2297 (1.2297)  time: 0.3288  data: 0.1493  max mem: 14938
[14:41:36.336060] Test:  [10/57]  eta: 0:00:09  loss: 1.2044 (1.1936)  time: 0.1946  data: 0.0136  max mem: 14938
[14:41:38.152309] Test:  [20/57]  eta: 0:00:06  loss: 1.2149 (1.1951)  time: 0.1814  data: 0.0001  max mem: 14938
[14:41:39.972609] Test:  [30/57]  eta: 0:00:05  loss: 1.1272 (1.1480)  time: 0.1818  data: 0.0001  max mem: 14938
[14:41:41.798961] Test:  [40/57]  eta: 0:00:03  loss: 1.0375 (1.1183)  time: 0.1823  data: 0.0001  max mem: 14938
[14:41:43.628169] Test:  [50/57]  eta: 0:00:01  loss: 1.0401 (1.1098)  time: 0.1827  data: 0.0001  max mem: 14938
[14:41:44.616008] Test:  [56/57]  eta: 0:00:00  loss: 1.0970 (1.1138)  time: 0.1774  data: 0.0001  max mem: 14938
[14:41:44.674774] Test: Total time: 0:00:10 (0.1839 s / it)
[14:41:46.480341] Dice score of the network on the train images: 0.522585, val images: 0.622035
[14:41:46.480570] saving best_prec_model_0 @ epoch 4
[14:41:47.205475] saving best_rec_model_0 @ epoch 4
[14:41:47.895899] saving best_dice_model_0 @ epoch 4
[14:41:49.041954] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:41:49.928160] Epoch: [5]  [  0/345]  eta: 0:05:05  lr: 0.000031  loss: 1.2067 (1.2067)  time: 0.8852  data: 0.1457  max mem: 14938
[14:42:04.755830] Epoch: [5]  [ 20/345]  eta: 0:04:03  lr: 0.000032  loss: 1.1559 (1.1634)  time: 0.7413  data: 0.0001  max mem: 14938
[14:42:19.664827] Epoch: [5]  [ 40/345]  eta: 0:03:47  lr: 0.000032  loss: 1.1516 (1.1596)  time: 0.7454  data: 0.0001  max mem: 14938
[14:42:34.617739] Epoch: [5]  [ 60/345]  eta: 0:03:32  lr: 0.000032  loss: 1.1608 (1.1604)  time: 0.7476  data: 0.0001  max mem: 14938
[14:42:49.605591] Epoch: [5]  [ 80/345]  eta: 0:03:18  lr: 0.000033  loss: 1.1414 (1.1572)  time: 0.7493  data: 0.0001  max mem: 14938
[14:43:04.626113] Epoch: [5]  [100/345]  eta: 0:03:03  lr: 0.000033  loss: 1.1394 (1.1538)  time: 0.7510  data: 0.0001  max mem: 14938
[14:43:19.658706] Epoch: [5]  [120/345]  eta: 0:02:48  lr: 0.000033  loss: 1.1146 (1.1487)  time: 0.7516  data: 0.0001  max mem: 14938
[14:43:34.679042] Epoch: [5]  [140/345]  eta: 0:02:33  lr: 0.000034  loss: 1.1218 (1.1450)  time: 0.7510  data: 0.0001  max mem: 14938
[14:43:49.674405] Epoch: [5]  [160/345]  eta: 0:02:18  lr: 0.000034  loss: 1.1245 (1.1421)  time: 0.7497  data: 0.0001  max mem: 14938
[14:44:04.661889] Epoch: [5]  [180/345]  eta: 0:02:03  lr: 0.000035  loss: 1.1248 (1.1398)  time: 0.7493  data: 0.0001  max mem: 14938
[14:44:19.644248] Epoch: [5]  [200/345]  eta: 0:01:48  lr: 0.000035  loss: 1.0984 (1.1364)  time: 0.7491  data: 0.0001  max mem: 14938
[14:44:34.620506] Epoch: [5]  [220/345]  eta: 0:01:33  lr: 0.000035  loss: 1.0899 (1.1322)  time: 0.7488  data: 0.0001  max mem: 14938
[14:44:49.601431] Epoch: [5]  [240/345]  eta: 0:01:18  lr: 0.000036  loss: 1.0831 (1.1285)  time: 0.7490  data: 0.0001  max mem: 14938
[14:45:04.576880] Epoch: [5]  [260/345]  eta: 0:01:03  lr: 0.000036  loss: 1.0778 (1.1251)  time: 0.7487  data: 0.0001  max mem: 14938
[14:45:19.550042] Epoch: [5]  [280/345]  eta: 0:00:48  lr: 0.000036  loss: 1.0883 (1.1230)  time: 0.7486  data: 0.0001  max mem: 14938
[14:45:34.521128] Epoch: [5]  [300/345]  eta: 0:00:33  lr: 0.000037  loss: 1.0670 (1.1192)  time: 0.7485  data: 0.0001  max mem: 14938
[14:45:49.492829] Epoch: [5]  [320/345]  eta: 0:00:18  lr: 0.000037  loss: 1.0666 (1.1165)  time: 0.7485  data: 0.0001  max mem: 14938
[14:46:04.465799] Epoch: [5]  [340/345]  eta: 0:00:03  lr: 0.000037  loss: 1.0665 (1.1136)  time: 0.7486  data: 0.0001  max mem: 14938
[14:46:07.460723] Epoch: [5]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 1.0670 (1.1129)  time: 0.7486  data: 0.0001  max mem: 14938
[14:46:07.519471] Epoch: [5] Total time: 0:04:18 (0.7492 s / it)
[14:46:07.519594] Averaged stats: lr: 0.000037  loss: 1.0670 (1.1129)
[14:46:07.859508] Test:  [  0/345]  eta: 0:01:55  loss: 0.9764 (0.9764)  time: 0.3354  data: 0.1539  max mem: 14938
[14:46:09.693277] Test:  [ 10/345]  eta: 0:01:06  loss: 1.0174 (1.0130)  time: 0.1971  data: 0.0141  max mem: 14938
[14:46:11.530487] Test:  [ 20/345]  eta: 0:01:01  loss: 1.0179 (1.0170)  time: 0.1835  data: 0.0001  max mem: 14938
[14:46:13.368987] Test:  [ 30/345]  eta: 0:00:59  loss: 1.0223 (1.0217)  time: 0.1837  data: 0.0001  max mem: 14938
[14:46:15.211016] Test:  [ 40/345]  eta: 0:00:57  loss: 1.0185 (1.0203)  time: 0.1840  data: 0.0001  max mem: 14938
[14:46:17.057019] Test:  [ 50/345]  eta: 0:00:55  loss: 1.0154 (1.0209)  time: 0.1843  data: 0.0001  max mem: 14938
[14:46:18.906989] Test:  [ 60/345]  eta: 0:00:53  loss: 1.0097 (1.0193)  time: 0.1847  data: 0.0001  max mem: 14938
[14:46:20.757723] Test:  [ 70/345]  eta: 0:00:51  loss: 1.0150 (1.0206)  time: 0.1850  data: 0.0001  max mem: 14938
[14:46:22.613678] Test:  [ 80/345]  eta: 0:00:49  loss: 1.0208 (1.0207)  time: 0.1853  data: 0.0001  max mem: 14938
[14:46:24.473556] Test:  [ 90/345]  eta: 0:00:47  loss: 1.0119 (1.0199)  time: 0.1857  data: 0.0001  max mem: 14938
[14:46:26.336398] Test:  [100/345]  eta: 0:00:45  loss: 1.0119 (1.0192)  time: 0.1861  data: 0.0001  max mem: 14938
[14:46:28.203602] Test:  [110/345]  eta: 0:00:43  loss: 1.0099 (1.0188)  time: 0.1864  data: 0.0001  max mem: 14938
[14:46:30.074148] Test:  [120/345]  eta: 0:00:41  loss: 1.0162 (1.0186)  time: 0.1868  data: 0.0001  max mem: 14938
[14:46:31.948037] Test:  [130/345]  eta: 0:00:40  loss: 1.0231 (1.0194)  time: 0.1872  data: 0.0001  max mem: 14938
[14:46:33.824099] Test:  [140/345]  eta: 0:00:38  loss: 1.0292 (1.0202)  time: 0.1874  data: 0.0001  max mem: 14938
[14:46:35.704269] Test:  [150/345]  eta: 0:00:36  loss: 1.0292 (1.0205)  time: 0.1878  data: 0.0001  max mem: 14938
[14:46:37.589396] Test:  [160/345]  eta: 0:00:34  loss: 1.0271 (1.0201)  time: 0.1882  data: 0.0001  max mem: 14938
[14:46:39.475999] Test:  [170/345]  eta: 0:00:32  loss: 1.0152 (1.0200)  time: 0.1885  data: 0.0001  max mem: 14938
[14:46:41.369103] Test:  [180/345]  eta: 0:00:30  loss: 1.0181 (1.0200)  time: 0.1889  data: 0.0001  max mem: 14938
[14:46:43.264848] Test:  [190/345]  eta: 0:00:28  loss: 1.0175 (1.0197)  time: 0.1894  data: 0.0001  max mem: 14938
[14:46:45.163084] Test:  [200/345]  eta: 0:00:27  loss: 1.0269 (1.0204)  time: 0.1897  data: 0.0001  max mem: 14938
[14:46:47.064048] Test:  [210/345]  eta: 0:00:25  loss: 1.0290 (1.0205)  time: 0.1899  data: 0.0001  max mem: 14938
[14:46:48.968822] Test:  [220/345]  eta: 0:00:23  loss: 1.0048 (1.0195)  time: 0.1902  data: 0.0001  max mem: 14938
[14:46:50.880079] Test:  [230/345]  eta: 0:00:21  loss: 1.0053 (1.0191)  time: 0.1908  data: 0.0001  max mem: 14938
[14:46:52.793789] Test:  [240/345]  eta: 0:00:19  loss: 1.0187 (1.0197)  time: 0.1912  data: 0.0001  max mem: 14938
[14:46:54.711946] Test:  [250/345]  eta: 0:00:17  loss: 1.0283 (1.0197)  time: 0.1915  data: 0.0001  max mem: 14938
[14:46:56.631654] Test:  [260/345]  eta: 0:00:15  loss: 1.0279 (1.0202)  time: 0.1918  data: 0.0001  max mem: 14938
[14:46:58.555481] Test:  [270/345]  eta: 0:00:14  loss: 1.0292 (1.0203)  time: 0.1921  data: 0.0001  max mem: 14938
[14:47:00.481336] Test:  [280/345]  eta: 0:00:12  loss: 1.0292 (1.0207)  time: 0.1924  data: 0.0001  max mem: 14938
[14:47:02.411636] Test:  [290/345]  eta: 0:00:10  loss: 1.0132 (1.0209)  time: 0.1928  data: 0.0001  max mem: 14938
[14:47:04.346920] Test:  [300/345]  eta: 0:00:08  loss: 1.0264 (1.0215)  time: 0.1932  data: 0.0001  max mem: 14938
[14:47:06.284444] Test:  [310/345]  eta: 0:00:06  loss: 1.0227 (1.0213)  time: 0.1936  data: 0.0001  max mem: 14938
[14:47:08.225759] Test:  [320/345]  eta: 0:00:04  loss: 1.0136 (1.0213)  time: 0.1939  data: 0.0001  max mem: 14938
[14:47:10.168741] Test:  [330/345]  eta: 0:00:02  loss: 1.0148 (1.0212)  time: 0.1942  data: 0.0001  max mem: 14938
[14:47:12.115705] Test:  [340/345]  eta: 0:00:00  loss: 1.0153 (1.0208)  time: 0.1944  data: 0.0001  max mem: 14938
[14:47:12.896511] Test:  [344/345]  eta: 0:00:00  loss: 1.0153 (1.0209)  time: 0.1946  data: 0.0001  max mem: 14938
[14:47:12.957583] Test: Total time: 0:01:05 (0.1897 s / it)
[14:47:23.449281] Test:  [ 0/57]  eta: 0:00:18  loss: 1.1079 (1.1079)  time: 0.3255  data: 0.1463  max mem: 14938
[14:47:25.263059] Test:  [10/57]  eta: 0:00:09  loss: 1.0810 (1.0736)  time: 0.1944  data: 0.0134  max mem: 14938
[14:47:27.079362] Test:  [20/57]  eta: 0:00:06  loss: 1.1072 (1.0802)  time: 0.1814  data: 0.0001  max mem: 14938
[14:47:28.900298] Test:  [30/57]  eta: 0:00:05  loss: 0.9626 (1.0236)  time: 0.1818  data: 0.0001  max mem: 14938
[14:47:30.725174] Test:  [40/57]  eta: 0:00:03  loss: 0.8896 (0.9895)  time: 0.1822  data: 0.0001  max mem: 14938
[14:47:32.556557] Test:  [50/57]  eta: 0:00:01  loss: 0.8896 (0.9798)  time: 0.1828  data: 0.0001  max mem: 14938
[14:47:33.544298] Test:  [56/57]  eta: 0:00:00  loss: 0.9673 (0.9849)  time: 0.1775  data: 0.0001  max mem: 14938
[14:47:33.604490] Test: Total time: 0:00:10 (0.1839 s / it)
[14:47:35.355575] Dice score of the network on the train images: 0.673510, val images: 0.729800
[14:47:35.355793] saving best_prec_model_0 @ epoch 5
[14:47:36.471753] saving best_dice_model_0 @ epoch 5
[14:47:37.484560] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:47:38.376805] Epoch: [6]  [  0/345]  eta: 0:05:07  lr: 0.000038  loss: 1.0379 (1.0379)  time: 0.8914  data: 0.1513  max mem: 14938
[14:47:53.235020] Epoch: [6]  [ 20/345]  eta: 0:04:03  lr: 0.000038  loss: 1.0474 (1.0480)  time: 0.7429  data: 0.0001  max mem: 14938
[14:48:08.152595] Epoch: [6]  [ 40/345]  eta: 0:03:48  lr: 0.000038  loss: 1.0442 (1.0500)  time: 0.7458  data: 0.0001  max mem: 14938
[14:48:23.109370] Epoch: [6]  [ 60/345]  eta: 0:03:33  lr: 0.000039  loss: 1.0403 (1.0453)  time: 0.7478  data: 0.0001  max mem: 14938
[14:48:38.077882] Epoch: [6]  [ 80/345]  eta: 0:03:18  lr: 0.000039  loss: 1.0382 (1.0425)  time: 0.7484  data: 0.0001  max mem: 14938
[14:48:53.069566] Epoch: [6]  [100/345]  eta: 0:03:03  lr: 0.000039  loss: 1.0328 (1.0421)  time: 0.7495  data: 0.0001  max mem: 14938
[14:49:08.083739] Epoch: [6]  [120/345]  eta: 0:02:48  lr: 0.000040  loss: 1.0214 (1.0393)  time: 0.7507  data: 0.0001  max mem: 14938
[14:49:23.094850] Epoch: [6]  [140/345]  eta: 0:02:33  lr: 0.000040  loss: 1.0408 (1.0394)  time: 0.7505  data: 0.0001  max mem: 14938
[14:49:38.091869] Epoch: [6]  [160/345]  eta: 0:02:18  lr: 0.000040  loss: 1.0073 (1.0356)  time: 0.7498  data: 0.0001  max mem: 14938
[14:49:53.085037] Epoch: [6]  [180/345]  eta: 0:02:03  lr: 0.000041  loss: 1.0060 (1.0328)  time: 0.7496  data: 0.0001  max mem: 14938
[14:50:08.068682] Epoch: [6]  [200/345]  eta: 0:01:48  lr: 0.000041  loss: 1.0079 (1.0308)  time: 0.7491  data: 0.0001  max mem: 14938
[14:50:23.055079] Epoch: [6]  [220/345]  eta: 0:01:33  lr: 0.000041  loss: 1.0130 (1.0293)  time: 0.7493  data: 0.0001  max mem: 14938
[14:50:38.052177] Epoch: [6]  [240/345]  eta: 0:01:18  lr: 0.000042  loss: 0.9993 (1.0265)  time: 0.7498  data: 0.0001  max mem: 14938
[14:50:53.039419] Epoch: [6]  [260/345]  eta: 0:01:03  lr: 0.000042  loss: 0.9856 (1.0247)  time: 0.7493  data: 0.0001  max mem: 14938
[14:51:08.005345] Epoch: [6]  [280/345]  eta: 0:00:48  lr: 0.000043  loss: 0.9751 (1.0213)  time: 0.7483  data: 0.0001  max mem: 14938
[14:51:22.981632] Epoch: [6]  [300/345]  eta: 0:00:33  lr: 0.000043  loss: 0.9783 (1.0191)  time: 0.7488  data: 0.0001  max mem: 14938
[14:51:37.959295] Epoch: [6]  [320/345]  eta: 0:00:18  lr: 0.000043  loss: 0.9743 (1.0169)  time: 0.7488  data: 0.0001  max mem: 14938
[14:51:52.929102] Epoch: [6]  [340/345]  eta: 0:00:03  lr: 0.000044  loss: 0.9728 (1.0149)  time: 0.7484  data: 0.0001  max mem: 14938
[14:51:55.928995] Epoch: [6]  [344/345]  eta: 0:00:00  lr: 0.000044  loss: 0.9862 (1.0149)  time: 0.7486  data: 0.0001  max mem: 14938
[14:51:55.996011] Epoch: [6] Total time: 0:04:18 (0.7493 s / it)
[14:51:55.996522] Averaged stats: lr: 0.000044  loss: 0.9862 (1.0149)
[14:51:56.349068] Test:  [  0/345]  eta: 0:02:00  loss: 0.9487 (0.9487)  time: 0.3485  data: 0.1671  max mem: 14938
[14:51:58.182535] Test:  [ 10/345]  eta: 0:01:06  loss: 0.9339 (0.9331)  time: 0.1983  data: 0.0152  max mem: 14938
[14:52:00.019264] Test:  [ 20/345]  eta: 0:01:02  loss: 0.9418 (0.9447)  time: 0.1834  data: 0.0001  max mem: 14938
[14:52:01.860486] Test:  [ 30/345]  eta: 0:00:59  loss: 0.9470 (0.9431)  time: 0.1838  data: 0.0001  max mem: 14938
[14:52:03.702289] Test:  [ 40/345]  eta: 0:00:57  loss: 0.9514 (0.9470)  time: 0.1841  data: 0.0001  max mem: 14938
[14:52:05.550758] Test:  [ 50/345]  eta: 0:00:55  loss: 0.9471 (0.9445)  time: 0.1845  data: 0.0001  max mem: 14938
[14:52:07.401378] Test:  [ 60/345]  eta: 0:00:53  loss: 0.9350 (0.9431)  time: 0.1849  data: 0.0001  max mem: 14938
[14:52:09.255634] Test:  [ 70/345]  eta: 0:00:51  loss: 0.9528 (0.9465)  time: 0.1852  data: 0.0001  max mem: 14938
[14:52:11.111668] Test:  [ 80/345]  eta: 0:00:49  loss: 0.9658 (0.9487)  time: 0.1855  data: 0.0001  max mem: 14938
[14:52:12.973437] Test:  [ 90/345]  eta: 0:00:47  loss: 0.9493 (0.9487)  time: 0.1858  data: 0.0001  max mem: 14938
[14:52:14.835823] Test:  [100/345]  eta: 0:00:45  loss: 0.9372 (0.9474)  time: 0.1862  data: 0.0001  max mem: 14938
[14:52:16.702217] Test:  [110/345]  eta: 0:00:43  loss: 0.9377 (0.9466)  time: 0.1864  data: 0.0001  max mem: 14938
[14:52:18.572363] Test:  [120/345]  eta: 0:00:41  loss: 0.9396 (0.9466)  time: 0.1868  data: 0.0001  max mem: 14938
[14:52:20.447618] Test:  [130/345]  eta: 0:00:40  loss: 0.9306 (0.9460)  time: 0.1872  data: 0.0001  max mem: 14938
[14:52:22.324735] Test:  [140/345]  eta: 0:00:38  loss: 0.9306 (0.9449)  time: 0.1876  data: 0.0001  max mem: 14938
[14:52:24.207132] Test:  [150/345]  eta: 0:00:36  loss: 0.9359 (0.9453)  time: 0.1879  data: 0.0001  max mem: 14938
[14:52:26.091451] Test:  [160/345]  eta: 0:00:34  loss: 0.9281 (0.9450)  time: 0.1883  data: 0.0001  max mem: 14938
[14:52:27.979786] Test:  [170/345]  eta: 0:00:32  loss: 0.9294 (0.9456)  time: 0.1886  data: 0.0001  max mem: 14938
[14:52:29.873757] Test:  [180/345]  eta: 0:00:30  loss: 0.9513 (0.9451)  time: 0.1891  data: 0.0001  max mem: 14938
[14:52:31.769659] Test:  [190/345]  eta: 0:00:29  loss: 0.9329 (0.9440)  time: 0.1894  data: 0.0001  max mem: 14938
[14:52:33.668712] Test:  [200/345]  eta: 0:00:27  loss: 0.9284 (0.9438)  time: 0.1897  data: 0.0001  max mem: 14938
[14:52:35.572304] Test:  [210/345]  eta: 0:00:25  loss: 0.9446 (0.9448)  time: 0.1901  data: 0.0001  max mem: 14938
[14:52:37.477928] Test:  [220/345]  eta: 0:00:23  loss: 0.9461 (0.9442)  time: 0.1904  data: 0.0001  max mem: 14938
[14:52:39.386712] Test:  [230/345]  eta: 0:00:21  loss: 0.9256 (0.9438)  time: 0.1907  data: 0.0001  max mem: 14938
[14:52:41.298689] Test:  [240/345]  eta: 0:00:19  loss: 0.9435 (0.9438)  time: 0.1910  data: 0.0001  max mem: 14938
[14:52:43.216074] Test:  [250/345]  eta: 0:00:17  loss: 0.9415 (0.9436)  time: 0.1914  data: 0.0001  max mem: 14938
[14:52:45.137230] Test:  [260/345]  eta: 0:00:15  loss: 0.9195 (0.9429)  time: 0.1919  data: 0.0001  max mem: 14938
[14:52:47.060539] Test:  [270/345]  eta: 0:00:14  loss: 0.9346 (0.9431)  time: 0.1922  data: 0.0001  max mem: 14938
[14:52:48.987504] Test:  [280/345]  eta: 0:00:12  loss: 0.9483 (0.9433)  time: 0.1925  data: 0.0001  max mem: 14938
[14:52:50.918379] Test:  [290/345]  eta: 0:00:10  loss: 0.9386 (0.9427)  time: 0.1928  data: 0.0001  max mem: 14938
[14:52:52.851859] Test:  [300/345]  eta: 0:00:08  loss: 0.9319 (0.9426)  time: 0.1932  data: 0.0001  max mem: 14938
[14:52:54.788804] Test:  [310/345]  eta: 0:00:06  loss: 0.9411 (0.9424)  time: 0.1935  data: 0.0001  max mem: 14938
[14:52:56.730827] Test:  [320/345]  eta: 0:00:04  loss: 0.9436 (0.9426)  time: 0.1939  data: 0.0001  max mem: 14938
[14:52:58.674556] Test:  [330/345]  eta: 0:00:02  loss: 0.9409 (0.9423)  time: 0.1942  data: 0.0001  max mem: 14938
[14:53:00.621559] Test:  [340/345]  eta: 0:00:00  loss: 0.9328 (0.9420)  time: 0.1945  data: 0.0001  max mem: 14938
[14:53:01.402502] Test:  [344/345]  eta: 0:00:00  loss: 0.9328 (0.9418)  time: 0.1947  data: 0.0001  max mem: 14938
[14:53:01.463547] Test: Total time: 0:01:05 (0.1897 s / it)
[14:53:12.094199] Test:  [ 0/57]  eta: 0:00:18  loss: 1.0420 (1.0420)  time: 0.3283  data: 0.1486  max mem: 14938
[14:53:13.906769] Test:  [10/57]  eta: 0:00:09  loss: 1.0144 (1.0015)  time: 0.1946  data: 0.0136  max mem: 14938
[14:53:15.723285] Test:  [20/57]  eta: 0:00:06  loss: 0.9882 (0.9944)  time: 0.1814  data: 0.0001  max mem: 14938
[14:53:17.544608] Test:  [30/57]  eta: 0:00:05  loss: 0.9034 (0.9459)  time: 0.1818  data: 0.0001  max mem: 14938
[14:53:19.370619] Test:  [40/57]  eta: 0:00:03  loss: 0.8246 (0.9162)  time: 0.1823  data: 0.0001  max mem: 14938
[14:53:21.200055] Test:  [50/57]  eta: 0:00:01  loss: 0.8246 (0.9068)  time: 0.1827  data: 0.0001  max mem: 14938
[14:53:22.187001] Test:  [56/57]  eta: 0:00:00  loss: 0.8832 (0.9112)  time: 0.1773  data: 0.0001  max mem: 14938
[14:53:22.249114] Test: Total time: 0:00:10 (0.1839 s / it)
[14:53:23.991870] Dice score of the network on the train images: 0.687988, val images: 0.751399
[14:53:23.992089] saving best_prec_model_0 @ epoch 6
[14:53:25.053088] saving best_dice_model_0 @ epoch 6
[14:53:26.045434] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:53:26.934679] Epoch: [7]  [  0/345]  eta: 0:05:06  lr: 0.000044  loss: 0.9412 (0.9412)  time: 0.8881  data: 0.1488  max mem: 14938
[14:53:41.789876] Epoch: [7]  [ 20/345]  eta: 0:04:03  lr: 0.000044  loss: 0.9639 (0.9707)  time: 0.7427  data: 0.0001  max mem: 14938
[14:53:56.709233] Epoch: [7]  [ 40/345]  eta: 0:03:48  lr: 0.000044  loss: 0.9675 (0.9710)  time: 0.7459  data: 0.0001  max mem: 14938
[14:54:11.649886] Epoch: [7]  [ 60/345]  eta: 0:03:33  lr: 0.000045  loss: 0.9566 (0.9664)  time: 0.7470  data: 0.0001  max mem: 14938
[14:54:26.622659] Epoch: [7]  [ 80/345]  eta: 0:03:18  lr: 0.000045  loss: 0.9572 (0.9638)  time: 0.7486  data: 0.0001  max mem: 14938
[14:54:41.621774] Epoch: [7]  [100/345]  eta: 0:03:03  lr: 0.000046  loss: 0.9703 (0.9674)  time: 0.7499  data: 0.0001  max mem: 14938
[14:54:56.634013] Epoch: [7]  [120/345]  eta: 0:02:48  lr: 0.000046  loss: 0.9688 (0.9671)  time: 0.7506  data: 0.0001  max mem: 14938
[14:55:11.641269] Epoch: [7]  [140/345]  eta: 0:02:33  lr: 0.000046  loss: 0.9624 (0.9659)  time: 0.7503  data: 0.0001  max mem: 14938
[14:55:26.633955] Epoch: [7]  [160/345]  eta: 0:02:18  lr: 0.000047  loss: 0.9524 (0.9647)  time: 0.7496  data: 0.0001  max mem: 14938
[14:55:41.621989] Epoch: [7]  [180/345]  eta: 0:02:03  lr: 0.000047  loss: 0.9461 (0.9643)  time: 0.7494  data: 0.0001  max mem: 14938
[14:55:56.603261] Epoch: [7]  [200/345]  eta: 0:01:48  lr: 0.000047  loss: 0.9458 (0.9625)  time: 0.7490  data: 0.0001  max mem: 14938
[14:56:11.575349] Epoch: [7]  [220/345]  eta: 0:01:33  lr: 0.000048  loss: 0.9390 (0.9609)  time: 0.7486  data: 0.0001  max mem: 14938
[14:56:26.558423] Epoch: [7]  [240/345]  eta: 0:01:18  lr: 0.000048  loss: 0.9412 (0.9586)  time: 0.7491  data: 0.0001  max mem: 14938
[14:56:41.545088] Epoch: [7]  [260/345]  eta: 0:01:03  lr: 0.000048  loss: 0.9253 (0.9562)  time: 0.7493  data: 0.0001  max mem: 14938
[14:56:56.527182] Epoch: [7]  [280/345]  eta: 0:00:48  lr: 0.000049  loss: 0.9300 (0.9548)  time: 0.7491  data: 0.0001  max mem: 14938
[14:57:11.505221] Epoch: [7]  [300/345]  eta: 0:00:33  lr: 0.000049  loss: 0.9283 (0.9530)  time: 0.7489  data: 0.0001  max mem: 14938
[14:57:26.478666] Epoch: [7]  [320/345]  eta: 0:00:18  lr: 0.000050  loss: 0.9319 (0.9520)  time: 0.7486  data: 0.0001  max mem: 14938
[14:57:41.453484] Epoch: [7]  [340/345]  eta: 0:00:03  lr: 0.000050  loss: 0.9216 (0.9508)  time: 0.7487  data: 0.0001  max mem: 14938
[14:57:44.448134] Epoch: [7]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.9216 (0.9503)  time: 0.7487  data: 0.0001  max mem: 14938
[14:57:44.515024] Epoch: [7] Total time: 0:04:18 (0.7492 s / it)
[14:57:44.515547] Averaged stats: lr: 0.000050  loss: 0.9216 (0.9503)
[14:57:44.855427] Test:  [  0/345]  eta: 0:01:55  loss: 0.8670 (0.8670)  time: 0.3354  data: 0.1545  max mem: 14938
[14:57:46.691088] Test:  [ 10/345]  eta: 0:01:06  loss: 0.8670 (0.8652)  time: 0.1973  data: 0.0141  max mem: 14938
[14:57:48.526826] Test:  [ 20/345]  eta: 0:01:01  loss: 0.8689 (0.8749)  time: 0.1835  data: 0.0001  max mem: 14938
[14:57:50.366752] Test:  [ 30/345]  eta: 0:00:59  loss: 0.8691 (0.8732)  time: 0.1837  data: 0.0001  max mem: 14938
[14:57:52.208423] Test:  [ 40/345]  eta: 0:00:57  loss: 0.8543 (0.8665)  time: 0.1840  data: 0.0001  max mem: 14938
[14:57:54.056281] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8687 (0.8684)  time: 0.1844  data: 0.0001  max mem: 14938
[14:57:55.908817] Test:  [ 60/345]  eta: 0:00:53  loss: 0.8687 (0.8697)  time: 0.1850  data: 0.0001  max mem: 14938
[14:57:57.763880] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8594 (0.8686)  time: 0.1853  data: 0.0001  max mem: 14938
[14:57:59.618962] Test:  [ 80/345]  eta: 0:00:49  loss: 0.8625 (0.8687)  time: 0.1855  data: 0.0001  max mem: 14938
[14:58:01.481875] Test:  [ 90/345]  eta: 0:00:47  loss: 0.8625 (0.8692)  time: 0.1859  data: 0.0001  max mem: 14938
[14:58:03.345913] Test:  [100/345]  eta: 0:00:45  loss: 0.8685 (0.8697)  time: 0.1863  data: 0.0001  max mem: 14938
[14:58:05.211425] Test:  [110/345]  eta: 0:00:43  loss: 0.8794 (0.8706)  time: 0.1864  data: 0.0001  max mem: 14938
[14:58:07.083727] Test:  [120/345]  eta: 0:00:41  loss: 0.8798 (0.8709)  time: 0.1868  data: 0.0001  max mem: 14938
[14:58:08.958568] Test:  [130/345]  eta: 0:00:40  loss: 0.8735 (0.8711)  time: 0.1873  data: 0.0001  max mem: 14938
[14:58:10.837285] Test:  [140/345]  eta: 0:00:38  loss: 0.8637 (0.8695)  time: 0.1876  data: 0.0001  max mem: 14938
[14:58:12.720716] Test:  [150/345]  eta: 0:00:36  loss: 0.8741 (0.8711)  time: 0.1881  data: 0.0001  max mem: 14938
[14:58:14.606252] Test:  [160/345]  eta: 0:00:34  loss: 0.8875 (0.8712)  time: 0.1884  data: 0.0001  max mem: 14938
[14:58:16.495308] Test:  [170/345]  eta: 0:00:32  loss: 0.8762 (0.8714)  time: 0.1887  data: 0.0001  max mem: 14938
[14:58:18.388231] Test:  [180/345]  eta: 0:00:30  loss: 0.8737 (0.8718)  time: 0.1890  data: 0.0001  max mem: 14938
[14:58:20.288679] Test:  [190/345]  eta: 0:00:29  loss: 0.8718 (0.8711)  time: 0.1896  data: 0.0001  max mem: 14938
[14:58:22.189123] Test:  [200/345]  eta: 0:00:27  loss: 0.8600 (0.8709)  time: 0.1900  data: 0.0001  max mem: 14938
[14:58:24.090747] Test:  [210/345]  eta: 0:00:25  loss: 0.8668 (0.8708)  time: 0.1901  data: 0.0001  max mem: 14938
[14:58:25.996264] Test:  [220/345]  eta: 0:00:23  loss: 0.8676 (0.8710)  time: 0.1903  data: 0.0001  max mem: 14938
[14:58:27.905689] Test:  [230/345]  eta: 0:00:21  loss: 0.8731 (0.8713)  time: 0.1907  data: 0.0001  max mem: 14938
[14:58:29.821465] Test:  [240/345]  eta: 0:00:19  loss: 0.8768 (0.8717)  time: 0.1912  data: 0.0001  max mem: 14938
[14:58:31.741518] Test:  [250/345]  eta: 0:00:17  loss: 0.8666 (0.8711)  time: 0.1917  data: 0.0001  max mem: 14938
[14:58:33.664465] Test:  [260/345]  eta: 0:00:16  loss: 0.8573 (0.8710)  time: 0.1921  data: 0.0001  max mem: 14938
[14:58:35.590326] Test:  [270/345]  eta: 0:00:14  loss: 0.8640 (0.8712)  time: 0.1924  data: 0.0001  max mem: 14938
[14:58:37.520391] Test:  [280/345]  eta: 0:00:12  loss: 0.8722 (0.8713)  time: 0.1927  data: 0.0001  max mem: 14938
[14:58:39.452747] Test:  [290/345]  eta: 0:00:10  loss: 0.8734 (0.8715)  time: 0.1931  data: 0.0001  max mem: 14938
[14:58:41.387101] Test:  [300/345]  eta: 0:00:08  loss: 0.8755 (0.8716)  time: 0.1933  data: 0.0001  max mem: 14938
[14:58:43.325856] Test:  [310/345]  eta: 0:00:06  loss: 0.8765 (0.8720)  time: 0.1936  data: 0.0001  max mem: 14938
[14:58:45.267190] Test:  [320/345]  eta: 0:00:04  loss: 0.8761 (0.8722)  time: 0.1940  data: 0.0001  max mem: 14938
[14:58:47.210403] Test:  [330/345]  eta: 0:00:02  loss: 0.8657 (0.8720)  time: 0.1942  data: 0.0001  max mem: 14938
[14:58:49.157527] Test:  [340/345]  eta: 0:00:00  loss: 0.8734 (0.8721)  time: 0.1945  data: 0.0001  max mem: 14938
[14:58:49.938142] Test:  [344/345]  eta: 0:00:00  loss: 0.8765 (0.8723)  time: 0.1946  data: 0.0001  max mem: 14938
[14:58:49.997590] Test: Total time: 0:01:05 (0.1898 s / it)
[14:59:00.473481] Test:  [ 0/57]  eta: 0:00:18  loss: 0.9775 (0.9775)  time: 0.3205  data: 0.1411  max mem: 14938
[14:59:02.286133] Test:  [10/57]  eta: 0:00:09  loss: 0.9276 (0.9342)  time: 0.1939  data: 0.0129  max mem: 14938
[14:59:04.104213] Test:  [20/57]  eta: 0:00:06  loss: 0.9276 (0.9312)  time: 0.1815  data: 0.0001  max mem: 14938
[14:59:05.925496] Test:  [30/57]  eta: 0:00:05  loss: 0.8277 (0.8877)  time: 0.1819  data: 0.0001  max mem: 14938
[14:59:07.751046] Test:  [40/57]  eta: 0:00:03  loss: 0.7923 (0.8618)  time: 0.1823  data: 0.0001  max mem: 14938
[14:59:09.583586] Test:  [50/57]  eta: 0:00:01  loss: 0.7923 (0.8539)  time: 0.1828  data: 0.0001  max mem: 14938
[14:59:10.571198] Test:  [56/57]  eta: 0:00:00  loss: 0.8275 (0.8587)  time: 0.1775  data: 0.0001  max mem: 14938
[14:59:10.633091] Test: Total time: 0:00:10 (0.1839 s / it)
[14:59:12.366666] Dice score of the network on the train images: 0.725694, val images: 0.787310
[14:59:12.366885] saving best_prec_model_0 @ epoch 7
[14:59:13.463920] saving best_rec_model_0 @ epoch 7
[14:59:14.462155] saving best_dice_model_0 @ epoch 7
[14:59:15.570932] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:59:16.454978] Epoch: [8]  [  0/345]  eta: 0:05:04  lr: 0.000050  loss: 0.9358 (0.9358)  time: 0.8828  data: 0.1429  max mem: 14938
[14:59:31.311151] Epoch: [8]  [ 20/345]  eta: 0:04:03  lr: 0.000050  loss: 0.9117 (0.9237)  time: 0.7428  data: 0.0001  max mem: 14938
[14:59:46.231790] Epoch: [8]  [ 40/345]  eta: 0:03:48  lr: 0.000051  loss: 0.9077 (0.9209)  time: 0.7460  data: 0.0001  max mem: 14938
[15:00:01.201640] Epoch: [8]  [ 60/345]  eta: 0:03:33  lr: 0.000051  loss: 0.9213 (0.9239)  time: 0.7485  data: 0.0001  max mem: 14938
[15:00:16.185343] Epoch: [8]  [ 80/345]  eta: 0:03:18  lr: 0.000051  loss: 0.9193 (0.9218)  time: 0.7491  data: 0.0001  max mem: 14938
[15:00:31.207943] Epoch: [8]  [100/345]  eta: 0:03:03  lr: 0.000052  loss: 0.9078 (0.9213)  time: 0.7511  data: 0.0001  max mem: 14938

[15:00:46.255179] Epoch: [8]  [120/345]  eta: 0:02:48  lr: 0.000052  loss: 0.9178 (0.9206)  time: 0.7523  data: 0.0001  max mem: 14938
[15:01:01.279583] Epoch: [8]  [140/345]  eta: 0:02:33  lr: 0.000053  loss: 0.9297 (0.9216)  time: 0.7512  data: 0.0001  max mem: 14938

[15:01:16.296009] Epoch: [8]  [160/345]  eta: 0:02:18  lr: 0.000053  loss: 0.9128 (0.9207)  time: 0.7508  data: 0.0001  max mem: 14938
[15:01:31.305106] Epoch: [8]  [180/345]  eta: 0:02:03  lr: 0.000053  loss: 0.9009 (0.9197)  time: 0.7504  data: 0.0001  max mem: 14938

[15:01:46.311663] Epoch: [8]  [200/345]  eta: 0:01:48  lr: 0.000054  loss: 0.8867 (0.9170)  time: 0.7503  data: 0.0001  max mem: 14938
[15:02:01.298861] Epoch: [8]  [220/345]  eta: 0:01:33  lr: 0.000054  loss: 0.8946 (0.9150)  time: 0.7493  data: 0.0001  max mem: 14938
[15:02:16.301283] Epoch: [8]  [240/345]  eta: 0:01:18  lr: 0.000054  loss: 0.8977 (0.9138)  time: 0.7501  data: 0.0001  max mem: 14938
[15:02:31.269188] Epoch: [8]  [260/345]  eta: 0:01:03  lr: 0.000055  loss: 0.9010 (0.9133)  time: 0.7484  data: 0.0001  max mem: 14938
[15:02:46.240876] Epoch: [8]  [280/345]  eta: 0:00:48  lr: 0.000055  loss: 0.8972 (0.9124)  time: 0.7485  data: 0.0001  max mem: 14938
[15:03:01.213924] Epoch: [8]  [300/345]  eta: 0:00:33  lr: 0.000055  loss: 0.8893 (0.9111)  time: 0.7486  data: 0.0001  max mem: 14938
[15:03:16.176762] Epoch: [8]  [320/345]  eta: 0:00:18  lr: 0.000056  loss: 0.8822 (0.9100)  time: 0.7481  data: 0.0001  max mem: 14938
[15:03:31.139889] Epoch: [8]  [340/345]  eta: 0:00:03  lr: 0.000056  loss: 0.8818 (0.9084)  time: 0.7481  data: 0.0001  max mem: 14938
[15:03:34.133612] Epoch: [8]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.8818 (0.9081)  time: 0.7481  data: 0.0001  max mem: 14938
[15:03:34.195280] Epoch: [8] Total time: 0:04:18 (0.7496 s / it)
[15:03:34.195489] Averaged stats: lr: 0.000056  loss: 0.8818 (0.9081)
[15:03:34.544050] Test:  [  0/345]  eta: 0:01:59  loss: 0.8710 (0.8710)  time: 0.3450  data: 0.1637  max mem: 14938
[15:03:36.378367] Test:  [ 10/345]  eta: 0:01:06  loss: 0.8449 (0.8460)  time: 0.1980  data: 0.0149  max mem: 14938
[15:03:38.215845] Test:  [ 20/345]  eta: 0:01:02  loss: 0.8352 (0.8368)  time: 0.1835  data: 0.0001  max mem: 14938
[15:03:40.056971] Test:  [ 30/345]  eta: 0:00:59  loss: 0.8406 (0.8410)  time: 0.1839  data: 0.0001  max mem: 14938
[15:03:41.899999] Test:  [ 40/345]  eta: 0:00:57  loss: 0.8509 (0.8441)  time: 0.1842  data: 0.0001  max mem: 14938
[15:03:43.749727] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8456 (0.8433)  time: 0.1846  data: 0.0001  max mem: 14938
[15:03:45.601334] Test:  [ 60/345]  eta: 0:00:53  loss: 0.8415 (0.8450)  time: 0.1850  data: 0.0001  max mem: 14938
[15:03:47.455739] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8481 (0.8464)  time: 0.1852  data: 0.0001  max mem: 14938
[15:03:49.312761] Test:  [ 80/345]  eta: 0:00:49  loss: 0.8500 (0.8466)  time: 0.1855  data: 0.0001  max mem: 14938
[15:03:51.174607] Test:  [ 90/345]  eta: 0:00:47  loss: 0.8502 (0.8480)  time: 0.1859  data: 0.0001  max mem: 14938
[15:03:53.038198] Test:  [100/345]  eta: 0:00:45  loss: 0.8502 (0.8476)  time: 0.1862  data: 0.0001  max mem: 14938
[15:03:54.905871] Test:  [110/345]  eta: 0:00:43  loss: 0.8487 (0.8482)  time: 0.1865  data: 0.0001  max mem: 14938
[15:03:56.779054] Test:  [120/345]  eta: 0:00:41  loss: 0.8578 (0.8482)  time: 0.1870  data: 0.0001  max mem: 14938
[15:03:58.656218] Test:  [130/345]  eta: 0:00:40  loss: 0.8316 (0.8475)  time: 0.1875  data: 0.0001  max mem: 14938
[15:04:00.536041] Test:  [140/345]  eta: 0:00:38  loss: 0.8405 (0.8479)  time: 0.1878  data: 0.0001  max mem: 14938
[15:04:02.420043] Test:  [150/345]  eta: 0:00:36  loss: 0.8405 (0.8477)  time: 0.1881  data: 0.0001  max mem: 14938
[15:04:04.304642] Test:  [160/345]  eta: 0:00:34  loss: 0.8403 (0.8479)  time: 0.1884  data: 0.0001  max mem: 14938
[15:04:06.193724] Test:  [170/345]  eta: 0:00:32  loss: 0.8608 (0.8489)  time: 0.1886  data: 0.0001  max mem: 14938
[15:04:08.089445] Test:  [180/345]  eta: 0:00:30  loss: 0.8553 (0.8483)  time: 0.1892  data: 0.0001  max mem: 14938
[15:04:09.986885] Test:  [190/345]  eta: 0:00:29  loss: 0.8468 (0.8487)  time: 0.1896  data: 0.0001  max mem: 14938
[15:04:11.886595] Test:  [200/345]  eta: 0:00:27  loss: 0.8460 (0.8481)  time: 0.1898  data: 0.0001  max mem: 14938
[15:04:13.791117] Test:  [210/345]  eta: 0:00:25  loss: 0.8464 (0.8484)  time: 0.1902  data: 0.0001  max mem: 14938
[15:04:15.698399] Test:  [220/345]  eta: 0:00:23  loss: 0.8464 (0.8482)  time: 0.1905  data: 0.0001  max mem: 14938
[15:04:17.610650] Test:  [230/345]  eta: 0:00:21  loss: 0.8451 (0.8489)  time: 0.1909  data: 0.0001  max mem: 14938
[15:04:19.523927] Test:  [240/345]  eta: 0:00:19  loss: 0.8539 (0.8489)  time: 0.1912  data: 0.0001  max mem: 14938
[15:04:21.443546] Test:  [250/345]  eta: 0:00:17  loss: 0.8443 (0.8483)  time: 0.1916  data: 0.0001  max mem: 14938
[15:04:23.364683] Test:  [260/345]  eta: 0:00:16  loss: 0.8520 (0.8491)  time: 0.1920  data: 0.0001  max mem: 14938
[15:04:25.289227] Test:  [270/345]  eta: 0:00:14  loss: 0.8616 (0.8491)  time: 0.1922  data: 0.0001  max mem: 14938
[15:04:27.217182] Test:  [280/345]  eta: 0:00:12  loss: 0.8581 (0.8498)  time: 0.1926  data: 0.0001  max mem: 14938
[15:04:29.150752] Test:  [290/345]  eta: 0:00:10  loss: 0.8577 (0.8502)  time: 0.1930  data: 0.0001  max mem: 14938
[15:04:31.087299] Test:  [300/345]  eta: 0:00:08  loss: 0.8547 (0.8504)  time: 0.1935  data: 0.0001  max mem: 14938
[15:04:33.023772] Test:  [310/345]  eta: 0:00:06  loss: 0.8547 (0.8505)  time: 0.1936  data: 0.0001  max mem: 14938
[15:04:34.967608] Test:  [320/345]  eta: 0:00:04  loss: 0.8321 (0.8499)  time: 0.1940  data: 0.0001  max mem: 14938
[15:04:36.914133] Test:  [330/345]  eta: 0:00:02  loss: 0.8412 (0.8498)  time: 0.1945  data: 0.0001  max mem: 14938
[15:04:38.862294] Test:  [340/345]  eta: 0:00:00  loss: 0.8511 (0.8504)  time: 0.1947  data: 0.0001  max mem: 14938
[15:04:39.643282] Test:  [344/345]  eta: 0:00:00  loss: 0.8639 (0.8506)  time: 0.1948  data: 0.0001  max mem: 14938
[15:04:39.703653] Test: Total time: 0:01:05 (0.1899 s / it)
[15:04:50.391944] Test:  [ 0/57]  eta: 0:00:18  loss: 0.9372 (0.9372)  time: 0.3215  data: 0.1421  max mem: 14938
[15:04:52.207059] Test:  [10/57]  eta: 0:00:09  loss: 0.8991 (0.9162)  time: 0.1942  data: 0.0130  max mem: 14938
[15:04:54.027133] Test:  [20/57]  eta: 0:00:06  loss: 0.8991 (0.9104)  time: 0.1817  data: 0.0001  max mem: 14938
[15:04:55.850285] Test:  [30/57]  eta: 0:00:05  loss: 0.8221 (0.8708)  time: 0.1821  data: 0.0001  max mem: 14938
[15:04:57.676793] Test:  [40/57]  eta: 0:00:03  loss: 0.7763 (0.8470)  time: 0.1824  data: 0.0001  max mem: 14938
[15:04:59.509116] Test:  [50/57]  eta: 0:00:01  loss: 0.7763 (0.8399)  time: 0.1829  data: 0.0001  max mem: 14938
[15:05:00.497527] Test:  [56/57]  eta: 0:00:00  loss: 0.8209 (0.8459)  time: 0.1775  data: 0.0001  max mem: 14938
[15:05:00.556532] Test: Total time: 0:00:10 (0.1840 s / it)
[15:05:02.307997] Dice score of the network on the train images: 0.735804, val images: 0.794383
[15:05:02.308227] saving best_prec_model_0 @ epoch 8
[15:05:03.368102] saving best_rec_model_0 @ epoch 8
[15:05:04.472012] saving best_dice_model_0 @ epoch 8
[15:05:05.481400] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:05:06.365750] Epoch: [9]  [  0/345]  eta: 0:05:04  lr: 0.000056  loss: 0.8773 (0.8773)  time: 0.8831  data: 0.1420  max mem: 14938
[15:05:21.225738] Epoch: [9]  [ 20/345]  eta: 0:04:03  lr: 0.000057  loss: 0.8668 (0.8767)  time: 0.7429  data: 0.0001  max mem: 14938
[15:05:36.147169] Epoch: [9]  [ 40/345]  eta: 0:03:48  lr: 0.000057  loss: 0.9134 (0.8891)  time: 0.7460  data: 0.0001  max mem: 14938
[15:05:51.109765] Epoch: [9]  [ 60/345]  eta: 0:03:33  lr: 0.000057  loss: 0.8906 (0.8918)  time: 0.7481  data: 0.0001  max mem: 14938
[15:06:06.108755] Epoch: [9]  [ 80/345]  eta: 0:03:18  lr: 0.000058  loss: 0.8763 (0.8892)  time: 0.7499  data: 0.0001  max mem: 14938
[15:06:21.133942] Epoch: [9]  [100/345]  eta: 0:03:03  lr: 0.000058  loss: 0.8862 (0.8879)  time: 0.7512  data: 0.0001  max mem: 14938
[15:06:36.176626] Epoch: [9]  [120/345]  eta: 0:02:48  lr: 0.000058  loss: 0.8773 (0.8875)  time: 0.7521  data: 0.0001  max mem: 14938
[15:06:51.203320] Epoch: [9]  [140/345]  eta: 0:02:33  lr: 0.000059  loss: 0.8807 (0.8864)  time: 0.7513  data: 0.0001  max mem: 14938
[15:07:06.348329] Epoch: [9]  [160/345]  eta: 0:02:18  lr: 0.000059  loss: 0.8856 (0.8852)  time: 0.7572  data: 0.0001  max mem: 14938
[15:07:21.356582] Epoch: [9]  [180/345]  eta: 0:02:03  lr: 0.000060  loss: 0.8887 (0.8859)  time: 0.7504  data: 0.0001  max mem: 14938
[15:07:36.362432] Epoch: [9]  [200/345]  eta: 0:01:48  lr: 0.000060  loss: 0.8729 (0.8845)  time: 0.7502  data: 0.0001  max mem: 14938
[15:07:51.361504] Epoch: [9]  [220/345]  eta: 0:01:33  lr: 0.000060  loss: 0.8787 (0.8842)  time: 0.7499  data: 0.0001  max mem: 14938
[15:08:06.353263] Epoch: [9]  [240/345]  eta: 0:01:18  lr: 0.000061  loss: 0.8545 (0.8823)  time: 0.7495  data: 0.0001  max mem: 14938
[15:08:21.354959] Epoch: [9]  [260/345]  eta: 0:01:03  lr: 0.000061  loss: 0.8911 (0.8831)  time: 0.7500  data: 0.0001  max mem: 14938
[15:08:36.338895] Epoch: [9]  [280/345]  eta: 0:00:48  lr: 0.000061  loss: 0.8772 (0.8829)  time: 0.7492  data: 0.0001  max mem: 14938
[15:08:51.307056] Epoch: [9]  [300/345]  eta: 0:00:33  lr: 0.000062  loss: 0.8761 (0.8823)  time: 0.7484  data: 0.0001  max mem: 14938
[15:09:06.273687] Epoch: [9]  [320/345]  eta: 0:00:18  lr: 0.000062  loss: 0.8741 (0.8820)  time: 0.7483  data: 0.0001  max mem: 14938
[15:09:21.234350] Epoch: [9]  [340/345]  eta: 0:00:03  lr: 0.000062  loss: 0.8692 (0.8814)  time: 0.7480  data: 0.0001  max mem: 14938
[15:09:24.228565] Epoch: [9]  [344/345]  eta: 0:00:00  lr: 0.000062  loss: 0.8524 (0.8812)  time: 0.7478  data: 0.0001  max mem: 14938
[15:09:24.294710] Epoch: [9] Total time: 0:04:18 (0.7502 s / it)
[15:09:24.295025] Averaged stats: lr: 0.000062  loss: 0.8524 (0.8812)
[15:09:24.635766] Test:  [  0/345]  eta: 0:01:56  loss: 0.8502 (0.8502)  time: 0.3374  data: 0.1563  max mem: 14938
[15:09:26.472172] Test:  [ 10/345]  eta: 0:01:06  loss: 0.8419 (0.8389)  time: 0.1975  data: 0.0143  max mem: 14938
[15:09:28.310670] Test:  [ 20/345]  eta: 0:01:02  loss: 0.8349 (0.8352)  time: 0.1837  data: 0.0001  max mem: 14938
[15:09:30.153699] Test:  [ 30/345]  eta: 0:00:59  loss: 0.8196 (0.8308)  time: 0.1840  data: 0.0001  max mem: 14938
[15:09:31.999238] Test:  [ 40/345]  eta: 0:00:57  loss: 0.8275 (0.8331)  time: 0.1844  data: 0.0001  max mem: 14938
[15:09:33.848067] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8403 (0.8358)  time: 0.1847  data: 0.0001  max mem: 14938
[15:09:35.701120] Test:  [ 60/345]  eta: 0:00:53  loss: 0.8304 (0.8332)  time: 0.1850  data: 0.0001  max mem: 14938
[15:09:37.556077] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8112 (0.8328)  time: 0.1854  data: 0.0001  max mem: 14938
[15:09:39.414444] Test:  [ 80/345]  eta: 0:00:49  loss: 0.8123 (0.8311)  time: 0.1856  data: 0.0001  max mem: 14938
[15:09:41.277990] Test:  [ 90/345]  eta: 0:00:47  loss: 0.8232 (0.8313)  time: 0.1860  data: 0.0001  max mem: 14938
[15:09:43.142760] Test:  [100/345]  eta: 0:00:45  loss: 0.8272 (0.8313)  time: 0.1864  data: 0.0001  max mem: 14938
[15:09:45.011349] Test:  [110/345]  eta: 0:00:43  loss: 0.8199 (0.8309)  time: 0.1866  data: 0.0001  max mem: 14938
[15:09:46.886182] Test:  [120/345]  eta: 0:00:41  loss: 0.8254 (0.8315)  time: 0.1871  data: 0.0001  max mem: 14938
[15:09:48.761871] Test:  [130/345]  eta: 0:00:40  loss: 0.8261 (0.8314)  time: 0.1875  data: 0.0001  max mem: 14938
[15:09:50.642371] Test:  [140/345]  eta: 0:00:38  loss: 0.8234 (0.8303)  time: 0.1878  data: 0.0001  max mem: 14938
[15:09:52.526312] Test:  [150/345]  eta: 0:00:36  loss: 0.8194 (0.8303)  time: 0.1882  data: 0.0001  max mem: 14938
[15:09:54.413150] Test:  [160/345]  eta: 0:00:34  loss: 0.8226 (0.8300)  time: 0.1885  data: 0.0001  max mem: 14938
[15:09:56.303128] Test:  [170/345]  eta: 0:00:32  loss: 0.8295 (0.8307)  time: 0.1888  data: 0.0001  max mem: 14938
[15:09:58.200870] Test:  [180/345]  eta: 0:00:30  loss: 0.8442 (0.8315)  time: 0.1893  data: 0.0001  max mem: 14938
[15:10:00.100745] Test:  [190/345]  eta: 0:00:29  loss: 0.8338 (0.8313)  time: 0.1898  data: 0.0001  max mem: 14938
[15:10:02.003156] Test:  [200/345]  eta: 0:00:27  loss: 0.8263 (0.8310)  time: 0.1901  data: 0.0001  max mem: 14938
[15:10:03.906665] Test:  [210/345]  eta: 0:00:25  loss: 0.8340 (0.8311)  time: 0.1902  data: 0.0001  max mem: 14938
[15:10:05.815466] Test:  [220/345]  eta: 0:00:23  loss: 0.8340 (0.8312)  time: 0.1906  data: 0.0001  max mem: 14938
[15:10:07.726503] Test:  [230/345]  eta: 0:00:21  loss: 0.8439 (0.8319)  time: 0.1909  data: 0.0001  max mem: 14938
[15:10:09.640884] Test:  [240/345]  eta: 0:00:19  loss: 0.8439 (0.8322)  time: 0.1912  data: 0.0001  max mem: 14938
[15:10:11.558687] Test:  [250/345]  eta: 0:00:17  loss: 0.8316 (0.8323)  time: 0.1916  data: 0.0001  max mem: 14938
[15:10:13.481831] Test:  [260/345]  eta: 0:00:16  loss: 0.8288 (0.8322)  time: 0.1920  data: 0.0001  max mem: 14938
[15:10:15.407164] Test:  [270/345]  eta: 0:00:14  loss: 0.8175 (0.8318)  time: 0.1924  data: 0.0001  max mem: 14938
[15:10:17.338015] Test:  [280/345]  eta: 0:00:12  loss: 0.8276 (0.8319)  time: 0.1928  data: 0.0001  max mem: 14938
[15:10:19.272841] Test:  [290/345]  eta: 0:00:10  loss: 0.8232 (0.8316)  time: 0.1932  data: 0.0001  max mem: 14938
[15:10:21.210052] Test:  [300/345]  eta: 0:00:08  loss: 0.8215 (0.8315)  time: 0.1936  data: 0.0001  max mem: 14938
[15:10:23.148424] Test:  [310/345]  eta: 0:00:06  loss: 0.8239 (0.8318)  time: 0.1937  data: 0.0001  max mem: 14938
[15:10:25.090437] Test:  [320/345]  eta: 0:00:04  loss: 0.8372 (0.8320)  time: 0.1940  data: 0.0001  max mem: 14938
[15:10:27.035615] Test:  [330/345]  eta: 0:00:02  loss: 0.8245 (0.8316)  time: 0.1943  data: 0.0001  max mem: 14938
[15:10:28.982735] Test:  [340/345]  eta: 0:00:00  loss: 0.8245 (0.8318)  time: 0.1946  data: 0.0001  max mem: 14938
[15:10:29.763528] Test:  [344/345]  eta: 0:00:00  loss: 0.8245 (0.8317)  time: 0.1947  data: 0.0001  max mem: 14938
[15:10:29.823924] Test: Total time: 0:01:05 (0.1899 s / it)
[15:10:40.245251] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8974 (0.8974)  time: 0.3197  data: 0.1403  max mem: 14938
[15:10:42.060880] Test:  [10/57]  eta: 0:00:09  loss: 0.8776 (0.8990)  time: 0.1940  data: 0.0128  max mem: 14938
[15:10:43.881833] Test:  [20/57]  eta: 0:00:06  loss: 0.8933 (0.8948)  time: 0.1818  data: 0.0001  max mem: 14938
[15:10:45.707398] Test:  [30/57]  eta: 0:00:05  loss: 0.8065 (0.8576)  time: 0.1823  data: 0.0001  max mem: 14938
[15:10:47.535544] Test:  [40/57]  eta: 0:00:03  loss: 0.7693 (0.8358)  time: 0.1826  data: 0.0001  max mem: 14938
[15:10:49.370129] Test:  [50/57]  eta: 0:00:01  loss: 0.7693 (0.8290)  time: 0.1831  data: 0.0001  max mem: 14938
[15:10:50.358763] Test:  [56/57]  eta: 0:00:00  loss: 0.8063 (0.8345)  time: 0.1777  data: 0.0001  max mem: 14938
[15:10:50.417723] Test: Total time: 0:00:10 (0.1841 s / it)
[15:10:52.177931] Dice score of the network on the train images: 0.744143, val images: 0.800471
[15:10:52.178150] saving best_prec_model_0 @ epoch 9
[15:10:53.213031] saving best_rec_model_0 @ epoch 9
[15:10:54.220782] saving best_dice_model_0 @ epoch 9
[15:10:55.329583] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:10:56.212939] Epoch: [10]  [  0/345]  eta: 0:05:04  lr: 0.000063  loss: 0.8895 (0.8895)  time: 0.8822  data: 0.1432  max mem: 14938
[15:11:11.054673] Epoch: [10]  [ 20/345]  eta: 0:04:03  lr: 0.000063  loss: 0.8740 (0.8714)  time: 0.7420  data: 0.0001  max mem: 14938
[15:11:25.958896] Epoch: [10]  [ 40/345]  eta: 0:03:47  lr: 0.000063  loss: 0.8567 (0.8657)  time: 0.7452  data: 0.0001  max mem: 14938
[15:11:40.921369] Epoch: [10]  [ 60/345]  eta: 0:03:32  lr: 0.000064  loss: 0.8621 (0.8652)  time: 0.7481  data: 0.0001  max mem: 14938
[15:11:55.896933] Epoch: [10]  [ 80/345]  eta: 0:03:18  lr: 0.000064  loss: 0.8592 (0.8654)  time: 0.7487  data: 0.0001  max mem: 14938
[15:12:10.910827] Epoch: [10]  [100/345]  eta: 0:03:03  lr: 0.000064  loss: 0.8609 (0.8651)  time: 0.7506  data: 0.0001  max mem: 14938
[15:12:25.931892] Epoch: [10]  [120/345]  eta: 0:02:48  lr: 0.000065  loss: 0.8569 (0.8639)  time: 0.7510  data: 0.0001  max mem: 14938
[15:12:40.945841] Epoch: [10]  [140/345]  eta: 0:02:33  lr: 0.000065  loss: 0.8436 (0.8616)  time: 0.7507  data: 0.0001  max mem: 14938
[15:12:55.942792] Epoch: [10]  [160/345]  eta: 0:02:18  lr: 0.000065  loss: 0.8614 (0.8616)  time: 0.7498  data: 0.0001  max mem: 14938
[15:13:10.937978] Epoch: [10]  [180/345]  eta: 0:02:03  lr: 0.000066  loss: 0.8528 (0.8612)  time: 0.7497  data: 0.0001  max mem: 14938
[15:13:25.926216] Epoch: [10]  [200/345]  eta: 0:01:48  lr: 0.000066  loss: 0.8436 (0.8605)  time: 0.7494  data: 0.0001  max mem: 14938
[15:13:40.917651] Epoch: [10]  [220/345]  eta: 0:01:33  lr: 0.000066  loss: 0.8424 (0.8593)  time: 0.7495  data: 0.0001  max mem: 14938
[15:13:55.895199] Epoch: [10]  [240/345]  eta: 0:01:18  lr: 0.000067  loss: 0.8480 (0.8591)  time: 0.7488  data: 0.0001  max mem: 14938
[15:14:10.868988] Epoch: [10]  [260/345]  eta: 0:01:03  lr: 0.000067  loss: 0.8589 (0.8589)  time: 0.7486  data: 0.0001  max mem: 14938
[15:14:25.839719] Epoch: [10]  [280/345]  eta: 0:00:48  lr: 0.000068  loss: 0.8550 (0.8590)  time: 0.7485  data: 0.0001  max mem: 14938
[15:14:40.806381] Epoch: [10]  [300/345]  eta: 0:00:33  lr: 0.000068  loss: 0.8379 (0.8582)  time: 0.7483  data: 0.0001  max mem: 14938
[15:14:55.773008] Epoch: [10]  [320/345]  eta: 0:00:18  lr: 0.000068  loss: 0.8378 (0.8575)  time: 0.7483  data: 0.0001  max mem: 14938
[15:15:10.736168] Epoch: [10]  [340/345]  eta: 0:00:03  lr: 0.000069  loss: 0.8369 (0.8562)  time: 0.7481  data: 0.0001  max mem: 14938
[15:15:13.729696] Epoch: [10]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.8365 (0.8559)  time: 0.7481  data: 0.0001  max mem: 14938
[15:15:13.797422] Epoch: [10] Total time: 0:04:18 (0.7492 s / it)
[15:15:13.797920] Averaged stats: lr: 0.000069  loss: 0.8365 (0.8559)
[15:15:14.142037] Test:  [  0/345]  eta: 0:01:57  loss: 0.7744 (0.7744)  time: 0.3407  data: 0.1591  max mem: 14938
[15:15:15.978539] Test:  [ 10/345]  eta: 0:01:06  loss: 0.8146 (0.8065)  time: 0.1979  data: 0.0145  max mem: 14938
[15:15:17.817184] Test:  [ 20/345]  eta: 0:01:02  loss: 0.8077 (0.8053)  time: 0.1837  data: 0.0001  max mem: 14938
[15:15:19.658969] Test:  [ 30/345]  eta: 0:00:59  loss: 0.8077 (0.8083)  time: 0.1840  data: 0.0001  max mem: 14938
[15:15:21.502282] Test:  [ 40/345]  eta: 0:00:57  loss: 0.8194 (0.8103)  time: 0.1842  data: 0.0001  max mem: 14938
[15:15:23.352478] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8027 (0.8088)  time: 0.1846  data: 0.0001  max mem: 14938
[15:15:25.205262] Test:  [ 60/345]  eta: 0:00:53  loss: 0.8009 (0.8104)  time: 0.1851  data: 0.0001  max mem: 14938
[15:15:27.062286] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8059 (0.8104)  time: 0.1854  data: 0.0001  max mem: 14938
[15:15:28.921856] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7976 (0.8090)  time: 0.1858  data: 0.0001  max mem: 14938
[15:15:30.783138] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7976 (0.8089)  time: 0.1860  data: 0.0001  max mem: 14938
[15:15:32.650536] Test:  [100/345]  eta: 0:00:45  loss: 0.8149 (0.8097)  time: 0.1864  data: 0.0001  max mem: 14938
[15:15:34.517756] Test:  [110/345]  eta: 0:00:43  loss: 0.8140 (0.8098)  time: 0.1867  data: 0.0001  max mem: 14938
[15:15:36.390828] Test:  [120/345]  eta: 0:00:41  loss: 0.8070 (0.8094)  time: 0.1870  data: 0.0001  max mem: 14938
[15:15:38.267322] Test:  [130/345]  eta: 0:00:40  loss: 0.8087 (0.8092)  time: 0.1874  data: 0.0001  max mem: 14938
[15:15:40.147330] Test:  [140/345]  eta: 0:00:38  loss: 0.8000 (0.8086)  time: 0.1878  data: 0.0001  max mem: 14938
[15:15:42.031746] Test:  [150/345]  eta: 0:00:36  loss: 0.8000 (0.8083)  time: 0.1882  data: 0.0001  max mem: 14938
[15:15:43.918369] Test:  [160/345]  eta: 0:00:34  loss: 0.8122 (0.8087)  time: 0.1885  data: 0.0001  max mem: 14938
[15:15:45.809331] Test:  [170/345]  eta: 0:00:32  loss: 0.8059 (0.8085)  time: 0.1888  data: 0.0001  max mem: 14938
[15:15:47.705462] Test:  [180/345]  eta: 0:00:30  loss: 0.8059 (0.8087)  time: 0.1893  data: 0.0001  max mem: 14938
[15:15:49.604061] Test:  [190/345]  eta: 0:00:29  loss: 0.8168 (0.8096)  time: 0.1897  data: 0.0001  max mem: 14938
[15:15:51.507318] Test:  [200/345]  eta: 0:00:27  loss: 0.8214 (0.8103)  time: 0.1900  data: 0.0001  max mem: 14938
[15:15:53.412534] Test:  [210/345]  eta: 0:00:25  loss: 0.8138 (0.8103)  time: 0.1904  data: 0.0001  max mem: 14938
[15:15:55.320709] Test:  [220/345]  eta: 0:00:23  loss: 0.8083 (0.8107)  time: 0.1906  data: 0.0001  max mem: 14938
[15:15:57.233399] Test:  [230/345]  eta: 0:00:21  loss: 0.8109 (0.8114)  time: 0.1910  data: 0.0001  max mem: 14938
[15:15:59.148032] Test:  [240/345]  eta: 0:00:19  loss: 0.8063 (0.8110)  time: 0.1913  data: 0.0001  max mem: 14938
[15:16:01.067303] Test:  [250/345]  eta: 0:00:17  loss: 0.8156 (0.8111)  time: 0.1916  data: 0.0001  max mem: 14938
[15:16:02.989397] Test:  [260/345]  eta: 0:00:16  loss: 0.8092 (0.8111)  time: 0.1920  data: 0.0001  max mem: 14938
[15:16:04.915133] Test:  [270/345]  eta: 0:00:14  loss: 0.8058 (0.8110)  time: 0.1923  data: 0.0001  max mem: 14938
[15:16:06.844445] Test:  [280/345]  eta: 0:00:12  loss: 0.8058 (0.8109)  time: 0.1927  data: 0.0001  max mem: 14938
[15:16:08.778029] Test:  [290/345]  eta: 0:00:10  loss: 0.8069 (0.8110)  time: 0.1931  data: 0.0001  max mem: 14938
[15:16:10.714406] Test:  [300/345]  eta: 0:00:08  loss: 0.7938 (0.8109)  time: 0.1934  data: 0.0001  max mem: 14938
[15:16:12.655364] Test:  [310/345]  eta: 0:00:06  loss: 0.7900 (0.8101)  time: 0.1938  data: 0.0001  max mem: 14938
[15:16:14.597051] Test:  [320/345]  eta: 0:00:04  loss: 0.8023 (0.8104)  time: 0.1941  data: 0.0001  max mem: 14938
[15:16:16.543227] Test:  [330/345]  eta: 0:00:02  loss: 0.8090 (0.8103)  time: 0.1943  data: 0.0001  max mem: 14938
[15:16:18.491123] Test:  [340/345]  eta: 0:00:00  loss: 0.8072 (0.8106)  time: 0.1947  data: 0.0001  max mem: 14938
[15:16:19.271965] Test:  [344/345]  eta: 0:00:00  loss: 0.8092 (0.8106)  time: 0.1948  data: 0.0001  max mem: 14938
[15:16:19.333539] Test: Total time: 0:01:05 (0.1899 s / it)
[15:16:29.788126] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8727 (0.8727)  time: 0.3249  data: 0.1456  max mem: 14938
[15:16:31.601116] Test:  [10/57]  eta: 0:00:09  loss: 0.8730 (0.8940)  time: 0.1943  data: 0.0133  max mem: 14938
[15:16:33.421805] Test:  [20/57]  eta: 0:00:06  loss: 0.8911 (0.8926)  time: 0.1816  data: 0.0001  max mem: 14938
[15:16:35.243816] Test:  [30/57]  eta: 0:00:05  loss: 0.8040 (0.8530)  time: 0.1821  data: 0.0001  max mem: 14938
[15:16:37.070938] Test:  [40/57]  eta: 0:00:03  loss: 0.7584 (0.8292)  time: 0.1824  data: 0.0001  max mem: 14938
[15:16:38.905371] Test:  [50/57]  eta: 0:00:01  loss: 0.7584 (0.8218)  time: 0.1830  data: 0.0001  max mem: 14938
[15:16:39.894537] Test:  [56/57]  eta: 0:00:00  loss: 0.7942 (0.8277)  time: 0.1777  data: 0.0001  max mem: 14938
[15:16:39.955903] Test: Total time: 0:00:10 (0.1841 s / it)
[15:16:41.723719] Dice score of the network on the train images: 0.761311, val images: 0.807261
[15:16:41.723940] saving best_prec_model_0 @ epoch 10
[15:16:42.811556] saving best_rec_model_0 @ epoch 10
[15:16:43.815213] saving best_dice_model_0 @ epoch 10
[15:16:44.923507] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:16:45.809466] Epoch: [11]  [  0/345]  eta: 0:05:05  lr: 0.000069  loss: 0.8701 (0.8701)  time: 0.8849  data: 0.1452  max mem: 14938
[15:17:00.670660] Epoch: [11]  [ 20/345]  eta: 0:04:03  lr: 0.000069  loss: 0.8518 (0.8458)  time: 0.7430  data: 0.0001  max mem: 14938
[15:17:15.588983] Epoch: [11]  [ 40/345]  eta: 0:03:48  lr: 0.000069  loss: 0.8314 (0.8419)  time: 0.7459  data: 0.0001  max mem: 14938
[15:17:30.549072] Epoch: [11]  [ 60/345]  eta: 0:03:33  lr: 0.000070  loss: 0.8262 (0.8399)  time: 0.7480  data: 0.0001  max mem: 14938
[15:17:45.551674] Epoch: [11]  [ 80/345]  eta: 0:03:18  lr: 0.000070  loss: 0.8338 (0.8398)  time: 0.7501  data: 0.0001  max mem: 14938
[15:18:00.604045] Epoch: [11]  [100/345]  eta: 0:03:03  lr: 0.000071  loss: 0.8326 (0.8399)  time: 0.7526  data: 0.0001  max mem: 14938
[15:18:15.670818] Epoch: [11]  [120/345]  eta: 0:02:48  lr: 0.000071  loss: 0.8489 (0.8419)  time: 0.7533  data: 0.0001  max mem: 14938
[15:18:30.701922] Epoch: [11]  [140/345]  eta: 0:02:33  lr: 0.000071  loss: 0.8365 (0.8421)  time: 0.7515  data: 0.0001  max mem: 14938
[15:18:45.722552] Epoch: [11]  [160/345]  eta: 0:02:18  lr: 0.000072  loss: 0.8392 (0.8412)  time: 0.7510  data: 0.0001  max mem: 14938
[15:19:00.726291] Epoch: [11]  [180/345]  eta: 0:02:03  lr: 0.000072  loss: 0.8303 (0.8409)  time: 0.7501  data: 0.0001  max mem: 14938
[15:19:15.737171] Epoch: [11]  [200/345]  eta: 0:01:48  lr: 0.000072  loss: 0.8275 (0.8405)  time: 0.7505  data: 0.0001  max mem: 14938
[15:19:30.745766] Epoch: [11]  [220/345]  eta: 0:01:33  lr: 0.000073  loss: 0.8443 (0.8406)  time: 0.7504  data: 0.0001  max mem: 14938
[15:19:45.748815] Epoch: [11]  [240/345]  eta: 0:01:18  lr: 0.000073  loss: 0.8237 (0.8393)  time: 0.7501  data: 0.0001  max mem: 14938
[15:20:00.747662] Epoch: [11]  [260/345]  eta: 0:01:03  lr: 0.000073  loss: 0.8262 (0.8384)  time: 0.7499  data: 0.0001  max mem: 14938
[15:20:15.724007] Epoch: [11]  [280/345]  eta: 0:00:48  lr: 0.000074  loss: 0.8335 (0.8385)  time: 0.7488  data: 0.0001  max mem: 14938
[15:20:30.703817] Epoch: [11]  [300/345]  eta: 0:00:33  lr: 0.000074  loss: 0.8170 (0.8371)  time: 0.7489  data: 0.0001  max mem: 14938

[15:20:45.685218] Epoch: [11]  [320/345]  eta: 0:00:18  lr: 0.000075  loss: 0.8196 (0.8364)  time: 0.7490  data: 0.0001  max mem: 14938
[15:21:00.667520] Epoch: [11]  [340/345]  eta: 0:00:03  lr: 0.000075  loss: 0.8267 (0.8358)  time: 0.7491  data: 0.0001  max mem: 14938
[15:21:03.665806] Epoch: [11]  [344/345]  eta: 0:00:00  lr: 0.000075  loss: 0.8236 (0.8357)  time: 0.7491  data: 0.0001  max mem: 14938
[15:21:03.726767] Epoch: [11] Total time: 0:04:18 (0.7502 s / it)
[15:21:03.727281] Averaged stats: lr: 0.000075  loss: 0.8236 (0.8357)
[15:21:04.067425] Test:  [  0/345]  eta: 0:01:55  loss: 0.8161 (0.8161)  time: 0.3361  data: 0.1545  max mem: 14938
[15:21:05.902695] Test:  [ 10/345]  eta: 0:01:06  loss: 0.8013 (0.8038)  time: 0.1973  data: 0.0141  max mem: 14938
[15:21:07.740293] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7918 (0.7938)  time: 0.1836  data: 0.0001  max mem: 14938
[15:21:09.581767] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7808 (0.7923)  time: 0.1839  data: 0.0001  max mem: 14938
[15:21:11.427262] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7980 (0.7983)  time: 0.1843  data: 0.0001  max mem: 14938
[15:21:13.277449] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8079 (0.7993)  time: 0.1847  data: 0.0001  max mem: 14938
[15:21:15.131364] Test:  [ 60/345]  eta: 0:00:53  loss: 0.8056 (0.7988)  time: 0.1852  data: 0.0001  max mem: 14938
[15:21:16.986562] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8021 (0.7989)  time: 0.1854  data: 0.0001  max mem: 14938
[15:21:18.846180] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7992 (0.7995)  time: 0.1857  data: 0.0001  max mem: 14938
[15:21:20.710002] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7992 (0.8000)  time: 0.1861  data: 0.0001  max mem: 14938
[15:21:22.576523] Test:  [100/345]  eta: 0:00:45  loss: 0.8000 (0.8000)  time: 0.1865  data: 0.0001  max mem: 14938
[15:21:24.446555] Test:  [110/345]  eta: 0:00:43  loss: 0.8062 (0.8004)  time: 0.1868  data: 0.0001  max mem: 14938
[15:21:26.319421] Test:  [120/345]  eta: 0:00:41  loss: 0.8062 (0.7997)  time: 0.1871  data: 0.0001  max mem: 14938
[15:21:28.197637] Test:  [130/345]  eta: 0:00:40  loss: 0.7940 (0.7997)  time: 0.1875  data: 0.0001  max mem: 14938
[15:21:30.077682] Test:  [140/345]  eta: 0:00:38  loss: 0.8034 (0.8002)  time: 0.1879  data: 0.0001  max mem: 14938
[15:21:31.963666] Test:  [150/345]  eta: 0:00:36  loss: 0.8018 (0.8004)  time: 0.1882  data: 0.0001  max mem: 14938
[15:21:33.850381] Test:  [160/345]  eta: 0:00:34  loss: 0.8010 (0.8001)  time: 0.1886  data: 0.0001  max mem: 14938
[15:21:35.741001] Test:  [170/345]  eta: 0:00:32  loss: 0.7893 (0.7996)  time: 0.1888  data: 0.0001  max mem: 14938
[15:21:37.638932] Test:  [180/345]  eta: 0:00:30  loss: 0.8014 (0.8001)  time: 0.1894  data: 0.0001  max mem: 14938
[15:21:39.539456] Test:  [190/345]  eta: 0:00:29  loss: 0.8047 (0.8004)  time: 0.1899  data: 0.0001  max mem: 14938
[15:21:41.442229] Test:  [200/345]  eta: 0:00:27  loss: 0.7968 (0.7999)  time: 0.1901  data: 0.0001  max mem: 14938
[15:21:43.346356] Test:  [210/345]  eta: 0:00:25  loss: 0.7968 (0.7999)  time: 0.1903  data: 0.0001  max mem: 14938
[15:21:45.255738] Test:  [220/345]  eta: 0:00:23  loss: 0.7986 (0.7998)  time: 0.1906  data: 0.0001  max mem: 14938
[15:21:47.167976] Test:  [230/345]  eta: 0:00:21  loss: 0.7986 (0.7995)  time: 0.1910  data: 0.0001  max mem: 14938
[15:21:49.085815] Test:  [240/345]  eta: 0:00:19  loss: 0.7941 (0.7993)  time: 0.1915  data: 0.0001  max mem: 14938
[15:21:51.006912] Test:  [250/345]  eta: 0:00:17  loss: 0.7882 (0.7988)  time: 0.1919  data: 0.0001  max mem: 14938
[15:21:52.930879] Test:  [260/345]  eta: 0:00:16  loss: 0.7868 (0.7986)  time: 0.1922  data: 0.0001  max mem: 14938
[15:21:54.856679] Test:  [270/345]  eta: 0:00:14  loss: 0.7931 (0.7984)  time: 0.1924  data: 0.0001  max mem: 14938
[15:21:56.788419] Test:  [280/345]  eta: 0:00:12  loss: 0.8030 (0.7987)  time: 0.1928  data: 0.0001  max mem: 14938
[15:21:58.723255] Test:  [290/345]  eta: 0:00:10  loss: 0.8055 (0.7990)  time: 0.1933  data: 0.0001  max mem: 14938
[15:22:00.660461] Test:  [300/345]  eta: 0:00:08  loss: 0.7996 (0.7989)  time: 0.1936  data: 0.0001  max mem: 14938
[15:22:02.600684] Test:  [310/345]  eta: 0:00:06  loss: 0.7964 (0.7988)  time: 0.1938  data: 0.0001  max mem: 14938
[15:22:04.544374] Test:  [320/345]  eta: 0:00:04  loss: 0.7949 (0.7989)  time: 0.1941  data: 0.0001  max mem: 14938
[15:22:06.491804] Test:  [330/345]  eta: 0:00:02  loss: 0.7927 (0.7986)  time: 0.1945  data: 0.0001  max mem: 14938
[15:22:08.441835] Test:  [340/345]  eta: 0:00:00  loss: 0.7927 (0.7987)  time: 0.1948  data: 0.0001  max mem: 14938
[15:22:09.223636] Test:  [344/345]  eta: 0:00:00  loss: 0.7901 (0.7986)  time: 0.1949  data: 0.0001  max mem: 14938
[15:22:09.283549] Test: Total time: 0:01:05 (0.1900 s / it)
[15:22:19.850761] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8477 (0.8477)  time: 0.3193  data: 0.1395  max mem: 14938
[15:22:21.665184] Test:  [10/57]  eta: 0:00:09  loss: 0.8636 (0.8806)  time: 0.1939  data: 0.0127  max mem: 14938
[15:22:23.485578] Test:  [20/57]  eta: 0:00:06  loss: 0.8723 (0.8783)  time: 0.1817  data: 0.0001  max mem: 14938
[15:22:25.308988] Test:  [30/57]  eta: 0:00:05  loss: 0.7722 (0.8395)  time: 0.1821  data: 0.0001  max mem: 14938
[15:22:27.136677] Test:  [40/57]  eta: 0:00:03  loss: 0.7598 (0.8183)  time: 0.1825  data: 0.0001  max mem: 14938
[15:22:28.970619] Test:  [50/57]  eta: 0:00:01  loss: 0.7467 (0.8101)  time: 0.1830  data: 0.0001  max mem: 14938
[15:22:29.959877] Test:  [56/57]  eta: 0:00:00  loss: 0.7922 (0.8154)  time: 0.1777  data: 0.0001  max mem: 14938
[15:22:30.020356] Test: Total time: 0:00:10 (0.1840 s / it)
[15:22:31.769953] Dice score of the network on the train images: 0.741628, val images: 0.804116
[15:22:31.770176] saving best_rec_model_0 @ epoch 11
[15:22:32.900856] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:22:33.787534] Epoch: [12]  [  0/345]  eta: 0:05:05  lr: 0.000075  loss: 0.8643 (0.8643)  time: 0.8856  data: 0.1456  max mem: 14938
[15:22:48.655931] Epoch: [12]  [ 20/345]  eta: 0:04:03  lr: 0.000075  loss: 0.8177 (0.8292)  time: 0.7434  data: 0.0001  max mem: 14938
[15:23:03.593275] Epoch: [12]  [ 40/345]  eta: 0:03:48  lr: 0.000076  loss: 0.8173 (0.8254)  time: 0.7468  data: 0.0001  max mem: 14938
[15:23:18.561470] Epoch: [12]  [ 60/345]  eta: 0:03:33  lr: 0.000076  loss: 0.8366 (0.8294)  time: 0.7484  data: 0.0001  max mem: 14938
[15:23:33.554133] Epoch: [12]  [ 80/345]  eta: 0:03:18  lr: 0.000076  loss: 0.8463 (0.8345)  time: 0.7496  data: 0.0001  max mem: 14938
[15:23:48.576320] Epoch: [12]  [100/345]  eta: 0:03:03  lr: 0.000077  loss: 0.8146 (0.8323)  time: 0.7511  data: 0.0001  max mem: 14938
[15:24:03.617279] Epoch: [12]  [120/345]  eta: 0:02:48  lr: 0.000077  loss: 0.8190 (0.8304)  time: 0.7520  data: 0.0001  max mem: 14938
[15:24:18.643851] Epoch: [12]  [140/345]  eta: 0:02:33  lr: 0.000078  loss: 0.8477 (0.8320)  time: 0.7513  data: 0.0001  max mem: 14938
[15:24:33.667379] Epoch: [12]  [160/345]  eta: 0:02:18  lr: 0.000078  loss: 0.8332 (0.8320)  time: 0.7511  data: 0.0001  max mem: 14938
[15:24:48.689032] Epoch: [12]  [180/345]  eta: 0:02:03  lr: 0.000078  loss: 0.8218 (0.8309)  time: 0.7510  data: 0.0001  max mem: 14938
[15:25:03.693432] Epoch: [12]  [200/345]  eta: 0:01:48  lr: 0.000079  loss: 0.8153 (0.8299)  time: 0.7502  data: 0.0001  max mem: 14938
[15:25:18.694215] Epoch: [12]  [220/345]  eta: 0:01:33  lr: 0.000079  loss: 0.8323 (0.8297)  time: 0.7500  data: 0.0001  max mem: 14938
[15:25:33.691072] Epoch: [12]  [240/345]  eta: 0:01:18  lr: 0.000079  loss: 0.8148 (0.8291)  time: 0.7498  data: 0.0001  max mem: 14938
[15:25:48.685415] Epoch: [12]  [260/345]  eta: 0:01:03  lr: 0.000080  loss: 0.8267 (0.8291)  time: 0.7497  data: 0.0001  max mem: 14938
[15:26:03.674396] Epoch: [12]  [280/345]  eta: 0:00:48  lr: 0.000080  loss: 0.8366 (0.8293)  time: 0.7494  data: 0.0001  max mem: 14938
[15:26:18.659922] Epoch: [12]  [300/345]  eta: 0:00:33  lr: 0.000080  loss: 0.8259 (0.8289)  time: 0.7492  data: 0.0001  max mem: 14938
[15:26:33.645871] Epoch: [12]  [320/345]  eta: 0:00:18  lr: 0.000081  loss: 0.8200 (0.8290)  time: 0.7492  data: 0.0001  max mem: 14938
[15:26:48.625330] Epoch: [12]  [340/345]  eta: 0:00:03  lr: 0.000081  loss: 0.8316 (0.8292)  time: 0.7489  data: 0.0001  max mem: 14938
[15:26:51.622285] Epoch: [12]  [344/345]  eta: 0:00:00  lr: 0.000081  loss: 0.8316 (0.8292)  time: 0.7489  data: 0.0001  max mem: 14938
[15:26:51.689388] Epoch: [12] Total time: 0:04:18 (0.7501 s / it)
[15:26:51.689750] Averaged stats: lr: 0.000081  loss: 0.8316 (0.8292)
[15:26:52.025858] Test:  [  0/345]  eta: 0:01:54  loss: 0.8298 (0.8298)  time: 0.3321  data: 0.1506  max mem: 14938
[15:26:53.863309] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7953 (0.7962)  time: 0.1972  data: 0.0138  max mem: 14938
[15:26:55.701704] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7869 (0.7913)  time: 0.1837  data: 0.0001  max mem: 14938
[15:26:57.543760] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7809 (0.7902)  time: 0.1840  data: 0.0001  max mem: 14938
[15:26:59.389618] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7837 (0.7907)  time: 0.1843  data: 0.0001  max mem: 14938
[15:27:01.239543] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7837 (0.7892)  time: 0.1847  data: 0.0001  max mem: 14938
[15:27:03.091939] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7889 (0.7907)  time: 0.1851  data: 0.0001  max mem: 14938
[15:27:04.946308] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7917 (0.7910)  time: 0.1853  data: 0.0001  max mem: 14938
[15:27:06.805770] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7913 (0.7915)  time: 0.1856  data: 0.0001  max mem: 14938
[15:27:08.669491] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7913 (0.7912)  time: 0.1861  data: 0.0001  max mem: 14938
[15:27:10.536135] Test:  [100/345]  eta: 0:00:45  loss: 0.7766 (0.7896)  time: 0.1865  data: 0.0001  max mem: 14938
[15:27:12.403886] Test:  [110/345]  eta: 0:00:43  loss: 0.7766 (0.7893)  time: 0.1867  data: 0.0001  max mem: 14938
[15:27:14.277998] Test:  [120/345]  eta: 0:00:41  loss: 0.7858 (0.7896)  time: 0.1870  data: 0.0001  max mem: 14938
[15:27:16.154963] Test:  [130/345]  eta: 0:00:40  loss: 0.7877 (0.7893)  time: 0.1875  data: 0.0001  max mem: 14938
[15:27:18.035539] Test:  [140/345]  eta: 0:00:38  loss: 0.7833 (0.7893)  time: 0.1878  data: 0.0001  max mem: 14938
[15:27:19.919961] Test:  [150/345]  eta: 0:00:36  loss: 0.7845 (0.7890)  time: 0.1882  data: 0.0001  max mem: 14938
[15:27:21.805861] Test:  [160/345]  eta: 0:00:34  loss: 0.7845 (0.7886)  time: 0.1885  data: 0.0001  max mem: 14938
[15:27:23.695999] Test:  [170/345]  eta: 0:00:32  loss: 0.7823 (0.7882)  time: 0.1888  data: 0.0001  max mem: 14938
[15:27:25.590767] Test:  [180/345]  eta: 0:00:30  loss: 0.7844 (0.7881)  time: 0.1892  data: 0.0001  max mem: 14938
[15:27:27.490327] Test:  [190/345]  eta: 0:00:29  loss: 0.7802 (0.7874)  time: 0.1897  data: 0.0001  max mem: 14938
[15:27:29.392298] Test:  [200/345]  eta: 0:00:27  loss: 0.7801 (0.7874)  time: 0.1900  data: 0.0001  max mem: 14938
[15:27:31.296811] Test:  [210/345]  eta: 0:00:25  loss: 0.7829 (0.7873)  time: 0.1903  data: 0.0001  max mem: 14938
[15:27:33.206304] Test:  [220/345]  eta: 0:00:23  loss: 0.7864 (0.7875)  time: 0.1906  data: 0.0001  max mem: 14938
[15:27:35.118126] Test:  [230/345]  eta: 0:00:21  loss: 0.7864 (0.7876)  time: 0.1910  data: 0.0001  max mem: 14938
[15:27:37.033525] Test:  [240/345]  eta: 0:00:19  loss: 0.7883 (0.7876)  time: 0.1913  data: 0.0001  max mem: 14938
[15:27:38.953131] Test:  [250/345]  eta: 0:00:17  loss: 0.7858 (0.7877)  time: 0.1917  data: 0.0001  max mem: 14938
[15:27:40.875217] Test:  [260/345]  eta: 0:00:16  loss: 0.7820 (0.7876)  time: 0.1920  data: 0.0001  max mem: 14938
[15:27:42.801701] Test:  [270/345]  eta: 0:00:14  loss: 0.7870 (0.7877)  time: 0.1924  data: 0.0001  max mem: 14938
[15:27:44.731377] Test:  [280/345]  eta: 0:00:12  loss: 0.7926 (0.7883)  time: 0.1928  data: 0.0001  max mem: 14938
[15:27:46.663731] Test:  [290/345]  eta: 0:00:10  loss: 0.8031 (0.7884)  time: 0.1931  data: 0.0001  max mem: 14938
[15:27:48.600167] Test:  [300/345]  eta: 0:00:08  loss: 0.7777 (0.7883)  time: 0.1934  data: 0.0001  max mem: 14938
[15:27:50.539966] Test:  [310/345]  eta: 0:00:06  loss: 0.7811 (0.7882)  time: 0.1938  data: 0.0001  max mem: 14938
[15:27:52.482661] Test:  [320/345]  eta: 0:00:04  loss: 0.7811 (0.7880)  time: 0.1941  data: 0.0001  max mem: 14938
[15:27:54.429099] Test:  [330/345]  eta: 0:00:02  loss: 0.7768 (0.7878)  time: 0.1944  data: 0.0001  max mem: 14938
[15:27:56.378083] Test:  [340/345]  eta: 0:00:00  loss: 0.7780 (0.7880)  time: 0.1947  data: 0.0001  max mem: 14938
[15:27:57.159083] Test:  [344/345]  eta: 0:00:00  loss: 0.7826 (0.7880)  time: 0.1949  data: 0.0001  max mem: 14938
[15:27:57.202197] Test: Total time: 0:01:05 (0.1899 s / it)
[15:28:07.744715] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8421 (0.8421)  time: 0.3191  data: 0.1397  max mem: 14938
[15:28:09.559633] Test:  [10/57]  eta: 0:00:09  loss: 0.8717 (0.8840)  time: 0.1939  data: 0.0128  max mem: 14938
[15:28:11.381105] Test:  [20/57]  eta: 0:00:06  loss: 0.8849 (0.8747)  time: 0.1818  data: 0.0001  max mem: 14938
[15:28:13.204781] Test:  [30/57]  eta: 0:00:05  loss: 0.7786 (0.8386)  time: 0.1822  data: 0.0001  max mem: 14938
[15:28:15.033388] Test:  [40/57]  eta: 0:00:03  loss: 0.7640 (0.8190)  time: 0.1826  data: 0.0001  max mem: 14938
[15:28:16.867728] Test:  [50/57]  eta: 0:00:01  loss: 0.7620 (0.8143)  time: 0.1831  data: 0.0001  max mem: 14938
[15:28:17.857271] Test:  [56/57]  eta: 0:00:00  loss: 0.7972 (0.8208)  time: 0.1778  data: 0.0001  max mem: 14938
[15:28:17.918548] Test: Total time: 0:00:10 (0.1841 s / it)
[15:28:19.647117] Dice score of the network on the train images: 0.761012, val images: 0.789393
[15:28:19.647343] saving best_prec_model_0 @ epoch 12
[15:28:20.712156] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:28:21.597892] Epoch: [13]  [  0/345]  eta: 0:05:05  lr: 0.000081  loss: 0.8329 (0.8329)  time: 0.8846  data: 0.1448  max mem: 14938
[15:28:36.456255] Epoch: [13]  [ 20/345]  eta: 0:04:03  lr: 0.000082  loss: 0.8123 (0.8116)  time: 0.7429  data: 0.0001  max mem: 14938
[15:28:51.369329] Epoch: [13]  [ 40/345]  eta: 0:03:48  lr: 0.000082  loss: 0.8079 (0.8116)  time: 0.7456  data: 0.0001  max mem: 14938

[15:29:06.309310] Epoch: [13]  [ 60/345]  eta: 0:03:33  lr: 0.000082  loss: 0.8375 (0.8220)  time: 0.7469  data: 0.0001  max mem: 14938
[15:29:21.259000] Epoch: [13]  [ 80/345]  eta: 0:03:18  lr: 0.000083  loss: 0.8159 (0.8224)  time: 0.7474  data: 0.0001  max mem: 14938
[15:29:36.259471] Epoch: [13]  [100/345]  eta: 0:03:03  lr: 0.000083  loss: 0.8284 (0.8263)  time: 0.7500  data: 0.0001  max mem: 14938
[15:29:51.290776] Epoch: [13]  [120/345]  eta: 0:02:48  lr: 0.000083  loss: 0.8263 (0.8264)  time: 0.7515  data: 0.0001  max mem: 14938
[15:30:06.316049] Epoch: [13]  [140/345]  eta: 0:02:33  lr: 0.000084  loss: 0.8179 (0.8256)  time: 0.7512  data: 0.0001  max mem: 14938
[15:30:21.329660] Epoch: [13]  [160/345]  eta: 0:02:18  lr: 0.000084  loss: 0.8192 (0.8254)  time: 0.7506  data: 0.0001  max mem: 14938
[15:30:36.336557] Epoch: [13]  [180/345]  eta: 0:02:03  lr: 0.000085  loss: 0.8159 (0.8244)  time: 0.7503  data: 0.0001  max mem: 14938
[15:30:51.329907] Epoch: [13]  [200/345]  eta: 0:01:48  lr: 0.000085  loss: 0.8152 (0.8244)  time: 0.7496  data: 0.0001  max mem: 14938
[15:31:06.311921] Epoch: [13]  [220/345]  eta: 0:01:33  lr: 0.000085  loss: 0.8066 (0.8232)  time: 0.7491  data: 0.0001  max mem: 14938
[15:31:21.277208] Epoch: [13]  [240/345]  eta: 0:01:18  lr: 0.000086  loss: 0.8213 (0.8235)  time: 0.7482  data: 0.0001  max mem: 14938
[15:31:36.238813] Epoch: [13]  [260/345]  eta: 0:01:03  lr: 0.000086  loss: 0.8259 (0.8240)  time: 0.7480  data: 0.0001  max mem: 14938
[15:31:51.223951] Epoch: [13]  [280/345]  eta: 0:00:48  lr: 0.000086  loss: 0.8183 (0.8241)  time: 0.7492  data: 0.0001  max mem: 14938
[15:32:06.203821] Epoch: [13]  [300/345]  eta: 0:00:33  lr: 0.000087  loss: 0.8195 (0.8240)  time: 0.7490  data: 0.0001  max mem: 14938
[15:32:21.180207] Epoch: [13]  [320/345]  eta: 0:00:18  lr: 0.000087  loss: 0.8184 (0.8234)  time: 0.7488  data: 0.0001  max mem: 14938
[15:32:36.156843] Epoch: [13]  [340/345]  eta: 0:00:03  lr: 0.000087  loss: 0.8106 (0.8229)  time: 0.7488  data: 0.0001  max mem: 14938
[15:32:39.150779] Epoch: [13]  [344/345]  eta: 0:00:00  lr: 0.000087  loss: 0.8196 (0.8229)  time: 0.7486  data: 0.0001  max mem: 14938
[15:32:39.215175] Epoch: [13] Total time: 0:04:18 (0.7493 s / it)
[15:32:39.215481] Averaged stats: lr: 0.000087  loss: 0.8196 (0.8229)
[15:32:39.562763] Test:  [  0/345]  eta: 0:01:58  loss: 0.8125 (0.8125)  time: 0.3429  data: 0.1607  max mem: 14938
[15:32:41.399729] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7999 (0.8013)  time: 0.1981  data: 0.0147  max mem: 14938
[15:32:43.239667] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7972 (0.7999)  time: 0.1838  data: 0.0001  max mem: 14938
[15:32:45.081625] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7972 (0.8019)  time: 0.1840  data: 0.0001  max mem: 14938
[15:32:46.926594] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7987 (0.7993)  time: 0.1843  data: 0.0001  max mem: 14938
[15:32:48.778035] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8009 (0.8007)  time: 0.1848  data: 0.0001  max mem: 14938
[15:32:50.631191] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7994 (0.7995)  time: 0.1852  data: 0.0001  max mem: 14938
[15:32:52.487437] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7945 (0.7988)  time: 0.1854  data: 0.0001  max mem: 14938
[15:32:54.347153] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7960 (0.7997)  time: 0.1857  data: 0.0001  max mem: 14938
[15:32:56.210071] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7928 (0.7976)  time: 0.1861  data: 0.0001  max mem: 14938
[15:32:58.075761] Test:  [100/345]  eta: 0:00:45  loss: 0.7897 (0.7970)  time: 0.1864  data: 0.0001  max mem: 14938
[15:32:59.945526] Test:  [110/345]  eta: 0:00:43  loss: 0.7976 (0.7971)  time: 0.1867  data: 0.0001  max mem: 14938
[15:33:01.819783] Test:  [120/345]  eta: 0:00:42  loss: 0.7989 (0.7971)  time: 0.1871  data: 0.0001  max mem: 14938
[15:33:03.696163] Test:  [130/345]  eta: 0:00:40  loss: 0.7933 (0.7971)  time: 0.1875  data: 0.0001  max mem: 14938
[15:33:05.576982] Test:  [140/345]  eta: 0:00:38  loss: 0.7870 (0.7967)  time: 0.1878  data: 0.0001  max mem: 14938
[15:33:07.461908] Test:  [150/345]  eta: 0:00:36  loss: 0.8018 (0.7967)  time: 0.1882  data: 0.0001  max mem: 14938
[15:33:09.349007] Test:  [160/345]  eta: 0:00:34  loss: 0.7939 (0.7963)  time: 0.1885  data: 0.0001  max mem: 14938
[15:33:11.239097] Test:  [170/345]  eta: 0:00:32  loss: 0.7918 (0.7964)  time: 0.1888  data: 0.0001  max mem: 14938
[15:33:13.134087] Test:  [180/345]  eta: 0:00:30  loss: 0.7918 (0.7959)  time: 0.1892  data: 0.0001  max mem: 14938
[15:33:15.033485] Test:  [190/345]  eta: 0:00:29  loss: 0.7970 (0.7961)  time: 0.1897  data: 0.0001  max mem: 14938
[15:33:16.935451] Test:  [200/345]  eta: 0:00:27  loss: 0.8009 (0.7963)  time: 0.1900  data: 0.0001  max mem: 14938
[15:33:18.840460] Test:  [210/345]  eta: 0:00:25  loss: 0.7968 (0.7962)  time: 0.1903  data: 0.0001  max mem: 14938
[15:33:20.749096] Test:  [220/345]  eta: 0:00:23  loss: 0.7868 (0.7960)  time: 0.1906  data: 0.0001  max mem: 14938
[15:33:22.661427] Test:  [230/345]  eta: 0:00:21  loss: 0.7940 (0.7964)  time: 0.1910  data: 0.0001  max mem: 14938
[15:33:24.577701] Test:  [240/345]  eta: 0:00:19  loss: 0.7966 (0.7962)  time: 0.1914  data: 0.0001  max mem: 14938
[15:33:26.497596] Test:  [250/345]  eta: 0:00:17  loss: 0.7911 (0.7961)  time: 0.1918  data: 0.0001  max mem: 14938
[15:33:28.419541] Test:  [260/345]  eta: 0:00:16  loss: 0.7870 (0.7962)  time: 0.1920  data: 0.0001  max mem: 14938
[15:33:30.345162] Test:  [270/345]  eta: 0:00:14  loss: 0.7870 (0.7961)  time: 0.1923  data: 0.0001  max mem: 14938
[15:33:32.276994] Test:  [280/345]  eta: 0:00:12  loss: 0.7879 (0.7960)  time: 0.1928  data: 0.0001  max mem: 14938
[15:33:34.210456] Test:  [290/345]  eta: 0:00:10  loss: 0.7925 (0.7962)  time: 0.1932  data: 0.0001  max mem: 14938
[15:33:36.148168] Test:  [300/345]  eta: 0:00:08  loss: 0.7969 (0.7963)  time: 0.1935  data: 0.0001  max mem: 14938
[15:33:38.089611] Test:  [310/345]  eta: 0:00:06  loss: 0.7907 (0.7962)  time: 0.1939  data: 0.0001  max mem: 14938
[15:33:40.033545] Test:  [320/345]  eta: 0:00:04  loss: 0.7932 (0.7962)  time: 0.1942  data: 0.0001  max mem: 14938
[15:33:41.978596] Test:  [330/345]  eta: 0:00:02  loss: 0.7957 (0.7962)  time: 0.1944  data: 0.0001  max mem: 14938
[15:33:43.926545] Test:  [340/345]  eta: 0:00:00  loss: 0.7931 (0.7961)  time: 0.1946  data: 0.0001  max mem: 14938
[15:33:44.707750] Test:  [344/345]  eta: 0:00:00  loss: 0.7958 (0.7960)  time: 0.1947  data: 0.0001  max mem: 14938
[15:33:44.767690] Test: Total time: 0:01:05 (0.1900 s / it)
[15:33:55.218490] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8925 (0.8925)  time: 0.3244  data: 0.1450  max mem: 14938
[15:33:57.032882] Test:  [10/57]  eta: 0:00:09  loss: 0.8925 (0.8838)  time: 0.1944  data: 0.0132  max mem: 14938
[15:33:58.852770] Test:  [20/57]  eta: 0:00:06  loss: 0.8898 (0.8764)  time: 0.1817  data: 0.0001  max mem: 14938
[15:34:00.675957] Test:  [30/57]  eta: 0:00:05  loss: 0.7813 (0.8414)  time: 0.1821  data: 0.0001  max mem: 14938
[15:34:02.503674] Test:  [40/57]  eta: 0:00:03  loss: 0.7656 (0.8218)  time: 0.1825  data: 0.0001  max mem: 14938
[15:34:04.338044] Test:  [50/57]  eta: 0:00:01  loss: 0.7606 (0.8161)  time: 0.1831  data: 0.0001  max mem: 14938
[15:34:05.326057] Test:  [56/57]  eta: 0:00:00  loss: 0.7955 (0.8214)  time: 0.1777  data: 0.0001  max mem: 14938
[15:34:05.384509] Test: Total time: 0:00:10 (0.1841 s / it)
[15:34:07.126254] Dice score of the network on the train images: 0.754233, val images: 0.775761
[15:34:07.130255] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:34:08.023323] Epoch: [14]  [  0/345]  eta: 0:05:07  lr: 0.000087  loss: 0.8445 (0.8445)  time: 0.8921  data: 0.1517  max mem: 14938
[15:34:22.896495] Epoch: [14]  [ 20/345]  eta: 0:04:03  lr: 0.000088  loss: 0.8181 (0.8160)  time: 0.7436  data: 0.0001  max mem: 14938
[15:34:37.823830] Epoch: [14]  [ 40/345]  eta: 0:03:48  lr: 0.000088  loss: 0.8026 (0.8118)  time: 0.7463  data: 0.0001  max mem: 14938
[15:34:52.782025] Epoch: [14]  [ 60/345]  eta: 0:03:33  lr: 0.000089  loss: 0.8026 (0.8090)  time: 0.7479  data: 0.0001  max mem: 14938
[15:35:07.759224] Epoch: [14]  [ 80/345]  eta: 0:03:18  lr: 0.000089  loss: 0.8003 (0.8067)  time: 0.7488  data: 0.0001  max mem: 14938
[15:35:22.758158] Epoch: [14]  [100/345]  eta: 0:03:03  lr: 0.000089  loss: 0.7988 (0.8057)  time: 0.7499  data: 0.0001  max mem: 14938
[15:35:37.796670] Epoch: [14]  [120/345]  eta: 0:02:48  lr: 0.000090  loss: 0.8063 (0.8064)  time: 0.7519  data: 0.0001  max mem: 14938
[15:35:52.817844] Epoch: [14]  [140/345]  eta: 0:02:33  lr: 0.000090  loss: 0.8025 (0.8065)  time: 0.7510  data: 0.0001  max mem: 14938
[15:36:07.830034] Epoch: [14]  [160/345]  eta: 0:02:18  lr: 0.000090  loss: 0.8116 (0.8071)  time: 0.7506  data: 0.0001  max mem: 14938
[15:36:22.818552] Epoch: [14]  [180/345]  eta: 0:02:03  lr: 0.000091  loss: 0.8064 (0.8071)  time: 0.7494  data: 0.0001  max mem: 14938
[15:36:37.792398] Epoch: [14]  [200/345]  eta: 0:01:48  lr: 0.000091  loss: 0.7971 (0.8065)  time: 0.7486  data: 0.0001  max mem: 14938
[15:36:52.766680] Epoch: [14]  [220/345]  eta: 0:01:33  lr: 0.000091  loss: 0.8149 (0.8070)  time: 0.7487  data: 0.0001  max mem: 14938
[15:37:07.734018] Epoch: [14]  [240/345]  eta: 0:01:18  lr: 0.000092  loss: 0.8062 (0.8071)  time: 0.7483  data: 0.0001  max mem: 14938
[15:37:22.709321] Epoch: [14]  [260/345]  eta: 0:01:03  lr: 0.000092  loss: 0.7867 (0.8060)  time: 0.7487  data: 0.0001  max mem: 14938
[15:37:37.695839] Epoch: [14]  [280/345]  eta: 0:00:48  lr: 0.000093  loss: 0.7928 (0.8056)  time: 0.7493  data: 0.0001  max mem: 14938
[15:37:52.670614] Epoch: [14]  [300/345]  eta: 0:00:33  lr: 0.000093  loss: 0.7995 (0.8053)  time: 0.7487  data: 0.0001  max mem: 14938
[15:38:07.623828] Epoch: [14]  [320/345]  eta: 0:00:18  lr: 0.000093  loss: 0.8067 (0.8055)  time: 0.7476  data: 0.0001  max mem: 14938
[15:38:22.574749] Epoch: [14]  [340/345]  eta: 0:00:03  lr: 0.000094  loss: 0.7904 (0.8049)  time: 0.7475  data: 0.0001  max mem: 14938
[15:38:25.564643] Epoch: [14]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.7898 (0.8048)  time: 0.7477  data: 0.0001  max mem: 14938
[15:38:25.624401] Epoch: [14] Total time: 0:04:18 (0.7493 s / it)
[15:38:25.624843] Averaged stats: lr: 0.000094  loss: 0.7898 (0.8048)
[15:38:25.969052] Test:  [  0/345]  eta: 0:01:57  loss: 0.7718 (0.7718)  time: 0.3403  data: 0.1589  max mem: 14938
[15:38:27.804755] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7718 (0.7694)  time: 0.1977  data: 0.0145  max mem: 14938
[15:38:29.642761] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7795 (0.7748)  time: 0.1836  data: 0.0001  max mem: 14938
[15:38:31.485410] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7762 (0.7712)  time: 0.1840  data: 0.0001  max mem: 14938
[15:38:33.330545] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7633 (0.7703)  time: 0.1843  data: 0.0001  max mem: 14938
[15:38:35.181492] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7601 (0.7694)  time: 0.1848  data: 0.0001  max mem: 14938
[15:38:37.034193] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7639 (0.7707)  time: 0.1851  data: 0.0001  max mem: 14938
[15:38:38.890208] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7736 (0.7710)  time: 0.1854  data: 0.0001  max mem: 14938
[15:38:40.748922] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7779 (0.7724)  time: 0.1857  data: 0.0001  max mem: 14938
[15:38:42.611449] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7773 (0.7722)  time: 0.1860  data: 0.0001  max mem: 14938
[15:38:44.477005] Test:  [100/345]  eta: 0:00:45  loss: 0.7702 (0.7732)  time: 0.1864  data: 0.0001  max mem: 14938
[15:38:46.347349] Test:  [110/345]  eta: 0:00:43  loss: 0.7702 (0.7731)  time: 0.1867  data: 0.0001  max mem: 14938
[15:38:48.219972] Test:  [120/345]  eta: 0:00:41  loss: 0.7646 (0.7732)  time: 0.1871  data: 0.0001  max mem: 14938
[15:38:50.095320] Test:  [130/345]  eta: 0:00:40  loss: 0.7677 (0.7735)  time: 0.1873  data: 0.0001  max mem: 14938
[15:38:51.976620] Test:  [140/345]  eta: 0:00:38  loss: 0.7703 (0.7734)  time: 0.1878  data: 0.0001  max mem: 14938
[15:38:53.860373] Test:  [150/345]  eta: 0:00:36  loss: 0.7639 (0.7730)  time: 0.1882  data: 0.0001  max mem: 14938
[15:38:55.747495] Test:  [160/345]  eta: 0:00:34  loss: 0.7692 (0.7731)  time: 0.1885  data: 0.0001  max mem: 14938
[15:38:57.637413] Test:  [170/345]  eta: 0:00:32  loss: 0.7712 (0.7727)  time: 0.1888  data: 0.0001  max mem: 14938
[15:38:59.533499] Test:  [180/345]  eta: 0:00:30  loss: 0.7692 (0.7724)  time: 0.1892  data: 0.0001  max mem: 14938
[15:39:01.432355] Test:  [190/345]  eta: 0:00:29  loss: 0.7705 (0.7725)  time: 0.1897  data: 0.0001  max mem: 14938
[15:39:03.335988] Test:  [200/345]  eta: 0:00:27  loss: 0.7813 (0.7725)  time: 0.1901  data: 0.0001  max mem: 14938
[15:39:05.240568] Test:  [210/345]  eta: 0:00:25  loss: 0.7724 (0.7724)  time: 0.1904  data: 0.0001  max mem: 14938
[15:39:07.150174] Test:  [220/345]  eta: 0:00:23  loss: 0.7696 (0.7726)  time: 0.1907  data: 0.0001  max mem: 14938
[15:39:09.063099] Test:  [230/345]  eta: 0:00:21  loss: 0.7660 (0.7719)  time: 0.1911  data: 0.0001  max mem: 14938
[15:39:10.977824] Test:  [240/345]  eta: 0:00:19  loss: 0.7633 (0.7721)  time: 0.1913  data: 0.0001  max mem: 14938
[15:39:12.896883] Test:  [250/345]  eta: 0:00:17  loss: 0.7721 (0.7721)  time: 0.1916  data: 0.0001  max mem: 14938
[15:39:14.818867] Test:  [260/345]  eta: 0:00:16  loss: 0.7787 (0.7723)  time: 0.1920  data: 0.0001  max mem: 14938
[15:39:16.747441] Test:  [270/345]  eta: 0:00:14  loss: 0.7776 (0.7726)  time: 0.1925  data: 0.0001  max mem: 14938
[15:39:18.677668] Test:  [280/345]  eta: 0:00:12  loss: 0.7709 (0.7727)  time: 0.1929  data: 0.0001  max mem: 14938
[15:39:20.610860] Test:  [290/345]  eta: 0:00:10  loss: 0.7619 (0.7726)  time: 0.1931  data: 0.0001  max mem: 14938
[15:39:22.547307] Test:  [300/345]  eta: 0:00:08  loss: 0.7630 (0.7726)  time: 0.1934  data: 0.0001  max mem: 14938
[15:39:24.487241] Test:  [310/345]  eta: 0:00:06  loss: 0.7631 (0.7723)  time: 0.1938  data: 0.0001  max mem: 14938
[15:39:26.428927] Test:  [320/345]  eta: 0:00:04  loss: 0.7716 (0.7725)  time: 0.1940  data: 0.0001  max mem: 14938
[15:39:28.374150] Test:  [330/345]  eta: 0:00:02  loss: 0.7773 (0.7726)  time: 0.1943  data: 0.0001  max mem: 14938
[15:39:30.322119] Test:  [340/345]  eta: 0:00:00  loss: 0.7738 (0.7724)  time: 0.1946  data: 0.0001  max mem: 14938
[15:39:31.102986] Test:  [344/345]  eta: 0:00:00  loss: 0.7771 (0.7726)  time: 0.1948  data: 0.0001  max mem: 14938
[15:39:31.164926] Test: Total time: 0:01:05 (0.1900 s / it)
[15:39:41.684430] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8461 (0.8461)  time: 0.3248  data: 0.1451  max mem: 14938
[15:39:43.499961] Test:  [10/57]  eta: 0:00:09  loss: 0.8492 (0.8712)  time: 0.1945  data: 0.0133  max mem: 14938
[15:39:45.321954] Test:  [20/57]  eta: 0:00:06  loss: 0.8696 (0.8657)  time: 0.1818  data: 0.0001  max mem: 14938
[15:39:47.145955] Test:  [30/57]  eta: 0:00:05  loss: 0.7663 (0.8301)  time: 0.1822  data: 0.0001  max mem: 14938
[15:39:48.972411] Test:  [40/57]  eta: 0:00:03  loss: 0.7510 (0.8115)  time: 0.1825  data: 0.0001  max mem: 14938
[15:39:50.807195] Test:  [50/57]  eta: 0:00:01  loss: 0.7468 (0.8048)  time: 0.1830  data: 0.0001  max mem: 14938
[15:39:51.796272] Test:  [56/57]  eta: 0:00:00  loss: 0.7814 (0.8106)  time: 0.1777  data: 0.0001  max mem: 14938
[15:39:51.854190] Test: Total time: 0:00:10 (0.1841 s / it)
[15:39:53.617379] Dice score of the network on the train images: 0.761946, val images: 0.808806
[15:39:53.617609] saving best_dice_model_0 @ epoch 14
[15:39:54.779051] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:39:55.668103] Epoch: [15]  [  0/345]  eta: 0:05:06  lr: 0.000094  loss: 0.8001 (0.8001)  time: 0.8879  data: 0.1477  max mem: 14938
[15:40:10.509084] Epoch: [15]  [ 20/345]  eta: 0:04:03  lr: 0.000094  loss: 0.7910 (0.7936)  time: 0.7420  data: 0.0001  max mem: 14938
[15:40:25.402905] Epoch: [15]  [ 40/345]  eta: 0:03:47  lr: 0.000094  loss: 0.7952 (0.7988)  time: 0.7446  data: 0.0001  max mem: 14938
[15:40:40.334667] Epoch: [15]  [ 60/345]  eta: 0:03:32  lr: 0.000095  loss: 0.8086 (0.8043)  time: 0.7465  data: 0.0001  max mem: 14938
[15:40:55.296611] Epoch: [15]  [ 80/345]  eta: 0:03:17  lr: 0.000095  loss: 0.8208 (0.8094)  time: 0.7480  data: 0.0001  max mem: 14938
[15:41:10.300509] Epoch: [15]  [100/345]  eta: 0:03:03  lr: 0.000096  loss: 0.7929 (0.8076)  time: 0.7501  data: 0.0001  max mem: 14938
[15:41:25.324135] Epoch: [15]  [120/345]  eta: 0:02:48  lr: 0.000096  loss: 0.8066 (0.8079)  time: 0.7511  data: 0.0001  max mem: 14938
[15:41:40.358409] Epoch: [15]  [140/345]  eta: 0:02:33  lr: 0.000096  loss: 0.7968 (0.8066)  time: 0.7517  data: 0.0001  max mem: 14938
[15:41:55.391024] Epoch: [15]  [160/345]  eta: 0:02:18  lr: 0.000097  loss: 0.7958 (0.8054)  time: 0.7516  data: 0.0001  max mem: 14938
[15:42:10.393983] Epoch: [15]  [180/345]  eta: 0:02:03  lr: 0.000097  loss: 0.8102 (0.8076)  time: 0.7501  data: 0.0001  max mem: 14938
[15:42:25.383686] Epoch: [15]  [200/345]  eta: 0:01:48  lr: 0.000097  loss: 0.8210 (0.8089)  time: 0.7494  data: 0.0001  max mem: 14938
[15:42:40.377722] Epoch: [15]  [220/345]  eta: 0:01:33  lr: 0.000098  loss: 0.8008 (0.8083)  time: 0.7497  data: 0.0001  max mem: 14938
[15:42:55.357874] Epoch: [15]  [240/345]  eta: 0:01:18  lr: 0.000098  loss: 0.8014 (0.8075)  time: 0.7490  data: 0.0001  max mem: 14938
[15:43:10.326675] Epoch: [15]  [260/345]  eta: 0:01:03  lr: 0.000098  loss: 0.7935 (0.8070)  time: 0.7484  data: 0.0001  max mem: 14938
[15:43:25.286041] Epoch: [15]  [280/345]  eta: 0:00:48  lr: 0.000099  loss: 0.8125 (0.8073)  time: 0.7479  data: 0.0001  max mem: 14938
[15:43:40.266576] Epoch: [15]  [300/345]  eta: 0:00:33  lr: 0.000099  loss: 0.7986 (0.8071)  time: 0.7490  data: 0.0001  max mem: 14938
[15:43:55.238662] Epoch: [15]  [320/345]  eta: 0:00:18  lr: 0.000100  loss: 0.8083 (0.8074)  time: 0.7486  data: 0.0001  max mem: 14938
[15:44:10.214156] Epoch: [15]  [340/345]  eta: 0:00:03  lr: 0.000100  loss: 0.8016 (0.8069)  time: 0.7487  data: 0.0001  max mem: 14938
[15:44:13.206381] Epoch: [15]  [344/345]  eta: 0:00:00  lr: 0.000100  loss: 0.7992 (0.8067)  time: 0.7486  data: 0.0001  max mem: 14938
[15:44:13.272246] Epoch: [15] Total time: 0:04:18 (0.7493 s / it)
[15:44:13.272665] Averaged stats: lr: 0.000100  loss: 0.7992 (0.8067)
[15:44:13.612696] Test:  [  0/345]  eta: 0:01:55  loss: 0.7587 (0.7587)  time: 0.3359  data: 0.1543  max mem: 14938
[15:44:15.448747] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7671 (0.7624)  time: 0.1974  data: 0.0141  max mem: 14938
[15:44:17.288085] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7602 (0.7591)  time: 0.1837  data: 0.0001  max mem: 14938
[15:44:19.130889] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7554 (0.7587)  time: 0.1841  data: 0.0001  max mem: 14938
[15:44:20.975104] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7554 (0.7576)  time: 0.1843  data: 0.0001  max mem: 14938
[15:44:22.824766] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7582 (0.7595)  time: 0.1846  data: 0.0001  max mem: 14938
[15:44:24.678425] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7645 (0.7596)  time: 0.1851  data: 0.0001  max mem: 14938
[15:44:26.533299] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7577 (0.7597)  time: 0.1854  data: 0.0001  max mem: 14938
[15:44:28.391372] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7538 (0.7587)  time: 0.1856  data: 0.0001  max mem: 14938
[15:44:30.254240] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7478 (0.7581)  time: 0.1860  data: 0.0001  max mem: 14938
[15:44:32.120761] Test:  [100/345]  eta: 0:00:45  loss: 0.7560 (0.7588)  time: 0.1864  data: 0.0001  max mem: 14938
[15:44:33.991157] Test:  [110/345]  eta: 0:00:43  loss: 0.7663 (0.7592)  time: 0.1868  data: 0.0001  max mem: 14938
[15:44:35.863702] Test:  [120/345]  eta: 0:00:41  loss: 0.7650 (0.7594)  time: 0.1871  data: 0.0001  max mem: 14938
[15:44:37.740436] Test:  [130/345]  eta: 0:00:40  loss: 0.7567 (0.7594)  time: 0.1874  data: 0.0001  max mem: 14938
[15:44:39.620773] Test:  [140/345]  eta: 0:00:38  loss: 0.7631 (0.7602)  time: 0.1878  data: 0.0001  max mem: 14938
[15:44:41.506278] Test:  [150/345]  eta: 0:00:36  loss: 0.7587 (0.7598)  time: 0.1882  data: 0.0001  max mem: 14938
[15:44:43.394079] Test:  [160/345]  eta: 0:00:34  loss: 0.7597 (0.7606)  time: 0.1886  data: 0.0001  max mem: 14938
[15:44:45.282447] Test:  [170/345]  eta: 0:00:32  loss: 0.7665 (0.7605)  time: 0.1888  data: 0.0001  max mem: 14938
[15:44:47.177834] Test:  [180/345]  eta: 0:00:30  loss: 0.7623 (0.7607)  time: 0.1891  data: 0.0001  max mem: 14938
[15:44:49.076099] Test:  [190/345]  eta: 0:00:29  loss: 0.7577 (0.7607)  time: 0.1896  data: 0.0001  max mem: 14938
[15:44:50.979043] Test:  [200/345]  eta: 0:00:27  loss: 0.7574 (0.7605)  time: 0.1900  data: 0.0001  max mem: 14938
[15:44:52.883474] Test:  [210/345]  eta: 0:00:25  loss: 0.7538 (0.7601)  time: 0.1903  data: 0.0001  max mem: 14938
[15:44:54.791984] Test:  [220/345]  eta: 0:00:23  loss: 0.7587 (0.7601)  time: 0.1906  data: 0.0001  max mem: 14938
[15:44:56.705130] Test:  [230/345]  eta: 0:00:21  loss: 0.7607 (0.7603)  time: 0.1910  data: 0.0001  max mem: 14938
[15:44:58.622170] Test:  [240/345]  eta: 0:00:19  loss: 0.7641 (0.7606)  time: 0.1914  data: 0.0001  max mem: 14938
[15:45:00.543125] Test:  [250/345]  eta: 0:00:17  loss: 0.7615 (0.7608)  time: 0.1918  data: 0.0001  max mem: 14938
[15:45:02.466509] Test:  [260/345]  eta: 0:00:16  loss: 0.7586 (0.7605)  time: 0.1922  data: 0.0001  max mem: 14938
[15:45:04.392569] Test:  [270/345]  eta: 0:00:14  loss: 0.7533 (0.7605)  time: 0.1924  data: 0.0001  max mem: 14938
[15:45:06.320719] Test:  [280/345]  eta: 0:00:12  loss: 0.7647 (0.7609)  time: 0.1927  data: 0.0001  max mem: 14938
[15:45:08.252779] Test:  [290/345]  eta: 0:00:10  loss: 0.7648 (0.7613)  time: 0.1930  data: 0.0001  max mem: 14938
[15:45:10.189027] Test:  [300/345]  eta: 0:00:08  loss: 0.7637 (0.7612)  time: 0.1934  data: 0.0001  max mem: 14938
[15:45:12.127311] Test:  [310/345]  eta: 0:00:06  loss: 0.7558 (0.7610)  time: 0.1937  data: 0.0001  max mem: 14938
[15:45:14.070458] Test:  [320/345]  eta: 0:00:04  loss: 0.7569 (0.7610)  time: 0.1940  data: 0.0001  max mem: 14938
[15:45:16.015644] Test:  [330/345]  eta: 0:00:02  loss: 0.7596 (0.7609)  time: 0.1944  data: 0.0001  max mem: 14938
[15:45:17.963308] Test:  [340/345]  eta: 0:00:00  loss: 0.7627 (0.7610)  time: 0.1946  data: 0.0001  max mem: 14938
[15:45:18.743747] Test:  [344/345]  eta: 0:00:00  loss: 0.7615 (0.7610)  time: 0.1947  data: 0.0001  max mem: 14938
[15:45:18.801693] Test: Total time: 0:01:05 (0.1899 s / it)
[15:45:29.285031] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8265 (0.8265)  time: 0.3232  data: 0.1439  max mem: 14938
[15:45:31.101252] Test:  [10/57]  eta: 0:00:09  loss: 0.8635 (0.8748)  time: 0.1944  data: 0.0131  max mem: 14938
[15:45:32.921101] Test:  [20/57]  eta: 0:00:06  loss: 0.8826 (0.8674)  time: 0.1817  data: 0.0001  max mem: 14938
[15:45:34.744523] Test:  [30/57]  eta: 0:00:05  loss: 0.7745 (0.8305)  time: 0.1821  data: 0.0001  max mem: 14938
[15:45:36.573551] Test:  [40/57]  eta: 0:00:03  loss: 0.7557 (0.8104)  time: 0.1826  data: 0.0001  max mem: 14938
[15:45:38.405737] Test:  [50/57]  eta: 0:00:01  loss: 0.7528 (0.8029)  time: 0.1830  data: 0.0001  max mem: 14938
[15:45:39.395865] Test:  [56/57]  eta: 0:00:00  loss: 0.7802 (0.8086)  time: 0.1777  data: 0.0001  max mem: 14938
[15:45:39.452387] Test: Total time: 0:00:10 (0.1841 s / it)
[15:45:41.188182] Dice score of the network on the train images: 0.771041, val images: 0.808566
[15:45:41.188407] saving best_prec_model_0 @ epoch 15
[15:45:42.263248] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:45:43.156464] Epoch: [16]  [  0/345]  eta: 0:05:07  lr: 0.000100  loss: 0.7536 (0.7536)  time: 0.8920  data: 0.1508  max mem: 14938
[15:45:58.023121] Epoch: [16]  [ 20/345]  eta: 0:04:03  lr: 0.000100  loss: 0.7858 (0.7865)  time: 0.7433  data: 0.0001  max mem: 14938
[15:46:12.954181] Epoch: [16]  [ 40/345]  eta: 0:03:48  lr: 0.000101  loss: 0.7989 (0.7916)  time: 0.7465  data: 0.0001  max mem: 14938
[15:46:27.914467] Epoch: [16]  [ 60/345]  eta: 0:03:33  lr: 0.000101  loss: 0.7884 (0.7929)  time: 0.7480  data: 0.0001  max mem: 14938
[15:46:42.884389] Epoch: [16]  [ 80/345]  eta: 0:03:18  lr: 0.000101  loss: 0.7935 (0.7932)  time: 0.7485  data: 0.0001  max mem: 14938
[15:46:57.881427] Epoch: [16]  [100/345]  eta: 0:03:03  lr: 0.000102  loss: 0.7835 (0.7923)  time: 0.7498  data: 0.0001  max mem: 14938
[15:47:12.900371] Epoch: [16]  [120/345]  eta: 0:02:48  lr: 0.000102  loss: 0.7863 (0.7914)  time: 0.7509  data: 0.0001  max mem: 14938
[15:47:27.917815] Epoch: [16]  [140/345]  eta: 0:02:33  lr: 0.000103  loss: 0.7838 (0.7904)  time: 0.7508  data: 0.0001  max mem: 14938
[15:47:42.931897] Epoch: [16]  [160/345]  eta: 0:02:18  lr: 0.000103  loss: 0.7888 (0.7908)  time: 0.7507  data: 0.0001  max mem: 14938
[15:47:57.941349] Epoch: [16]  [180/345]  eta: 0:02:03  lr: 0.000103  loss: 0.7864 (0.7907)  time: 0.7504  data: 0.0001  max mem: 14938
[15:48:12.948851] Epoch: [16]  [200/345]  eta: 0:01:48  lr: 0.000104  loss: 0.7956 (0.7914)  time: 0.7503  data: 0.0001  max mem: 14938
[15:48:27.952380] Epoch: [16]  [220/345]  eta: 0:01:33  lr: 0.000104  loss: 0.7934 (0.7920)  time: 0.7501  data: 0.0001  max mem: 14938
[15:48:42.939031] Epoch: [16]  [240/345]  eta: 0:01:18  lr: 0.000104  loss: 0.7849 (0.7917)  time: 0.7493  data: 0.0001  max mem: 14938
[15:48:57.922786] Epoch: [16]  [260/345]  eta: 0:01:03  lr: 0.000105  loss: 0.7994 (0.7919)  time: 0.7491  data: 0.0001  max mem: 14938
[15:49:12.895111] Epoch: [16]  [280/345]  eta: 0:00:48  lr: 0.000105  loss: 0.8050 (0.7932)  time: 0.7486  data: 0.0001  max mem: 14938
[15:49:27.868201] Epoch: [16]  [300/345]  eta: 0:00:33  lr: 0.000105  loss: 0.7978 (0.7937)  time: 0.7486  data: 0.0001  max mem: 14938
[15:49:42.844279] Epoch: [16]  [320/345]  eta: 0:00:18  lr: 0.000106  loss: 0.7884 (0.7935)  time: 0.7488  data: 0.0001  max mem: 14938
[15:49:57.814822] Epoch: [16]  [340/345]  eta: 0:00:03  lr: 0.000106  loss: 0.8010 (0.7939)  time: 0.7485  data: 0.0001  max mem: 14938
[15:50:00.811017] Epoch: [16]  [344/345]  eta: 0:00:00  lr: 0.000106  loss: 0.7918 (0.7938)  time: 0.7483  data: 0.0001  max mem: 14938
[15:50:00.872572] Epoch: [16] Total time: 0:04:18 (0.7496 s / it)
[15:50:00.872805] Averaged stats: lr: 0.000106  loss: 0.7918 (0.7938)
[15:50:01.212047] Test:  [  0/345]  eta: 0:01:55  loss: 0.7514 (0.7514)  time: 0.3355  data: 0.1536  max mem: 14938
[15:50:03.047356] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7722 (0.7678)  time: 0.1973  data: 0.0140  max mem: 14938
[15:50:04.886388] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7668 (0.7681)  time: 0.1837  data: 0.0001  max mem: 14938
[15:50:06.729700] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7653 (0.7675)  time: 0.1841  data: 0.0001  max mem: 14938
[15:50:08.575867] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7653 (0.7675)  time: 0.1844  data: 0.0001  max mem: 14938
[15:50:10.425787] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7678 (0.7669)  time: 0.1848  data: 0.0001  max mem: 14938
[15:50:12.279680] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7615 (0.7668)  time: 0.1851  data: 0.0001  max mem: 14938
[15:50:14.137208] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7588 (0.7657)  time: 0.1855  data: 0.0001  max mem: 14938
[15:50:15.997353] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7585 (0.7657)  time: 0.1858  data: 0.0001  max mem: 14938
[15:50:17.861592] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7585 (0.7651)  time: 0.1862  data: 0.0001  max mem: 14938
[15:50:19.728145] Test:  [100/345]  eta: 0:00:45  loss: 0.7541 (0.7649)  time: 0.1865  data: 0.0001  max mem: 14938
[15:50:21.598223] Test:  [110/345]  eta: 0:00:43  loss: 0.7563 (0.7644)  time: 0.1868  data: 0.0001  max mem: 14938
[15:50:23.472872] Test:  [120/345]  eta: 0:00:42  loss: 0.7602 (0.7640)  time: 0.1872  data: 0.0001  max mem: 14938
[15:50:25.350092] Test:  [130/345]  eta: 0:00:40  loss: 0.7623 (0.7636)  time: 0.1875  data: 0.0001  max mem: 14938
[15:50:27.232584] Test:  [140/345]  eta: 0:00:38  loss: 0.7583 (0.7639)  time: 0.1879  data: 0.0001  max mem: 14938
[15:50:29.116873] Test:  [150/345]  eta: 0:00:36  loss: 0.7642 (0.7652)  time: 0.1883  data: 0.0001  max mem: 14938
[15:50:31.003540] Test:  [160/345]  eta: 0:00:34  loss: 0.7826 (0.7658)  time: 0.1885  data: 0.0001  max mem: 14938
[15:50:32.894008] Test:  [170/345]  eta: 0:00:32  loss: 0.7667 (0.7656)  time: 0.1888  data: 0.0001  max mem: 14938
[15:50:34.789428] Test:  [180/345]  eta: 0:00:30  loss: 0.7630 (0.7654)  time: 0.1892  data: 0.0001  max mem: 14938
[15:50:36.688112] Test:  [190/345]  eta: 0:00:29  loss: 0.7588 (0.7648)  time: 0.1897  data: 0.0001  max mem: 14938
[15:50:38.590645] Test:  [200/345]  eta: 0:00:27  loss: 0.7588 (0.7646)  time: 0.1900  data: 0.0001  max mem: 14938
[15:50:40.495421] Test:  [210/345]  eta: 0:00:25  loss: 0.7605 (0.7644)  time: 0.1903  data: 0.0001  max mem: 14938
[15:50:42.406872] Test:  [220/345]  eta: 0:00:23  loss: 0.7657 (0.7646)  time: 0.1908  data: 0.0001  max mem: 14938
[15:50:44.319335] Test:  [230/345]  eta: 0:00:21  loss: 0.7679 (0.7649)  time: 0.1911  data: 0.0001  max mem: 14938
[15:50:46.237267] Test:  [240/345]  eta: 0:00:19  loss: 0.7654 (0.7647)  time: 0.1915  data: 0.0001  max mem: 14938
[15:50:48.157274] Test:  [250/345]  eta: 0:00:17  loss: 0.7654 (0.7653)  time: 0.1918  data: 0.0001  max mem: 14938
[15:50:50.081140] Test:  [260/345]  eta: 0:00:16  loss: 0.7651 (0.7651)  time: 0.1921  data: 0.0001  max mem: 14938
[15:50:52.007245] Test:  [270/345]  eta: 0:00:14  loss: 0.7602 (0.7649)  time: 0.1924  data: 0.0001  max mem: 14938
[15:50:53.938520] Test:  [280/345]  eta: 0:00:12  loss: 0.7557 (0.7645)  time: 0.1928  data: 0.0001  max mem: 14938
[15:50:55.871121] Test:  [290/345]  eta: 0:00:10  loss: 0.7606 (0.7647)  time: 0.1931  data: 0.0001  max mem: 14938
[15:50:57.806231] Test:  [300/345]  eta: 0:00:08  loss: 0.7703 (0.7650)  time: 0.1933  data: 0.0001  max mem: 14938
[15:50:59.745671] Test:  [310/345]  eta: 0:00:06  loss: 0.7682 (0.7650)  time: 0.1937  data: 0.0001  max mem: 14938
[15:51:01.687820] Test:  [320/345]  eta: 0:00:04  loss: 0.7608 (0.7650)  time: 0.1940  data: 0.0001  max mem: 14938
[15:51:03.635134] Test:  [330/345]  eta: 0:00:02  loss: 0.7608 (0.7650)  time: 0.1944  data: 0.0001  max mem: 14938
[15:51:05.584096] Test:  [340/345]  eta: 0:00:00  loss: 0.7624 (0.7650)  time: 0.1948  data: 0.0001  max mem: 14938
[15:51:06.366444] Test:  [344/345]  eta: 0:00:00  loss: 0.7624 (0.7650)  time: 0.1949  data: 0.0001  max mem: 14938
[15:51:06.427464] Test: Total time: 0:01:05 (0.1900 s / it)
[15:51:16.919461] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8602 (0.8602)  time: 0.3208  data: 0.1410  max mem: 14938
[15:51:18.734593] Test:  [10/57]  eta: 0:00:09  loss: 0.8794 (0.8919)  time: 0.1941  data: 0.0129  max mem: 14938
[15:51:20.554886] Test:  [20/57]  eta: 0:00:06  loss: 0.8710 (0.8728)  time: 0.1817  data: 0.0001  max mem: 14938
[15:51:22.378697] Test:  [30/57]  eta: 0:00:05  loss: 0.7598 (0.8332)  time: 0.1822  data: 0.0001  max mem: 14938
[15:51:24.207526] Test:  [40/57]  eta: 0:00:03  loss: 0.7504 (0.8123)  time: 0.1826  data: 0.0001  max mem: 14938
[15:51:26.042116] Test:  [50/57]  eta: 0:00:01  loss: 0.7500 (0.8069)  time: 0.1831  data: 0.0001  max mem: 14938
[15:51:27.032383] Test:  [56/57]  eta: 0:00:00  loss: 0.7737 (0.8129)  time: 0.1778  data: 0.0001  max mem: 14938
[15:51:27.093002] Test: Total time: 0:00:10 (0.1841 s / it)
[15:51:28.864367] Dice score of the network on the train images: 0.772507, val images: 0.804402
[15:51:28.864585] saving best_prec_model_0 @ epoch 16
[15:51:29.899408] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:51:30.784488] Epoch: [17]  [  0/345]  eta: 0:05:04  lr: 0.000106  loss: 0.7688 (0.7688)  time: 0.8840  data: 0.1438  max mem: 14938
[15:51:45.625516] Epoch: [17]  [ 20/345]  eta: 0:04:03  lr: 0.000107  loss: 0.7864 (0.7866)  time: 0.7420  data: 0.0001  max mem: 14938
[15:52:00.657918] Epoch: [17]  [ 40/345]  eta: 0:03:48  lr: 0.000107  loss: 0.7843 (0.7886)  time: 0.7516  data: 0.0001  max mem: 14938
[15:52:15.613360] Epoch: [17]  [ 60/345]  eta: 0:03:33  lr: 0.000107  loss: 0.7929 (0.7925)  time: 0.7477  data: 0.0001  max mem: 14938
[15:52:30.592403] Epoch: [17]  [ 80/345]  eta: 0:03:18  lr: 0.000108  loss: 0.7959 (0.7939)  time: 0.7489  data: 0.0001  max mem: 14938
[15:52:45.604820] Epoch: [17]  [100/345]  eta: 0:03:03  lr: 0.000108  loss: 0.7892 (0.7931)  time: 0.7506  data: 0.0001  max mem: 14938
[15:53:00.651945] Epoch: [17]  [120/345]  eta: 0:02:48  lr: 0.000108  loss: 0.7966 (0.7932)  time: 0.7523  data: 0.0001  max mem: 14938
[15:53:15.695125] Epoch: [17]  [140/345]  eta: 0:02:33  lr: 0.000109  loss: 0.7868 (0.7924)  time: 0.7521  data: 0.0001  max mem: 14938
[15:53:30.725170] Epoch: [17]  [160/345]  eta: 0:02:18  lr: 0.000109  loss: 0.7865 (0.7920)  time: 0.7515  data: 0.0001  max mem: 14938
[15:53:45.743435] Epoch: [17]  [180/345]  eta: 0:02:03  lr: 0.000110  loss: 0.7948 (0.7926)  time: 0.7509  data: 0.0001  max mem: 14938
[15:54:00.752166] Epoch: [17]  [200/345]  eta: 0:01:48  lr: 0.000110  loss: 0.8017 (0.7933)  time: 0.7504  data: 0.0001  max mem: 14938
[15:54:15.745380] Epoch: [17]  [220/345]  eta: 0:01:33  lr: 0.000110  loss: 0.8307 (0.7978)  time: 0.7496  data: 0.0001  max mem: 14938
[15:54:30.721794] Epoch: [17]  [240/345]  eta: 0:01:18  lr: 0.000111  loss: 0.8443 (0.8016)  time: 0.7488  data: 0.0001  max mem: 14938
[15:54:45.687856] Epoch: [17]  [260/345]  eta: 0:01:03  lr: 0.000111  loss: 0.8208 (0.8028)  time: 0.7483  data: 0.0001  max mem: 14938
[15:55:00.649428] Epoch: [17]  [280/345]  eta: 0:00:48  lr: 0.000111  loss: 0.7933 (0.8020)  time: 0.7480  data: 0.0001  max mem: 14938
[15:55:15.610299] Epoch: [17]  [300/345]  eta: 0:00:33  lr: 0.000112  loss: 0.7874 (0.8015)  time: 0.7480  data: 0.0001  max mem: 14938
[15:55:30.557869] Epoch: [17]  [320/345]  eta: 0:00:18  lr: 0.000112  loss: 0.7818 (0.8005)  time: 0.7473  data: 0.0001  max mem: 14938
[15:55:45.509745] Epoch: [17]  [340/345]  eta: 0:00:03  lr: 0.000112  loss: 0.7843 (0.7998)  time: 0.7476  data: 0.0001  max mem: 14938
[15:55:48.498645] Epoch: [17]  [344/345]  eta: 0:00:00  lr: 0.000112  loss: 0.7851 (0.7997)  time: 0.7474  data: 0.0001  max mem: 14938
[15:55:48.565570] Epoch: [17] Total time: 0:04:18 (0.7498 s / it)
[15:55:48.566058] Averaged stats: lr: 0.000112  loss: 0.7851 (0.7997)
[15:55:48.902297] Test:  [  0/345]  eta: 0:01:54  loss: 0.7570 (0.7570)  time: 0.3329  data: 0.1518  max mem: 14938
[15:55:50.739539] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7536 (0.7523)  time: 0.1972  data: 0.0139  max mem: 14938
[15:55:52.578866] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7432 (0.7454)  time: 0.1838  data: 0.0001  max mem: 14938
[15:55:54.421544] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7432 (0.7505)  time: 0.1840  data: 0.0001  max mem: 14938
[15:55:56.268696] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7578 (0.7507)  time: 0.1844  data: 0.0001  max mem: 14938
[15:55:58.118125] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7627 (0.7545)  time: 0.1848  data: 0.0001  max mem: 14938
[15:55:59.971964] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7622 (0.7535)  time: 0.1851  data: 0.0001  max mem: 14938
[15:56:01.828095] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7484 (0.7536)  time: 0.1854  data: 0.0001  max mem: 14938
[15:56:03.687202] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7523 (0.7537)  time: 0.1857  data: 0.0001  max mem: 14938
[15:56:05.550233] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7539 (0.7541)  time: 0.1860  data: 0.0001  max mem: 14938
[15:56:07.415860] Test:  [100/345]  eta: 0:00:45  loss: 0.7496 (0.7537)  time: 0.1864  data: 0.0001  max mem: 14938
[15:56:09.285520] Test:  [110/345]  eta: 0:00:43  loss: 0.7461 (0.7528)  time: 0.1867  data: 0.0001  max mem: 14938
[15:56:11.159192] Test:  [120/345]  eta: 0:00:41  loss: 0.7543 (0.7534)  time: 0.1871  data: 0.0001  max mem: 14938
[15:56:13.037461] Test:  [130/345]  eta: 0:00:40  loss: 0.7564 (0.7536)  time: 0.1875  data: 0.0001  max mem: 14938
[15:56:14.918636] Test:  [140/345]  eta: 0:00:38  loss: 0.7529 (0.7535)  time: 0.1879  data: 0.0001  max mem: 14938
[15:56:16.803268] Test:  [150/345]  eta: 0:00:36  loss: 0.7494 (0.7532)  time: 0.1882  data: 0.0001  max mem: 14938
[15:56:18.691327] Test:  [160/345]  eta: 0:00:34  loss: 0.7515 (0.7535)  time: 0.1886  data: 0.0001  max mem: 14938
[15:56:20.581447] Test:  [170/345]  eta: 0:00:32  loss: 0.7578 (0.7536)  time: 0.1889  data: 0.0001  max mem: 14938
[15:56:22.476581] Test:  [180/345]  eta: 0:00:30  loss: 0.7540 (0.7539)  time: 0.1892  data: 0.0001  max mem: 14938
[15:56:24.375638] Test:  [190/345]  eta: 0:00:29  loss: 0.7632 (0.7544)  time: 0.1897  data: 0.0001  max mem: 14938
[15:56:26.276695] Test:  [200/345]  eta: 0:00:27  loss: 0.7667 (0.7548)  time: 0.1900  data: 0.0001  max mem: 14938
[15:56:28.182396] Test:  [210/345]  eta: 0:00:25  loss: 0.7663 (0.7551)  time: 0.1903  data: 0.0001  max mem: 14938
[15:56:30.089847] Test:  [220/345]  eta: 0:00:23  loss: 0.7558 (0.7550)  time: 0.1906  data: 0.0001  max mem: 14938
[15:56:32.004258] Test:  [230/345]  eta: 0:00:21  loss: 0.7496 (0.7549)  time: 0.1910  data: 0.0001  max mem: 14938
[15:56:33.923012] Test:  [240/345]  eta: 0:00:19  loss: 0.7487 (0.7548)  time: 0.1916  data: 0.0001  max mem: 14938
[15:56:35.844730] Test:  [250/345]  eta: 0:00:17  loss: 0.7516 (0.7550)  time: 0.1920  data: 0.0001  max mem: 14938
[15:56:37.767935] Test:  [260/345]  eta: 0:00:16  loss: 0.7516 (0.7551)  time: 0.1922  data: 0.0001  max mem: 14938
[15:56:39.693733] Test:  [270/345]  eta: 0:00:14  loss: 0.7605 (0.7553)  time: 0.1924  data: 0.0001  max mem: 14938
[15:56:41.624677] Test:  [280/345]  eta: 0:00:12  loss: 0.7574 (0.7553)  time: 0.1928  data: 0.0001  max mem: 14938
[15:56:43.558173] Test:  [290/345]  eta: 0:00:10  loss: 0.7458 (0.7548)  time: 0.1932  data: 0.0001  max mem: 14938
[15:56:45.494264] Test:  [300/345]  eta: 0:00:08  loss: 0.7484 (0.7551)  time: 0.1934  data: 0.0001  max mem: 14938
[15:56:47.437024] Test:  [310/345]  eta: 0:00:06  loss: 0.7569 (0.7553)  time: 0.1939  data: 0.0001  max mem: 14938
[15:56:49.379819] Test:  [320/345]  eta: 0:00:04  loss: 0.7468 (0.7550)  time: 0.1942  data: 0.0001  max mem: 14938
[15:56:51.326756] Test:  [330/345]  eta: 0:00:02  loss: 0.7420 (0.7546)  time: 0.1944  data: 0.0001  max mem: 14938
[15:56:53.274504] Test:  [340/345]  eta: 0:00:00  loss: 0.7431 (0.7544)  time: 0.1947  data: 0.0001  max mem: 14938
[15:56:54.056239] Test:  [344/345]  eta: 0:00:00  loss: 0.7490 (0.7543)  time: 0.1948  data: 0.0001  max mem: 14938
[15:56:54.117323] Test: Total time: 0:01:05 (0.1900 s / it)
[15:57:04.677959] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8787 (0.8787)  time: 0.3198  data: 0.1403  max mem: 14938
[15:57:06.493194] Test:  [10/57]  eta: 0:00:09  loss: 0.8976 (0.8824)  time: 0.1940  data: 0.0128  max mem: 14938
[15:57:08.313472] Test:  [20/57]  eta: 0:00:06  loss: 0.8991 (0.8752)  time: 0.1817  data: 0.0001  max mem: 14938
[15:57:10.139357] Test:  [30/57]  eta: 0:00:05  loss: 0.7666 (0.8361)  time: 0.1823  data: 0.0001  max mem: 14938
[15:57:11.967966] Test:  [40/57]  eta: 0:00:03  loss: 0.7472 (0.8154)  time: 0.1827  data: 0.0001  max mem: 14938
[15:57:13.801491] Test:  [50/57]  eta: 0:00:01  loss: 0.7498 (0.8094)  time: 0.1831  data: 0.0001  max mem: 14938
[15:57:14.790476] Test:  [56/57]  eta: 0:00:00  loss: 0.7773 (0.8152)  time: 0.1776  data: 0.0001  max mem: 14938
[15:57:14.851927] Test: Total time: 0:00:10 (0.1841 s / it)
[15:57:16.600527] Dice score of the network on the train images: 0.782518, val images: 0.810716
[15:57:16.600747] saving best_prec_model_0 @ epoch 17
[15:57:17.622776] saving best_dice_model_0 @ epoch 17
[15:57:18.630621] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:57:19.517028] Epoch: [18]  [  0/345]  eta: 0:05:05  lr: 0.000113  loss: 0.7776 (0.7776)  time: 0.8852  data: 0.1445  max mem: 14938
[15:57:34.349984] Epoch: [18]  [ 20/345]  eta: 0:04:03  lr: 0.000113  loss: 0.7774 (0.7795)  time: 0.7416  data: 0.0001  max mem: 14938
[15:57:49.241563] Epoch: [18]  [ 40/345]  eta: 0:03:47  lr: 0.000113  loss: 0.7848 (0.7836)  time: 0.7445  data: 0.0001  max mem: 14938
[15:58:04.164020] Epoch: [18]  [ 60/345]  eta: 0:03:32  lr: 0.000114  loss: 0.7804 (0.7832)  time: 0.7461  data: 0.0001  max mem: 14938
[15:58:19.122692] Epoch: [18]  [ 80/345]  eta: 0:03:17  lr: 0.000114  loss: 0.7754 (0.7826)  time: 0.7479  data: 0.0001  max mem: 14938
[15:58:34.117938] Epoch: [18]  [100/345]  eta: 0:03:03  lr: 0.000114  loss: 0.8136 (0.7887)  time: 0.7497  data: 0.0001  max mem: 14938
[15:58:49.135165] Epoch: [18]  [120/345]  eta: 0:02:48  lr: 0.000115  loss: 0.8076 (0.7918)  time: 0.7508  data: 0.0001  max mem: 14938
[15:59:04.147246] Epoch: [18]  [140/345]  eta: 0:02:33  lr: 0.000115  loss: 0.7969 (0.7917)  time: 0.7506  data: 0.0001  max mem: 14938
[15:59:19.148254] Epoch: [18]  [160/345]  eta: 0:02:18  lr: 0.000115  loss: 0.7928 (0.7926)  time: 0.7500  data: 0.0001  max mem: 14938
[15:59:34.136248] Epoch: [18]  [180/345]  eta: 0:02:03  lr: 0.000116  loss: 0.7971 (0.7935)  time: 0.7494  data: 0.0001  max mem: 14938
[15:59:49.117486] Epoch: [18]  [200/345]  eta: 0:01:48  lr: 0.000116  loss: 0.7796 (0.7926)  time: 0.7490  data: 0.0001  max mem: 14938
[16:00:04.082988] Epoch: [18]  [220/345]  eta: 0:01:33  lr: 0.000116  loss: 0.7939 (0.7923)  time: 0.7482  data: 0.0001  max mem: 14938
[16:00:19.053709] Epoch: [18]  [240/345]  eta: 0:01:18  lr: 0.000117  loss: 0.7971 (0.7928)  time: 0.7485  data: 0.0001  max mem: 14938
[16:00:34.009844] Epoch: [18]  [260/345]  eta: 0:01:03  lr: 0.000117  loss: 0.7868 (0.7924)  time: 0.7478  data: 0.0001  max mem: 14938
[16:00:48.967131] Epoch: [18]  [280/345]  eta: 0:00:48  lr: 0.000118  loss: 0.7798 (0.7920)  time: 0.7478  data: 0.0001  max mem: 14938
[16:01:03.922897] Epoch: [18]  [300/345]  eta: 0:00:33  lr: 0.000118  loss: 0.7810 (0.7913)  time: 0.7478  data: 0.0001  max mem: 14938
[16:01:18.883877] Epoch: [18]  [320/345]  eta: 0:00:18  lr: 0.000118  loss: 0.7816 (0.7907)  time: 0.7480  data: 0.0001  max mem: 14938
[16:01:33.831426] Epoch: [18]  [340/345]  eta: 0:00:03  lr: 0.000119  loss: 0.7845 (0.7902)  time: 0.7473  data: 0.0001  max mem: 14938
[16:01:36.823981] Epoch: [18]  [344/345]  eta: 0:00:00  lr: 0.000119  loss: 0.7845 (0.7901)  time: 0.7474  data: 0.0001  max mem: 14938
[16:01:36.889577] Epoch: [18] Total time: 0:04:18 (0.7486 s / it)
[16:01:36.889971] Averaged stats: lr: 0.000119  loss: 0.7845 (0.7901)
[16:01:37.231271] Test:  [  0/345]  eta: 0:01:56  loss: 0.7494 (0.7494)  time: 0.3381  data: 0.1567  max mem: 14938
[16:01:39.066432] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7454 (0.7437)  time: 0.1975  data: 0.0143  max mem: 14938
[16:01:40.905519] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7510 (0.7538)  time: 0.1836  data: 0.0001  max mem: 14938
[16:01:42.747939] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7525 (0.7530)  time: 0.1840  data: 0.0001  max mem: 14938
[16:01:44.593451] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7490 (0.7507)  time: 0.1843  data: 0.0001  max mem: 14938
[16:01:46.445597] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7508 (0.7517)  time: 0.1847  data: 0.0001  max mem: 14938
[16:01:48.298692] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7489 (0.7515)  time: 0.1851  data: 0.0001  max mem: 14938
[16:01:50.155073] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7405 (0.7495)  time: 0.1854  data: 0.0001  max mem: 14938
[16:01:52.013290] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7388 (0.7494)  time: 0.1857  data: 0.0001  max mem: 14938
[16:01:53.877007] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7460 (0.7493)  time: 0.1860  data: 0.0001  max mem: 14938
[16:01:55.742855] Test:  [100/345]  eta: 0:00:45  loss: 0.7450 (0.7490)  time: 0.1864  data: 0.0001  max mem: 14938
[16:01:57.613954] Test:  [110/345]  eta: 0:00:43  loss: 0.7458 (0.7492)  time: 0.1868  data: 0.0001  max mem: 14938
[16:01:59.488410] Test:  [120/345]  eta: 0:00:42  loss: 0.7362 (0.7488)  time: 0.1872  data: 0.0001  max mem: 14938
[16:02:01.365675] Test:  [130/345]  eta: 0:00:40  loss: 0.7495 (0.7491)  time: 0.1875  data: 0.0001  max mem: 14938
[16:02:03.246816] Test:  [140/345]  eta: 0:00:38  loss: 0.7532 (0.7486)  time: 0.1879  data: 0.0001  max mem: 14938
[16:02:05.130956] Test:  [150/345]  eta: 0:00:36  loss: 0.7378 (0.7483)  time: 0.1882  data: 0.0001  max mem: 14938
[16:02:07.018319] Test:  [160/345]  eta: 0:00:34  loss: 0.7448 (0.7487)  time: 0.1885  data: 0.0001  max mem: 14938
[16:02:08.908891] Test:  [170/345]  eta: 0:00:32  loss: 0.7456 (0.7490)  time: 0.1888  data: 0.0001  max mem: 14938
[16:02:10.805702] Test:  [180/345]  eta: 0:00:30  loss: 0.7517 (0.7495)  time: 0.1893  data: 0.0001  max mem: 14938
[16:02:12.705562] Test:  [190/345]  eta: 0:00:29  loss: 0.7551 (0.7495)  time: 0.1898  data: 0.0001  max mem: 14938
[16:02:14.609916] Test:  [200/345]  eta: 0:00:27  loss: 0.7485 (0.7496)  time: 0.1902  data: 0.0001  max mem: 14938
[16:02:16.514735] Test:  [210/345]  eta: 0:00:25  loss: 0.7436 (0.7495)  time: 0.1904  data: 0.0001  max mem: 14938
[16:02:18.424031] Test:  [220/345]  eta: 0:00:23  loss: 0.7433 (0.7492)  time: 0.1907  data: 0.0001  max mem: 14938
[16:02:20.338814] Test:  [230/345]  eta: 0:00:21  loss: 0.7464 (0.7492)  time: 0.1912  data: 0.0001  max mem: 14938
[16:02:22.254744] Test:  [240/345]  eta: 0:00:19  loss: 0.7485 (0.7491)  time: 0.1915  data: 0.0001  max mem: 14938
[16:02:24.175538] Test:  [250/345]  eta: 0:00:17  loss: 0.7446 (0.7488)  time: 0.1918  data: 0.0001  max mem: 14938
[16:02:26.098413] Test:  [260/345]  eta: 0:00:16  loss: 0.7446 (0.7495)  time: 0.1921  data: 0.0001  max mem: 14938
[16:02:28.025189] Test:  [270/345]  eta: 0:00:14  loss: 0.7558 (0.7495)  time: 0.1924  data: 0.0001  max mem: 14938
[16:02:29.956883] Test:  [280/345]  eta: 0:00:12  loss: 0.7455 (0.7495)  time: 0.1929  data: 0.0001  max mem: 14938
[16:02:31.891616] Test:  [290/345]  eta: 0:00:10  loss: 0.7524 (0.7500)  time: 0.1933  data: 0.0001  max mem: 14938
[16:02:33.829064] Test:  [300/345]  eta: 0:00:08  loss: 0.7501 (0.7498)  time: 0.1936  data: 0.0001  max mem: 14938
[16:02:35.769149] Test:  [310/345]  eta: 0:00:06  loss: 0.7487 (0.7496)  time: 0.1938  data: 0.0001  max mem: 14938
[16:02:37.712045] Test:  [320/345]  eta: 0:00:04  loss: 0.7515 (0.7497)  time: 0.1941  data: 0.0001  max mem: 14938
[16:02:39.658951] Test:  [330/345]  eta: 0:00:02  loss: 0.7518 (0.7497)  time: 0.1944  data: 0.0001  max mem: 14938
[16:02:41.610831] Test:  [340/345]  eta: 0:00:00  loss: 0.7462 (0.7495)  time: 0.1949  data: 0.0001  max mem: 14938
[16:02:42.393382] Test:  [344/345]  eta: 0:00:00  loss: 0.7441 (0.7494)  time: 0.1951  data: 0.0001  max mem: 14938
[16:02:42.454017] Test: Total time: 0:01:05 (0.1900 s / it)
[16:02:52.904708] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8384 (0.8384)  time: 0.3188  data: 0.1397  max mem: 14938
[16:02:54.721245] Test:  [10/57]  eta: 0:00:09  loss: 0.8658 (0.8692)  time: 0.1940  data: 0.0128  max mem: 14938
[16:02:56.542101] Test:  [20/57]  eta: 0:00:06  loss: 0.8769 (0.8591)  time: 0.1818  data: 0.0001  max mem: 14938
[16:02:58.366914] Test:  [30/57]  eta: 0:00:05  loss: 0.7640 (0.8223)  time: 0.1822  data: 0.0001  max mem: 14938
[16:03:00.195592] Test:  [40/57]  eta: 0:00:03  loss: 0.7446 (0.8034)  time: 0.1826  data: 0.0001  max mem: 14938
[16:03:02.028153] Test:  [50/57]  eta: 0:00:01  loss: 0.7501 (0.7974)  time: 0.1830  data: 0.0001  max mem: 14938
[16:03:03.017220] Test:  [56/57]  eta: 0:00:00  loss: 0.7719 (0.8038)  time: 0.1776  data: 0.0001  max mem: 14938
[16:03:03.075906] Test: Total time: 0:00:10 (0.1840 s / it)
[16:03:04.844350] Dice score of the network on the train images: 0.773119, val images: 0.814302
[16:03:04.844577] saving best_dice_model_0 @ epoch 18
[16:03:05.907644] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:03:06.792715] Epoch: [19]  [  0/345]  eta: 0:05:05  lr: 0.000119  loss: 0.7728 (0.7728)  time: 0.8841  data: 0.1423  max mem: 14938
[16:03:21.633674] Epoch: [19]  [ 20/345]  eta: 0:04:03  lr: 0.000119  loss: 0.7686 (0.7720)  time: 0.7420  data: 0.0001  max mem: 14938
[16:03:36.534164] Epoch: [19]  [ 40/345]  eta: 0:03:47  lr: 0.000119  loss: 0.7699 (0.7739)  time: 0.7450  data: 0.0001  max mem: 14938
[16:03:51.465907] Epoch: [19]  [ 60/345]  eta: 0:03:32  lr: 0.000120  loss: 0.7690 (0.7745)  time: 0.7465  data: 0.0001  max mem: 14938
[16:04:06.414940] Epoch: [19]  [ 80/345]  eta: 0:03:17  lr: 0.000120  loss: 0.7716 (0.7749)  time: 0.7474  data: 0.0001  max mem: 14938
[16:04:21.398633] Epoch: [19]  [100/345]  eta: 0:03:03  lr: 0.000121  loss: 0.7789 (0.7760)  time: 0.7491  data: 0.0001  max mem: 14938
[16:04:36.405422] Epoch: [19]  [120/345]  eta: 0:02:48  lr: 0.000121  loss: 0.7795 (0.7769)  time: 0.7503  data: 0.0001  max mem: 14938
[16:04:51.539729] Epoch: [19]  [140/345]  eta: 0:02:33  lr: 0.000121  loss: 0.7791 (0.7775)  time: 0.7567  data: 0.0001  max mem: 14938
[16:05:06.549516] Epoch: [19]  [160/345]  eta: 0:02:18  lr: 0.000122  loss: 0.7821 (0.7780)  time: 0.7505  data: 0.0001  max mem: 14938
[16:05:21.550238] Epoch: [19]  [180/345]  eta: 0:02:03  lr: 0.000122  loss: 0.7748 (0.7782)  time: 0.7500  data: 0.0001  max mem: 14938
[16:05:36.539254] Epoch: [19]  [200/345]  eta: 0:01:48  lr: 0.000122  loss: 0.7706 (0.7778)  time: 0.7494  data: 0.0001  max mem: 14938
[16:05:51.522176] Epoch: [19]  [220/345]  eta: 0:01:33  lr: 0.000123  loss: 0.7859 (0.7787)  time: 0.7491  data: 0.0001  max mem: 14938
[16:06:06.498184] Epoch: [19]  [240/345]  eta: 0:01:18  lr: 0.000123  loss: 0.7850 (0.7793)  time: 0.7488  data: 0.0001  max mem: 14938
[16:06:21.478962] Epoch: [19]  [260/345]  eta: 0:01:03  lr: 0.000123  loss: 0.7866 (0.7796)  time: 0.7490  data: 0.0001  max mem: 14938
[16:06:36.444031] Epoch: [19]  [280/345]  eta: 0:00:48  lr: 0.000124  loss: 0.7741 (0.7793)  time: 0.7482  data: 0.0001  max mem: 14938
[16:06:51.409275] Epoch: [19]  [300/345]  eta: 0:00:33  lr: 0.000124  loss: 0.7762 (0.7794)  time: 0.7482  data: 0.0001  max mem: 14938
[16:07:06.369504] Epoch: [19]  [320/345]  eta: 0:00:18  lr: 0.000125  loss: 0.7700 (0.7790)  time: 0.7480  data: 0.0001  max mem: 14938
[16:07:21.332074] Epoch: [19]  [340/345]  eta: 0:00:03  lr: 0.000125  loss: 0.7662 (0.7785)  time: 0.7481  data: 0.0001  max mem: 14938
[16:07:24.323163] Epoch: [19]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.7626 (0.7784)  time: 0.7479  data: 0.0001  max mem: 14938
[16:07:24.389558] Epoch: [19] Total time: 0:04:18 (0.7492 s / it)
[16:07:24.389949] Averaged stats: lr: 0.000125  loss: 0.7626 (0.7784)
[16:07:24.733701] Test:  [  0/345]  eta: 0:01:57  loss: 0.7388 (0.7388)  time: 0.3405  data: 0.1591  max mem: 14938
[16:07:26.571073] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7388 (0.7376)  time: 0.1979  data: 0.0145  max mem: 14938
[16:07:28.410471] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7423 (0.7401)  time: 0.1838  data: 0.0001  max mem: 14938
[16:07:30.252820] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7414 (0.7385)  time: 0.1840  data: 0.0001  max mem: 14938
[16:07:32.099409] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7414 (0.7415)  time: 0.1844  data: 0.0001  max mem: 14938
[16:07:33.949400] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7393 (0.7409)  time: 0.1848  data: 0.0001  max mem: 14938
[16:07:35.804089] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7376 (0.7412)  time: 0.1852  data: 0.0001  max mem: 14938
[16:07:37.659775] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7376 (0.7404)  time: 0.1855  data: 0.0001  max mem: 14938
[16:07:39.520503] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7445 (0.7411)  time: 0.1858  data: 0.0001  max mem: 14938
[16:07:41.382487] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7480 (0.7415)  time: 0.1861  data: 0.0001  max mem: 14938
[16:07:43.248125] Test:  [100/345]  eta: 0:00:45  loss: 0.7416 (0.7414)  time: 0.1863  data: 0.0001  max mem: 14938
[16:07:45.117456] Test:  [110/345]  eta: 0:00:43  loss: 0.7415 (0.7412)  time: 0.1867  data: 0.0001  max mem: 14938
[16:07:46.991567] Test:  [120/345]  eta: 0:00:42  loss: 0.7361 (0.7410)  time: 0.1871  data: 0.0001  max mem: 14938
[16:07:48.869485] Test:  [130/345]  eta: 0:00:40  loss: 0.7361 (0.7411)  time: 0.1876  data: 0.0001  max mem: 14938
[16:07:50.751236] Test:  [140/345]  eta: 0:00:38  loss: 0.7483 (0.7417)  time: 0.1879  data: 0.0001  max mem: 14938
[16:07:52.636226] Test:  [150/345]  eta: 0:00:36  loss: 0.7502 (0.7420)  time: 0.1883  data: 0.0001  max mem: 14938
[16:07:54.523597] Test:  [160/345]  eta: 0:00:34  loss: 0.7497 (0.7423)  time: 0.1886  data: 0.0001  max mem: 14938
[16:07:56.415393] Test:  [170/345]  eta: 0:00:32  loss: 0.7374 (0.7422)  time: 0.1889  data: 0.0001  max mem: 14938
[16:07:58.312458] Test:  [180/345]  eta: 0:00:30  loss: 0.7329 (0.7417)  time: 0.1894  data: 0.0001  max mem: 14938
[16:08:00.211512] Test:  [190/345]  eta: 0:00:29  loss: 0.7414 (0.7418)  time: 0.1898  data: 0.0001  max mem: 14938
[16:08:02.114834] Test:  [200/345]  eta: 0:00:27  loss: 0.7444 (0.7421)  time: 0.1901  data: 0.0001  max mem: 14938
[16:08:04.019505] Test:  [210/345]  eta: 0:00:25  loss: 0.7395 (0.7417)  time: 0.1903  data: 0.0001  max mem: 14938
[16:08:05.927725] Test:  [220/345]  eta: 0:00:23  loss: 0.7379 (0.7418)  time: 0.1906  data: 0.0001  max mem: 14938
[16:08:07.841037] Test:  [230/345]  eta: 0:00:21  loss: 0.7440 (0.7419)  time: 0.1910  data: 0.0001  max mem: 14938
[16:08:09.756938] Test:  [240/345]  eta: 0:00:19  loss: 0.7371 (0.7421)  time: 0.1914  data: 0.0001  max mem: 14938
[16:08:11.676650] Test:  [250/345]  eta: 0:00:17  loss: 0.7409 (0.7422)  time: 0.1917  data: 0.0001  max mem: 14938
[16:08:13.599997] Test:  [260/345]  eta: 0:00:16  loss: 0.7409 (0.7419)  time: 0.1921  data: 0.0001  max mem: 14938
[16:08:15.527297] Test:  [270/345]  eta: 0:00:14  loss: 0.7481 (0.7420)  time: 0.1925  data: 0.0001  max mem: 14938
[16:08:17.459927] Test:  [280/345]  eta: 0:00:12  loss: 0.7482 (0.7423)  time: 0.1929  data: 0.0001  max mem: 14938
[16:08:19.395565] Test:  [290/345]  eta: 0:00:10  loss: 0.7433 (0.7423)  time: 0.1934  data: 0.0001  max mem: 14938
[16:08:21.334237] Test:  [300/345]  eta: 0:00:08  loss: 0.7406 (0.7425)  time: 0.1937  data: 0.0001  max mem: 14938
[16:08:23.273295] Test:  [310/345]  eta: 0:00:06  loss: 0.7409 (0.7427)  time: 0.1938  data: 0.0001  max mem: 14938
[16:08:25.216864] Test:  [320/345]  eta: 0:00:04  loss: 0.7382 (0.7426)  time: 0.1941  data: 0.0001  max mem: 14938
[16:08:27.163696] Test:  [330/345]  eta: 0:00:02  loss: 0.7330 (0.7423)  time: 0.1945  data: 0.0001  max mem: 14938
[16:08:29.114058] Test:  [340/345]  eta: 0:00:00  loss: 0.7347 (0.7425)  time: 0.1948  data: 0.0001  max mem: 14938
[16:08:29.895815] Test:  [344/345]  eta: 0:00:00  loss: 0.7330 (0.7424)  time: 0.1950  data: 0.0001  max mem: 14938
[16:08:29.956733] Test: Total time: 0:01:05 (0.1900 s / it)
[16:08:40.437743] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8632 (0.8632)  time: 0.3225  data: 0.1427  max mem: 14938
[16:08:42.252256] Test:  [10/57]  eta: 0:00:09  loss: 0.8632 (0.8714)  time: 0.1942  data: 0.0130  max mem: 14938
[16:08:44.072630] Test:  [20/57]  eta: 0:00:06  loss: 0.8816 (0.8635)  time: 0.1817  data: 0.0001  max mem: 14938
[16:08:45.899231] Test:  [30/57]  eta: 0:00:05  loss: 0.7645 (0.8253)  time: 0.1823  data: 0.0001  max mem: 14938
[16:08:47.726435] Test:  [40/57]  eta: 0:00:03  loss: 0.7469 (0.8068)  time: 0.1826  data: 0.0001  max mem: 14938
[16:08:49.562635] Test:  [50/57]  eta: 0:00:01  loss: 0.7538 (0.8029)  time: 0.1831  data: 0.0001  max mem: 14938
[16:08:50.552419] Test:  [56/57]  eta: 0:00:00  loss: 0.7699 (0.8076)  time: 0.1778  data: 0.0001  max mem: 14938
[16:08:50.611733] Test: Total time: 0:00:10 (0.1842 s / it)
[16:08:52.360182] Dice score of the network on the train images: 0.775506, val images: 0.804364
[16:08:52.363815] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:08:53.250660] Epoch: [20]  [  0/345]  eta: 0:05:05  lr: 0.000125  loss: 0.7521 (0.7521)  time: 0.8861  data: 0.1443  max mem: 14938
[16:09:08.106505] Epoch: [20]  [ 20/345]  eta: 0:04:03  lr: 0.000125  loss: 0.7563 (0.7600)  time: 0.7427  data: 0.0001  max mem: 14938
[16:09:23.048397] Epoch: [20]  [ 40/345]  eta: 0:03:48  lr: 0.000125  loss: 0.7931 (0.7773)  time: 0.7471  data: 0.0001  max mem: 14938
[16:09:38.003812] Epoch: [20]  [ 60/345]  eta: 0:03:33  lr: 0.000125  loss: 0.7742 (0.7792)  time: 0.7477  data: 0.0001  max mem: 14938
[16:09:52.990736] Epoch: [20]  [ 80/345]  eta: 0:03:18  lr: 0.000125  loss: 0.7753 (0.7783)  time: 0.7493  data: 0.0001  max mem: 14938
[16:10:08.000852] Epoch: [20]  [100/345]  eta: 0:03:03  lr: 0.000125  loss: 0.7668 (0.7766)  time: 0.7505  data: 0.0001  max mem: 14938
[16:10:23.039955] Epoch: [20]  [120/345]  eta: 0:02:48  lr: 0.000125  loss: 0.7716 (0.7767)  time: 0.7519  data: 0.0001  max mem: 14938
[16:10:38.067366] Epoch: [20]  [140/345]  eta: 0:02:33  lr: 0.000125  loss: 0.7839 (0.7783)  time: 0.7513  data: 0.0001  max mem: 14938
[16:10:53.072249] Epoch: [20]  [160/345]  eta: 0:02:18  lr: 0.000125  loss: 0.7813 (0.7789)  time: 0.7502  data: 0.0001  max mem: 14938
[16:11:08.087123] Epoch: [20]  [180/345]  eta: 0:02:03  lr: 0.000125  loss: 0.7705 (0.7783)  time: 0.7507  data: 0.0001  max mem: 14938
[16:11:23.081361] Epoch: [20]  [200/345]  eta: 0:01:48  lr: 0.000125  loss: 0.7730 (0.7777)  time: 0.7497  data: 0.0001  max mem: 14938
[16:11:38.072707] Epoch: [20]  [220/345]  eta: 0:01:33  lr: 0.000125  loss: 0.7758 (0.7775)  time: 0.7495  data: 0.0001  max mem: 14938
[16:11:53.054314] Epoch: [20]  [240/345]  eta: 0:01:18  lr: 0.000125  loss: 0.7740 (0.7773)  time: 0.7490  data: 0.0001  max mem: 14938
[16:12:08.110924] Epoch: [20]  [260/345]  eta: 0:01:03  lr: 0.000125  loss: 0.7738 (0.7770)  time: 0.7528  data: 0.0001  max mem: 14938
[16:12:23.077884] Epoch: [20]  [280/345]  eta: 0:00:48  lr: 0.000125  loss: 0.7723 (0.7768)  time: 0.7483  data: 0.0001  max mem: 14938
[16:12:38.046310] Epoch: [20]  [300/345]  eta: 0:00:33  lr: 0.000125  loss: 0.7752 (0.7771)  time: 0.7484  data: 0.0001  max mem: 14938
[16:12:53.012415] Epoch: [20]  [320/345]  eta: 0:00:18  lr: 0.000125  loss: 0.7743 (0.7770)  time: 0.7483  data: 0.0001  max mem: 14938
[16:13:07.971510] Epoch: [20]  [340/345]  eta: 0:00:03  lr: 0.000125  loss: 0.7741 (0.7769)  time: 0.7479  data: 0.0001  max mem: 14938
[16:13:10.966093] Epoch: [20]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.7787 (0.7769)  time: 0.7481  data: 0.0001  max mem: 14938
[16:13:11.033411] Epoch: [20] Total time: 0:04:18 (0.7498 s / it)
[16:13:11.034011] Averaged stats: lr: 0.000125  loss: 0.7787 (0.7769)
[16:13:11.378933] Test:  [  0/345]  eta: 0:01:57  loss: 0.7572 (0.7572)  time: 0.3413  data: 0.1599  max mem: 14938
[16:13:13.216254] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7456 (0.7443)  time: 0.1980  data: 0.0146  max mem: 14938
[16:13:15.056664] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7388 (0.7391)  time: 0.1838  data: 0.0001  max mem: 14938
[16:13:16.899809] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7388 (0.7416)  time: 0.1841  data: 0.0001  max mem: 14938
[16:13:18.746261] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7434 (0.7413)  time: 0.1844  data: 0.0001  max mem: 14938
[16:13:20.596372] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7397 (0.7419)  time: 0.1848  data: 0.0001  max mem: 14938
[16:13:22.451021] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7405 (0.7437)  time: 0.1852  data: 0.0001  max mem: 14938
[16:13:24.308426] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7423 (0.7442)  time: 0.1856  data: 0.0001  max mem: 14938
[16:13:26.169502] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7423 (0.7437)  time: 0.1859  data: 0.0001  max mem: 14938
[16:13:28.032812] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7453 (0.7447)  time: 0.1862  data: 0.0001  max mem: 14938
[16:13:29.898715] Test:  [100/345]  eta: 0:00:45  loss: 0.7436 (0.7442)  time: 0.1864  data: 0.0001  max mem: 14938
[16:13:31.769929] Test:  [110/345]  eta: 0:00:43  loss: 0.7436 (0.7445)  time: 0.1868  data: 0.0001  max mem: 14938
[16:13:33.642463] Test:  [120/345]  eta: 0:00:42  loss: 0.7471 (0.7448)  time: 0.1871  data: 0.0001  max mem: 14938
[16:13:35.519658] Test:  [130/345]  eta: 0:00:40  loss: 0.7461 (0.7454)  time: 0.1874  data: 0.0001  max mem: 14938
[16:13:37.401831] Test:  [140/345]  eta: 0:00:38  loss: 0.7440 (0.7456)  time: 0.1879  data: 0.0001  max mem: 14938
[16:13:39.286026] Test:  [150/345]  eta: 0:00:36  loss: 0.7459 (0.7460)  time: 0.1883  data: 0.0001  max mem: 14938
[16:13:41.173851] Test:  [160/345]  eta: 0:00:34  loss: 0.7438 (0.7456)  time: 0.1886  data: 0.0001  max mem: 14938
[16:13:43.064733] Test:  [170/345]  eta: 0:00:32  loss: 0.7383 (0.7454)  time: 0.1889  data: 0.0001  max mem: 14938
[16:13:44.964025] Test:  [180/345]  eta: 0:00:30  loss: 0.7393 (0.7451)  time: 0.1895  data: 0.0001  max mem: 14938
[16:13:46.865514] Test:  [190/345]  eta: 0:00:29  loss: 0.7338 (0.7446)  time: 0.1900  data: 0.0001  max mem: 14938
[16:13:48.767882] Test:  [200/345]  eta: 0:00:27  loss: 0.7338 (0.7445)  time: 0.1901  data: 0.0001  max mem: 14938
[16:13:50.672986] Test:  [210/345]  eta: 0:00:25  loss: 0.7481 (0.7452)  time: 0.1903  data: 0.0001  max mem: 14938
[16:13:52.581142] Test:  [220/345]  eta: 0:00:23  loss: 0.7468 (0.7450)  time: 0.1906  data: 0.0001  max mem: 14938
[16:13:54.494130] Test:  [230/345]  eta: 0:00:21  loss: 0.7421 (0.7451)  time: 0.1910  data: 0.0001  max mem: 14938
[16:13:56.410005] Test:  [240/345]  eta: 0:00:19  loss: 0.7421 (0.7452)  time: 0.1914  data: 0.0001  max mem: 14938
[16:13:58.330257] Test:  [250/345]  eta: 0:00:17  loss: 0.7426 (0.7452)  time: 0.1917  data: 0.0001  max mem: 14938
[16:14:00.254019] Test:  [260/345]  eta: 0:00:16  loss: 0.7389 (0.7450)  time: 0.1922  data: 0.0001  max mem: 14938
[16:14:02.181287] Test:  [270/345]  eta: 0:00:14  loss: 0.7389 (0.7454)  time: 0.1925  data: 0.0001  max mem: 14938
[16:14:04.111850] Test:  [280/345]  eta: 0:00:12  loss: 0.7459 (0.7456)  time: 0.1928  data: 0.0001  max mem: 14938
[16:14:06.045458] Test:  [290/345]  eta: 0:00:10  loss: 0.7448 (0.7457)  time: 0.1932  data: 0.0001  max mem: 14938
[16:14:07.982050] Test:  [300/345]  eta: 0:00:08  loss: 0.7385 (0.7455)  time: 0.1935  data: 0.0001  max mem: 14938
[16:14:09.922299] Test:  [310/345]  eta: 0:00:06  loss: 0.7403 (0.7454)  time: 0.1938  data: 0.0001  max mem: 14938
[16:14:11.866309] Test:  [320/345]  eta: 0:00:04  loss: 0.7451 (0.7457)  time: 0.1942  data: 0.0001  max mem: 14938
[16:14:13.813450] Test:  [330/345]  eta: 0:00:02  loss: 0.7505 (0.7458)  time: 0.1945  data: 0.0001  max mem: 14938
[16:14:15.762757] Test:  [340/345]  eta: 0:00:00  loss: 0.7499 (0.7460)  time: 0.1948  data: 0.0001  max mem: 14938
[16:14:16.544241] Test:  [344/345]  eta: 0:00:00  loss: 0.7499 (0.7461)  time: 0.1949  data: 0.0001  max mem: 14938
[16:14:16.605165] Test: Total time: 0:01:05 (0.1901 s / it)
[16:14:27.082815] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8729 (0.8729)  time: 0.3225  data: 0.1431  max mem: 14938
[16:14:28.899792] Test:  [10/57]  eta: 0:00:09  loss: 0.8855 (0.9019)  time: 0.1944  data: 0.0131  max mem: 14938
[16:14:30.719896] Test:  [20/57]  eta: 0:00:06  loss: 0.9076 (0.8893)  time: 0.1818  data: 0.0001  max mem: 14938
[16:14:32.548085] Test:  [30/57]  eta: 0:00:05  loss: 0.7789 (0.8498)  time: 0.1824  data: 0.0001  max mem: 14938
[16:14:34.376880] Test:  [40/57]  eta: 0:00:03  loss: 0.7556 (0.8285)  time: 0.1828  data: 0.0001  max mem: 14938
[16:14:36.211837] Test:  [50/57]  eta: 0:00:01  loss: 0.7632 (0.8260)  time: 0.1831  data: 0.0001  max mem: 14938
[16:14:37.201368] Test:  [56/57]  eta: 0:00:00  loss: 0.8107 (0.8305)  time: 0.1778  data: 0.0001  max mem: 14938
[16:14:37.261132] Test: Total time: 0:00:10 (0.1842 s / it)
[16:14:39.035085] Dice score of the network on the train images: 0.790016, val images: 0.770873
[16:14:39.035333] saving best_prec_model_0 @ epoch 20
[16:14:40.098759] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:14:40.988550] Epoch: [21]  [  0/345]  eta: 0:05:06  lr: 0.000125  loss: 0.7960 (0.7960)  time: 0.8889  data: 0.1492  max mem: 14938
[16:14:55.839655] Epoch: [21]  [ 20/345]  eta: 0:04:03  lr: 0.000125  loss: 0.7671 (0.7700)  time: 0.7425  data: 0.0001  max mem: 14938
[16:15:10.742734] Epoch: [21]  [ 40/345]  eta: 0:03:47  lr: 0.000125  loss: 0.7636 (0.7692)  time: 0.7451  data: 0.0001  max mem: 14938
[16:15:25.684973] Epoch: [21]  [ 60/345]  eta: 0:03:32  lr: 0.000125  loss: 0.7660 (0.7689)  time: 0.7471  data: 0.0001  max mem: 14938
[16:15:40.650252] Epoch: [21]  [ 80/345]  eta: 0:03:18  lr: 0.000124  loss: 0.7789 (0.7707)  time: 0.7482  data: 0.0001  max mem: 14938
[16:15:55.652781] Epoch: [21]  [100/345]  eta: 0:03:03  lr: 0.000124  loss: 0.7656 (0.7703)  time: 0.7501  data: 0.0001  max mem: 14938
[16:16:10.681644] Epoch: [21]  [120/345]  eta: 0:02:48  lr: 0.000124  loss: 0.7636 (0.7691)  time: 0.7514  data: 0.0001  max mem: 14938
[16:16:25.697123] Epoch: [21]  [140/345]  eta: 0:02:33  lr: 0.000124  loss: 0.7679 (0.7683)  time: 0.7507  data: 0.0001  max mem: 14938
[16:16:40.834194] Epoch: [21]  [160/345]  eta: 0:02:18  lr: 0.000124  loss: 0.7656 (0.7682)  time: 0.7568  data: 0.0001  max mem: 14938
[16:16:55.840955] Epoch: [21]  [180/345]  eta: 0:02:03  lr: 0.000124  loss: 0.7712 (0.7687)  time: 0.7503  data: 0.0001  max mem: 14938
[16:17:10.835961] Epoch: [21]  [200/345]  eta: 0:01:48  lr: 0.000124  loss: 0.7635 (0.7684)  time: 0.7497  data: 0.0001  max mem: 14938
[16:17:25.824707] Epoch: [21]  [220/345]  eta: 0:01:33  lr: 0.000124  loss: 0.7584 (0.7676)  time: 0.7494  data: 0.0001  max mem: 14938
[16:17:40.810282] Epoch: [21]  [240/345]  eta: 0:01:18  lr: 0.000124  loss: 0.7550 (0.7675)  time: 0.7492  data: 0.0001  max mem: 14938
[16:17:55.790434] Epoch: [21]  [260/345]  eta: 0:01:03  lr: 0.000124  loss: 0.7611 (0.7673)  time: 0.7490  data: 0.0001  max mem: 14938
[16:18:10.766422] Epoch: [21]  [280/345]  eta: 0:00:48  lr: 0.000124  loss: 0.7634 (0.7671)  time: 0.7488  data: 0.0001  max mem: 14938
[16:18:25.739444] Epoch: [21]  [300/345]  eta: 0:00:33  lr: 0.000124  loss: 0.7859 (0.7682)  time: 0.7486  data: 0.0001  max mem: 14938
[16:18:40.707408] Epoch: [21]  [320/345]  eta: 0:00:18  lr: 0.000124  loss: 0.7801 (0.7693)  time: 0.7484  data: 0.0001  max mem: 14938
[16:18:55.678122] Epoch: [21]  [340/345]  eta: 0:00:03  lr: 0.000124  loss: 0.7779 (0.7699)  time: 0.7485  data: 0.0001  max mem: 14938
[16:18:58.675039] Epoch: [21]  [344/345]  eta: 0:00:00  lr: 0.000124  loss: 0.7770 (0.7700)  time: 0.7487  data: 0.0001  max mem: 14938
[16:18:58.740124] Epoch: [21] Total time: 0:04:18 (0.7497 s / it)
[16:18:58.740579] Averaged stats: lr: 0.000124  loss: 0.7770 (0.7700)
[16:18:59.087962] Test:  [  0/345]  eta: 0:01:58  loss: 0.7212 (0.7212)  time: 0.3433  data: 0.1613  max mem: 14938
[16:19:00.924090] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7297 (0.7343)  time: 0.1981  data: 0.0147  max mem: 14938
[16:19:02.764832] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7344 (0.7361)  time: 0.1838  data: 0.0001  max mem: 14938
[16:19:04.607453] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7398 (0.7399)  time: 0.1841  data: 0.0001  max mem: 14938
[16:19:06.453802] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7491 (0.7406)  time: 0.1844  data: 0.0001  max mem: 14938
[16:19:08.303910] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7395 (0.7418)  time: 0.1848  data: 0.0001  max mem: 14938
[16:19:10.157764] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7389 (0.7414)  time: 0.1851  data: 0.0001  max mem: 14938
[16:19:12.012767] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7369 (0.7415)  time: 0.1854  data: 0.0001  max mem: 14938
[16:19:13.871594] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7412 (0.7416)  time: 0.1856  data: 0.0001  max mem: 14938
[16:19:15.736165] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7464 (0.7419)  time: 0.1861  data: 0.0001  max mem: 14938
[16:19:17.602330] Test:  [100/345]  eta: 0:00:45  loss: 0.7387 (0.7419)  time: 0.1865  data: 0.0001  max mem: 14938
[16:19:19.471626] Test:  [110/345]  eta: 0:00:43  loss: 0.7390 (0.7425)  time: 0.1867  data: 0.0001  max mem: 14938
[16:19:21.346426] Test:  [120/345]  eta: 0:00:42  loss: 0.7444 (0.7428)  time: 0.1872  data: 0.0001  max mem: 14938
[16:19:23.224503] Test:  [130/345]  eta: 0:00:40  loss: 0.7458 (0.7429)  time: 0.1876  data: 0.0001  max mem: 14938
[16:19:25.107014] Test:  [140/345]  eta: 0:00:38  loss: 0.7435 (0.7431)  time: 0.1880  data: 0.0001  max mem: 14938
[16:19:26.992811] Test:  [150/345]  eta: 0:00:36  loss: 0.7426 (0.7431)  time: 0.1884  data: 0.0001  max mem: 14938
[16:19:28.881468] Test:  [160/345]  eta: 0:00:34  loss: 0.7426 (0.7429)  time: 0.1887  data: 0.0001  max mem: 14938
[16:19:30.772791] Test:  [170/345]  eta: 0:00:32  loss: 0.7377 (0.7429)  time: 0.1889  data: 0.0001  max mem: 14938
[16:19:32.672208] Test:  [180/345]  eta: 0:00:30  loss: 0.7346 (0.7423)  time: 0.1895  data: 0.0001  max mem: 14938
[16:19:34.573418] Test:  [190/345]  eta: 0:00:29  loss: 0.7347 (0.7422)  time: 0.1900  data: 0.0001  max mem: 14938
[16:19:36.475368] Test:  [200/345]  eta: 0:00:27  loss: 0.7377 (0.7421)  time: 0.1901  data: 0.0001  max mem: 14938
[16:19:38.382408] Test:  [210/345]  eta: 0:00:25  loss: 0.7377 (0.7418)  time: 0.1904  data: 0.0001  max mem: 14938
[16:19:40.292086] Test:  [220/345]  eta: 0:00:23  loss: 0.7364 (0.7416)  time: 0.1908  data: 0.0001  max mem: 14938
[16:19:42.205800] Test:  [230/345]  eta: 0:00:21  loss: 0.7368 (0.7416)  time: 0.1911  data: 0.0001  max mem: 14938
[16:19:44.124444] Test:  [240/345]  eta: 0:00:19  loss: 0.7368 (0.7415)  time: 0.1916  data: 0.0001  max mem: 14938
[16:19:46.045427] Test:  [250/345]  eta: 0:00:17  loss: 0.7391 (0.7415)  time: 0.1919  data: 0.0001  max mem: 14938
[16:19:47.968680] Test:  [260/345]  eta: 0:00:16  loss: 0.7400 (0.7414)  time: 0.1921  data: 0.0001  max mem: 14938
[16:19:49.897001] Test:  [270/345]  eta: 0:00:14  loss: 0.7389 (0.7417)  time: 0.1925  data: 0.0001  max mem: 14938
[16:19:51.829016] Test:  [280/345]  eta: 0:00:12  loss: 0.7389 (0.7418)  time: 0.1930  data: 0.0001  max mem: 14938
[16:19:53.763578] Test:  [290/345]  eta: 0:00:10  loss: 0.7348 (0.7415)  time: 0.1933  data: 0.0001  max mem: 14938
[16:19:55.701297] Test:  [300/345]  eta: 0:00:08  loss: 0.7312 (0.7413)  time: 0.1936  data: 0.0001  max mem: 14938
[16:19:57.641840] Test:  [310/345]  eta: 0:00:06  loss: 0.7391 (0.7417)  time: 0.1939  data: 0.0001  max mem: 14938
[16:19:59.585171] Test:  [320/345]  eta: 0:00:04  loss: 0.7392 (0.7415)  time: 0.1941  data: 0.0001  max mem: 14938
[16:20:01.531519] Test:  [330/345]  eta: 0:00:02  loss: 0.7279 (0.7413)  time: 0.1944  data: 0.0001  max mem: 14938
[16:20:03.480538] Test:  [340/345]  eta: 0:00:00  loss: 0.7350 (0.7412)  time: 0.1947  data: 0.0001  max mem: 14938
[16:20:04.261882] Test:  [344/345]  eta: 0:00:00  loss: 0.7361 (0.7413)  time: 0.1949  data: 0.0001  max mem: 14938
[16:20:04.322588] Test: Total time: 0:01:05 (0.1901 s / it)
[16:20:14.945564] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8356 (0.8356)  time: 0.3210  data: 0.1418  max mem: 14938
[16:20:16.762067] Test:  [10/57]  eta: 0:00:09  loss: 0.8796 (0.8774)  time: 0.1942  data: 0.0130  max mem: 14938
[16:20:18.583361] Test:  [20/57]  eta: 0:00:06  loss: 0.8677 (0.8618)  time: 0.1818  data: 0.0001  max mem: 14938
[16:20:20.410376] Test:  [30/57]  eta: 0:00:05  loss: 0.7830 (0.8301)  time: 0.1824  data: 0.0001  max mem: 14938
[16:20:22.240227] Test:  [40/57]  eta: 0:00:03  loss: 0.7547 (0.8125)  time: 0.1828  data: 0.0001  max mem: 14938
[16:20:24.076004] Test:  [50/57]  eta: 0:00:01  loss: 0.7547 (0.8070)  time: 0.1832  data: 0.0001  max mem: 14938
[16:20:25.065489] Test:  [56/57]  eta: 0:00:00  loss: 0.7902 (0.8111)  time: 0.1778  data: 0.0001  max mem: 14938
[16:20:25.125236] Test: Total time: 0:00:10 (0.1842 s / it)
[16:20:26.868354] Dice score of the network on the train images: 0.790593, val images: 0.807852
[16:20:26.868577] saving best_prec_model_0 @ epoch 21
[16:20:28.031325] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:20:28.922128] Epoch: [22]  [  0/345]  eta: 0:05:06  lr: 0.000124  loss: 0.7635 (0.7635)  time: 0.8898  data: 0.1480  max mem: 14938
[16:20:43.793709] Epoch: [22]  [ 20/345]  eta: 0:04:03  lr: 0.000124  loss: 0.7637 (0.7663)  time: 0.7435  data: 0.0001  max mem: 14938
[16:20:58.708498] Epoch: [22]  [ 40/345]  eta: 0:03:48  lr: 0.000123  loss: 0.7594 (0.7650)  time: 0.7457  data: 0.0001  max mem: 14938
[16:21:13.670878] Epoch: [22]  [ 60/345]  eta: 0:03:33  lr: 0.000123  loss: 0.7617 (0.7642)  time: 0.7481  data: 0.0001  max mem: 14938
[16:21:28.659868] Epoch: [22]  [ 80/345]  eta: 0:03:18  lr: 0.000123  loss: 0.7636 (0.7648)  time: 0.7494  data: 0.0001  max mem: 14938
[16:21:43.684573] Epoch: [22]  [100/345]  eta: 0:03:03  lr: 0.000123  loss: 0.7697 (0.7664)  time: 0.7512  data: 0.0001  max mem: 14938
[16:21:58.727482] Epoch: [22]  [120/345]  eta: 0:02:48  lr: 0.000123  loss: 0.7526 (0.7643)  time: 0.7521  data: 0.0001  max mem: 14938
[16:22:13.772038] Epoch: [22]  [140/345]  eta: 0:02:33  lr: 0.000123  loss: 0.7571 (0.7640)  time: 0.7522  data: 0.0001  max mem: 14938
[16:22:28.812171] Epoch: [22]  [160/345]  eta: 0:02:18  lr: 0.000123  loss: 0.7551 (0.7629)  time: 0.7520  data: 0.0001  max mem: 14938
[16:22:43.848836] Epoch: [22]  [180/345]  eta: 0:02:03  lr: 0.000123  loss: 0.7586 (0.7626)  time: 0.7518  data: 0.0001  max mem: 14938
[16:22:58.993022] Epoch: [22]  [200/345]  eta: 0:01:48  lr: 0.000123  loss: 0.7634 (0.7631)  time: 0.7572  data: 0.0001  max mem: 14938
[16:23:13.995595] Epoch: [22]  [220/345]  eta: 0:01:33  lr: 0.000123  loss: 0.7554 (0.7625)  time: 0.7501  data: 0.0001  max mem: 14938
[16:23:28.998017] Epoch: [22]  [240/345]  eta: 0:01:18  lr: 0.000123  loss: 0.7674 (0.7622)  time: 0.7501  data: 0.0001  max mem: 14938
[16:23:43.994979] Epoch: [22]  [260/345]  eta: 0:01:03  lr: 0.000122  loss: 0.7602 (0.7623)  time: 0.7498  data: 0.0001  max mem: 14938
[16:23:58.989653] Epoch: [22]  [280/345]  eta: 0:00:48  lr: 0.000122  loss: 0.7488 (0.7615)  time: 0.7497  data: 0.0001  max mem: 14938
[16:24:13.983903] Epoch: [22]  [300/345]  eta: 0:00:33  lr: 0.000122  loss: 0.7604 (0.7615)  time: 0.7497  data: 0.0001  max mem: 14938
[16:24:28.969992] Epoch: [22]  [320/345]  eta: 0:00:18  lr: 0.000122  loss: 0.7649 (0.7619)  time: 0.7493  data: 0.0001  max mem: 14938
[16:24:43.965142] Epoch: [22]  [340/345]  eta: 0:00:03  lr: 0.000122  loss: 0.7713 (0.7626)  time: 0.7497  data: 0.0001  max mem: 14938
[16:24:46.973397] Epoch: [22]  [344/345]  eta: 0:00:00  lr: 0.000122  loss: 0.7677 (0.7625)  time: 0.7502  data: 0.0001  max mem: 14938
[16:24:47.037984] Epoch: [22] Total time: 0:04:19 (0.7507 s / it)
[16:24:47.038472] Averaged stats: lr: 0.000122  loss: 0.7677 (0.7625)
[16:24:47.385285] Test:  [  0/345]  eta: 0:01:58  loss: 0.7241 (0.7241)  time: 0.3421  data: 0.1606  max mem: 14938
[16:24:49.222915] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7290 (0.7294)  time: 0.1981  data: 0.0147  max mem: 14938
[16:24:51.064001] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7321 (0.7294)  time: 0.1839  data: 0.0001  max mem: 14938
[16:24:52.907700] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7364 (0.7309)  time: 0.1842  data: 0.0001  max mem: 14938
[16:24:54.754852] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7384 (0.7319)  time: 0.1845  data: 0.0001  max mem: 14938
[16:24:56.606534] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7316 (0.7317)  time: 0.1849  data: 0.0001  max mem: 14938
[16:24:58.461111] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7266 (0.7314)  time: 0.1853  data: 0.0001  max mem: 14938
[16:25:00.317962] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7256 (0.7314)  time: 0.1855  data: 0.0001  max mem: 14938
[16:25:02.178587] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7265 (0.7315)  time: 0.1858  data: 0.0001  max mem: 14938
[16:25:04.042874] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7262 (0.7309)  time: 0.1862  data: 0.0001  max mem: 14938
[16:25:05.910326] Test:  [100/345]  eta: 0:00:45  loss: 0.7304 (0.7318)  time: 0.1865  data: 0.0001  max mem: 14938
[16:25:07.780810] Test:  [110/345]  eta: 0:00:43  loss: 0.7343 (0.7323)  time: 0.1868  data: 0.0001  max mem: 14938
[16:25:09.655101] Test:  [120/345]  eta: 0:00:42  loss: 0.7343 (0.7324)  time: 0.1872  data: 0.0001  max mem: 14938
[16:25:11.534673] Test:  [130/345]  eta: 0:00:40  loss: 0.7354 (0.7332)  time: 0.1876  data: 0.0001  max mem: 14938
[16:25:13.418450] Test:  [140/345]  eta: 0:00:38  loss: 0.7421 (0.7335)  time: 0.1881  data: 0.0001  max mem: 14938
[16:25:15.303273] Test:  [150/345]  eta: 0:00:36  loss: 0.7277 (0.7329)  time: 0.1884  data: 0.0001  max mem: 14938
[16:25:17.191795] Test:  [160/345]  eta: 0:00:34  loss: 0.7288 (0.7331)  time: 0.1886  data: 0.0001  max mem: 14938
[16:25:19.084361] Test:  [170/345]  eta: 0:00:32  loss: 0.7288 (0.7330)  time: 0.1890  data: 0.0001  max mem: 14938
[16:25:20.982081] Test:  [180/345]  eta: 0:00:30  loss: 0.7288 (0.7334)  time: 0.1895  data: 0.0001  max mem: 14938
[16:25:22.881988] Test:  [190/345]  eta: 0:00:29  loss: 0.7423 (0.7336)  time: 0.1898  data: 0.0001  max mem: 14938
[16:25:24.783858] Test:  [200/345]  eta: 0:00:27  loss: 0.7347 (0.7335)  time: 0.1900  data: 0.0001  max mem: 14938
[16:25:26.690111] Test:  [210/345]  eta: 0:00:25  loss: 0.7294 (0.7335)  time: 0.1904  data: 0.0001  max mem: 14938
[16:25:28.599156] Test:  [220/345]  eta: 0:00:23  loss: 0.7305 (0.7336)  time: 0.1907  data: 0.0001  max mem: 14938
[16:25:30.512193] Test:  [230/345]  eta: 0:00:21  loss: 0.7308 (0.7336)  time: 0.1911  data: 0.0001  max mem: 14938
[16:25:32.429071] Test:  [240/345]  eta: 0:00:19  loss: 0.7281 (0.7337)  time: 0.1914  data: 0.0001  max mem: 14938
[16:25:34.349641] Test:  [250/345]  eta: 0:00:17  loss: 0.7393 (0.7342)  time: 0.1918  data: 0.0001  max mem: 14938
[16:25:36.273763] Test:  [260/345]  eta: 0:00:16  loss: 0.7387 (0.7343)  time: 0.1922  data: 0.0001  max mem: 14938
[16:25:38.201092] Test:  [270/345]  eta: 0:00:14  loss: 0.7350 (0.7345)  time: 0.1925  data: 0.0001  max mem: 14938
[16:25:40.133777] Test:  [280/345]  eta: 0:00:12  loss: 0.7387 (0.7347)  time: 0.1929  data: 0.0001  max mem: 14938
[16:25:42.067587] Test:  [290/345]  eta: 0:00:10  loss: 0.7377 (0.7348)  time: 0.1933  data: 0.0001  max mem: 14938
[16:25:44.004428] Test:  [300/345]  eta: 0:00:08  loss: 0.7347 (0.7348)  time: 0.1935  data: 0.0001  max mem: 14938
[16:25:45.947691] Test:  [310/345]  eta: 0:00:06  loss: 0.7347 (0.7350)  time: 0.1939  data: 0.0001  max mem: 14938
[16:25:47.890611] Test:  [320/345]  eta: 0:00:04  loss: 0.7338 (0.7351)  time: 0.1942  data: 0.0001  max mem: 14938
[16:25:49.839717] Test:  [330/345]  eta: 0:00:02  loss: 0.7409 (0.7355)  time: 0.1945  data: 0.0001  max mem: 14938
[16:25:51.791689] Test:  [340/345]  eta: 0:00:00  loss: 0.7409 (0.7357)  time: 0.1950  data: 0.0001  max mem: 14938
[16:25:52.572744] Test:  [344/345]  eta: 0:00:00  loss: 0.7425 (0.7357)  time: 0.1951  data: 0.0001  max mem: 14938
[16:25:52.633892] Test: Total time: 0:01:05 (0.1901 s / it)
[16:26:03.086246] Test:  [ 0/57]  eta: 0:00:18  loss: 0.7927 (0.7927)  time: 0.3271  data: 0.1472  max mem: 14938
[16:26:04.903281] Test:  [10/57]  eta: 0:00:09  loss: 0.8702 (0.8640)  time: 0.1948  data: 0.0134  max mem: 14938
[16:26:06.725990] Test:  [20/57]  eta: 0:00:06  loss: 0.8702 (0.8542)  time: 0.1819  data: 0.0001  max mem: 14938
[16:26:08.552422] Test:  [30/57]  eta: 0:00:05  loss: 0.7616 (0.8199)  time: 0.1824  data: 0.0001  max mem: 14938
[16:26:10.383521] Test:  [40/57]  eta: 0:00:03  loss: 0.7468 (0.8031)  time: 0.1828  data: 0.0001  max mem: 14938
[16:26:12.218717] Test:  [50/57]  eta: 0:00:01  loss: 0.7525 (0.7979)  time: 0.1833  data: 0.0001  max mem: 14938
[16:26:13.208967] Test:  [56/57]  eta: 0:00:00  loss: 0.7645 (0.8016)  time: 0.1779  data: 0.0001  max mem: 14938
[16:26:13.268099] Test: Total time: 0:00:10 (0.1844 s / it)
[16:26:14.999839] Dice score of the network on the train images: 0.786521, val images: 0.813138
[16:26:15.003702] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:26:15.893634] Epoch: [23]  [  0/345]  eta: 0:05:06  lr: 0.000122  loss: 0.7399 (0.7399)  time: 0.8887  data: 0.1468  max mem: 14938
[16:26:30.781796] Epoch: [23]  [ 20/345]  eta: 0:04:04  lr: 0.000122  loss: 0.7644 (0.7648)  time: 0.7443  data: 0.0001  max mem: 14938
[16:26:45.705081] Epoch: [23]  [ 40/345]  eta: 0:03:48  lr: 0.000122  loss: 0.7782 (0.7721)  time: 0.7461  data: 0.0001  max mem: 14938
[16:27:00.679560] Epoch: [23]  [ 60/345]  eta: 0:03:33  lr: 0.000122  loss: 0.7595 (0.7691)  time: 0.7487  data: 0.0001  max mem: 14938
[16:27:15.664287] Epoch: [23]  [ 80/345]  eta: 0:03:18  lr: 0.000121  loss: 0.7566 (0.7673)  time: 0.7492  data: 0.0001  max mem: 14938
[16:27:30.676281] Epoch: [23]  [100/345]  eta: 0:03:03  lr: 0.000121  loss: 0.7544 (0.7652)  time: 0.7506  data: 0.0001  max mem: 14938
[16:27:45.703419] Epoch: [23]  [120/345]  eta: 0:02:48  lr: 0.000121  loss: 0.7556 (0.7651)  time: 0.7513  data: 0.0001  max mem: 14938
[16:28:00.729898] Epoch: [23]  [140/345]  eta: 0:02:33  lr: 0.000121  loss: 0.7572 (0.7636)  time: 0.7513  data: 0.0001  max mem: 14938
[16:28:15.751184] Epoch: [23]  [160/345]  eta: 0:02:18  lr: 0.000121  loss: 0.7586 (0.7634)  time: 0.7510  data: 0.0001  max mem: 14938
[16:28:30.772175] Epoch: [23]  [180/345]  eta: 0:02:03  lr: 0.000121  loss: 0.7485 (0.7619)  time: 0.7510  data: 0.0001  max mem: 14938
[16:28:45.784473] Epoch: [23]  [200/345]  eta: 0:01:48  lr: 0.000121  loss: 0.7523 (0.7610)  time: 0.7506  data: 0.0001  max mem: 14938
[16:29:00.784975] Epoch: [23]  [220/345]  eta: 0:01:33  lr: 0.000121  loss: 0.7610 (0.7608)  time: 0.7500  data: 0.0001  max mem: 14938
[16:29:15.786417] Epoch: [23]  [240/345]  eta: 0:01:18  lr: 0.000120  loss: 0.7594 (0.7604)  time: 0.7500  data: 0.0001  max mem: 14938
[16:29:30.773656] Epoch: [23]  [260/345]  eta: 0:01:03  lr: 0.000120  loss: 0.7599 (0.7602)  time: 0.7493  data: 0.0001  max mem: 14938
[16:29:45.758189] Epoch: [23]  [280/345]  eta: 0:00:48  lr: 0.000120  loss: 0.7558 (0.7599)  time: 0.7492  data: 0.0001  max mem: 14938
[16:30:00.747973] Epoch: [23]  [300/345]  eta: 0:00:33  lr: 0.000120  loss: 0.7555 (0.7596)  time: 0.7494  data: 0.0001  max mem: 14938
[16:30:15.827069] Epoch: [23]  [320/345]  eta: 0:00:18  lr: 0.000120  loss: 0.7538 (0.7595)  time: 0.7539  data: 0.0001  max mem: 14938
[16:30:30.810798] Epoch: [23]  [340/345]  eta: 0:00:03  lr: 0.000120  loss: 0.7537 (0.7591)  time: 0.7491  data: 0.0001  max mem: 14938
[16:30:33.806311] Epoch: [23]  [344/345]  eta: 0:00:00  lr: 0.000120  loss: 0.7508 (0.7590)  time: 0.7489  data: 0.0001  max mem: 14938
[16:30:33.870806] Epoch: [23] Total time: 0:04:18 (0.7503 s / it)
[16:30:33.871326] Averaged stats: lr: 0.000120  loss: 0.7508 (0.7590)
[16:30:34.221800] Test:  [  0/345]  eta: 0:01:59  loss: 0.7354 (0.7354)  time: 0.3465  data: 0.1651  max mem: 14938
[16:30:36.057906] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7340 (0.7320)  time: 0.1983  data: 0.0151  max mem: 14938
[16:30:37.896586] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7312 (0.7311)  time: 0.1837  data: 0.0001  max mem: 14938
[16:30:39.739776] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7216 (0.7276)  time: 0.1840  data: 0.0001  max mem: 14938
[16:30:41.585390] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7244 (0.7283)  time: 0.1844  data: 0.0001  max mem: 14938
[16:30:43.437618] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7309 (0.7288)  time: 0.1848  data: 0.0001  max mem: 14938
[16:30:45.290584] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7280 (0.7288)  time: 0.1852  data: 0.0001  max mem: 14938
[16:30:47.147347] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7253 (0.7273)  time: 0.1854  data: 0.0001  max mem: 14938
[16:30:49.007682] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7224 (0.7268)  time: 0.1858  data: 0.0001  max mem: 14938
[16:30:50.872340] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7255 (0.7271)  time: 0.1862  data: 0.0001  max mem: 14938
[16:30:52.739364] Test:  [100/345]  eta: 0:00:45  loss: 0.7267 (0.7272)  time: 0.1865  data: 0.0001  max mem: 14938
[16:30:54.608977] Test:  [110/345]  eta: 0:00:43  loss: 0.7275 (0.7275)  time: 0.1868  data: 0.0001  max mem: 14938
[16:30:56.483552] Test:  [120/345]  eta: 0:00:42  loss: 0.7280 (0.7271)  time: 0.1872  data: 0.0001  max mem: 14938
[16:30:58.361989] Test:  [130/345]  eta: 0:00:40  loss: 0.7252 (0.7270)  time: 0.1876  data: 0.0001  max mem: 14938
[16:31:00.244396] Test:  [140/345]  eta: 0:00:38  loss: 0.7232 (0.7268)  time: 0.1880  data: 0.0001  max mem: 14938
[16:31:02.128747] Test:  [150/345]  eta: 0:00:36  loss: 0.7201 (0.7264)  time: 0.1883  data: 0.0001  max mem: 14938
[16:31:04.016137] Test:  [160/345]  eta: 0:00:34  loss: 0.7248 (0.7268)  time: 0.1885  data: 0.0001  max mem: 14938
[16:31:05.907297] Test:  [170/345]  eta: 0:00:32  loss: 0.7285 (0.7270)  time: 0.1889  data: 0.0001  max mem: 14938
[16:31:07.804417] Test:  [180/345]  eta: 0:00:30  loss: 0.7256 (0.7269)  time: 0.1894  data: 0.0001  max mem: 14938
[16:31:09.703904] Test:  [190/345]  eta: 0:00:29  loss: 0.7293 (0.7270)  time: 0.1898  data: 0.0001  max mem: 14938
[16:31:11.607136] Test:  [200/345]  eta: 0:00:27  loss: 0.7289 (0.7268)  time: 0.1901  data: 0.0001  max mem: 14938
[16:31:13.512501] Test:  [210/345]  eta: 0:00:25  loss: 0.7233 (0.7267)  time: 0.1904  data: 0.0001  max mem: 14938
[16:31:15.421327] Test:  [220/345]  eta: 0:00:23  loss: 0.7241 (0.7267)  time: 0.1907  data: 0.0001  max mem: 14938
[16:31:17.334562] Test:  [230/345]  eta: 0:00:21  loss: 0.7241 (0.7266)  time: 0.1911  data: 0.0001  max mem: 14938
[16:31:19.250951] Test:  [240/345]  eta: 0:00:19  loss: 0.7199 (0.7264)  time: 0.1914  data: 0.0001  max mem: 14938
[16:31:21.171428] Test:  [250/345]  eta: 0:00:17  loss: 0.7197 (0.7263)  time: 0.1918  data: 0.0001  max mem: 14938
[16:31:23.096457] Test:  [260/345]  eta: 0:00:16  loss: 0.7251 (0.7266)  time: 0.1922  data: 0.0001  max mem: 14938
[16:31:25.022511] Test:  [270/345]  eta: 0:00:14  loss: 0.7238 (0.7264)  time: 0.1925  data: 0.0001  max mem: 14938
[16:31:26.954067] Test:  [280/345]  eta: 0:00:12  loss: 0.7220 (0.7263)  time: 0.1928  data: 0.0001  max mem: 14938
[16:31:28.888365] Test:  [290/345]  eta: 0:00:10  loss: 0.7243 (0.7261)  time: 0.1932  data: 0.0001  max mem: 14938
[16:31:30.825513] Test:  [300/345]  eta: 0:00:08  loss: 0.7234 (0.7262)  time: 0.1935  data: 0.0001  max mem: 14938
[16:31:32.766459] Test:  [310/345]  eta: 0:00:06  loss: 0.7234 (0.7261)  time: 0.1939  data: 0.0001  max mem: 14938
[16:31:34.710549] Test:  [320/345]  eta: 0:00:04  loss: 0.7186 (0.7259)  time: 0.1942  data: 0.0001  max mem: 14938
[16:31:36.657556] Test:  [330/345]  eta: 0:00:02  loss: 0.7222 (0.7258)  time: 0.1945  data: 0.0001  max mem: 14938
[16:31:38.608304] Test:  [340/345]  eta: 0:00:00  loss: 0.7246 (0.7257)  time: 0.1948  data: 0.0001  max mem: 14938
[16:31:39.390149] Test:  [344/345]  eta: 0:00:00  loss: 0.7253 (0.7258)  time: 0.1950  data: 0.0001  max mem: 14938
[16:31:39.431871] Test: Total time: 0:01:05 (0.1900 s / it)
[16:31:50.143824] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8421 (0.8421)  time: 0.3305  data: 0.1509  max mem: 14938
[16:31:51.958791] Test:  [10/57]  eta: 0:00:09  loss: 0.8777 (0.8711)  time: 0.1950  data: 0.0138  max mem: 14938
[16:31:53.780811] Test:  [20/57]  eta: 0:00:06  loss: 0.8595 (0.8564)  time: 0.1818  data: 0.0001  max mem: 14938
[16:31:55.605056] Test:  [30/57]  eta: 0:00:05  loss: 0.7563 (0.8195)  time: 0.1823  data: 0.0001  max mem: 14938
[16:31:57.434839] Test:  [40/57]  eta: 0:00:03  loss: 0.7413 (0.8005)  time: 0.1827  data: 0.0001  max mem: 14938
[16:31:59.269061] Test:  [50/57]  eta: 0:00:01  loss: 0.7464 (0.7956)  time: 0.1831  data: 0.0001  max mem: 14938
[16:32:00.258212] Test:  [56/57]  eta: 0:00:00  loss: 0.7574 (0.7998)  time: 0.1777  data: 0.0001  max mem: 14938
[16:32:00.321163] Test: Total time: 0:00:10 (0.1844 s / it)
[16:32:02.158055] Dice score of the network on the train images: 0.796441, val images: 0.813594
[16:32:02.162369] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:32:03.050857] Epoch: [24]  [  0/345]  eta: 0:05:06  lr: 0.000120  loss: 0.7364 (0.7364)  time: 0.8873  data: 0.1439  max mem: 14938
[16:32:17.928007] Epoch: [24]  [ 20/345]  eta: 0:04:03  lr: 0.000119  loss: 0.7542 (0.7553)  time: 0.7438  data: 0.0001  max mem: 14938
[16:32:32.853825] Epoch: [24]  [ 40/345]  eta: 0:03:48  lr: 0.000119  loss: 0.7587 (0.7572)  time: 0.7462  data: 0.0001  max mem: 14938
[16:32:47.816466] Epoch: [24]  [ 60/345]  eta: 0:03:33  lr: 0.000119  loss: 0.7524 (0.7569)  time: 0.7481  data: 0.0001  max mem: 14938
[16:33:02.809148] Epoch: [24]  [ 80/345]  eta: 0:03:18  lr: 0.000119  loss: 0.7534 (0.7562)  time: 0.7496  data: 0.0001  max mem: 14938
[16:33:17.824257] Epoch: [24]  [100/345]  eta: 0:03:03  lr: 0.000119  loss: 0.7527 (0.7560)  time: 0.7507  data: 0.0001  max mem: 14938
[16:33:32.858297] Epoch: [24]  [120/345]  eta: 0:02:48  lr: 0.000119  loss: 0.7485 (0.7545)  time: 0.7517  data: 0.0001  max mem: 14938
[16:33:47.903256] Epoch: [24]  [140/345]  eta: 0:02:33  lr: 0.000118  loss: 0.7558 (0.7551)  time: 0.7522  data: 0.0001  max mem: 14938
[16:34:02.940476] Epoch: [24]  [160/345]  eta: 0:02:18  lr: 0.000118  loss: 0.7569 (0.7557)  time: 0.7518  data: 0.0001  max mem: 14938
[16:34:17.953437] Epoch: [24]  [180/345]  eta: 0:02:03  lr: 0.000118  loss: 0.7695 (0.7577)  time: 0.7506  data: 0.0001  max mem: 14938
[16:34:32.961025] Epoch: [24]  [200/345]  eta: 0:01:48  lr: 0.000118  loss: 0.7568 (0.7576)  time: 0.7503  data: 0.0001  max mem: 14938
[16:34:47.966037] Epoch: [24]  [220/345]  eta: 0:01:33  lr: 0.000118  loss: 0.7503 (0.7573)  time: 0.7502  data: 0.0001  max mem: 14938
[16:35:02.961676] Epoch: [24]  [240/345]  eta: 0:01:18  lr: 0.000118  loss: 0.7478 (0.7568)  time: 0.7497  data: 0.0001  max mem: 14938
[16:35:17.953609] Epoch: [24]  [260/345]  eta: 0:01:03  lr: 0.000117  loss: 0.7523 (0.7565)  time: 0.7495  data: 0.0001  max mem: 14938
[16:35:32.938948] Epoch: [24]  [280/345]  eta: 0:00:48  lr: 0.000117  loss: 0.7611 (0.7571)  time: 0.7492  data: 0.0001  max mem: 14938
[16:35:47.919472] Epoch: [24]  [300/345]  eta: 0:00:33  lr: 0.000117  loss: 0.7638 (0.7580)  time: 0.7490  data: 0.0001  max mem: 14938
[16:36:02.904364] Epoch: [24]  [320/345]  eta: 0:00:18  lr: 0.000117  loss: 0.7571 (0.7580)  time: 0.7492  data: 0.0001  max mem: 14938
[16:36:17.887172] Epoch: [24]  [340/345]  eta: 0:00:03  lr: 0.000117  loss: 0.7610 (0.7582)  time: 0.7491  data: 0.0001  max mem: 14938
[16:36:20.882502] Epoch: [24]  [344/345]  eta: 0:00:00  lr: 0.000117  loss: 0.7610 (0.7582)  time: 0.7490  data: 0.0001  max mem: 14938
[16:36:20.950698] Epoch: [24] Total time: 0:04:18 (0.7501 s / it)
[16:36:20.951143] Averaged stats: lr: 0.000117  loss: 0.7610 (0.7582)
[16:36:21.296577] Test:  [  0/345]  eta: 0:01:57  loss: 0.7486 (0.7486)  time: 0.3414  data: 0.1600  max mem: 14938
[16:36:23.133496] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7455 (0.7450)  time: 0.1980  data: 0.0146  max mem: 14938
[16:36:24.971516] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7421 (0.7439)  time: 0.1837  data: 0.0001  max mem: 14938
[16:36:26.814296] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7365 (0.7419)  time: 0.1840  data: 0.0001  max mem: 14938
[16:36:28.661434] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7436 (0.7432)  time: 0.1844  data: 0.0001  max mem: 14938
[16:36:30.510489] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7404 (0.7422)  time: 0.1848  data: 0.0001  max mem: 14938
[16:36:32.363179] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7308 (0.7409)  time: 0.1850  data: 0.0001  max mem: 14938
[16:36:34.219987] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7309 (0.7404)  time: 0.1854  data: 0.0001  max mem: 14938
[16:36:36.080158] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7349 (0.7395)  time: 0.1858  data: 0.0001  max mem: 14938
[16:36:37.943970] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7366 (0.7401)  time: 0.1862  data: 0.0001  max mem: 14938
[16:36:39.809998] Test:  [100/345]  eta: 0:00:45  loss: 0.7407 (0.7394)  time: 0.1864  data: 0.0001  max mem: 14938
[16:36:41.681035] Test:  [110/345]  eta: 0:00:43  loss: 0.7379 (0.7397)  time: 0.1868  data: 0.0001  max mem: 14938
[16:36:43.555603] Test:  [120/345]  eta: 0:00:42  loss: 0.7409 (0.7399)  time: 0.1872  data: 0.0001  max mem: 14938
[16:36:45.433289] Test:  [130/345]  eta: 0:00:40  loss: 0.7370 (0.7398)  time: 0.1876  data: 0.0001  max mem: 14938
[16:36:47.315145] Test:  [140/345]  eta: 0:00:38  loss: 0.7341 (0.7392)  time: 0.1879  data: 0.0001  max mem: 14938
[16:36:49.200414] Test:  [150/345]  eta: 0:00:36  loss: 0.7352 (0.7392)  time: 0.1883  data: 0.0001  max mem: 14938
[16:36:51.087423] Test:  [160/345]  eta: 0:00:34  loss: 0.7352 (0.7393)  time: 0.1886  data: 0.0001  max mem: 14938
[16:36:52.978416] Test:  [170/345]  eta: 0:00:32  loss: 0.7348 (0.7392)  time: 0.1889  data: 0.0001  max mem: 14938
[16:36:54.874695] Test:  [180/345]  eta: 0:00:30  loss: 0.7390 (0.7392)  time: 0.1893  data: 0.0001  max mem: 14938
[16:36:56.776427] Test:  [190/345]  eta: 0:00:29  loss: 0.7390 (0.7393)  time: 0.1899  data: 0.0001  max mem: 14938
[16:36:58.678994] Test:  [200/345]  eta: 0:00:27  loss: 0.7372 (0.7390)  time: 0.1902  data: 0.0001  max mem: 14938
[16:37:00.585559] Test:  [210/345]  eta: 0:00:25  loss: 0.7372 (0.7391)  time: 0.1904  data: 0.0001  max mem: 14938
[16:37:02.494787] Test:  [220/345]  eta: 0:00:23  loss: 0.7326 (0.7390)  time: 0.1907  data: 0.0001  max mem: 14938
[16:37:04.409680] Test:  [230/345]  eta: 0:00:21  loss: 0.7260 (0.7384)  time: 0.1912  data: 0.0001  max mem: 14938
[16:37:06.326403] Test:  [240/345]  eta: 0:00:19  loss: 0.7350 (0.7383)  time: 0.1915  data: 0.0001  max mem: 14938
[16:37:08.248691] Test:  [250/345]  eta: 0:00:17  loss: 0.7394 (0.7383)  time: 0.1919  data: 0.0001  max mem: 14938
[16:37:10.171653] Test:  [260/345]  eta: 0:00:16  loss: 0.7280 (0.7381)  time: 0.1922  data: 0.0001  max mem: 14938
[16:37:12.097885] Test:  [270/345]  eta: 0:00:14  loss: 0.7348 (0.7382)  time: 0.1924  data: 0.0001  max mem: 14938
[16:37:14.030326] Test:  [280/345]  eta: 0:00:12  loss: 0.7385 (0.7384)  time: 0.1929  data: 0.0001  max mem: 14938
[16:37:15.963758] Test:  [290/345]  eta: 0:00:10  loss: 0.7380 (0.7384)  time: 0.1932  data: 0.0001  max mem: 14938
[16:37:17.902722] Test:  [300/345]  eta: 0:00:08  loss: 0.7340 (0.7382)  time: 0.1936  data: 0.0001  max mem: 14938
[16:37:19.844178] Test:  [310/345]  eta: 0:00:06  loss: 0.7336 (0.7383)  time: 0.1940  data: 0.0001  max mem: 14938
[16:37:21.787472] Test:  [320/345]  eta: 0:00:04  loss: 0.7292 (0.7380)  time: 0.1942  data: 0.0001  max mem: 14938
[16:37:23.733481] Test:  [330/345]  eta: 0:00:02  loss: 0.7387 (0.7384)  time: 0.1944  data: 0.0001  max mem: 14938
[16:37:25.684138] Test:  [340/345]  eta: 0:00:00  loss: 0.7482 (0.7386)  time: 0.1948  data: 0.0001  max mem: 14938
[16:37:26.466237] Test:  [344/345]  eta: 0:00:00  loss: 0.7382 (0.7386)  time: 0.1950  data: 0.0001  max mem: 14938
[16:37:26.528022] Test: Total time: 0:01:05 (0.1901 s / it)
[16:37:37.287012] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8590 (0.8590)  time: 0.3277  data: 0.1482  max mem: 14938
[16:37:39.104721] Test:  [10/57]  eta: 0:00:09  loss: 0.8638 (0.8750)  time: 0.1950  data: 0.0135  max mem: 14938
[16:37:40.926475] Test:  [20/57]  eta: 0:00:06  loss: 0.8586 (0.8622)  time: 0.1819  data: 0.0001  max mem: 14938
[16:37:42.751033] Test:  [30/57]  eta: 0:00:05  loss: 0.7637 (0.8274)  time: 0.1823  data: 0.0001  max mem: 14938
[16:37:44.581806] Test:  [40/57]  eta: 0:00:03  loss: 0.7488 (0.8089)  time: 0.1827  data: 0.0001  max mem: 14938
[16:37:46.417670] Test:  [50/57]  eta: 0:00:01  loss: 0.7408 (0.8012)  time: 0.1833  data: 0.0001  max mem: 14938
[16:37:47.407912] Test:  [56/57]  eta: 0:00:00  loss: 0.7738 (0.8060)  time: 0.1779  data: 0.0001  max mem: 14938
[16:37:47.470440] Test: Total time: 0:00:10 (0.1844 s / it)
[16:37:49.312484] Dice score of the network on the train images: 0.793922, val images: 0.811436
[16:37:49.316556] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:37:50.208372] Epoch: [25]  [  0/345]  eta: 0:05:07  lr: 0.000117  loss: 0.7524 (0.7524)  time: 0.8908  data: 0.1493  max mem: 14938
[16:38:05.098021] Epoch: [25]  [ 20/345]  eta: 0:04:04  lr: 0.000116  loss: 0.7718 (0.7665)  time: 0.7444  data: 0.0001  max mem: 14938
[16:38:20.027232] Epoch: [25]  [ 40/345]  eta: 0:03:48  lr: 0.000116  loss: 0.7530 (0.7598)  time: 0.7464  data: 0.0001  max mem: 14938
[16:38:34.987945] Epoch: [25]  [ 60/345]  eta: 0:03:33  lr: 0.000116  loss: 0.7522 (0.7588)  time: 0.7480  data: 0.0001  max mem: 14938
[16:38:49.969012] Epoch: [25]  [ 80/345]  eta: 0:03:18  lr: 0.000116  loss: 0.7595 (0.7597)  time: 0.7490  data: 0.0001  max mem: 14938
[16:39:04.980100] Epoch: [25]  [100/345]  eta: 0:03:03  lr: 0.000116  loss: 0.7553 (0.7594)  time: 0.7505  data: 0.0001  max mem: 14938
[16:39:20.013758] Epoch: [25]  [120/345]  eta: 0:02:48  lr: 0.000115  loss: 0.7618 (0.7595)  time: 0.7516  data: 0.0001  max mem: 14938
[16:39:35.043692] Epoch: [25]  [140/345]  eta: 0:02:33  lr: 0.000115  loss: 0.7521 (0.7583)  time: 0.7515  data: 0.0001  max mem: 14938
[16:39:50.065695] Epoch: [25]  [160/345]  eta: 0:02:18  lr: 0.000115  loss: 0.7553 (0.7586)  time: 0.7511  data: 0.0001  max mem: 14938
[16:40:05.077815] Epoch: [25]  [180/345]  eta: 0:02:03  lr: 0.000115  loss: 0.7650 (0.7596)  time: 0.7506  data: 0.0001  max mem: 14938
[16:40:20.067597] Epoch: [25]  [200/345]  eta: 0:01:48  lr: 0.000115  loss: 0.7440 (0.7580)  time: 0.7494  data: 0.0001  max mem: 14938
[16:40:35.075586] Epoch: [25]  [220/345]  eta: 0:01:33  lr: 0.000114  loss: 0.7453 (0.7571)  time: 0.7503  data: 0.0001  max mem: 14938
[16:40:50.073208] Epoch: [25]  [240/345]  eta: 0:01:18  lr: 0.000114  loss: 0.7413 (0.7561)  time: 0.7498  data: 0.0001  max mem: 14938
[16:41:05.074070] Epoch: [25]  [260/345]  eta: 0:01:03  lr: 0.000114  loss: 0.7558 (0.7560)  time: 0.7500  data: 0.0001  max mem: 14938
[16:41:20.066813] Epoch: [25]  [280/345]  eta: 0:00:48  lr: 0.000114  loss: 0.7572 (0.7561)  time: 0.7496  data: 0.0001  max mem: 14938
[16:41:35.059616] Epoch: [25]  [300/345]  eta: 0:00:33  lr: 0.000114  loss: 0.7643 (0.7566)  time: 0.7496  data: 0.0001  max mem: 14938
[16:41:50.135423] Epoch: [25]  [320/345]  eta: 0:00:18  lr: 0.000113  loss: 0.7635 (0.7570)  time: 0.7537  data: 0.0001  max mem: 14938
[16:42:05.128690] Epoch: [25]  [340/345]  eta: 0:00:03  lr: 0.000113  loss: 0.7509 (0.7568)  time: 0.7496  data: 0.0001  max mem: 14938
[16:42:08.124642] Epoch: [25]  [344/345]  eta: 0:00:00  lr: 0.000113  loss: 0.7516 (0.7567)  time: 0.7495  data: 0.0001  max mem: 14938
[16:42:08.192695] Epoch: [25] Total time: 0:04:18 (0.7504 s / it)
[16:42:08.193128] Averaged stats: lr: 0.000113  loss: 0.7516 (0.7567)
[16:42:08.546759] Test:  [  0/345]  eta: 0:02:00  loss: 0.6919 (0.6919)  time: 0.3496  data: 0.1681  max mem: 14938
[16:42:10.384354] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7198 (0.7261)  time: 0.1988  data: 0.0153  max mem: 14938
[16:42:12.225850] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7240 (0.7263)  time: 0.1839  data: 0.0001  max mem: 14938
[16:42:14.068857] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7231 (0.7242)  time: 0.1842  data: 0.0001  max mem: 14938
[16:42:15.915507] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7232 (0.7253)  time: 0.1844  data: 0.0001  max mem: 14938
[16:42:17.766166] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7232 (0.7241)  time: 0.1848  data: 0.0001  max mem: 14938
[16:42:19.618857] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7170 (0.7245)  time: 0.1851  data: 0.0001  max mem: 14938
[16:42:21.475640] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7229 (0.7248)  time: 0.1854  data: 0.0001  max mem: 14938
[16:42:23.335538] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7220 (0.7242)  time: 0.1858  data: 0.0001  max mem: 14938
[16:42:25.199981] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7211 (0.7241)  time: 0.1862  data: 0.0001  max mem: 14938
[16:42:27.067821] Test:  [100/345]  eta: 0:00:45  loss: 0.7189 (0.7238)  time: 0.1866  data: 0.0001  max mem: 14938
[16:42:28.937485] Test:  [110/345]  eta: 0:00:43  loss: 0.7284 (0.7249)  time: 0.1868  data: 0.0001  max mem: 14938
[16:42:30.811953] Test:  [120/345]  eta: 0:00:42  loss: 0.7328 (0.7253)  time: 0.1872  data: 0.0001  max mem: 14938
[16:42:32.690127] Test:  [130/345]  eta: 0:00:40  loss: 0.7177 (0.7250)  time: 0.1876  data: 0.0001  max mem: 14938
[16:42:34.571541] Test:  [140/345]  eta: 0:00:38  loss: 0.7177 (0.7253)  time: 0.1879  data: 0.0001  max mem: 14938
[16:42:36.456227] Test:  [150/345]  eta: 0:00:36  loss: 0.7295 (0.7253)  time: 0.1883  data: 0.0001  max mem: 14938
[16:42:38.345054] Test:  [160/345]  eta: 0:00:34  loss: 0.7264 (0.7255)  time: 0.1886  data: 0.0001  max mem: 14938
[16:42:40.236545] Test:  [170/345]  eta: 0:00:32  loss: 0.7249 (0.7253)  time: 0.1890  data: 0.0001  max mem: 14938
[16:42:42.132516] Test:  [180/345]  eta: 0:00:30  loss: 0.7268 (0.7255)  time: 0.1893  data: 0.0001  max mem: 14938
[16:42:44.033163] Test:  [190/345]  eta: 0:00:29  loss: 0.7269 (0.7254)  time: 0.1898  data: 0.0001  max mem: 14938
[16:42:45.934228] Test:  [200/345]  eta: 0:00:27  loss: 0.7238 (0.7255)  time: 0.1900  data: 0.0001  max mem: 14938
[16:42:47.840179] Test:  [210/345]  eta: 0:00:25  loss: 0.7198 (0.7252)  time: 0.1903  data: 0.0001  max mem: 14938
[16:42:49.749237] Test:  [220/345]  eta: 0:00:23  loss: 0.7198 (0.7251)  time: 0.1907  data: 0.0001  max mem: 14938
[16:42:51.662088] Test:  [230/345]  eta: 0:00:21  loss: 0.7258 (0.7255)  time: 0.1910  data: 0.0001  max mem: 14938
[16:42:53.578994] Test:  [240/345]  eta: 0:00:19  loss: 0.7352 (0.7257)  time: 0.1914  data: 0.0001  max mem: 14938
[16:42:55.499812] Test:  [250/345]  eta: 0:00:17  loss: 0.7286 (0.7258)  time: 0.1918  data: 0.0001  max mem: 14938
[16:42:57.424713] Test:  [260/345]  eta: 0:00:16  loss: 0.7285 (0.7258)  time: 0.1922  data: 0.0001  max mem: 14938
[16:42:59.352868] Test:  [270/345]  eta: 0:00:14  loss: 0.7238 (0.7257)  time: 0.1926  data: 0.0001  max mem: 14938
[16:43:01.285337] Test:  [280/345]  eta: 0:00:12  loss: 0.7264 (0.7257)  time: 0.1930  data: 0.0001  max mem: 14938
[16:43:03.220063] Test:  [290/345]  eta: 0:00:10  loss: 0.7264 (0.7256)  time: 0.1933  data: 0.0001  max mem: 14938
[16:43:05.157367] Test:  [300/345]  eta: 0:00:08  loss: 0.7189 (0.7254)  time: 0.1936  data: 0.0001  max mem: 14938
[16:43:07.098657] Test:  [310/345]  eta: 0:00:06  loss: 0.7183 (0.7252)  time: 0.1939  data: 0.0001  max mem: 14938
[16:43:09.042814] Test:  [320/345]  eta: 0:00:04  loss: 0.7252 (0.7253)  time: 0.1942  data: 0.0001  max mem: 14938
[16:43:10.989748] Test:  [330/345]  eta: 0:00:02  loss: 0.7289 (0.7254)  time: 0.1945  data: 0.0001  max mem: 14938
[16:43:12.940839] Test:  [340/345]  eta: 0:00:00  loss: 0.7320 (0.7256)  time: 0.1949  data: 0.0001  max mem: 14938
[16:43:13.722660] Test:  [344/345]  eta: 0:00:00  loss: 0.7320 (0.7257)  time: 0.1950  data: 0.0001  max mem: 14938
[16:43:13.784113] Test: Total time: 0:01:05 (0.1901 s / it)
[16:43:24.650639] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8331 (0.8331)  time: 0.3249  data: 0.1453  max mem: 14938
[16:43:26.466616] Test:  [10/57]  eta: 0:00:09  loss: 0.8862 (0.8810)  time: 0.1946  data: 0.0133  max mem: 14938
[16:43:28.287192] Test:  [20/57]  eta: 0:00:06  loss: 0.8862 (0.8674)  time: 0.1818  data: 0.0001  max mem: 14938
[16:43:30.112078] Test:  [30/57]  eta: 0:00:05  loss: 0.7689 (0.8279)  time: 0.1822  data: 0.0001  max mem: 14938
[16:43:31.943131] Test:  [40/57]  eta: 0:00:03  loss: 0.7443 (0.8074)  time: 0.1827  data: 0.0001  max mem: 14938
[16:43:33.779531] Test:  [50/57]  eta: 0:00:01  loss: 0.7432 (0.7995)  time: 0.1833  data: 0.0001  max mem: 14938
[16:43:34.769966] Test:  [56/57]  eta: 0:00:00  loss: 0.7592 (0.8044)  time: 0.1779  data: 0.0001  max mem: 14938
[16:43:34.827703] Test: Total time: 0:00:10 (0.1843 s / it)
[16:43:36.722485] Dice score of the network on the train images: 0.798506, val images: 0.821180
[16:43:36.722726] saving best_dice_model_0 @ epoch 25
[16:43:37.768737] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:43:38.664037] Epoch: [26]  [  0/345]  eta: 0:05:08  lr: 0.000113  loss: 0.7305 (0.7305)  time: 0.8944  data: 0.1520  max mem: 14938
[16:43:53.538445] Epoch: [26]  [ 20/345]  eta: 0:04:04  lr: 0.000113  loss: 0.7600 (0.7558)  time: 0.7437  data: 0.0001  max mem: 14938
[16:44:08.446420] Epoch: [26]  [ 40/345]  eta: 0:03:48  lr: 0.000113  loss: 0.7688 (0.7628)  time: 0.7454  data: 0.0001  max mem: 14938
[16:44:23.405488] Epoch: [26]  [ 60/345]  eta: 0:03:33  lr: 0.000112  loss: 0.7731 (0.7666)  time: 0.7479  data: 0.0001  max mem: 14938
[16:44:38.391111] Epoch: [26]  [ 80/345]  eta: 0:03:18  lr: 0.000112  loss: 0.7581 (0.7648)  time: 0.7492  data: 0.0001  max mem: 14938
[16:44:53.402079] Epoch: [26]  [100/345]  eta: 0:03:03  lr: 0.000112  loss: 0.7439 (0.7624)  time: 0.7505  data: 0.0001  max mem: 14938
[16:45:08.430895] Epoch: [26]  [120/345]  eta: 0:02:48  lr: 0.000112  loss: 0.7534 (0.7615)  time: 0.7514  data: 0.0001  max mem: 14938
[16:45:23.449912] Epoch: [26]  [140/345]  eta: 0:02:33  lr: 0.000111  loss: 0.7438 (0.7595)  time: 0.7509  data: 0.0001  max mem: 14938
[16:45:38.464366] Epoch: [26]  [160/345]  eta: 0:02:18  lr: 0.000111  loss: 0.7520 (0.7589)  time: 0.7507  data: 0.0001  max mem: 14938
[16:45:53.469286] Epoch: [26]  [180/345]  eta: 0:02:03  lr: 0.000111  loss: 0.7552 (0.7589)  time: 0.7502  data: 0.0001  max mem: 14938
[16:46:08.461636] Epoch: [26]  [200/345]  eta: 0:01:48  lr: 0.000111  loss: 0.7531 (0.7586)  time: 0.7496  data: 0.0001  max mem: 14938
[16:46:23.451500] Epoch: [26]  [220/345]  eta: 0:01:33  lr: 0.000110  loss: 0.7485 (0.7578)  time: 0.7494  data: 0.0001  max mem: 14938
[16:46:38.433621] Epoch: [26]  [240/345]  eta: 0:01:18  lr: 0.000110  loss: 0.7565 (0.7579)  time: 0.7491  data: 0.0001  max mem: 14938
[16:46:53.421662] Epoch: [26]  [260/345]  eta: 0:01:03  lr: 0.000110  loss: 0.7491 (0.7573)  time: 0.7494  data: 0.0001  max mem: 14938

[16:47:08.394646] Epoch: [26]  [280/345]  eta: 0:00:48  lr: 0.000110  loss: 0.7496 (0.7571)  time: 0.7486  data: 0.0001  max mem: 14938
[16:47:23.383077] Epoch: [26]  [300/345]  eta: 0:00:33  lr: 0.000110  loss: 0.7505 (0.7569)  time: 0.7494  data: 0.0001  max mem: 14938
[16:47:38.352306] Epoch: [26]  [320/345]  eta: 0:00:18  lr: 0.000109  loss: 0.7690 (0.7576)  time: 0.7484  data: 0.0001  max mem: 14938
[16:47:53.326861] Epoch: [26]  [340/345]  eta: 0:00:03  lr: 0.000109  loss: 0.7634 (0.7578)  time: 0.7487  data: 0.0001  max mem: 14938
[16:47:56.324199] Epoch: [26]  [344/345]  eta: 0:00:00  lr: 0.000109  loss: 0.7536 (0.7576)  time: 0.7487  data: 0.0001  max mem: 14938
[16:47:56.391743] Epoch: [26] Total time: 0:04:18 (0.7496 s / it)
[16:47:56.392252] Averaged stats: lr: 0.000109  loss: 0.7536 (0.7576)
[16:47:56.738478] Test:  [  0/345]  eta: 0:01:58  loss: 0.7223 (0.7223)  time: 0.3423  data: 0.1608  max mem: 14938
[16:47:58.575467] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7302 (0.7317)  time: 0.1981  data: 0.0147  max mem: 14938
[16:48:00.415378] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7323 (0.7338)  time: 0.1838  data: 0.0001  max mem: 14938
[16:48:02.259039] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7356 (0.7343)  time: 0.1841  data: 0.0001  max mem: 14938
[16:48:04.107289] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7288 (0.7320)  time: 0.1845  data: 0.0001  max mem: 14938
[16:48:05.959049] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7320 (0.7325)  time: 0.1850  data: 0.0001  max mem: 14938
[16:48:07.812817] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7320 (0.7322)  time: 0.1852  data: 0.0001  max mem: 14938
[16:48:09.668983] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7317 (0.7332)  time: 0.1854  data: 0.0001  max mem: 14938
[16:48:11.528112] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7302 (0.7329)  time: 0.1857  data: 0.0001  max mem: 14938
[16:48:13.391034] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7282 (0.7322)  time: 0.1860  data: 0.0001  max mem: 14938
[16:48:15.259137] Test:  [100/345]  eta: 0:00:45  loss: 0.7326 (0.7330)  time: 0.1865  data: 0.0001  max mem: 14938
[16:48:17.130814] Test:  [110/345]  eta: 0:00:43  loss: 0.7376 (0.7333)  time: 0.1869  data: 0.0001  max mem: 14938
[16:48:19.004683] Test:  [120/345]  eta: 0:00:42  loss: 0.7334 (0.7329)  time: 0.1872  data: 0.0001  max mem: 14938
[16:48:20.882969] Test:  [130/345]  eta: 0:00:40  loss: 0.7309 (0.7333)  time: 0.1876  data: 0.0001  max mem: 14938
[16:48:22.764623] Test:  [140/345]  eta: 0:00:38  loss: 0.7308 (0.7330)  time: 0.1879  data: 0.0001  max mem: 14938
[16:48:24.648867] Test:  [150/345]  eta: 0:00:36  loss: 0.7321 (0.7335)  time: 0.1882  data: 0.0001  max mem: 14938
[16:48:26.535074] Test:  [160/345]  eta: 0:00:34  loss: 0.7228 (0.7325)  time: 0.1885  data: 0.0001  max mem: 14938
[16:48:28.425772] Test:  [170/345]  eta: 0:00:32  loss: 0.7189 (0.7321)  time: 0.1888  data: 0.0001  max mem: 14938
[16:48:30.320304] Test:  [180/345]  eta: 0:00:30  loss: 0.7286 (0.7321)  time: 0.1892  data: 0.0001  max mem: 14938
[16:48:32.220567] Test:  [190/345]  eta: 0:00:29  loss: 0.7286 (0.7319)  time: 0.1897  data: 0.0001  max mem: 14938
[16:48:34.120867] Test:  [200/345]  eta: 0:00:27  loss: 0.7286 (0.7320)  time: 0.1900  data: 0.0001  max mem: 14938
[16:48:36.027168] Test:  [210/345]  eta: 0:00:25  loss: 0.7294 (0.7320)  time: 0.1903  data: 0.0001  max mem: 14938
[16:48:37.936784] Test:  [220/345]  eta: 0:00:23  loss: 0.7318 (0.7322)  time: 0.1907  data: 0.0001  max mem: 14938
[16:48:39.851156] Test:  [230/345]  eta: 0:00:21  loss: 0.7323 (0.7321)  time: 0.1911  data: 0.0001  max mem: 14938
[16:48:41.767893] Test:  [240/345]  eta: 0:00:19  loss: 0.7340 (0.7321)  time: 0.1915  data: 0.0001  max mem: 14938
[16:48:43.687605] Test:  [250/345]  eta: 0:00:17  loss: 0.7276 (0.7320)  time: 0.1918  data: 0.0001  max mem: 14938
[16:48:45.611596] Test:  [260/345]  eta: 0:00:16  loss: 0.7245 (0.7318)  time: 0.1921  data: 0.0001  max mem: 14938
[16:48:47.538858] Test:  [270/345]  eta: 0:00:14  loss: 0.7288 (0.7319)  time: 0.1925  data: 0.0001  max mem: 14938
[16:48:49.469610] Test:  [280/345]  eta: 0:00:12  loss: 0.7314 (0.7318)  time: 0.1929  data: 0.0001  max mem: 14938
[16:48:51.402998] Test:  [290/345]  eta: 0:00:10  loss: 0.7323 (0.7318)  time: 0.1932  data: 0.0001  max mem: 14938
[16:48:53.339670] Test:  [300/345]  eta: 0:00:08  loss: 0.7295 (0.7318)  time: 0.1935  data: 0.0001  max mem: 14938
[16:48:55.279615] Test:  [310/345]  eta: 0:00:06  loss: 0.7361 (0.7320)  time: 0.1938  data: 0.0001  max mem: 14938
[16:48:57.224086] Test:  [320/345]  eta: 0:00:04  loss: 0.7275 (0.7318)  time: 0.1942  data: 0.0001  max mem: 14938
[16:48:59.170277] Test:  [330/345]  eta: 0:00:02  loss: 0.7245 (0.7316)  time: 0.1945  data: 0.0001  max mem: 14938
[16:49:01.120189] Test:  [340/345]  eta: 0:00:00  loss: 0.7221 (0.7315)  time: 0.1948  data: 0.0001  max mem: 14938
[16:49:01.901549] Test:  [344/345]  eta: 0:00:00  loss: 0.7221 (0.7314)  time: 0.1949  data: 0.0001  max mem: 14938
[16:49:01.963441] Test: Total time: 0:01:05 (0.1901 s / it)
[16:49:12.716202] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8666 (0.8666)  time: 0.3255  data: 0.1456  max mem: 14938
[16:49:14.533137] Test:  [10/57]  eta: 0:00:09  loss: 0.8903 (0.8839)  time: 0.1947  data: 0.0133  max mem: 14938
[16:49:16.355044] Test:  [20/57]  eta: 0:00:06  loss: 0.8903 (0.8684)  time: 0.1819  data: 0.0001  max mem: 14938
[16:49:18.179240] Test:  [30/57]  eta: 0:00:05  loss: 0.7557 (0.8300)  time: 0.1823  data: 0.0001  max mem: 14938
[16:49:20.010347] Test:  [40/57]  eta: 0:00:03  loss: 0.7450 (0.8089)  time: 0.1827  data: 0.0001  max mem: 14938
[16:49:21.846724] Test:  [50/57]  eta: 0:00:01  loss: 0.7427 (0.8007)  time: 0.1833  data: 0.0001  max mem: 14938
[16:49:22.836475] Test:  [56/57]  eta: 0:00:00  loss: 0.7613 (0.8061)  time: 0.1779  data: 0.0001  max mem: 14938
[16:49:22.895999] Test: Total time: 0:00:10 (0.1843 s / it)
[16:49:24.801508] Dice score of the network on the train images: 0.787467, val images: 0.818062
[16:49:24.805623] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:49:25.696028] Epoch: [27]  [  0/345]  eta: 0:05:06  lr: 0.000109  loss: 0.7696 (0.7696)  time: 0.8894  data: 0.1495  max mem: 14938
[16:49:40.567533] Epoch: [27]  [ 20/345]  eta: 0:04:03  lr: 0.000109  loss: 0.7586 (0.7637)  time: 0.7435  data: 0.0001  max mem: 14938
[16:49:55.477545] Epoch: [27]  [ 40/345]  eta: 0:03:48  lr: 0.000108  loss: 0.7595 (0.7629)  time: 0.7455  data: 0.0001  max mem: 14938
[16:50:10.437008] Epoch: [27]  [ 60/345]  eta: 0:03:33  lr: 0.000108  loss: 0.7573 (0.7611)  time: 0.7479  data: 0.0001  max mem: 14938
[16:50:25.412177] Epoch: [27]  [ 80/345]  eta: 0:03:18  lr: 0.000108  loss: 0.7696 (0.7647)  time: 0.7487  data: 0.0001  max mem: 14938
[16:50:40.413505] Epoch: [27]  [100/345]  eta: 0:03:03  lr: 0.000108  loss: 0.7669 (0.7648)  time: 0.7500  data: 0.0001  max mem: 14938
[16:50:55.429314] Epoch: [27]  [120/345]  eta: 0:02:48  lr: 0.000107  loss: 0.7518 (0.7632)  time: 0.7507  data: 0.0001  max mem: 14938
[16:51:10.426954] Epoch: [27]  [140/345]  eta: 0:02:33  lr: 0.000107  loss: 0.7536 (0.7614)  time: 0.7498  data: 0.0001  max mem: 14938
[16:51:25.443651] Epoch: [27]  [160/345]  eta: 0:02:18  lr: 0.000107  loss: 0.7439 (0.7598)  time: 0.7508  data: 0.0001  max mem: 14938
[16:51:40.461775] Epoch: [27]  [180/345]  eta: 0:02:03  lr: 0.000107  loss: 0.7430 (0.7583)  time: 0.7509  data: 0.0001  max mem: 14938
[16:51:55.468951] Epoch: [27]  [200/345]  eta: 0:01:48  lr: 0.000106  loss: 0.7478 (0.7573)  time: 0.7503  data: 0.0001  max mem: 14938
[16:52:10.475673] Epoch: [27]  [220/345]  eta: 0:01:33  lr: 0.000106  loss: 0.7446 (0.7562)  time: 0.7503  data: 0.0001  max mem: 14938
[16:52:25.468284] Epoch: [27]  [240/345]  eta: 0:01:18  lr: 0.000106  loss: 0.7453 (0.7552)  time: 0.7496  data: 0.0001  max mem: 14938
[16:52:40.459823] Epoch: [27]  [260/345]  eta: 0:01:03  lr: 0.000106  loss: 0.7441 (0.7548)  time: 0.7495  data: 0.0001  max mem: 14938
[16:52:55.449151] Epoch: [27]  [280/345]  eta: 0:00:48  lr: 0.000105  loss: 0.7471 (0.7545)  time: 0.7494  data: 0.0001  max mem: 14938
[16:53:10.434133] Epoch: [27]  [300/345]  eta: 0:00:33  lr: 0.000105  loss: 0.7385 (0.7537)  time: 0.7492  data: 0.0001  max mem: 14938
[16:53:25.417451] Epoch: [27]  [320/345]  eta: 0:00:18  lr: 0.000105  loss: 0.7381 (0.7529)  time: 0.7491  data: 0.0001  max mem: 14938
[16:53:40.399243] Epoch: [27]  [340/345]  eta: 0:00:03  lr: 0.000104  loss: 0.7431 (0.7525)  time: 0.7490  data: 0.0001  max mem: 14938
[16:53:43.398374] Epoch: [27]  [344/345]  eta: 0:00:00  lr: 0.000104  loss: 0.7434 (0.7524)  time: 0.7490  data: 0.0001  max mem: 14938
[16:53:43.467151] Epoch: [27] Total time: 0:04:18 (0.7497 s / it)
[16:53:43.467406] Averaged stats: lr: 0.000104  loss: 0.7434 (0.7524)
[16:53:43.816500] Test:  [  0/345]  eta: 0:01:58  loss: 0.7218 (0.7218)  time: 0.3449  data: 0.1637  max mem: 14938
[16:53:45.653074] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7218 (0.7250)  time: 0.1982  data: 0.0149  max mem: 14938
[16:53:47.491604] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7161 (0.7183)  time: 0.1837  data: 0.0001  max mem: 14938
[16:53:49.335216] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7161 (0.7182)  time: 0.1841  data: 0.0001  max mem: 14938
[16:53:51.181478] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7186 (0.7187)  time: 0.1844  data: 0.0001  max mem: 14938
[16:53:53.031837] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7157 (0.7184)  time: 0.1848  data: 0.0001  max mem: 14938
[16:53:54.885062] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7177 (0.7190)  time: 0.1851  data: 0.0001  max mem: 14938
[16:53:56.741934] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7226 (0.7196)  time: 0.1855  data: 0.0001  max mem: 14938
[16:53:58.602890] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7183 (0.7197)  time: 0.1858  data: 0.0001  max mem: 14938
[16:54:00.466220] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7200 (0.7200)  time: 0.1862  data: 0.0001  max mem: 14938
[16:54:02.334402] Test:  [100/345]  eta: 0:00:45  loss: 0.7211 (0.7205)  time: 0.1865  data: 0.0001  max mem: 14938
[16:54:04.204107] Test:  [110/345]  eta: 0:00:43  loss: 0.7188 (0.7206)  time: 0.1868  data: 0.0001  max mem: 14938
[16:54:06.079026] Test:  [120/345]  eta: 0:00:42  loss: 0.7164 (0.7208)  time: 0.1872  data: 0.0001  max mem: 14938
[16:54:07.956513] Test:  [130/345]  eta: 0:00:40  loss: 0.7202 (0.7213)  time: 0.1876  data: 0.0001  max mem: 14938
[16:54:09.837811] Test:  [140/345]  eta: 0:00:38  loss: 0.7202 (0.7210)  time: 0.1879  data: 0.0001  max mem: 14938
[16:54:11.724535] Test:  [150/345]  eta: 0:00:36  loss: 0.7145 (0.7206)  time: 0.1884  data: 0.0001  max mem: 14938
[16:54:13.612510] Test:  [160/345]  eta: 0:00:34  loss: 0.7168 (0.7206)  time: 0.1887  data: 0.0001  max mem: 14938
[16:54:15.504676] Test:  [170/345]  eta: 0:00:32  loss: 0.7190 (0.7204)  time: 0.1890  data: 0.0001  max mem: 14938
[16:54:17.402473] Test:  [180/345]  eta: 0:00:30  loss: 0.7146 (0.7201)  time: 0.1894  data: 0.0001  max mem: 14938
[16:54:19.302383] Test:  [190/345]  eta: 0:00:29  loss: 0.7130 (0.7198)  time: 0.1898  data: 0.0001  max mem: 14938
[16:54:21.205679] Test:  [200/345]  eta: 0:00:27  loss: 0.7155 (0.7196)  time: 0.1901  data: 0.0001  max mem: 14938
[16:54:23.110687] Test:  [210/345]  eta: 0:00:25  loss: 0.7175 (0.7196)  time: 0.1904  data: 0.0001  max mem: 14938
[16:54:25.020951] Test:  [220/345]  eta: 0:00:23  loss: 0.7186 (0.7197)  time: 0.1907  data: 0.0001  max mem: 14938
[16:54:26.934303] Test:  [230/345]  eta: 0:00:21  loss: 0.7229 (0.7201)  time: 0.1911  data: 0.0001  max mem: 14938
[16:54:28.853142] Test:  [240/345]  eta: 0:00:19  loss: 0.7232 (0.7201)  time: 0.1916  data: 0.0001  max mem: 14938
[16:54:30.776072] Test:  [250/345]  eta: 0:00:17  loss: 0.7183 (0.7202)  time: 0.1920  data: 0.0001  max mem: 14938
[16:54:32.699976] Test:  [260/345]  eta: 0:00:16  loss: 0.7127 (0.7198)  time: 0.1923  data: 0.0001  max mem: 14938
[16:54:34.626755] Test:  [270/345]  eta: 0:00:14  loss: 0.7107 (0.7198)  time: 0.1925  data: 0.0001  max mem: 14938
[16:54:36.557358] Test:  [280/345]  eta: 0:00:12  loss: 0.7173 (0.7198)  time: 0.1928  data: 0.0001  max mem: 14938
[16:54:38.490770] Test:  [290/345]  eta: 0:00:10  loss: 0.7171 (0.7198)  time: 0.1932  data: 0.0001  max mem: 14938
[16:54:40.428660] Test:  [300/345]  eta: 0:00:08  loss: 0.7171 (0.7198)  time: 0.1935  data: 0.0001  max mem: 14938
[16:54:42.368600] Test:  [310/345]  eta: 0:00:06  loss: 0.7205 (0.7201)  time: 0.1938  data: 0.0001  max mem: 14938
[16:54:44.315408] Test:  [320/345]  eta: 0:00:04  loss: 0.7205 (0.7201)  time: 0.1943  data: 0.0001  max mem: 14938
[16:54:46.262426] Test:  [330/345]  eta: 0:00:02  loss: 0.7193 (0.7200)  time: 0.1946  data: 0.0001  max mem: 14938
[16:54:48.213785] Test:  [340/345]  eta: 0:00:00  loss: 0.7202 (0.7200)  time: 0.1949  data: 0.0001  max mem: 14938
[16:54:48.994848] Test:  [344/345]  eta: 0:00:00  loss: 0.7191 (0.7200)  time: 0.1950  data: 0.0001  max mem: 14938
[16:54:49.055080] Test: Total time: 0:01:05 (0.1901 s / it)
[16:54:59.794509] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8148 (0.8148)  time: 0.3311  data: 0.1509  max mem: 14938
[16:55:01.610146] Test:  [10/57]  eta: 0:00:09  loss: 0.8872 (0.8803)  time: 0.1951  data: 0.0138  max mem: 14938
[16:55:03.431994] Test:  [20/57]  eta: 0:00:06  loss: 0.8871 (0.8680)  time: 0.1818  data: 0.0001  max mem: 14938
[16:55:05.258863] Test:  [30/57]  eta: 0:00:05  loss: 0.7578 (0.8286)  time: 0.1824  data: 0.0001  max mem: 14938
[16:55:07.086974] Test:  [40/57]  eta: 0:00:03  loss: 0.7429 (0.8073)  time: 0.1827  data: 0.0001  max mem: 14938
[16:55:08.921499] Test:  [50/57]  eta: 0:00:01  loss: 0.7376 (0.8000)  time: 0.1831  data: 0.0001  max mem: 14938
[16:55:09.910376] Test:  [56/57]  eta: 0:00:00  loss: 0.7639 (0.8056)  time: 0.1777  data: 0.0001  max mem: 14938
[16:55:09.972186] Test: Total time: 0:00:10 (0.1844 s / it)
[16:55:11.874607] Dice score of the network on the train images: 0.801570, val images: 0.819789
[16:55:11.878937] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:55:12.898761] Epoch: [28]  [  0/345]  eta: 0:05:51  lr: 0.000104  loss: 0.7269 (0.7269)  time: 1.0188  data: 0.1496  max mem: 14938
[16:55:27.783585] Epoch: [28]  [ 20/345]  eta: 0:04:06  lr: 0.000104  loss: 0.7409 (0.7439)  time: 0.7442  data: 0.0001  max mem: 14938
[16:55:42.712190] Epoch: [28]  [ 40/345]  eta: 0:03:49  lr: 0.000104  loss: 0.7423 (0.7437)  time: 0.7464  data: 0.0001  max mem: 14938
[16:55:57.686634] Epoch: [28]  [ 60/345]  eta: 0:03:34  lr: 0.000103  loss: 0.7343 (0.7415)  time: 0.7487  data: 0.0001  max mem: 14938
[16:56:12.681754] Epoch: [28]  [ 80/345]  eta: 0:03:18  lr: 0.000103  loss: 0.7440 (0.7423)  time: 0.7497  data: 0.0001  max mem: 14938
[16:56:27.708689] Epoch: [28]  [100/345]  eta: 0:03:03  lr: 0.000103  loss: 0.7508 (0.7443)  time: 0.7513  data: 0.0001  max mem: 14938
[16:56:42.747754] Epoch: [28]  [120/345]  eta: 0:02:48  lr: 0.000103  loss: 0.7467 (0.7447)  time: 0.7519  data: 0.0001  max mem: 14938
[16:56:57.785191] Epoch: [28]  [140/345]  eta: 0:02:33  lr: 0.000102  loss: 0.7416 (0.7443)  time: 0.7518  data: 0.0001  max mem: 14938
[16:57:12.819992] Epoch: [28]  [160/345]  eta: 0:02:18  lr: 0.000102  loss: 0.7446 (0.7448)  time: 0.7517  data: 0.0001  max mem: 14938
[16:57:27.844111] Epoch: [28]  [180/345]  eta: 0:02:03  lr: 0.000102  loss: 0.7576 (0.7464)  time: 0.7512  data: 0.0001  max mem: 14938
[16:57:42.863941] Epoch: [28]  [200/345]  eta: 0:01:48  lr: 0.000101  loss: 0.7523 (0.7470)  time: 0.7509  data: 0.0001  max mem: 14938
[16:57:57.868134] Epoch: [28]  [220/345]  eta: 0:01:33  lr: 0.000101  loss: 0.7460 (0.7468)  time: 0.7502  data: 0.0001  max mem: 14938
[16:58:12.862836] Epoch: [28]  [240/345]  eta: 0:01:18  lr: 0.000101  loss: 0.7415 (0.7466)  time: 0.7497  data: 0.0001  max mem: 14938
[16:58:27.857359] Epoch: [28]  [260/345]  eta: 0:01:03  lr: 0.000101  loss: 0.7478 (0.7466)  time: 0.7497  data: 0.0001  max mem: 14938
[16:58:42.848609] Epoch: [28]  [280/345]  eta: 0:00:48  lr: 0.000100  loss: 0.7429 (0.7466)  time: 0.7495  data: 0.0001  max mem: 14938
[16:58:57.831015] Epoch: [28]  [300/345]  eta: 0:00:33  lr: 0.000100  loss: 0.7408 (0.7463)  time: 0.7491  data: 0.0001  max mem: 14938
[16:59:12.795444] Epoch: [28]  [320/345]  eta: 0:00:18  lr: 0.000100  loss: 0.7529 (0.7467)  time: 0.7482  data: 0.0001  max mem: 14938
[16:59:27.765616] Epoch: [28]  [340/345]  eta: 0:00:03  lr: 0.000099  loss: 0.7451 (0.7468)  time: 0.7485  data: 0.0001  max mem: 14938
[16:59:30.762994] Epoch: [28]  [344/345]  eta: 0:00:00  lr: 0.000099  loss: 0.7493 (0.7469)  time: 0.7487  data: 0.0001  max mem: 14938
[16:59:30.826064] Epoch: [28] Total time: 0:04:18 (0.7506 s / it)
[16:59:30.826468] Averaged stats: lr: 0.000099  loss: 0.7493 (0.7469)
[16:59:31.175656] Test:  [  0/345]  eta: 0:01:59  loss: 0.7283 (0.7283)  time: 0.3453  data: 0.1634  max mem: 14938
[16:59:33.011542] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7310 (0.7320)  time: 0.1982  data: 0.0149  max mem: 14938
[16:59:34.851424] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7362 (0.7349)  time: 0.1837  data: 0.0001  max mem: 14938
[16:59:36.692810] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7362 (0.7344)  time: 0.1840  data: 0.0001  max mem: 14938
[16:59:38.540175] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7312 (0.7352)  time: 0.1844  data: 0.0001  max mem: 14938
[16:59:40.391531] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7309 (0.7340)  time: 0.1849  data: 0.0001  max mem: 14938
[16:59:42.244419] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7203 (0.7310)  time: 0.1852  data: 0.0001  max mem: 14938
[16:59:44.100221] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7187 (0.7307)  time: 0.1854  data: 0.0001  max mem: 14938
[16:59:45.958340] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7245 (0.7301)  time: 0.1856  data: 0.0001  max mem: 14938
[16:59:47.822601] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7222 (0.7294)  time: 0.1861  data: 0.0001  max mem: 14938
[16:59:49.689881] Test:  [100/345]  eta: 0:00:45  loss: 0.7277 (0.7298)  time: 0.1865  data: 0.0001  max mem: 14938
[16:59:51.559215] Test:  [110/345]  eta: 0:00:43  loss: 0.7320 (0.7301)  time: 0.1868  data: 0.0001  max mem: 14938
[16:59:53.432676] Test:  [120/345]  eta: 0:00:42  loss: 0.7289 (0.7299)  time: 0.1871  data: 0.0001  max mem: 14938
[16:59:55.312017] Test:  [130/345]  eta: 0:00:40  loss: 0.7308 (0.7306)  time: 0.1876  data: 0.0001  max mem: 14938
[16:59:57.193578] Test:  [140/345]  eta: 0:00:38  loss: 0.7350 (0.7303)  time: 0.1880  data: 0.0001  max mem: 14938
[16:59:59.078776] Test:  [150/345]  eta: 0:00:36  loss: 0.7315 (0.7304)  time: 0.1883  data: 0.0001  max mem: 14938
[17:00:00.967727] Test:  [160/345]  eta: 0:00:34  loss: 0.7294 (0.7301)  time: 0.1887  data: 0.0001  max mem: 14938
[17:00:02.858705] Test:  [170/345]  eta: 0:00:32  loss: 0.7293 (0.7306)  time: 0.1889  data: 0.0001  max mem: 14938
[17:00:04.753943] Test:  [180/345]  eta: 0:00:30  loss: 0.7285 (0.7306)  time: 0.1893  data: 0.0001  max mem: 14938
[17:00:06.654701] Test:  [190/345]  eta: 0:00:29  loss: 0.7240 (0.7303)  time: 0.1898  data: 0.0001  max mem: 14938
[17:00:08.556766] Test:  [200/345]  eta: 0:00:27  loss: 0.7238 (0.7301)  time: 0.1901  data: 0.0001  max mem: 14938
[17:00:10.464690] Test:  [210/345]  eta: 0:00:25  loss: 0.7296 (0.7302)  time: 0.1905  data: 0.0001  max mem: 14938
[17:00:12.373857] Test:  [220/345]  eta: 0:00:23  loss: 0.7282 (0.7300)  time: 0.1908  data: 0.0001  max mem: 14938
[17:00:14.288691] Test:  [230/345]  eta: 0:00:21  loss: 0.7243 (0.7299)  time: 0.1912  data: 0.0001  max mem: 14938
[17:00:16.206738] Test:  [240/345]  eta: 0:00:19  loss: 0.7257 (0.7300)  time: 0.1916  data: 0.0001  max mem: 14938
[17:00:18.127477] Test:  [250/345]  eta: 0:00:17  loss: 0.7327 (0.7301)  time: 0.1919  data: 0.0001  max mem: 14938
[17:00:20.050965] Test:  [260/345]  eta: 0:00:16  loss: 0.7197 (0.7297)  time: 0.1922  data: 0.0001  max mem: 14938
[17:00:21.978658] Test:  [270/345]  eta: 0:00:14  loss: 0.7168 (0.7292)  time: 0.1925  data: 0.0001  max mem: 14938
[17:00:23.909960] Test:  [280/345]  eta: 0:00:12  loss: 0.7229 (0.7292)  time: 0.1929  data: 0.0001  max mem: 14938
[17:00:25.844338] Test:  [290/345]  eta: 0:00:10  loss: 0.7343 (0.7295)  time: 0.1932  data: 0.0001  max mem: 14938
[17:00:27.783197] Test:  [300/345]  eta: 0:00:08  loss: 0.7264 (0.7292)  time: 0.1936  data: 0.0001  max mem: 14938
[17:00:29.725133] Test:  [310/345]  eta: 0:00:06  loss: 0.7159 (0.7290)  time: 0.1940  data: 0.0001  max mem: 14938
[17:00:31.668653] Test:  [320/345]  eta: 0:00:04  loss: 0.7187 (0.7288)  time: 0.1942  data: 0.0001  max mem: 14938
[17:00:33.616167] Test:  [330/345]  eta: 0:00:02  loss: 0.7234 (0.7288)  time: 0.1945  data: 0.0001  max mem: 14938
[17:00:35.567095] Test:  [340/345]  eta: 0:00:00  loss: 0.7253 (0.7289)  time: 0.1949  data: 0.0001  max mem: 14938
[17:00:36.348749] Test:  [344/345]  eta: 0:00:00  loss: 0.7252 (0.7290)  time: 0.1950  data: 0.0001  max mem: 14938
[17:00:36.410443] Test: Total time: 0:01:05 (0.1901 s / it)
[17:00:47.150544] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8788 (0.8788)  time: 0.3282  data: 0.1481  max mem: 14938
[17:00:48.967246] Test:  [10/57]  eta: 0:00:09  loss: 0.8881 (0.8857)  time: 0.1949  data: 0.0135  max mem: 14938
[17:00:50.789020] Test:  [20/57]  eta: 0:00:06  loss: 0.8881 (0.8768)  time: 0.1819  data: 0.0001  max mem: 14938
[17:00:52.615731] Test:  [30/57]  eta: 0:00:05  loss: 0.7769 (0.8357)  time: 0.1824  data: 0.0001  max mem: 14938
[17:00:54.447012] Test:  [40/57]  eta: 0:00:03  loss: 0.7357 (0.8144)  time: 0.1828  data: 0.0001  max mem: 14938
[17:00:56.283074] Test:  [50/57]  eta: 0:00:01  loss: 0.7399 (0.8111)  time: 0.1833  data: 0.0001  max mem: 14938
[17:00:57.274155] Test:  [56/57]  eta: 0:00:00  loss: 0.7980 (0.8178)  time: 0.1780  data: 0.0001  max mem: 14938
[17:00:57.334657] Test: Total time: 0:00:10 (0.1844 s / it)
[17:00:59.174461] Dice score of the network on the train images: 0.781044, val images: 0.808770
[17:00:59.179524] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:01:00.069102] Epoch: [29]  [  0/345]  eta: 0:05:06  lr: 0.000099  loss: 0.7478 (0.7478)  time: 0.8885  data: 0.1454  max mem: 14938
[17:01:14.957040] Epoch: [29]  [ 20/345]  eta: 0:04:04  lr: 0.000099  loss: 0.7478 (0.7484)  time: 0.7443  data: 0.0001  max mem: 14938
[17:01:29.891010] Epoch: [29]  [ 40/345]  eta: 0:03:48  lr: 0.000099  loss: 0.7507 (0.7506)  time: 0.7466  data: 0.0001  max mem: 14938
[17:01:45.000296] Epoch: [29]  [ 60/345]  eta: 0:03:34  lr: 0.000098  loss: 0.7352 (0.7461)  time: 0.7554  data: 0.0001  max mem: 14938

[17:01:59.976492] Epoch: [29]  [ 80/345]  eta: 0:03:18  lr: 0.000098  loss: 0.7442 (0.7457)  time: 0.7488  data: 0.0001  max mem: 14938
[17:02:14.997072] Epoch: [29]  [100/345]  eta: 0:03:03  lr: 0.000098  loss: 0.7423 (0.7450)  time: 0.7510  data: 0.0001  max mem: 14938
[17:02:30.057770] Epoch: [29]  [120/345]  eta: 0:02:48  lr: 0.000097  loss: 0.7399 (0.7440)  time: 0.7530  data: 0.0001  max mem: 14938
[17:02:45.106737] Epoch: [29]  [140/345]  eta: 0:02:33  lr: 0.000097  loss: 0.7427 (0.7439)  time: 0.7524  data: 0.0001  max mem: 14938
[17:03:00.131715] Epoch: [29]  [160/345]  eta: 0:02:18  lr: 0.000097  loss: 0.7425 (0.7438)  time: 0.7512  data: 0.0001  max mem: 14938
[17:03:15.149101] Epoch: [29]  [180/345]  eta: 0:02:03  lr: 0.000096  loss: 0.7357 (0.7430)  time: 0.7508  data: 0.0001  max mem: 14938
[17:03:30.159277] Epoch: [29]  [200/345]  eta: 0:01:48  lr: 0.000096  loss: 0.7403 (0.7428)  time: 0.7505  data: 0.0001  max mem: 14938
[17:03:45.163840] Epoch: [29]  [220/345]  eta: 0:01:33  lr: 0.000096  loss: 0.7378 (0.7424)  time: 0.7502  data: 0.0001  max mem: 14938
[17:04:00.158416] Epoch: [29]  [240/345]  eta: 0:01:18  lr: 0.000095  loss: 0.7436 (0.7429)  time: 0.7497  data: 0.0001  max mem: 14938
[17:04:15.153693] Epoch: [29]  [260/345]  eta: 0:01:03  lr: 0.000095  loss: 0.7429 (0.7430)  time: 0.7497  data: 0.0001  max mem: 14938

[17:04:30.149800] Epoch: [29]  [280/345]  eta: 0:00:48  lr: 0.000095  loss: 0.7473 (0.7437)  time: 0.7498  data: 0.0001  max mem: 14938
[17:04:45.140742] Epoch: [29]  [300/345]  eta: 0:00:33  lr: 0.000094  loss: 0.7555 (0.7443)  time: 0.7495  data: 0.0001  max mem: 14938
[17:05:00.131119] Epoch: [29]  [320/345]  eta: 0:00:18  lr: 0.000094  loss: 0.7448 (0.7444)  time: 0.7495  data: 0.0001  max mem: 14938
[17:05:15.115957] Epoch: [29]  [340/345]  eta: 0:00:03  lr: 0.000094  loss: 0.7456 (0.7445)  time: 0.7492  data: 0.0001  max mem: 14938
[17:05:18.113024] Epoch: [29]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.7421 (0.7444)  time: 0.7492  data: 0.0001  max mem: 14938
[17:05:18.176462] Epoch: [29] Total time: 0:04:18 (0.7507 s / it)
[17:05:18.176733] Averaged stats: lr: 0.000094  loss: 0.7421 (0.7444)
[17:05:18.522575] Test:  [  0/345]  eta: 0:01:57  loss: 0.7044 (0.7044)  time: 0.3416  data: 0.1593  max mem: 14938
[17:05:20.360392] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7158 (0.7151)  time: 0.1980  data: 0.0145  max mem: 14938
[17:05:22.200277] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7144 (0.7147)  time: 0.1838  data: 0.0001  max mem: 14938
[17:05:24.045009] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7130 (0.7160)  time: 0.1842  data: 0.0001  max mem: 14938
[17:05:25.892944] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7160 (0.7171)  time: 0.1846  data: 0.0001  max mem: 14938
[17:05:27.744393] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7175 (0.7175)  time: 0.1849  data: 0.0001  max mem: 14938
[17:05:29.599481] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7173 (0.7174)  time: 0.1853  data: 0.0001  max mem: 14938
[17:05:31.456615] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7157 (0.7169)  time: 0.1856  data: 0.0001  max mem: 14938
[17:05:33.316076] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7169 (0.7173)  time: 0.1858  data: 0.0001  max mem: 14938
[17:05:35.181161] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7198 (0.7172)  time: 0.1862  data: 0.0001  max mem: 14938
[17:05:37.049184] Test:  [100/345]  eta: 0:00:45  loss: 0.7198 (0.7181)  time: 0.1866  data: 0.0001  max mem: 14938
[17:05:38.919860] Test:  [110/345]  eta: 0:00:43  loss: 0.7158 (0.7171)  time: 0.1869  data: 0.0001  max mem: 14938
[17:05:40.796059] Test:  [120/345]  eta: 0:00:42  loss: 0.7019 (0.7160)  time: 0.1873  data: 0.0001  max mem: 14938
[17:05:42.674814] Test:  [130/345]  eta: 0:00:40  loss: 0.7075 (0.7161)  time: 0.1877  data: 0.0001  max mem: 14938
[17:05:44.555840] Test:  [140/345]  eta: 0:00:38  loss: 0.7145 (0.7158)  time: 0.1879  data: 0.0001  max mem: 14938
[17:05:46.441322] Test:  [150/345]  eta: 0:00:36  loss: 0.7091 (0.7156)  time: 0.1883  data: 0.0001  max mem: 14938
[17:05:48.329318] Test:  [160/345]  eta: 0:00:34  loss: 0.7091 (0.7157)  time: 0.1886  data: 0.0001  max mem: 14938
[17:05:50.220257] Test:  [170/345]  eta: 0:00:32  loss: 0.7132 (0.7155)  time: 0.1889  data: 0.0001  max mem: 14938
[17:05:52.119231] Test:  [180/345]  eta: 0:00:30  loss: 0.7110 (0.7152)  time: 0.1894  data: 0.0001  max mem: 14938
[17:05:54.019697] Test:  [190/345]  eta: 0:00:29  loss: 0.7122 (0.7153)  time: 0.1899  data: 0.0001  max mem: 14938
[17:05:55.921879] Test:  [200/345]  eta: 0:00:27  loss: 0.7148 (0.7154)  time: 0.1901  data: 0.0001  max mem: 14938
[17:05:57.828505] Test:  [210/345]  eta: 0:00:25  loss: 0.7120 (0.7154)  time: 0.1904  data: 0.0001  max mem: 14938
[17:05:59.738606] Test:  [220/345]  eta: 0:00:23  loss: 0.7136 (0.7155)  time: 0.1908  data: 0.0001  max mem: 14938
[17:06:01.653232] Test:  [230/345]  eta: 0:00:21  loss: 0.7133 (0.7152)  time: 0.1912  data: 0.0001  max mem: 14938
[17:06:03.571194] Test:  [240/345]  eta: 0:00:19  loss: 0.7103 (0.7152)  time: 0.1916  data: 0.0001  max mem: 14938
[17:06:05.492441] Test:  [250/345]  eta: 0:00:17  loss: 0.7160 (0.7153)  time: 0.1919  data: 0.0001  max mem: 14938
[17:06:07.416866] Test:  [260/345]  eta: 0:00:16  loss: 0.7134 (0.7153)  time: 0.1922  data: 0.0001  max mem: 14938
[17:06:09.342919] Test:  [270/345]  eta: 0:00:14  loss: 0.7088 (0.7152)  time: 0.1925  data: 0.0001  max mem: 14938
[17:06:11.273190] Test:  [280/345]  eta: 0:00:12  loss: 0.7117 (0.7151)  time: 0.1928  data: 0.0001  max mem: 14938
[17:06:13.207183] Test:  [290/345]  eta: 0:00:10  loss: 0.7119 (0.7151)  time: 0.1932  data: 0.0001  max mem: 14938
[17:06:15.145740] Test:  [300/345]  eta: 0:00:08  loss: 0.7088 (0.7148)  time: 0.1936  data: 0.0001  max mem: 14938
[17:06:17.086251] Test:  [310/345]  eta: 0:00:06  loss: 0.7089 (0.7149)  time: 0.1939  data: 0.0001  max mem: 14938
[17:06:19.029651] Test:  [320/345]  eta: 0:00:04  loss: 0.7192 (0.7152)  time: 0.1941  data: 0.0001  max mem: 14938
[17:06:20.976508] Test:  [330/345]  eta: 0:00:02  loss: 0.7167 (0.7153)  time: 0.1945  data: 0.0001  max mem: 14938
[17:06:22.927464] Test:  [340/345]  eta: 0:00:00  loss: 0.7103 (0.7151)  time: 0.1948  data: 0.0001  max mem: 14938
[17:06:23.710267] Test:  [344/345]  eta: 0:00:00  loss: 0.7092 (0.7150)  time: 0.1950  data: 0.0001  max mem: 14938
[17:06:23.772203] Test: Total time: 0:01:05 (0.1901 s / it)
[17:06:34.537835] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8418 (0.8418)  time: 0.3255  data: 0.1461  max mem: 14938
[17:06:36.355393] Test:  [10/57]  eta: 0:00:09  loss: 0.8792 (0.8760)  time: 0.1947  data: 0.0133  max mem: 14938
[17:06:38.178299] Test:  [20/57]  eta: 0:00:06  loss: 0.8753 (0.8618)  time: 0.1820  data: 0.0001  max mem: 14938
[17:06:40.003160] Test:  [30/57]  eta: 0:00:05  loss: 0.7557 (0.8239)  time: 0.1823  data: 0.0001  max mem: 14938
[17:06:41.833989] Test:  [40/57]  eta: 0:00:03  loss: 0.7418 (0.8039)  time: 0.1827  data: 0.0001  max mem: 14938
[17:06:43.670529] Test:  [50/57]  eta: 0:00:01  loss: 0.7334 (0.7952)  time: 0.1833  data: 0.0001  max mem: 14938
[17:06:44.660346] Test:  [56/57]  eta: 0:00:00  loss: 0.7533 (0.8010)  time: 0.1779  data: 0.0001  max mem: 14938
[17:06:44.722823] Test: Total time: 0:00:10 (0.1844 s / it)
[17:06:46.605823] Dice score of the network on the train images: 0.807834, val images: 0.822534
[17:06:46.606060] saving best_prec_model_0 @ epoch 29
[17:06:47.659382] saving best_dice_model_0 @ epoch 29
[17:06:48.682867] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:06:49.571237] Epoch: [30]  [  0/345]  eta: 0:05:06  lr: 0.000094  loss: 0.7217 (0.7217)  time: 0.8872  data: 0.1448  max mem: 14938
[17:07:04.446291] Epoch: [30]  [ 20/345]  eta: 0:04:03  lr: 0.000093  loss: 0.7363 (0.7373)  time: 0.7437  data: 0.0001  max mem: 14938
[17:07:19.365206] Epoch: [30]  [ 40/345]  eta: 0:03:48  lr: 0.000093  loss: 0.7311 (0.7365)  time: 0.7459  data: 0.0001  max mem: 14938
[17:07:34.346914] Epoch: [30]  [ 60/345]  eta: 0:03:33  lr: 0.000093  loss: 0.7312 (0.7363)  time: 0.7490  data: 0.0001  max mem: 14938
[17:07:49.345659] Epoch: [30]  [ 80/345]  eta: 0:03:18  lr: 0.000092  loss: 0.7372 (0.7371)  time: 0.7499  data: 0.0001  max mem: 14938
[17:08:04.395662] Epoch: [30]  [100/345]  eta: 0:03:03  lr: 0.000092  loss: 0.7325 (0.7362)  time: 0.7525  data: 0.0001  max mem: 14938
[17:08:19.456592] Epoch: [30]  [120/345]  eta: 0:02:48  lr: 0.000092  loss: 0.7299 (0.7358)  time: 0.7530  data: 0.0001  max mem: 14938
[17:08:34.496056] Epoch: [30]  [140/345]  eta: 0:02:33  lr: 0.000091  loss: 0.7315 (0.7361)  time: 0.7519  data: 0.0001  max mem: 14938
[17:08:49.521223] Epoch: [30]  [160/345]  eta: 0:02:18  lr: 0.000091  loss: 0.7422 (0.7363)  time: 0.7512  data: 0.0001  max mem: 14938
[17:09:04.544435] Epoch: [30]  [180/345]  eta: 0:02:03  lr: 0.000091  loss: 0.7405 (0.7365)  time: 0.7511  data: 0.0001  max mem: 14938
[17:09:19.565218] Epoch: [30]  [200/345]  eta: 0:01:48  lr: 0.000090  loss: 0.7390 (0.7368)  time: 0.7510  data: 0.0001  max mem: 14938
[17:09:34.571508] Epoch: [30]  [220/345]  eta: 0:01:33  lr: 0.000090  loss: 0.7266 (0.7360)  time: 0.7503  data: 0.0001  max mem: 14938
[17:09:49.578462] Epoch: [30]  [240/345]  eta: 0:01:18  lr: 0.000090  loss: 0.7372 (0.7359)  time: 0.7503  data: 0.0001  max mem: 14938
[17:10:04.578908] Epoch: [30]  [260/345]  eta: 0:01:03  lr: 0.000089  loss: 0.7331 (0.7358)  time: 0.7500  data: 0.0001  max mem: 14938
[17:10:19.575376] Epoch: [30]  [280/345]  eta: 0:00:48  lr: 0.000089  loss: 0.7319 (0.7357)  time: 0.7498  data: 0.0001  max mem: 14938
[17:10:34.564132] Epoch: [30]  [300/345]  eta: 0:00:33  lr: 0.000089  loss: 0.7324 (0.7355)  time: 0.7494  data: 0.0001  max mem: 14938
[17:10:49.554682] Epoch: [30]  [320/345]  eta: 0:00:18  lr: 0.000088  loss: 0.7275 (0.7349)  time: 0.7495  data: 0.0001  max mem: 14938
[17:11:04.539437] Epoch: [30]  [340/345]  eta: 0:00:03  lr: 0.000088  loss: 0.7331 (0.7348)  time: 0.7492  data: 0.0001  max mem: 14938
[17:11:07.626129] Epoch: [30]  [344/345]  eta: 0:00:00  lr: 0.000088  loss: 0.7331 (0.7348)  time: 0.7535  data: 0.0001  max mem: 14938
[17:11:07.691402] Epoch: [30] Total time: 0:04:19 (0.7507 s / it)
[17:11:07.691828] Averaged stats: lr: 0.000088  loss: 0.7331 (0.7348)
[17:11:08.036626] Test:  [  0/345]  eta: 0:01:57  loss: 0.7248 (0.7248)  time: 0.3402  data: 0.1585  max mem: 14938
[17:11:09.874601] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7167 (0.7126)  time: 0.1980  data: 0.0145  max mem: 14938
[17:11:11.714499] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7091 (0.7102)  time: 0.1838  data: 0.0001  max mem: 14938
[17:11:13.557377] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7076 (0.7089)  time: 0.1841  data: 0.0001  max mem: 14938
[17:11:15.404181] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7051 (0.7078)  time: 0.1844  data: 0.0001  max mem: 14938
[17:11:17.255054] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7050 (0.7080)  time: 0.1848  data: 0.0001  max mem: 14938
[17:11:19.108832] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7046 (0.7085)  time: 0.1852  data: 0.0001  max mem: 14938
[17:11:20.965236] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7024 (0.7078)  time: 0.1855  data: 0.0001  max mem: 14938
[17:11:22.825224] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7027 (0.7069)  time: 0.1858  data: 0.0001  max mem: 14938
[17:11:24.688744] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7111 (0.7080)  time: 0.1861  data: 0.0001  max mem: 14938
[17:11:26.556494] Test:  [100/345]  eta: 0:00:45  loss: 0.7117 (0.7080)  time: 0.1865  data: 0.0001  max mem: 14938
[17:11:28.427490] Test:  [110/345]  eta: 0:00:43  loss: 0.7007 (0.7073)  time: 0.1869  data: 0.0001  max mem: 14938
[17:11:30.302930] Test:  [120/345]  eta: 0:00:42  loss: 0.6989 (0.7067)  time: 0.1873  data: 0.0001  max mem: 14938
[17:11:32.179696] Test:  [130/345]  eta: 0:00:40  loss: 0.7008 (0.7067)  time: 0.1876  data: 0.0001  max mem: 14938
[17:11:34.061739] Test:  [140/345]  eta: 0:00:38  loss: 0.7088 (0.7069)  time: 0.1879  data: 0.0001  max mem: 14938
[17:11:35.946861] Test:  [150/345]  eta: 0:00:36  loss: 0.7088 (0.7069)  time: 0.1883  data: 0.0001  max mem: 14938
[17:11:37.835001] Test:  [160/345]  eta: 0:00:34  loss: 0.7071 (0.7070)  time: 0.1886  data: 0.0001  max mem: 14938
[17:11:39.725942] Test:  [170/345]  eta: 0:00:32  loss: 0.7062 (0.7066)  time: 0.1889  data: 0.0001  max mem: 14938
[17:11:41.625228] Test:  [180/345]  eta: 0:00:30  loss: 0.7023 (0.7065)  time: 0.1895  data: 0.0001  max mem: 14938
[17:11:43.526214] Test:  [190/345]  eta: 0:00:29  loss: 0.7030 (0.7067)  time: 0.1900  data: 0.0001  max mem: 14938
[17:11:45.427227] Test:  [200/345]  eta: 0:00:27  loss: 0.7064 (0.7067)  time: 0.1901  data: 0.0001  max mem: 14938
[17:11:47.334332] Test:  [210/345]  eta: 0:00:25  loss: 0.7053 (0.7068)  time: 0.1904  data: 0.0001  max mem: 14938
[17:11:49.244772] Test:  [220/345]  eta: 0:00:23  loss: 0.7053 (0.7068)  time: 0.1908  data: 0.0001  max mem: 14938
[17:11:51.157447] Test:  [230/345]  eta: 0:00:21  loss: 0.7032 (0.7067)  time: 0.1911  data: 0.0001  max mem: 14938
[17:11:53.074197] Test:  [240/345]  eta: 0:00:19  loss: 0.6998 (0.7064)  time: 0.1914  data: 0.0001  max mem: 14938
[17:11:54.995654] Test:  [250/345]  eta: 0:00:17  loss: 0.7006 (0.7065)  time: 0.1919  data: 0.0001  max mem: 14938
[17:11:56.919812] Test:  [260/345]  eta: 0:00:16  loss: 0.7089 (0.7066)  time: 0.1922  data: 0.0001  max mem: 14938
[17:11:58.846922] Test:  [270/345]  eta: 0:00:14  loss: 0.7092 (0.7067)  time: 0.1925  data: 0.0001  max mem: 14938
[17:12:00.780586] Test:  [280/345]  eta: 0:00:12  loss: 0.7050 (0.7065)  time: 0.1930  data: 0.0001  max mem: 14938
[17:12:02.714484] Test:  [290/345]  eta: 0:00:10  loss: 0.7026 (0.7066)  time: 0.1933  data: 0.0001  max mem: 14938
[17:12:04.652234] Test:  [300/345]  eta: 0:00:08  loss: 0.7113 (0.7067)  time: 0.1935  data: 0.0001  max mem: 14938
[17:12:06.593168] Test:  [310/345]  eta: 0:00:06  loss: 0.7049 (0.7067)  time: 0.1939  data: 0.0001  max mem: 14938
[17:12:08.537384] Test:  [320/345]  eta: 0:00:04  loss: 0.7058 (0.7069)  time: 0.1942  data: 0.0001  max mem: 14938
[17:12:10.484462] Test:  [330/345]  eta: 0:00:02  loss: 0.7080 (0.7068)  time: 0.1945  data: 0.0001  max mem: 14938
[17:12:12.434293] Test:  [340/345]  eta: 0:00:00  loss: 0.7067 (0.7069)  time: 0.1948  data: 0.0001  max mem: 14938
[17:12:13.215449] Test:  [344/345]  eta: 0:00:00  loss: 0.7067 (0.7068)  time: 0.1949  data: 0.0001  max mem: 14938
[17:12:13.277977] Test: Total time: 0:01:05 (0.1901 s / it)
[17:12:24.053426] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8515 (0.8515)  time: 0.3257  data: 0.1462  max mem: 14938
[17:12:25.870795] Test:  [10/57]  eta: 0:00:09  loss: 0.8720 (0.8760)  time: 0.1948  data: 0.0133  max mem: 14938
[17:12:27.692859] Test:  [20/57]  eta: 0:00:06  loss: 0.8720 (0.8648)  time: 0.1819  data: 0.0001  max mem: 14938
[17:12:29.519257] Test:  [30/57]  eta: 0:00:05  loss: 0.7596 (0.8276)  time: 0.1824  data: 0.0001  max mem: 14938
[17:12:31.348121] Test:  [40/57]  eta: 0:00:03  loss: 0.7467 (0.8088)  time: 0.1827  data: 0.0001  max mem: 14938
[17:12:33.183327] Test:  [50/57]  eta: 0:00:01  loss: 0.7469 (0.8027)  time: 0.1832  data: 0.0001  max mem: 14938
[17:12:34.172577] Test:  [56/57]  eta: 0:00:00  loss: 0.7705 (0.8093)  time: 0.1777  data: 0.0001  max mem: 14938
[17:12:34.230363] Test: Total time: 0:00:10 (0.1843 s / it)
[17:12:36.060415] Dice score of the network on the train images: 0.819775, val images: 0.815905
[17:12:36.060648] saving best_prec_model_0 @ epoch 30
[17:12:37.130281] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:12:38.024754] Epoch: [31]  [  0/345]  eta: 0:05:08  lr: 0.000088  loss: 0.7243 (0.7243)  time: 0.8933  data: 0.1517  max mem: 14938
[17:12:52.875384] Epoch: [31]  [ 20/345]  eta: 0:04:03  lr: 0.000088  loss: 0.7398 (0.7432)  time: 0.7425  data: 0.0001  max mem: 14938
[17:13:07.773508] Epoch: [31]  [ 40/345]  eta: 0:03:47  lr: 0.000087  loss: 0.7423 (0.7432)  time: 0.7449  data: 0.0001  max mem: 14938
[17:13:22.724493] Epoch: [31]  [ 60/345]  eta: 0:03:33  lr: 0.000087  loss: 0.7356 (0.7412)  time: 0.7475  data: 0.0001  max mem: 14938
[17:13:37.696175] Epoch: [31]  [ 80/345]  eta: 0:03:18  lr: 0.000087  loss: 0.7330 (0.7391)  time: 0.7485  data: 0.0001  max mem: 14938
[17:13:52.695932] Epoch: [31]  [100/345]  eta: 0:03:03  lr: 0.000086  loss: 0.7276 (0.7378)  time: 0.7499  data: 0.0001  max mem: 14938
[17:14:07.718535] Epoch: [31]  [120/345]  eta: 0:02:48  lr: 0.000086  loss: 0.7269 (0.7367)  time: 0.7511  data: 0.0001  max mem: 14938
[17:14:22.735565] Epoch: [31]  [140/345]  eta: 0:02:33  lr: 0.000085  loss: 0.7275 (0.7358)  time: 0.7508  data: 0.0001  max mem: 14938
[17:14:37.744526] Epoch: [31]  [160/345]  eta: 0:02:18  lr: 0.000085  loss: 0.7361 (0.7355)  time: 0.7504  data: 0.0001  max mem: 14938
[17:14:52.742169] Epoch: [31]  [180/345]  eta: 0:02:03  lr: 0.000085  loss: 0.7381 (0.7354)  time: 0.7498  data: 0.0001  max mem: 14938
[17:15:07.731352] Epoch: [31]  [200/345]  eta: 0:01:48  lr: 0.000084  loss: 0.7545 (0.7373)  time: 0.7494  data: 0.0001  max mem: 14938
[17:15:22.715926] Epoch: [31]  [220/345]  eta: 0:01:33  lr: 0.000084  loss: 0.7373 (0.7374)  time: 0.7492  data: 0.0001  max mem: 14938
[17:15:37.695400] Epoch: [31]  [240/345]  eta: 0:01:18  lr: 0.000084  loss: 0.7306 (0.7370)  time: 0.7489  data: 0.0001  max mem: 14938
[17:15:52.676057] Epoch: [31]  [260/345]  eta: 0:01:03  lr: 0.000083  loss: 0.7297 (0.7370)  time: 0.7490  data: 0.0001  max mem: 14938
[17:16:07.650495] Epoch: [31]  [280/345]  eta: 0:00:48  lr: 0.000083  loss: 0.7333 (0.7368)  time: 0.7487  data: 0.0001  max mem: 14938
[17:16:22.615381] Epoch: [31]  [300/345]  eta: 0:00:33  lr: 0.000083  loss: 0.7342 (0.7367)  time: 0.7482  data: 0.0001  max mem: 14938
[17:16:37.577645] Epoch: [31]  [320/345]  eta: 0:00:18  lr: 0.000082  loss: 0.7301 (0.7363)  time: 0.7481  data: 0.0001  max mem: 14938
[17:16:52.541578] Epoch: [31]  [340/345]  eta: 0:00:03  lr: 0.000082  loss: 0.7299 (0.7360)  time: 0.7482  data: 0.0001  max mem: 14938
[17:16:55.535269] Epoch: [31]  [344/345]  eta: 0:00:00  lr: 0.000082  loss: 0.7247 (0.7359)  time: 0.7482  data: 0.0001  max mem: 14938
[17:16:55.603101] Epoch: [31] Total time: 0:04:18 (0.7492 s / it)
[17:16:55.603602] Averaged stats: lr: 0.000082  loss: 0.7247 (0.7359)
[17:16:55.949416] Test:  [  0/345]  eta: 0:01:58  loss: 0.7238 (0.7238)  time: 0.3423  data: 0.1608  max mem: 14938
[17:16:57.787158] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6979 (0.6991)  time: 0.1981  data: 0.0147  max mem: 14938
[17:16:59.626962] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6989 (0.7010)  time: 0.1838  data: 0.0001  max mem: 14938
[17:17:01.471671] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7007 (0.7038)  time: 0.1842  data: 0.0001  max mem: 14938
[17:17:03.317047] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6992 (0.7043)  time: 0.1845  data: 0.0001  max mem: 14938
[17:17:05.168262] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6994 (0.7043)  time: 0.1848  data: 0.0001  max mem: 14938
[17:17:07.023399] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6995 (0.7037)  time: 0.1853  data: 0.0001  max mem: 14938
[17:17:08.880618] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6999 (0.7044)  time: 0.1856  data: 0.0001  max mem: 14938
[17:17:10.742394] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7045 (0.7046)  time: 0.1859  data: 0.0001  max mem: 14938
[17:17:12.608095] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7056 (0.7049)  time: 0.1863  data: 0.0001  max mem: 14938
[17:17:14.476646] Test:  [100/345]  eta: 0:00:45  loss: 0.7055 (0.7049)  time: 0.1867  data: 0.0001  max mem: 14938
[17:17:16.347328] Test:  [110/345]  eta: 0:00:43  loss: 0.7045 (0.7049)  time: 0.1869  data: 0.0001  max mem: 14938
[17:17:18.221999] Test:  [120/345]  eta: 0:00:42  loss: 0.6985 (0.7042)  time: 0.1872  data: 0.0001  max mem: 14938
[17:17:20.100362] Test:  [130/345]  eta: 0:00:40  loss: 0.6951 (0.7040)  time: 0.1876  data: 0.0001  max mem: 14938
[17:17:21.982415] Test:  [140/345]  eta: 0:00:38  loss: 0.7048 (0.7041)  time: 0.1880  data: 0.0001  max mem: 14938
[17:17:23.869285] Test:  [150/345]  eta: 0:00:36  loss: 0.7064 (0.7042)  time: 0.1884  data: 0.0001  max mem: 14938
[17:17:25.756394] Test:  [160/345]  eta: 0:00:34  loss: 0.7079 (0.7046)  time: 0.1886  data: 0.0001  max mem: 14938
[17:17:27.648831] Test:  [170/345]  eta: 0:00:32  loss: 0.7061 (0.7049)  time: 0.1889  data: 0.0001  max mem: 14938
[17:17:29.543150] Test:  [180/345]  eta: 0:00:30  loss: 0.7078 (0.7053)  time: 0.1893  data: 0.0001  max mem: 14938
[17:17:31.444070] Test:  [190/345]  eta: 0:00:29  loss: 0.7068 (0.7052)  time: 0.1897  data: 0.0001  max mem: 14938
[17:17:33.345982] Test:  [200/345]  eta: 0:00:27  loss: 0.7061 (0.7052)  time: 0.1901  data: 0.0001  max mem: 14938
[17:17:35.251078] Test:  [210/345]  eta: 0:00:25  loss: 0.7053 (0.7052)  time: 0.1903  data: 0.0001  max mem: 14938
[17:17:37.160819] Test:  [220/345]  eta: 0:00:23  loss: 0.6993 (0.7050)  time: 0.1907  data: 0.0001  max mem: 14938
[17:17:39.073861] Test:  [230/345]  eta: 0:00:21  loss: 0.6985 (0.7052)  time: 0.1911  data: 0.0001  max mem: 14938
[17:17:40.992494] Test:  [240/345]  eta: 0:00:19  loss: 0.7027 (0.7050)  time: 0.1915  data: 0.0001  max mem: 14938
[17:17:42.912779] Test:  [250/345]  eta: 0:00:17  loss: 0.7035 (0.7050)  time: 0.1919  data: 0.0001  max mem: 14938
[17:17:44.837369] Test:  [260/345]  eta: 0:00:16  loss: 0.7043 (0.7050)  time: 0.1922  data: 0.0001  max mem: 14938
[17:17:46.765980] Test:  [270/345]  eta: 0:00:14  loss: 0.7043 (0.7052)  time: 0.1926  data: 0.0001  max mem: 14938
[17:17:48.696319] Test:  [280/345]  eta: 0:00:12  loss: 0.7032 (0.7052)  time: 0.1929  data: 0.0001  max mem: 14938
[17:17:50.630395] Test:  [290/345]  eta: 0:00:10  loss: 0.7036 (0.7052)  time: 0.1932  data: 0.0001  max mem: 14938
[17:17:52.569802] Test:  [300/345]  eta: 0:00:08  loss: 0.7027 (0.7051)  time: 0.1936  data: 0.0001  max mem: 14938
[17:17:54.513910] Test:  [310/345]  eta: 0:00:06  loss: 0.6960 (0.7049)  time: 0.1941  data: 0.0001  max mem: 14938
[17:17:56.459069] Test:  [320/345]  eta: 0:00:04  loss: 0.6997 (0.7050)  time: 0.1944  data: 0.0001  max mem: 14938
[17:17:58.405766] Test:  [330/345]  eta: 0:00:02  loss: 0.7067 (0.7050)  time: 0.1945  data: 0.0001  max mem: 14938
[17:18:00.355608] Test:  [340/345]  eta: 0:00:00  loss: 0.7042 (0.7051)  time: 0.1948  data: 0.0001  max mem: 14938
[17:18:01.136702] Test:  [344/345]  eta: 0:00:00  loss: 0.7066 (0.7052)  time: 0.1949  data: 0.0001  max mem: 14938
[17:18:01.198200] Test: Total time: 0:01:05 (0.1901 s / it)
[17:18:11.868545] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8340 (0.8340)  time: 0.3316  data: 0.1518  max mem: 14938
[17:18:13.687440] Test:  [10/57]  eta: 0:00:09  loss: 0.8846 (0.8729)  time: 0.1954  data: 0.0139  max mem: 14938
[17:18:15.510107] Test:  [20/57]  eta: 0:00:06  loss: 0.8706 (0.8583)  time: 0.1820  data: 0.0001  max mem: 14938
[17:18:17.337045] Test:  [30/57]  eta: 0:00:05  loss: 0.7461 (0.8198)  time: 0.1824  data: 0.0001  max mem: 14938
[17:18:19.168323] Test:  [40/57]  eta: 0:00:03  loss: 0.7343 (0.8005)  time: 0.1829  data: 0.0001  max mem: 14938
[17:18:21.004986] Test:  [50/57]  eta: 0:00:01  loss: 0.7357 (0.7948)  time: 0.1833  data: 0.0001  max mem: 14938
[17:18:21.995893] Test:  [56/57]  eta: 0:00:00  loss: 0.7616 (0.8007)  time: 0.1780  data: 0.0001  max mem: 14938
[17:18:22.057809] Test: Total time: 0:00:10 (0.1846 s / it)
[17:18:23.893648] Dice score of the network on the train images: 0.811337, val images: 0.820703
[17:18:23.897936] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:18:24.787770] Epoch: [32]  [  0/345]  eta: 0:05:06  lr: 0.000082  loss: 0.7173 (0.7173)  time: 0.8889  data: 0.1480  max mem: 14938
[17:18:39.658576] Epoch: [32]  [ 20/345]  eta: 0:04:03  lr: 0.000081  loss: 0.7242 (0.7272)  time: 0.7435  data: 0.0001  max mem: 14938
[17:18:54.571197] Epoch: [32]  [ 40/345]  eta: 0:03:48  lr: 0.000081  loss: 0.7393 (0.7329)  time: 0.7456  data: 0.0001  max mem: 14938
[17:19:09.536585] Epoch: [32]  [ 60/345]  eta: 0:03:33  lr: 0.000081  loss: 0.7307 (0.7330)  time: 0.7482  data: 0.0001  max mem: 14938
[17:19:24.553600] Epoch: [32]  [ 80/345]  eta: 0:03:18  lr: 0.000080  loss: 0.7299 (0.7329)  time: 0.7508  data: 0.0001  max mem: 14938
[17:19:39.588034] Epoch: [32]  [100/345]  eta: 0:03:03  lr: 0.000080  loss: 0.7330 (0.7327)  time: 0.7517  data: 0.0001  max mem: 14938
[17:19:54.627440] Epoch: [32]  [120/345]  eta: 0:02:48  lr: 0.000080  loss: 0.7312 (0.7328)  time: 0.7519  data: 0.0001  max mem: 14938
[17:20:09.661048] Epoch: [32]  [140/345]  eta: 0:02:33  lr: 0.000079  loss: 0.7347 (0.7330)  time: 0.7516  data: 0.0001  max mem: 14938
[17:20:24.694445] Epoch: [32]  [160/345]  eta: 0:02:18  lr: 0.000079  loss: 0.7441 (0.7343)  time: 0.7516  data: 0.0001  max mem: 14938
[17:20:39.709455] Epoch: [32]  [180/345]  eta: 0:02:03  lr: 0.000079  loss: 0.7201 (0.7331)  time: 0.7507  data: 0.0001  max mem: 14938
[17:20:54.722953] Epoch: [32]  [200/345]  eta: 0:01:48  lr: 0.000078  loss: 0.7312 (0.7330)  time: 0.7506  data: 0.0001  max mem: 14938
[17:21:09.724588] Epoch: [32]  [220/345]  eta: 0:01:33  lr: 0.000078  loss: 0.7309 (0.7330)  time: 0.7500  data: 0.0001  max mem: 14938
[17:21:24.715697] Epoch: [32]  [240/345]  eta: 0:01:18  lr: 0.000077  loss: 0.7360 (0.7335)  time: 0.7495  data: 0.0001  max mem: 14938
[17:21:39.717744] Epoch: [32]  [260/345]  eta: 0:01:03  lr: 0.000077  loss: 0.7283 (0.7336)  time: 0.7501  data: 0.0001  max mem: 14938
[17:21:54.703902] Epoch: [32]  [280/345]  eta: 0:00:48  lr: 0.000077  loss: 0.7371 (0.7340)  time: 0.7493  data: 0.0001  max mem: 14938
[17:22:09.761671] Epoch: [32]  [300/345]  eta: 0:00:33  lr: 0.000076  loss: 0.7324 (0.7341)  time: 0.7528  data: 0.0001  max mem: 14938
[17:22:24.727060] Epoch: [32]  [320/345]  eta: 0:00:18  lr: 0.000076  loss: 0.7323 (0.7342)  time: 0.7482  data: 0.0001  max mem: 14938
[17:22:39.692561] Epoch: [32]  [340/345]  eta: 0:00:03  lr: 0.000076  loss: 0.7324 (0.7341)  time: 0.7482  data: 0.0001  max mem: 14938
[17:22:42.687641] Epoch: [32]  [344/345]  eta: 0:00:00  lr: 0.000076  loss: 0.7333 (0.7341)  time: 0.7483  data: 0.0001  max mem: 14938
[17:22:42.753383] Epoch: [32] Total time: 0:04:18 (0.7503 s / it)
[17:22:42.753865] Averaged stats: lr: 0.000076  loss: 0.7333 (0.7341)
[17:22:43.098707] Test:  [  0/345]  eta: 0:01:57  loss: 0.7285 (0.7285)  time: 0.3408  data: 0.1586  max mem: 14938
[17:22:44.936284] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7109 (0.7106)  time: 0.1980  data: 0.0145  max mem: 14938
[17:22:46.775296] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7109 (0.7139)  time: 0.1838  data: 0.0001  max mem: 14938
[17:22:48.618623] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7089 (0.7124)  time: 0.1841  data: 0.0001  max mem: 14938
[17:22:50.464568] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7070 (0.7121)  time: 0.1844  data: 0.0001  max mem: 14938
[17:22:52.316674] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7075 (0.7122)  time: 0.1849  data: 0.0001  max mem: 14938
[17:22:54.171146] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7118 (0.7123)  time: 0.1853  data: 0.0001  max mem: 14938
[17:22:56.028244] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7163 (0.7135)  time: 0.1855  data: 0.0001  max mem: 14938
[17:22:57.889776] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7145 (0.7138)  time: 0.1859  data: 0.0001  max mem: 14938
[17:22:59.756181] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7099 (0.7142)  time: 0.1863  data: 0.0001  max mem: 14938
[17:23:01.625370] Test:  [100/345]  eta: 0:00:45  loss: 0.7114 (0.7142)  time: 0.1867  data: 0.0001  max mem: 14938
[17:23:03.497063] Test:  [110/345]  eta: 0:00:43  loss: 0.7123 (0.7144)  time: 0.1870  data: 0.0001  max mem: 14938
[17:23:05.372743] Test:  [120/345]  eta: 0:00:42  loss: 0.7123 (0.7141)  time: 0.1873  data: 0.0001  max mem: 14938
[17:23:07.252825] Test:  [130/345]  eta: 0:00:40  loss: 0.7052 (0.7134)  time: 0.1877  data: 0.0001  max mem: 14938
[17:23:09.136106] Test:  [140/345]  eta: 0:00:38  loss: 0.7115 (0.7134)  time: 0.1881  data: 0.0001  max mem: 14938
[17:23:11.022007] Test:  [150/345]  eta: 0:00:36  loss: 0.7123 (0.7132)  time: 0.1884  data: 0.0001  max mem: 14938
[17:23:12.911199] Test:  [160/345]  eta: 0:00:34  loss: 0.7114 (0.7131)  time: 0.1887  data: 0.0001  max mem: 14938
[17:23:14.803723] Test:  [170/345]  eta: 0:00:32  loss: 0.7129 (0.7133)  time: 0.1890  data: 0.0001  max mem: 14938
[17:23:16.701462] Test:  [180/345]  eta: 0:00:30  loss: 0.7096 (0.7131)  time: 0.1895  data: 0.0001  max mem: 14938
[17:23:18.602068] Test:  [190/345]  eta: 0:00:29  loss: 0.7071 (0.7132)  time: 0.1899  data: 0.0001  max mem: 14938
[17:23:20.505112] Test:  [200/345]  eta: 0:00:27  loss: 0.7127 (0.7131)  time: 0.1901  data: 0.0001  max mem: 14938
[17:23:22.412557] Test:  [210/345]  eta: 0:00:25  loss: 0.7130 (0.7130)  time: 0.1905  data: 0.0001  max mem: 14938
[17:23:24.324102] Test:  [220/345]  eta: 0:00:23  loss: 0.7167 (0.7133)  time: 0.1909  data: 0.0001  max mem: 14938
[17:23:26.238431] Test:  [230/345]  eta: 0:00:21  loss: 0.7183 (0.7135)  time: 0.1912  data: 0.0001  max mem: 14938
[17:23:28.156158] Test:  [240/345]  eta: 0:00:19  loss: 0.7136 (0.7134)  time: 0.1916  data: 0.0001  max mem: 14938
[17:23:30.079076] Test:  [250/345]  eta: 0:00:17  loss: 0.7118 (0.7132)  time: 0.1920  data: 0.0001  max mem: 14938
[17:23:32.003641] Test:  [260/345]  eta: 0:00:16  loss: 0.7109 (0.7134)  time: 0.1923  data: 0.0001  max mem: 14938
[17:23:33.932267] Test:  [270/345]  eta: 0:00:14  loss: 0.7129 (0.7133)  time: 0.1926  data: 0.0001  max mem: 14938
[17:23:35.864069] Test:  [280/345]  eta: 0:00:12  loss: 0.7124 (0.7133)  time: 0.1930  data: 0.0001  max mem: 14938
[17:23:37.799143] Test:  [290/345]  eta: 0:00:10  loss: 0.7123 (0.7132)  time: 0.1933  data: 0.0001  max mem: 14938
[17:23:39.738352] Test:  [300/345]  eta: 0:00:08  loss: 0.7123 (0.7132)  time: 0.1937  data: 0.0001  max mem: 14938
[17:23:41.679549] Test:  [310/345]  eta: 0:00:06  loss: 0.7083 (0.7132)  time: 0.1940  data: 0.0001  max mem: 14938
[17:23:43.625884] Test:  [320/345]  eta: 0:00:04  loss: 0.7022 (0.7129)  time: 0.1943  data: 0.0001  max mem: 14938
[17:23:45.573933] Test:  [330/345]  eta: 0:00:02  loss: 0.7090 (0.7131)  time: 0.1947  data: 0.0001  max mem: 14938
[17:23:47.524835] Test:  [340/345]  eta: 0:00:00  loss: 0.7154 (0.7131)  time: 0.1949  data: 0.0001  max mem: 14938
[17:23:48.306502] Test:  [344/345]  eta: 0:00:00  loss: 0.7154 (0.7132)  time: 0.1950  data: 0.0001  max mem: 14938
[17:23:48.367703] Test: Total time: 0:01:05 (0.1902 s / it)
[17:23:59.155618] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8675 (0.8675)  time: 0.3256  data: 0.1457  max mem: 14938
[17:24:00.972932] Test:  [10/57]  eta: 0:00:09  loss: 0.8892 (0.8910)  time: 0.1947  data: 0.0133  max mem: 14938
[17:24:02.793589] Test:  [20/57]  eta: 0:00:06  loss: 0.8968 (0.8829)  time: 0.1818  data: 0.0001  max mem: 14938
[17:24:04.618118] Test:  [30/57]  eta: 0:00:05  loss: 0.7952 (0.8445)  time: 0.1822  data: 0.0001  max mem: 14938
[17:24:06.448763] Test:  [40/57]  eta: 0:00:03  loss: 0.7523 (0.8245)  time: 0.1827  data: 0.0001  max mem: 14938
[17:24:08.285179] Test:  [50/57]  eta: 0:00:01  loss: 0.7574 (0.8180)  time: 0.1833  data: 0.0001  max mem: 14938
[17:24:09.275710] Test:  [56/57]  eta: 0:00:00  loss: 0.7847 (0.8218)  time: 0.1779  data: 0.0001  max mem: 14938
[17:24:09.338659] Test: Total time: 0:00:10 (0.1844 s / it)
[17:24:11.172757] Dice score of the network on the train images: 0.809656, val images: 0.812075
[17:24:11.176867] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:24:12.075419] Epoch: [33]  [  0/345]  eta: 0:05:09  lr: 0.000075  loss: 0.7386 (0.7386)  time: 0.8975  data: 0.1542  max mem: 14938
[17:24:26.947482] Epoch: [33]  [ 20/345]  eta: 0:04:04  lr: 0.000075  loss: 0.7338 (0.7353)  time: 0.7435  data: 0.0001  max mem: 14938
[17:24:41.850253] Epoch: [33]  [ 40/345]  eta: 0:03:48  lr: 0.000075  loss: 0.7245 (0.7309)  time: 0.7451  data: 0.0001  max mem: 14938
[17:24:56.790940] Epoch: [33]  [ 60/345]  eta: 0:03:33  lr: 0.000074  loss: 0.7268 (0.7297)  time: 0.7470  data: 0.0001  max mem: 14938
[17:25:11.774720] Epoch: [33]  [ 80/345]  eta: 0:03:18  lr: 0.000074  loss: 0.7282 (0.7295)  time: 0.7491  data: 0.0001  max mem: 14938
[17:25:26.786957] Epoch: [33]  [100/345]  eta: 0:03:03  lr: 0.000074  loss: 0.7323 (0.7304)  time: 0.7506  data: 0.0001  max mem: 14938
[17:25:41.815596] Epoch: [33]  [120/345]  eta: 0:02:48  lr: 0.000073  loss: 0.7239 (0.7301)  time: 0.7514  data: 0.0001  max mem: 14938
[17:25:56.844217] Epoch: [33]  [140/345]  eta: 0:02:33  lr: 0.000073  loss: 0.7263 (0.7300)  time: 0.7514  data: 0.0001  max mem: 14938
[17:26:11.863375] Epoch: [33]  [160/345]  eta: 0:02:18  lr: 0.000073  loss: 0.7406 (0.7310)  time: 0.7509  data: 0.0001  max mem: 14938
[17:26:26.877435] Epoch: [33]  [180/345]  eta: 0:02:03  lr: 0.000072  loss: 0.7232 (0.7302)  time: 0.7507  data: 0.0001  max mem: 14938
[17:26:41.880028] Epoch: [33]  [200/345]  eta: 0:01:48  lr: 0.000072  loss: 0.7311 (0.7304)  time: 0.7501  data: 0.0001  max mem: 14938
[17:26:56.870495] Epoch: [33]  [220/345]  eta: 0:01:33  lr: 0.000071  loss: 0.7280 (0.7303)  time: 0.7495  data: 0.0001  max mem: 14938
[17:27:11.855673] Epoch: [33]  [240/345]  eta: 0:01:18  lr: 0.000071  loss: 0.7287 (0.7304)  time: 0.7492  data: 0.0001  max mem: 14938
[17:27:26.839094] Epoch: [33]  [260/345]  eta: 0:01:03  lr: 0.000071  loss: 0.7196 (0.7298)  time: 0.7491  data: 0.0001  max mem: 14938

[17:27:41.822584] Epoch: [33]  [280/345]  eta: 0:00:48  lr: 0.000070  loss: 0.7210 (0.7293)  time: 0.7491  data: 0.0001  max mem: 14938
[17:27:56.801960] Epoch: [33]  [300/345]  eta: 0:00:33  lr: 0.000070  loss: 0.7227 (0.7289)  time: 0.7489  data: 0.0001  max mem: 14938
[17:28:11.775361] Epoch: [33]  [320/345]  eta: 0:00:18  lr: 0.000070  loss: 0.7235 (0.7286)  time: 0.7486  data: 0.0001  max mem: 14938
[17:28:26.746817] Epoch: [33]  [340/345]  eta: 0:00:03  lr: 0.000069  loss: 0.7233 (0.7281)  time: 0.7485  data: 0.0001  max mem: 14938
[17:28:29.740942] Epoch: [33]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.7245 (0.7281)  time: 0.7485  data: 0.0001  max mem: 14938
[17:28:29.805859] Epoch: [33] Total time: 0:04:18 (0.7496 s / it)
[17:28:29.806299] Averaged stats: lr: 0.000069  loss: 0.7245 (0.7281)
[17:28:30.151701] Test:  [  0/345]  eta: 0:01:57  loss: 0.6904 (0.6904)  time: 0.3417  data: 0.1590  max mem: 14938
[17:28:31.989356] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6969 (0.7009)  time: 0.1981  data: 0.0145  max mem: 14938
[17:28:33.830950] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6978 (0.7015)  time: 0.1839  data: 0.0001  max mem: 14938
[17:28:35.674494] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6948 (0.7000)  time: 0.1842  data: 0.0001  max mem: 14938
[17:28:37.522398] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6948 (0.6997)  time: 0.1845  data: 0.0001  max mem: 14938
[17:28:39.375486] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7015 (0.7006)  time: 0.1850  data: 0.0001  max mem: 14938
[17:28:41.232612] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6996 (0.7003)  time: 0.1855  data: 0.0001  max mem: 14938
[17:28:43.089288] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6981 (0.7003)  time: 0.1856  data: 0.0001  max mem: 14938
[17:28:44.949154] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6976 (0.7000)  time: 0.1858  data: 0.0001  max mem: 14938
[17:28:46.814359] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6950 (0.6999)  time: 0.1862  data: 0.0001  max mem: 14938
[17:28:48.680834] Test:  [100/345]  eta: 0:00:45  loss: 0.7005 (0.6999)  time: 0.1865  data: 0.0001  max mem: 14938
[17:28:50.552390] Test:  [110/345]  eta: 0:00:43  loss: 0.7029 (0.7002)  time: 0.1869  data: 0.0001  max mem: 14938
[17:28:52.427789] Test:  [120/345]  eta: 0:00:42  loss: 0.7005 (0.7000)  time: 0.1873  data: 0.0001  max mem: 14938
[17:28:54.306128] Test:  [130/345]  eta: 0:00:40  loss: 0.6955 (0.6998)  time: 0.1876  data: 0.0001  max mem: 14938
[17:28:56.188548] Test:  [140/345]  eta: 0:00:38  loss: 0.6955 (0.6996)  time: 0.1880  data: 0.0001  max mem: 14938
[17:28:58.074718] Test:  [150/345]  eta: 0:00:36  loss: 0.7018 (0.7007)  time: 0.1884  data: 0.0001  max mem: 14938
[17:28:59.962300] Test:  [160/345]  eta: 0:00:34  loss: 0.7032 (0.7005)  time: 0.1886  data: 0.0001  max mem: 14938
[17:29:01.854959] Test:  [170/345]  eta: 0:00:32  loss: 0.6970 (0.7006)  time: 0.1890  data: 0.0001  max mem: 14938
[17:29:03.751606] Test:  [180/345]  eta: 0:00:30  loss: 0.6996 (0.7005)  time: 0.1894  data: 0.0001  max mem: 14938
[17:29:05.651054] Test:  [190/345]  eta: 0:00:29  loss: 0.6980 (0.7005)  time: 0.1898  data: 0.0001  max mem: 14938
[17:29:07.552746] Test:  [200/345]  eta: 0:00:27  loss: 0.6980 (0.7006)  time: 0.1900  data: 0.0001  max mem: 14938
[17:29:09.461312] Test:  [210/345]  eta: 0:00:25  loss: 0.7050 (0.7009)  time: 0.1905  data: 0.0001  max mem: 14938
[17:29:11.371317] Test:  [220/345]  eta: 0:00:23  loss: 0.6959 (0.7008)  time: 0.1909  data: 0.0001  max mem: 14938
[17:29:13.283981] Test:  [230/345]  eta: 0:00:21  loss: 0.6942 (0.7007)  time: 0.1911  data: 0.0001  max mem: 14938
[17:29:15.201238] Test:  [240/345]  eta: 0:00:19  loss: 0.6971 (0.7006)  time: 0.1914  data: 0.0001  max mem: 14938
[17:29:17.122716] Test:  [250/345]  eta: 0:00:17  loss: 0.6972 (0.7006)  time: 0.1919  data: 0.0001  max mem: 14938
[17:29:19.046983] Test:  [260/345]  eta: 0:00:16  loss: 0.7004 (0.7006)  time: 0.1922  data: 0.0001  max mem: 14938
[17:29:20.974822] Test:  [270/345]  eta: 0:00:14  loss: 0.7004 (0.7006)  time: 0.1926  data: 0.0001  max mem: 14938
[17:29:22.907894] Test:  [280/345]  eta: 0:00:12  loss: 0.7009 (0.7009)  time: 0.1930  data: 0.0001  max mem: 14938
[17:29:24.842852] Test:  [290/345]  eta: 0:00:10  loss: 0.6988 (0.7010)  time: 0.1933  data: 0.0001  max mem: 14938
[17:29:26.782103] Test:  [300/345]  eta: 0:00:08  loss: 0.6952 (0.7011)  time: 0.1937  data: 0.0001  max mem: 14938
[17:29:28.724191] Test:  [310/345]  eta: 0:00:06  loss: 0.6989 (0.7011)  time: 0.1940  data: 0.0001  max mem: 14938
[17:29:30.668784] Test:  [320/345]  eta: 0:00:04  loss: 0.6989 (0.7012)  time: 0.1943  data: 0.0001  max mem: 14938
[17:29:32.617197] Test:  [330/345]  eta: 0:00:02  loss: 0.6962 (0.7011)  time: 0.1946  data: 0.0001  max mem: 14938
[17:29:34.567381] Test:  [340/345]  eta: 0:00:00  loss: 0.6979 (0.7012)  time: 0.1949  data: 0.0001  max mem: 14938
[17:29:35.350306] Test:  [344/345]  eta: 0:00:00  loss: 0.6989 (0.7011)  time: 0.1950  data: 0.0001  max mem: 14938
[17:29:35.410336] Test: Total time: 0:01:05 (0.1901 s / it)
[17:29:46.165707] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8556 (0.8556)  time: 0.3303  data: 0.1503  max mem: 14938
[17:29:47.982094] Test:  [10/57]  eta: 0:00:09  loss: 0.8815 (0.8763)  time: 0.1951  data: 0.0137  max mem: 14938
[17:29:49.804082] Test:  [20/57]  eta: 0:00:06  loss: 0.8815 (0.8627)  time: 0.1819  data: 0.0001  max mem: 14938
[17:29:51.630553] Test:  [30/57]  eta: 0:00:05  loss: 0.7551 (0.8239)  time: 0.1824  data: 0.0001  max mem: 14938
[17:29:53.461677] Test:  [40/57]  eta: 0:00:03  loss: 0.7463 (0.8042)  time: 0.1828  data: 0.0001  max mem: 14938
[17:29:55.297395] Test:  [50/57]  eta: 0:00:01  loss: 0.7405 (0.7978)  time: 0.1833  data: 0.0001  max mem: 14938
[17:29:56.287223] Test:  [56/57]  eta: 0:00:00  loss: 0.7575 (0.8037)  time: 0.1779  data: 0.0001  max mem: 14938
[17:29:56.345247] Test: Total time: 0:00:10 (0.1844 s / it)
[17:29:58.200940] Dice score of the network on the train images: 0.820101, val images: 0.821596
[17:29:58.204910] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:29:59.098135] Epoch: [34]  [  0/345]  eta: 0:05:07  lr: 0.000069  loss: 0.7242 (0.7242)  time: 0.8923  data: 0.1493  max mem: 14938
[17:30:13.971932] Epoch: [34]  [ 20/345]  eta: 0:04:03  lr: 0.000069  loss: 0.7174 (0.7221)  time: 0.7436  data: 0.0001  max mem: 14938
[17:30:28.879197] Epoch: [34]  [ 40/345]  eta: 0:03:48  lr: 0.000068  loss: 0.7226 (0.7227)  time: 0.7453  data: 0.0001  max mem: 14938
[17:30:43.826665] Epoch: [34]  [ 60/345]  eta: 0:03:33  lr: 0.000068  loss: 0.7199 (0.7216)  time: 0.7473  data: 0.0001  max mem: 14938
[17:30:58.809031] Epoch: [34]  [ 80/345]  eta: 0:03:18  lr: 0.000068  loss: 0.7234 (0.7216)  time: 0.7491  data: 0.0001  max mem: 14938
[17:31:13.805834] Epoch: [34]  [100/345]  eta: 0:03:03  lr: 0.000067  loss: 0.7271 (0.7233)  time: 0.7498  data: 0.0001  max mem: 14938
[17:31:28.829906] Epoch: [34]  [120/345]  eta: 0:02:48  lr: 0.000067  loss: 0.7143 (0.7224)  time: 0.7512  data: 0.0001  max mem: 14938
[17:31:43.865893] Epoch: [34]  [140/345]  eta: 0:02:33  lr: 0.000066  loss: 0.7191 (0.7218)  time: 0.7518  data: 0.0001  max mem: 14938
[17:31:58.881227] Epoch: [34]  [160/345]  eta: 0:02:18  lr: 0.000066  loss: 0.7206 (0.7216)  time: 0.7507  data: 0.0001  max mem: 14938
[17:32:13.886907] Epoch: [34]  [180/345]  eta: 0:02:03  lr: 0.000066  loss: 0.7214 (0.7215)  time: 0.7502  data: 0.0001  max mem: 14938
[17:32:28.887656] Epoch: [34]  [200/345]  eta: 0:01:48  lr: 0.000065  loss: 0.7261 (0.7220)  time: 0.7500  data: 0.0001  max mem: 14938
[17:32:43.883630] Epoch: [34]  [220/345]  eta: 0:01:33  lr: 0.000065  loss: 0.7240 (0.7221)  time: 0.7498  data: 0.0001  max mem: 14938
[17:32:58.866599] Epoch: [34]  [240/345]  eta: 0:01:18  lr: 0.000064  loss: 0.7188 (0.7219)  time: 0.7491  data: 0.0001  max mem: 14938
[17:33:13.842868] Epoch: [34]  [260/345]  eta: 0:01:03  lr: 0.000064  loss: 0.7197 (0.7222)  time: 0.7488  data: 0.0001  max mem: 14938
[17:33:28.846696] Epoch: [34]  [280/345]  eta: 0:00:48  lr: 0.000064  loss: 0.7203 (0.7221)  time: 0.7501  data: 0.0001  max mem: 14938
[17:33:43.851714] Epoch: [34]  [300/345]  eta: 0:00:33  lr: 0.000063  loss: 0.7152 (0.7219)  time: 0.7502  data: 0.0001  max mem: 14938
[17:33:58.845743] Epoch: [34]  [320/345]  eta: 0:00:18  lr: 0.000063  loss: 0.7237 (0.7220)  time: 0.7497  data: 0.0001  max mem: 14938
[17:34:13.840799] Epoch: [34]  [340/345]  eta: 0:00:03  lr: 0.000063  loss: 0.7246 (0.7221)  time: 0.7497  data: 0.0000  max mem: 14938
[17:34:16.841248] Epoch: [34]  [344/345]  eta: 0:00:00  lr: 0.000063  loss: 0.7227 (0.7222)  time: 0.7498  data: 0.0001  max mem: 14938
[17:34:16.906013] Epoch: [34] Total time: 0:04:18 (0.7499 s / it)
[17:34:16.906547] Averaged stats: lr: 0.000063  loss: 0.7227 (0.7222)
[17:34:17.249816] Test:  [  0/345]  eta: 0:01:56  loss: 0.7067 (0.7067)  time: 0.3385  data: 0.1565  max mem: 14938
[17:34:19.087808] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6949 (0.6955)  time: 0.1978  data: 0.0143  max mem: 14938
[17:34:20.928236] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6949 (0.6952)  time: 0.1839  data: 0.0001  max mem: 14938
[17:34:22.772932] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6963 (0.6960)  time: 0.1842  data: 0.0001  max mem: 14938
[17:34:24.620500] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6977 (0.6966)  time: 0.1846  data: 0.0001  max mem: 14938
[17:34:26.472123] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6999 (0.6969)  time: 0.1849  data: 0.0001  max mem: 14938
[17:34:28.327038] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7000 (0.6979)  time: 0.1853  data: 0.0001  max mem: 14938
[17:34:30.185426] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6991 (0.6976)  time: 0.1856  data: 0.0001  max mem: 14938
[17:34:32.045846] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6972 (0.6981)  time: 0.1859  data: 0.0001  max mem: 14938
[17:34:33.910365] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7002 (0.6984)  time: 0.1862  data: 0.0001  max mem: 14938
[17:34:35.777759] Test:  [100/345]  eta: 0:00:45  loss: 0.7002 (0.6984)  time: 0.1865  data: 0.0001  max mem: 14938
[17:34:37.649842] Test:  [110/345]  eta: 0:00:43  loss: 0.7002 (0.6982)  time: 0.1869  data: 0.0001  max mem: 14938
[17:34:39.526797] Test:  [120/345]  eta: 0:00:42  loss: 0.6991 (0.6986)  time: 0.1874  data: 0.0001  max mem: 14938
[17:34:41.405390] Test:  [130/345]  eta: 0:00:40  loss: 0.6991 (0.6985)  time: 0.1877  data: 0.0001  max mem: 14938
[17:34:43.286339] Test:  [140/345]  eta: 0:00:38  loss: 0.6989 (0.6983)  time: 0.1879  data: 0.0001  max mem: 14938
[17:34:45.171478] Test:  [150/345]  eta: 0:00:36  loss: 0.6941 (0.6982)  time: 0.1883  data: 0.0001  max mem: 14938
[17:34:47.061268] Test:  [160/345]  eta: 0:00:34  loss: 0.6941 (0.6977)  time: 0.1887  data: 0.0001  max mem: 14938
[17:34:48.953164] Test:  [170/345]  eta: 0:00:32  loss: 0.6945 (0.6980)  time: 0.1890  data: 0.0001  max mem: 14938
[17:34:50.851261] Test:  [180/345]  eta: 0:00:30  loss: 0.6961 (0.6977)  time: 0.1894  data: 0.0001  max mem: 14938
[17:34:52.752118] Test:  [190/345]  eta: 0:00:29  loss: 0.6961 (0.6980)  time: 0.1899  data: 0.0001  max mem: 14938
[17:34:54.656287] Test:  [200/345]  eta: 0:00:27  loss: 0.6932 (0.6977)  time: 0.1902  data: 0.0001  max mem: 14938
[17:34:56.562984] Test:  [210/345]  eta: 0:00:25  loss: 0.6976 (0.6978)  time: 0.1905  data: 0.0001  max mem: 14938
[17:34:58.471505] Test:  [220/345]  eta: 0:00:23  loss: 0.6976 (0.6977)  time: 0.1907  data: 0.0001  max mem: 14938
[17:35:00.386764] Test:  [230/345]  eta: 0:00:21  loss: 0.6956 (0.6977)  time: 0.1911  data: 0.0001  max mem: 14938
[17:35:02.305175] Test:  [240/345]  eta: 0:00:19  loss: 0.7000 (0.6979)  time: 0.1916  data: 0.0001  max mem: 14938
[17:35:04.227681] Test:  [250/345]  eta: 0:00:17  loss: 0.6973 (0.6978)  time: 0.1920  data: 0.0001  max mem: 14938
[17:35:06.153421] Test:  [260/345]  eta: 0:00:16  loss: 0.6905 (0.6979)  time: 0.1924  data: 0.0001  max mem: 14938
[17:35:08.082840] Test:  [270/345]  eta: 0:00:14  loss: 0.6962 (0.6979)  time: 0.1927  data: 0.0001  max mem: 14938
[17:35:10.015544] Test:  [280/345]  eta: 0:00:12  loss: 0.6953 (0.6977)  time: 0.1931  data: 0.0001  max mem: 14938
[17:35:11.951722] Test:  [290/345]  eta: 0:00:10  loss: 0.6935 (0.6975)  time: 0.1934  data: 0.0001  max mem: 14938
[17:35:13.891205] Test:  [300/345]  eta: 0:00:08  loss: 0.6955 (0.6974)  time: 0.1937  data: 0.0001  max mem: 14938
[17:35:15.832706] Test:  [310/345]  eta: 0:00:06  loss: 0.6894 (0.6975)  time: 0.1940  data: 0.0001  max mem: 14938
[17:35:17.776578] Test:  [320/345]  eta: 0:00:04  loss: 0.6894 (0.6973)  time: 0.1942  data: 0.0001  max mem: 14938
[17:35:19.724042] Test:  [330/345]  eta: 0:00:02  loss: 0.6939 (0.6972)  time: 0.1945  data: 0.0001  max mem: 14938
[17:35:21.674601] Test:  [340/345]  eta: 0:00:00  loss: 0.6961 (0.6972)  time: 0.1949  data: 0.0001  max mem: 14938
[17:35:22.456792] Test:  [344/345]  eta: 0:00:00  loss: 0.6959 (0.6971)  time: 0.1950  data: 0.0001  max mem: 14938
[17:35:22.519716] Test: Total time: 0:01:05 (0.1902 s / it)
[17:35:33.281050] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8460 (0.8460)  time: 0.3282  data: 0.1488  max mem: 14938
[17:35:35.096958] Test:  [10/57]  eta: 0:00:09  loss: 0.8936 (0.8803)  time: 0.1949  data: 0.0136  max mem: 14938
[17:35:36.920252] Test:  [20/57]  eta: 0:00:06  loss: 0.8936 (0.8673)  time: 0.1819  data: 0.0001  max mem: 14938
[17:35:38.747288] Test:  [30/57]  eta: 0:00:05  loss: 0.7571 (0.8283)  time: 0.1825  data: 0.0001  max mem: 14938
[17:35:40.578282] Test:  [40/57]  eta: 0:00:03  loss: 0.7472 (0.8095)  time: 0.1828  data: 0.0001  max mem: 14938
[17:35:42.415581] Test:  [50/57]  eta: 0:00:01  loss: 0.7541 (0.8037)  time: 0.1834  data: 0.0001  max mem: 14938
[17:35:43.406091] Test:  [56/57]  eta: 0:00:00  loss: 0.7583 (0.8096)  time: 0.1779  data: 0.0001  max mem: 14938
[17:35:43.468514] Test: Total time: 0:00:10 (0.1845 s / it)
[17:35:45.318250] Dice score of the network on the train images: 0.823119, val images: 0.815333
[17:35:45.322432] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:35:46.214009] Epoch: [35]  [  0/345]  eta: 0:05:07  lr: 0.000063  loss: 0.7413 (0.7413)  time: 0.8906  data: 0.1483  max mem: 14938
[17:36:01.112202] Epoch: [35]  [ 20/345]  eta: 0:04:04  lr: 0.000062  loss: 0.7146 (0.7178)  time: 0.7449  data: 0.0001  max mem: 14938
[17:36:16.062197] Epoch: [35]  [ 40/345]  eta: 0:03:48  lr: 0.000062  loss: 0.7190 (0.7195)  time: 0.7475  data: 0.0001  max mem: 14938
[17:36:31.044739] Epoch: [35]  [ 60/345]  eta: 0:03:33  lr: 0.000061  loss: 0.7161 (0.7194)  time: 0.7491  data: 0.0001  max mem: 14938
[17:36:46.051107] Epoch: [35]  [ 80/345]  eta: 0:03:18  lr: 0.000061  loss: 0.7170 (0.7190)  time: 0.7503  data: 0.0001  max mem: 14938
[17:37:01.081205] Epoch: [35]  [100/345]  eta: 0:03:03  lr: 0.000061  loss: 0.7168 (0.7192)  time: 0.7515  data: 0.0001  max mem: 14938
[17:37:16.133001] Epoch: [35]  [120/345]  eta: 0:02:48  lr: 0.000060  loss: 0.7269 (0.7203)  time: 0.7525  data: 0.0001  max mem: 14938
[17:37:31.183148] Epoch: [35]  [140/345]  eta: 0:02:33  lr: 0.000060  loss: 0.7253 (0.7212)  time: 0.7525  data: 0.0001  max mem: 14938
[17:37:46.219492] Epoch: [35]  [160/345]  eta: 0:02:18  lr: 0.000059  loss: 0.7199 (0.7211)  time: 0.7518  data: 0.0001  max mem: 14938
[17:38:01.247446] Epoch: [35]  [180/345]  eta: 0:02:03  lr: 0.000059  loss: 0.7199 (0.7215)  time: 0.7513  data: 0.0001  max mem: 14938
[17:38:16.259984] Epoch: [35]  [200/345]  eta: 0:01:48  lr: 0.000059  loss: 0.7191 (0.7212)  time: 0.7506  data: 0.0001  max mem: 14938
[17:38:31.258114] Epoch: [35]  [220/345]  eta: 0:01:33  lr: 0.000058  loss: 0.7197 (0.7210)  time: 0.7499  data: 0.0001  max mem: 14938
[17:38:46.252586] Epoch: [35]  [240/345]  eta: 0:01:18  lr: 0.000058  loss: 0.7171 (0.7209)  time: 0.7497  data: 0.0001  max mem: 14938
[17:39:01.243019] Epoch: [35]  [260/345]  eta: 0:01:03  lr: 0.000058  loss: 0.7160 (0.7209)  time: 0.7495  data: 0.0001  max mem: 14938
[17:39:16.226781] Epoch: [35]  [280/345]  eta: 0:00:48  lr: 0.000057  loss: 0.7177 (0.7208)  time: 0.7491  data: 0.0001  max mem: 14938
[17:39:31.223682] Epoch: [35]  [300/345]  eta: 0:00:33  lr: 0.000057  loss: 0.7147 (0.7208)  time: 0.7498  data: 0.0001  max mem: 14938
[17:39:46.217924] Epoch: [35]  [320/345]  eta: 0:00:18  lr: 0.000056  loss: 0.7170 (0.7206)  time: 0.7497  data: 0.0001  max mem: 14938
[17:40:01.209633] Epoch: [35]  [340/345]  eta: 0:00:03  lr: 0.000056  loss: 0.7179 (0.7206)  time: 0.7495  data: 0.0001  max mem: 14938
[17:40:04.206623] Epoch: [35]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.7132 (0.7206)  time: 0.7495  data: 0.0001  max mem: 14938
[17:40:04.275107] Epoch: [35] Total time: 0:04:18 (0.7506 s / it)
[17:40:04.275458] Averaged stats: lr: 0.000056  loss: 0.7132 (0.7206)
[17:40:04.616992] Test:  [  0/345]  eta: 0:01:56  loss: 0.7209 (0.7209)  time: 0.3376  data: 0.1556  max mem: 14938
[17:40:06.454491] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7028 (0.7053)  time: 0.1977  data: 0.0142  max mem: 14938
[17:40:08.296652] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6988 (0.6993)  time: 0.1839  data: 0.0001  max mem: 14938
[17:40:10.140806] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6917 (0.6975)  time: 0.1843  data: 0.0001  max mem: 14938
[17:40:11.987706] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6912 (0.6961)  time: 0.1845  data: 0.0001  max mem: 14938
[17:40:13.839333] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6912 (0.6959)  time: 0.1849  data: 0.0001  max mem: 14938
[17:40:15.694228] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6906 (0.6952)  time: 0.1853  data: 0.0001  max mem: 14938
[17:40:17.551096] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6906 (0.6951)  time: 0.1855  data: 0.0001  max mem: 14938
[17:40:19.411788] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6967 (0.6960)  time: 0.1858  data: 0.0001  max mem: 14938
[17:40:21.277716] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6987 (0.6960)  time: 0.1863  data: 0.0001  max mem: 14938
[17:40:23.145468] Test:  [100/345]  eta: 0:00:45  loss: 0.6990 (0.6965)  time: 0.1866  data: 0.0001  max mem: 14938
[17:40:25.016373] Test:  [110/345]  eta: 0:00:43  loss: 0.7006 (0.6969)  time: 0.1869  data: 0.0001  max mem: 14938
[17:40:26.891749] Test:  [120/345]  eta: 0:00:42  loss: 0.6988 (0.6970)  time: 0.1873  data: 0.0001  max mem: 14938
[17:40:28.769944] Test:  [130/345]  eta: 0:00:40  loss: 0.6980 (0.6969)  time: 0.1876  data: 0.0001  max mem: 14938
[17:40:30.651646] Test:  [140/345]  eta: 0:00:38  loss: 0.6980 (0.6970)  time: 0.1879  data: 0.0001  max mem: 14938
[17:40:32.538074] Test:  [150/345]  eta: 0:00:36  loss: 0.6927 (0.6970)  time: 0.1884  data: 0.0001  max mem: 14938
[17:40:34.426111] Test:  [160/345]  eta: 0:00:34  loss: 0.6908 (0.6970)  time: 0.1887  data: 0.0001  max mem: 14938
[17:40:36.319337] Test:  [170/345]  eta: 0:00:32  loss: 0.6963 (0.6973)  time: 0.1890  data: 0.0001  max mem: 14938
[17:40:38.215709] Test:  [180/345]  eta: 0:00:30  loss: 0.6920 (0.6972)  time: 0.1894  data: 0.0001  max mem: 14938
[17:40:40.115386] Test:  [190/345]  eta: 0:00:29  loss: 0.6913 (0.6971)  time: 0.1897  data: 0.0001  max mem: 14938
[17:40:42.016717] Test:  [200/345]  eta: 0:00:27  loss: 0.6933 (0.6970)  time: 0.1900  data: 0.0001  max mem: 14938
[17:40:43.925051] Test:  [210/345]  eta: 0:00:25  loss: 0.6945 (0.6970)  time: 0.1904  data: 0.0001  max mem: 14938
[17:40:45.836317] Test:  [220/345]  eta: 0:00:23  loss: 0.6968 (0.6972)  time: 0.1909  data: 0.0001  max mem: 14938
[17:40:47.750476] Test:  [230/345]  eta: 0:00:21  loss: 0.6969 (0.6971)  time: 0.1912  data: 0.0001  max mem: 14938
[17:40:49.668633] Test:  [240/345]  eta: 0:00:19  loss: 0.6916 (0.6968)  time: 0.1916  data: 0.0001  max mem: 14938
[17:40:51.591662] Test:  [250/345]  eta: 0:00:17  loss: 0.6891 (0.6966)  time: 0.1920  data: 0.0001  max mem: 14938
[17:40:53.516548] Test:  [260/345]  eta: 0:00:16  loss: 0.6916 (0.6965)  time: 0.1923  data: 0.0001  max mem: 14938
[17:40:55.443685] Test:  [270/345]  eta: 0:00:14  loss: 0.6932 (0.6963)  time: 0.1925  data: 0.0001  max mem: 14938
[17:40:57.374291] Test:  [280/345]  eta: 0:00:12  loss: 0.6891 (0.6962)  time: 0.1928  data: 0.0001  max mem: 14938
[17:40:59.311328] Test:  [290/345]  eta: 0:00:10  loss: 0.6887 (0.6959)  time: 0.1933  data: 0.0001  max mem: 14938
[17:41:01.250544] Test:  [300/345]  eta: 0:00:08  loss: 0.6921 (0.6962)  time: 0.1938  data: 0.0001  max mem: 14938
[17:41:03.195020] Test:  [310/345]  eta: 0:00:06  loss: 0.7042 (0.6964)  time: 0.1941  data: 0.0001  max mem: 14938
[17:41:05.140554] Test:  [320/345]  eta: 0:00:04  loss: 0.6990 (0.6964)  time: 0.1944  data: 0.0001  max mem: 14938
[17:41:07.087807] Test:  [330/345]  eta: 0:00:02  loss: 0.6977 (0.6964)  time: 0.1946  data: 0.0001  max mem: 14938
[17:41:09.037888] Test:  [340/345]  eta: 0:00:00  loss: 0.6955 (0.6964)  time: 0.1948  data: 0.0001  max mem: 14938
[17:41:09.819521] Test:  [344/345]  eta: 0:00:00  loss: 0.6948 (0.6963)  time: 0.1949  data: 0.0001  max mem: 14938
[17:41:09.878129] Test: Total time: 0:01:05 (0.1901 s / it)
[17:41:20.616805] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8655 (0.8655)  time: 0.3238  data: 0.1438  max mem: 14938
[17:41:22.430619] Test:  [10/57]  eta: 0:00:09  loss: 0.8875 (0.8854)  time: 0.1942  data: 0.0131  max mem: 14938
[17:41:24.252378] Test:  [20/57]  eta: 0:00:06  loss: 0.8932 (0.8753)  time: 0.1817  data: 0.0001  max mem: 14938
[17:41:26.078378] Test:  [30/57]  eta: 0:00:05  loss: 0.7580 (0.8341)  time: 0.1823  data: 0.0001  max mem: 14938
[17:41:27.910070] Test:  [40/57]  eta: 0:00:03  loss: 0.7477 (0.8135)  time: 0.1828  data: 0.0001  max mem: 14938
[17:41:29.745660] Test:  [50/57]  eta: 0:00:01  loss: 0.7404 (0.8063)  time: 0.1833  data: 0.0001  max mem: 14938
[17:41:30.734936] Test:  [56/57]  eta: 0:00:00  loss: 0.7536 (0.8114)  time: 0.1778  data: 0.0001  max mem: 14938
[17:41:30.798440] Test: Total time: 0:00:10 (0.1843 s / it)
[17:41:32.635832] Dice score of the network on the train images: 0.830310, val images: 0.820134
[17:41:32.636069] saving best_prec_model_0 @ epoch 35
[17:41:33.741720] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:41:34.633764] Epoch: [36]  [  0/345]  eta: 0:05:07  lr: 0.000056  loss: 0.7080 (0.7080)  time: 0.8909  data: 0.1477  max mem: 14938
[17:41:49.517220] Epoch: [36]  [ 20/345]  eta: 0:04:04  lr: 0.000056  loss: 0.7203 (0.7201)  time: 0.7441  data: 0.0001  max mem: 14938
[17:42:04.451675] Epoch: [36]  [ 40/345]  eta: 0:03:48  lr: 0.000055  loss: 0.7146 (0.7186)  time: 0.7467  data: 0.0001  max mem: 14938
[17:42:19.424086] Epoch: [36]  [ 60/345]  eta: 0:03:33  lr: 0.000055  loss: 0.7197 (0.7196)  time: 0.7485  data: 0.0001  max mem: 14938
[17:42:34.441003] Epoch: [36]  [ 80/345]  eta: 0:03:18  lr: 0.000054  loss: 0.7216 (0.7194)  time: 0.7508  data: 0.0001  max mem: 14938
[17:42:49.474658] Epoch: [36]  [100/345]  eta: 0:03:03  lr: 0.000054  loss: 0.7152 (0.7190)  time: 0.7516  data: 0.0001  max mem: 14938
[17:43:04.532227] Epoch: [36]  [120/345]  eta: 0:02:48  lr: 0.000054  loss: 0.7219 (0.7198)  time: 0.7528  data: 0.0001  max mem: 14938
[17:43:19.560427] Epoch: [36]  [140/345]  eta: 0:02:33  lr: 0.000053  loss: 0.7205 (0.7195)  time: 0.7514  data: 0.0001  max mem: 14938
[17:43:34.591809] Epoch: [36]  [160/345]  eta: 0:02:18  lr: 0.000053  loss: 0.7174 (0.7197)  time: 0.7515  data: 0.0001  max mem: 14938
[17:43:49.625970] Epoch: [36]  [180/345]  eta: 0:02:03  lr: 0.000053  loss: 0.7197 (0.7201)  time: 0.7517  data: 0.0001  max mem: 14938
[17:44:04.635892] Epoch: [36]  [200/345]  eta: 0:01:48  lr: 0.000052  loss: 0.7157 (0.7197)  time: 0.7505  data: 0.0001  max mem: 14938
[17:44:19.645881] Epoch: [36]  [220/345]  eta: 0:01:33  lr: 0.000052  loss: 0.7184 (0.7197)  time: 0.7505  data: 0.0001  max mem: 14938
[17:44:34.659129] Epoch: [36]  [240/345]  eta: 0:01:18  lr: 0.000051  loss: 0.7181 (0.7198)  time: 0.7506  data: 0.0001  max mem: 14938
[17:44:49.667862] Epoch: [36]  [260/345]  eta: 0:01:03  lr: 0.000051  loss: 0.7147 (0.7194)  time: 0.7504  data: 0.0001  max mem: 14938
[17:45:04.663667] Epoch: [36]  [280/345]  eta: 0:00:48  lr: 0.000051  loss: 0.7152 (0.7192)  time: 0.7497  data: 0.0001  max mem: 14938
[17:45:19.656791] Epoch: [36]  [300/345]  eta: 0:00:33  lr: 0.000050  loss: 0.7143 (0.7190)  time: 0.7496  data: 0.0001  max mem: 14938
[17:45:34.649482] Epoch: [36]  [320/345]  eta: 0:00:18  lr: 0.000050  loss: 0.7146 (0.7190)  time: 0.7496  data: 0.0001  max mem: 14938
[17:45:49.639996] Epoch: [36]  [340/345]  eta: 0:00:03  lr: 0.000050  loss: 0.7232 (0.7191)  time: 0.7495  data: 0.0001  max mem: 14938
[17:45:52.638890] Epoch: [36]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.7222 (0.7192)  time: 0.7495  data: 0.0001  max mem: 14938
[17:45:52.706788] Epoch: [36] Total time: 0:04:18 (0.7506 s / it)
[17:45:52.707118] Averaged stats: lr: 0.000050  loss: 0.7222 (0.7192)
[17:45:53.054323] Test:  [  0/345]  eta: 0:01:58  loss: 0.6879 (0.6879)  time: 0.3426  data: 0.1604  max mem: 14938
[17:45:54.891807] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6956 (0.6947)  time: 0.1981  data: 0.0146  max mem: 14938
[17:45:56.732831] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6934 (0.6939)  time: 0.1839  data: 0.0001  max mem: 14938
[17:45:58.574702] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6910 (0.6931)  time: 0.1841  data: 0.0001  max mem: 14938
[17:46:00.421656] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6861 (0.6923)  time: 0.1844  data: 0.0001  max mem: 14938
[17:46:02.273698] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6964 (0.6935)  time: 0.1849  data: 0.0001  max mem: 14938
[17:46:04.128125] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6916 (0.6927)  time: 0.1853  data: 0.0001  max mem: 14938
[17:46:05.984972] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6888 (0.6919)  time: 0.1855  data: 0.0001  max mem: 14938
[17:46:07.845497] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6888 (0.6913)  time: 0.1858  data: 0.0001  max mem: 14938
[17:46:09.711274] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6905 (0.6921)  time: 0.1863  data: 0.0001  max mem: 14938
[17:46:11.579444] Test:  [100/345]  eta: 0:00:45  loss: 0.6922 (0.6922)  time: 0.1866  data: 0.0001  max mem: 14938
[17:46:13.448796] Test:  [110/345]  eta: 0:00:43  loss: 0.6922 (0.6924)  time: 0.1868  data: 0.0001  max mem: 14938
[17:46:15.323224] Test:  [120/345]  eta: 0:00:42  loss: 0.6965 (0.6928)  time: 0.1871  data: 0.0001  max mem: 14938
[17:46:17.201374] Test:  [130/345]  eta: 0:00:40  loss: 0.6943 (0.6929)  time: 0.1876  data: 0.0001  max mem: 14938
[17:46:19.082101] Test:  [140/345]  eta: 0:00:38  loss: 0.6936 (0.6928)  time: 0.1879  data: 0.0001  max mem: 14938
[17:46:20.968124] Test:  [150/345]  eta: 0:00:36  loss: 0.6907 (0.6927)  time: 0.1883  data: 0.0001  max mem: 14938
[17:46:22.856251] Test:  [160/345]  eta: 0:00:34  loss: 0.6978 (0.6931)  time: 0.1887  data: 0.0001  max mem: 14938
[17:46:24.748741] Test:  [170/345]  eta: 0:00:32  loss: 0.6980 (0.6935)  time: 0.1890  data: 0.0001  max mem: 14938
[17:46:26.646917] Test:  [180/345]  eta: 0:00:30  loss: 0.6947 (0.6936)  time: 0.1895  data: 0.0001  max mem: 14938
[17:46:28.547299] Test:  [190/345]  eta: 0:00:29  loss: 0.6928 (0.6935)  time: 0.1899  data: 0.0001  max mem: 14938
[17:46:30.450717] Test:  [200/345]  eta: 0:00:27  loss: 0.6916 (0.6935)  time: 0.1901  data: 0.0001  max mem: 14938
[17:46:32.356458] Test:  [210/345]  eta: 0:00:25  loss: 0.6892 (0.6933)  time: 0.1904  data: 0.0001  max mem: 14938
[17:46:34.267867] Test:  [220/345]  eta: 0:00:23  loss: 0.6888 (0.6933)  time: 0.1908  data: 0.0001  max mem: 14938
[17:46:36.181399] Test:  [230/345]  eta: 0:00:21  loss: 0.6890 (0.6930)  time: 0.1912  data: 0.0001  max mem: 14938
[17:46:38.098067] Test:  [240/345]  eta: 0:00:19  loss: 0.6877 (0.6930)  time: 0.1915  data: 0.0001  max mem: 14938
[17:46:40.019541] Test:  [250/345]  eta: 0:00:17  loss: 0.6877 (0.6927)  time: 0.1919  data: 0.0001  max mem: 14938
[17:46:41.945017] Test:  [260/345]  eta: 0:00:16  loss: 0.6868 (0.6927)  time: 0.1923  data: 0.0001  max mem: 14938
[17:46:43.874034] Test:  [270/345]  eta: 0:00:14  loss: 0.6919 (0.6928)  time: 0.1926  data: 0.0001  max mem: 14938
[17:46:45.806362] Test:  [280/345]  eta: 0:00:12  loss: 0.6925 (0.6929)  time: 0.1930  data: 0.0001  max mem: 14938
[17:46:47.741709] Test:  [290/345]  eta: 0:00:10  loss: 0.6970 (0.6930)  time: 0.1933  data: 0.0001  max mem: 14938
[17:46:49.680485] Test:  [300/345]  eta: 0:00:08  loss: 0.6962 (0.6930)  time: 0.1937  data: 0.0001  max mem: 14938
[17:46:51.622163] Test:  [310/345]  eta: 0:00:06  loss: 0.6933 (0.6929)  time: 0.1940  data: 0.0001  max mem: 14938
[17:46:53.566234] Test:  [320/345]  eta: 0:00:04  loss: 0.6951 (0.6931)  time: 0.1942  data: 0.0001  max mem: 14938
[17:46:55.514524] Test:  [330/345]  eta: 0:00:02  loss: 0.7003 (0.6933)  time: 0.1946  data: 0.0001  max mem: 14938
[17:46:57.467457] Test:  [340/345]  eta: 0:00:00  loss: 0.6948 (0.6933)  time: 0.1950  data: 0.0001  max mem: 14938
[17:46:58.248768] Test:  [344/345]  eta: 0:00:00  loss: 0.6912 (0.6932)  time: 0.1951  data: 0.0001  max mem: 14938
[17:46:58.311545] Test: Total time: 0:01:05 (0.1901 s / it)
[17:47:09.161147] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8554 (0.8554)  time: 0.3279  data: 0.1480  max mem: 14938
[17:47:10.976108] Test:  [10/57]  eta: 0:00:09  loss: 0.8897 (0.8828)  time: 0.1947  data: 0.0135  max mem: 14938
[17:47:12.798057] Test:  [20/57]  eta: 0:00:06  loss: 0.8897 (0.8742)  time: 0.1818  data: 0.0001  max mem: 14938
[17:47:14.623474] Test:  [30/57]  eta: 0:00:05  loss: 0.7565 (0.8320)  time: 0.1823  data: 0.0001  max mem: 14938
[17:47:16.454775] Test:  [40/57]  eta: 0:00:03  loss: 0.7463 (0.8115)  time: 0.1828  data: 0.0001  max mem: 14938
[17:47:18.290344] Test:  [50/57]  eta: 0:00:01  loss: 0.7461 (0.8041)  time: 0.1833  data: 0.0001  max mem: 14938
[17:47:19.279848] Test:  [56/57]  eta: 0:00:00  loss: 0.7497 (0.8092)  time: 0.1779  data: 0.0001  max mem: 14938
[17:47:19.335823] Test: Total time: 0:00:10 (0.1843 s / it)
[17:47:21.218277] Dice score of the network on the train images: 0.831162, val images: 0.818003
[17:47:21.222035] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:47:22.114039] Epoch: [37]  [  0/345]  eta: 0:05:07  lr: 0.000050  loss: 0.7177 (0.7177)  time: 0.8912  data: 0.1490  max mem: 14938
[17:47:37.009657] Epoch: [37]  [ 20/345]  eta: 0:04:04  lr: 0.000049  loss: 0.7125 (0.7149)  time: 0.7447  data: 0.0001  max mem: 14938
[17:47:51.940612] Epoch: [37]  [ 40/345]  eta: 0:03:48  lr: 0.000049  loss: 0.7112 (0.7140)  time: 0.7465  data: 0.0001  max mem: 14938
[17:48:06.907887] Epoch: [37]  [ 60/345]  eta: 0:03:33  lr: 0.000048  loss: 0.7170 (0.7151)  time: 0.7483  data: 0.0001  max mem: 14938
[17:48:21.916072] Epoch: [37]  [ 80/345]  eta: 0:03:18  lr: 0.000048  loss: 0.7198 (0.7159)  time: 0.7504  data: 0.0001  max mem: 14938
[17:48:36.943536] Epoch: [37]  [100/345]  eta: 0:03:03  lr: 0.000048  loss: 0.7185 (0.7158)  time: 0.7513  data: 0.0001  max mem: 14938
[17:48:51.991362] Epoch: [37]  [120/345]  eta: 0:02:48  lr: 0.000047  loss: 0.7125 (0.7159)  time: 0.7523  data: 0.0001  max mem: 14938
[17:49:07.033767] Epoch: [37]  [140/345]  eta: 0:02:33  lr: 0.000047  loss: 0.7091 (0.7157)  time: 0.7521  data: 0.0001  max mem: 14938
[17:49:22.067680] Epoch: [37]  [160/345]  eta: 0:02:18  lr: 0.000047  loss: 0.7171 (0.7158)  time: 0.7517  data: 0.0001  max mem: 14938
[17:49:37.088824] Epoch: [37]  [180/345]  eta: 0:02:03  lr: 0.000046  loss: 0.7149 (0.7160)  time: 0.7510  data: 0.0001  max mem: 14938
[17:49:52.109652] Epoch: [37]  [200/345]  eta: 0:01:48  lr: 0.000046  loss: 0.7135 (0.7160)  time: 0.7510  data: 0.0001  max mem: 14938
[17:50:07.122367] Epoch: [37]  [220/345]  eta: 0:01:33  lr: 0.000045  loss: 0.7135 (0.7160)  time: 0.7506  data: 0.0001  max mem: 14938
[17:50:22.122059] Epoch: [37]  [240/345]  eta: 0:01:18  lr: 0.000045  loss: 0.7127 (0.7161)  time: 0.7499  data: 0.0001  max mem: 14938
[17:50:37.128225] Epoch: [37]  [260/345]  eta: 0:01:03  lr: 0.000045  loss: 0.7209 (0.7166)  time: 0.7503  data: 0.0001  max mem: 14938
[17:50:52.125190] Epoch: [37]  [280/345]  eta: 0:00:48  lr: 0.000044  loss: 0.7126 (0.7166)  time: 0.7498  data: 0.0001  max mem: 14938
[17:51:07.115580] Epoch: [37]  [300/345]  eta: 0:00:33  lr: 0.000044  loss: 0.7162 (0.7165)  time: 0.7495  data: 0.0001  max mem: 14938
[17:51:22.104942] Epoch: [37]  [320/345]  eta: 0:00:18  lr: 0.000044  loss: 0.7145 (0.7164)  time: 0.7494  data: 0.0001  max mem: 14938
[17:51:37.176235] Epoch: [37]  [340/345]  eta: 0:00:03  lr: 0.000043  loss: 0.7190 (0.7166)  time: 0.7535  data: 0.0001  max mem: 14938
[17:51:40.173983] Epoch: [37]  [344/345]  eta: 0:00:00  lr: 0.000043  loss: 0.7187 (0.7166)  time: 0.7491  data: 0.0001  max mem: 14938
[17:51:40.240003] Epoch: [37] Total time: 0:04:19 (0.7508 s / it)
[17:51:40.240306] Averaged stats: lr: 0.000043  loss: 0.7187 (0.7166)
[17:51:40.589184] Test:  [  0/345]  eta: 0:01:58  loss: 0.7061 (0.7061)  time: 0.3449  data: 0.1631  max mem: 14938
[17:51:42.426546] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6873 (0.6936)  time: 0.1983  data: 0.0149  max mem: 14938
[17:51:44.265994] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6866 (0.6918)  time: 0.1838  data: 0.0001  max mem: 14938
[17:51:46.108856] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6884 (0.6924)  time: 0.1841  data: 0.0001  max mem: 14938
[17:51:47.956605] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6892 (0.6923)  time: 0.1845  data: 0.0001  max mem: 14938
[17:51:49.808080] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6918 (0.6920)  time: 0.1849  data: 0.0001  max mem: 14938
[17:51:51.662839] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6865 (0.6913)  time: 0.1853  data: 0.0001  max mem: 14938
[17:51:53.519952] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6852 (0.6902)  time: 0.1855  data: 0.0001  max mem: 14938
[17:51:55.379342] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6837 (0.6896)  time: 0.1858  data: 0.0001  max mem: 14938
[17:51:57.243753] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6889 (0.6900)  time: 0.1861  data: 0.0001  max mem: 14938
[17:51:59.112919] Test:  [100/345]  eta: 0:00:45  loss: 0.6927 (0.6901)  time: 0.1866  data: 0.0001  max mem: 14938
[17:52:00.981168] Test:  [110/345]  eta: 0:00:43  loss: 0.6952 (0.6906)  time: 0.1868  data: 0.0001  max mem: 14938
[17:52:02.855564] Test:  [120/345]  eta: 0:00:42  loss: 0.6924 (0.6905)  time: 0.1871  data: 0.0001  max mem: 14938
[17:52:04.735575] Test:  [130/345]  eta: 0:00:40  loss: 0.6909 (0.6908)  time: 0.1877  data: 0.0001  max mem: 14938
[17:52:06.616757] Test:  [140/345]  eta: 0:00:38  loss: 0.6887 (0.6908)  time: 0.1880  data: 0.0001  max mem: 14938
[17:52:08.501270] Test:  [150/345]  eta: 0:00:36  loss: 0.6887 (0.6912)  time: 0.1882  data: 0.0001  max mem: 14938
[17:52:10.389453] Test:  [160/345]  eta: 0:00:34  loss: 0.6917 (0.6911)  time: 0.1886  data: 0.0001  max mem: 14938
[17:52:12.281777] Test:  [170/345]  eta: 0:00:32  loss: 0.6839 (0.6906)  time: 0.1890  data: 0.0001  max mem: 14938
[17:52:14.179699] Test:  [180/345]  eta: 0:00:30  loss: 0.6863 (0.6909)  time: 0.1895  data: 0.0001  max mem: 14938
[17:52:16.078440] Test:  [190/345]  eta: 0:00:29  loss: 0.6929 (0.6913)  time: 0.1898  data: 0.0001  max mem: 14938
[17:52:17.981297] Test:  [200/345]  eta: 0:00:27  loss: 0.6970 (0.6913)  time: 0.1900  data: 0.0001  max mem: 14938
[17:52:19.888308] Test:  [210/345]  eta: 0:00:25  loss: 0.6950 (0.6914)  time: 0.1904  data: 0.0001  max mem: 14938
[17:52:21.798389] Test:  [220/345]  eta: 0:00:23  loss: 0.6931 (0.6915)  time: 0.1908  data: 0.0001  max mem: 14938
[17:52:23.711626] Test:  [230/345]  eta: 0:00:21  loss: 0.6889 (0.6914)  time: 0.1911  data: 0.0001  max mem: 14938
[17:52:25.629239] Test:  [240/345]  eta: 0:00:19  loss: 0.6898 (0.6914)  time: 0.1915  data: 0.0001  max mem: 14938
[17:52:27.548964] Test:  [250/345]  eta: 0:00:17  loss: 0.6916 (0.6913)  time: 0.1918  data: 0.0001  max mem: 14938
[17:52:29.471323] Test:  [260/345]  eta: 0:00:16  loss: 0.6886 (0.6913)  time: 0.1921  data: 0.0001  max mem: 14938
[17:52:31.398048] Test:  [270/345]  eta: 0:00:14  loss: 0.6880 (0.6911)  time: 0.1924  data: 0.0001  max mem: 14938
[17:52:33.332106] Test:  [280/345]  eta: 0:00:12  loss: 0.6867 (0.6910)  time: 0.1930  data: 0.0001  max mem: 14938
[17:52:35.268348] Test:  [290/345]  eta: 0:00:10  loss: 0.6905 (0.6911)  time: 0.1935  data: 0.0001  max mem: 14938
[17:52:37.205828] Test:  [300/345]  eta: 0:00:08  loss: 0.6911 (0.6910)  time: 0.1936  data: 0.0001  max mem: 14938
[17:52:39.148197] Test:  [310/345]  eta: 0:00:06  loss: 0.6860 (0.6909)  time: 0.1939  data: 0.0001  max mem: 14938
[17:52:41.093335] Test:  [320/345]  eta: 0:00:04  loss: 0.6854 (0.6908)  time: 0.1943  data: 0.0001  max mem: 14938
[17:52:43.040311] Test:  [330/345]  eta: 0:00:02  loss: 0.6895 (0.6910)  time: 0.1946  data: 0.0001  max mem: 14938
[17:52:44.989814] Test:  [340/345]  eta: 0:00:00  loss: 0.6937 (0.6912)  time: 0.1948  data: 0.0001  max mem: 14938
[17:52:45.771652] Test:  [344/345]  eta: 0:00:00  loss: 0.7005 (0.6914)  time: 0.1949  data: 0.0001  max mem: 14938
[17:52:45.832507] Test: Total time: 0:01:05 (0.1901 s / it)
[17:52:56.659271] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8381 (0.8381)  time: 0.3306  data: 0.1514  max mem: 14938
[17:52:58.474854] Test:  [10/57]  eta: 0:00:09  loss: 0.8990 (0.8886)  time: 0.1950  data: 0.0138  max mem: 14938
[17:53:00.296896] Test:  [20/57]  eta: 0:00:06  loss: 0.8990 (0.8804)  time: 0.1818  data: 0.0001  max mem: 14938
[17:53:02.124093] Test:  [30/57]  eta: 0:00:05  loss: 0.7585 (0.8375)  time: 0.1824  data: 0.0001  max mem: 14938
[17:53:03.954711] Test:  [40/57]  eta: 0:00:03  loss: 0.7504 (0.8165)  time: 0.1828  data: 0.0001  max mem: 14938
[17:53:05.790898] Test:  [50/57]  eta: 0:00:01  loss: 0.7481 (0.8093)  time: 0.1833  data: 0.0001  max mem: 14938
[17:53:06.779383] Test:  [56/57]  eta: 0:00:00  loss: 0.7573 (0.8146)  time: 0.1778  data: 0.0001  max mem: 14938
[17:53:06.839528] Test: Total time: 0:00:10 (0.1844 s / it)
[17:53:08.670775] Dice score of the network on the train images: 0.837495, val images: 0.815174
[17:53:08.671010] saving best_prec_model_0 @ epoch 37
[17:53:09.744495] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:53:10.633919] Epoch: [38]  [  0/345]  eta: 0:05:06  lr: 0.000043  loss: 0.7200 (0.7200)  time: 0.8882  data: 0.1464  max mem: 14938
[17:53:25.513411] Epoch: [38]  [ 20/345]  eta: 0:04:04  lr: 0.000043  loss: 0.7167 (0.7140)  time: 0.7439  data: 0.0001  max mem: 14938
[17:53:40.441107] Epoch: [38]  [ 40/345]  eta: 0:03:48  lr: 0.000042  loss: 0.7154 (0.7146)  time: 0.7463  data: 0.0001  max mem: 14938
[17:53:55.398391] Epoch: [38]  [ 60/345]  eta: 0:03:33  lr: 0.000042  loss: 0.7147 (0.7151)  time: 0.7478  data: 0.0001  max mem: 14938
[17:54:10.391308] Epoch: [38]  [ 80/345]  eta: 0:03:18  lr: 0.000042  loss: 0.7131 (0.7148)  time: 0.7496  data: 0.0001  max mem: 14938
[17:54:25.421472] Epoch: [38]  [100/345]  eta: 0:03:03  lr: 0.000041  loss: 0.7151 (0.7148)  time: 0.7515  data: 0.0001  max mem: 14938
[17:54:40.464813] Epoch: [38]  [120/345]  eta: 0:02:48  lr: 0.000041  loss: 0.7162 (0.7153)  time: 0.7521  data: 0.0001  max mem: 14938
[17:54:55.504198] Epoch: [38]  [140/345]  eta: 0:02:33  lr: 0.000041  loss: 0.7149 (0.7152)  time: 0.7519  data: 0.0001  max mem: 14938
[17:55:10.532176] Epoch: [38]  [160/345]  eta: 0:02:18  lr: 0.000040  loss: 0.7079 (0.7149)  time: 0.7514  data: 0.0001  max mem: 14938
[17:55:25.558088] Epoch: [38]  [180/345]  eta: 0:02:03  lr: 0.000040  loss: 0.7079 (0.7143)  time: 0.7513  data: 0.0001  max mem: 14938
[17:55:40.574965] Epoch: [38]  [200/345]  eta: 0:01:48  lr: 0.000040  loss: 0.7136 (0.7145)  time: 0.7508  data: 0.0001  max mem: 14938
[17:55:55.583669] Epoch: [38]  [220/345]  eta: 0:01:33  lr: 0.000039  loss: 0.7122 (0.7144)  time: 0.7504  data: 0.0001  max mem: 14938
[17:56:10.592010] Epoch: [38]  [240/345]  eta: 0:01:18  lr: 0.000039  loss: 0.7133 (0.7143)  time: 0.7504  data: 0.0001  max mem: 14938
[17:56:25.588376] Epoch: [38]  [260/345]  eta: 0:01:03  lr: 0.000039  loss: 0.7063 (0.7139)  time: 0.7498  data: 0.0001  max mem: 14938
[17:56:40.580646] Epoch: [38]  [280/345]  eta: 0:00:48  lr: 0.000038  loss: 0.7151 (0.7142)  time: 0.7496  data: 0.0001  max mem: 14938
[17:56:55.584057] Epoch: [38]  [300/345]  eta: 0:00:33  lr: 0.000038  loss: 0.7167 (0.7144)  time: 0.7501  data: 0.0001  max mem: 14938
[17:57:10.580373] Epoch: [38]  [320/345]  eta: 0:00:18  lr: 0.000038  loss: 0.7121 (0.7144)  time: 0.7498  data: 0.0001  max mem: 14938
[17:57:25.560454] Epoch: [38]  [340/345]  eta: 0:00:03  lr: 0.000037  loss: 0.7210 (0.7147)  time: 0.7490  data: 0.0001  max mem: 14938
[17:57:28.559016] Epoch: [38]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 0.7210 (0.7147)  time: 0.7491  data: 0.0001  max mem: 14938
[17:57:28.627163] Epoch: [38] Total time: 0:04:18 (0.7504 s / it)
[17:57:28.627629] Averaged stats: lr: 0.000037  loss: 0.7210 (0.7147)
[17:57:28.973875] Test:  [  0/345]  eta: 0:01:57  loss: 0.6653 (0.6653)  time: 0.3417  data: 0.1597  max mem: 14938
[17:57:30.811073] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6962 (0.6963)  time: 0.1980  data: 0.0146  max mem: 14938
[17:57:32.651087] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6919 (0.6944)  time: 0.1838  data: 0.0001  max mem: 14938
[17:57:34.494586] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6863 (0.6918)  time: 0.1841  data: 0.0001  max mem: 14938
[17:57:36.340375] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6839 (0.6916)  time: 0.1844  data: 0.0001  max mem: 14938
[17:57:38.192412] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6888 (0.6918)  time: 0.1848  data: 0.0001  max mem: 14938
[17:57:40.044982] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6913 (0.6920)  time: 0.1852  data: 0.0001  max mem: 14938
[17:57:41.903185] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6899 (0.6916)  time: 0.1855  data: 0.0001  max mem: 14938
[17:57:43.763280] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6899 (0.6917)  time: 0.1859  data: 0.0001  max mem: 14938
[17:57:45.625605] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6924 (0.6917)  time: 0.1861  data: 0.0001  max mem: 14938
[17:57:47.493265] Test:  [100/345]  eta: 0:00:45  loss: 0.6938 (0.6920)  time: 0.1864  data: 0.0001  max mem: 14938
[17:57:49.364220] Test:  [110/345]  eta: 0:00:43  loss: 0.6927 (0.6921)  time: 0.1869  data: 0.0001  max mem: 14938
[17:57:51.238782] Test:  [120/345]  eta: 0:00:42  loss: 0.6892 (0.6921)  time: 0.1872  data: 0.0001  max mem: 14938
[17:57:53.119054] Test:  [130/345]  eta: 0:00:40  loss: 0.6892 (0.6918)  time: 0.1877  data: 0.0001  max mem: 14938
[17:57:55.001537] Test:  [140/345]  eta: 0:00:38  loss: 0.6861 (0.6915)  time: 0.1881  data: 0.0001  max mem: 14938
[17:57:56.887400] Test:  [150/345]  eta: 0:00:36  loss: 0.6878 (0.6915)  time: 0.1884  data: 0.0001  max mem: 14938
[17:57:58.775328] Test:  [160/345]  eta: 0:00:34  loss: 0.6903 (0.6911)  time: 0.1886  data: 0.0001  max mem: 14938
[17:58:00.665370] Test:  [170/345]  eta: 0:00:32  loss: 0.6910 (0.6914)  time: 0.1888  data: 0.0001  max mem: 14938
[17:58:02.562457] Test:  [180/345]  eta: 0:00:30  loss: 0.6859 (0.6909)  time: 0.1893  data: 0.0001  max mem: 14938
[17:58:04.463835] Test:  [190/345]  eta: 0:00:29  loss: 0.6853 (0.6909)  time: 0.1899  data: 0.0001  max mem: 14938
[17:58:06.365771] Test:  [200/345]  eta: 0:00:27  loss: 0.6935 (0.6909)  time: 0.1901  data: 0.0001  max mem: 14938
[17:58:08.273279] Test:  [210/345]  eta: 0:00:25  loss: 0.6933 (0.6911)  time: 0.1904  data: 0.0001  max mem: 14938
[17:58:10.185637] Test:  [220/345]  eta: 0:00:23  loss: 0.6891 (0.6910)  time: 0.1909  data: 0.0001  max mem: 14938
[17:58:12.099769] Test:  [230/345]  eta: 0:00:21  loss: 0.6895 (0.6913)  time: 0.1913  data: 0.0001  max mem: 14938
[17:58:14.017520] Test:  [240/345]  eta: 0:00:19  loss: 0.6895 (0.6912)  time: 0.1915  data: 0.0001  max mem: 14938
[17:58:15.939150] Test:  [250/345]  eta: 0:00:17  loss: 0.6868 (0.6909)  time: 0.1919  data: 0.0001  max mem: 14938
[17:58:17.864189] Test:  [260/345]  eta: 0:00:16  loss: 0.6854 (0.6910)  time: 0.1923  data: 0.0001  max mem: 14938
[17:58:19.793115] Test:  [270/345]  eta: 0:00:14  loss: 0.6935 (0.6912)  time: 0.1926  data: 0.0001  max mem: 14938
[17:58:21.723322] Test:  [280/345]  eta: 0:00:12  loss: 0.6918 (0.6910)  time: 0.1929  data: 0.0001  max mem: 14938
[17:58:23.659237] Test:  [290/345]  eta: 0:00:10  loss: 0.6891 (0.6910)  time: 0.1933  data: 0.0001  max mem: 14938
[17:58:25.597384] Test:  [300/345]  eta: 0:00:08  loss: 0.6896 (0.6910)  time: 0.1937  data: 0.0001  max mem: 14938
[17:58:27.537975] Test:  [310/345]  eta: 0:00:06  loss: 0.6864 (0.6909)  time: 0.1939  data: 0.0001  max mem: 14938
[17:58:29.483584] Test:  [320/345]  eta: 0:00:04  loss: 0.6878 (0.6910)  time: 0.1942  data: 0.0001  max mem: 14938
[17:58:31.430528] Test:  [330/345]  eta: 0:00:02  loss: 0.6858 (0.6908)  time: 0.1946  data: 0.0001  max mem: 14938
[17:58:33.382310] Test:  [340/345]  eta: 0:00:00  loss: 0.6878 (0.6910)  time: 0.1949  data: 0.0001  max mem: 14938
[17:58:34.165468] Test:  [344/345]  eta: 0:00:00  loss: 0.6891 (0.6908)  time: 0.1951  data: 0.0001  max mem: 14938
[17:58:34.225329] Test: Total time: 0:01:05 (0.1901 s / it)
[17:58:45.059444] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8166 (0.8166)  time: 0.3222  data: 0.1422  max mem: 14938
[17:58:46.875042] Test:  [10/57]  eta: 0:00:09  loss: 0.8884 (0.8752)  time: 0.1943  data: 0.0130  max mem: 14938
[17:58:48.696563] Test:  [20/57]  eta: 0:00:06  loss: 0.8884 (0.8644)  time: 0.1818  data: 0.0001  max mem: 14938
[17:58:50.521395] Test:  [30/57]  eta: 0:00:05  loss: 0.7516 (0.8246)  time: 0.1823  data: 0.0001  max mem: 14938
[17:58:52.353064] Test:  [40/57]  eta: 0:00:03  loss: 0.7435 (0.8051)  time: 0.1828  data: 0.0001  max mem: 14938
[17:58:54.189483] Test:  [50/57]  eta: 0:00:01  loss: 0.7435 (0.7992)  time: 0.1834  data: 0.0001  max mem: 14938
[17:58:55.180252] Test:  [56/57]  eta: 0:00:00  loss: 0.7561 (0.8049)  time: 0.1780  data: 0.0001  max mem: 14938
[17:58:55.237705] Test: Total time: 0:00:10 (0.1842 s / it)
[17:58:57.065341] Dice score of the network on the train images: 0.833139, val images: 0.819861
[17:58:57.069530] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:58:57.954997] Epoch: [39]  [  0/345]  eta: 0:05:05  lr: 0.000037  loss: 0.7168 (0.7168)  time: 0.8844  data: 0.1426  max mem: 14938
[17:59:12.842008] Epoch: [39]  [ 20/345]  eta: 0:04:04  lr: 0.000037  loss: 0.7100 (0.7098)  time: 0.7443  data: 0.0001  max mem: 14938
[17:59:27.768988] Epoch: [39]  [ 40/345]  eta: 0:03:48  lr: 0.000036  loss: 0.7160 (0.7131)  time: 0.7463  data: 0.0001  max mem: 14938
[17:59:42.699182] Epoch: [39]  [ 60/345]  eta: 0:03:33  lr: 0.000036  loss: 0.7129 (0.7146)  time: 0.7465  data: 0.0001  max mem: 14938
[17:59:57.676786] Epoch: [39]  [ 80/345]  eta: 0:03:18  lr: 0.000036  loss: 0.7098 (0.7145)  time: 0.7488  data: 0.0001  max mem: 14938
[18:00:12.679388] Epoch: [39]  [100/345]  eta: 0:03:03  lr: 0.000035  loss: 0.7217 (0.7165)  time: 0.7501  data: 0.0001  max mem: 14938
[18:00:27.701092] Epoch: [39]  [120/345]  eta: 0:02:48  lr: 0.000035  loss: 0.7168 (0.7169)  time: 0.7510  data: 0.0001  max mem: 14938
[18:00:42.718070] Epoch: [39]  [140/345]  eta: 0:02:33  lr: 0.000035  loss: 0.7080 (0.7159)  time: 0.7508  data: 0.0001  max mem: 14938
[18:00:57.727729] Epoch: [39]  [160/345]  eta: 0:02:18  lr: 0.000034  loss: 0.7098 (0.7155)  time: 0.7504  data: 0.0001  max mem: 14938
[18:01:12.723261] Epoch: [39]  [180/345]  eta: 0:02:03  lr: 0.000034  loss: 0.7103 (0.7152)  time: 0.7497  data: 0.0001  max mem: 14938
[18:01:27.712048] Epoch: [39]  [200/345]  eta: 0:01:48  lr: 0.000034  loss: 0.7118 (0.7151)  time: 0.7494  data: 0.0001  max mem: 14938
[18:01:42.826535] Epoch: [39]  [220/345]  eta: 0:01:33  lr: 0.000033  loss: 0.7131 (0.7152)  time: 0.7557  data: 0.0001  max mem: 14938
[18:01:57.808088] Epoch: [39]  [240/345]  eta: 0:01:18  lr: 0.000033  loss: 0.7089 (0.7148)  time: 0.7490  data: 0.0001  max mem: 14938
[18:02:12.789984] Epoch: [39]  [260/345]  eta: 0:01:03  lr: 0.000033  loss: 0.7140 (0.7148)  time: 0.7490  data: 0.0001  max mem: 14938
[18:02:27.765611] Epoch: [39]  [280/345]  eta: 0:00:48  lr: 0.000032  loss: 0.7069 (0.7145)  time: 0.7487  data: 0.0001  max mem: 14938
[18:02:42.740255] Epoch: [39]  [300/345]  eta: 0:00:33  lr: 0.000032  loss: 0.7076 (0.7143)  time: 0.7487  data: 0.0001  max mem: 14938
[18:02:57.709813] Epoch: [39]  [320/345]  eta: 0:00:18  lr: 0.000032  loss: 0.7101 (0.7142)  time: 0.7484  data: 0.0001  max mem: 14938
[18:03:12.679548] Epoch: [39]  [340/345]  eta: 0:00:03  lr: 0.000031  loss: 0.7163 (0.7141)  time: 0.7484  data: 0.0001  max mem: 14938
[18:03:15.673819] Epoch: [39]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 0.7163 (0.7140)  time: 0.7484  data: 0.0001  max mem: 14938
[18:03:15.741702] Epoch: [39] Total time: 0:04:18 (0.7498 s / it)
[18:03:15.742246] Averaged stats: lr: 0.000031  loss: 0.7163 (0.7140)
[18:03:16.084840] Test:  [  0/345]  eta: 0:01:56  loss: 0.6854 (0.6854)  time: 0.3388  data: 0.1569  max mem: 14938
[18:03:17.921704] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6854 (0.6869)  time: 0.1977  data: 0.0143  max mem: 14938
[18:03:19.763308] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6869 (0.6892)  time: 0.1838  data: 0.0001  max mem: 14938
[18:03:21.606668] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6875 (0.6882)  time: 0.1842  data: 0.0001  max mem: 14938
[18:03:23.453636] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6846 (0.6874)  time: 0.1845  data: 0.0001  max mem: 14938
[18:03:25.304487] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6864 (0.6885)  time: 0.1848  data: 0.0001  max mem: 14938
[18:03:27.159555] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6926 (0.6898)  time: 0.1852  data: 0.0001  max mem: 14938
[18:03:29.017478] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6897 (0.6904)  time: 0.1856  data: 0.0001  max mem: 14938
[18:03:30.877768] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6894 (0.6901)  time: 0.1859  data: 0.0001  max mem: 14938
[18:03:32.739757] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6880 (0.6898)  time: 0.1861  data: 0.0001  max mem: 14938
[18:03:34.606408] Test:  [100/345]  eta: 0:00:45  loss: 0.6881 (0.6899)  time: 0.1864  data: 0.0001  max mem: 14938
[18:03:36.476507] Test:  [110/345]  eta: 0:00:43  loss: 0.6861 (0.6895)  time: 0.1868  data: 0.0001  max mem: 14938
[18:03:38.351706] Test:  [120/345]  eta: 0:00:42  loss: 0.6852 (0.6902)  time: 0.1872  data: 0.0001  max mem: 14938
[18:03:40.229331] Test:  [130/345]  eta: 0:00:40  loss: 0.6949 (0.6907)  time: 0.1876  data: 0.0001  max mem: 14938
[18:03:42.111417] Test:  [140/345]  eta: 0:00:38  loss: 0.6949 (0.6908)  time: 0.1879  data: 0.0001  max mem: 14938
[18:03:43.998315] Test:  [150/345]  eta: 0:00:36  loss: 0.6875 (0.6903)  time: 0.1884  data: 0.0001  max mem: 14938
[18:03:45.888399] Test:  [160/345]  eta: 0:00:34  loss: 0.6867 (0.6903)  time: 0.1888  data: 0.0001  max mem: 14938
[18:03:47.781565] Test:  [170/345]  eta: 0:00:32  loss: 0.6859 (0.6900)  time: 0.1891  data: 0.0001  max mem: 14938
[18:03:49.679381] Test:  [180/345]  eta: 0:00:30  loss: 0.6900 (0.6904)  time: 0.1895  data: 0.0001  max mem: 14938
[18:03:51.579620] Test:  [190/345]  eta: 0:00:29  loss: 0.6969 (0.6907)  time: 0.1899  data: 0.0001  max mem: 14938
[18:03:53.484828] Test:  [200/345]  eta: 0:00:27  loss: 0.6899 (0.6905)  time: 0.1902  data: 0.0001  max mem: 14938
[18:03:55.392261] Test:  [210/345]  eta: 0:00:25  loss: 0.6885 (0.6909)  time: 0.1906  data: 0.0001  max mem: 14938
[18:03:57.304037] Test:  [220/345]  eta: 0:00:23  loss: 0.6885 (0.6908)  time: 0.1909  data: 0.0001  max mem: 14938
[18:03:59.218655] Test:  [230/345]  eta: 0:00:21  loss: 0.6868 (0.6907)  time: 0.1913  data: 0.0001  max mem: 14938
[18:04:01.136496] Test:  [240/345]  eta: 0:00:19  loss: 0.6855 (0.6906)  time: 0.1916  data: 0.0001  max mem: 14938
[18:04:03.059047] Test:  [250/345]  eta: 0:00:17  loss: 0.6935 (0.6909)  time: 0.1920  data: 0.0001  max mem: 14938
[18:04:04.985276] Test:  [260/345]  eta: 0:00:16  loss: 0.6979 (0.6911)  time: 0.1924  data: 0.0001  max mem: 14938
[18:04:06.914577] Test:  [270/345]  eta: 0:00:14  loss: 0.6944 (0.6911)  time: 0.1927  data: 0.0001  max mem: 14938
[18:04:08.847201] Test:  [280/345]  eta: 0:00:12  loss: 0.6879 (0.6911)  time: 0.1930  data: 0.0001  max mem: 14938
[18:04:10.784116] Test:  [290/345]  eta: 0:00:10  loss: 0.6914 (0.6911)  time: 0.1934  data: 0.0001  max mem: 14938
[18:04:12.721446] Test:  [300/345]  eta: 0:00:08  loss: 0.6871 (0.6909)  time: 0.1937  data: 0.0001  max mem: 14938
[18:04:14.663378] Test:  [310/345]  eta: 0:00:06  loss: 0.6855 (0.6910)  time: 0.1939  data: 0.0001  max mem: 14938
[18:04:16.607807] Test:  [320/345]  eta: 0:00:04  loss: 0.6923 (0.6909)  time: 0.1943  data: 0.0001  max mem: 14938
[18:04:18.556889] Test:  [330/345]  eta: 0:00:02  loss: 0.6921 (0.6908)  time: 0.1946  data: 0.0001  max mem: 14938
[18:04:20.507963] Test:  [340/345]  eta: 0:00:00  loss: 0.6867 (0.6908)  time: 0.1950  data: 0.0001  max mem: 14938
[18:04:21.290053] Test:  [344/345]  eta: 0:00:00  loss: 0.6867 (0.6908)  time: 0.1950  data: 0.0001  max mem: 14938
[18:04:21.349075] Test: Total time: 0:01:05 (0.1902 s / it)
[18:04:32.006676] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8595 (0.8595)  time: 0.3243  data: 0.1449  max mem: 14938
[18:04:33.822307] Test:  [10/57]  eta: 0:00:09  loss: 0.8865 (0.8832)  time: 0.1945  data: 0.0132  max mem: 14938
[18:04:35.642290] Test:  [20/57]  eta: 0:00:06  loss: 0.8865 (0.8739)  time: 0.1817  data: 0.0001  max mem: 14938
[18:04:37.469895] Test:  [30/57]  eta: 0:00:05  loss: 0.7533 (0.8306)  time: 0.1823  data: 0.0001  max mem: 14938
[18:04:39.300654] Test:  [40/57]  eta: 0:00:03  loss: 0.7420 (0.8090)  time: 0.1829  data: 0.0001  max mem: 14938
[18:04:41.137027] Test:  [50/57]  eta: 0:00:01  loss: 0.7447 (0.8021)  time: 0.1833  data: 0.0001  max mem: 14938
[18:04:42.127025] Test:  [56/57]  eta: 0:00:00  loss: 0.7554 (0.8072)  time: 0.1779  data: 0.0001  max mem: 14938
[18:04:42.188823] Test: Total time: 0:00:10 (0.1843 s / it)
[18:04:44.014189] Dice score of the network on the train images: 0.827595, val images: 0.817359
[18:04:44.018326] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:04:44.906776] Epoch: [40]  [  0/345]  eta: 0:05:06  lr: 0.000031  loss: 0.7169 (0.7169)  time: 0.8874  data: 0.1457  max mem: 14938
[18:04:59.799980] Epoch: [40]  [ 20/345]  eta: 0:04:04  lr: 0.000031  loss: 0.7124 (0.7133)  time: 0.7446  data: 0.0001  max mem: 14938
[18:05:14.730265] Epoch: [40]  [ 40/345]  eta: 0:03:48  lr: 0.000031  loss: 0.7143 (0.7141)  time: 0.7465  data: 0.0001  max mem: 14938
[18:05:29.684569] Epoch: [40]  [ 60/345]  eta: 0:03:33  lr: 0.000030  loss: 0.7117 (0.7144)  time: 0.7477  data: 0.0001  max mem: 14938
[18:05:44.683061] Epoch: [40]  [ 80/345]  eta: 0:03:18  lr: 0.000030  loss: 0.7163 (0.7146)  time: 0.7499  data: 0.0001  max mem: 14938
[18:05:59.696946] Epoch: [40]  [100/345]  eta: 0:03:03  lr: 0.000030  loss: 0.7084 (0.7140)  time: 0.7506  data: 0.0001  max mem: 14938
[18:06:14.735628] Epoch: [40]  [120/345]  eta: 0:02:48  lr: 0.000029  loss: 0.7152 (0.7140)  time: 0.7519  data: 0.0001  max mem: 14938
[18:06:29.777144] Epoch: [40]  [140/345]  eta: 0:02:33  lr: 0.000029  loss: 0.7104 (0.7142)  time: 0.7520  data: 0.0001  max mem: 14938
[18:06:44.804049] Epoch: [40]  [160/345]  eta: 0:02:18  lr: 0.000029  loss: 0.7093 (0.7138)  time: 0.7513  data: 0.0001  max mem: 14938
[18:06:59.946292] Epoch: [40]  [180/345]  eta: 0:02:03  lr: 0.000028  loss: 0.7080 (0.7134)  time: 0.7571  data: 0.0001  max mem: 14938
[18:07:14.960138] Epoch: [40]  [200/345]  eta: 0:01:48  lr: 0.000028  loss: 0.7090 (0.7131)  time: 0.7506  data: 0.0001  max mem: 14938
[18:07:29.973937] Epoch: [40]  [220/345]  eta: 0:01:33  lr: 0.000028  loss: 0.7153 (0.7132)  time: 0.7506  data: 0.0001  max mem: 14938
[18:07:44.985647] Epoch: [40]  [240/345]  eta: 0:01:18  lr: 0.000027  loss: 0.7101 (0.7130)  time: 0.7505  data: 0.0001  max mem: 14938
[18:07:59.995139] Epoch: [40]  [260/345]  eta: 0:01:03  lr: 0.000027  loss: 0.7088 (0.7130)  time: 0.7504  data: 0.0001  max mem: 14938
[18:08:14.994744] Epoch: [40]  [280/345]  eta: 0:00:48  lr: 0.000027  loss: 0.7049 (0.7125)  time: 0.7499  data: 0.0001  max mem: 14938
[18:08:29.995756] Epoch: [40]  [300/345]  eta: 0:00:33  lr: 0.000026  loss: 0.7052 (0.7120)  time: 0.7500  data: 0.0001  max mem: 14938
[18:08:44.999487] Epoch: [40]  [320/345]  eta: 0:00:18  lr: 0.000026  loss: 0.7142 (0.7122)  time: 0.7501  data: 0.0001  max mem: 14938
[18:08:59.999983] Epoch: [40]  [340/345]  eta: 0:00:03  lr: 0.000026  loss: 0.7111 (0.7123)  time: 0.7500  data: 0.0001  max mem: 14938
[18:09:02.999916] Epoch: [40]  [344/345]  eta: 0:00:00  lr: 0.000026  loss: 0.7111 (0.7123)  time: 0.7499  data: 0.0001  max mem: 14938
[18:09:03.067752] Epoch: [40] Total time: 0:04:19 (0.7509 s / it)
[18:09:03.067995] Averaged stats: lr: 0.000026  loss: 0.7111 (0.7123)
[18:09:03.409514] Test:  [  0/345]  eta: 0:01:56  loss: 0.6875 (0.6875)  time: 0.3375  data: 0.1555  max mem: 14938
[18:09:05.248054] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6888 (0.6904)  time: 0.1977  data: 0.0142  max mem: 14938
[18:09:07.090603] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6888 (0.6893)  time: 0.1840  data: 0.0001  max mem: 14938
[18:09:08.933460] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6825 (0.6867)  time: 0.1842  data: 0.0001  max mem: 14938
[18:09:10.780158] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6803 (0.6852)  time: 0.1844  data: 0.0001  max mem: 14938
[18:09:12.631541] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6853 (0.6860)  time: 0.1849  data: 0.0001  max mem: 14938
[18:09:14.487219] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6889 (0.6863)  time: 0.1853  data: 0.0001  max mem: 14938
[18:09:16.345507] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6871 (0.6868)  time: 0.1856  data: 0.0001  max mem: 14938
[18:09:18.207263] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6855 (0.6866)  time: 0.1860  data: 0.0001  max mem: 14938
[18:09:20.072403] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6826 (0.6862)  time: 0.1863  data: 0.0001  max mem: 14938
[18:09:21.939957] Test:  [100/345]  eta: 0:00:45  loss: 0.6873 (0.6865)  time: 0.1866  data: 0.0001  max mem: 14938
[18:09:23.810530] Test:  [110/345]  eta: 0:00:43  loss: 0.6844 (0.6862)  time: 0.1869  data: 0.0001  max mem: 14938
[18:09:25.686407] Test:  [120/345]  eta: 0:00:42  loss: 0.6802 (0.6862)  time: 0.1873  data: 0.0001  max mem: 14938
[18:09:27.567283] Test:  [130/345]  eta: 0:00:40  loss: 0.6802 (0.6857)  time: 0.1878  data: 0.0001  max mem: 14938
[18:09:29.448806] Test:  [140/345]  eta: 0:00:38  loss: 0.6811 (0.6857)  time: 0.1881  data: 0.0001  max mem: 14938
[18:09:31.335050] Test:  [150/345]  eta: 0:00:36  loss: 0.6873 (0.6860)  time: 0.1883  data: 0.0001  max mem: 14938
[18:09:33.223548] Test:  [160/345]  eta: 0:00:34  loss: 0.6897 (0.6860)  time: 0.1887  data: 0.0001  max mem: 14938
[18:09:35.115711] Test:  [170/345]  eta: 0:00:32  loss: 0.6827 (0.6860)  time: 0.1890  data: 0.0001  max mem: 14938
[18:09:37.015427] Test:  [180/345]  eta: 0:00:30  loss: 0.6816 (0.6861)  time: 0.1895  data: 0.0001  max mem: 14938
[18:09:38.917434] Test:  [190/345]  eta: 0:00:29  loss: 0.6845 (0.6860)  time: 0.1900  data: 0.0001  max mem: 14938
[18:09:40.819292] Test:  [200/345]  eta: 0:00:27  loss: 0.6885 (0.6864)  time: 0.1901  data: 0.0001  max mem: 14938
[18:09:42.729154] Test:  [210/345]  eta: 0:00:25  loss: 0.6905 (0.6866)  time: 0.1905  data: 0.0001  max mem: 14938
[18:09:44.639356] Test:  [220/345]  eta: 0:00:23  loss: 0.6873 (0.6865)  time: 0.1910  data: 0.0001  max mem: 14938
[18:09:46.555467] Test:  [230/345]  eta: 0:00:21  loss: 0.6829 (0.6866)  time: 0.1913  data: 0.0001  max mem: 14938
[18:09:48.474891] Test:  [240/345]  eta: 0:00:19  loss: 0.6852 (0.6867)  time: 0.1917  data: 0.0001  max mem: 14938
[18:09:50.396414] Test:  [250/345]  eta: 0:00:17  loss: 0.6852 (0.6868)  time: 0.1920  data: 0.0001  max mem: 14938
[18:09:52.321790] Test:  [260/345]  eta: 0:00:16  loss: 0.6805 (0.6867)  time: 0.1923  data: 0.0001  max mem: 14938
[18:09:54.251168] Test:  [270/345]  eta: 0:00:14  loss: 0.6801 (0.6866)  time: 0.1927  data: 0.0001  max mem: 14938
[18:09:56.182998] Test:  [280/345]  eta: 0:00:12  loss: 0.6858 (0.6867)  time: 0.1930  data: 0.0001  max mem: 14938
[18:09:58.117320] Test:  [290/345]  eta: 0:00:10  loss: 0.6884 (0.6868)  time: 0.1933  data: 0.0001  max mem: 14938
[18:10:00.056175] Test:  [300/345]  eta: 0:00:08  loss: 0.6894 (0.6867)  time: 0.1936  data: 0.0001  max mem: 14938
[18:10:01.999040] Test:  [310/345]  eta: 0:00:06  loss: 0.6905 (0.6868)  time: 0.1940  data: 0.0001  max mem: 14938
[18:10:03.946007] Test:  [320/345]  eta: 0:00:04  loss: 0.6908 (0.6870)  time: 0.1944  data: 0.0001  max mem: 14938
[18:10:05.893730] Test:  [330/345]  eta: 0:00:02  loss: 0.6879 (0.6871)  time: 0.1947  data: 0.0001  max mem: 14938
[18:10:07.846761] Test:  [340/345]  eta: 0:00:00  loss: 0.6906 (0.6872)  time: 0.1950  data: 0.0001  max mem: 14938
[18:10:08.629490] Test:  [344/345]  eta: 0:00:00  loss: 0.6844 (0.6871)  time: 0.1951  data: 0.0001  max mem: 14938
[18:10:08.691557] Test: Total time: 0:01:05 (0.1902 s / it)
[18:10:19.448564] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8475 (0.8475)  time: 0.3269  data: 0.1470  max mem: 14938
[18:10:21.264106] Test:  [10/57]  eta: 0:00:09  loss: 0.8930 (0.8845)  time: 0.1947  data: 0.0134  max mem: 14938
[18:10:23.083532] Test:  [20/57]  eta: 0:00:06  loss: 0.8930 (0.8726)  time: 0.1817  data: 0.0001  max mem: 14938
[18:10:24.907933] Test:  [30/57]  eta: 0:00:05  loss: 0.7555 (0.8313)  time: 0.1821  data: 0.0001  max mem: 14938
[18:10:26.739263] Test:  [40/57]  eta: 0:00:03  loss: 0.7467 (0.8112)  time: 0.1827  data: 0.0001  max mem: 14938
[18:10:28.575965] Test:  [50/57]  eta: 0:00:01  loss: 0.7467 (0.8038)  time: 0.1833  data: 0.0001  max mem: 14938
[18:10:29.565473] Test:  [56/57]  eta: 0:00:00  loss: 0.7540 (0.8092)  time: 0.1779  data: 0.0001  max mem: 14938
[18:10:29.628224] Test: Total time: 0:00:10 (0.1843 s / it)
[18:10:31.464334] Dice score of the network on the train images: 0.837704, val images: 0.818744
[18:10:31.468270] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:10:32.359031] Epoch: [41]  [  0/345]  eta: 0:05:06  lr: 0.000026  loss: 0.7029 (0.7029)  time: 0.8896  data: 0.1483  max mem: 14938
[18:10:47.255647] Epoch: [41]  [ 20/345]  eta: 0:04:04  lr: 0.000025  loss: 0.7003 (0.7048)  time: 0.7448  data: 0.0001  max mem: 14938
[18:11:02.184409] Epoch: [41]  [ 40/345]  eta: 0:03:48  lr: 0.000025  loss: 0.7142 (0.7092)  time: 0.7464  data: 0.0001  max mem: 14938
[18:11:17.150427] Epoch: [41]  [ 60/345]  eta: 0:03:33  lr: 0.000025  loss: 0.7107 (0.7108)  time: 0.7482  data: 0.0001  max mem: 14938
[18:11:32.142961] Epoch: [41]  [ 80/345]  eta: 0:03:18  lr: 0.000025  loss: 0.7093 (0.7116)  time: 0.7496  data: 0.0001  max mem: 14938
[18:11:47.171363] Epoch: [41]  [100/345]  eta: 0:03:03  lr: 0.000024  loss: 0.7136 (0.7118)  time: 0.7514  data: 0.0001  max mem: 14938
[18:12:02.224872] Epoch: [41]  [120/345]  eta: 0:02:48  lr: 0.000024  loss: 0.7107 (0.7118)  time: 0.7526  data: 0.0001  max mem: 14938
[18:12:17.274302] Epoch: [41]  [140/345]  eta: 0:02:33  lr: 0.000024  loss: 0.7095 (0.7120)  time: 0.7524  data: 0.0001  max mem: 14938
[18:12:32.428820] Epoch: [41]  [160/345]  eta: 0:02:18  lr: 0.000023  loss: 0.7125 (0.7118)  time: 0.7577  data: 0.0001  max mem: 14938
[18:12:47.457236] Epoch: [41]  [180/345]  eta: 0:02:03  lr: 0.000023  loss: 0.7077 (0.7116)  time: 0.7514  data: 0.0001  max mem: 14938
[18:13:02.469404] Epoch: [41]  [200/345]  eta: 0:01:48  lr: 0.000023  loss: 0.7097 (0.7113)  time: 0.7506  data: 0.0001  max mem: 14938
[18:13:17.477867] Epoch: [41]  [220/345]  eta: 0:01:33  lr: 0.000022  loss: 0.7092 (0.7113)  time: 0.7504  data: 0.0001  max mem: 14938
[18:13:32.487249] Epoch: [41]  [240/345]  eta: 0:01:18  lr: 0.000022  loss: 0.7129 (0.7115)  time: 0.7504  data: 0.0001  max mem: 14938
[18:13:47.491264] Epoch: [41]  [260/345]  eta: 0:01:03  lr: 0.000022  loss: 0.7138 (0.7119)  time: 0.7502  data: 0.0001  max mem: 14938
[18:14:02.487561] Epoch: [41]  [280/345]  eta: 0:00:48  lr: 0.000022  loss: 0.7114 (0.7119)  time: 0.7498  data: 0.0001  max mem: 14938
[18:14:17.490554] Epoch: [41]  [300/345]  eta: 0:00:33  lr: 0.000021  loss: 0.7105 (0.7120)  time: 0.7501  data: 0.0001  max mem: 14938
[18:14:32.492959] Epoch: [41]  [320/345]  eta: 0:00:18  lr: 0.000021  loss: 0.7050 (0.7118)  time: 0.7501  data: 0.0001  max mem: 14938
[18:14:47.480327] Epoch: [41]  [340/345]  eta: 0:00:03  lr: 0.000021  loss: 0.7080 (0.7117)  time: 0.7493  data: 0.0001  max mem: 14938
[18:14:50.482400] Epoch: [41]  [344/345]  eta: 0:00:00  lr: 0.000021  loss: 0.7092 (0.7117)  time: 0.7494  data: 0.0001  max mem: 14938
[18:14:50.550323] Epoch: [41] Total time: 0:04:19 (0.7510 s / it)
[18:14:50.550799] Averaged stats: lr: 0.000021  loss: 0.7092 (0.7117)
[18:14:50.898847] Test:  [  0/345]  eta: 0:01:58  loss: 0.6770 (0.6770)  time: 0.3438  data: 0.1611  max mem: 14938
[18:14:52.736323] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6912 (0.6894)  time: 0.1982  data: 0.0147  max mem: 14938
[18:14:54.578584] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6951 (0.6924)  time: 0.1839  data: 0.0001  max mem: 14938
[18:14:56.422494] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6913 (0.6913)  time: 0.1843  data: 0.0001  max mem: 14938
[18:14:58.270505] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6811 (0.6892)  time: 0.1845  data: 0.0001  max mem: 14938
[18:15:00.122525] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6811 (0.6875)  time: 0.1850  data: 0.0001  max mem: 14938
[18:15:01.975907] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6815 (0.6869)  time: 0.1852  data: 0.0001  max mem: 14938
[18:15:03.833917] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6866 (0.6874)  time: 0.1855  data: 0.0001  max mem: 14938
[18:15:05.696870] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6852 (0.6870)  time: 0.1860  data: 0.0001  max mem: 14938
[18:15:07.561247] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6841 (0.6867)  time: 0.1863  data: 0.0001  max mem: 14938
[18:15:09.428126] Test:  [100/345]  eta: 0:00:45  loss: 0.6836 (0.6867)  time: 0.1865  data: 0.0001  max mem: 14938
[18:15:11.299768] Test:  [110/345]  eta: 0:00:43  loss: 0.6850 (0.6870)  time: 0.1869  data: 0.0001  max mem: 14938
[18:15:13.174690] Test:  [120/345]  eta: 0:00:42  loss: 0.6850 (0.6870)  time: 0.1873  data: 0.0001  max mem: 14938
[18:15:15.055270] Test:  [130/345]  eta: 0:00:40  loss: 0.6829 (0.6871)  time: 0.1877  data: 0.0001  max mem: 14938
[18:15:16.938325] Test:  [140/345]  eta: 0:00:38  loss: 0.6855 (0.6873)  time: 0.1881  data: 0.0001  max mem: 14938
[18:15:18.824107] Test:  [150/345]  eta: 0:00:36  loss: 0.6863 (0.6872)  time: 0.1884  data: 0.0001  max mem: 14938
[18:15:20.713216] Test:  [160/345]  eta: 0:00:34  loss: 0.6829 (0.6869)  time: 0.1887  data: 0.0001  max mem: 14938
[18:15:22.604421] Test:  [170/345]  eta: 0:00:32  loss: 0.6827 (0.6867)  time: 0.1890  data: 0.0001  max mem: 14938
[18:15:24.501819] Test:  [180/345]  eta: 0:00:30  loss: 0.6854 (0.6867)  time: 0.1894  data: 0.0001  max mem: 14938
[18:15:26.402660] Test:  [190/345]  eta: 0:00:29  loss: 0.6862 (0.6868)  time: 0.1899  data: 0.0001  max mem: 14938
[18:15:28.308179] Test:  [200/345]  eta: 0:00:27  loss: 0.6892 (0.6869)  time: 0.1903  data: 0.0001  max mem: 14938
[18:15:30.217515] Test:  [210/345]  eta: 0:00:25  loss: 0.6830 (0.6865)  time: 0.1907  data: 0.0001  max mem: 14938
[18:15:32.126785] Test:  [220/345]  eta: 0:00:23  loss: 0.6800 (0.6865)  time: 0.1909  data: 0.0001  max mem: 14938
[18:15:34.041114] Test:  [230/345]  eta: 0:00:21  loss: 0.6802 (0.6864)  time: 0.1911  data: 0.0001  max mem: 14938
[18:15:35.957202] Test:  [240/345]  eta: 0:00:19  loss: 0.6812 (0.6866)  time: 0.1915  data: 0.0001  max mem: 14938
[18:15:37.879717] Test:  [250/345]  eta: 0:00:17  loss: 0.6845 (0.6867)  time: 0.1919  data: 0.0001  max mem: 14938
[18:15:39.803005] Test:  [260/345]  eta: 0:00:16  loss: 0.6796 (0.6864)  time: 0.1922  data: 0.0001  max mem: 14938
[18:15:41.730350] Test:  [270/345]  eta: 0:00:14  loss: 0.6807 (0.6864)  time: 0.1925  data: 0.0001  max mem: 14938
[18:15:43.660246] Test:  [280/345]  eta: 0:00:12  loss: 0.6830 (0.6864)  time: 0.1928  data: 0.0001  max mem: 14938
[18:15:45.595420] Test:  [290/345]  eta: 0:00:10  loss: 0.6867 (0.6865)  time: 0.1932  data: 0.0001  max mem: 14938
[18:15:47.533585] Test:  [300/345]  eta: 0:00:08  loss: 0.6879 (0.6865)  time: 0.1936  data: 0.0001  max mem: 14938
[18:15:49.474297] Test:  [310/345]  eta: 0:00:06  loss: 0.6865 (0.6866)  time: 0.1939  data: 0.0001  max mem: 14938
[18:15:51.418934] Test:  [320/345]  eta: 0:00:04  loss: 0.6817 (0.6864)  time: 0.1942  data: 0.0001  max mem: 14938
[18:15:53.365971] Test:  [330/345]  eta: 0:00:02  loss: 0.6867 (0.6865)  time: 0.1945  data: 0.0001  max mem: 14938
[18:15:55.316091] Test:  [340/345]  eta: 0:00:00  loss: 0.6847 (0.6866)  time: 0.1948  data: 0.0001  max mem: 14938
[18:15:56.097877] Test:  [344/345]  eta: 0:00:00  loss: 0.6872 (0.6866)  time: 0.1950  data: 0.0001  max mem: 14938
[18:15:56.160438] Test: Total time: 0:01:05 (0.1902 s / it)
[18:16:06.659180] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8252 (0.8252)  time: 0.3238  data: 0.1443  max mem: 14938
[18:16:08.474740] Test:  [10/57]  eta: 0:00:09  loss: 0.8835 (0.8786)  time: 0.1944  data: 0.0132  max mem: 14938
[18:16:10.296268] Test:  [20/57]  eta: 0:00:06  loss: 0.8835 (0.8657)  time: 0.1818  data: 0.0001  max mem: 14938
[18:16:12.122108] Test:  [30/57]  eta: 0:00:05  loss: 0.7556 (0.8261)  time: 0.1823  data: 0.0001  max mem: 14938
[18:16:13.952995] Test:  [40/57]  eta: 0:00:03  loss: 0.7435 (0.8066)  time: 0.1828  data: 0.0001  max mem: 14938
[18:16:15.789264] Test:  [50/57]  eta: 0:00:01  loss: 0.7461 (0.8006)  time: 0.1833  data: 0.0001  max mem: 14938
[18:16:16.779281] Test:  [56/57]  eta: 0:00:00  loss: 0.7618 (0.8063)  time: 0.1779  data: 0.0001  max mem: 14938
[18:16:16.838544] Test: Total time: 0:00:10 (0.1843 s / it)
[18:16:18.623823] Dice score of the network on the train images: 0.835346, val images: 0.817287
[18:16:18.627832] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:16:19.517382] Epoch: [42]  [  0/345]  eta: 0:05:06  lr: 0.000021  loss: 0.7004 (0.7004)  time: 0.8885  data: 0.1472  max mem: 14938
[18:16:34.405837] Epoch: [42]  [ 20/345]  eta: 0:04:04  lr: 0.000020  loss: 0.7059 (0.7061)  time: 0.7444  data: 0.0001  max mem: 14938
[18:16:49.326086] Epoch: [42]  [ 40/345]  eta: 0:03:48  lr: 0.000020  loss: 0.7082 (0.7072)  time: 0.7460  data: 0.0001  max mem: 14938
[18:17:04.266550] Epoch: [42]  [ 60/345]  eta: 0:03:33  lr: 0.000020  loss: 0.7102 (0.7084)  time: 0.7470  data: 0.0001  max mem: 14938
[18:17:19.244574] Epoch: [42]  [ 80/345]  eta: 0:03:18  lr: 0.000020  loss: 0.7131 (0.7094)  time: 0.7489  data: 0.0001  max mem: 14938
[18:17:34.277202] Epoch: [42]  [100/345]  eta: 0:03:03  lr: 0.000019  loss: 0.7078 (0.7100)  time: 0.7516  data: 0.0001  max mem: 14938
[18:17:49.325284] Epoch: [42]  [120/345]  eta: 0:02:48  lr: 0.000019  loss: 0.7110 (0.7101)  time: 0.7524  data: 0.0001  max mem: 14938
[18:18:04.370516] Epoch: [42]  [140/345]  eta: 0:02:33  lr: 0.000019  loss: 0.7086 (0.7098)  time: 0.7522  data: 0.0001  max mem: 14938
[18:18:19.429369] Epoch: [42]  [160/345]  eta: 0:02:18  lr: 0.000018  loss: 0.7063 (0.7095)  time: 0.7529  data: 0.0001  max mem: 14938
[18:18:34.474655] Epoch: [42]  [180/345]  eta: 0:02:03  lr: 0.000018  loss: 0.7006 (0.7090)  time: 0.7522  data: 0.0001  max mem: 14938
[18:18:49.497518] Epoch: [42]  [200/345]  eta: 0:01:48  lr: 0.000018  loss: 0.7154 (0.7095)  time: 0.7511  data: 0.0001  max mem: 14938
[18:19:04.495042] Epoch: [42]  [220/345]  eta: 0:01:33  lr: 0.000018  loss: 0.7052 (0.7094)  time: 0.7498  data: 0.0001  max mem: 14938
[18:19:19.493698] Epoch: [42]  [240/345]  eta: 0:01:18  lr: 0.000017  loss: 0.7063 (0.7094)  time: 0.7499  data: 0.0001  max mem: 14938
[18:19:34.486229] Epoch: [42]  [260/345]  eta: 0:01:03  lr: 0.000017  loss: 0.7096 (0.7096)  time: 0.7496  data: 0.0001  max mem: 14938
[18:19:49.472033] Epoch: [42]  [280/345]  eta: 0:00:48  lr: 0.000017  loss: 0.7042 (0.7093)  time: 0.7492  data: 0.0001  max mem: 14938
[18:20:04.461785] Epoch: [42]  [300/345]  eta: 0:00:33  lr: 0.000017  loss: 0.7081 (0.7095)  time: 0.7494  data: 0.0001  max mem: 14938
[18:20:19.448610] Epoch: [42]  [320/345]  eta: 0:00:18  lr: 0.000016  loss: 0.7041 (0.7098)  time: 0.7493  data: 0.0001  max mem: 14938
[18:20:34.450513] Epoch: [42]  [340/345]  eta: 0:00:03  lr: 0.000016  loss: 0.7012 (0.7096)  time: 0.7500  data: 0.0001  max mem: 14938
[18:20:37.451483] Epoch: [42]  [344/345]  eta: 0:00:00  lr: 0.000016  loss: 0.7023 (0.7096)  time: 0.7501  data: 0.0001  max mem: 14938
[18:20:37.516962] Epoch: [42] Total time: 0:04:18 (0.7504 s / it)
[18:20:37.517319] Averaged stats: lr: 0.000016  loss: 0.7023 (0.7096)
[18:20:37.860432] Test:  [  0/345]  eta: 0:01:56  loss: 0.7083 (0.7083)  time: 0.3385  data: 0.1569  max mem: 14938
[18:20:39.697749] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6880 (0.6889)  time: 0.1977  data: 0.0143  max mem: 14938
[18:20:41.539744] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6773 (0.6839)  time: 0.1839  data: 0.0001  max mem: 14938
[18:20:43.383146] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6775 (0.6845)  time: 0.1842  data: 0.0001  max mem: 14938
[18:20:45.232287] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6845 (0.6845)  time: 0.1846  data: 0.0001  max mem: 14938
[18:20:47.083580] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6845 (0.6851)  time: 0.1850  data: 0.0001  max mem: 14938
[18:20:48.939230] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6883 (0.6854)  time: 0.1853  data: 0.0001  max mem: 14938
[18:20:50.798007] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6861 (0.6852)  time: 0.1857  data: 0.0001  max mem: 14938
[18:20:52.660215] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6812 (0.6845)  time: 0.1860  data: 0.0001  max mem: 14938
[18:20:54.525458] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6816 (0.6843)  time: 0.1863  data: 0.0001  max mem: 14938
[18:20:56.391999] Test:  [100/345]  eta: 0:00:45  loss: 0.6818 (0.6843)  time: 0.1865  data: 0.0001  max mem: 14938
[18:20:58.262299] Test:  [110/345]  eta: 0:00:43  loss: 0.6807 (0.6849)  time: 0.1868  data: 0.0001  max mem: 14938
[18:21:00.135450] Test:  [120/345]  eta: 0:00:42  loss: 0.6875 (0.6848)  time: 0.1871  data: 0.0001  max mem: 14938
[18:21:02.014023] Test:  [130/345]  eta: 0:00:40  loss: 0.6875 (0.6850)  time: 0.1875  data: 0.0001  max mem: 14938
[18:21:03.896216] Test:  [140/345]  eta: 0:00:38  loss: 0.6879 (0.6852)  time: 0.1880  data: 0.0001  max mem: 14938
[18:21:05.781050] Test:  [150/345]  eta: 0:00:36  loss: 0.6842 (0.6847)  time: 0.1883  data: 0.0001  max mem: 14938
[18:21:07.669468] Test:  [160/345]  eta: 0:00:34  loss: 0.6784 (0.6845)  time: 0.1886  data: 0.0001  max mem: 14938
[18:21:09.560767] Test:  [170/345]  eta: 0:00:32  loss: 0.6809 (0.6846)  time: 0.1889  data: 0.0001  max mem: 14938
[18:21:11.458494] Test:  [180/345]  eta: 0:00:30  loss: 0.6830 (0.6849)  time: 0.1894  data: 0.0001  max mem: 14938
[18:21:13.358982] Test:  [190/345]  eta: 0:00:29  loss: 0.6830 (0.6851)  time: 0.1899  data: 0.0001  max mem: 14938
[18:21:15.263862] Test:  [200/345]  eta: 0:00:27  loss: 0.6823 (0.6851)  time: 0.1902  data: 0.0001  max mem: 14938
[18:21:17.170649] Test:  [210/345]  eta: 0:00:25  loss: 0.6823 (0.6850)  time: 0.1905  data: 0.0001  max mem: 14938
[18:21:19.080839] Test:  [220/345]  eta: 0:00:23  loss: 0.6830 (0.6852)  time: 0.1908  data: 0.0001  max mem: 14938
[18:21:20.993489] Test:  [230/345]  eta: 0:00:21  loss: 0.6877 (0.6853)  time: 0.1911  data: 0.0001  max mem: 14938
[18:21:22.911815] Test:  [240/345]  eta: 0:00:19  loss: 0.6801 (0.6851)  time: 0.1915  data: 0.0001  max mem: 14938
[18:21:24.832674] Test:  [250/345]  eta: 0:00:17  loss: 0.6858 (0.6853)  time: 0.1919  data: 0.0001  max mem: 14938
[18:21:26.755906] Test:  [260/345]  eta: 0:00:16  loss: 0.6865 (0.6851)  time: 0.1922  data: 0.0001  max mem: 14938
[18:21:28.684870] Test:  [270/345]  eta: 0:00:14  loss: 0.6794 (0.6851)  time: 0.1926  data: 0.0001  max mem: 14938
[18:21:30.615887] Test:  [280/345]  eta: 0:00:12  loss: 0.6864 (0.6852)  time: 0.1929  data: 0.0001  max mem: 14938
[18:21:32.549736] Test:  [290/345]  eta: 0:00:10  loss: 0.6823 (0.6853)  time: 0.1932  data: 0.0001  max mem: 14938
[18:21:34.487769] Test:  [300/345]  eta: 0:00:08  loss: 0.6811 (0.6852)  time: 0.1935  data: 0.0001  max mem: 14938
[18:21:36.428032] Test:  [310/345]  eta: 0:00:06  loss: 0.6846 (0.6851)  time: 0.1939  data: 0.0001  max mem: 14938
[18:21:38.371532] Test:  [320/345]  eta: 0:00:04  loss: 0.6834 (0.6851)  time: 0.1941  data: 0.0001  max mem: 14938
[18:21:40.319772] Test:  [330/345]  eta: 0:00:02  loss: 0.6826 (0.6852)  time: 0.1945  data: 0.0001  max mem: 14938
[18:21:42.269179] Test:  [340/345]  eta: 0:00:00  loss: 0.6857 (0.6853)  time: 0.1948  data: 0.0001  max mem: 14938
[18:21:43.052284] Test:  [344/345]  eta: 0:00:00  loss: 0.6846 (0.6852)  time: 0.1950  data: 0.0001  max mem: 14938
[18:21:43.112546] Test: Total time: 0:01:05 (0.1901 s / it)
[18:21:53.811055] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8369 (0.8369)  time: 0.3222  data: 0.1428  max mem: 14938
[18:21:55.625698] Test:  [10/57]  eta: 0:00:09  loss: 0.8943 (0.8816)  time: 0.1942  data: 0.0130  max mem: 14938
[18:21:57.445456] Test:  [20/57]  eta: 0:00:06  loss: 0.8943 (0.8714)  time: 0.1817  data: 0.0001  max mem: 14938
[18:21:59.269470] Test:  [30/57]  eta: 0:00:05  loss: 0.7607 (0.8308)  time: 0.1821  data: 0.0001  max mem: 14938
[18:22:01.099867] Test:  [40/57]  eta: 0:00:03  loss: 0.7451 (0.8107)  time: 0.1827  data: 0.0001  max mem: 14938
[18:22:02.936663] Test:  [50/57]  eta: 0:00:01  loss: 0.7468 (0.8041)  time: 0.1833  data: 0.0001  max mem: 14938
[18:22:03.926972] Test:  [56/57]  eta: 0:00:00  loss: 0.7601 (0.8096)  time: 0.1780  data: 0.0001  max mem: 14938
[18:22:03.986533] Test: Total time: 0:00:10 (0.1842 s / it)
[18:22:05.735506] Dice score of the network on the train images: 0.837853, val images: 0.816010
[18:22:05.740140] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:22:06.623167] Epoch: [43]  [  0/345]  eta: 0:05:04  lr: 0.000016  loss: 0.7041 (0.7041)  time: 0.8819  data: 0.1413  max mem: 14938
[18:22:21.524613] Epoch: [43]  [ 20/345]  eta: 0:04:04  lr: 0.000016  loss: 0.7094 (0.7092)  time: 0.7450  data: 0.0001  max mem: 14938
[18:22:36.460451] Epoch: [43]  [ 40/345]  eta: 0:03:48  lr: 0.000016  loss: 0.7084 (0.7088)  time: 0.7467  data: 0.0001  max mem: 14938
[18:22:51.419549] Epoch: [43]  [ 60/345]  eta: 0:03:33  lr: 0.000015  loss: 0.7077 (0.7091)  time: 0.7479  data: 0.0001  max mem: 14938
[18:23:06.401528] Epoch: [43]  [ 80/345]  eta: 0:03:18  lr: 0.000015  loss: 0.7080 (0.7090)  time: 0.7491  data: 0.0001  max mem: 14938
[18:23:21.414898] Epoch: [43]  [100/345]  eta: 0:03:03  lr: 0.000015  loss: 0.7048 (0.7087)  time: 0.7506  data: 0.0001  max mem: 14938
[18:23:36.447870] Epoch: [43]  [120/345]  eta: 0:02:48  lr: 0.000015  loss: 0.7069 (0.7089)  time: 0.7516  data: 0.0001  max mem: 14938
[18:23:51.492075] Epoch: [43]  [140/345]  eta: 0:02:33  lr: 0.000014  loss: 0.7049 (0.7087)  time: 0.7522  data: 0.0001  max mem: 14938
[18:24:06.533847] Epoch: [43]  [160/345]  eta: 0:02:18  lr: 0.000014  loss: 0.7076 (0.7088)  time: 0.7520  data: 0.0001  max mem: 14938
[18:24:21.566678] Epoch: [43]  [180/345]  eta: 0:02:03  lr: 0.000014  loss: 0.7053 (0.7088)  time: 0.7516  data: 0.0001  max mem: 14938
[18:24:36.597605] Epoch: [43]  [200/345]  eta: 0:01:48  lr: 0.000014  loss: 0.7050 (0.7085)  time: 0.7515  data: 0.0001  max mem: 14938
[18:24:51.620868] Epoch: [43]  [220/345]  eta: 0:01:33  lr: 0.000013  loss: 0.7050 (0.7082)  time: 0.7511  data: 0.0001  max mem: 14938
[18:25:06.632418] Epoch: [43]  [240/345]  eta: 0:01:18  lr: 0.000013  loss: 0.7060 (0.7081)  time: 0.7505  data: 0.0001  max mem: 14938
[18:25:21.646326] Epoch: [43]  [260/345]  eta: 0:01:03  lr: 0.000013  loss: 0.7044 (0.7081)  time: 0.7507  data: 0.0001  max mem: 14938
[18:25:36.657926] Epoch: [43]  [280/345]  eta: 0:00:48  lr: 0.000013  loss: 0.7073 (0.7081)  time: 0.7505  data: 0.0001  max mem: 14938
[18:25:51.659831] Epoch: [43]  [300/345]  eta: 0:00:33  lr: 0.000012  loss: 0.7092 (0.7084)  time: 0.7501  data: 0.0001  max mem: 14938
[18:26:06.666462] Epoch: [43]  [320/345]  eta: 0:00:18  lr: 0.000012  loss: 0.7082 (0.7084)  time: 0.7503  data: 0.0001  max mem: 14938
[18:26:21.665649] Epoch: [43]  [340/345]  eta: 0:00:03  lr: 0.000012  loss: 0.7093 (0.7084)  time: 0.7499  data: 0.0001  max mem: 14938
[18:26:24.664714] Epoch: [43]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 0.7093 (0.7084)  time: 0.7498  data: 0.0001  max mem: 14938
[18:26:24.729205] Epoch: [43] Total time: 0:04:18 (0.7507 s / it)
[18:26:24.729652] Averaged stats: lr: 0.000012  loss: 0.7093 (0.7084)
[18:26:25.075805] Test:  [  0/345]  eta: 0:01:57  loss: 0.6899 (0.6899)  time: 0.3419  data: 0.1604  max mem: 14938
[18:26:26.911412] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6822 (0.6837)  time: 0.1979  data: 0.0146  max mem: 14938
[18:26:28.750500] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6822 (0.6851)  time: 0.1837  data: 0.0001  max mem: 14938
[18:26:30.591869] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6818 (0.6834)  time: 0.1840  data: 0.0001  max mem: 14938
[18:26:32.436714] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6801 (0.6835)  time: 0.1843  data: 0.0001  max mem: 14938
[18:26:34.286458] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6801 (0.6831)  time: 0.1847  data: 0.0001  max mem: 14938
[18:26:36.139086] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6794 (0.6833)  time: 0.1851  data: 0.0001  max mem: 14938
[18:26:37.994960] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6794 (0.6833)  time: 0.1854  data: 0.0001  max mem: 14938
[18:26:39.853567] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6782 (0.6833)  time: 0.1857  data: 0.0001  max mem: 14938
[18:26:41.717716] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6782 (0.6827)  time: 0.1861  data: 0.0001  max mem: 14938
[18:26:43.584710] Test:  [100/345]  eta: 0:00:45  loss: 0.6810 (0.6834)  time: 0.1865  data: 0.0001  max mem: 14938
[18:26:45.452840] Test:  [110/345]  eta: 0:00:43  loss: 0.6878 (0.6839)  time: 0.1867  data: 0.0001  max mem: 14938
[18:26:47.325999] Test:  [120/345]  eta: 0:00:41  loss: 0.6890 (0.6842)  time: 0.1870  data: 0.0001  max mem: 14938
[18:26:49.201925] Test:  [130/345]  eta: 0:00:40  loss: 0.6819 (0.6839)  time: 0.1874  data: 0.0001  max mem: 14938
[18:26:51.081112] Test:  [140/345]  eta: 0:00:38  loss: 0.6801 (0.6839)  time: 0.1877  data: 0.0001  max mem: 14938
[18:26:52.964092] Test:  [150/345]  eta: 0:00:36  loss: 0.6856 (0.6843)  time: 0.1881  data: 0.0001  max mem: 14938
[18:26:54.850119] Test:  [160/345]  eta: 0:00:34  loss: 0.6843 (0.6842)  time: 0.1884  data: 0.0001  max mem: 14938
[18:26:56.738946] Test:  [170/345]  eta: 0:00:32  loss: 0.6836 (0.6845)  time: 0.1887  data: 0.0001  max mem: 14938
[18:26:58.635484] Test:  [180/345]  eta: 0:00:30  loss: 0.6862 (0.6845)  time: 0.1892  data: 0.0001  max mem: 14938
[18:27:00.535051] Test:  [190/345]  eta: 0:00:29  loss: 0.6793 (0.6842)  time: 0.1898  data: 0.0001  max mem: 14938
[18:27:02.436767] Test:  [200/345]  eta: 0:00:27  loss: 0.6793 (0.6842)  time: 0.1900  data: 0.0001  max mem: 14938
[18:27:04.340791] Test:  [210/345]  eta: 0:00:25  loss: 0.6809 (0.6842)  time: 0.1902  data: 0.0001  max mem: 14938
[18:27:06.250607] Test:  [220/345]  eta: 0:00:23  loss: 0.6830 (0.6842)  time: 0.1906  data: 0.0001  max mem: 14938
[18:27:08.161966] Test:  [230/345]  eta: 0:00:21  loss: 0.6830 (0.6841)  time: 0.1910  data: 0.0001  max mem: 14938
[18:27:10.078765] Test:  [240/345]  eta: 0:00:19  loss: 0.6777 (0.6839)  time: 0.1914  data: 0.0001  max mem: 14938
[18:27:11.998778] Test:  [250/345]  eta: 0:00:17  loss: 0.6799 (0.6841)  time: 0.1918  data: 0.0001  max mem: 14938
[18:27:13.921079] Test:  [260/345]  eta: 0:00:16  loss: 0.6911 (0.6843)  time: 0.1921  data: 0.0001  max mem: 14938
[18:27:15.846365] Test:  [270/345]  eta: 0:00:14  loss: 0.6820 (0.6841)  time: 0.1923  data: 0.0001  max mem: 14938
[18:27:17.775136] Test:  [280/345]  eta: 0:00:12  loss: 0.6819 (0.6842)  time: 0.1927  data: 0.0001  max mem: 14938
[18:27:19.708527] Test:  [290/345]  eta: 0:00:10  loss: 0.6823 (0.6842)  time: 0.1931  data: 0.0001  max mem: 14938
[18:27:21.644610] Test:  [300/345]  eta: 0:00:08  loss: 0.6811 (0.6842)  time: 0.1934  data: 0.0001  max mem: 14938
[18:27:23.582922] Test:  [310/345]  eta: 0:00:06  loss: 0.6818 (0.6842)  time: 0.1937  data: 0.0001  max mem: 14938
[18:27:25.524540] Test:  [320/345]  eta: 0:00:04  loss: 0.6821 (0.6842)  time: 0.1940  data: 0.0001  max mem: 14938
[18:27:27.469960] Test:  [330/345]  eta: 0:00:02  loss: 0.6829 (0.6842)  time: 0.1943  data: 0.0001  max mem: 14938
[18:27:29.418445] Test:  [340/345]  eta: 0:00:00  loss: 0.6823 (0.6841)  time: 0.1946  data: 0.0001  max mem: 14938
[18:27:30.200173] Test:  [344/345]  eta: 0:00:00  loss: 0.6823 (0.6841)  time: 0.1948  data: 0.0001  max mem: 14938
[18:27:30.260615] Test: Total time: 0:01:05 (0.1899 s / it)
[18:27:40.873926] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8359 (0.8359)  time: 0.3279  data: 0.1481  max mem: 14938
[18:27:42.690533] Test:  [10/57]  eta: 0:00:09  loss: 0.8939 (0.8836)  time: 0.1949  data: 0.0135  max mem: 14938
[18:27:44.511376] Test:  [20/57]  eta: 0:00:06  loss: 0.8939 (0.8711)  time: 0.1818  data: 0.0001  max mem: 14938
[18:27:46.334524] Test:  [30/57]  eta: 0:00:05  loss: 0.7562 (0.8306)  time: 0.1821  data: 0.0001  max mem: 14938
[18:27:48.164576] Test:  [40/57]  eta: 0:00:03  loss: 0.7456 (0.8105)  time: 0.1826  data: 0.0001  max mem: 14938
[18:27:50.000790] Test:  [50/57]  eta: 0:00:01  loss: 0.7494 (0.8038)  time: 0.1833  data: 0.0001  max mem: 14938
[18:27:50.990799] Test:  [56/57]  eta: 0:00:00  loss: 0.7581 (0.8093)  time: 0.1779  data: 0.0001  max mem: 14938
[18:27:51.049710] Test: Total time: 0:00:10 (0.1843 s / it)
[18:27:52.807541] Dice score of the network on the train images: 0.838665, val images: 0.818504
[18:27:52.811699] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:27:53.702427] Epoch: [44]  [  0/345]  eta: 0:05:06  lr: 0.000012  loss: 0.6934 (0.6934)  time: 0.8897  data: 0.1490  max mem: 14938
[18:28:08.576656] Epoch: [44]  [ 20/345]  eta: 0:04:03  lr: 0.000012  loss: 0.7066 (0.7073)  time: 0.7437  data: 0.0001  max mem: 14938
[18:28:23.494569] Epoch: [44]  [ 40/345]  eta: 0:03:48  lr: 0.000011  loss: 0.7042 (0.7067)  time: 0.7458  data: 0.0001  max mem: 14938
[18:28:38.437699] Epoch: [44]  [ 60/345]  eta: 0:03:33  lr: 0.000011  loss: 0.7052 (0.7066)  time: 0.7471  data: 0.0001  max mem: 14938
[18:28:53.401236] Epoch: [44]  [ 80/345]  eta: 0:03:18  lr: 0.000011  loss: 0.7061 (0.7058)  time: 0.7481  data: 0.0001  max mem: 14938
[18:29:08.391787] Epoch: [44]  [100/345]  eta: 0:03:03  lr: 0.000011  loss: 0.7070 (0.7063)  time: 0.7495  data: 0.0001  max mem: 14938
[18:29:23.419960] Epoch: [44]  [120/345]  eta: 0:02:48  lr: 0.000011  loss: 0.7050 (0.7063)  time: 0.7514  data: 0.0001  max mem: 14938
[18:29:38.454961] Epoch: [44]  [140/345]  eta: 0:02:33  lr: 0.000010  loss: 0.7062 (0.7062)  time: 0.7517  data: 0.0001  max mem: 14938
[18:29:53.476379] Epoch: [44]  [160/345]  eta: 0:02:18  lr: 0.000010  loss: 0.7065 (0.7066)  time: 0.7510  data: 0.0001  max mem: 14938
[18:30:08.491565] Epoch: [44]  [180/345]  eta: 0:02:03  lr: 0.000010  loss: 0.7160 (0.7074)  time: 0.7507  data: 0.0001  max mem: 14938
[18:30:23.499892] Epoch: [44]  [200/345]  eta: 0:01:48  lr: 0.000010  loss: 0.7083 (0.7075)  time: 0.7504  data: 0.0001  max mem: 14938
[18:30:38.534150] Epoch: [44]  [220/345]  eta: 0:01:33  lr: 0.000010  loss: 0.7050 (0.7076)  time: 0.7517  data: 0.0001  max mem: 14938
[18:30:53.528495] Epoch: [44]  [240/345]  eta: 0:01:18  lr: 0.000009  loss: 0.7059 (0.7079)  time: 0.7497  data: 0.0001  max mem: 14938
[18:31:08.516482] Epoch: [44]  [260/345]  eta: 0:01:03  lr: 0.000009  loss: 0.7128 (0.7082)  time: 0.7494  data: 0.0001  max mem: 14938
[18:31:23.505601] Epoch: [44]  [280/345]  eta: 0:00:48  lr: 0.000009  loss: 0.7059 (0.7081)  time: 0.7494  data: 0.0001  max mem: 14938
[18:31:38.494045] Epoch: [44]  [300/345]  eta: 0:00:33  lr: 0.000009  loss: 0.7045 (0.7080)  time: 0.7494  data: 0.0001  max mem: 14938
[18:31:53.479993] Epoch: [44]  [320/345]  eta: 0:00:18  lr: 0.000009  loss: 0.7072 (0.7081)  time: 0.7492  data: 0.0001  max mem: 14938
[18:32:08.453262] Epoch: [44]  [340/345]  eta: 0:00:03  lr: 0.000008  loss: 0.7047 (0.7081)  time: 0.7486  data: 0.0001  max mem: 14938
[18:32:11.452296] Epoch: [44]  [344/345]  eta: 0:00:00  lr: 0.000008  loss: 0.7089 (0.7081)  time: 0.7489  data: 0.0001  max mem: 14938
[18:32:11.520007] Epoch: [44] Total time: 0:04:18 (0.7499 s / it)
[18:32:11.520397] Averaged stats: lr: 0.000008  loss: 0.7089 (0.7081)
[18:32:11.867999] Test:  [  0/345]  eta: 0:01:58  loss: 0.6960 (0.6960)  time: 0.3441  data: 0.1630  max mem: 14938
[18:32:13.702994] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6845 (0.6844)  time: 0.1980  data: 0.0149  max mem: 14938
[18:32:15.541778] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6814 (0.6842)  time: 0.1836  data: 0.0001  max mem: 14938
[18:32:17.382943] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6841 (0.6873)  time: 0.1839  data: 0.0001  max mem: 14938
[18:32:19.227282] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6843 (0.6868)  time: 0.1842  data: 0.0001  max mem: 14938
[18:32:21.078500] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6823 (0.6863)  time: 0.1847  data: 0.0001  max mem: 14938
[18:32:22.930634] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6774 (0.6849)  time: 0.1851  data: 0.0001  max mem: 14938
[18:32:24.786233] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6800 (0.6852)  time: 0.1853  data: 0.0001  max mem: 14938
[18:32:26.645469] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6875 (0.6862)  time: 0.1857  data: 0.0001  max mem: 14938
[18:32:28.509104] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6836 (0.6860)  time: 0.1861  data: 0.0001  max mem: 14938
[18:32:30.375861] Test:  [100/345]  eta: 0:00:45  loss: 0.6794 (0.6857)  time: 0.1865  data: 0.0001  max mem: 14938
[18:32:32.243128] Test:  [110/345]  eta: 0:00:43  loss: 0.6792 (0.6854)  time: 0.1867  data: 0.0001  max mem: 14938
[18:32:34.117277] Test:  [120/345]  eta: 0:00:42  loss: 0.6776 (0.6850)  time: 0.1870  data: 0.0001  max mem: 14938
[18:32:35.992297] Test:  [130/345]  eta: 0:00:40  loss: 0.6798 (0.6849)  time: 0.1874  data: 0.0001  max mem: 14938
[18:32:37.873669] Test:  [140/345]  eta: 0:00:38  loss: 0.6798 (0.6847)  time: 0.1878  data: 0.0001  max mem: 14938
[18:32:39.757103] Test:  [150/345]  eta: 0:00:36  loss: 0.6823 (0.6848)  time: 0.1882  data: 0.0001  max mem: 14938
[18:32:41.644753] Test:  [160/345]  eta: 0:00:34  loss: 0.6845 (0.6847)  time: 0.1885  data: 0.0001  max mem: 14938
[18:32:43.534308] Test:  [170/345]  eta: 0:00:32  loss: 0.6822 (0.6846)  time: 0.1888  data: 0.0001  max mem: 14938
[18:32:45.432824] Test:  [180/345]  eta: 0:00:30  loss: 0.6871 (0.6849)  time: 0.1894  data: 0.0001  max mem: 14938
[18:32:47.332651] Test:  [190/345]  eta: 0:00:29  loss: 0.6872 (0.6852)  time: 0.1899  data: 0.0001  max mem: 14938
[18:32:49.235504] Test:  [200/345]  eta: 0:00:27  loss: 0.6835 (0.6850)  time: 0.1901  data: 0.0001  max mem: 14938
[18:32:51.138531] Test:  [210/345]  eta: 0:00:25  loss: 0.6799 (0.6849)  time: 0.1902  data: 0.0001  max mem: 14938
[18:32:53.045852] Test:  [220/345]  eta: 0:00:23  loss: 0.6798 (0.6849)  time: 0.1905  data: 0.0001  max mem: 14938
[18:32:54.958760] Test:  [230/345]  eta: 0:00:21  loss: 0.6816 (0.6848)  time: 0.1910  data: 0.0001  max mem: 14938
[18:32:56.875437] Test:  [240/345]  eta: 0:00:19  loss: 0.6800 (0.6846)  time: 0.1914  data: 0.0001  max mem: 14938
[18:32:58.795238] Test:  [250/345]  eta: 0:00:17  loss: 0.6773 (0.6843)  time: 0.1918  data: 0.0001  max mem: 14938
[18:33:00.717946] Test:  [260/345]  eta: 0:00:16  loss: 0.6803 (0.6843)  time: 0.1921  data: 0.0001  max mem: 14938
[18:33:02.644070] Test:  [270/345]  eta: 0:00:14  loss: 0.6804 (0.6842)  time: 0.1924  data: 0.0001  max mem: 14938
[18:33:04.575027] Test:  [280/345]  eta: 0:00:12  loss: 0.6804 (0.6842)  time: 0.1928  data: 0.0001  max mem: 14938
[18:33:06.507370] Test:  [290/345]  eta: 0:00:10  loss: 0.6797 (0.6840)  time: 0.1931  data: 0.0001  max mem: 14938
[18:33:08.443880] Test:  [300/345]  eta: 0:00:08  loss: 0.6795 (0.6840)  time: 0.1934  data: 0.0001  max mem: 14938
[18:33:10.384982] Test:  [310/345]  eta: 0:00:06  loss: 0.6829 (0.6841)  time: 0.1938  data: 0.0001  max mem: 14938
[18:33:12.328201] Test:  [320/345]  eta: 0:00:04  loss: 0.6854 (0.6842)  time: 0.1942  data: 0.0001  max mem: 14938
[18:33:14.274512] Test:  [330/345]  eta: 0:00:02  loss: 0.6821 (0.6840)  time: 0.1944  data: 0.0001  max mem: 14938
[18:33:16.221895] Test:  [340/345]  eta: 0:00:00  loss: 0.6742 (0.6839)  time: 0.1946  data: 0.0001  max mem: 14938
[18:33:17.003556] Test:  [344/345]  eta: 0:00:00  loss: 0.6730 (0.6838)  time: 0.1948  data: 0.0001  max mem: 14938
[18:33:17.066247] Test: Total time: 0:01:05 (0.1900 s / it)
[18:33:27.724850] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8404 (0.8404)  time: 0.3234  data: 0.1442  max mem: 14938
[18:33:29.541071] Test:  [10/57]  eta: 0:00:09  loss: 0.8915 (0.8856)  time: 0.1944  data: 0.0132  max mem: 14938
[18:33:31.360324] Test:  [20/57]  eta: 0:00:06  loss: 0.8915 (0.8744)  time: 0.1817  data: 0.0001  max mem: 14938
[18:33:33.185196] Test:  [30/57]  eta: 0:00:05  loss: 0.7593 (0.8335)  time: 0.1822  data: 0.0001  max mem: 14938
[18:33:35.015308] Test:  [40/57]  eta: 0:00:03  loss: 0.7466 (0.8131)  time: 0.1827  data: 0.0001  max mem: 14938
[18:33:36.853911] Test:  [50/57]  eta: 0:00:01  loss: 0.7500 (0.8061)  time: 0.1834  data: 0.0001  max mem: 14938
[18:33:37.844348] Test:  [56/57]  eta: 0:00:00  loss: 0.7598 (0.8115)  time: 0.1781  data: 0.0001  max mem: 14938
[18:33:37.887673] Test: Total time: 0:00:10 (0.1840 s / it)
[18:33:39.660822] Dice score of the network on the train images: 0.839525, val images: 0.816509
[18:33:39.665168] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:33:40.549455] Epoch: [45]  [  0/345]  eta: 0:05:04  lr: 0.000008  loss: 0.7199 (0.7199)  time: 0.8833  data: 0.1428  max mem: 14938
[18:33:55.430893] Epoch: [45]  [ 20/345]  eta: 0:04:03  lr: 0.000008  loss: 0.6997 (0.7047)  time: 0.7440  data: 0.0001  max mem: 14938
[18:34:10.348600] Epoch: [45]  [ 40/345]  eta: 0:03:48  lr: 0.000008  loss: 0.7068 (0.7062)  time: 0.7458  data: 0.0001  max mem: 14938
[18:34:25.315283] Epoch: [45]  [ 60/345]  eta: 0:03:33  lr: 0.000008  loss: 0.6985 (0.7058)  time: 0.7483  data: 0.0001  max mem: 14938
[18:34:40.312907] Epoch: [45]  [ 80/345]  eta: 0:03:18  lr: 0.000008  loss: 0.7076 (0.7063)  time: 0.7498  data: 0.0001  max mem: 14938
[18:34:55.351622] Epoch: [45]  [100/345]  eta: 0:03:03  lr: 0.000007  loss: 0.7078 (0.7071)  time: 0.7519  data: 0.0001  max mem: 14938
[18:35:10.393566] Epoch: [45]  [120/345]  eta: 0:02:48  lr: 0.000007  loss: 0.7085 (0.7073)  time: 0.7521  data: 0.0001  max mem: 14938
[18:35:25.434803] Epoch: [45]  [140/345]  eta: 0:02:33  lr: 0.000007  loss: 0.7049 (0.7072)  time: 0.7520  data: 0.0001  max mem: 14938
[18:35:40.470208] Epoch: [45]  [160/345]  eta: 0:02:18  lr: 0.000007  loss: 0.7035 (0.7069)  time: 0.7517  data: 0.0001  max mem: 14938
[18:35:55.504117] Epoch: [45]  [180/345]  eta: 0:02:03  lr: 0.000007  loss: 0.7083 (0.7072)  time: 0.7517  data: 0.0001  max mem: 14938
[18:36:10.538637] Epoch: [45]  [200/345]  eta: 0:01:48  lr: 0.000007  loss: 0.7045 (0.7071)  time: 0.7517  data: 0.0001  max mem: 14938
[18:36:25.559275] Epoch: [45]  [220/345]  eta: 0:01:33  lr: 0.000006  loss: 0.7117 (0.7075)  time: 0.7510  data: 0.0001  max mem: 14938
[18:36:40.570583] Epoch: [45]  [240/345]  eta: 0:01:18  lr: 0.000006  loss: 0.7089 (0.7077)  time: 0.7505  data: 0.0001  max mem: 14938
[18:36:55.569005] Epoch: [45]  [260/345]  eta: 0:01:03  lr: 0.000006  loss: 0.7059 (0.7076)  time: 0.7499  data: 0.0001  max mem: 14938
[18:37:10.575951] Epoch: [45]  [280/345]  eta: 0:00:48  lr: 0.000006  loss: 0.7021 (0.7075)  time: 0.7503  data: 0.0001  max mem: 14938
[18:37:25.575655] Epoch: [45]  [300/345]  eta: 0:00:33  lr: 0.000006  loss: 0.7017 (0.7073)  time: 0.7499  data: 0.0001  max mem: 14938
[18:37:40.577710] Epoch: [45]  [320/345]  eta: 0:00:18  lr: 0.000006  loss: 0.7073 (0.7073)  time: 0.7501  data: 0.0001  max mem: 14938
[18:37:55.573877] Epoch: [45]  [340/345]  eta: 0:00:03  lr: 0.000005  loss: 0.7042 (0.7072)  time: 0.7498  data: 0.0001  max mem: 14938
[18:37:58.573562] Epoch: [45]  [344/345]  eta: 0:00:00  lr: 0.000005  loss: 0.7043 (0.7072)  time: 0.7498  data: 0.0001  max mem: 14938
[18:37:58.639930] Epoch: [45] Total time: 0:04:18 (0.7507 s / it)
[18:37:58.640475] Averaged stats: lr: 0.000005  loss: 0.7043 (0.7072)
[18:37:58.982996] Test:  [  0/345]  eta: 0:01:56  loss: 0.6609 (0.6609)  time: 0.3380  data: 0.1571  max mem: 14938
[18:38:00.818458] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6767 (0.6798)  time: 0.1975  data: 0.0143  max mem: 14938
[18:38:02.656284] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6815 (0.6835)  time: 0.1836  data: 0.0001  max mem: 14938
[18:38:04.499336] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6806 (0.6813)  time: 0.1840  data: 0.0001  max mem: 14938
[18:38:06.344713] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6823 (0.6837)  time: 0.1844  data: 0.0001  max mem: 14938
[18:38:08.192717] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6879 (0.6840)  time: 0.1846  data: 0.0001  max mem: 14938
[18:38:10.045039] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6819 (0.6833)  time: 0.1850  data: 0.0001  max mem: 14938
[18:38:11.900928] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6803 (0.6830)  time: 0.1854  data: 0.0001  max mem: 14938
[18:38:13.760512] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6818 (0.6836)  time: 0.1857  data: 0.0001  max mem: 14938
[18:38:15.623392] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6843 (0.6834)  time: 0.1861  data: 0.0001  max mem: 14938
[18:38:17.489588] Test:  [100/345]  eta: 0:00:45  loss: 0.6845 (0.6836)  time: 0.1864  data: 0.0001  max mem: 14938
[18:38:19.358197] Test:  [110/345]  eta: 0:00:43  loss: 0.6842 (0.6837)  time: 0.1867  data: 0.0001  max mem: 14938
[18:38:21.231083] Test:  [120/345]  eta: 0:00:41  loss: 0.6790 (0.6835)  time: 0.1870  data: 0.0001  max mem: 14938
[18:38:23.107616] Test:  [130/345]  eta: 0:00:40  loss: 0.6774 (0.6830)  time: 0.1874  data: 0.0001  max mem: 14938
[18:38:24.987994] Test:  [140/345]  eta: 0:00:38  loss: 0.6764 (0.6829)  time: 0.1878  data: 0.0001  max mem: 14938
[18:38:26.871750] Test:  [150/345]  eta: 0:00:36  loss: 0.6820 (0.6830)  time: 0.1882  data: 0.0001  max mem: 14938
[18:38:28.757851] Test:  [160/345]  eta: 0:00:34  loss: 0.6815 (0.6828)  time: 0.1884  data: 0.0001  max mem: 14938
[18:38:30.647300] Test:  [170/345]  eta: 0:00:32  loss: 0.6784 (0.6829)  time: 0.1887  data: 0.0001  max mem: 14938
[18:38:32.540959] Test:  [180/345]  eta: 0:00:30  loss: 0.6853 (0.6832)  time: 0.1891  data: 0.0001  max mem: 14938
[18:38:34.439368] Test:  [190/345]  eta: 0:00:29  loss: 0.6873 (0.6833)  time: 0.1896  data: 0.0001  max mem: 14938
[18:38:36.342390] Test:  [200/345]  eta: 0:00:27  loss: 0.6822 (0.6833)  time: 0.1900  data: 0.0001  max mem: 14938
[18:38:38.245421] Test:  [210/345]  eta: 0:00:25  loss: 0.6822 (0.6833)  time: 0.1903  data: 0.0001  max mem: 14938
[18:38:40.153742] Test:  [220/345]  eta: 0:00:23  loss: 0.6816 (0.6833)  time: 0.1905  data: 0.0001  max mem: 14938
[18:38:42.065884] Test:  [230/345]  eta: 0:00:21  loss: 0.6816 (0.6833)  time: 0.1910  data: 0.0001  max mem: 14938
[18:38:43.980829] Test:  [240/345]  eta: 0:00:19  loss: 0.6780 (0.6830)  time: 0.1913  data: 0.0001  max mem: 14938
[18:38:45.900200] Test:  [250/345]  eta: 0:00:17  loss: 0.6797 (0.6830)  time: 0.1917  data: 0.0001  max mem: 14938
[18:38:47.823232] Test:  [260/345]  eta: 0:00:16  loss: 0.6835 (0.6831)  time: 0.1921  data: 0.0001  max mem: 14938
[18:38:49.748645] Test:  [270/345]  eta: 0:00:14  loss: 0.6788 (0.6827)  time: 0.1924  data: 0.0001  max mem: 14938
[18:38:51.678399] Test:  [280/345]  eta: 0:00:12  loss: 0.6798 (0.6829)  time: 0.1927  data: 0.0001  max mem: 14938
[18:38:53.609872] Test:  [290/345]  eta: 0:00:10  loss: 0.6863 (0.6829)  time: 0.1930  data: 0.0001  max mem: 14938
[18:38:55.545762] Test:  [300/345]  eta: 0:00:08  loss: 0.6863 (0.6832)  time: 0.1933  data: 0.0001  max mem: 14938
[18:38:57.484458] Test:  [310/345]  eta: 0:00:06  loss: 0.6840 (0.6832)  time: 0.1937  data: 0.0001  max mem: 14938
[18:38:59.425896] Test:  [320/345]  eta: 0:00:04  loss: 0.6839 (0.6835)  time: 0.1940  data: 0.0001  max mem: 14938
[18:39:01.370760] Test:  [330/345]  eta: 0:00:02  loss: 0.6836 (0.6832)  time: 0.1943  data: 0.0001  max mem: 14938
[18:39:03.319238] Test:  [340/345]  eta: 0:00:00  loss: 0.6764 (0.6832)  time: 0.1946  data: 0.0001  max mem: 14938
[18:39:04.100203] Test:  [344/345]  eta: 0:00:00  loss: 0.6770 (0.6831)  time: 0.1948  data: 0.0001  max mem: 14938
[18:39:04.158600] Test: Total time: 0:01:05 (0.1899 s / it)
[18:39:14.772287] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8604 (0.8604)  time: 0.3241  data: 0.1447  max mem: 14938
[18:39:16.588114] Test:  [10/57]  eta: 0:00:09  loss: 0.8924 (0.8891)  time: 0.1945  data: 0.0132  max mem: 14938
[18:39:18.408695] Test:  [20/57]  eta: 0:00:06  loss: 0.8924 (0.8758)  time: 0.1818  data: 0.0001  max mem: 14938
[18:39:20.231983] Test:  [30/57]  eta: 0:00:05  loss: 0.7569 (0.8342)  time: 0.1821  data: 0.0001  max mem: 14938
[18:39:22.061703] Test:  [40/57]  eta: 0:00:03  loss: 0.7450 (0.8134)  time: 0.1826  data: 0.0001  max mem: 14938
[18:39:23.897870] Test:  [50/57]  eta: 0:00:01  loss: 0.7450 (0.8062)  time: 0.1832  data: 0.0001  max mem: 14938
[18:39:24.887944] Test:  [56/57]  eta: 0:00:00  loss: 0.7593 (0.8115)  time: 0.1779  data: 0.0001  max mem: 14938
[18:39:24.930484] Test: Total time: 0:00:10 (0.1839 s / it)
[18:39:26.708279] Dice score of the network on the train images: 0.840562, val images: 0.817345
[18:39:26.712353] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:39:27.595689] Epoch: [46]  [  0/345]  eta: 0:05:04  lr: 0.000005  loss: 0.7015 (0.7015)  time: 0.8825  data: 0.1428  max mem: 14938
[18:39:42.471410] Epoch: [46]  [ 20/345]  eta: 0:04:03  lr: 0.000005  loss: 0.7034 (0.7063)  time: 0.7437  data: 0.0001  max mem: 14938
[18:39:57.398924] Epoch: [46]  [ 40/345]  eta: 0:03:48  lr: 0.000005  loss: 0.7103 (0.7069)  time: 0.7463  data: 0.0001  max mem: 14938
[18:40:12.361395] Epoch: [46]  [ 60/345]  eta: 0:03:33  lr: 0.000005  loss: 0.7052 (0.7068)  time: 0.7481  data: 0.0001  max mem: 14938
[18:40:27.318815] Epoch: [46]  [ 80/345]  eta: 0:03:18  lr: 0.000005  loss: 0.7088 (0.7082)  time: 0.7478  data: 0.0001  max mem: 14938
[18:40:42.303847] Epoch: [46]  [100/345]  eta: 0:03:03  lr: 0.000005  loss: 0.7050 (0.7078)  time: 0.7492  data: 0.0001  max mem: 14938
[18:40:57.323185] Epoch: [46]  [120/345]  eta: 0:02:48  lr: 0.000005  loss: 0.7022 (0.7078)  time: 0.7509  data: 0.0001  max mem: 14938
[18:41:12.379249] Epoch: [46]  [140/345]  eta: 0:02:33  lr: 0.000004  loss: 0.7042 (0.7073)  time: 0.7528  data: 0.0001  max mem: 14938
[18:41:27.411815] Epoch: [46]  [160/345]  eta: 0:02:18  lr: 0.000004  loss: 0.7094 (0.7074)  time: 0.7516  data: 0.0001  max mem: 14938
[18:41:42.444517] Epoch: [46]  [180/345]  eta: 0:02:03  lr: 0.000004  loss: 0.7067 (0.7071)  time: 0.7516  data: 0.0001  max mem: 14938
[18:41:57.460302] Epoch: [46]  [200/345]  eta: 0:01:48  lr: 0.000004  loss: 0.7014 (0.7071)  time: 0.7507  data: 0.0001  max mem: 14938
[18:42:12.457806] Epoch: [46]  [220/345]  eta: 0:01:33  lr: 0.000004  loss: 0.7046 (0.7071)  time: 0.7498  data: 0.0001  max mem: 14938
[18:42:27.472318] Epoch: [46]  [240/345]  eta: 0:01:18  lr: 0.000004  loss: 0.7114 (0.7074)  time: 0.7507  data: 0.0001  max mem: 14938
[18:42:42.484126] Epoch: [46]  [260/345]  eta: 0:01:03  lr: 0.000004  loss: 0.7022 (0.7070)  time: 0.7505  data: 0.0001  max mem: 14938
[18:42:57.487376] Epoch: [46]  [280/345]  eta: 0:00:48  lr: 0.000003  loss: 0.6987 (0.7066)  time: 0.7501  data: 0.0001  max mem: 14938
[18:43:12.494773] Epoch: [46]  [300/345]  eta: 0:00:33  lr: 0.000003  loss: 0.7059 (0.7066)  time: 0.7503  data: 0.0001  max mem: 14938
[18:43:27.476652] Epoch: [46]  [320/345]  eta: 0:00:18  lr: 0.000003  loss: 0.7048 (0.7067)  time: 0.7491  data: 0.0001  max mem: 14938
[18:43:42.455585] Epoch: [46]  [340/345]  eta: 0:00:03  lr: 0.000003  loss: 0.7067 (0.7067)  time: 0.7489  data: 0.0001  max mem: 14938
[18:43:45.452047] Epoch: [46]  [344/345]  eta: 0:00:00  lr: 0.000003  loss: 0.7076 (0.7068)  time: 0.7490  data: 0.0001  max mem: 14938
[18:43:45.519818] Epoch: [46] Total time: 0:04:18 (0.7502 s / it)
[18:43:45.520269] Averaged stats: lr: 0.000003  loss: 0.7076 (0.7068)
[18:43:45.858141] Test:  [  0/345]  eta: 0:01:55  loss: 0.6781 (0.6781)  time: 0.3346  data: 0.1537  max mem: 14938
[18:43:47.693283] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6809 (0.6819)  time: 0.1972  data: 0.0140  max mem: 14938
[18:43:49.532879] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6809 (0.6825)  time: 0.1837  data: 0.0001  max mem: 14938
[18:43:51.376701] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6787 (0.6813)  time: 0.1841  data: 0.0001  max mem: 14938
[18:43:53.222502] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6796 (0.6814)  time: 0.1844  data: 0.0001  max mem: 14938
[18:43:55.074070] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6796 (0.6814)  time: 0.1848  data: 0.0001  max mem: 14938
[18:43:56.928533] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6790 (0.6816)  time: 0.1853  data: 0.0001  max mem: 14938
[18:43:58.786530] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6790 (0.6813)  time: 0.1856  data: 0.0001  max mem: 14938
[18:44:00.645557] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6807 (0.6817)  time: 0.1858  data: 0.0001  max mem: 14938
[18:44:02.509111] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6827 (0.6815)  time: 0.1861  data: 0.0001  max mem: 14938
[18:44:04.377309] Test:  [100/345]  eta: 0:00:45  loss: 0.6783 (0.6812)  time: 0.1865  data: 0.0001  max mem: 14938
[18:44:06.247676] Test:  [110/345]  eta: 0:00:43  loss: 0.6808 (0.6815)  time: 0.1869  data: 0.0001  max mem: 14938
[18:44:08.121343] Test:  [120/345]  eta: 0:00:42  loss: 0.6809 (0.6812)  time: 0.1872  data: 0.0001  max mem: 14938
[18:44:09.998883] Test:  [130/345]  eta: 0:00:40  loss: 0.6769 (0.6808)  time: 0.1875  data: 0.0001  max mem: 14938
[18:44:11.880258] Test:  [140/345]  eta: 0:00:38  loss: 0.6842 (0.6814)  time: 0.1879  data: 0.0001  max mem: 14938
[18:44:13.765526] Test:  [150/345]  eta: 0:00:36  loss: 0.6845 (0.6815)  time: 0.1883  data: 0.0001  max mem: 14938
[18:44:15.653019] Test:  [160/345]  eta: 0:00:34  loss: 0.6799 (0.6812)  time: 0.1886  data: 0.0001  max mem: 14938
[18:44:17.541993] Test:  [170/345]  eta: 0:00:32  loss: 0.6794 (0.6812)  time: 0.1888  data: 0.0001  max mem: 14938
[18:44:19.437537] Test:  [180/345]  eta: 0:00:30  loss: 0.6794 (0.6815)  time: 0.1892  data: 0.0001  max mem: 14938
[18:44:21.337335] Test:  [190/345]  eta: 0:00:29  loss: 0.6837 (0.6818)  time: 0.1897  data: 0.0001  max mem: 14938
[18:44:23.239553] Test:  [200/345]  eta: 0:00:27  loss: 0.6875 (0.6821)  time: 0.1900  data: 0.0001  max mem: 14938
[18:44:25.144439] Test:  [210/345]  eta: 0:00:25  loss: 0.6872 (0.6821)  time: 0.1903  data: 0.0001  max mem: 14938
[18:44:27.051924] Test:  [220/345]  eta: 0:00:23  loss: 0.6839 (0.6822)  time: 0.1906  data: 0.0001  max mem: 14938
[18:44:28.963889] Test:  [230/345]  eta: 0:00:21  loss: 0.6821 (0.6821)  time: 0.1909  data: 0.0001  max mem: 14938
[18:44:30.880938] Test:  [240/345]  eta: 0:00:19  loss: 0.6811 (0.6822)  time: 0.1914  data: 0.0001  max mem: 14938
[18:44:32.798863] Test:  [250/345]  eta: 0:00:17  loss: 0.6811 (0.6822)  time: 0.1917  data: 0.0001  max mem: 14938
[18:44:34.720768] Test:  [260/345]  eta: 0:00:16  loss: 0.6793 (0.6821)  time: 0.1919  data: 0.0001  max mem: 14938
[18:44:36.645589] Test:  [270/345]  eta: 0:00:14  loss: 0.6834 (0.6823)  time: 0.1923  data: 0.0001  max mem: 14938
[18:44:38.575437] Test:  [280/345]  eta: 0:00:12  loss: 0.6834 (0.6823)  time: 0.1927  data: 0.0001  max mem: 14938
[18:44:40.508025] Test:  [290/345]  eta: 0:00:10  loss: 0.6791 (0.6824)  time: 0.1931  data: 0.0001  max mem: 14938
[18:44:42.445094] Test:  [300/345]  eta: 0:00:08  loss: 0.6836 (0.6826)  time: 0.1934  data: 0.0001  max mem: 14938
[18:44:44.383220] Test:  [310/345]  eta: 0:00:06  loss: 0.6832 (0.6826)  time: 0.1937  data: 0.0001  max mem: 14938
[18:44:46.324506] Test:  [320/345]  eta: 0:00:04  loss: 0.6808 (0.6826)  time: 0.1939  data: 0.0001  max mem: 14938
[18:44:48.270344] Test:  [330/345]  eta: 0:00:02  loss: 0.6845 (0.6827)  time: 0.1943  data: 0.0001  max mem: 14938
[18:44:50.217063] Test:  [340/345]  eta: 0:00:00  loss: 0.6850 (0.6828)  time: 0.1946  data: 0.0001  max mem: 14938
[18:44:50.998745] Test:  [344/345]  eta: 0:00:00  loss: 0.6838 (0.6828)  time: 0.1948  data: 0.0001  max mem: 14938
[18:44:51.057399] Test: Total time: 0:01:05 (0.1900 s / it)
[18:45:01.746950] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8438 (0.8438)  time: 0.3228  data: 0.1433  max mem: 14938
[18:45:03.561663] Test:  [10/57]  eta: 0:00:09  loss: 0.8913 (0.8854)  time: 0.1943  data: 0.0131  max mem: 14938
[18:45:05.383322] Test:  [20/57]  eta: 0:00:06  loss: 0.8913 (0.8729)  time: 0.1818  data: 0.0001  max mem: 14938
[18:45:07.208218] Test:  [30/57]  eta: 0:00:05  loss: 0.7563 (0.8317)  time: 0.1823  data: 0.0001  max mem: 14938
[18:45:09.035550] Test:  [40/57]  eta: 0:00:03  loss: 0.7452 (0.8113)  time: 0.1826  data: 0.0001  max mem: 14938
[18:45:10.871421] Test:  [50/57]  eta: 0:00:01  loss: 0.7461 (0.8044)  time: 0.1831  data: 0.0001  max mem: 14938
[18:45:11.861036] Test:  [56/57]  eta: 0:00:00  loss: 0.7590 (0.8099)  time: 0.1777  data: 0.0001  max mem: 14938
[18:45:11.916900] Test: Total time: 0:00:10 (0.1841 s / it)
[18:45:13.695320] Dice score of the network on the train images: 0.839534, val images: 0.817912
[18:45:13.699462] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:45:14.588783] Epoch: [47]  [  0/345]  eta: 0:05:06  lr: 0.000003  loss: 0.7145 (0.7145)  time: 0.8885  data: 0.1465  max mem: 14938
[18:45:29.457923] Epoch: [47]  [ 20/345]  eta: 0:04:03  lr: 0.000003  loss: 0.7019 (0.7030)  time: 0.7434  data: 0.0001  max mem: 14938
[18:45:44.370275] Epoch: [47]  [ 40/345]  eta: 0:03:48  lr: 0.000003  loss: 0.7039 (0.7045)  time: 0.7456  data: 0.0001  max mem: 14938
[18:45:59.306957] Epoch: [47]  [ 60/345]  eta: 0:03:33  lr: 0.000003  loss: 0.7070 (0.7056)  time: 0.7468  data: 0.0001  max mem: 14938
[18:46:14.261407] Epoch: [47]  [ 80/345]  eta: 0:03:18  lr: 0.000003  loss: 0.7076 (0.7065)  time: 0.7477  data: 0.0001  max mem: 14938
[18:46:29.247670] Epoch: [47]  [100/345]  eta: 0:03:03  lr: 0.000003  loss: 0.7051 (0.7064)  time: 0.7493  data: 0.0001  max mem: 14938
[18:46:44.249307] Epoch: [47]  [120/345]  eta: 0:02:48  lr: 0.000002  loss: 0.7053 (0.7065)  time: 0.7500  data: 0.0001  max mem: 14938
[18:46:59.251993] Epoch: [47]  [140/345]  eta: 0:02:33  lr: 0.000002  loss: 0.7056 (0.7068)  time: 0.7501  data: 0.0001  max mem: 14938
[18:47:14.265281] Epoch: [47]  [160/345]  eta: 0:02:18  lr: 0.000002  loss: 0.7044 (0.7065)  time: 0.7506  data: 0.0001  max mem: 14938
[18:47:29.285992] Epoch: [47]  [180/345]  eta: 0:02:03  lr: 0.000002  loss: 0.7070 (0.7069)  time: 0.7510  data: 0.0001  max mem: 14938
[18:47:44.412777] Epoch: [47]  [200/345]  eta: 0:01:48  lr: 0.000002  loss: 0.7062 (0.7069)  time: 0.7563  data: 0.0001  max mem: 14938
[18:47:59.414874] Epoch: [47]  [220/345]  eta: 0:01:33  lr: 0.000002  loss: 0.7036 (0.7067)  time: 0.7501  data: 0.0001  max mem: 14938
[18:48:14.382933] Epoch: [47]  [240/345]  eta: 0:01:18  lr: 0.000002  loss: 0.6996 (0.7064)  time: 0.7484  data: 0.0001  max mem: 14938
[18:48:29.362624] Epoch: [47]  [260/345]  eta: 0:01:03  lr: 0.000002  loss: 0.7066 (0.7066)  time: 0.7489  data: 0.0001  max mem: 14938
[18:48:44.341323] Epoch: [47]  [280/345]  eta: 0:00:48  lr: 0.000002  loss: 0.7095 (0.7068)  time: 0.7489  data: 0.0001  max mem: 14938
[18:48:59.319991] Epoch: [47]  [300/345]  eta: 0:00:33  lr: 0.000002  loss: 0.7043 (0.7067)  time: 0.7489  data: 0.0001  max mem: 14938
[18:49:14.295962] Epoch: [47]  [320/345]  eta: 0:00:18  lr: 0.000001  loss: 0.7052 (0.7066)  time: 0.7488  data: 0.0001  max mem: 14938
[18:49:29.265291] Epoch: [47]  [340/345]  eta: 0:00:03  lr: 0.000001  loss: 0.7055 (0.7065)  time: 0.7484  data: 0.0001  max mem: 14938
[18:49:32.260131] Epoch: [47]  [344/345]  eta: 0:00:00  lr: 0.000001  loss: 0.7023 (0.7065)  time: 0.7484  data: 0.0001  max mem: 14938
[18:49:32.324621] Epoch: [47] Total time: 0:04:18 (0.7496 s / it)
[18:49:32.325141] Averaged stats: lr: 0.000001  loss: 0.7023 (0.7065)
[18:49:32.663535] Test:  [  0/345]  eta: 0:01:55  loss: 0.6642 (0.6642)  time: 0.3342  data: 0.1522  max mem: 14938
[18:49:34.497263] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6831 (0.6817)  time: 0.1970  data: 0.0139  max mem: 14938
[18:49:36.335829] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6821 (0.6799)  time: 0.1835  data: 0.0001  max mem: 14938
[18:49:38.176611] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6759 (0.6786)  time: 0.1839  data: 0.0001  max mem: 14938
[18:49:40.023916] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6781 (0.6812)  time: 0.1844  data: 0.0001  max mem: 14938
[18:49:41.873114] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6818 (0.6813)  time: 0.1848  data: 0.0001  max mem: 14938
[18:49:43.727128] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6812 (0.6819)  time: 0.1851  data: 0.0001  max mem: 14938
[18:49:45.582521] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6800 (0.6814)  time: 0.1854  data: 0.0001  max mem: 14938
[18:49:47.442123] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6800 (0.6821)  time: 0.1857  data: 0.0001  max mem: 14938
[18:49:49.305851] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6900 (0.6829)  time: 0.1861  data: 0.0001  max mem: 14938
[18:49:51.173561] Test:  [100/345]  eta: 0:00:45  loss: 0.6895 (0.6831)  time: 0.1865  data: 0.0001  max mem: 14938
[18:49:53.043276] Test:  [110/345]  eta: 0:00:43  loss: 0.6807 (0.6829)  time: 0.1868  data: 0.0001  max mem: 14938
[18:49:54.915501] Test:  [120/345]  eta: 0:00:41  loss: 0.6811 (0.6835)  time: 0.1870  data: 0.0001  max mem: 14938
[18:49:56.792686] Test:  [130/345]  eta: 0:00:40  loss: 0.6822 (0.6837)  time: 0.1874  data: 0.0001  max mem: 14938
[18:49:58.672658] Test:  [140/345]  eta: 0:00:38  loss: 0.6819 (0.6839)  time: 0.1878  data: 0.0001  max mem: 14938
[18:50:00.555663] Test:  [150/345]  eta: 0:00:36  loss: 0.6816 (0.6836)  time: 0.1881  data: 0.0001  max mem: 14938
[18:50:02.441776] Test:  [160/345]  eta: 0:00:34  loss: 0.6797 (0.6837)  time: 0.1884  data: 0.0001  max mem: 14938
[18:50:04.331250] Test:  [170/345]  eta: 0:00:32  loss: 0.6891 (0.6843)  time: 0.1887  data: 0.0001  max mem: 14938
[18:50:06.224836] Test:  [180/345]  eta: 0:00:30  loss: 0.6843 (0.6841)  time: 0.1891  data: 0.0001  max mem: 14938
[18:50:08.124539] Test:  [190/345]  eta: 0:00:29  loss: 0.6813 (0.6843)  time: 0.1896  data: 0.0001  max mem: 14938
[18:50:10.024305] Test:  [200/345]  eta: 0:00:27  loss: 0.6809 (0.6840)  time: 0.1899  data: 0.0001  max mem: 14938
[18:50:11.926950] Test:  [210/345]  eta: 0:00:25  loss: 0.6809 (0.6839)  time: 0.1901  data: 0.0001  max mem: 14938
[18:50:13.834369] Test:  [220/345]  eta: 0:00:23  loss: 0.6814 (0.6839)  time: 0.1905  data: 0.0001  max mem: 14938
[18:50:15.745930] Test:  [230/345]  eta: 0:00:21  loss: 0.6784 (0.6839)  time: 0.1909  data: 0.0001  max mem: 14938
[18:50:17.660763] Test:  [240/345]  eta: 0:00:19  loss: 0.6777 (0.6836)  time: 0.1913  data: 0.0001  max mem: 14938
[18:50:19.578676] Test:  [250/345]  eta: 0:00:17  loss: 0.6736 (0.6834)  time: 0.1916  data: 0.0001  max mem: 14938
[18:50:21.498902] Test:  [260/345]  eta: 0:00:16  loss: 0.6739 (0.6835)  time: 0.1919  data: 0.0001  max mem: 14938
[18:50:23.426088] Test:  [270/345]  eta: 0:00:14  loss: 0.6769 (0.6832)  time: 0.1923  data: 0.0001  max mem: 14938
[18:50:25.356221] Test:  [280/345]  eta: 0:00:12  loss: 0.6787 (0.6831)  time: 0.1928  data: 0.0001  max mem: 14938
[18:50:27.288619] Test:  [290/345]  eta: 0:00:10  loss: 0.6831 (0.6831)  time: 0.1931  data: 0.0001  max mem: 14938
[18:50:29.223366] Test:  [300/345]  eta: 0:00:08  loss: 0.6794 (0.6830)  time: 0.1933  data: 0.0001  max mem: 14938
[18:50:31.162923] Test:  [310/345]  eta: 0:00:06  loss: 0.6784 (0.6830)  time: 0.1937  data: 0.0001  max mem: 14938
[18:50:33.104607] Test:  [320/345]  eta: 0:00:04  loss: 0.6784 (0.6828)  time: 0.1940  data: 0.0001  max mem: 14938
[18:50:35.050722] Test:  [330/345]  eta: 0:00:02  loss: 0.6793 (0.6829)  time: 0.1943  data: 0.0001  max mem: 14938
[18:50:37.000008] Test:  [340/345]  eta: 0:00:00  loss: 0.6809 (0.6828)  time: 0.1947  data: 0.0001  max mem: 14938
[18:50:37.780039] Test:  [344/345]  eta: 0:00:00  loss: 0.6809 (0.6828)  time: 0.1948  data: 0.0001  max mem: 14938
[18:50:37.840583] Test: Total time: 0:01:05 (0.1899 s / it)
[18:50:48.317462] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8435 (0.8435)  time: 0.3226  data: 0.1427  max mem: 14938
[18:50:50.132353] Test:  [10/57]  eta: 0:00:09  loss: 0.8937 (0.8864)  time: 0.1942  data: 0.0130  max mem: 14938
[18:50:51.952382] Test:  [20/57]  eta: 0:00:06  loss: 0.8937 (0.8740)  time: 0.1817  data: 0.0001  max mem: 14938
[18:50:53.775804] Test:  [30/57]  eta: 0:00:05  loss: 0.7571 (0.8327)  time: 0.1821  data: 0.0001  max mem: 14938
[18:50:55.601703] Test:  [40/57]  eta: 0:00:03  loss: 0.7461 (0.8123)  time: 0.1824  data: 0.0001  max mem: 14938
[18:50:57.437243] Test:  [50/57]  eta: 0:00:01  loss: 0.7472 (0.8053)  time: 0.1830  data: 0.0001  max mem: 14938
[18:50:58.427030] Test:  [56/57]  eta: 0:00:00  loss: 0.7580 (0.8108)  time: 0.1778  data: 0.0001  max mem: 14938
[18:50:58.486636] Test: Total time: 0:00:10 (0.1841 s / it)
[18:51:00.273125] Dice score of the network on the train images: 0.839923, val images: 0.817657
[18:51:00.277158] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:51:01.161736] Epoch: [48]  [  0/345]  eta: 0:05:04  lr: 0.000001  loss: 0.7021 (0.7021)  time: 0.8836  data: 0.1430  max mem: 14938
[18:51:16.055267] Epoch: [48]  [ 20/345]  eta: 0:04:04  lr: 0.000001  loss: 0.7014 (0.7026)  time: 0.7446  data: 0.0001  max mem: 14938
[18:51:30.977750] Epoch: [48]  [ 40/345]  eta: 0:03:48  lr: 0.000001  loss: 0.7041 (0.7029)  time: 0.7461  data: 0.0001  max mem: 14938
[18:51:45.911957] Epoch: [48]  [ 60/345]  eta: 0:03:33  lr: 0.000001  loss: 0.7027 (0.7029)  time: 0.7467  data: 0.0001  max mem: 14938
[18:52:00.882858] Epoch: [48]  [ 80/345]  eta: 0:03:18  lr: 0.000001  loss: 0.7061 (0.7046)  time: 0.7485  data: 0.0001  max mem: 14938
[18:52:15.893410] Epoch: [48]  [100/345]  eta: 0:03:03  lr: 0.000001  loss: 0.7024 (0.7046)  time: 0.7505  data: 0.0001  max mem: 14938
[18:52:30.910294] Epoch: [48]  [120/345]  eta: 0:02:48  lr: 0.000001  loss: 0.7059 (0.7049)  time: 0.7508  data: 0.0001  max mem: 14938
[18:52:45.938548] Epoch: [48]  [140/345]  eta: 0:02:33  lr: 0.000001  loss: 0.7054 (0.7049)  time: 0.7514  data: 0.0001  max mem: 14938
[18:53:00.949845] Epoch: [48]  [160/345]  eta: 0:02:18  lr: 0.000001  loss: 0.7062 (0.7053)  time: 0.7505  data: 0.0001  max mem: 14938
[18:53:15.962401] Epoch: [48]  [180/345]  eta: 0:02:03  lr: 0.000001  loss: 0.7094 (0.7057)  time: 0.7506  data: 0.0001  max mem: 14938
[18:53:30.974099] Epoch: [48]  [200/345]  eta: 0:01:48  lr: 0.000001  loss: 0.7055 (0.7059)  time: 0.7505  data: 0.0001  max mem: 14938
[18:53:45.964818] Epoch: [48]  [220/345]  eta: 0:01:33  lr: 0.000001  loss: 0.7062 (0.7059)  time: 0.7495  data: 0.0001  max mem: 14938
[18:54:00.936457] Epoch: [48]  [240/345]  eta: 0:01:18  lr: 0.000001  loss: 0.7116 (0.7063)  time: 0.7485  data: 0.0001  max mem: 14938
[18:54:15.927575] Epoch: [48]  [260/345]  eta: 0:01:03  lr: 0.000001  loss: 0.7033 (0.7061)  time: 0.7495  data: 0.0001  max mem: 14938
[18:54:30.912128] Epoch: [48]  [280/345]  eta: 0:00:48  lr: 0.000000  loss: 0.7058 (0.7062)  time: 0.7492  data: 0.0001  max mem: 14938
[18:54:45.889423] Epoch: [48]  [300/345]  eta: 0:00:33  lr: 0.000000  loss: 0.7090 (0.7064)  time: 0.7488  data: 0.0001  max mem: 14938
[18:55:00.868606] Epoch: [48]  [320/345]  eta: 0:00:18  lr: 0.000000  loss: 0.7021 (0.7062)  time: 0.7489  data: 0.0001  max mem: 14938
[18:55:15.844091] Epoch: [48]  [340/345]  eta: 0:00:03  lr: 0.000000  loss: 0.7026 (0.7062)  time: 0.7487  data: 0.0001  max mem: 14938
[18:55:18.840183] Epoch: [48]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.7026 (0.7062)  time: 0.7487  data: 0.0001  max mem: 14938
[18:55:18.904988] Epoch: [48] Total time: 0:04:18 (0.7496 s / it)
[18:55:18.905411] Averaged stats: lr: 0.000000  loss: 0.7026 (0.7062)
[18:55:19.245322] Test:  [  0/345]  eta: 0:01:55  loss: 0.6790 (0.6790)  time: 0.3351  data: 0.1540  max mem: 14938
[18:55:21.080232] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6830 (0.6868)  time: 0.1972  data: 0.0141  max mem: 14938
[18:55:22.916815] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6814 (0.6837)  time: 0.1835  data: 0.0001  max mem: 14938
[18:55:24.758305] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6799 (0.6843)  time: 0.1839  data: 0.0001  max mem: 14938
[18:55:26.603072] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6830 (0.6844)  time: 0.1843  data: 0.0001  max mem: 14938
[18:55:28.451860] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6800 (0.6834)  time: 0.1846  data: 0.0001  max mem: 14938
[18:55:30.303195] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6784 (0.6832)  time: 0.1850  data: 0.0001  max mem: 14938
[18:55:32.158640] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6792 (0.6831)  time: 0.1853  data: 0.0001  max mem: 14938
[18:55:34.016749] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6792 (0.6825)  time: 0.1856  data: 0.0001  max mem: 14938
[18:55:35.878328] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6787 (0.6825)  time: 0.1859  data: 0.0001  max mem: 14938
[18:55:37.743875] Test:  [100/345]  eta: 0:00:45  loss: 0.6805 (0.6825)  time: 0.1863  data: 0.0001  max mem: 14938
[18:55:39.613667] Test:  [110/345]  eta: 0:00:43  loss: 0.6829 (0.6830)  time: 0.1867  data: 0.0001  max mem: 14938
[18:55:41.486281] Test:  [120/345]  eta: 0:00:41  loss: 0.6810 (0.6824)  time: 0.1871  data: 0.0001  max mem: 14938
[18:55:43.361640] Test:  [130/345]  eta: 0:00:40  loss: 0.6807 (0.6828)  time: 0.1873  data: 0.0001  max mem: 14938
[18:55:45.241841] Test:  [140/345]  eta: 0:00:38  loss: 0.6867 (0.6831)  time: 0.1877  data: 0.0001  max mem: 14938
[18:55:47.125891] Test:  [150/345]  eta: 0:00:36  loss: 0.6815 (0.6829)  time: 0.1882  data: 0.0001  max mem: 14938
[18:55:49.011643] Test:  [160/345]  eta: 0:00:34  loss: 0.6827 (0.6833)  time: 0.1884  data: 0.0001  max mem: 14938
[18:55:50.901610] Test:  [170/345]  eta: 0:00:32  loss: 0.6822 (0.6830)  time: 0.1887  data: 0.0001  max mem: 14938
[18:55:52.795009] Test:  [180/345]  eta: 0:00:30  loss: 0.6820 (0.6832)  time: 0.1891  data: 0.0001  max mem: 14938
[18:55:54.693044] Test:  [190/345]  eta: 0:00:29  loss: 0.6820 (0.6831)  time: 0.1895  data: 0.0001  max mem: 14938
[18:55:56.592866] Test:  [200/345]  eta: 0:00:27  loss: 0.6802 (0.6829)  time: 0.1898  data: 0.0001  max mem: 14938
[18:55:58.496010] Test:  [210/345]  eta: 0:00:25  loss: 0.6809 (0.6831)  time: 0.1901  data: 0.0001  max mem: 14938
[18:56:00.405413] Test:  [220/345]  eta: 0:00:23  loss: 0.6835 (0.6830)  time: 0.1906  data: 0.0001  max mem: 14938
[18:56:02.318026] Test:  [230/345]  eta: 0:00:21  loss: 0.6835 (0.6830)  time: 0.1910  data: 0.0001  max mem: 14938
[18:56:04.233042] Test:  [240/345]  eta: 0:00:19  loss: 0.6804 (0.6829)  time: 0.1913  data: 0.0001  max mem: 14938
[18:56:06.152011] Test:  [250/345]  eta: 0:00:17  loss: 0.6785 (0.6829)  time: 0.1916  data: 0.0001  max mem: 14938
[18:56:08.073792] Test:  [260/345]  eta: 0:00:16  loss: 0.6785 (0.6828)  time: 0.1920  data: 0.0001  max mem: 14938
[18:56:09.999363] Test:  [270/345]  eta: 0:00:14  loss: 0.6803 (0.6827)  time: 0.1923  data: 0.0001  max mem: 14938
[18:56:11.928756] Test:  [280/345]  eta: 0:00:12  loss: 0.6833 (0.6828)  time: 0.1927  data: 0.0001  max mem: 14938
[18:56:13.861069] Test:  [290/345]  eta: 0:00:10  loss: 0.6833 (0.6829)  time: 0.1930  data: 0.0001  max mem: 14938
[18:56:15.796226] Test:  [300/345]  eta: 0:00:08  loss: 0.6818 (0.6829)  time: 0.1933  data: 0.0001  max mem: 14938
[18:56:17.735825] Test:  [310/345]  eta: 0:00:06  loss: 0.6822 (0.6828)  time: 0.1937  data: 0.0001  max mem: 14938
[18:56:19.676252] Test:  [320/345]  eta: 0:00:04  loss: 0.6831 (0.6829)  time: 0.1939  data: 0.0001  max mem: 14938
[18:56:21.620407] Test:  [330/345]  eta: 0:00:02  loss: 0.6828 (0.6829)  time: 0.1942  data: 0.0001  max mem: 14938
[18:56:23.566221] Test:  [340/345]  eta: 0:00:00  loss: 0.6783 (0.6827)  time: 0.1944  data: 0.0001  max mem: 14938
[18:56:24.348076] Test:  [344/345]  eta: 0:00:00  loss: 0.6781 (0.6827)  time: 0.1947  data: 0.0001  max mem: 14938
[18:56:24.410608] Test: Total time: 0:01:05 (0.1899 s / it)
[18:56:34.886472] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8427 (0.8427)  time: 0.3256  data: 0.1461  max mem: 14938
[18:56:36.701020] Test:  [10/57]  eta: 0:00:09  loss: 0.8923 (0.8854)  time: 0.1945  data: 0.0133  max mem: 14938
[18:56:38.521077] Test:  [20/57]  eta: 0:00:06  loss: 0.8923 (0.8732)  time: 0.1817  data: 0.0001  max mem: 14938
[18:56:40.346652] Test:  [30/57]  eta: 0:00:05  loss: 0.7567 (0.8320)  time: 0.1822  data: 0.0001  max mem: 14938
[18:56:42.172507] Test:  [40/57]  eta: 0:00:03  loss: 0.7450 (0.8116)  time: 0.1825  data: 0.0001  max mem: 14938
[18:56:44.009254] Test:  [50/57]  eta: 0:00:01  loss: 0.7465 (0.8047)  time: 0.1831  data: 0.0001  max mem: 14938
[18:56:44.999555] Test:  [56/57]  eta: 0:00:00  loss: 0.7588 (0.8102)  time: 0.1778  data: 0.0001  max mem: 14938
[18:56:45.062430] Test: Total time: 0:00:10 (0.1842 s / it)
[18:56:46.845098] Dice score of the network on the train images: 0.839697, val images: 0.817745
[18:56:46.849306] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[18:56:47.743526] Epoch: [49]  [  0/345]  eta: 0:05:08  lr: 0.000000  loss: 0.7161 (0.7161)  time: 0.8934  data: 0.1514  max mem: 14938
[18:57:02.612381] Epoch: [49]  [ 20/345]  eta: 0:04:03  lr: 0.000000  loss: 0.7081 (0.7081)  time: 0.7434  data: 0.0001  max mem: 14938
[18:57:17.520731] Epoch: [49]  [ 40/345]  eta: 0:03:48  lr: 0.000000  loss: 0.7067 (0.7084)  time: 0.7454  data: 0.0001  max mem: 14938
[18:57:32.453221] Epoch: [49]  [ 60/345]  eta: 0:03:33  lr: 0.000000  loss: 0.7051 (0.7080)  time: 0.7466  data: 0.0001  max mem: 14938
[18:57:47.413029] Epoch: [49]  [ 80/345]  eta: 0:03:18  lr: 0.000000  loss: 0.7058 (0.7071)  time: 0.7479  data: 0.0001  max mem: 14938
[18:58:02.393585] Epoch: [49]  [100/345]  eta: 0:03:03  lr: 0.000000  loss: 0.7070 (0.7072)  time: 0.7490  data: 0.0001  max mem: 14938
[18:58:17.395996] Epoch: [49]  [120/345]  eta: 0:02:48  lr: 0.000000  loss: 0.7023 (0.7066)  time: 0.7501  data: 0.0001  max mem: 14938
[18:58:32.528710] Epoch: [49]  [140/345]  eta: 0:02:33  lr: 0.000000  loss: 0.7056 (0.7066)  time: 0.7566  data: 0.0001  max mem: 14938
[18:58:47.518806] Epoch: [49]  [160/345]  eta: 0:02:18  lr: 0.000000  loss: 0.7011 (0.7065)  time: 0.7495  data: 0.0001  max mem: 14938
[18:59:02.507263] Epoch: [49]  [180/345]  eta: 0:02:03  lr: 0.000000  loss: 0.7074 (0.7063)  time: 0.7494  data: 0.0001  max mem: 14938
[18:59:17.488291] Epoch: [49]  [200/345]  eta: 0:01:48  lr: 0.000000  loss: 0.6996 (0.7060)  time: 0.7490  data: 0.0001  max mem: 14938
[18:59:32.461823] Epoch: [49]  [220/345]  eta: 0:01:33  lr: 0.000000  loss: 0.7027 (0.7061)  time: 0.7486  data: 0.0001  max mem: 14938
[18:59:47.431515] Epoch: [49]  [240/345]  eta: 0:01:18  lr: 0.000000  loss: 0.7055 (0.7060)  time: 0.7484  data: 0.0001  max mem: 14938
[19:00:02.389070] Epoch: [49]  [260/345]  eta: 0:01:03  lr: 0.000000  loss: 0.7023 (0.7060)  time: 0.7478  data: 0.0001  max mem: 14938
[19:00:17.348653] Epoch: [49]  [280/345]  eta: 0:00:48  lr: 0.000000  loss: 0.7031 (0.7059)  time: 0.7479  data: 0.0001  max mem: 14938
[19:00:32.307154] Epoch: [49]  [300/345]  eta: 0:00:33  lr: 0.000000  loss: 0.7052 (0.7061)  time: 0.7479  data: 0.0001  max mem: 14938
[19:00:47.264494] Epoch: [49]  [320/345]  eta: 0:00:18  lr: 0.000000  loss: 0.7056 (0.7062)  time: 0.7478  data: 0.0001  max mem: 14938
[19:01:02.216420] Epoch: [49]  [340/345]  eta: 0:00:03  lr: 0.000000  loss: 0.6995 (0.7062)  time: 0.7476  data: 0.0001  max mem: 14938
[19:01:05.207556] Epoch: [49]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.6995 (0.7062)  time: 0.7475  data: 0.0001  max mem: 14938
[19:01:05.274444] Epoch: [49] Total time: 0:04:18 (0.7491 s / it)
[19:01:05.274955] Averaged stats: lr: 0.000000  loss: 0.6995 (0.7062)
[19:01:05.616647] Test:  [  0/345]  eta: 0:01:56  loss: 0.6803 (0.6803)  time: 0.3381  data: 0.1567  max mem: 14938
[19:01:07.453762] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6764 (0.6771)  time: 0.1977  data: 0.0143  max mem: 14938
[19:01:09.291870] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6764 (0.6803)  time: 0.1837  data: 0.0001  max mem: 14938
[19:01:11.135792] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6832 (0.6818)  time: 0.1840  data: 0.0001  max mem: 14938
[19:01:12.982117] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6832 (0.6822)  time: 0.1845  data: 0.0001  max mem: 14938
[19:01:14.831962] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6824 (0.6820)  time: 0.1848  data: 0.0001  max mem: 14938
[19:01:16.685629] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6817 (0.6817)  time: 0.1851  data: 0.0001  max mem: 14938
[19:01:18.541303] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6781 (0.6810)  time: 0.1854  data: 0.0001  max mem: 14938
[19:01:20.400419] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6806 (0.6816)  time: 0.1857  data: 0.0001  max mem: 14938
[19:01:22.262661] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6825 (0.6820)  time: 0.1860  data: 0.0001  max mem: 14938
[19:01:24.129026] Test:  [100/345]  eta: 0:00:45  loss: 0.6808 (0.6823)  time: 0.1864  data: 0.0001  max mem: 14938
[19:01:25.998879] Test:  [110/345]  eta: 0:00:43  loss: 0.6820 (0.6824)  time: 0.1868  data: 0.0001  max mem: 14938
[19:01:27.872202] Test:  [120/345]  eta: 0:00:42  loss: 0.6753 (0.6816)  time: 0.1871  data: 0.0001  max mem: 14938
[19:01:29.748832] Test:  [130/345]  eta: 0:00:40  loss: 0.6753 (0.6816)  time: 0.1874  data: 0.0001  max mem: 14938
[19:01:31.628599] Test:  [140/345]  eta: 0:00:38  loss: 0.6826 (0.6818)  time: 0.1878  data: 0.0001  max mem: 14938
[19:01:33.512514] Test:  [150/345]  eta: 0:00:36  loss: 0.6841 (0.6819)  time: 0.1881  data: 0.0001  max mem: 14938
[19:01:35.398999] Test:  [160/345]  eta: 0:00:34  loss: 0.6796 (0.6818)  time: 0.1885  data: 0.0001  max mem: 14938
[19:01:37.288944] Test:  [170/345]  eta: 0:00:32  loss: 0.6794 (0.6818)  time: 0.1888  data: 0.0001  max mem: 14938
[19:01:39.183952] Test:  [180/345]  eta: 0:00:30  loss: 0.6821 (0.6819)  time: 0.1892  data: 0.0001  max mem: 14938
[19:01:41.081848] Test:  [190/345]  eta: 0:00:29  loss: 0.6823 (0.6821)  time: 0.1896  data: 0.0001  max mem: 14938
[19:01:42.981088] Test:  [200/345]  eta: 0:00:27  loss: 0.6823 (0.6820)  time: 0.1898  data: 0.0001  max mem: 14938
[19:01:44.883464] Test:  [210/345]  eta: 0:00:25  loss: 0.6829 (0.6822)  time: 0.1900  data: 0.0001  max mem: 14938
[19:01:46.792222] Test:  [220/345]  eta: 0:00:23  loss: 0.6834 (0.6823)  time: 0.1905  data: 0.0001  max mem: 14938
[19:01:48.702451] Test:  [230/345]  eta: 0:00:21  loss: 0.6834 (0.6825)  time: 0.1909  data: 0.0001  max mem: 14938
[19:01:50.618106] Test:  [240/345]  eta: 0:00:19  loss: 0.6845 (0.6825)  time: 0.1912  data: 0.0001  max mem: 14938
[19:01:52.537087] Test:  [250/345]  eta: 0:00:17  loss: 0.6866 (0.6827)  time: 0.1917  data: 0.0001  max mem: 14938
[19:01:54.459305] Test:  [260/345]  eta: 0:00:16  loss: 0.6867 (0.6828)  time: 0.1920  data: 0.0001  max mem: 14938
[19:01:56.384443] Test:  [270/345]  eta: 0:00:14  loss: 0.6844 (0.6828)  time: 0.1923  data: 0.0001  max mem: 14938
[19:01:58.314354] Test:  [280/345]  eta: 0:00:12  loss: 0.6796 (0.6827)  time: 0.1927  data: 0.0001  max mem: 14938
[19:02:00.246299] Test:  [290/345]  eta: 0:00:10  loss: 0.6777 (0.6824)  time: 0.1930  data: 0.0001  max mem: 14938
[19:02:02.182123] Test:  [300/345]  eta: 0:00:08  loss: 0.6781 (0.6825)  time: 0.1933  data: 0.0001  max mem: 14938
[19:02:04.121276] Test:  [310/345]  eta: 0:00:06  loss: 0.6834 (0.6826)  time: 0.1937  data: 0.0001  max mem: 14938
[19:02:06.063675] Test:  [320/345]  eta: 0:00:04  loss: 0.6773 (0.6823)  time: 0.1940  data: 0.0001  max mem: 14938
[19:02:08.010464] Test:  [330/345]  eta: 0:00:02  loss: 0.6782 (0.6825)  time: 0.1944  data: 0.0001  max mem: 14938
[19:02:09.957604] Test:  [340/345]  eta: 0:00:00  loss: 0.6827 (0.6825)  time: 0.1946  data: 0.0001  max mem: 14938
[19:02:10.738598] Test:  [344/345]  eta: 0:00:00  loss: 0.6818 (0.6826)  time: 0.1947  data: 0.0001  max mem: 14938
[19:02:10.799707] Test: Total time: 0:01:05 (0.1899 s / it)
[19:02:21.351743] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8421 (0.8421)  time: 0.3268  data: 0.1471  max mem: 14938
[19:02:23.165517] Test:  [10/57]  eta: 0:00:09  loss: 0.8921 (0.8850)  time: 0.1945  data: 0.0134  max mem: 14938
[19:02:24.984338] Test:  [20/57]  eta: 0:00:06  loss: 0.8921 (0.8728)  time: 0.1816  data: 0.0001  max mem: 14938
[19:02:26.808399] Test:  [30/57]  eta: 0:00:05  loss: 0.7564 (0.8316)  time: 0.1821  data: 0.0001  max mem: 14938
[19:02:28.636416] Test:  [40/57]  eta: 0:00:03  loss: 0.7447 (0.8112)  time: 0.1825  data: 0.0001  max mem: 14938
[19:02:30.470610] Test:  [50/57]  eta: 0:00:01  loss: 0.7461 (0.8044)  time: 0.1830  data: 0.0001  max mem: 14938
[19:02:31.459328] Test:  [56/57]  eta: 0:00:00  loss: 0.7582 (0.8098)  time: 0.1777  data: 0.0001  max mem: 14938
[19:02:31.520649] Test: Total time: 0:00:10 (0.1841 s / it)
[19:02:33.275064] Dice score of the network on the train images: 0.839313, val images: 0.817983
[19:02:33.276635] Training time 4:49:42
[19:02:35.151868] Load pre-trained checkpoint from: /root/seg_framework/MS-Mamba/output_dir/mslesseg/checkpoints_0/checkpoint-best_dice_model_0.pth
[19:02:35.173315] <All keys matched successfully>
[19:02:35.750778] Test:  [  0/246]  eta: 0:02:04    time: 0.5074  data: 0.1727  max mem: 14938
[19:02:38.431943] Test:  [ 10/246]  eta: 0:01:08    time: 0.2898  data: 0.0158  max mem: 14938
[19:02:44.620301] ---------------------------------
[19:02:44.620525] Patient 1:
[19:02:44.620612]       precision: 0.41994884610176086
[19:02:44.620682]       recall: 0.5404871702194214
[19:02:44.620742]       dice_score: 0.4726540148258209
[19:02:44.623945] Test:  [ 20/246]  eta: 0:01:40    time: 0.4436  data: 0.0001  max mem: 14938
[19:02:47.299642] Test:  [ 30/246]  eta: 0:01:23    time: 0.4433  data: 0.0001  max mem: 14938
[19:02:53.443822] ---------------------------------
[19:02:53.444049] Patient 2:
[19:02:53.444128]       precision: 0.5456310510635376
[19:02:53.444193]       recall: 0.5673902034759521
[19:02:53.444266]       dice_score: 0.5562979578971863
[19:02:53.444803] Test:  [ 40/246]  eta: 0:01:31    time: 0.4410  data: 0.0001  max mem: 14938
[19:02:56.122876] Test:  [ 50/246]  eta: 0:01:20    time: 0.4411  data: 0.0001  max mem: 14938
[19:02:58.982436] Test:  [ 60/246]  eta: 0:01:12    time: 0.2768  data: 0.0001  max mem: 14938
[19:03:02.556129] ---------------------------------
[19:03:02.556358] Patient 3:
[19:03:02.556440]       precision: 0.3779424726963043
[19:03:02.556505]       recall: 0.47558969259262085
[19:03:02.556564]       dice_score: 0.42118045687675476
[19:03:04.952979] Test:  [ 70/246]  eta: 0:01:13    time: 0.4415  data: 0.0001  max mem: 14938
[19:03:07.813538] Test:  [ 80/246]  eta: 0:01:06    time: 0.4415  data: 0.0001  max mem: 14938
[19:03:11.379491] ---------------------------------
[19:03:11.379714] Patient 4:
[19:03:11.379798]       precision: 0.5801365971565247
[19:03:11.379863]       recall: 0.5572943091392517
[19:03:11.379927]       dice_score: 0.5684860944747925
[19:03:13.770063] Test:  [ 90/246]  eta: 0:01:06    time: 0.4408  data: 0.0001  max mem: 14938
[19:03:16.629302] Test:  [100/246]  eta: 0:00:59    time: 0.4407  data: 0.0001  max mem: 14938
[19:03:20.518749] ---------------------------------
[19:03:20.518979] Patient 5:
[19:03:20.519059]       precision: 0.3907129466533661
[19:03:20.519123]       recall: 0.45693910121917725
[19:03:20.519183]       dice_score: 0.4212389290332794
[19:03:22.624868] Test:  [110/246]  eta: 0:00:58    time: 0.4427  data: 0.0001  max mem: 14938
[19:03:25.485468] Test:  [120/246]  eta: 0:00:52    time: 0.4428  data: 0.0001  max mem: 14938
[19:03:29.331706] ---------------------------------
[19:03:29.331929] Patient 6:
[19:03:29.332010]       precision: 0.3641069829463959
[19:03:29.332075]       recall: 0.46297311782836914
[19:03:29.332133]       dice_score: 0.4076310098171234
[19:03:31.439852] Test:  [130/246]  eta: 0:00:49    time: 0.4407  data: 0.0001  max mem: 14938
[19:03:34.301482] Test:  [140/246]  eta: 0:00:44    time: 0.4408  data: 0.0001  max mem: 14938
[19:03:38.465381] ---------------------------------
[19:03:38.465608] Patient 7:
[19:03:38.465687]       precision: 0.8056764602661133
[19:03:38.465751]       recall: 0.7708182334899902
[19:03:38.465813]       dice_score: 0.7878619432449341
[19:03:40.286219] Test:  [150/246]  eta: 0:00:41    time: 0.4423  data: 0.0001  max mem: 14938
[19:03:43.145822] Test:  [160/246]  eta: 0:00:36    time: 0.4422  data: 0.0001  max mem: 14938
[19:03:47.308944] ---------------------------------
[19:03:47.309173] Patient 8:
[19:03:47.309275]       precision: 0.8806987404823303
[19:03:47.309363]       recall: 0.6106625199317932
[19:03:47.309440]       dice_score: 0.7212333083152771
[19:03:49.130673] Test:  [170/246]  eta: 0:00:32    time: 0.4422  data: 0.0001  max mem: 14938
[19:03:51.990622] Test:  [180/246]  eta: 0:00:27    time: 0.4422  data: 0.0001  max mem: 14938
[19:03:56.154643] ---------------------------------
[19:03:56.154864] Patient 9:
[19:03:56.154943]       precision: 0.7181993722915649
[19:03:56.155003]       recall: 0.8117297291755676
[19:03:56.155060]       dice_score: 0.7621056437492371
[19:03:57.989297] Test:  [190/246]  eta: 0:00:24    time: 0.4417  data: 0.0001  max mem: 14938
[19:04:00.843399] Test:  [200/246]  eta: 0:00:19    time: 0.4414  data: 0.0001  max mem: 14938
[19:04:05.296404] ---------------------------------
[19:04:05.296625] Patient 10:
[19:04:05.296708]       precision: 0.729124128818512
[19:04:05.296771]       recall: 0.8020763993263245
[19:04:05.296832]       dice_score: 0.7638623714447021
[19:04:06.843193] Test:  [210/246]  eta: 0:00:15    time: 0.4426  data: 0.0001  max mem: 14938
[19:04:09.696457] Test:  [220/246]  eta: 0:00:11    time: 0.4426  data: 0.0001  max mem: 14938
[19:04:14.153804] ---------------------------------
[19:04:14.154031] Patient 11:
[19:04:14.154113]       precision: 0.8742231726646423
[19:04:14.154180]       recall: 0.7628266215324402
[19:04:14.154260]       dice_score: 0.8147348165512085
[19:04:15.693470] Test:  [230/246]  eta: 0:00:06    time: 0.4425  data: 0.0001  max mem: 14938
[19:04:18.549108] Test:  [240/246]  eta: 0:00:02    time: 0.4426  data: 0.0001  max mem: 14938
[19:04:23.067488] ---------------------------------
[19:04:23.067713] Patient 12:
[19:04:23.067792]       precision: 0.6369450688362122
[19:04:23.067856]       recall: 0.7633002996444702
[19:04:23.067916]       dice_score: 0.694421648979187
[19:04:23.068333] Test:  [245/246]  eta: 0:00:00    time: 0.4401  data: 0.0001  max mem: 14938
[19:04:23.134887] Test: Total time: 0:01:47 (0.4386 s / it)
[19:04:23.135013] ================================
[19:04:23.135073] Averaged over all patients:
[19:04:23.135297]       precision: 0.6103 ± 0.1852
[19:04:23.135437]       recall: 0.6318 ± 0.1345
[19:04:23.135561]       dice_score: 0.6160 ± 0.1514
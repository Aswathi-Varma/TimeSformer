Not using distributed mode
[20:22:16.283173] job dir: /root/seg_framework/MS-Mamba/run_scripts
[20:22:16.283321] Namespace(accum_iter=1,
model='SegFormer3D',
in_channels=1,
lr=None,
blr=0.001,
min_lr=0,
dist_on_itp=False,
warmup_epochs=20,
device='cuda:0',
seed=42,
layer_decay=0.75,
clip_grad=None,
num_workers=8,
pin_mem=True,
resume='',
mask_mode='concatenate to image',
world_size=1,
embed_dim=1,
local_rank=-1,
dist_url='env://',
nb_classes=2,
data_dir='/root/MSLesSeg24/data',
datalist=None,
preprocess=False,
dim=2,
distributed=False)
[20:22:16.284266] Starting for fold 0
[20:22:16.474919] Elements in data_dir_paths: 11052
[20:22:16.510084] Elements in data_dir_paths: 1803
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[20:22:18.501279] number of params: 59620439
[20:22:18.501484] model: Vivim2D(
  (encoder): mamba_block(
    (downsample_layers): SegformerEncoder(
      (patch_embeddings): ModuleList(
        (0): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (1): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (2): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (3): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (block): ModuleList(
        (0): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): Identity()
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.003703703870996833)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.007407407741993666)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.011111111380159855)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.014814815483987331)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.018518518656492233)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.02222222276031971)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (2): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.025925926864147186)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.029629630967974663)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03333333507180214)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03703703731298447)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04074074327945709)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04444444552063942)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.048148151487112045)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.051851850003004074)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0555555559694767)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.05925925821065903)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06296296417713165)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06666667014360428)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07037036865949631)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07407407462596893)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07777778059244156)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08148147910833359)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08518518507480621)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08888889104127884)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (3): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.09259259700775146)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0962962955236435)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.10000000149011612)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (layer_norm): ModuleList(
        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=64, out_features=256, bias=False)
              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (act): SiLU()
              (x_proj): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_b): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_b): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_b): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_s): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_s): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_s): Linear(in_features=4, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=64, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=256, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=64, out_features=256, bias=False)
              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (act): SiLU()
              (x_proj): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_b): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_b): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_b): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_s): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_s): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_s): Linear(in_features=4, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=64, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=256, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (1): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=128, out_features=512, bias=False)
              (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (act): SiLU()
              (x_proj): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_b): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_b): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_b): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_s): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_s): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_s): Linear(in_features=8, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=128, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=128, out_features=512, bias=False)
              (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (act): SiLU()
              (x_proj): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_b): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_b): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_b): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_s): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_s): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_s): Linear(in_features=8, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=128, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (2): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=320, out_features=1280, bias=False)
              (conv1d): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (act): SiLU()
              (x_proj): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_b): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_b): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_b): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_s): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_s): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_s): Linear(in_features=20, out_features=640, bias=True)
              (out_proj): Linear(in_features=640, out_features=320, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(1280, 1280, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=320, out_features=1280, bias=False)
              (conv1d): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (act): SiLU()
              (x_proj): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_b): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_b): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_b): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_s): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_s): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_s): Linear(in_features=20, out_features=640, bias=True)
              (out_proj): Linear(in_features=640, out_features=320, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(1280, 1280, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (3): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=512, out_features=2048, bias=False)
              (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (act): SiLU()
              (x_proj): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_b): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_b): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_b): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_s): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_s): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_s): Linear(in_features=32, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=512, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=512, out_features=2048, bias=False)
              (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (act): SiLU()
              (x_proj): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_b): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_b): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_b): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_s): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_s): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_s): Linear(in_features=32, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=512, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
  )
  (decoder): SegformerDecodeHead(
    (linear_c): ModuleList(
      (0): SegformerMLP(
        (proj): Linear(in_features=64, out_features=768, bias=True)
      )
      (1): SegformerMLP(
        (proj): Linear(in_features=128, out_features=768, bias=True)
      )
      (2): SegformerMLP(
        (proj): Linear(in_features=320, out_features=768, bias=True)
      )
      (3): SegformerMLP(
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
    )
    (linear_fuse): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (batch_norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): ReLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Conv2d(768, 150, kernel_size=(1, 1), stride=(1, 1))
  )
  (out): Conv2d(768, 1, kernel_size=(1, 1), stride=(1, 1))
)
[20:22:18.504440] base lr: 1.00e-03
[20:22:18.504497] actual lr: 1.25e-04
[20:22:18.504545] accumulate grad iterations: 1
[20:22:18.504591] effective batch size: 32
[20:22:18.506016] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.000125
    maximize: False
    weight_decay: 0.01
)
[20:22:18.508128] Start training for 50 epochs
[20:22:18.508220] Number of samples in train dataloader:  345
[20:22:18.510023] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
[20:22:28.471525] Epoch: [0]  [  0/345]  eta: 0:57:16  lr: 0.000000  loss: 1.7518 (1.7518)  time: 9.9605  data: 0.3818  max mem: 15821
[20:22:40.228189] Epoch: [0]  [ 20/345]  eta: 0:05:36  lr: 0.000000  loss: 1.7502 (1.7532)  time: 0.5878  data: 0.0001  max mem: 15821
[20:22:52.069995] Epoch: [0]  [ 40/345]  eta: 0:04:09  lr: 0.000001  loss: 1.7377 (1.7456)  time: 0.5920  data: 0.0001  max mem: 15821
[20:23:04.106965] Epoch: [0]  [ 60/345]  eta: 0:03:33  lr: 0.000001  loss: 1.7284 (1.7411)  time: 0.6018  data: 0.0001  max mem: 15821
[20:23:16.059986] Epoch: [0]  [ 80/345]  eta: 0:03:08  lr: 0.000001  loss: 1.7253 (1.7373)  time: 0.5976  data: 0.0001  max mem: 15821
[20:23:28.058583] Epoch: [0]  [100/345]  eta: 0:02:48  lr: 0.000002  loss: 1.7049 (1.7310)  time: 0.5999  data: 0.0001  max mem: 15821
[20:23:40.082499] Epoch: [0]  [120/345]  eta: 0:02:31  lr: 0.000002  loss: 1.6913 (1.7239)  time: 0.6011  data: 0.0001  max mem: 15821
[20:23:52.137544] Epoch: [0]  [140/345]  eta: 0:02:16  lr: 0.000003  loss: 1.6627 (1.7156)  time: 0.6027  data: 0.0001  max mem: 15821

[20:24:04.197425] Epoch: [0]  [160/345]  eta: 0:02:01  lr: 0.000003  loss: 1.6343 (1.7056)  time: 0.6029  data: 0.0001  max mem: 15821
[20:24:16.269981] Epoch: [0]  [180/345]  eta: 0:01:47  lr: 0.000003  loss: 1.6012 (1.6939)  time: 0.6036  data: 0.0001  max mem: 15821
[20:24:28.369292] Epoch: [0]  [200/345]  eta: 0:01:33  lr: 0.000004  loss: 1.5487 (1.6798)  time: 0.6049  data: 0.0001  max mem: 15821
[20:24:40.469973] Epoch: [0]  [220/345]  eta: 0:01:20  lr: 0.000004  loss: 1.4950 (1.6632)  time: 0.6050  data: 0.0001  max mem: 15821
[20:24:52.573680] Epoch: [0]  [240/345]  eta: 0:01:07  lr: 0.000004  loss: 1.4280 (1.6439)  time: 0.6051  data: 0.0001  max mem: 15821
[20:25:04.657708] Epoch: [0]  [260/345]  eta: 0:00:54  lr: 0.000005  loss: 1.3488 (1.6216)  time: 0.6042  data: 0.0001  max mem: 15821
[20:25:16.746533] Epoch: [0]  [280/345]  eta: 0:00:41  lr: 0.000005  loss: 1.2882 (1.5976)  time: 0.6044  data: 0.0001  max mem: 15821
[20:25:28.922960] Epoch: [0]  [300/345]  eta: 0:00:28  lr: 0.000005  loss: 1.2316 (1.5734)  time: 0.6088  data: 0.0001  max mem: 15821
[20:25:41.011999] Epoch: [0]  [320/345]  eta: 0:00:15  lr: 0.000006  loss: 1.1881 (1.5497)  time: 0.6044  data: 0.0001  max mem: 15821
[20:25:53.084397] Epoch: [0]  [340/345]  eta: 0:00:03  lr: 0.000006  loss: 1.1579 (1.5267)  time: 0.6036  data: 0.0001  max mem: 15821
[20:25:55.499794] Epoch: [0]  [344/345]  eta: 0:00:00  lr: 0.000006  loss: 1.1537 (1.5223)  time: 0.6036  data: 0.0001  max mem: 15821
[20:25:55.559529] Epoch: [0] Total time: 0:03:37 (0.6291 s / it)
[20:25:55.560187] Averaged stats: lr: 0.000006  loss: 1.1537 (1.5223)
[20:25:56.120556] Test:  [  0/345]  eta: 0:03:11  loss: 1.1504 (1.1504)  time: 0.5553  data: 0.3897  max mem: 15821
[20:25:57.789264] Test:  [ 10/345]  eta: 0:01:07  loss: 1.1521 (1.1518)  time: 0.2021  data: 0.0355  max mem: 15821
[20:25:59.460823] Test:  [ 20/345]  eta: 0:01:00  loss: 1.1521 (1.1524)  time: 0.1669  data: 0.0001  max mem: 15821
[20:26:01.134709] Test:  [ 30/345]  eta: 0:00:56  loss: 1.1521 (1.1526)  time: 0.1672  data: 0.0001  max mem: 15821
[20:26:02.811903] Test:  [ 40/345]  eta: 0:00:53  loss: 1.1539 (1.1528)  time: 0.1675  data: 0.0001  max mem: 15821
[20:26:04.492856] Test:  [ 50/345]  eta: 0:00:51  loss: 1.1539 (1.1529)  time: 0.1678  data: 0.0001  max mem: 15821
[20:26:06.178052] Test:  [ 60/345]  eta: 0:00:49  loss: 1.1543 (1.1532)  time: 0.1682  data: 0.0001  max mem: 15821
[20:26:07.867050] Test:  [ 70/345]  eta: 0:00:47  loss: 1.1540 (1.1532)  time: 0.1686  data: 0.0001  max mem: 15821
[20:26:09.559680] Test:  [ 80/345]  eta: 0:00:45  loss: 1.1523 (1.1531)  time: 0.1690  data: 0.0001  max mem: 15821
[20:26:11.256104] Test:  [ 90/345]  eta: 0:00:43  loss: 1.1511 (1.1532)  time: 0.1694  data: 0.0001  max mem: 15821
[20:26:12.956675] Test:  [100/345]  eta: 0:00:42  loss: 1.1535 (1.1533)  time: 0.1698  data: 0.0001  max mem: 15821
[20:26:14.661030] Test:  [110/345]  eta: 0:00:40  loss: 1.1545 (1.1534)  time: 0.1702  data: 0.0001  max mem: 15821
[20:26:16.367982] Test:  [120/345]  eta: 0:00:38  loss: 1.1549 (1.1536)  time: 0.1705  data: 0.0001  max mem: 15821
[20:26:18.076705] Test:  [130/345]  eta: 0:00:36  loss: 1.1546 (1.1535)  time: 0.1707  data: 0.0001  max mem: 15821
[20:26:19.790714] Test:  [140/345]  eta: 0:00:35  loss: 1.1540 (1.1536)  time: 0.1711  data: 0.0001  max mem: 15821
[20:26:21.507615] Test:  [150/345]  eta: 0:00:33  loss: 1.1541 (1.1536)  time: 0.1715  data: 0.0001  max mem: 15821
[20:26:23.228192] Test:  [160/345]  eta: 0:00:31  loss: 1.1537 (1.1535)  time: 0.1718  data: 0.0001  max mem: 15821
[20:26:24.951312] Test:  [170/345]  eta: 0:00:30  loss: 1.1537 (1.1536)  time: 0.1721  data: 0.0001  max mem: 15821
[20:26:26.678229] Test:  [180/345]  eta: 0:00:28  loss: 1.1541 (1.1536)  time: 0.1724  data: 0.0001  max mem: 15821
[20:26:28.408254] Test:  [190/345]  eta: 0:00:26  loss: 1.1521 (1.1535)  time: 0.1728  data: 0.0001  max mem: 15821
[20:26:30.142855] Test:  [200/345]  eta: 0:00:24  loss: 1.1523 (1.1535)  time: 0.1732  data: 0.0001  max mem: 15821
[20:26:32.272000] Test:  [210/345]  eta: 0:00:23  loss: 1.1520 (1.1533)  time: 0.1931  data: 0.0001  max mem: 15821
[20:26:34.025362] Test:  [220/345]  eta: 0:00:21  loss: 1.1515 (1.1533)  time: 0.1941  data: 0.0001  max mem: 15821
[20:26:35.903823] Test:  [230/345]  eta: 0:00:20  loss: 1.1535 (1.1534)  time: 0.1815  data: 0.0001  max mem: 15821
[20:26:37.654365] Test:  [240/345]  eta: 0:00:18  loss: 1.1533 (1.1533)  time: 0.1814  data: 0.0001  max mem: 15821
[20:26:39.640410] Test:  [250/345]  eta: 0:00:16  loss: 1.1535 (1.1533)  time: 0.1868  data: 0.0001  max mem: 15821
[20:26:41.633901] Test:  [260/345]  eta: 0:00:14  loss: 1.1535 (1.1533)  time: 0.1989  data: 0.0001  max mem: 15821
[20:26:43.543895] Test:  [270/345]  eta: 0:00:13  loss: 1.1524 (1.1532)  time: 0.1951  data: 0.0001  max mem: 15821
[20:26:45.332160] Test:  [280/345]  eta: 0:00:11  loss: 1.1526 (1.1532)  time: 0.1849  data: 0.0001  max mem: 15821
[20:26:47.283300] Test:  [290/345]  eta: 0:00:09  loss: 1.1536 (1.1532)  time: 0.1869  data: 0.0001  max mem: 15821
[20:26:49.301205] Test:  [300/345]  eta: 0:00:08  loss: 1.1540 (1.1532)  time: 0.1984  data: 0.0001  max mem: 15821
[20:26:51.296747] Test:  [310/345]  eta: 0:00:06  loss: 1.1545 (1.1533)  time: 0.2006  data: 0.0001  max mem: 15821
[20:26:53.312648] Test:  [320/345]  eta: 0:00:04  loss: 1.1549 (1.1533)  time: 0.2005  data: 0.0001  max mem: 15821
[20:26:55.323072] Test:  [330/345]  eta: 0:00:02  loss: 1.1558 (1.1534)  time: 0.2012  data: 0.0001  max mem: 15821
[20:26:57.127564] Test:  [340/345]  eta: 0:00:00  loss: 1.1549 (1.1534)  time: 0.1907  data: 0.0001  max mem: 15821
[20:26:58.162239] Test:  [344/345]  eta: 0:00:00  loss: 1.1541 (1.1534)  time: 0.2059  data: 0.0001  max mem: 15821
[20:26:58.231334] Test: Total time: 0:01:02 (0.1816 s / it)
[20:27:09.045442] Test:  [ 0/57]  eta: 0:00:34  loss: 1.1627 (1.1627)  time: 0.6043  data: 0.4412  max mem: 15821
[20:27:10.693291] Test:  [10/57]  eta: 0:00:09  loss: 1.1617 (1.1604)  time: 0.2047  data: 0.0402  max mem: 15821
[20:27:12.346013] Test:  [20/57]  eta: 0:00:06  loss: 1.1600 (1.1576)  time: 0.1649  data: 0.0001  max mem: 15821
[20:27:14.002655] Test:  [30/57]  eta: 0:00:04  loss: 1.1469 (1.1485)  time: 0.1654  data: 0.0001  max mem: 15821
[20:27:15.662055] Test:  [40/57]  eta: 0:00:02  loss: 1.1314 (1.1435)  time: 0.1657  data: 0.0001  max mem: 15821
[20:27:17.325741] Test:  [50/57]  eta: 0:00:01  loss: 1.1404 (1.1420)  time: 0.1661  data: 0.0001  max mem: 15821
[20:27:18.999927] Test:  [56/57]  eta: 0:00:00  loss: 1.1408 (1.1425)  time: 0.2001  data: 0.0000  max mem: 15821
[20:27:19.077368] Test: Total time: 0:00:10 (0.1866 s / it)
[20:27:20.990196] Dice score of the network on the train images: 0.000000, val images: 0.000000
[20:27:20.990426] saving best_dice_model_0 @ epoch 0
[20:27:21.740168] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:27:22.750594] Epoch: [1]  [  0/345]  eta: 0:05:48  lr: 0.000006  loss: 1.1359 (1.1359)  time: 1.0092  data: 0.4108  max mem: 15821
[20:27:34.736133] Epoch: [1]  [ 20/345]  eta: 0:03:21  lr: 0.000007  loss: 1.1267 (1.1249)  time: 0.5992  data: 0.0001  max mem: 15821
[20:27:46.739573] Epoch: [1]  [ 40/345]  eta: 0:03:05  lr: 0.000007  loss: 1.1024 (1.1150)  time: 0.6001  data: 0.0001  max mem: 15821
[20:27:58.777090] Epoch: [1]  [ 60/345]  eta: 0:02:53  lr: 0.000007  loss: 1.0866 (1.1060)  time: 0.6018  data: 0.0001  max mem: 15821
[20:28:10.846559] Epoch: [1]  [ 80/345]  eta: 0:02:40  lr: 0.000008  loss: 1.0743 (1.0982)  time: 0.6034  data: 0.0001  max mem: 15821
[20:28:22.928119] Epoch: [1]  [100/345]  eta: 0:02:28  lr: 0.000008  loss: 1.0626 (1.0914)  time: 0.6040  data: 0.0001  max mem: 15821
[20:28:35.028960] Epoch: [1]  [120/345]  eta: 0:02:16  lr: 0.000008  loss: 1.0519 (1.0853)  time: 0.6050  data: 0.0001  max mem: 15821
[20:28:47.125954] Epoch: [1]  [140/345]  eta: 0:02:04  lr: 0.000009  loss: 1.0426 (1.0795)  time: 0.6048  data: 0.0001  max mem: 15821
[20:28:59.216735] Epoch: [1]  [160/345]  eta: 0:01:51  lr: 0.000009  loss: 1.0274 (1.0730)  time: 0.6045  data: 0.0001  max mem: 15821
[20:29:11.324428] Epoch: [1]  [180/345]  eta: 0:01:39  lr: 0.000010  loss: 1.0195 (1.0670)  time: 0.6053  data: 0.0001  max mem: 15821
[20:29:23.424140] Epoch: [1]  [200/345]  eta: 0:01:27  lr: 0.000010  loss: 1.0062 (1.0607)  time: 0.6049  data: 0.0001  max mem: 15821
[20:29:35.501545] Epoch: [1]  [220/345]  eta: 0:01:15  lr: 0.000010  loss: 0.9938 (1.0546)  time: 0.6038  data: 0.0001  max mem: 15821
[20:29:47.588362] Epoch: [1]  [240/345]  eta: 0:01:03  lr: 0.000011  loss: 0.9853 (1.0488)  time: 0.6043  data: 0.0001  max mem: 15821
[20:29:59.667618] Epoch: [1]  [260/345]  eta: 0:00:51  lr: 0.000011  loss: 0.9742 (1.0431)  time: 0.6039  data: 0.0001  max mem: 15821
[20:30:11.742293] Epoch: [1]  [280/345]  eta: 0:00:39  lr: 0.000011  loss: 0.9593 (1.0373)  time: 0.6037  data: 0.0001  max mem: 15821
[20:30:23.815530] Epoch: [1]  [300/345]  eta: 0:00:27  lr: 0.000012  loss: 0.9710 (1.0326)  time: 0.6036  data: 0.0001  max mem: 15821
[20:30:35.863443] Epoch: [1]  [320/345]  eta: 0:00:15  lr: 0.000012  loss: 0.9488 (1.0275)  time: 0.6023  data: 0.0001  max mem: 15821
[20:30:47.923612] Epoch: [1]  [340/345]  eta: 0:00:03  lr: 0.000012  loss: 0.9451 (1.0226)  time: 0.6030  data: 0.0001  max mem: 15821
[20:30:50.339431] Epoch: [1]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 0.9414 (1.0217)  time: 0.6033  data: 0.0001  max mem: 15821
[20:30:50.417957] Epoch: [1] Total time: 0:03:28 (0.6049 s / it)
[20:30:50.418556] Averaged stats: lr: 0.000012  loss: 0.9414 (1.0217)
[20:30:51.045271] Test:  [  0/345]  eta: 0:03:33  loss: 0.9981 (0.9981)  time: 0.6177  data: 0.4537  max mem: 15821
[20:30:52.711874] Test:  [ 10/345]  eta: 0:01:09  loss: 0.9402 (0.9365)  time: 0.2076  data: 0.0413  max mem: 15821
[20:30:54.380244] Test:  [ 20/345]  eta: 0:01:01  loss: 0.9364 (0.9380)  time: 0.1667  data: 0.0001  max mem: 15821
[20:30:56.053718] Test:  [ 30/345]  eta: 0:00:57  loss: 0.9358 (0.9374)  time: 0.1670  data: 0.0001  max mem: 15821
[20:30:57.729515] Test:  [ 40/345]  eta: 0:00:54  loss: 0.9333 (0.9365)  time: 0.1674  data: 0.0001  max mem: 15821
[20:30:59.408978] Test:  [ 50/345]  eta: 0:00:51  loss: 0.9333 (0.9351)  time: 0.1677  data: 0.0001  max mem: 15821
[20:31:01.092456] Test:  [ 60/345]  eta: 0:00:49  loss: 0.9314 (0.9355)  time: 0.1681  data: 0.0001  max mem: 15821
[20:31:02.778419] Test:  [ 70/345]  eta: 0:00:47  loss: 0.9273 (0.9338)  time: 0.1684  data: 0.0001  max mem: 15821
[20:31:04.469486] Test:  [ 80/345]  eta: 0:00:45  loss: 0.9145 (0.9324)  time: 0.1688  data: 0.0001  max mem: 15821
[20:31:06.163102] Test:  [ 90/345]  eta: 0:00:44  loss: 0.9163 (0.9317)  time: 0.1692  data: 0.0001  max mem: 15821
[20:31:07.860360] Test:  [100/345]  eta: 0:00:42  loss: 0.9348 (0.9321)  time: 0.1695  data: 0.0001  max mem: 15821
[20:31:09.561197] Test:  [110/345]  eta: 0:00:40  loss: 0.9353 (0.9328)  time: 0.1698  data: 0.0001  max mem: 15821
[20:31:11.265964] Test:  [120/345]  eta: 0:00:38  loss: 0.9377 (0.9334)  time: 0.1702  data: 0.0001  max mem: 15821
[20:31:12.972778] Test:  [130/345]  eta: 0:00:36  loss: 0.9308 (0.9327)  time: 0.1705  data: 0.0001  max mem: 15821
[20:31:14.684476] Test:  [140/345]  eta: 0:00:35  loss: 0.9333 (0.9326)  time: 0.1709  data: 0.0001  max mem: 15821
[20:31:16.399025] Test:  [150/345]  eta: 0:00:33  loss: 0.9320 (0.9324)  time: 0.1712  data: 0.0001  max mem: 15821
[20:31:18.116492] Test:  [160/345]  eta: 0:00:31  loss: 0.9357 (0.9331)  time: 0.1715  data: 0.0001  max mem: 15821
[20:31:19.837075] Test:  [170/345]  eta: 0:00:30  loss: 0.9456 (0.9336)  time: 0.1718  data: 0.0001  max mem: 15821
[20:31:21.560966] Test:  [180/345]  eta: 0:00:28  loss: 0.9403 (0.9331)  time: 0.1722  data: 0.0001  max mem: 15821
[20:31:23.288428] Test:  [190/345]  eta: 0:00:26  loss: 0.9207 (0.9322)  time: 0.1725  data: 0.0001  max mem: 15821
[20:31:25.018985] Test:  [200/345]  eta: 0:00:24  loss: 0.9206 (0.9317)  time: 0.1728  data: 0.0001  max mem: 15821

[20:31:26.754097] Test:  [210/345]  eta: 0:00:23  loss: 0.9217 (0.9318)  time: 0.1732  data: 0.0001  max mem: 15821
[20:31:28.854813] Test:  [220/345]  eta: 0:00:21  loss: 0.9352 (0.9317)  time: 0.1917  data: 0.0001  max mem: 15821
[20:31:30.594626] Test:  [230/345]  eta: 0:00:19  loss: 0.9316 (0.9318)  time: 0.1920  data: 0.0001  max mem: 15821
[20:31:32.502879] Test:  [240/345]  eta: 0:00:18  loss: 0.9275 (0.9317)  time: 0.1823  data: 0.0001  max mem: 15821
[20:31:34.268538] Test:  [250/345]  eta: 0:00:16  loss: 0.9141 (0.9313)  time: 0.1836  data: 0.0001  max mem: 15821
[20:31:36.224457] Test:  [260/345]  eta: 0:00:14  loss: 0.9186 (0.9314)  time: 0.1860  data: 0.0001  max mem: 15821
[20:31:38.004542] Test:  [270/345]  eta: 0:00:13  loss: 0.9435 (0.9318)  time: 0.1867  data: 0.0001  max mem: 15821
[20:31:39.902737] Test:  [280/345]  eta: 0:00:11  loss: 0.9313 (0.9314)  time: 0.1838  data: 0.0001  max mem: 15821
[20:31:41.691299] Test:  [290/345]  eta: 0:00:09  loss: 0.9178 (0.9310)  time: 0.1843  data: 0.0001  max mem: 15821
[20:31:43.632531] Test:  [300/345]  eta: 0:00:07  loss: 0.9178 (0.9308)  time: 0.1864  data: 0.0001  max mem: 15821
[20:31:45.419360] Test:  [310/345]  eta: 0:00:06  loss: 0.9261 (0.9309)  time: 0.1863  data: 0.0001  max mem: 15821
[20:31:47.450960] Test:  [320/345]  eta: 0:00:04  loss: 0.9261 (0.9308)  time: 0.1909  data: 0.0001  max mem: 15821
[20:31:49.229574] Test:  [330/345]  eta: 0:00:02  loss: 0.9300 (0.9309)  time: 0.1905  data: 0.0001  max mem: 15821
[20:31:51.119794] Test:  [340/345]  eta: 0:00:00  loss: 0.9330 (0.9311)  time: 0.1834  data: 0.0001  max mem: 15821
[20:31:51.831852] Test:  [344/345]  eta: 0:00:00  loss: 0.9326 (0.9311)  time: 0.1833  data: 0.0001  max mem: 15821
[20:31:51.918833] Test: Total time: 0:01:01 (0.1782 s / it)
[20:32:02.539258] Test:  [ 0/57]  eta: 0:00:29  loss: 0.9880 (0.9880)  time: 0.5229  data: 0.3603  max mem: 15821
[20:32:04.187269] Test:  [10/57]  eta: 0:00:09  loss: 0.9632 (0.9725)  time: 0.1972  data: 0.0329  max mem: 15821
[20:32:05.839137] Test:  [20/57]  eta: 0:00:06  loss: 0.9621 (0.9632)  time: 0.1649  data: 0.0001  max mem: 15821
[20:32:07.494628] Test:  [30/57]  eta: 0:00:04  loss: 0.8642 (0.9067)  time: 0.1653  data: 0.0001  max mem: 15821
[20:32:09.154456] Test:  [40/57]  eta: 0:00:02  loss: 0.7999 (0.8759)  time: 0.1657  data: 0.0001  max mem: 15821
[20:32:10.816980] Test:  [50/57]  eta: 0:00:01  loss: 0.8314 (0.8693)  time: 0.1661  data: 0.0001  max mem: 15821
[20:32:11.715053] Test:  [56/57]  eta: 0:00:00  loss: 0.9002 (0.8789)  time: 0.1612  data: 0.0001  max mem: 15821
[20:32:11.788164] Test: Total time: 0:00:09 (0.1715 s / it)
[20:32:13.627132] Dice score of the network on the train images: 0.429626, val images: 0.546515
[20:32:13.627373] saving best_prec_model_0 @ epoch 1
[20:32:14.380676] saving best_rec_model_0 @ epoch 1
[20:32:15.085482] saving best_dice_model_0 @ epoch 1
[20:32:16.156671] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:32:17.152748] Epoch: [2]  [  0/345]  eta: 0:05:43  lr: 0.000013  loss: 0.9757 (0.9757)  time: 0.9948  data: 0.3965  max mem: 15821
[20:32:29.106338] Epoch: [2]  [ 20/345]  eta: 0:03:20  lr: 0.000013  loss: 0.9229 (0.9305)  time: 0.5976  data: 0.0001  max mem: 15821
[20:32:41.102704] Epoch: [2]  [ 40/345]  eta: 0:03:05  lr: 0.000013  loss: 0.9205 (0.9267)  time: 0.5998  data: 0.0001  max mem: 15821
[20:32:53.135092] Epoch: [2]  [ 60/345]  eta: 0:02:52  lr: 0.000014  loss: 0.9147 (0.9222)  time: 0.6016  data: 0.0001  max mem: 15821
[20:33:05.185124] Epoch: [2]  [ 80/345]  eta: 0:02:40  lr: 0.000014  loss: 0.9157 (0.9201)  time: 0.6025  data: 0.0001  max mem: 15821
[20:33:17.267914] Epoch: [2]  [100/345]  eta: 0:02:28  lr: 0.000014  loss: 0.8983 (0.9159)  time: 0.6041  data: 0.0001  max mem: 15821
[20:33:29.360295] Epoch: [2]  [120/345]  eta: 0:02:16  lr: 0.000015  loss: 0.8753 (0.9098)  time: 0.6046  data: 0.0001  max mem: 15821
[20:33:41.462869] Epoch: [2]  [140/345]  eta: 0:02:04  lr: 0.000015  loss: 0.8771 (0.9044)  time: 0.6051  data: 0.0001  max mem: 15821
[20:33:53.550790] Epoch: [2]  [160/345]  eta: 0:01:51  lr: 0.000015  loss: 0.8575 (0.9002)  time: 0.6044  data: 0.0001  max mem: 15821
[20:34:05.641521] Epoch: [2]  [180/345]  eta: 0:01:39  lr: 0.000016  loss: 0.8618 (0.8960)  time: 0.6045  data: 0.0001  max mem: 15821
[20:34:17.718671] Epoch: [2]  [200/345]  eta: 0:01:27  lr: 0.000016  loss: 0.8582 (0.8920)  time: 0.6038  data: 0.0001  max mem: 15821
[20:34:29.791860] Epoch: [2]  [220/345]  eta: 0:01:15  lr: 0.000016  loss: 0.8383 (0.8871)  time: 0.6036  data: 0.0001  max mem: 15821
[20:34:41.862278] Epoch: [2]  [240/345]  eta: 0:01:03  lr: 0.000017  loss: 0.8305 (0.8825)  time: 0.6035  data: 0.0001  max mem: 15821
[20:34:53.932113] Epoch: [2]  [260/345]  eta: 0:00:51  lr: 0.000017  loss: 0.8283 (0.8788)  time: 0.6035  data: 0.0001  max mem: 15821
[20:35:06.007436] Epoch: [2]  [280/345]  eta: 0:00:39  lr: 0.000018  loss: 0.8149 (0.8747)  time: 0.6037  data: 0.0001  max mem: 15821
[20:35:18.165266] Epoch: [2]  [300/345]  eta: 0:00:27  lr: 0.000018  loss: 0.8076 (0.8703)  time: 0.6078  data: 0.0001  max mem: 15821
[20:35:30.231368] Epoch: [2]  [320/345]  eta: 0:00:15  lr: 0.000018  loss: 0.7942 (0.8660)  time: 0.6033  data: 0.0001  max mem: 15821
[20:35:42.290818] Epoch: [2]  [340/345]  eta: 0:00:03  lr: 0.000019  loss: 0.7802 (0.8610)  time: 0.6029  data: 0.0001  max mem: 15821
[20:35:44.701895] Epoch: [2]  [344/345]  eta: 0:00:00  lr: 0.000019  loss: 0.7794 (0.8601)  time: 0.6027  data: 0.0001  max mem: 15821
[20:35:44.773550] Epoch: [2] Total time: 0:03:28 (0.6047 s / it)
[20:35:44.773877] Averaged stats: lr: 0.000019  loss: 0.7794 (0.8601)
[20:35:45.400077] Test:  [  0/345]  eta: 0:03:34  loss: 0.8981 (0.8981)  time: 0.6209  data: 0.4571  max mem: 15821
[20:35:47.065603] Test:  [ 10/345]  eta: 0:01:09  loss: 0.8291 (0.8171)  time: 0.2078  data: 0.0416  max mem: 15821
[20:35:48.734745] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7832 (0.7919)  time: 0.1667  data: 0.0001  max mem: 15821
[20:35:50.405742] Test:  [ 30/345]  eta: 0:00:57  loss: 0.7613 (0.7893)  time: 0.1669  data: 0.0001  max mem: 15821
[20:35:52.080073] Test:  [ 40/345]  eta: 0:00:54  loss: 0.7817 (0.7890)  time: 0.1672  data: 0.0001  max mem: 15821
[20:35:53.758762] Test:  [ 50/345]  eta: 0:00:51  loss: 0.7850 (0.7875)  time: 0.1676  data: 0.0001  max mem: 15821
[20:35:55.441515] Test:  [ 60/345]  eta: 0:00:49  loss: 0.7641 (0.7825)  time: 0.1680  data: 0.0001  max mem: 15821
[20:35:57.127549] Test:  [ 70/345]  eta: 0:00:47  loss: 0.7641 (0.7840)  time: 0.1684  data: 0.0001  max mem: 15821
[20:35:58.815962] Test:  [ 80/345]  eta: 0:00:45  loss: 0.7782 (0.7846)  time: 0.1687  data: 0.0001  max mem: 15821
[20:36:00.507371] Test:  [ 90/345]  eta: 0:00:44  loss: 0.7757 (0.7833)  time: 0.1689  data: 0.0001  max mem: 15821
[20:36:02.204431] Test:  [100/345]  eta: 0:00:42  loss: 0.7657 (0.7829)  time: 0.1694  data: 0.0001  max mem: 15821
[20:36:03.904200] Test:  [110/345]  eta: 0:00:40  loss: 0.7657 (0.7806)  time: 0.1698  data: 0.0001  max mem: 15821
[20:36:05.606836] Test:  [120/345]  eta: 0:00:38  loss: 0.7644 (0.7802)  time: 0.1701  data: 0.0001  max mem: 15821
[20:36:07.312077] Test:  [130/345]  eta: 0:00:36  loss: 0.7790 (0.7803)  time: 0.1703  data: 0.0001  max mem: 15821
[20:36:09.021005] Test:  [140/345]  eta: 0:00:35  loss: 0.7824 (0.7808)  time: 0.1706  data: 0.0001  max mem: 15821
[20:36:10.733266] Test:  [150/345]  eta: 0:00:33  loss: 0.7692 (0.7803)  time: 0.1710  data: 0.0001  max mem: 15821
[20:36:12.448246] Test:  [160/345]  eta: 0:00:31  loss: 0.7692 (0.7803)  time: 0.1713  data: 0.0001  max mem: 15821
[20:36:14.168678] Test:  [170/345]  eta: 0:00:30  loss: 0.7658 (0.7800)  time: 0.1717  data: 0.0001  max mem: 15821
[20:36:15.890794] Test:  [180/345]  eta: 0:00:28  loss: 0.7778 (0.7799)  time: 0.1721  data: 0.0001  max mem: 15821
[20:36:17.616566] Test:  [190/345]  eta: 0:00:26  loss: 0.7808 (0.7798)  time: 0.1723  data: 0.0001  max mem: 15821
[20:36:19.345634] Test:  [200/345]  eta: 0:00:24  loss: 0.7767 (0.7793)  time: 0.1727  data: 0.0001  max mem: 15821
[20:36:21.078075] Test:  [210/345]  eta: 0:00:23  loss: 0.7700 (0.7784)  time: 0.1730  data: 0.0001  max mem: 15821
[20:36:22.816297] Test:  [220/345]  eta: 0:00:21  loss: 0.7516 (0.7765)  time: 0.1735  data: 0.0001  max mem: 15821
[20:36:24.556495] Test:  [230/345]  eta: 0:00:19  loss: 0.7579 (0.7768)  time: 0.1738  data: 0.0001  max mem: 15821
[20:36:26.301141] Test:  [240/345]  eta: 0:00:18  loss: 0.7847 (0.7764)  time: 0.1742  data: 0.0001  max mem: 15821
[20:36:28.049318] Test:  [250/345]  eta: 0:00:16  loss: 0.7710 (0.7766)  time: 0.1746  data: 0.0001  max mem: 15821
[20:36:29.798598] Test:  [260/345]  eta: 0:00:14  loss: 0.7582 (0.7763)  time: 0.1748  data: 0.0001  max mem: 15821
[20:36:31.552568] Test:  [270/345]  eta: 0:00:12  loss: 0.7577 (0.7758)  time: 0.1751  data: 0.0001  max mem: 15821
[20:36:33.309805] Test:  [280/345]  eta: 0:00:11  loss: 0.7818 (0.7760)  time: 0.1755  data: 0.0001  max mem: 15821
[20:36:35.069732] Test:  [290/345]  eta: 0:00:09  loss: 0.7903 (0.7768)  time: 0.1758  data: 0.0001  max mem: 15821
[20:36:36.832873] Test:  [300/345]  eta: 0:00:07  loss: 0.7885 (0.7767)  time: 0.1761  data: 0.0001  max mem: 15821
[20:36:38.599808] Test:  [310/345]  eta: 0:00:06  loss: 0.7684 (0.7766)  time: 0.1764  data: 0.0001  max mem: 15821
[20:36:40.372874] Test:  [320/345]  eta: 0:00:04  loss: 0.7670 (0.7758)  time: 0.1769  data: 0.0001  max mem: 15821
[20:36:42.148391] Test:  [330/345]  eta: 0:00:02  loss: 0.7589 (0.7761)  time: 0.1774  data: 0.0001  max mem: 15821
[20:36:43.925297] Test:  [340/345]  eta: 0:00:00  loss: 0.7590 (0.7762)  time: 0.1776  data: 0.0001  max mem: 15821
[20:36:44.637608] Test:  [344/345]  eta: 0:00:00  loss: 0.7590 (0.7760)  time: 0.1777  data: 0.0001  max mem: 15821
[20:36:44.711274] Test: Total time: 0:00:59 (0.1737 s / it)
[20:36:55.257925] Test:  [ 0/57]  eta: 0:00:29  loss: 0.8498 (0.8498)  time: 0.5227  data: 0.3602  max mem: 15821
[20:36:56.903800] Test:  [10/57]  eta: 0:00:09  loss: 0.8498 (0.8309)  time: 0.1970  data: 0.0328  max mem: 15821
[20:36:58.554784] Test:  [20/57]  eta: 0:00:06  loss: 0.7807 (0.8186)  time: 0.1648  data: 0.0001  max mem: 15821
[20:37:00.209850] Test:  [30/57]  eta: 0:00:04  loss: 0.6888 (0.7439)  time: 0.1652  data: 0.0001  max mem: 15821
[20:37:01.867762] Test:  [40/57]  eta: 0:00:02  loss: 0.5885 (0.7023)  time: 0.1656  data: 0.0001  max mem: 15821
[20:37:03.531798] Test:  [50/57]  eta: 0:00:01  loss: 0.6113 (0.6943)  time: 0.1660  data: 0.0001  max mem: 15821
[20:37:04.428261] Test:  [56/57]  eta: 0:00:00  loss: 0.7241 (0.7015)  time: 0.1612  data: 0.0000  max mem: 15821
[20:37:04.507078] Test: Total time: 0:00:09 (0.1714 s / it)
[20:37:06.328168] Dice score of the network on the train images: 0.548090, val images: 0.676556
[20:37:06.328411] saving best_prec_model_0 @ epoch 2
[20:37:07.422851] saving best_rec_model_0 @ epoch 2
[20:37:08.443760] saving best_dice_model_0 @ epoch 2
[20:37:09.880876] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:37:10.870179] Epoch: [3]  [  0/345]  eta: 0:05:40  lr: 0.000019  loss: 0.7791 (0.7791)  time: 0.9882  data: 0.3920  max mem: 15821
[20:37:22.792268] Epoch: [3]  [ 20/345]  eta: 0:03:19  lr: 0.000019  loss: 0.7595 (0.7636)  time: 0.5960  data: 0.0001  max mem: 15821
[20:37:34.756592] Epoch: [3]  [ 40/345]  eta: 0:03:05  lr: 0.000019  loss: 0.7570 (0.7635)  time: 0.5982  data: 0.0001  max mem: 15821
[20:37:46.766547] Epoch: [3]  [ 60/345]  eta: 0:02:52  lr: 0.000020  loss: 0.7377 (0.7553)  time: 0.6005  data: 0.0001  max mem: 15821
[20:37:58.818469] Epoch: [3]  [ 80/345]  eta: 0:02:40  lr: 0.000020  loss: 0.7377 (0.7527)  time: 0.6025  data: 0.0001  max mem: 15821
[20:38:10.892134] Epoch: [3]  [100/345]  eta: 0:02:27  lr: 0.000021  loss: 0.7439 (0.7502)  time: 0.6036  data: 0.0001  max mem: 15821
[20:38:22.984003] Epoch: [3]  [120/345]  eta: 0:02:15  lr: 0.000021  loss: 0.7118 (0.7447)  time: 0.6045  data: 0.0001  max mem: 15821
[20:38:35.075130] Epoch: [3]  [140/345]  eta: 0:02:03  lr: 0.000021  loss: 0.6903 (0.7387)  time: 0.6045  data: 0.0001  max mem: 15821
[20:38:47.163915] Epoch: [3]  [160/345]  eta: 0:01:51  lr: 0.000022  loss: 0.6860 (0.7341)  time: 0.6043  data: 0.0001  max mem: 15821
[20:38:59.244879] Epoch: [3]  [180/345]  eta: 0:01:39  lr: 0.000022  loss: 0.6916 (0.7298)  time: 0.6040  data: 0.0001  max mem: 15821

[20:39:11.316392] Epoch: [3]  [200/345]  eta: 0:01:27  lr: 0.000022  loss: 0.6754 (0.7244)  time: 0.6035  data: 0.0001  max mem: 15821
[20:39:23.370272] Epoch: [3]  [220/345]  eta: 0:01:15  lr: 0.000023  loss: 0.6708 (0.7194)  time: 0.6027  data: 0.0001  max mem: 15821
[20:39:35.407511] Epoch: [3]  [240/345]  eta: 0:01:03  lr: 0.000023  loss: 0.6673 (0.7159)  time: 0.6018  data: 0.0001  max mem: 15821
[20:39:47.448404] Epoch: [3]  [260/345]  eta: 0:00:51  lr: 0.000023  loss: 0.6428 (0.7108)  time: 0.6020  data: 0.0001  max mem: 15821
[20:39:59.577251] Epoch: [3]  [280/345]  eta: 0:00:39  lr: 0.000024  loss: 0.6469 (0.7063)  time: 0.6064  data: 0.0001  max mem: 15821
[20:40:11.613537] Epoch: [3]  [300/345]  eta: 0:00:27  lr: 0.000024  loss: 0.6452 (0.7018)  time: 0.6018  data: 0.0001  max mem: 15821
[20:40:23.655945] Epoch: [3]  [320/345]  eta: 0:00:15  lr: 0.000025  loss: 0.6038 (0.6964)  time: 0.6021  data: 0.0001  max mem: 15821
[20:40:35.683223] Epoch: [3]  [340/345]  eta: 0:00:03  lr: 0.000025  loss: 0.6060 (0.6909)  time: 0.6013  data: 0.0001  max mem: 15821
[20:40:38.089299] Epoch: [3]  [344/345]  eta: 0:00:00  lr: 0.000025  loss: 0.6105 (0.6903)  time: 0.6011  data: 0.0001  max mem: 15821
[20:40:38.172232] Epoch: [3] Total time: 0:03:28 (0.6037 s / it)
[20:40:38.172453] Averaged stats: lr: 0.000025  loss: 0.6105 (0.6903)
[20:40:38.737740] Test:  [  0/345]  eta: 0:03:13  loss: 0.6441 (0.6441)  time: 0.5603  data: 0.3967  max mem: 15821
[20:40:40.403378] Test:  [ 10/345]  eta: 0:01:07  loss: 0.6115 (0.6030)  time: 0.2023  data: 0.0361  max mem: 15821
[20:40:42.072330] Test:  [ 20/345]  eta: 0:01:00  loss: 0.6080 (0.6000)  time: 0.1666  data: 0.0001  max mem: 15821
[20:40:43.743738] Test:  [ 30/345]  eta: 0:00:56  loss: 0.6014 (0.5984)  time: 0.1670  data: 0.0001  max mem: 15821
[20:40:45.418556] Test:  [ 40/345]  eta: 0:00:53  loss: 0.5896 (0.5996)  time: 0.1672  data: 0.0001  max mem: 15821
[20:40:47.095775] Test:  [ 50/345]  eta: 0:00:51  loss: 0.5938 (0.5987)  time: 0.1675  data: 0.0001  max mem: 15821
[20:40:48.777517] Test:  [ 60/345]  eta: 0:00:49  loss: 0.5938 (0.5967)  time: 0.1679  data: 0.0001  max mem: 15821
[20:40:50.461116] Test:  [ 70/345]  eta: 0:00:47  loss: 0.6055 (0.5998)  time: 0.1682  data: 0.0001  max mem: 15821
[20:40:52.148857] Test:  [ 80/345]  eta: 0:00:45  loss: 0.5932 (0.5992)  time: 0.1685  data: 0.0001  max mem: 15821
[20:40:53.841086] Test:  [ 90/345]  eta: 0:00:43  loss: 0.5597 (0.5936)  time: 0.1689  data: 0.0001  max mem: 15821
[20:40:55.535550] Test:  [100/345]  eta: 0:00:42  loss: 0.5585 (0.5931)  time: 0.1693  data: 0.0001  max mem: 15821
[20:40:57.233770] Test:  [110/345]  eta: 0:00:40  loss: 0.5652 (0.5919)  time: 0.1696  data: 0.0001  max mem: 15821
[20:40:58.935362] Test:  [120/345]  eta: 0:00:38  loss: 0.5643 (0.5912)  time: 0.1699  data: 0.0001  max mem: 15821
[20:41:00.641271] Test:  [130/345]  eta: 0:00:36  loss: 0.5609 (0.5895)  time: 0.1703  data: 0.0001  max mem: 15821
[20:41:02.348081] Test:  [140/345]  eta: 0:00:35  loss: 0.5641 (0.5884)  time: 0.1706  data: 0.0001  max mem: 15821
[20:41:04.059249] Test:  [150/345]  eta: 0:00:33  loss: 0.5752 (0.5887)  time: 0.1708  data: 0.0001  max mem: 15821
[20:41:05.774735] Test:  [160/345]  eta: 0:00:31  loss: 0.5927 (0.5894)  time: 0.1713  data: 0.0001  max mem: 15821
[20:41:07.494462] Test:  [170/345]  eta: 0:00:29  loss: 0.5876 (0.5889)  time: 0.1717  data: 0.0001  max mem: 15821
[20:41:09.216975] Test:  [180/345]  eta: 0:00:28  loss: 0.5769 (0.5883)  time: 0.1720  data: 0.0001  max mem: 15821
[20:41:10.942244] Test:  [190/345]  eta: 0:00:26  loss: 0.5783 (0.5884)  time: 0.1723  data: 0.0001  max mem: 15821
[20:41:12.670702] Test:  [200/345]  eta: 0:00:24  loss: 0.5889 (0.5889)  time: 0.1726  data: 0.0001  max mem: 15821
[20:41:14.402075] Test:  [210/345]  eta: 0:00:23  loss: 0.5985 (0.5892)  time: 0.1729  data: 0.0001  max mem: 15821
[20:41:16.137587] Test:  [220/345]  eta: 0:00:21  loss: 0.5850 (0.5881)  time: 0.1733  data: 0.0001  max mem: 15821
[20:41:17.876720] Test:  [230/345]  eta: 0:00:19  loss: 0.5513 (0.5879)  time: 0.1737  data: 0.0001  max mem: 15821
[20:41:19.621093] Test:  [240/345]  eta: 0:00:18  loss: 0.5916 (0.5883)  time: 0.1741  data: 0.0001  max mem: 15821
[20:41:21.366661] Test:  [250/345]  eta: 0:00:16  loss: 0.5916 (0.5882)  time: 0.1744  data: 0.0001  max mem: 15821
[20:41:23.116869] Test:  [260/345]  eta: 0:00:14  loss: 0.5776 (0.5884)  time: 0.1747  data: 0.0001  max mem: 15821
[20:41:24.868741] Test:  [270/345]  eta: 0:00:12  loss: 0.5966 (0.5891)  time: 0.1750  data: 0.0001  max mem: 15821
[20:41:26.625332] Test:  [280/345]  eta: 0:00:11  loss: 0.5951 (0.5893)  time: 0.1754  data: 0.0001  max mem: 15821
[20:41:28.385987] Test:  [290/345]  eta: 0:00:09  loss: 0.5733 (0.5883)  time: 0.1758  data: 0.0001  max mem: 15821
[20:41:30.149539] Test:  [300/345]  eta: 0:00:07  loss: 0.5733 (0.5881)  time: 0.1761  data: 0.0001  max mem: 15821
[20:41:31.917587] Test:  [310/345]  eta: 0:00:06  loss: 0.5812 (0.5875)  time: 0.1765  data: 0.0001  max mem: 15821
[20:41:33.687298] Test:  [320/345]  eta: 0:00:04  loss: 0.5812 (0.5878)  time: 0.1768  data: 0.0001  max mem: 15821
[20:41:35.461155] Test:  [330/345]  eta: 0:00:02  loss: 0.5921 (0.5881)  time: 0.1771  data: 0.0001  max mem: 15821
[20:41:37.238955] Test:  [340/345]  eta: 0:00:00  loss: 0.5872 (0.5878)  time: 0.1775  data: 0.0001  max mem: 15821
[20:41:37.951576] Test:  [344/345]  eta: 0:00:00  loss: 0.5697 (0.5875)  time: 0.1777  data: 0.0001  max mem: 15821
[20:41:38.024832] Test: Total time: 0:00:59 (0.1735 s / it)
[20:41:48.452030] Test:  [ 0/57]  eta: 0:00:29  loss: 0.6392 (0.6392)  time: 0.5198  data: 0.3578  max mem: 15821
[20:41:50.098414] Test:  [10/57]  eta: 0:00:09  loss: 0.6058 (0.6371)  time: 0.1968  data: 0.0326  max mem: 15821
[20:41:51.748602] Test:  [20/57]  eta: 0:00:06  loss: 0.5864 (0.6044)  time: 0.1647  data: 0.0001  max mem: 15821
[20:41:53.403263] Test:  [30/57]  eta: 0:00:04  loss: 0.4801 (0.5440)  time: 0.1652  data: 0.0001  max mem: 15821
[20:41:55.062118] Test:  [40/57]  eta: 0:00:02  loss: 0.4189 (0.5129)  time: 0.1656  data: 0.0001  max mem: 15821
[20:41:56.724899] Test:  [50/57]  eta: 0:00:01  loss: 0.4205 (0.5105)  time: 0.1660  data: 0.0001  max mem: 15821
[20:41:57.622106] Test:  [56/57]  eta: 0:00:00  loss: 0.5398 (0.5175)  time: 0.1611  data: 0.0000  max mem: 15821
[20:41:57.687173] Test: Total time: 0:00:09 (0.1712 s / it)
[20:41:59.428549] Dice score of the network on the train images: 0.627408, val images: 0.714222
[20:41:59.428768] saving best_prec_model_0 @ epoch 3
[20:42:00.855757] saving best_dice_model_0 @ epoch 3
[20:42:02.058516] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:42:03.030947] Epoch: [4]  [  0/345]  eta: 0:05:35  lr: 0.000025  loss: 0.5948 (0.5948)  time: 0.9712  data: 0.3719  max mem: 15821
[20:42:14.969634] Epoch: [4]  [ 20/345]  eta: 0:03:19  lr: 0.000025  loss: 0.6035 (0.6050)  time: 0.5969  data: 0.0001  max mem: 15821
[20:42:26.951678] Epoch: [4]  [ 40/345]  eta: 0:03:05  lr: 0.000026  loss: 0.5708 (0.5885)  time: 0.5991  data: 0.0001  max mem: 15821
[20:42:39.083158] Epoch: [4]  [ 60/345]  eta: 0:02:52  lr: 0.000026  loss: 0.5907 (0.5850)  time: 0.6065  data: 0.0001  max mem: 15821
[20:42:51.128140] Epoch: [4]  [ 80/345]  eta: 0:02:40  lr: 0.000026  loss: 0.5730 (0.5850)  time: 0.6022  data: 0.0001  max mem: 15821
[20:43:03.174177] Epoch: [4]  [100/345]  eta: 0:02:28  lr: 0.000027  loss: 0.5637 (0.5821)  time: 0.6023  data: 0.0001  max mem: 15821
[20:43:15.255687] Epoch: [4]  [120/345]  eta: 0:02:16  lr: 0.000027  loss: 0.5728 (0.5819)  time: 0.6040  data: 0.0001  max mem: 15821
[20:43:27.331505] Epoch: [4]  [140/345]  eta: 0:02:03  lr: 0.000028  loss: 0.5644 (0.5799)  time: 0.6038  data: 0.0001  max mem: 15821
[20:43:39.414386] Epoch: [4]  [160/345]  eta: 0:01:51  lr: 0.000028  loss: 0.5326 (0.5752)  time: 0.6041  data: 0.0001  max mem: 15821
[20:43:51.495232] Epoch: [4]  [180/345]  eta: 0:01:39  lr: 0.000028  loss: 0.5380 (0.5717)  time: 0.6040  data: 0.0001  max mem: 15821
[20:44:03.555727] Epoch: [4]  [200/345]  eta: 0:01:27  lr: 0.000029  loss: 0.5271 (0.5683)  time: 0.6030  data: 0.0001  max mem: 15821
[20:44:15.629288] Epoch: [4]  [220/345]  eta: 0:01:15  lr: 0.000029  loss: 0.5276 (0.5640)  time: 0.6036  data: 0.0001  max mem: 15821
[20:44:27.710575] Epoch: [4]  [240/345]  eta: 0:01:03  lr: 0.000029  loss: 0.5138 (0.5611)  time: 0.6040  data: 0.0001  max mem: 15821
[20:44:39.780797] Epoch: [4]  [260/345]  eta: 0:00:51  lr: 0.000030  loss: 0.4961 (0.5566)  time: 0.6035  data: 0.0001  max mem: 15821
[20:44:51.839322] Epoch: [4]  [280/345]  eta: 0:00:39  lr: 0.000030  loss: 0.4967 (0.5531)  time: 0.6029  data: 0.0001  max mem: 15821
[20:45:03.901959] Epoch: [4]  [300/345]  eta: 0:00:27  lr: 0.000030  loss: 0.5021 (0.5496)  time: 0.6031  data: 0.0001  max mem: 15821
[20:45:15.952079] Epoch: [4]  [320/345]  eta: 0:00:15  lr: 0.000031  loss: 0.4858 (0.5460)  time: 0.6025  data: 0.0001  max mem: 15821
[20:45:27.990428] Epoch: [4]  [340/345]  eta: 0:00:03  lr: 0.000031  loss: 0.4991 (0.5428)  time: 0.6019  data: 0.0001  max mem: 15821
[20:45:30.395382] Epoch: [4]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 0.4991 (0.5424)  time: 0.6018  data: 0.0001  max mem: 15821
[20:45:30.478790] Epoch: [4] Total time: 0:03:28 (0.6041 s / it)
[20:45:30.479413] Averaged stats: lr: 0.000031  loss: 0.4991 (0.5424)
[20:45:31.059254] Test:  [  0/345]  eta: 0:03:18  loss: 0.4632 (0.4632)  time: 0.5740  data: 0.4104  max mem: 15821
[20:45:32.723793] Test:  [ 10/345]  eta: 0:01:08  loss: 0.4632 (0.4665)  time: 0.2034  data: 0.0374  max mem: 15821
[20:45:34.391363] Test:  [ 20/345]  eta: 0:01:00  loss: 0.4865 (0.4886)  time: 0.1665  data: 0.0001  max mem: 15821
[20:45:36.062958] Test:  [ 30/345]  eta: 0:00:56  loss: 0.4863 (0.4859)  time: 0.1669  data: 0.0001  max mem: 15821
[20:45:37.736896] Test:  [ 40/345]  eta: 0:00:53  loss: 0.4683 (0.4814)  time: 0.1672  data: 0.0001  max mem: 15821
[20:45:39.414927] Test:  [ 50/345]  eta: 0:00:51  loss: 0.4624 (0.4827)  time: 0.1675  data: 0.0001  max mem: 15821
[20:45:41.095837] Test:  [ 60/345]  eta: 0:00:49  loss: 0.4708 (0.4801)  time: 0.1679  data: 0.0001  max mem: 15821
[20:45:42.779774] Test:  [ 70/345]  eta: 0:00:47  loss: 0.4599 (0.4788)  time: 0.1682  data: 0.0001  max mem: 15821
[20:45:44.467799] Test:  [ 80/345]  eta: 0:00:45  loss: 0.4485 (0.4767)  time: 0.1685  data: 0.0001  max mem: 15821
[20:45:46.161194] Test:  [ 90/345]  eta: 0:00:43  loss: 0.4485 (0.4767)  time: 0.1690  data: 0.0001  max mem: 15821
[20:45:47.855085] Test:  [100/345]  eta: 0:00:42  loss: 0.4751 (0.4765)  time: 0.1693  data: 0.0001  max mem: 15821
[20:45:49.554710] Test:  [110/345]  eta: 0:00:40  loss: 0.4751 (0.4770)  time: 0.1696  data: 0.0001  max mem: 15821
[20:45:51.256421] Test:  [120/345]  eta: 0:00:38  loss: 0.4754 (0.4773)  time: 0.1700  data: 0.0001  max mem: 15821
[20:45:52.962442] Test:  [130/345]  eta: 0:00:36  loss: 0.4812 (0.4777)  time: 0.1703  data: 0.0001  max mem: 15821
[20:45:54.670158] Test:  [140/345]  eta: 0:00:35  loss: 0.4784 (0.4780)  time: 0.1706  data: 0.0001  max mem: 15821
[20:45:56.382740] Test:  [150/345]  eta: 0:00:33  loss: 0.4859 (0.4789)  time: 0.1709  data: 0.0001  max mem: 15821
[20:45:58.098499] Test:  [160/345]  eta: 0:00:31  loss: 0.4853 (0.4790)  time: 0.1713  data: 0.0001  max mem: 15821
[20:45:59.819663] Test:  [170/345]  eta: 0:00:30  loss: 0.4694 (0.4781)  time: 0.1718  data: 0.0001  max mem: 15821
[20:46:01.543226] Test:  [180/345]  eta: 0:00:28  loss: 0.4606 (0.4778)  time: 0.1722  data: 0.0001  max mem: 15821
[20:46:03.269054] Test:  [190/345]  eta: 0:00:26  loss: 0.4857 (0.4795)  time: 0.1724  data: 0.0001  max mem: 15821
[20:46:04.998848] Test:  [200/345]  eta: 0:00:24  loss: 0.4918 (0.4803)  time: 0.1727  data: 0.0001  max mem: 15821
[20:46:06.731687] Test:  [210/345]  eta: 0:00:23  loss: 0.4852 (0.4802)  time: 0.1731  data: 0.0001  max mem: 15821
[20:46:08.468006] Test:  [220/345]  eta: 0:00:21  loss: 0.4729 (0.4804)  time: 0.1734  data: 0.0001  max mem: 15821
[20:46:10.207947] Test:  [230/345]  eta: 0:00:19  loss: 0.4757 (0.4807)  time: 0.1737  data: 0.0001  max mem: 15821
[20:46:11.950602] Test:  [240/345]  eta: 0:00:18  loss: 0.4822 (0.4802)  time: 0.1741  data: 0.0001  max mem: 15821
[20:46:13.698458] Test:  [250/345]  eta: 0:00:16  loss: 0.4837 (0.4810)  time: 0.1745  data: 0.0001  max mem: 15821
[20:46:15.448131] Test:  [260/345]  eta: 0:00:14  loss: 0.5020 (0.4813)  time: 0.1748  data: 0.0001  max mem: 15821
[20:46:17.202327] Test:  [270/345]  eta: 0:00:12  loss: 0.5018 (0.4823)  time: 0.1751  data: 0.0001  max mem: 15821
[20:46:18.959455] Test:  [280/345]  eta: 0:00:11  loss: 0.4881 (0.4819)  time: 0.1755  data: 0.0001  max mem: 15821
[20:46:20.720240] Test:  [290/345]  eta: 0:00:09  loss: 0.4510 (0.4813)  time: 0.1758  data: 0.0001  max mem: 15821
[20:46:22.484306] Test:  [300/345]  eta: 0:00:07  loss: 0.4457 (0.4815)  time: 0.1762  data: 0.0001  max mem: 15821
[20:46:24.251893] Test:  [310/345]  eta: 0:00:06  loss: 0.5022 (0.4825)  time: 0.1765  data: 0.0001  max mem: 15821
[20:46:26.023375] Test:  [320/345]  eta: 0:00:04  loss: 0.4952 (0.4826)  time: 0.1769  data: 0.0001  max mem: 15821
[20:46:27.800074] Test:  [330/345]  eta: 0:00:02  loss: 0.4815 (0.4826)  time: 0.1773  data: 0.0001  max mem: 15821
[20:46:29.577548] Test:  [340/345]  eta: 0:00:00  loss: 0.4815 (0.4827)  time: 0.1776  data: 0.0001  max mem: 15821
[20:46:30.289156] Test:  [344/345]  eta: 0:00:00  loss: 0.4815 (0.4827)  time: 0.1777  data: 0.0001  max mem: 15821
[20:46:30.370887] Test: Total time: 0:00:59 (0.1736 s / it)
[20:46:40.909872] Test:  [ 0/57]  eta: 0:00:30  loss: 0.5637 (0.5637)  time: 0.5409  data: 0.3793  max mem: 15821
[20:46:42.554552] Test:  [10/57]  eta: 0:00:09  loss: 0.5262 (0.5374)  time: 0.1986  data: 0.0346  max mem: 15821
[20:46:44.205106] Test:  [20/57]  eta: 0:00:06  loss: 0.4881 (0.5021)  time: 0.1647  data: 0.0001  max mem: 15821
[20:46:45.859525] Test:  [30/57]  eta: 0:00:04  loss: 0.3803 (0.4507)  time: 0.1652  data: 0.0001  max mem: 15821
[20:46:47.518695] Test:  [40/57]  eta: 0:00:02  loss: 0.3335 (0.4233)  time: 0.1656  data: 0.0001  max mem: 15821
[20:46:49.180560] Test:  [50/57]  eta: 0:00:01  loss: 0.3475 (0.4221)  time: 0.1660  data: 0.0001  max mem: 15821
[20:46:50.077646] Test:  [56/57]  eta: 0:00:00  loss: 0.4310 (0.4328)  time: 0.1611  data: 0.0001  max mem: 15821
[20:46:50.148320] Test: Total time: 0:00:09 (0.1716 s / it)
[20:46:51.914543] Dice score of the network on the train images: 0.660726, val images: 0.728261
[20:46:51.914771] saving best_prec_model_0 @ epoch 4
[20:46:53.135028] saving best_dice_model_0 @ epoch 4
[20:46:54.402529] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:46:55.379158] Epoch: [5]  [  0/345]  eta: 0:05:36  lr: 0.000031  loss: 0.4819 (0.4819)  time: 0.9756  data: 0.3762  max mem: 15821
[20:47:07.345144] Epoch: [5]  [ 20/345]  eta: 0:03:20  lr: 0.000032  loss: 0.4910 (0.4899)  time: 0.5982  data: 0.0001  max mem: 15821
[20:47:19.337282] Epoch: [5]  [ 40/345]  eta: 0:03:05  lr: 0.000032  loss: 0.4653 (0.4799)  time: 0.5996  data: 0.0001  max mem: 15821
[20:47:31.350805] Epoch: [5]  [ 60/345]  eta: 0:02:52  lr: 0.000032  loss: 0.4619 (0.4757)  time: 0.6006  data: 0.0001  max mem: 15821
[20:47:43.390935] Epoch: [5]  [ 80/345]  eta: 0:02:40  lr: 0.000033  loss: 0.4654 (0.4736)  time: 0.6020  data: 0.0001  max mem: 15821
[20:47:55.450714] Epoch: [5]  [100/345]  eta: 0:02:28  lr: 0.000033  loss: 0.4846 (0.4754)  time: 0.6029  data: 0.0001  max mem: 15821
[20:48:07.541663] Epoch: [5]  [120/345]  eta: 0:02:15  lr: 0.000033  loss: 0.4662 (0.4729)  time: 0.6045  data: 0.0001  max mem: 15821
[20:48:19.636933] Epoch: [5]  [140/345]  eta: 0:02:03  lr: 0.000034  loss: 0.4552 (0.4714)  time: 0.6047  data: 0.0001  max mem: 15821
[20:48:31.716759] Epoch: [5]  [160/345]  eta: 0:01:51  lr: 0.000034  loss: 0.4285 (0.4673)  time: 0.6039  data: 0.0001  max mem: 15821
[20:48:43.784932] Epoch: [5]  [180/345]  eta: 0:01:39  lr: 0.000035  loss: 0.4419 (0.4646)  time: 0.6034  data: 0.0001  max mem: 15821
[20:48:55.865116] Epoch: [5]  [200/345]  eta: 0:01:27  lr: 0.000035  loss: 0.4584 (0.4652)  time: 0.6040  data: 0.0001  max mem: 15821
[20:49:07.939117] Epoch: [5]  [220/345]  eta: 0:01:15  lr: 0.000035  loss: 0.4332 (0.4630)  time: 0.6037  data: 0.0001  max mem: 15821
[20:49:20.018050] Epoch: [5]  [240/345]  eta: 0:01:03  lr: 0.000036  loss: 0.4255 (0.4601)  time: 0.6039  data: 0.0001  max mem: 15821
[20:49:32.091190] Epoch: [5]  [260/345]  eta: 0:00:51  lr: 0.000036  loss: 0.4237 (0.4578)  time: 0.6036  data: 0.0001  max mem: 15821
[20:49:44.150492] Epoch: [5]  [280/345]  eta: 0:00:39  lr: 0.000036  loss: 0.4312 (0.4568)  time: 0.6029  data: 0.0001  max mem: 15821
[20:49:56.204445] Epoch: [5]  [300/345]  eta: 0:00:27  lr: 0.000037  loss: 0.4326 (0.4549)  time: 0.6027  data: 0.0001  max mem: 15821
[20:50:08.245299] Epoch: [5]  [320/345]  eta: 0:00:15  lr: 0.000037  loss: 0.4223 (0.4532)  time: 0.6020  data: 0.0001  max mem: 15821
[20:50:20.308961] Epoch: [5]  [340/345]  eta: 0:00:03  lr: 0.000037  loss: 0.4268 (0.4511)  time: 0.6031  data: 0.0001  max mem: 15821
[20:50:22.719054] Epoch: [5]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 0.4178 (0.4508)  time: 0.6029  data: 0.0001  max mem: 15821
[20:50:22.791200] Epoch: [5] Total time: 0:03:28 (0.6040 s / it)
[20:50:22.791499] Averaged stats: lr: 0.000037  loss: 0.4178 (0.4508)
[20:50:23.370124] Test:  [  0/345]  eta: 0:03:17  loss: 0.4203 (0.4203)  time: 0.5729  data: 0.4095  max mem: 15821
[20:50:25.034550] Test:  [ 10/345]  eta: 0:01:08  loss: 0.4080 (0.4203)  time: 0.2033  data: 0.0373  max mem: 15821
[20:50:26.703072] Test:  [ 20/345]  eta: 0:01:00  loss: 0.4080 (0.4182)  time: 0.1666  data: 0.0001  max mem: 15821
[20:50:28.374527] Test:  [ 30/345]  eta: 0:00:56  loss: 0.4038 (0.4128)  time: 0.1669  data: 0.0001  max mem: 15821
[20:50:30.049287] Test:  [ 40/345]  eta: 0:00:53  loss: 0.4060 (0.4151)  time: 0.1672  data: 0.0001  max mem: 15821
[20:50:31.727109] Test:  [ 50/345]  eta: 0:00:51  loss: 0.4217 (0.4161)  time: 0.1676  data: 0.0001  max mem: 15821
[20:50:33.409548] Test:  [ 60/345]  eta: 0:00:49  loss: 0.4073 (0.4161)  time: 0.1680  data: 0.0001  max mem: 15821
[20:50:35.095030] Test:  [ 70/345]  eta: 0:00:47  loss: 0.4008 (0.4123)  time: 0.1683  data: 0.0001  max mem: 15821
[20:50:36.783413] Test:  [ 80/345]  eta: 0:00:45  loss: 0.4003 (0.4137)  time: 0.1686  data: 0.0001  max mem: 15821
[20:50:38.475500] Test:  [ 90/345]  eta: 0:00:43  loss: 0.4243 (0.4131)  time: 0.1690  data: 0.0001  max mem: 15821
[20:50:40.169558] Test:  [100/345]  eta: 0:00:42  loss: 0.4177 (0.4128)  time: 0.1692  data: 0.0001  max mem: 15821
[20:50:41.868467] Test:  [110/345]  eta: 0:00:40  loss: 0.4125 (0.4126)  time: 0.1696  data: 0.0001  max mem: 15821
[20:50:43.571132] Test:  [120/345]  eta: 0:00:38  loss: 0.4347 (0.4153)  time: 0.1700  data: 0.0001  max mem: 15821
[20:50:45.275663] Test:  [130/345]  eta: 0:00:36  loss: 0.4235 (0.4136)  time: 0.1703  data: 0.0001  max mem: 15821
[20:50:46.984687] Test:  [140/345]  eta: 0:00:35  loss: 0.3980 (0.4136)  time: 0.1706  data: 0.0001  max mem: 15821
[20:50:48.696121] Test:  [150/345]  eta: 0:00:33  loss: 0.4107 (0.4136)  time: 0.1710  data: 0.0001  max mem: 15821
[20:50:50.412354] Test:  [160/345]  eta: 0:00:31  loss: 0.4179 (0.4149)  time: 0.1713  data: 0.0001  max mem: 15821
[20:50:52.133314] Test:  [170/345]  eta: 0:00:30  loss: 0.4088 (0.4143)  time: 0.1718  data: 0.0001  max mem: 15821
[20:50:53.856399] Test:  [180/345]  eta: 0:00:28  loss: 0.4027 (0.4150)  time: 0.1721  data: 0.0001  max mem: 15821
[20:50:55.582990] Test:  [190/345]  eta: 0:00:26  loss: 0.3928 (0.4131)  time: 0.1724  data: 0.0001  max mem: 15821
[20:50:57.312205] Test:  [200/345]  eta: 0:00:24  loss: 0.3928 (0.4137)  time: 0.1727  data: 0.0001  max mem: 15821
[20:50:59.044067] Test:  [210/345]  eta: 0:00:23  loss: 0.4224 (0.4135)  time: 0.1730  data: 0.0001  max mem: 15821
[20:51:00.779299] Test:  [220/345]  eta: 0:00:21  loss: 0.4179 (0.4134)  time: 0.1733  data: 0.0001  max mem: 15821
[20:51:02.519970] Test:  [230/345]  eta: 0:00:19  loss: 0.4116 (0.4133)  time: 0.1737  data: 0.0001  max mem: 15821
[20:51:04.263582] Test:  [240/345]  eta: 0:00:18  loss: 0.4119 (0.4133)  time: 0.1742  data: 0.0001  max mem: 15821
[20:51:06.012279] Test:  [250/345]  eta: 0:00:16  loss: 0.4190 (0.4141)  time: 0.1744  data: 0.0001  max mem: 15821
[20:51:07.762979] Test:  [260/345]  eta: 0:00:14  loss: 0.4183 (0.4140)  time: 0.1748  data: 0.0001  max mem: 15821
[20:51:09.515931] Test:  [270/345]  eta: 0:00:12  loss: 0.4057 (0.4139)  time: 0.1751  data: 0.0001  max mem: 15821
[20:51:11.272551] Test:  [280/345]  eta: 0:00:11  loss: 0.4199 (0.4142)  time: 0.1754  data: 0.0001  max mem: 15821
[20:51:13.032839] Test:  [290/345]  eta: 0:00:09  loss: 0.4194 (0.4144)  time: 0.1758  data: 0.0001  max mem: 15821
[20:51:14.796098] Test:  [300/345]  eta: 0:00:07  loss: 0.4181 (0.4147)  time: 0.1761  data: 0.0001  max mem: 15821
[20:51:16.564463] Test:  [310/345]  eta: 0:00:06  loss: 0.4200 (0.4151)  time: 0.1765  data: 0.0001  max mem: 15821
[20:51:18.335155] Test:  [320/345]  eta: 0:00:04  loss: 0.4106 (0.4147)  time: 0.1769  data: 0.0001  max mem: 15821
[20:51:20.109394] Test:  [330/345]  eta: 0:00:02  loss: 0.4106 (0.4151)  time: 0.1772  data: 0.0001  max mem: 15821
[20:51:21.888579] Test:  [340/345]  eta: 0:00:00  loss: 0.3946 (0.4145)  time: 0.1776  data: 0.0001  max mem: 15821
[20:51:22.601861] Test:  [344/345]  eta: 0:00:00  loss: 0.3946 (0.4144)  time: 0.1778  data: 0.0001  max mem: 15821
[20:51:22.677077] Test: Total time: 0:00:59 (0.1736 s / it)
[20:51:33.110531] Test:  [ 0/57]  eta: 0:00:30  loss: 0.5336 (0.5336)  time: 0.5263  data: 0.3638  max mem: 15821
[20:51:34.756327] Test:  [10/57]  eta: 0:00:09  loss: 0.4657 (0.4817)  time: 0.1974  data: 0.0332  max mem: 15821
[20:51:36.407593] Test:  [20/57]  eta: 0:00:06  loss: 0.4458 (0.4581)  time: 0.1648  data: 0.0001  max mem: 15821
[20:51:38.062766] Test:  [30/57]  eta: 0:00:04  loss: 0.3297 (0.4106)  time: 0.1653  data: 0.0001  max mem: 15821
[20:51:39.721449] Test:  [40/57]  eta: 0:00:02  loss: 0.3112 (0.3877)  time: 0.1656  data: 0.0001  max mem: 15821
[20:51:41.383718] Test:  [50/57]  eta: 0:00:01  loss: 0.3133 (0.3880)  time: 0.1660  data: 0.0001  max mem: 15821
[20:51:42.280009] Test:  [56/57]  eta: 0:00:00  loss: 0.3837 (0.3973)  time: 0.1611  data: 0.0000  max mem: 15821
[20:51:42.343544] Test: Total time: 0:00:09 (0.1712 s / it)
[20:51:44.088613] Dice score of the network on the train images: 0.695409, val images: 0.738633
[20:51:44.088827] saving best_prec_model_0 @ epoch 5
[20:51:45.188863] saving best_dice_model_0 @ epoch 5
[20:51:46.249025] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[20:51:47.278946] Epoch: [6]  [  0/345]  eta: 0:05:55  lr: 0.000038  loss: 0.4086 (0.4086)  time: 1.0290  data: 0.4303  max mem: 15821
[20:51:59.239624] Epoch: [6]  [ 20/345]  eta: 0:03:21  lr: 0.000038  loss: 0.3892 (0.3895)  time: 0.5980  data: 0.0001  max mem: 15821
[20:52:11.222141] Epoch: [6]  [ 40/345]  eta: 0:03:05  lr: 0.000038  loss: 0.3934 (0.3947)  time: 0.5991  data: 0.0001  max mem: 15821
[20:52:23.230523] Epoch: [6]  [ 60/345]  eta: 0:02:52  lr: 0.000039  loss: 0.4103 (0.4003)  time: 0.6004  data: 0.0001  max mem: 15821
[20:52:35.277711] Epoch: [6]  [ 80/345]  eta: 0:02:40  lr: 0.000039  loss: 0.3961 (0.4018)  time: 0.6023  data: 0.0001  max mem: 15821
[20:52:47.334064] Epoch: [6]  [100/345]  eta: 0:02:28  lr: 0.000039  loss: 0.3979 (0.4026)  time: 0.6028  data: 0.0001  max mem: 15821
[20:52:59.427112] Epoch: [6]  [120/345]  eta: 0:02:16  lr: 0.000040  loss: 0.4020 (0.4015)  time: 0.6046  data: 0.0001  max mem: 15821
[20:53:11.522714] Epoch: [6]  [140/345]  eta: 0:02:03  lr: 0.000040  loss: 0.4057 (0.4017)  time: 0.6047  data: 0.0001  max mem: 15821
[20:53:23.613077] Epoch: [6]  [160/345]  eta: 0:01:51  lr: 0.000040  loss: 0.4045 (0.4021)  time: 0.6045  data: 0.0001  max mem: 15821
[20:53:35.695627] Epoch: [6]  [180/345]  eta: 0:01:39  lr: 0.000041  loss: 0.3910 (0.4021)  time: 0.6041  data: 0.0001  max mem: 15821
[20:53:47.755430] Epoch: [6]  [200/345]  eta: 0:01:27  lr: 0.000041  loss: 0.3965 (0.4016)  time: 0.6029  data: 0.0001  max mem: 15821
[20:53:59.813098] Epoch: [6]  [220/345]  eta: 0:01:15  lr: 0.000041  loss: 0.3965 (0.4010)  time: 0.6028  data: 0.0001  max mem: 15821
[20:54:11.868646] Epoch: [6]  [240/345]  eta: 0:01:03  lr: 0.000042  loss: 0.3643 (0.3988)  time: 0.6027  data: 0.0001  max mem: 15821
[20:54:24.001365] Epoch: [6]  [260/345]  eta: 0:00:51  lr: 0.000042  loss: 0.3796 (0.3980)  time: 0.6066  data: 0.0001  max mem: 15821
[20:54:36.052684] Epoch: [6]  [280/345]  eta: 0:00:39  lr: 0.000043  loss: 0.3875 (0.3977)  time: 0.6025  data: 0.0001  max mem: 15821
[20:54:48.098963] Epoch: [6]  [300/345]  eta: 0:00:27  lr: 0.000043  loss: 0.3680 (0.3964)  time: 0.6023  data: 0.0001  max mem: 15821
[20:55:00.138397] Epoch: [6]  [320/345]  eta: 0:00:15  lr: 0.000043  loss: 0.3921 (0.3961)  time: 0.6019  data: 0.0001  max mem: 15821
[20:55:12.178184] Epoch: [6]  [340/345]  eta: 0:00:03  lr: 0.000044  loss: 0.3890 (0.3967)  time: 0.6019  data: 0.0001  max mem: 15821
[20:55:14.585165] Epoch: [6]  [344/345]  eta: 0:00:00  lr: 0.000044  loss: 0.3850 (0.3962)  time: 0.6019  data: 0.0001  max mem: 15821
[20:55:14.657404] Epoch: [6] Total time: 0:03:28 (0.6041 s / it)
[20:55:14.657543] Averaged stats: lr: 0.000044  loss: 0.3850 (0.3962)
[20:55:15.232540] Test:  [  0/345]  eta: 0:03:16  loss: 0.3974 (0.3974)  time: 0.5707  data: 0.4062  max mem: 15821
[20:55:16.900159] Test:  [ 10/345]  eta: 0:01:08  loss: 0.3799 (0.3909)  time: 0.2032  data: 0.0370  max mem: 15821
[20:55:18.570510] Test:  [ 20/345]  eta: 0:01:00  loss: 0.3773 (0.3847)  time: 0.1667  data: 0.0001  max mem: 15821
[20:55:20.242259] Test:  [ 30/345]  eta: 0:00:56  loss: 0.3545 (0.3782)  time: 0.1670  data: 0.0001  max mem: 15821
[20:55:21.918396] Test:  [ 40/345]  eta: 0:00:53  loss: 0.3734 (0.3791)  time: 0.1673  data: 0.0001  max mem: 15821
[20:55:23.596388] Test:  [ 50/345]  eta: 0:00:51  loss: 0.3824 (0.3823)  time: 0.1676  data: 0.0001  max mem: 15821
[20:55:25.279144] Test:  [ 60/345]  eta: 0:00:49  loss: 0.3858 (0.3824)  time: 0.1680  data: 0.0001  max mem: 15821
[20:55:26.964805] Test:  [ 70/345]  eta: 0:00:47  loss: 0.3832 (0.3827)  time: 0.1683  data: 0.0001  max mem: 15821
[20:55:28.654889] Test:  [ 80/345]  eta: 0:00:45  loss: 0.3766 (0.3839)  time: 0.1687  data: 0.0001  max mem: 15821
[20:55:30.347278] Test:  [ 90/345]  eta: 0:00:43  loss: 0.3932 (0.3850)  time: 0.1691  data: 0.0001  max mem: 15821
[20:55:32.043736] Test:  [100/345]  eta: 0:00:42  loss: 0.3663 (0.3825)  time: 0.1694  data: 0.0001  max mem: 15821
[20:55:33.743957] Test:  [110/345]  eta: 0:00:40  loss: 0.3603 (0.3808)  time: 0.1698  data: 0.0001  max mem: 15821
[20:55:35.447485] Test:  [120/345]  eta: 0:00:38  loss: 0.3553 (0.3801)  time: 0.1701  data: 0.0001  max mem: 15821
[20:55:37.153406] Test:  [130/345]  eta: 0:00:36  loss: 0.3716 (0.3796)  time: 0.1704  data: 0.0001  max mem: 15821
[20:55:38.862588] Test:  [140/345]  eta: 0:00:35  loss: 0.3781 (0.3808)  time: 0.1707  data: 0.0001  max mem: 15821
[20:55:40.576403] Test:  [150/345]  eta: 0:00:33  loss: 0.3931 (0.3814)  time: 0.1711  data: 0.0001  max mem: 15821
[20:55:42.293462] Test:  [160/345]  eta: 0:00:31  loss: 0.3773 (0.3806)  time: 0.1715  data: 0.0001  max mem: 15821
[20:55:44.012964] Test:  [170/345]  eta: 0:00:30  loss: 0.3529 (0.3801)  time: 0.1718  data: 0.0001  max mem: 15821
[20:55:45.736081] Test:  [180/345]  eta: 0:00:28  loss: 0.3700 (0.3799)  time: 0.1721  data: 0.0001  max mem: 15821
[20:55:47.463093] Test:  [190/345]  eta: 0:00:26  loss: 0.3705 (0.3794)  time: 0.1724  data: 0.0001  max mem: 15821
[20:55:49.193854] Test:  [200/345]  eta: 0:00:24  loss: 0.3774 (0.3804)  time: 0.1728  data: 0.0001  max mem: 15821
[20:55:50.927017] Test:  [210/345]  eta: 0:00:23  loss: 0.3876 (0.3800)  time: 0.1731  data: 0.0001  max mem: 15821
[20:55:52.662851] Test:  [220/345]  eta: 0:00:21  loss: 0.3741 (0.3801)  time: 0.1734  data: 0.0001  max mem: 15821
[20:55:54.402709] Test:  [230/345]  eta: 0:00:19  loss: 0.3959 (0.3810)  time: 0.1737  data: 0.0001  max mem: 15821
[20:55:56.146979] Test:  [240/345]  eta: 0:00:18  loss: 0.4069 (0.3815)  time: 0.1741  data: 0.0001  max mem: 15821
[20:55:57.894509] Test:  [250/345]  eta: 0:00:16  loss: 0.3717 (0.3810)  time: 0.1745  data: 0.0001  max mem: 15821
[20:55:59.646466] Test:  [260/345]  eta: 0:00:14  loss: 0.3903 (0.3822)  time: 0.1749  data: 0.0001  max mem: 15821
[20:56:01.400371] Test:  [270/345]  eta: 0:00:12  loss: 0.3943 (0.3819)  time: 0.1752  data: 0.0001  max mem: 15821
[20:56:03.159315] Test:  [280/345]  eta: 0:00:11  loss: 0.3724 (0.3815)  time: 0.1756  data: 0.0001  max mem: 15821
[20:56:04.919716] Test:  [290/345]  eta: 0:00:09  loss: 0.3878 (0.3817)  time: 0.1759  data: 0.0001  max mem: 15821
[20:56:06.685128] Test:  [300/345]  eta: 0:00:07  loss: 0.3889 (0.3817)  time: 0.1762  data: 0.0001  max mem: 15821
[20:56:08.453290] Test:  [310/345]  eta: 0:00:06  loss: 0.3586 (0.3812)  time: 0.1766  data: 0.0001  max mem: 15821
[20:56:10.225243] Test:  [320/345]  eta: 0:00:04  loss: 0.3545 (0.3804)  time: 0.1769  data: 0.0001  max mem: 15821
[20:56:11.999797] Test:  [330/345]  eta: 0:00:02  loss: 0.3586 (0.3803)  time: 0.1773  data: 0.0001  max mem: 15821
[20:56:13.778331] Test:  [340/345]  eta: 0:00:00  loss: 0.3618 (0.3801)  time: 0.1776  data: 0.0001  max mem: 15821
[20:56:14.492087] Test:  [344/345]  eta: 0:00:00  loss: 0.3675 (0.3800)  time: 0.1778  data: 0.0001  max mem: 15821
[20:56:14.573199] Test: Total time: 0:00:59 (0.1737 s / it)
[20:56:24.984846] Test:  [ 0/57]  eta: 0:00:29  loss: 0.5214 (0.5214)  time: 0.5199  data: 0.3571  max mem: 15821
[20:56:26.631508] Test:  [10/57]  eta: 0:00:09  loss: 0.4575 (0.4649)  time: 0.1969  data: 0.0325  max mem: 15821
[20:56:28.281458] Test:  [20/57]  eta: 0:00:06  loss: 0.4350 (0.4448)  time: 0.1648  data: 0.0001  max mem: 15821
[20:56:29.936673] Test:  [30/57]  eta: 0:00:04  loss: 0.3113 (0.3966)  time: 0.1652  data: 0.0001  max mem: 15821
[20:56:31.595169] Test:  [40/57]  eta: 0:00:02  loss: 0.2963 (0.3735)  time: 0.1656  data: 0.0001  max mem: 15821
[20:56:33.257637] Test:  [50/57]  eta: 0:00:01  loss: 0.2998 (0.3725)  time: 0.1660  data: 0.0001  max mem: 15821
[20:56:34.154571] Test:  [56/57]  eta: 0:00:00  loss: 0.3595 (0.3822)  time: 0.1611  data: 0.0000  max mem: 15821
[20:56:34.233147] Test: Total time: 0:00:09 (0.1714 s / it)
[20:56:35.977604] Dice score of the network on the train images: 0.721759, val images: 0.752824
[20:56:35.977817] saving best_prec_model_0 @ epoch 6
[20:56:37.035948] saving best_dice_model_0 @ epoch 6
[20:56:38.150978] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft

[20:56:39.147080] Epoch: [7]  [  0/345]  eta: 0:05:43  lr: 0.000044  loss: 0.3905 (0.3905)  time: 0.9953  data: 0.3969  max mem: 15821
[20:56:51.117665] Epoch: [7]  [ 20/345]  eta: 0:03:20  lr: 0.000044  loss: 0.3672 (0.3793)  time: 0.5985  data: 0.0001  max mem: 15821
[20:57:03.103685] Epoch: [7]  [ 40/345]  eta: 0:03:05  lr: 0.000044  loss: 0.3588 (0.3717)  time: 0.5993  data: 0.0001  max mem: 15821
[20:57:15.120982] Epoch: [7]  [ 60/345]  eta: 0:02:52  lr: 0.000045  loss: 0.3516 (0.3660)  time: 0.6008  data: 0.0001  max mem: 15821
[20:57:27.165621] Epoch: [7]  [ 80/345]  eta: 0:02:40  lr: 0.000045  loss: 0.3447 (0.3611)  time: 0.6022  data: 0.0001  max mem: 15821
[20:57:39.226473] Epoch: [7]  [100/345]  eta: 0:02:28  lr: 0.000046  loss: 0.3602 (0.3616)  time: 0.6030  data: 0.0001  max mem: 15821
[20:57:51.310527] Epoch: [7]  [120/345]  eta: 0:02:16  lr: 0.000046  loss: 0.3647 (0.3622)  time: 0.6042  data: 0.0001  max mem: 15821
[20:58:03.406188] Epoch: [7]  [140/345]  eta: 0:02:03  lr: 0.000046  loss: 0.3571 (0.3616)  time: 0.6047  data: 0.0001  max mem: 15821
[20:58:15.500018] Epoch: [7]  [160/345]  eta: 0:01:51  lr: 0.000047  loss: 0.3473 (0.3597)  time: 0.6046  data: 0.0001  max mem: 15821
[20:58:27.584040] Epoch: [7]  [180/345]  eta: 0:01:39  lr: 0.000047  loss: 0.3689 (0.3603)  time: 0.6042  data: 0.0001  max mem: 15821
[20:58:39.666832] Epoch: [7]  [200/345]  eta: 0:01:27  lr: 0.000047  loss: 0.3639 (0.3604)  time: 0.6041  data: 0.0001  max mem: 15821
[20:58:51.747806] Epoch: [7]  [220/345]  eta: 0:01:15  lr: 0.000048  loss: 0.3426 (0.3596)  time: 0.6040  data: 0.0001  max mem: 15821
[20:59:03.826747] Epoch: [7]  [240/345]  eta: 0:01:03  lr: 0.000048  loss: 0.3465 (0.3595)  time: 0.6039  data: 0.0001  max mem: 15821
[20:59:15.903801] Epoch: [7]  [260/345]  eta: 0:00:51  lr: 0.000048  loss: 0.3365 (0.3583)  time: 0.6038  data: 0.0001  max mem: 15821
[20:59:27.975795] Epoch: [7]  [280/345]  eta: 0:00:39  lr: 0.000049  loss: 0.3483 (0.3586)  time: 0.6035  data: 0.0001  max mem: 15821
[20:59:40.035184] Epoch: [7]  [300/345]  eta: 0:00:27  lr: 0.000049  loss: 0.3618 (0.3588)  time: 0.6029  data: 0.0001  max mem: 15821
[20:59:52.099258] Epoch: [7]  [320/345]  eta: 0:00:15  lr: 0.000050  loss: 0.3607 (0.3589)  time: 0.6031  data: 0.0001  max mem: 15821
[21:00:04.244746] Epoch: [7]  [340/345]  eta: 0:00:03  lr: 0.000050  loss: 0.3546 (0.3584)  time: 0.6072  data: 0.0001  max mem: 15821
[21:00:06.662450] Epoch: [7]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.3557 (0.3584)  time: 0.6074  data: 0.0001  max mem: 15821
[21:00:06.736083] Epoch: [7] Total time: 0:03:28 (0.6046 s / it)
[21:00:06.736392] Averaged stats: lr: 0.000050  loss: 0.3557 (0.3584)
[21:00:07.307869] Test:  [  0/345]  eta: 0:03:15  loss: 0.3067 (0.3067)  time: 0.5668  data: 0.4029  max mem: 15821
[21:00:08.973093] Test:  [ 10/345]  eta: 0:01:07  loss: 0.3276 (0.3405)  time: 0.2028  data: 0.0367  max mem: 15821
[21:00:10.642433] Test:  [ 20/345]  eta: 0:01:00  loss: 0.3269 (0.3311)  time: 0.1666  data: 0.0001  max mem: 15821
[21:00:12.314013] Test:  [ 30/345]  eta: 0:00:56  loss: 0.3366 (0.3376)  time: 0.1670  data: 0.0001  max mem: 15821
[21:00:13.988454] Test:  [ 40/345]  eta: 0:00:53  loss: 0.3522 (0.3366)  time: 0.1672  data: 0.0001  max mem: 15821
[21:00:15.667129] Test:  [ 50/345]  eta: 0:00:51  loss: 0.3400 (0.3363)  time: 0.1676  data: 0.0001  max mem: 15821
[21:00:17.348452] Test:  [ 60/345]  eta: 0:00:49  loss: 0.3400 (0.3376)  time: 0.1679  data: 0.0001  max mem: 15821
[21:00:19.034263] Test:  [ 70/345]  eta: 0:00:47  loss: 0.3354 (0.3361)  time: 0.1683  data: 0.0001  max mem: 15821
[21:00:20.722067] Test:  [ 80/345]  eta: 0:00:45  loss: 0.3354 (0.3372)  time: 0.1686  data: 0.0001  max mem: 15821
[21:00:22.415140] Test:  [ 90/345]  eta: 0:00:43  loss: 0.3382 (0.3367)  time: 0.1690  data: 0.0001  max mem: 15821
[21:00:24.109499] Test:  [100/345]  eta: 0:00:42  loss: 0.3382 (0.3368)  time: 0.1693  data: 0.0001  max mem: 15821
[21:00:25.807799] Test:  [110/345]  eta: 0:00:40  loss: 0.3298 (0.3352)  time: 0.1696  data: 0.0001  max mem: 15821
[21:00:27.510971] Test:  [120/345]  eta: 0:00:38  loss: 0.3269 (0.3343)  time: 0.1700  data: 0.0001  max mem: 15821
[21:00:29.215993] Test:  [130/345]  eta: 0:00:36  loss: 0.3330 (0.3343)  time: 0.1703  data: 0.0001  max mem: 15821
[21:00:30.924619] Test:  [140/345]  eta: 0:00:35  loss: 0.3357 (0.3342)  time: 0.1706  data: 0.0001  max mem: 15821
[21:00:32.638017] Test:  [150/345]  eta: 0:00:33  loss: 0.3281 (0.3342)  time: 0.1710  data: 0.0001  max mem: 15821
[21:00:34.354055] Test:  [160/345]  eta: 0:00:31  loss: 0.3297 (0.3350)  time: 0.1714  data: 0.0001  max mem: 15821
[21:00:36.073181] Test:  [170/345]  eta: 0:00:30  loss: 0.3384 (0.3347)  time: 0.1717  data: 0.0001  max mem: 15821
[21:00:37.796656] Test:  [180/345]  eta: 0:00:28  loss: 0.3193 (0.3339)  time: 0.1721  data: 0.0001  max mem: 15821
[21:00:39.523765] Test:  [190/345]  eta: 0:00:26  loss: 0.3196 (0.3343)  time: 0.1725  data: 0.0001  max mem: 15821
[21:00:41.255315] Test:  [200/345]  eta: 0:00:24  loss: 0.3560 (0.3348)  time: 0.1729  data: 0.0001  max mem: 15821
[21:00:42.988201] Test:  [210/345]  eta: 0:00:23  loss: 0.3324 (0.3346)  time: 0.1732  data: 0.0001  max mem: 15821
[21:00:44.724591] Test:  [220/345]  eta: 0:00:21  loss: 0.3311 (0.3346)  time: 0.1734  data: 0.0001  max mem: 15821
[21:00:46.464805] Test:  [230/345]  eta: 0:00:19  loss: 0.3325 (0.3346)  time: 0.1738  data: 0.0001  max mem: 15821
[21:00:48.209025] Test:  [240/345]  eta: 0:00:18  loss: 0.3330 (0.3345)  time: 0.1742  data: 0.0001  max mem: 15821
[21:00:49.957650] Test:  [250/345]  eta: 0:00:16  loss: 0.3300 (0.3349)  time: 0.1746  data: 0.0001  max mem: 15821
[21:00:51.709114] Test:  [260/345]  eta: 0:00:14  loss: 0.3255 (0.3346)  time: 0.1749  data: 0.0001  max mem: 15821
[21:00:53.463733] Test:  [270/345]  eta: 0:00:12  loss: 0.3162 (0.3342)  time: 0.1752  data: 0.0001  max mem: 15821
[21:00:55.220881] Test:  [280/345]  eta: 0:00:11  loss: 0.3333 (0.3346)  time: 0.1755  data: 0.0001  max mem: 15821
[21:00:56.981523] Test:  [290/345]  eta: 0:00:09  loss: 0.3407 (0.3348)  time: 0.1758  data: 0.0001  max mem: 15821
[21:00:58.745912] Test:  [300/345]  eta: 0:00:07  loss: 0.3363 (0.3345)  time: 0.1762  data: 0.0001  max mem: 15821
[21:01:00.515714] Test:  [310/345]  eta: 0:00:06  loss: 0.3268 (0.3344)  time: 0.1766  data: 0.0001  max mem: 15821
[21:01:02.287997] Test:  [320/345]  eta: 0:00:04  loss: 0.3399 (0.3344)  time: 0.1770  data: 0.0001  max mem: 15821
[21:01:04.062689] Test:  [330/345]  eta: 0:00:02  loss: 0.3126 (0.3333)  time: 0.1773  data: 0.0001  max mem: 15821
[21:01:05.841474] Test:  [340/345]  eta: 0:00:00  loss: 0.3204 (0.3340)  time: 0.1776  data: 0.0001  max mem: 15821
[21:01:06.554562] Test:  [344/345]  eta: 0:00:00  loss: 0.3275 (0.3342)  time: 0.1778  data: 0.0001  max mem: 15821
[21:01:06.633136] Test: Total time: 0:00:59 (0.1736 s / it)
[21:01:17.154466] Test:  [ 0/57]  eta: 0:00:29  loss: 0.5019 (0.5019)  time: 0.5210  data: 0.3587  max mem: 15821
[21:01:18.800904] Test:  [10/57]  eta: 0:00:09  loss: 0.4535 (0.4634)  time: 0.1969  data: 0.0327  max mem: 15821
[21:01:20.452270] Test:  [20/57]  eta: 0:00:06  loss: 0.4090 (0.4338)  time: 0.1648  data: 0.0001  max mem: 15821
[21:01:22.107300] Test:  [30/57]  eta: 0:00:04  loss: 0.2933 (0.3824)  time: 0.1653  data: 0.0001  max mem: 15821
[21:01:23.766899] Test:  [40/57]  eta: 0:00:02  loss: 0.2825 (0.3606)  time: 0.1657  data: 0.0001  max mem: 15821
[21:01:25.431047] Test:  [50/57]  eta: 0:00:01  loss: 0.3002 (0.3595)  time: 0.1661  data: 0.0001  max mem: 15821
[21:01:26.328222] Test:  [56/57]  eta: 0:00:00  loss: 0.3435 (0.3718)  time: 0.1612  data: 0.0001  max mem: 15821
[21:01:26.402226] Test: Total time: 0:00:09 (0.1714 s / it)
[21:01:28.230702] Dice score of the network on the train images: 0.749923, val images: 0.768349
[21:01:28.230938] saving best_prec_model_0 @ epoch 7
[21:01:29.304101] saving best_dice_model_0 @ epoch 7
[21:01:30.310932] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:01:31.301558] Epoch: [8]  [  0/345]  eta: 0:05:41  lr: 0.000050  loss: 0.3319 (0.3319)  time: 0.9896  data: 0.3912  max mem: 15821
[21:01:43.278677] Epoch: [8]  [ 20/345]  eta: 0:03:20  lr: 0.000050  loss: 0.3361 (0.3448)  time: 0.5988  data: 0.0001  max mem: 15821
[21:01:55.268262] Epoch: [8]  [ 40/345]  eta: 0:03:05  lr: 0.000051  loss: 0.3377 (0.3414)  time: 0.5994  data: 0.0001  max mem: 15821
[21:02:07.279547] Epoch: [8]  [ 60/345]  eta: 0:02:52  lr: 0.000051  loss: 0.3292 (0.3391)  time: 0.6005  data: 0.0001  max mem: 15821
[21:02:19.338217] Epoch: [8]  [ 80/345]  eta: 0:02:40  lr: 0.000051  loss: 0.3161 (0.3361)  time: 0.6029  data: 0.0001  max mem: 15821
[21:02:31.412153] Epoch: [8]  [100/345]  eta: 0:02:28  lr: 0.000052  loss: 0.3405 (0.3378)  time: 0.6037  data: 0.0001  max mem: 15821
[21:02:43.508686] Epoch: [8]  [120/345]  eta: 0:02:16  lr: 0.000052  loss: 0.3578 (0.3418)  time: 0.6048  data: 0.0001  max mem: 15821
[21:02:55.611172] Epoch: [8]  [140/345]  eta: 0:02:04  lr: 0.000053  loss: 0.3208 (0.3384)  time: 0.6051  data: 0.0001  max mem: 15821
[21:03:07.706866] Epoch: [8]  [160/345]  eta: 0:01:51  lr: 0.000053  loss: 0.3281 (0.3366)  time: 0.6047  data: 0.0001  max mem: 15821
[21:03:19.791538] Epoch: [8]  [180/345]  eta: 0:01:39  lr: 0.000053  loss: 0.3424 (0.3367)  time: 0.6042  data: 0.0001  max mem: 15821
[21:03:31.878287] Epoch: [8]  [200/345]  eta: 0:01:27  lr: 0.000054  loss: 0.3217 (0.3361)  time: 0.6043  data: 0.0001  max mem: 15821
[21:03:43.968819] Epoch: [8]  [220/345]  eta: 0:01:15  lr: 0.000054  loss: 0.3110 (0.3342)  time: 0.6045  data: 0.0001  max mem: 15821
[21:03:56.056872] Epoch: [8]  [240/345]  eta: 0:01:03  lr: 0.000054  loss: 0.3213 (0.3332)  time: 0.6044  data: 0.0001  max mem: 15821
[21:04:08.128806] Epoch: [8]  [260/345]  eta: 0:00:51  lr: 0.000055  loss: 0.3118 (0.3326)  time: 0.6036  data: 0.0001  max mem: 15821
[21:04:20.200661] Epoch: [8]  [280/345]  eta: 0:00:39  lr: 0.000055  loss: 0.3227 (0.3318)  time: 0.6035  data: 0.0001  max mem: 15821
[21:04:32.270429] Epoch: [8]  [300/345]  eta: 0:00:27  lr: 0.000055  loss: 0.3323 (0.3322)  time: 0.6034  data: 0.0001  max mem: 15821
[21:04:44.335966] Epoch: [8]  [320/345]  eta: 0:00:15  lr: 0.000056  loss: 0.3038 (0.3308)  time: 0.6032  data: 0.0001  max mem: 15821
[21:04:56.395246] Epoch: [8]  [340/345]  eta: 0:00:03  lr: 0.000056  loss: 0.2977 (0.3291)  time: 0.6029  data: 0.0001  max mem: 15821
[21:04:58.807576] Epoch: [8]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.3118 (0.3292)  time: 0.6029  data: 0.0001  max mem: 15821
[21:04:58.886398] Epoch: [8] Total time: 0:03:28 (0.6046 s / it)
[21:04:58.886620] Averaged stats: lr: 0.000056  loss: 0.3118 (0.3292)
[21:04:59.455353] Test:  [  0/345]  eta: 0:03:14  loss: 0.2786 (0.2786)  time: 0.5634  data: 0.3995  max mem: 15821
[21:05:01.121696] Test:  [ 10/345]  eta: 0:01:07  loss: 0.3056 (0.3002)  time: 0.2026  data: 0.0364  max mem: 15821
[21:05:02.789426] Test:  [ 20/345]  eta: 0:01:00  loss: 0.3067 (0.3062)  time: 0.1666  data: 0.0001  max mem: 15821
[21:05:04.461143] Test:  [ 30/345]  eta: 0:00:56  loss: 0.3129 (0.3073)  time: 0.1669  data: 0.0001  max mem: 15821
[21:05:06.135528] Test:  [ 40/345]  eta: 0:00:53  loss: 0.3014 (0.3066)  time: 0.1672  data: 0.0001  max mem: 15821
[21:05:07.812581] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2887 (0.3043)  time: 0.1675  data: 0.0001  max mem: 15821
[21:05:09.493920] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2882 (0.3037)  time: 0.1679  data: 0.0001  max mem: 15821
[21:05:11.178953] Test:  [ 70/345]  eta: 0:00:47  loss: 0.3223 (0.3075)  time: 0.1683  data: 0.0001  max mem: 15821
[21:05:12.866977] Test:  [ 80/345]  eta: 0:00:45  loss: 0.3062 (0.3063)  time: 0.1686  data: 0.0001  max mem: 15821
[21:05:14.559364] Test:  [ 90/345]  eta: 0:00:43  loss: 0.3013 (0.3057)  time: 0.1690  data: 0.0001  max mem: 15821
[21:05:16.253378] Test:  [100/345]  eta: 0:00:42  loss: 0.2982 (0.3049)  time: 0.1693  data: 0.0001  max mem: 15821
[21:05:17.953629] Test:  [110/345]  eta: 0:00:40  loss: 0.2982 (0.3055)  time: 0.1696  data: 0.0001  max mem: 15821
[21:05:19.655841] Test:  [120/345]  eta: 0:00:38  loss: 0.3004 (0.3047)  time: 0.1701  data: 0.0001  max mem: 15821
[21:05:21.361122] Test:  [130/345]  eta: 0:00:36  loss: 0.2911 (0.3039)  time: 0.1703  data: 0.0001  max mem: 15821
[21:05:23.069572] Test:  [140/345]  eta: 0:00:35  loss: 0.2897 (0.3049)  time: 0.1706  data: 0.0001  max mem: 15821
[21:05:24.782377] Test:  [150/345]  eta: 0:00:33  loss: 0.2916 (0.3046)  time: 0.1710  data: 0.0001  max mem: 15821
[21:05:26.498567] Test:  [160/345]  eta: 0:00:31  loss: 0.2945 (0.3051)  time: 0.1714  data: 0.0001  max mem: 15821
[21:05:28.218948] Test:  [170/345]  eta: 0:00:30  loss: 0.3037 (0.3048)  time: 0.1718  data: 0.0001  max mem: 15821
[21:05:29.941903] Test:  [180/345]  eta: 0:00:28  loss: 0.3036 (0.3054)  time: 0.1721  data: 0.0001  max mem: 15821
[21:05:31.667005] Test:  [190/345]  eta: 0:00:26  loss: 0.2935 (0.3047)  time: 0.1723  data: 0.0001  max mem: 15821
[21:05:33.397454] Test:  [200/345]  eta: 0:00:24  loss: 0.2935 (0.3047)  time: 0.1727  data: 0.0001  max mem: 15821
[21:05:35.130577] Test:  [210/345]  eta: 0:00:23  loss: 0.3022 (0.3043)  time: 0.1731  data: 0.0001  max mem: 15821
[21:05:36.867630] Test:  [220/345]  eta: 0:00:21  loss: 0.3134 (0.3052)  time: 0.1734  data: 0.0001  max mem: 15821
[21:05:38.607084] Test:  [230/345]  eta: 0:00:19  loss: 0.3211 (0.3052)  time: 0.1738  data: 0.0001  max mem: 15821
[21:05:40.350898] Test:  [240/345]  eta: 0:00:18  loss: 0.2922 (0.3045)  time: 0.1741  data: 0.0001  max mem: 15821
[21:05:42.098723] Test:  [250/345]  eta: 0:00:16  loss: 0.2918 (0.3045)  time: 0.1745  data: 0.0001  max mem: 15821
[21:05:43.847177] Test:  [260/345]  eta: 0:00:14  loss: 0.3101 (0.3045)  time: 0.1748  data: 0.0001  max mem: 15821
[21:05:45.600924] Test:  [270/345]  eta: 0:00:12  loss: 0.3148 (0.3045)  time: 0.1751  data: 0.0001  max mem: 15821
[21:05:47.358788] Test:  [280/345]  eta: 0:00:11  loss: 0.2949 (0.3047)  time: 0.1755  data: 0.0001  max mem: 15821
[21:05:49.118269] Test:  [290/345]  eta: 0:00:09  loss: 0.2977 (0.3044)  time: 0.1758  data: 0.0001  max mem: 15821
[21:05:50.882537] Test:  [300/345]  eta: 0:00:07  loss: 0.2963 (0.3042)  time: 0.1761  data: 0.0001  max mem: 15821
[21:05:52.649365] Test:  [310/345]  eta: 0:00:06  loss: 0.2963 (0.3045)  time: 0.1765  data: 0.0001  max mem: 15821
[21:05:54.422509] Test:  [320/345]  eta: 0:00:04  loss: 0.3028 (0.3047)  time: 0.1769  data: 0.0001  max mem: 15821
[21:05:56.198422] Test:  [330/345]  eta: 0:00:02  loss: 0.3008 (0.3049)  time: 0.1774  data: 0.0001  max mem: 15821
[21:05:57.976934] Test:  [340/345]  eta: 0:00:00  loss: 0.3008 (0.3051)  time: 0.1777  data: 0.0001  max mem: 15821
[21:05:58.688831] Test:  [344/345]  eta: 0:00:00  loss: 0.3013 (0.3052)  time: 0.1778  data: 0.0001  max mem: 15821
[21:05:58.774678] Test: Total time: 0:00:59 (0.1736 s / it)
[21:06:09.318223] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4845 (0.4845)  time: 0.5608  data: 0.3991  max mem: 15821
[21:06:10.964878] Test:  [10/57]  eta: 0:00:09  loss: 0.4280 (0.4521)  time: 0.2006  data: 0.0364  max mem: 15821
[21:06:12.617499] Test:  [20/57]  eta: 0:00:06  loss: 0.4227 (0.4250)  time: 0.1649  data: 0.0001  max mem: 15821
[21:06:14.272514] Test:  [30/57]  eta: 0:00:04  loss: 0.2974 (0.3765)  time: 0.1653  data: 0.0001  max mem: 15821
[21:06:15.933271] Test:  [40/57]  eta: 0:00:02  loss: 0.2854 (0.3557)  time: 0.1657  data: 0.0001  max mem: 15821
[21:06:17.597103] Test:  [50/57]  eta: 0:00:01  loss: 0.3091 (0.3557)  time: 0.1662  data: 0.0001  max mem: 15821
[21:06:18.494156] Test:  [56/57]  eta: 0:00:00  loss: 0.3358 (0.3677)  time: 0.1612  data: 0.0001  max mem: 15821
[21:06:18.572120] Test: Total time: 0:00:09 (0.1722 s / it)
[21:06:20.343299] Dice score of the network on the train images: 0.767319, val images: 0.764130
[21:06:20.343530] saving best_prec_model_0 @ epoch 8
[21:06:21.425603] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:06:22.405140] Epoch: [9]  [  0/345]  eta: 0:05:37  lr: 0.000056  loss: 0.3086 (0.3086)  time: 0.9786  data: 0.3785  max mem: 15821
[21:06:34.385341] Epoch: [9]  [ 20/345]  eta: 0:03:20  lr: 0.000057  loss: 0.3166 (0.3267)  time: 0.5990  data: 0.0001  max mem: 15821
[21:06:46.377084] Epoch: [9]  [ 40/345]  eta: 0:03:05  lr: 0.000057  loss: 0.3223 (0.3275)  time: 0.5995  data: 0.0001  max mem: 15821
[21:06:58.398984] Epoch: [9]  [ 60/345]  eta: 0:02:52  lr: 0.000057  loss: 0.3070 (0.3233)  time: 0.6011  data: 0.0001  max mem: 15821
[21:07:10.456830] Epoch: [9]  [ 80/345]  eta: 0:02:40  lr: 0.000058  loss: 0.3224 (0.3220)  time: 0.6029  data: 0.0001  max mem: 15821
[21:07:22.528852] Epoch: [9]  [100/345]  eta: 0:02:28  lr: 0.000058  loss: 0.3056 (0.3190)  time: 0.6036  data: 0.0001  max mem: 15821
[21:07:34.603503] Epoch: [9]  [120/345]  eta: 0:02:16  lr: 0.000058  loss: 0.3051 (0.3177)  time: 0.6037  data: 0.0001  max mem: 15821
[21:07:46.685356] Epoch: [9]  [140/345]  eta: 0:02:03  lr: 0.000059  loss: 0.2858 (0.3144)  time: 0.6041  data: 0.0001  max mem: 15821
[21:07:58.884977] Epoch: [9]  [160/345]  eta: 0:01:51  lr: 0.000059  loss: 0.3089 (0.3137)  time: 0.6099  data: 0.0001  max mem: 15821
[21:08:10.976079] Epoch: [9]  [180/345]  eta: 0:01:39  lr: 0.000060  loss: 0.3024 (0.3128)  time: 0.6045  data: 0.0001  max mem: 15821
[21:08:23.065255] Epoch: [9]  [200/345]  eta: 0:01:27  lr: 0.000060  loss: 0.2802 (0.3103)  time: 0.6044  data: 0.0001  max mem: 15821
[21:08:35.132214] Epoch: [9]  [220/345]  eta: 0:01:15  lr: 0.000060  loss: 0.3175 (0.3112)  time: 0.6033  data: 0.0001  max mem: 15821
[21:08:47.214579] Epoch: [9]  [240/345]  eta: 0:01:03  lr: 0.000061  loss: 0.2912 (0.3098)  time: 0.6041  data: 0.0001  max mem: 15821
[21:08:59.295694] Epoch: [9]  [260/345]  eta: 0:00:51  lr: 0.000061  loss: 0.3026 (0.3092)  time: 0.6040  data: 0.0001  max mem: 15821
[21:09:11.371667] Epoch: [9]  [280/345]  eta: 0:00:39  lr: 0.000061  loss: 0.3044 (0.3090)  time: 0.6037  data: 0.0001  max mem: 15821
[21:09:23.443279] Epoch: [9]  [300/345]  eta: 0:00:27  lr: 0.000062  loss: 0.3016 (0.3085)  time: 0.6035  data: 0.0001  max mem: 15821
[21:09:35.513053] Epoch: [9]  [320/345]  eta: 0:00:15  lr: 0.000062  loss: 0.2914 (0.3077)  time: 0.6034  data: 0.0001  max mem: 15821
[21:09:47.576714] Epoch: [9]  [340/345]  eta: 0:00:03  lr: 0.000062  loss: 0.2848 (0.3071)  time: 0.6031  data: 0.0001  max mem: 15821
[21:09:49.986959] Epoch: [9]  [344/345]  eta: 0:00:00  lr: 0.000062  loss: 0.2832 (0.3069)  time: 0.6028  data: 0.0001  max mem: 15821
[21:09:50.061773] Epoch: [9] Total time: 0:03:28 (0.6047 s / it)
[21:09:50.062004] Averaged stats: lr: 0.000062  loss: 0.2832 (0.3069)
[21:09:50.629136] Test:  [  0/345]  eta: 0:03:13  loss: 0.2688 (0.2688)  time: 0.5614  data: 0.3979  max mem: 15821
[21:09:52.295264] Test:  [ 10/345]  eta: 0:01:07  loss: 0.2543 (0.2605)  time: 0.2024  data: 0.0363  max mem: 15821
[21:09:53.964706] Test:  [ 20/345]  eta: 0:01:00  loss: 0.2604 (0.2721)  time: 0.1667  data: 0.0001  max mem: 15821
[21:09:55.637594] Test:  [ 30/345]  eta: 0:00:56  loss: 0.2763 (0.2716)  time: 0.1670  data: 0.0001  max mem: 15821
[21:09:57.313131] Test:  [ 40/345]  eta: 0:00:53  loss: 0.2803 (0.2758)  time: 0.1674  data: 0.0001  max mem: 15821
[21:09:58.992538] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2800 (0.2770)  time: 0.1677  data: 0.0001  max mem: 15821
[21:10:00.675551] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2760 (0.2783)  time: 0.1680  data: 0.0001  max mem: 15821
[21:10:02.360630] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2769 (0.2783)  time: 0.1683  data: 0.0001  max mem: 15821
[21:10:04.049801] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2793 (0.2815)  time: 0.1686  data: 0.0001  max mem: 15821
[21:10:05.741479] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2944 (0.2825)  time: 0.1690  data: 0.0001  max mem: 15821
[21:10:07.437587] Test:  [100/345]  eta: 0:00:42  loss: 0.2934 (0.2829)  time: 0.1693  data: 0.0001  max mem: 15821
[21:10:09.136083] Test:  [110/345]  eta: 0:00:40  loss: 0.2763 (0.2822)  time: 0.1697  data: 0.0001  max mem: 15821
[21:10:10.837940] Test:  [120/345]  eta: 0:00:38  loss: 0.2653 (0.2809)  time: 0.1699  data: 0.0001  max mem: 15821
[21:10:12.545188] Test:  [130/345]  eta: 0:00:36  loss: 0.2771 (0.2805)  time: 0.1704  data: 0.0001  max mem: 15821
[21:10:14.255427] Test:  [140/345]  eta: 0:00:35  loss: 0.2877 (0.2815)  time: 0.1708  data: 0.0001  max mem: 15821
[21:10:15.968458] Test:  [150/345]  eta: 0:00:33  loss: 0.2813 (0.2816)  time: 0.1711  data: 0.0001  max mem: 15821
[21:10:17.685835] Test:  [160/345]  eta: 0:00:31  loss: 0.2779 (0.2819)  time: 0.1714  data: 0.0001  max mem: 15821
[21:10:19.406282] Test:  [170/345]  eta: 0:00:30  loss: 0.2593 (0.2814)  time: 0.1718  data: 0.0001  max mem: 15821
[21:10:21.131429] Test:  [180/345]  eta: 0:00:28  loss: 0.2644 (0.2811)  time: 0.1722  data: 0.0001  max mem: 15821
[21:10:22.859232] Test:  [190/345]  eta: 0:00:26  loss: 0.2815 (0.2817)  time: 0.1726  data: 0.0001  max mem: 15821
[21:10:24.589695] Test:  [200/345]  eta: 0:00:24  loss: 0.2866 (0.2825)  time: 0.1728  data: 0.0001  max mem: 15821
[21:10:26.323515] Test:  [210/345]  eta: 0:00:23  loss: 0.2638 (0.2818)  time: 0.1731  data: 0.0001  max mem: 15821
[21:10:28.061232] Test:  [220/345]  eta: 0:00:21  loss: 0.2741 (0.2817)  time: 0.1735  data: 0.0001  max mem: 15821
[21:10:29.802696] Test:  [230/345]  eta: 0:00:19  loss: 0.2834 (0.2822)  time: 0.1739  data: 0.0001  max mem: 15821
[21:10:31.546156] Test:  [240/345]  eta: 0:00:18  loss: 0.2866 (0.2825)  time: 0.1742  data: 0.0001  max mem: 15821
[21:10:33.294065] Test:  [250/345]  eta: 0:00:16  loss: 0.2786 (0.2818)  time: 0.1745  data: 0.0001  max mem: 15821
[21:10:35.045713] Test:  [260/345]  eta: 0:00:14  loss: 0.2652 (0.2816)  time: 0.1749  data: 0.0001  max mem: 15821
[21:10:36.800425] Test:  [270/345]  eta: 0:00:12  loss: 0.2730 (0.2815)  time: 0.1753  data: 0.0001  max mem: 15821
[21:10:38.558746] Test:  [280/345]  eta: 0:00:11  loss: 0.2900 (0.2819)  time: 0.1756  data: 0.0001  max mem: 15821
[21:10:40.321182] Test:  [290/345]  eta: 0:00:09  loss: 0.2928 (0.2822)  time: 0.1760  data: 0.0001  max mem: 15821
[21:10:42.088046] Test:  [300/345]  eta: 0:00:07  loss: 0.2801 (0.2819)  time: 0.1764  data: 0.0001  max mem: 15821
[21:10:43.856736] Test:  [310/345]  eta: 0:00:06  loss: 0.2830 (0.2826)  time: 0.1767  data: 0.0001  max mem: 15821
[21:10:45.629765] Test:  [320/345]  eta: 0:00:04  loss: 0.2753 (0.2821)  time: 0.1770  data: 0.0001  max mem: 15821
[21:10:47.406571] Test:  [330/345]  eta: 0:00:02  loss: 0.2761 (0.2825)  time: 0.1774  data: 0.0001  max mem: 15821
[21:10:49.185065] Test:  [340/345]  eta: 0:00:00  loss: 0.2870 (0.2824)  time: 0.1777  data: 0.0001  max mem: 15821
[21:10:49.897043] Test:  [344/345]  eta: 0:00:00  loss: 0.2758 (0.2824)  time: 0.1778  data: 0.0001  max mem: 15821
[21:10:49.971802] Test: Total time: 0:00:59 (0.1736 s / it)
[21:11:00.624333] Test:  [ 0/57]  eta: 0:00:35  loss: 0.4708 (0.4708)  time: 0.6259  data: 0.4624  max mem: 15821
[21:11:02.269751] Test:  [10/57]  eta: 0:00:09  loss: 0.4359 (0.4468)  time: 0.2064  data: 0.0421  max mem: 15821
[21:11:03.922215] Test:  [20/57]  eta: 0:00:06  loss: 0.4103 (0.4182)  time: 0.1648  data: 0.0001  max mem: 15821
[21:11:05.576983] Test:  [30/57]  eta: 0:00:04  loss: 0.2772 (0.3676)  time: 0.1653  data: 0.0001  max mem: 15821
[21:11:07.236057] Test:  [40/57]  eta: 0:00:02  loss: 0.2701 (0.3456)  time: 0.1656  data: 0.0001  max mem: 15821
[21:11:08.899733] Test:  [50/57]  eta: 0:00:01  loss: 0.2984 (0.3438)  time: 0.1661  data: 0.0001  max mem: 15821
[21:11:09.797452] Test:  [56/57]  eta: 0:00:00  loss: 0.3237 (0.3529)  time: 0.1612  data: 0.0000  max mem: 15821
[21:11:09.878457] Test: Total time: 0:00:09 (0.1733 s / it)
[21:11:11.650115] Dice score of the network on the train images: 0.768679, val images: 0.770120
[21:11:11.650354] saving best_dice_model_0 @ epoch 9
[21:11:12.781136] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:11:13.766795] Epoch: [10]  [  0/345]  eta: 0:05:39  lr: 0.000063  loss: 0.2493 (0.2493)  time: 0.9846  data: 0.3852  max mem: 15821
[21:11:25.740280] Epoch: [10]  [ 20/345]  eta: 0:03:20  lr: 0.000063  loss: 0.3019 (0.2980)  time: 0.5986  data: 0.0001  max mem: 15821
[21:11:37.746868] Epoch: [10]  [ 40/345]  eta: 0:03:05  lr: 0.000063  loss: 0.2891 (0.2974)  time: 0.6003  data: 0.0001  max mem: 15821
[21:11:49.761408] Epoch: [10]  [ 60/345]  eta: 0:02:52  lr: 0.000064  loss: 0.2886 (0.2975)  time: 0.6007  data: 0.0001  max mem: 15821
[21:12:01.804073] Epoch: [10]  [ 80/345]  eta: 0:02:40  lr: 0.000064  loss: 0.2871 (0.2949)  time: 0.6021  data: 0.0001  max mem: 15821
[21:12:13.867335] Epoch: [10]  [100/345]  eta: 0:02:28  lr: 0.000064  loss: 0.2849 (0.2950)  time: 0.6031  data: 0.0001  max mem: 15821
[21:12:25.950917] Epoch: [10]  [120/345]  eta: 0:02:16  lr: 0.000065  loss: 0.2892 (0.2936)  time: 0.6041  data: 0.0001  max mem: 15821
[21:12:38.031682] Epoch: [10]  [140/345]  eta: 0:02:03  lr: 0.000065  loss: 0.3035 (0.2937)  time: 0.6040  data: 0.0001  max mem: 15821
[21:12:50.116425] Epoch: [10]  [160/345]  eta: 0:01:51  lr: 0.000065  loss: 0.2839 (0.2926)  time: 0.6042  data: 0.0001  max mem: 15821
[21:13:02.208379] Epoch: [10]  [180/345]  eta: 0:01:39  lr: 0.000066  loss: 0.2908 (0.2928)  time: 0.6045  data: 0.0001  max mem: 15821
[21:13:14.305202] Epoch: [10]  [200/345]  eta: 0:01:27  lr: 0.000066  loss: 0.2750 (0.2911)  time: 0.6048  data: 0.0001  max mem: 15821
[21:13:26.381348] Epoch: [10]  [220/345]  eta: 0:01:15  lr: 0.000066  loss: 0.2856 (0.2903)  time: 0.6038  data: 0.0001  max mem: 15821
[21:13:38.461491] Epoch: [10]  [240/345]  eta: 0:01:03  lr: 0.000067  loss: 0.2830 (0.2899)  time: 0.6040  data: 0.0001  max mem: 15821
[21:13:50.535447] Epoch: [10]  [260/345]  eta: 0:00:51  lr: 0.000067  loss: 0.2909 (0.2901)  time: 0.6036  data: 0.0001  max mem: 15821
[21:14:02.603906] Epoch: [10]  [280/345]  eta: 0:00:39  lr: 0.000068  loss: 0.2812 (0.2893)  time: 0.6034  data: 0.0001  max mem: 15821
[21:14:14.676736] Epoch: [10]  [300/345]  eta: 0:00:27  lr: 0.000068  loss: 0.2753 (0.2883)  time: 0.6036  data: 0.0001  max mem: 15821
[21:14:26.748253] Epoch: [10]  [320/345]  eta: 0:00:15  lr: 0.000068  loss: 0.2883 (0.2882)  time: 0.6035  data: 0.0001  max mem: 15821
[21:14:38.807885] Epoch: [10]  [340/345]  eta: 0:00:03  lr: 0.000069  loss: 0.2844 (0.2877)  time: 0.6029  data: 0.0001  max mem: 15821
[21:14:41.220671] Epoch: [10]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.2844 (0.2878)  time: 0.6029  data: 0.0001  max mem: 15821
[21:14:41.300452] Epoch: [10] Total time: 0:03:28 (0.6044 s / it)
[21:14:41.300675] Averaged stats: lr: 0.000069  loss: 0.2844 (0.2878)
[21:14:41.871274] Test:  [  0/345]  eta: 0:03:14  loss: 0.2525 (0.2525)  time: 0.5652  data: 0.4011  max mem: 15821
[21:14:43.537781] Test:  [ 10/345]  eta: 0:01:07  loss: 0.2601 (0.2573)  time: 0.2028  data: 0.0365  max mem: 15821
[21:14:45.206597] Test:  [ 20/345]  eta: 0:01:00  loss: 0.2601 (0.2577)  time: 0.1667  data: 0.0001  max mem: 15821
[21:14:46.879366] Test:  [ 30/345]  eta: 0:00:56  loss: 0.2682 (0.2639)  time: 0.1670  data: 0.0001  max mem: 15821
[21:14:48.554572] Test:  [ 40/345]  eta: 0:00:53  loss: 0.2657 (0.2622)  time: 0.1673  data: 0.0001  max mem: 15821
[21:14:50.233722] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2631 (0.2625)  time: 0.1677  data: 0.0001  max mem: 15821
[21:14:51.916487] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2722 (0.2646)  time: 0.1680  data: 0.0001  max mem: 15821
[21:14:53.602583] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2749 (0.2675)  time: 0.1684  data: 0.0001  max mem: 15821
[21:14:55.290983] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2681 (0.2670)  time: 0.1687  data: 0.0001  max mem: 15821
[21:14:56.983487] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2579 (0.2662)  time: 0.1690  data: 0.0001  max mem: 15821
[21:14:58.679427] Test:  [100/345]  eta: 0:00:42  loss: 0.2654 (0.2674)  time: 0.1693  data: 0.0001  max mem: 15821
[21:15:00.379929] Test:  [110/345]  eta: 0:00:40  loss: 0.2699 (0.2677)  time: 0.1698  data: 0.0001  max mem: 15821
[21:15:02.082567] Test:  [120/345]  eta: 0:00:38  loss: 0.2701 (0.2685)  time: 0.1701  data: 0.0001  max mem: 15821
[21:15:03.789021] Test:  [130/345]  eta: 0:00:36  loss: 0.2645 (0.2673)  time: 0.1704  data: 0.0001  max mem: 15821
[21:15:05.498441] Test:  [140/345]  eta: 0:00:35  loss: 0.2584 (0.2675)  time: 0.1707  data: 0.0001  max mem: 15821
[21:15:07.211274] Test:  [150/345]  eta: 0:00:33  loss: 0.2653 (0.2669)  time: 0.1710  data: 0.0001  max mem: 15821
[21:15:08.928521] Test:  [160/345]  eta: 0:00:31  loss: 0.2507 (0.2663)  time: 0.1714  data: 0.0001  max mem: 15821
[21:15:10.649659] Test:  [170/345]  eta: 0:00:30  loss: 0.2541 (0.2667)  time: 0.1719  data: 0.0001  max mem: 15821
[21:15:12.373590] Test:  [180/345]  eta: 0:00:28  loss: 0.2490 (0.2657)  time: 0.1722  data: 0.0001  max mem: 15821
[21:15:14.101050] Test:  [190/345]  eta: 0:00:26  loss: 0.2555 (0.2658)  time: 0.1725  data: 0.0001  max mem: 15821
[21:15:15.831252] Test:  [200/345]  eta: 0:00:24  loss: 0.2760 (0.2665)  time: 0.1728  data: 0.0001  max mem: 15821
[21:15:17.564945] Test:  [210/345]  eta: 0:00:23  loss: 0.2821 (0.2666)  time: 0.1731  data: 0.0001  max mem: 15821
[21:15:19.302382] Test:  [220/345]  eta: 0:00:21  loss: 0.2720 (0.2670)  time: 0.1735  data: 0.0001  max mem: 15821
[21:15:21.044065] Test:  [230/345]  eta: 0:00:19  loss: 0.2624 (0.2667)  time: 0.1739  data: 0.0001  max mem: 15821
[21:15:22.789355] Test:  [240/345]  eta: 0:00:18  loss: 0.2629 (0.2672)  time: 0.1743  data: 0.0001  max mem: 15821
[21:15:24.536953] Test:  [250/345]  eta: 0:00:16  loss: 0.2587 (0.2666)  time: 0.1746  data: 0.0001  max mem: 15821
[21:15:26.287688] Test:  [260/345]  eta: 0:00:14  loss: 0.2512 (0.2663)  time: 0.1748  data: 0.0001  max mem: 15821
[21:15:28.042825] Test:  [270/345]  eta: 0:00:12  loss: 0.2563 (0.2660)  time: 0.1752  data: 0.0001  max mem: 15821
[21:15:29.802791] Test:  [280/345]  eta: 0:00:11  loss: 0.2597 (0.2662)  time: 0.1757  data: 0.0001  max mem: 15821
[21:15:31.565227] Test:  [290/345]  eta: 0:00:09  loss: 0.2597 (0.2661)  time: 0.1761  data: 0.0001  max mem: 15821
[21:15:33.331033] Test:  [300/345]  eta: 0:00:07  loss: 0.2568 (0.2657)  time: 0.1763  data: 0.0001  max mem: 15821
[21:15:35.099904] Test:  [310/345]  eta: 0:00:06  loss: 0.2511 (0.2653)  time: 0.1767  data: 0.0001  max mem: 15821
[21:15:36.872696] Test:  [320/345]  eta: 0:00:04  loss: 0.2637 (0.2656)  time: 0.1770  data: 0.0001  max mem: 15821
[21:15:38.648087] Test:  [330/345]  eta: 0:00:02  loss: 0.2694 (0.2659)  time: 0.1773  data: 0.0001  max mem: 15821
[21:15:40.427895] Test:  [340/345]  eta: 0:00:00  loss: 0.2701 (0.2659)  time: 0.1777  data: 0.0001  max mem: 15821
[21:15:41.140895] Test:  [344/345]  eta: 0:00:00  loss: 0.2541 (0.2658)  time: 0.1779  data: 0.0001  max mem: 15821
[21:15:41.219266] Test: Total time: 0:00:59 (0.1737 s / it)
[21:15:51.690200] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4820 (0.4820)  time: 0.5204  data: 0.3583  max mem: 15821
[21:15:53.336854] Test:  [10/57]  eta: 0:00:09  loss: 0.4570 (0.4668)  time: 0.1969  data: 0.0327  max mem: 15821
[21:15:54.988448] Test:  [20/57]  eta: 0:00:06  loss: 0.4135 (0.4386)  time: 0.1648  data: 0.0001  max mem: 15821
[21:15:56.643619] Test:  [30/57]  eta: 0:00:04  loss: 0.2878 (0.3823)  time: 0.1653  data: 0.0001  max mem: 15821
[21:15:58.304404] Test:  [40/57]  eta: 0:00:02  loss: 0.2608 (0.3560)  time: 0.1657  data: 0.0001  max mem: 15821
[21:15:59.968226] Test:  [50/57]  eta: 0:00:01  loss: 0.2855 (0.3513)  time: 0.1662  data: 0.0001  max mem: 15821
[21:16:00.866249] Test:  [56/57]  eta: 0:00:00  loss: 0.3377 (0.3647)  time: 0.1613  data: 0.0000  max mem: 15821
[21:16:00.944496] Test: Total time: 0:00:09 (0.1715 s / it)
[21:16:02.729191] Dice score of the network on the train images: 0.785973, val images: 0.785892
[21:16:02.730437] saving best_prec_model_0 @ epoch 10
[21:16:04.176288] saving best_dice_model_0 @ epoch 10
[21:16:05.237885] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:16:06.228374] Epoch: [11]  [  0/345]  eta: 0:05:41  lr: 0.000069  loss: 0.3251 (0.3251)  time: 0.9892  data: 0.3897  max mem: 15821
[21:16:18.189259] Epoch: [11]  [ 20/345]  eta: 0:03:20  lr: 0.000069  loss: 0.2632 (0.2716)  time: 0.5980  data: 0.0001  max mem: 15821
[21:16:30.186790] Epoch: [11]  [ 40/345]  eta: 0:03:05  lr: 0.000069  loss: 0.2611 (0.2674)  time: 0.5998  data: 0.0001  max mem: 15821
[21:16:42.197945] Epoch: [11]  [ 60/345]  eta: 0:02:52  lr: 0.000070  loss: 0.2625 (0.2677)  time: 0.6005  data: 0.0001  max mem: 15821
[21:16:54.246971] Epoch: [11]  [ 80/345]  eta: 0:02:40  lr: 0.000070  loss: 0.2557 (0.2667)  time: 0.6024  data: 0.0001  max mem: 15821
[21:17:06.323515] Epoch: [11]  [100/345]  eta: 0:02:28  lr: 0.000071  loss: 0.2416 (0.2637)  time: 0.6038  data: 0.0001  max mem: 15821
[21:17:18.418023] Epoch: [11]  [120/345]  eta: 0:02:16  lr: 0.000071  loss: 0.2609 (0.2647)  time: 0.6047  data: 0.0001  max mem: 15821
[21:17:30.510780] Epoch: [11]  [140/345]  eta: 0:02:03  lr: 0.000071  loss: 0.2810 (0.2675)  time: 0.6046  data: 0.0001  max mem: 15821
[21:17:42.595166] Epoch: [11]  [160/345]  eta: 0:01:51  lr: 0.000072  loss: 0.2641 (0.2674)  time: 0.6042  data: 0.0001  max mem: 15821

[21:17:54.678266] Epoch: [11]  [180/345]  eta: 0:01:39  lr: 0.000072  loss: 0.2582 (0.2678)  time: 0.6041  data: 0.0001  max mem: 15821
[21:18:06.759513] Epoch: [11]  [200/345]  eta: 0:01:27  lr: 0.000072  loss: 0.2711 (0.2679)  time: 0.6040  data: 0.0001  max mem: 15821
[21:18:18.823447] Epoch: [11]  [220/345]  eta: 0:01:15  lr: 0.000073  loss: 0.2608 (0.2681)  time: 0.6031  data: 0.0001  max mem: 15821
[21:18:30.880048] Epoch: [11]  [240/345]  eta: 0:01:03  lr: 0.000073  loss: 0.2838 (0.2687)  time: 0.6028  data: 0.0001  max mem: 15821
[21:18:42.942764] Epoch: [11]  [260/345]  eta: 0:00:51  lr: 0.000073  loss: 0.2816 (0.2703)  time: 0.6031  data: 0.0001  max mem: 15821
[21:18:54.988977] Epoch: [11]  [280/345]  eta: 0:00:39  lr: 0.000074  loss: 0.2760 (0.2702)  time: 0.6023  data: 0.0001  max mem: 15821
[21:19:07.036910] Epoch: [11]  [300/345]  eta: 0:00:27  lr: 0.000074  loss: 0.2748 (0.2699)  time: 0.6023  data: 0.0001  max mem: 15821
[21:19:19.089643] Epoch: [11]  [320/345]  eta: 0:00:15  lr: 0.000075  loss: 0.2605 (0.2697)  time: 0.6026  data: 0.0001  max mem: 15821
[21:19:31.138553] Epoch: [11]  [340/345]  eta: 0:00:03  lr: 0.000075  loss: 0.2686 (0.2696)  time: 0.6024  data: 0.0001  max mem: 15821
[21:19:33.548994] Epoch: [11]  [344/345]  eta: 0:00:00  lr: 0.000075  loss: 0.2652 (0.2694)  time: 0.6023  data: 0.0001  max mem: 15821
[21:19:33.616377] Epoch: [11] Total time: 0:03:28 (0.6040 s / it)
[21:19:33.616710] Averaged stats: lr: 0.000075  loss: 0.2652 (0.2694)
[21:19:34.192879] Test:  [  0/345]  eta: 0:03:16  loss: 0.2426 (0.2426)  time: 0.5707  data: 0.4068  max mem: 15821
[21:19:35.857587] Test:  [ 10/345]  eta: 0:01:08  loss: 0.2418 (0.2469)  time: 0.2031  data: 0.0371  max mem: 15821
[21:19:37.526725] Test:  [ 20/345]  eta: 0:01:00  loss: 0.2408 (0.2443)  time: 0.1666  data: 0.0001  max mem: 15821
[21:19:39.199007] Test:  [ 30/345]  eta: 0:00:56  loss: 0.2308 (0.2427)  time: 0.1670  data: 0.0001  max mem: 15821
[21:19:40.874460] Test:  [ 40/345]  eta: 0:00:53  loss: 0.2414 (0.2440)  time: 0.1673  data: 0.0001  max mem: 15821
[21:19:42.554129] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2495 (0.2475)  time: 0.1677  data: 0.0001  max mem: 15821
[21:19:44.237380] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2558 (0.2483)  time: 0.1681  data: 0.0001  max mem: 15821
[21:19:45.921835] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2554 (0.2496)  time: 0.1683  data: 0.0001  max mem: 15821
[21:19:47.610910] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2593 (0.2520)  time: 0.1686  data: 0.0001  max mem: 15821
[21:19:49.303257] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2705 (0.2536)  time: 0.1690  data: 0.0001  max mem: 15821
[21:19:50.999204] Test:  [100/345]  eta: 0:00:42  loss: 0.2686 (0.2549)  time: 0.1693  data: 0.0001  max mem: 15821
[21:19:52.698163] Test:  [110/345]  eta: 0:00:40  loss: 0.2403 (0.2527)  time: 0.1697  data: 0.0001  max mem: 15821
[21:19:54.399620] Test:  [120/345]  eta: 0:00:38  loss: 0.2403 (0.2532)  time: 0.1700  data: 0.0001  max mem: 15821
[21:19:56.105162] Test:  [130/345]  eta: 0:00:36  loss: 0.2440 (0.2527)  time: 0.1703  data: 0.0001  max mem: 15821
[21:19:57.814226] Test:  [140/345]  eta: 0:00:35  loss: 0.2478 (0.2523)  time: 0.1707  data: 0.0001  max mem: 15821
[21:19:59.526418] Test:  [150/345]  eta: 0:00:33  loss: 0.2519 (0.2531)  time: 0.1710  data: 0.0001  max mem: 15821
[21:20:01.242586] Test:  [160/345]  eta: 0:00:31  loss: 0.2519 (0.2534)  time: 0.1714  data: 0.0001  max mem: 15821
[21:20:02.962746] Test:  [170/345]  eta: 0:00:30  loss: 0.2519 (0.2532)  time: 0.1717  data: 0.0001  max mem: 15821
[21:20:04.685603] Test:  [180/345]  eta: 0:00:28  loss: 0.2473 (0.2527)  time: 0.1721  data: 0.0001  max mem: 15821
[21:20:06.412591] Test:  [190/345]  eta: 0:00:26  loss: 0.2489 (0.2526)  time: 0.1724  data: 0.0001  max mem: 15821
[21:20:08.143010] Test:  [200/345]  eta: 0:00:24  loss: 0.2583 (0.2532)  time: 0.1728  data: 0.0001  max mem: 15821
[21:20:09.877342] Test:  [210/345]  eta: 0:00:23  loss: 0.2613 (0.2531)  time: 0.1732  data: 0.0001  max mem: 15821
[21:20:11.615238] Test:  [220/345]  eta: 0:00:21  loss: 0.2442 (0.2527)  time: 0.1735  data: 0.0001  max mem: 15821
[21:20:13.357659] Test:  [230/345]  eta: 0:00:19  loss: 0.2496 (0.2529)  time: 0.1739  data: 0.0001  max mem: 15821
[21:20:15.101331] Test:  [240/345]  eta: 0:00:18  loss: 0.2537 (0.2534)  time: 0.1742  data: 0.0001  max mem: 15821
[21:20:16.849712] Test:  [250/345]  eta: 0:00:16  loss: 0.2543 (0.2533)  time: 0.1745  data: 0.0001  max mem: 15821
[21:20:18.600945] Test:  [260/345]  eta: 0:00:14  loss: 0.2534 (0.2535)  time: 0.1749  data: 0.0001  max mem: 15821
[21:20:20.355333] Test:  [270/345]  eta: 0:00:12  loss: 0.2534 (0.2534)  time: 0.1752  data: 0.0001  max mem: 15821
[21:20:22.112164] Test:  [280/345]  eta: 0:00:11  loss: 0.2434 (0.2530)  time: 0.1755  data: 0.0001  max mem: 15821
[21:20:23.874190] Test:  [290/345]  eta: 0:00:09  loss: 0.2399 (0.2530)  time: 0.1759  data: 0.0001  max mem: 15821
[21:20:25.639270] Test:  [300/345]  eta: 0:00:07  loss: 0.2564 (0.2532)  time: 0.1763  data: 0.0001  max mem: 15821
[21:20:27.406671] Test:  [310/345]  eta: 0:00:06  loss: 0.2564 (0.2532)  time: 0.1766  data: 0.0001  max mem: 15821
[21:20:29.179035] Test:  [320/345]  eta: 0:00:04  loss: 0.2476 (0.2534)  time: 0.1769  data: 0.0001  max mem: 15821
[21:20:30.954297] Test:  [330/345]  eta: 0:00:02  loss: 0.2476 (0.2534)  time: 0.1773  data: 0.0001  max mem: 15821
[21:20:32.733021] Test:  [340/345]  eta: 0:00:00  loss: 0.2500 (0.2534)  time: 0.1776  data: 0.0001  max mem: 15821
[21:20:33.445327] Test:  [344/345]  eta: 0:00:00  loss: 0.2457 (0.2533)  time: 0.1778  data: 0.0001  max mem: 15821
[21:20:33.525350] Test: Total time: 0:00:59 (0.1736 s / it)
[21:20:44.006995] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4768 (0.4768)  time: 0.5352  data: 0.3729  max mem: 15821
[21:20:45.652426] Test:  [10/57]  eta: 0:00:09  loss: 0.4206 (0.4349)  time: 0.1981  data: 0.0340  max mem: 15821
[21:20:47.305397] Test:  [20/57]  eta: 0:00:06  loss: 0.4006 (0.4168)  time: 0.1648  data: 0.0001  max mem: 15821
[21:20:48.960225] Test:  [30/57]  eta: 0:00:04  loss: 0.2807 (0.3649)  time: 0.1653  data: 0.0001  max mem: 15821
[21:20:50.620093] Test:  [40/57]  eta: 0:00:02  loss: 0.2622 (0.3420)  time: 0.1657  data: 0.0001  max mem: 15821
[21:20:52.283370] Test:  [50/57]  eta: 0:00:01  loss: 0.2814 (0.3381)  time: 0.1661  data: 0.0001  max mem: 15821
[21:20:53.180706] Test:  [56/57]  eta: 0:00:00  loss: 0.2941 (0.3482)  time: 0.1612  data: 0.0000  max mem: 15821
[21:20:53.259336] Test: Total time: 0:00:09 (0.1717 s / it)
[21:20:55.046382] Dice score of the network on the train images: 0.783462, val images: 0.779743
[21:20:55.050487] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:20:56.021470] Epoch: [12]  [  0/345]  eta: 0:05:34  lr: 0.000075  loss: 0.2565 (0.2565)  time: 0.9702  data: 0.3687  max mem: 15821
[21:21:08.012864] Epoch: [12]  [ 20/345]  eta: 0:03:20  lr: 0.000075  loss: 0.2356 (0.2470)  time: 0.5995  data: 0.0001  max mem: 15821
[21:21:20.009559] Epoch: [12]  [ 40/345]  eta: 0:03:05  lr: 0.000076  loss: 0.2583 (0.2572)  time: 0.5998  data: 0.0001  max mem: 15821
[21:21:32.011098] Epoch: [12]  [ 60/345]  eta: 0:02:52  lr: 0.000076  loss: 0.2517 (0.2555)  time: 0.6000  data: 0.0001  max mem: 15821
[21:21:44.064612] Epoch: [12]  [ 80/345]  eta: 0:02:40  lr: 0.000076  loss: 0.2703 (0.2585)  time: 0.6026  data: 0.0001  max mem: 15821
[21:21:56.127631] Epoch: [12]  [100/345]  eta: 0:02:28  lr: 0.000077  loss: 0.2440 (0.2567)  time: 0.6031  data: 0.0001  max mem: 15821
[21:22:08.218189] Epoch: [12]  [120/345]  eta: 0:02:16  lr: 0.000077  loss: 0.2569 (0.2573)  time: 0.6045  data: 0.0001  max mem: 15821
[21:22:20.300658] Epoch: [12]  [140/345]  eta: 0:02:03  lr: 0.000078  loss: 0.2420 (0.2563)  time: 0.6041  data: 0.0001  max mem: 15821
[21:22:32.402166] Epoch: [12]  [160/345]  eta: 0:01:51  lr: 0.000078  loss: 0.2488 (0.2562)  time: 0.6050  data: 0.0001  max mem: 15821
[21:22:44.506775] Epoch: [12]  [180/345]  eta: 0:01:39  lr: 0.000078  loss: 0.2607 (0.2573)  time: 0.6052  data: 0.0001  max mem: 15821
[21:22:56.585241] Epoch: [12]  [200/345]  eta: 0:01:27  lr: 0.000079  loss: 0.2675 (0.2582)  time: 0.6039  data: 0.0001  max mem: 15821
[21:23:08.658399] Epoch: [12]  [220/345]  eta: 0:01:15  lr: 0.000079  loss: 0.2537 (0.2580)  time: 0.6036  data: 0.0001  max mem: 15821
[21:23:20.748327] Epoch: [12]  [240/345]  eta: 0:01:03  lr: 0.000079  loss: 0.2663 (0.2587)  time: 0.6044  data: 0.0001  max mem: 15821
[21:23:32.817408] Epoch: [12]  [260/345]  eta: 0:00:51  lr: 0.000080  loss: 0.2511 (0.2584)  time: 0.6034  data: 0.0001  max mem: 15821
[21:23:44.901701] Epoch: [12]  [280/345]  eta: 0:00:39  lr: 0.000080  loss: 0.2573 (0.2579)  time: 0.6042  data: 0.0001  max mem: 15821
[21:23:56.981704] Epoch: [12]  [300/345]  eta: 0:00:27  lr: 0.000080  loss: 0.2572 (0.2581)  time: 0.6039  data: 0.0001  max mem: 15821
[21:24:09.055612] Epoch: [12]  [320/345]  eta: 0:00:15  lr: 0.000081  loss: 0.2510 (0.2582)  time: 0.6036  data: 0.0001  max mem: 15821

[21:24:21.125580] Epoch: [12]  [340/345]  eta: 0:00:03  lr: 0.000081  loss: 0.2680 (0.2586)  time: 0.6035  data: 0.0001  max mem: 15821
[21:24:23.538593] Epoch: [12]  [344/345]  eta: 0:00:00  lr: 0.000081  loss: 0.2680 (0.2585)  time: 0.6035  data: 0.0001  max mem: 15821
[21:24:23.610480] Epoch: [12] Total time: 0:03:28 (0.6045 s / it)
[21:24:23.610718] Averaged stats: lr: 0.000081  loss: 0.2680 (0.2585)
[21:24:24.195532] Test:  [  0/345]  eta: 0:03:19  loss: 0.2545 (0.2545)  time: 0.5792  data: 0.4144  max mem: 15821
[21:24:25.862281] Test:  [ 10/345]  eta: 0:01:08  loss: 0.2374 (0.2449)  time: 0.2041  data: 0.0378  max mem: 15821
[21:24:27.530958] Test:  [ 20/345]  eta: 0:01:00  loss: 0.2412 (0.2469)  time: 0.1667  data: 0.0001  max mem: 15821
[21:24:29.203335] Test:  [ 30/345]  eta: 0:00:56  loss: 0.2386 (0.2411)  time: 0.1670  data: 0.0001  max mem: 15821
[21:24:30.878242] Test:  [ 40/345]  eta: 0:00:53  loss: 0.2335 (0.2410)  time: 0.1673  data: 0.0001  max mem: 15821
[21:24:32.557012] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2376 (0.2421)  time: 0.1676  data: 0.0001  max mem: 15821
[21:24:34.238817] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2239 (0.2404)  time: 0.1680  data: 0.0001  max mem: 15821
[21:24:35.924706] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2324 (0.2407)  time: 0.1683  data: 0.0001  max mem: 15821
[21:24:37.614003] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2324 (0.2402)  time: 0.1687  data: 0.0001  max mem: 15821
[21:24:39.308086] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2315 (0.2405)  time: 0.1691  data: 0.0001  max mem: 15821
[21:24:41.003777] Test:  [100/345]  eta: 0:00:42  loss: 0.2304 (0.2406)  time: 0.1694  data: 0.0001  max mem: 15821
[21:24:42.704175] Test:  [110/345]  eta: 0:00:40  loss: 0.2277 (0.2401)  time: 0.1697  data: 0.0001  max mem: 15821
[21:24:44.405571] Test:  [120/345]  eta: 0:00:38  loss: 0.2332 (0.2408)  time: 0.1700  data: 0.0001  max mem: 15821
[21:24:46.111203] Test:  [130/345]  eta: 0:00:36  loss: 0.2376 (0.2406)  time: 0.1703  data: 0.0001  max mem: 15821
[21:24:47.819652] Test:  [140/345]  eta: 0:00:35  loss: 0.2376 (0.2410)  time: 0.1706  data: 0.0001  max mem: 15821
[21:24:49.534359] Test:  [150/345]  eta: 0:00:33  loss: 0.2428 (0.2412)  time: 0.1711  data: 0.0001  max mem: 15821
[21:24:51.250247] Test:  [160/345]  eta: 0:00:31  loss: 0.2343 (0.2415)  time: 0.1715  data: 0.0001  max mem: 15821
[21:24:52.970218] Test:  [170/345]  eta: 0:00:30  loss: 0.2294 (0.2407)  time: 0.1717  data: 0.0001  max mem: 15821
[21:24:54.692811] Test:  [180/345]  eta: 0:00:28  loss: 0.2359 (0.2409)  time: 0.1721  data: 0.0001  max mem: 15821
[21:24:56.419225] Test:  [190/345]  eta: 0:00:26  loss: 0.2409 (0.2413)  time: 0.1724  data: 0.0001  max mem: 15821
[21:24:58.150328] Test:  [200/345]  eta: 0:00:24  loss: 0.2322 (0.2413)  time: 0.1728  data: 0.0001  max mem: 15821
[21:24:59.884275] Test:  [210/345]  eta: 0:00:23  loss: 0.2401 (0.2414)  time: 0.1732  data: 0.0001  max mem: 15821
[21:25:01.621331] Test:  [220/345]  eta: 0:00:21  loss: 0.2488 (0.2418)  time: 0.1735  data: 0.0001  max mem: 15821
[21:25:03.362323] Test:  [230/345]  eta: 0:00:19  loss: 0.2535 (0.2426)  time: 0.1738  data: 0.0001  max mem: 15821
[21:25:05.107278] Test:  [240/345]  eta: 0:00:18  loss: 0.2301 (0.2420)  time: 0.1742  data: 0.0001  max mem: 15821
[21:25:06.855360] Test:  [250/345]  eta: 0:00:16  loss: 0.2243 (0.2421)  time: 0.1746  data: 0.0001  max mem: 15821
[21:25:08.607913] Test:  [260/345]  eta: 0:00:14  loss: 0.2240 (0.2416)  time: 0.1750  data: 0.0001  max mem: 15821
[21:25:10.362360] Test:  [270/345]  eta: 0:00:12  loss: 0.2307 (0.2423)  time: 0.1753  data: 0.0001  max mem: 15821
[21:25:12.119123] Test:  [280/345]  eta: 0:00:11  loss: 0.2345 (0.2420)  time: 0.1755  data: 0.0001  max mem: 15821
[21:25:13.880249] Test:  [290/345]  eta: 0:00:09  loss: 0.2456 (0.2425)  time: 0.1758  data: 0.0001  max mem: 15821
[21:25:15.646378] Test:  [300/345]  eta: 0:00:07  loss: 0.2419 (0.2425)  time: 0.1763  data: 0.0001  max mem: 15821
[21:25:17.414481] Test:  [310/345]  eta: 0:00:06  loss: 0.2355 (0.2422)  time: 0.1766  data: 0.0001  max mem: 15821
[21:25:19.186705] Test:  [320/345]  eta: 0:00:04  loss: 0.2326 (0.2423)  time: 0.1770  data: 0.0001  max mem: 15821
[21:25:20.962289] Test:  [330/345]  eta: 0:00:02  loss: 0.2303 (0.2419)  time: 0.1773  data: 0.0001  max mem: 15821
[21:25:22.741294] Test:  [340/345]  eta: 0:00:00  loss: 0.2154 (0.2414)  time: 0.1777  data: 0.0001  max mem: 15821
[21:25:23.453466] Test:  [344/345]  eta: 0:00:00  loss: 0.2164 (0.2413)  time: 0.1778  data: 0.0001  max mem: 15821
[21:25:23.524497] Test: Total time: 0:00:59 (0.1736 s / it)
[21:25:34.013508] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4787 (0.4787)  time: 0.5268  data: 0.3644  max mem: 15821
[21:25:35.658321] Test:  [10/57]  eta: 0:00:09  loss: 0.4232 (0.4599)  time: 0.1973  data: 0.0332  max mem: 15821
[21:25:37.310487] Test:  [20/57]  eta: 0:00:06  loss: 0.4078 (0.4282)  time: 0.1648  data: 0.0001  max mem: 15821
[21:25:38.965146] Test:  [30/57]  eta: 0:00:04  loss: 0.2754 (0.3726)  time: 0.1653  data: 0.0001  max mem: 15821
[21:25:40.623939] Test:  [40/57]  eta: 0:00:02  loss: 0.2494 (0.3464)  time: 0.1656  data: 0.0001  max mem: 15821
[21:25:42.286564] Test:  [50/57]  eta: 0:00:01  loss: 0.2717 (0.3438)  time: 0.1660  data: 0.0001  max mem: 15821
[21:25:43.183581] Test:  [56/57]  eta: 0:00:00  loss: 0.3100 (0.3564)  time: 0.1611  data: 0.0001  max mem: 15821
[21:25:43.256099] Test: Total time: 0:00:09 (0.1714 s / it)
[21:25:45.009547] Dice score of the network on the train images: 0.790534, val images: 0.772920
[21:25:45.013725] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:25:45.977925] Epoch: [13]  [  0/345]  eta: 0:05:32  lr: 0.000081  loss: 0.2336 (0.2336)  time: 0.9633  data: 0.3638  max mem: 15821
[21:25:57.959657] Epoch: [13]  [ 20/345]  eta: 0:03:20  lr: 0.000082  loss: 0.2335 (0.2503)  time: 0.5990  data: 0.0001  max mem: 15821
[21:26:10.084760] Epoch: [13]  [ 40/345]  eta: 0:03:06  lr: 0.000082  loss: 0.2430 (0.2512)  time: 0.6062  data: 0.0001  max mem: 15821
[21:26:22.117370] Epoch: [13]  [ 60/345]  eta: 0:02:53  lr: 0.000082  loss: 0.2436 (0.2512)  time: 0.6016  data: 0.0001  max mem: 15821
[21:26:34.175525] Epoch: [13]  [ 80/345]  eta: 0:02:40  lr: 0.000083  loss: 0.2416 (0.2498)  time: 0.6029  data: 0.0001  max mem: 15821
[21:26:46.240366] Epoch: [13]  [100/345]  eta: 0:02:28  lr: 0.000083  loss: 0.2550 (0.2509)  time: 0.6032  data: 0.0001  max mem: 15821
[21:26:58.322757] Epoch: [13]  [120/345]  eta: 0:02:16  lr: 0.000083  loss: 0.2413 (0.2506)  time: 0.6041  data: 0.0001  max mem: 15821
[21:27:10.403068] Epoch: [13]  [140/345]  eta: 0:02:04  lr: 0.000084  loss: 0.2556 (0.2521)  time: 0.6040  data: 0.0001  max mem: 15821
[21:27:22.505863] Epoch: [13]  [160/345]  eta: 0:01:52  lr: 0.000084  loss: 0.2248 (0.2498)  time: 0.6051  data: 0.0001  max mem: 15821
[21:27:34.600088] Epoch: [13]  [180/345]  eta: 0:01:39  lr: 0.000085  loss: 0.2366 (0.2485)  time: 0.6047  data: 0.0001  max mem: 15821
[21:27:46.697790] Epoch: [13]  [200/345]  eta: 0:01:27  lr: 0.000085  loss: 0.2277 (0.2471)  time: 0.6048  data: 0.0001  max mem: 15821
[21:27:58.794506] Epoch: [13]  [220/345]  eta: 0:01:15  lr: 0.000085  loss: 0.2409 (0.2467)  time: 0.6048  data: 0.0001  max mem: 15821
[21:28:10.877041] Epoch: [13]  [240/345]  eta: 0:01:03  lr: 0.000086  loss: 0.2495 (0.2473)  time: 0.6041  data: 0.0001  max mem: 15821
[21:28:22.949912] Epoch: [13]  [260/345]  eta: 0:00:51  lr: 0.000086  loss: 0.2368 (0.2472)  time: 0.6036  data: 0.0001  max mem: 15821
[21:28:35.021508] Epoch: [13]  [280/345]  eta: 0:00:39  lr: 0.000086  loss: 0.2445 (0.2475)  time: 0.6035  data: 0.0001  max mem: 15821
[21:28:47.083438] Epoch: [13]  [300/345]  eta: 0:00:27  lr: 0.000087  loss: 0.2810 (0.2495)  time: 0.6030  data: 0.0001  max mem: 15821
[21:28:59.158337] Epoch: [13]  [320/345]  eta: 0:00:15  lr: 0.000087  loss: 0.2491 (0.2497)  time: 0.6037  data: 0.0001  max mem: 15821
[21:29:11.223435] Epoch: [13]  [340/345]  eta: 0:00:03  lr: 0.000087  loss: 0.2556 (0.2500)  time: 0.6032  data: 0.0001  max mem: 15821
[21:29:13.638189] Epoch: [13]  [344/345]  eta: 0:00:00  lr: 0.000087  loss: 0.2541 (0.2501)  time: 0.6033  data: 0.0001  max mem: 15821
[21:29:13.715875] Epoch: [13] Total time: 0:03:28 (0.6049 s / it)
[21:29:13.716101] Averaged stats: lr: 0.000087  loss: 0.2541 (0.2501)
[21:29:14.282629] Test:  [  0/345]  eta: 0:03:13  loss: 0.2364 (0.2364)  time: 0.5611  data: 0.3967  max mem: 15821
[21:29:15.949021] Test:  [ 10/345]  eta: 0:01:07  loss: 0.2364 (0.2348)  time: 0.2024  data: 0.0361  max mem: 15821
[21:29:17.618264] Test:  [ 20/345]  eta: 0:01:00  loss: 0.2403 (0.2383)  time: 0.1667  data: 0.0001  max mem: 15821
[21:29:19.290514] Test:  [ 30/345]  eta: 0:00:56  loss: 0.2434 (0.2416)  time: 0.1670  data: 0.0001  max mem: 15821
[21:29:20.967051] Test:  [ 40/345]  eta: 0:00:53  loss: 0.2434 (0.2407)  time: 0.1674  data: 0.0001  max mem: 15821
[21:29:22.645809] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2310 (0.2377)  time: 0.1677  data: 0.0001  max mem: 15821
[21:29:24.328244] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2310 (0.2371)  time: 0.1680  data: 0.0001  max mem: 15821
[21:29:26.013693] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2331 (0.2364)  time: 0.1683  data: 0.0001  max mem: 15821
[21:29:27.701653] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2235 (0.2348)  time: 0.1686  data: 0.0001  max mem: 15821
[21:29:29.396163] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2269 (0.2356)  time: 0.1691  data: 0.0001  max mem: 15821
[21:29:31.094013] Test:  [100/345]  eta: 0:00:42  loss: 0.2355 (0.2354)  time: 0.1696  data: 0.0001  max mem: 15821
[21:29:32.795465] Test:  [110/345]  eta: 0:00:40  loss: 0.2355 (0.2357)  time: 0.1699  data: 0.0001  max mem: 15821
[21:29:34.498217] Test:  [120/345]  eta: 0:00:38  loss: 0.2387 (0.2362)  time: 0.1701  data: 0.0001  max mem: 15821
[21:29:36.204308] Test:  [130/345]  eta: 0:00:36  loss: 0.2259 (0.2353)  time: 0.1704  data: 0.0001  max mem: 15821
[21:29:37.914691] Test:  [140/345]  eta: 0:00:35  loss: 0.2257 (0.2348)  time: 0.1708  data: 0.0001  max mem: 15821
[21:29:39.626767] Test:  [150/345]  eta: 0:00:33  loss: 0.2304 (0.2345)  time: 0.1711  data: 0.0001  max mem: 15821
[21:29:41.344968] Test:  [160/345]  eta: 0:00:31  loss: 0.2254 (0.2339)  time: 0.1715  data: 0.0001  max mem: 15821
[21:29:43.065885] Test:  [170/345]  eta: 0:00:30  loss: 0.2291 (0.2342)  time: 0.1719  data: 0.0001  max mem: 15821
[21:29:44.790097] Test:  [180/345]  eta: 0:00:28  loss: 0.2507 (0.2348)  time: 0.1722  data: 0.0001  max mem: 15821
[21:29:46.517640] Test:  [190/345]  eta: 0:00:26  loss: 0.2312 (0.2342)  time: 0.1725  data: 0.0001  max mem: 15821
[21:29:48.248886] Test:  [200/345]  eta: 0:00:24  loss: 0.2252 (0.2340)  time: 0.1729  data: 0.0001  max mem: 15821
[21:29:49.983261] Test:  [210/345]  eta: 0:00:23  loss: 0.2368 (0.2338)  time: 0.1732  data: 0.0001  max mem: 15821
[21:29:51.722831] Test:  [220/345]  eta: 0:00:21  loss: 0.2255 (0.2335)  time: 0.1736  data: 0.0001  max mem: 15821
[21:29:53.463605] Test:  [230/345]  eta: 0:00:19  loss: 0.2236 (0.2335)  time: 0.1739  data: 0.0001  max mem: 15821
[21:29:55.207369] Test:  [240/345]  eta: 0:00:18  loss: 0.2334 (0.2344)  time: 0.1742  data: 0.0001  max mem: 15821
[21:29:56.957278] Test:  [250/345]  eta: 0:00:16  loss: 0.2504 (0.2348)  time: 0.1746  data: 0.0001  max mem: 15821
[21:29:58.708806] Test:  [260/345]  eta: 0:00:14  loss: 0.2354 (0.2348)  time: 0.1750  data: 0.0001  max mem: 15821
[21:30:00.462688] Test:  [270/345]  eta: 0:00:12  loss: 0.2303 (0.2349)  time: 0.1752  data: 0.0001  max mem: 15821
[21:30:02.221179] Test:  [280/345]  eta: 0:00:11  loss: 0.2374 (0.2351)  time: 0.1756  data: 0.0001  max mem: 15821
[21:30:03.983077] Test:  [290/345]  eta: 0:00:09  loss: 0.2395 (0.2350)  time: 0.1760  data: 0.0001  max mem: 15821
[21:30:05.749433] Test:  [300/345]  eta: 0:00:07  loss: 0.2296 (0.2349)  time: 0.1764  data: 0.0001  max mem: 15821
[21:30:07.518779] Test:  [310/345]  eta: 0:00:06  loss: 0.2252 (0.2348)  time: 0.1767  data: 0.0001  max mem: 15821
[21:30:09.292163] Test:  [320/345]  eta: 0:00:04  loss: 0.2360 (0.2353)  time: 0.1771  data: 0.0001  max mem: 15821
[21:30:11.070144] Test:  [330/345]  eta: 0:00:02  loss: 0.2409 (0.2355)  time: 0.1775  data: 0.0001  max mem: 15821
[21:30:12.850473] Test:  [340/345]  eta: 0:00:00  loss: 0.2325 (0.2357)  time: 0.1779  data: 0.0001  max mem: 15821
[21:30:13.562418] Test:  [344/345]  eta: 0:00:00  loss: 0.2339 (0.2357)  time: 0.1780  data: 0.0001  max mem: 15821
[21:30:13.624296] Test: Total time: 0:00:59 (0.1736 s / it)
[21:30:24.229864] Test:  [ 0/57]  eta: 0:00:34  loss: 0.4582 (0.4582)  time: 0.5965  data: 0.4343  max mem: 15821
[21:30:25.875603] Test:  [10/57]  eta: 0:00:09  loss: 0.4249 (0.4544)  time: 0.2038  data: 0.0396  max mem: 15821
[21:30:27.528498] Test:  [20/57]  eta: 0:00:06  loss: 0.4214 (0.4356)  time: 0.1649  data: 0.0001  max mem: 15821
[21:30:29.184724] Test:  [30/57]  eta: 0:00:04  loss: 0.3167 (0.3901)  time: 0.1654  data: 0.0001  max mem: 15821
[21:30:30.844826] Test:  [40/57]  eta: 0:00:02  loss: 0.3102 (0.3737)  time: 0.1658  data: 0.0001  max mem: 15821
[21:30:32.508983] Test:  [50/57]  eta: 0:00:01  loss: 0.3384 (0.3744)  time: 0.1662  data: 0.0001  max mem: 15821
[21:30:33.406351] Test:  [56/57]  eta: 0:00:00  loss: 0.3613 (0.3867)  time: 0.1612  data: 0.0001  max mem: 15821
[21:30:33.475365] Test: Total time: 0:00:09 (0.1727 s / it)
[21:30:35.239847] Dice score of the network on the train images: 0.808414, val images: 0.745596
[21:30:35.240073] saving best_prec_model_0 @ epoch 13
[21:30:36.332367] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:30:37.328332] Epoch: [14]  [  0/345]  eta: 0:05:43  lr: 0.000087  loss: 0.2349 (0.2349)  time: 0.9947  data: 0.3927  max mem: 15821
[21:30:49.312418] Epoch: [14]  [ 20/345]  eta: 0:03:20  lr: 0.000088  loss: 0.2437 (0.2519)  time: 0.5992  data: 0.0001  max mem: 15821
[21:31:01.310287] Epoch: [14]  [ 40/345]  eta: 0:03:05  lr: 0.000088  loss: 0.2360 (0.2474)  time: 0.5998  data: 0.0001  max mem: 15821
[21:31:13.333927] Epoch: [14]  [ 60/345]  eta: 0:02:52  lr: 0.000089  loss: 0.2303 (0.2435)  time: 0.6011  data: 0.0001  max mem: 15821
[21:31:25.502041] Epoch: [14]  [ 80/345]  eta: 0:02:40  lr: 0.000089  loss: 0.2379 (0.2412)  time: 0.6084  data: 0.0001  max mem: 15821
[21:31:37.577812] Epoch: [14]  [100/345]  eta: 0:02:28  lr: 0.000089  loss: 0.2343 (0.2413)  time: 0.6037  data: 0.0001  max mem: 15821

[21:31:49.668682] Epoch: [14]  [120/345]  eta: 0:02:16  lr: 0.000090  loss: 0.2435 (0.2418)  time: 0.6045  data: 0.0001  max mem: 15821
[21:32:01.764857] Epoch: [14]  [140/345]  eta: 0:02:04  lr: 0.000090  loss: 0.2339 (0.2423)  time: 0.6048  data: 0.0001  max mem: 15821
[21:32:13.870341] Epoch: [14]  [160/345]  eta: 0:01:52  lr: 0.000090  loss: 0.2457 (0.2421)  time: 0.6052  data: 0.0001  max mem: 15821
[21:32:25.972140] Epoch: [14]  [180/345]  eta: 0:01:39  lr: 0.000091  loss: 0.2571 (0.2435)  time: 0.6050  data: 0.0001  max mem: 15821
[21:32:38.070017] Epoch: [14]  [200/345]  eta: 0:01:27  lr: 0.000091  loss: 0.2416 (0.2443)  time: 0.6048  data: 0.0001  max mem: 15821
[21:32:50.159616] Epoch: [14]  [220/345]  eta: 0:01:15  lr: 0.000091  loss: 0.2325 (0.2438)  time: 0.6044  data: 0.0001  max mem: 15821
[21:33:02.221658] Epoch: [14]  [240/345]  eta: 0:01:03  lr: 0.000092  loss: 0.2346 (0.2433)  time: 0.6031  data: 0.0001  max mem: 15821
[21:33:14.294343] Epoch: [14]  [260/345]  eta: 0:00:51  lr: 0.000092  loss: 0.2348 (0.2427)  time: 0.6036  data: 0.0001  max mem: 15821
[21:33:26.371091] Epoch: [14]  [280/345]  eta: 0:00:39  lr: 0.000093  loss: 0.2271 (0.2420)  time: 0.6038  data: 0.0001  max mem: 15821
[21:33:38.442842] Epoch: [14]  [300/345]  eta: 0:00:27  lr: 0.000093  loss: 0.2407 (0.2421)  time: 0.6035  data: 0.0001  max mem: 15821
[21:33:50.512522] Epoch: [14]  [320/345]  eta: 0:00:15  lr: 0.000093  loss: 0.2297 (0.2420)  time: 0.6034  data: 0.0001  max mem: 15821
[21:34:02.579478] Epoch: [14]  [340/345]  eta: 0:00:03  lr: 0.000094  loss: 0.2276 (0.2413)  time: 0.6033  data: 0.0001  max mem: 15821
[21:34:04.992605] Epoch: [14]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.2366 (0.2415)  time: 0.6031  data: 0.0001  max mem: 15821
[21:34:05.079097] Epoch: [14] Total time: 0:03:28 (0.6051 s / it)
[21:34:05.079230] Averaged stats: lr: 0.000094  loss: 0.2366 (0.2415)
[21:34:05.667294] Test:  [  0/345]  eta: 0:03:21  loss: 0.2290 (0.2290)  time: 0.5839  data: 0.4196  max mem: 15821
[21:34:07.333154] Test:  [ 10/345]  eta: 0:01:08  loss: 0.2290 (0.2261)  time: 0.2044  data: 0.0382  max mem: 15821
[21:34:09.001917] Test:  [ 20/345]  eta: 0:01:00  loss: 0.2287 (0.2258)  time: 0.1667  data: 0.0001  max mem: 15821
[21:34:10.674756] Test:  [ 30/345]  eta: 0:00:56  loss: 0.2275 (0.2231)  time: 0.1670  data: 0.0001  max mem: 15821
[21:34:12.350191] Test:  [ 40/345]  eta: 0:00:54  loss: 0.2258 (0.2228)  time: 0.1674  data: 0.0001  max mem: 15821
[21:34:14.029065] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2261 (0.2222)  time: 0.1677  data: 0.0001  max mem: 15821
[21:34:15.712532] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2237 (0.2223)  time: 0.1680  data: 0.0001  max mem: 15821
[21:34:17.398333] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2129 (0.2215)  time: 0.1684  data: 0.0001  max mem: 15821
[21:34:19.087874] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2129 (0.2209)  time: 0.1687  data: 0.0001  max mem: 15821
[21:34:20.780634] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2165 (0.2216)  time: 0.1691  data: 0.0001  max mem: 15821
[21:34:22.477549] Test:  [100/345]  eta: 0:00:42  loss: 0.2184 (0.2219)  time: 0.1694  data: 0.0001  max mem: 15821
[21:34:24.177433] Test:  [110/345]  eta: 0:00:40  loss: 0.2298 (0.2227)  time: 0.1698  data: 0.0001  max mem: 15821
[21:34:25.881344] Test:  [120/345]  eta: 0:00:38  loss: 0.2187 (0.2216)  time: 0.1701  data: 0.0001  max mem: 15821
[21:34:27.587146] Test:  [130/345]  eta: 0:00:36  loss: 0.2110 (0.2212)  time: 0.1704  data: 0.0001  max mem: 15821
[21:34:29.297081] Test:  [140/345]  eta: 0:00:35  loss: 0.2222 (0.2226)  time: 0.1707  data: 0.0001  max mem: 15821
[21:34:31.009650] Test:  [150/345]  eta: 0:00:33  loss: 0.2223 (0.2229)  time: 0.1711  data: 0.0001  max mem: 15821
[21:34:32.727298] Test:  [160/345]  eta: 0:00:31  loss: 0.2185 (0.2238)  time: 0.1714  data: 0.0001  max mem: 15821
[21:34:34.446960] Test:  [170/345]  eta: 0:00:30  loss: 0.2263 (0.2241)  time: 0.1718  data: 0.0001  max mem: 15821
[21:34:36.170654] Test:  [180/345]  eta: 0:00:28  loss: 0.2236 (0.2241)  time: 0.1721  data: 0.0001  max mem: 15821
[21:34:37.897982] Test:  [190/345]  eta: 0:00:26  loss: 0.2265 (0.2249)  time: 0.1725  data: 0.0001  max mem: 15821
[21:34:39.628873] Test:  [200/345]  eta: 0:00:24  loss: 0.2319 (0.2253)  time: 0.1728  data: 0.0001  max mem: 15821
[21:34:41.362597] Test:  [210/345]  eta: 0:00:23  loss: 0.2312 (0.2251)  time: 0.1732  data: 0.0001  max mem: 15821
[21:34:43.099041] Test:  [220/345]  eta: 0:00:21  loss: 0.2262 (0.2252)  time: 0.1734  data: 0.0001  max mem: 15821
[21:34:44.841368] Test:  [230/345]  eta: 0:00:19  loss: 0.2156 (0.2250)  time: 0.1739  data: 0.0001  max mem: 15821
[21:34:46.585701] Test:  [240/345]  eta: 0:00:18  loss: 0.2184 (0.2252)  time: 0.1743  data: 0.0001  max mem: 15821
[21:34:48.333096] Test:  [250/345]  eta: 0:00:16  loss: 0.2192 (0.2252)  time: 0.1745  data: 0.0001  max mem: 15821
[21:34:50.083870] Test:  [260/345]  eta: 0:00:14  loss: 0.2164 (0.2254)  time: 0.1748  data: 0.0001  max mem: 15821
[21:34:51.838704] Test:  [270/345]  eta: 0:00:12  loss: 0.2164 (0.2252)  time: 0.1752  data: 0.0001  max mem: 15821
[21:34:53.597744] Test:  [280/345]  eta: 0:00:11  loss: 0.2224 (0.2255)  time: 0.1756  data: 0.0001  max mem: 15821
[21:34:55.359467] Test:  [290/345]  eta: 0:00:09  loss: 0.2251 (0.2255)  time: 0.1760  data: 0.0001  max mem: 15821
[21:34:57.124914] Test:  [300/345]  eta: 0:00:07  loss: 0.2160 (0.2252)  time: 0.1763  data: 0.0001  max mem: 15821
[21:34:58.895142] Test:  [310/345]  eta: 0:00:06  loss: 0.2153 (0.2252)  time: 0.1767  data: 0.0001  max mem: 15821
[21:35:00.665439] Test:  [320/345]  eta: 0:00:04  loss: 0.2235 (0.2251)  time: 0.1770  data: 0.0001  max mem: 15821
[21:35:02.440987] Test:  [330/345]  eta: 0:00:02  loss: 0.2178 (0.2250)  time: 0.1772  data: 0.0001  max mem: 15821
[21:35:04.220219] Test:  [340/345]  eta: 0:00:00  loss: 0.2230 (0.2253)  time: 0.1777  data: 0.0001  max mem: 15821
[21:35:04.933802] Test:  [344/345]  eta: 0:00:00  loss: 0.2321 (0.2256)  time: 0.1778  data: 0.0001  max mem: 15821
[21:35:05.002920] Test: Total time: 0:00:59 (0.1737 s / it)
[21:35:15.513519] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4612 (0.4612)  time: 0.5258  data: 0.3636  max mem: 15821
[21:35:17.160092] Test:  [10/57]  eta: 0:00:09  loss: 0.4209 (0.4502)  time: 0.1974  data: 0.0331  max mem: 15821
[21:35:18.812181] Test:  [20/57]  eta: 0:00:06  loss: 0.4209 (0.4377)  time: 0.1648  data: 0.0001  max mem: 15821
[21:35:20.467680] Test:  [30/57]  eta: 0:00:04  loss: 0.3087 (0.3862)  time: 0.1653  data: 0.0001  max mem: 15821
[21:35:22.127161] Test:  [40/57]  eta: 0:00:02  loss: 0.2743 (0.3632)  time: 0.1657  data: 0.0001  max mem: 15821
[21:35:23.792050] Test:  [50/57]  eta: 0:00:01  loss: 0.2986 (0.3623)  time: 0.1662  data: 0.0001  max mem: 15821
[21:35:24.690110] Test:  [56/57]  eta: 0:00:00  loss: 0.3367 (0.3798)  time: 0.1613  data: 0.0001  max mem: 15821
[21:35:24.766135] Test: Total time: 0:00:09 (0.1716 s / it)
[21:35:26.509992] Dice score of the network on the train images: 0.809241, val images: 0.757939
[21:35:26.513993] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:35:27.535424] Epoch: [15]  [  0/345]  eta: 0:05:52  lr: 0.000094  loss: 0.2562 (0.2562)  time: 1.0203  data: 0.4187  max mem: 15821
[21:35:39.526646] Epoch: [15]  [ 20/345]  eta: 0:03:21  lr: 0.000094  loss: 0.2306 (0.2352)  time: 0.5995  data: 0.0001  max mem: 15821
[21:35:51.529922] Epoch: [15]  [ 40/345]  eta: 0:03:06  lr: 0.000094  loss: 0.2247 (0.2323)  time: 0.6001  data: 0.0001  max mem: 15821
[21:36:03.550276] Epoch: [15]  [ 60/345]  eta: 0:02:53  lr: 0.000095  loss: 0.2291 (0.2346)  time: 0.6010  data: 0.0001  max mem: 15821
[21:36:15.590065] Epoch: [15]  [ 80/345]  eta: 0:02:40  lr: 0.000095  loss: 0.2365 (0.2344)  time: 0.6019  data: 0.0001  max mem: 15821
[21:36:27.649511] Epoch: [15]  [100/345]  eta: 0:02:28  lr: 0.000096  loss: 0.2268 (0.2325)  time: 0.6029  data: 0.0001  max mem: 15821
[21:36:39.729708] Epoch: [15]  [120/345]  eta: 0:02:16  lr: 0.000096  loss: 0.2263 (0.2319)  time: 0.6040  data: 0.0001  max mem: 15821
[21:36:51.816674] Epoch: [15]  [140/345]  eta: 0:02:04  lr: 0.000096  loss: 0.2464 (0.2339)  time: 0.6043  data: 0.0001  max mem: 15821
[21:37:03.920022] Epoch: [15]  [160/345]  eta: 0:01:51  lr: 0.000097  loss: 0.2281 (0.2342)  time: 0.6051  data: 0.0001  max mem: 15821
[21:37:16.019695] Epoch: [15]  [180/345]  eta: 0:01:39  lr: 0.000097  loss: 0.2195 (0.2329)  time: 0.6049  data: 0.0001  max mem: 15821
[21:37:28.121205] Epoch: [15]  [200/345]  eta: 0:01:27  lr: 0.000097  loss: 0.2132 (0.2319)  time: 0.6050  data: 0.0001  max mem: 15821
[21:37:40.204362] Epoch: [15]  [220/345]  eta: 0:01:15  lr: 0.000098  loss: 0.2145 (0.2311)  time: 0.6041  data: 0.0001  max mem: 15821
[21:37:52.286692] Epoch: [15]  [240/345]  eta: 0:01:03  lr: 0.000098  loss: 0.2247 (0.2308)  time: 0.6041  data: 0.0001  max mem: 15821
[21:38:04.367026] Epoch: [15]  [260/345]  eta: 0:00:51  lr: 0.000098  loss: 0.2185 (0.2304)  time: 0.6040  data: 0.0001  max mem: 15821
[21:38:16.436976] Epoch: [15]  [280/345]  eta: 0:00:39  lr: 0.000099  loss: 0.2258 (0.2305)  time: 0.6035  data: 0.0001  max mem: 15821
[21:38:28.509711] Epoch: [15]  [300/345]  eta: 0:00:27  lr: 0.000099  loss: 0.2309 (0.2307)  time: 0.6036  data: 0.0001  max mem: 15821
[21:38:40.583069] Epoch: [15]  [320/345]  eta: 0:00:15  lr: 0.000100  loss: 0.2222 (0.2306)  time: 0.6036  data: 0.0001  max mem: 15821
[21:38:52.650740] Epoch: [15]  [340/345]  eta: 0:00:03  lr: 0.000100  loss: 0.2324 (0.2309)  time: 0.6033  data: 0.0001  max mem: 15821
[21:38:55.063536] Epoch: [15]  [344/345]  eta: 0:00:00  lr: 0.000100  loss: 0.2358 (0.2307)  time: 0.6032  data: 0.0001  max mem: 15821
[21:38:55.133245] Epoch: [15] Total time: 0:03:28 (0.6047 s / it)
[21:38:55.134083] Averaged stats: lr: 0.000100  loss: 0.2358 (0.2307)
[21:38:55.704336] Test:  [  0/345]  eta: 0:03:14  loss: 0.2455 (0.2455)  time: 0.5633  data: 0.3994  max mem: 15821
[21:38:57.372179] Test:  [ 10/345]  eta: 0:01:07  loss: 0.2151 (0.2211)  time: 0.2027  data: 0.0364  max mem: 15821
[21:38:59.042123] Test:  [ 20/345]  eta: 0:01:00  loss: 0.2126 (0.2144)  time: 0.1668  data: 0.0001  max mem: 15821
[21:39:00.713875] Test:  [ 30/345]  eta: 0:00:56  loss: 0.2160 (0.2217)  time: 0.1670  data: 0.0001  max mem: 15821
[21:39:02.389927] Test:  [ 40/345]  eta: 0:00:53  loss: 0.2219 (0.2208)  time: 0.1673  data: 0.0001  max mem: 15821
[21:39:04.069479] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2074 (0.2201)  time: 0.1677  data: 0.0001  max mem: 15821
[21:39:05.751373] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2131 (0.2206)  time: 0.1680  data: 0.0001  max mem: 15821
[21:39:07.437740] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2195 (0.2207)  time: 0.1684  data: 0.0001  max mem: 15821
[21:39:09.127121] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2186 (0.2216)  time: 0.1687  data: 0.0001  max mem: 15821
[21:39:10.819997] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2228 (0.2220)  time: 0.1690  data: 0.0001  max mem: 15821
[21:39:12.515544] Test:  [100/345]  eta: 0:00:42  loss: 0.2235 (0.2228)  time: 0.1694  data: 0.0001  max mem: 15821
[21:39:14.216723] Test:  [110/345]  eta: 0:00:40  loss: 0.2248 (0.2230)  time: 0.1698  data: 0.0001  max mem: 15821
[21:39:15.920592] Test:  [120/345]  eta: 0:00:38  loss: 0.2209 (0.2222)  time: 0.1702  data: 0.0001  max mem: 15821
[21:39:17.626501] Test:  [130/345]  eta: 0:00:36  loss: 0.2166 (0.2223)  time: 0.1704  data: 0.0001  max mem: 15821
[21:39:19.335822] Test:  [140/345]  eta: 0:00:35  loss: 0.2150 (0.2218)  time: 0.1707  data: 0.0001  max mem: 15821
[21:39:21.048074] Test:  [150/345]  eta: 0:00:33  loss: 0.2091 (0.2209)  time: 0.1710  data: 0.0001  max mem: 15821
[21:39:22.765218] Test:  [160/345]  eta: 0:00:31  loss: 0.2124 (0.2212)  time: 0.1714  data: 0.0001  max mem: 15821
[21:39:24.485728] Test:  [170/345]  eta: 0:00:30  loss: 0.2130 (0.2211)  time: 0.1718  data: 0.0001  max mem: 15821
[21:39:26.209058] Test:  [180/345]  eta: 0:00:28  loss: 0.2097 (0.2209)  time: 0.1721  data: 0.0001  max mem: 15821
[21:39:27.936962] Test:  [190/345]  eta: 0:00:26  loss: 0.2112 (0.2204)  time: 0.1725  data: 0.0001  max mem: 15821
[21:39:29.667821] Test:  [200/345]  eta: 0:00:24  loss: 0.2087 (0.2198)  time: 0.1729  data: 0.0001  max mem: 15821
[21:39:31.402320] Test:  [210/345]  eta: 0:00:23  loss: 0.2118 (0.2197)  time: 0.1732  data: 0.0001  max mem: 15821
[21:39:33.139460] Test:  [220/345]  eta: 0:00:21  loss: 0.2217 (0.2198)  time: 0.1735  data: 0.0001  max mem: 15821
[21:39:34.879960] Test:  [230/345]  eta: 0:00:19  loss: 0.2094 (0.2194)  time: 0.1738  data: 0.0001  max mem: 15821
[21:39:36.623948] Test:  [240/345]  eta: 0:00:18  loss: 0.2094 (0.2192)  time: 0.1742  data: 0.0001  max mem: 15821
[21:39:38.372427] Test:  [250/345]  eta: 0:00:16  loss: 0.2145 (0.2198)  time: 0.1746  data: 0.0001  max mem: 15821
[21:39:40.123897] Test:  [260/345]  eta: 0:00:14  loss: 0.2175 (0.2196)  time: 0.1749  data: 0.0001  max mem: 15821
[21:39:41.878280] Test:  [270/345]  eta: 0:00:12  loss: 0.2126 (0.2197)  time: 0.1752  data: 0.0001  max mem: 15821
[21:39:43.635666] Test:  [280/345]  eta: 0:00:11  loss: 0.2293 (0.2203)  time: 0.1755  data: 0.0001  max mem: 15821
[21:39:45.396831] Test:  [290/345]  eta: 0:00:09  loss: 0.2192 (0.2204)  time: 0.1759  data: 0.0001  max mem: 15821
[21:39:47.161772] Test:  [300/345]  eta: 0:00:07  loss: 0.2192 (0.2210)  time: 0.1762  data: 0.0001  max mem: 15821
[21:39:48.930503] Test:  [310/345]  eta: 0:00:06  loss: 0.2357 (0.2213)  time: 0.1766  data: 0.0001  max mem: 15821
[21:39:50.702349] Test:  [320/345]  eta: 0:00:04  loss: 0.2194 (0.2213)  time: 0.1770  data: 0.0001  max mem: 15821
[21:39:52.479464] Test:  [330/345]  eta: 0:00:02  loss: 0.2183 (0.2212)  time: 0.1774  data: 0.0001  max mem: 15821
[21:39:54.258091] Test:  [340/345]  eta: 0:00:00  loss: 0.2164 (0.2212)  time: 0.1777  data: 0.0001  max mem: 15821
[21:39:54.970424] Test:  [344/345]  eta: 0:00:00  loss: 0.2286 (0.2213)  time: 0.1779  data: 0.0001  max mem: 15821
[21:39:55.042816] Test: Total time: 0:00:59 (0.1736 s / it)
[21:40:05.516166] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4557 (0.4557)  time: 0.5212  data: 0.3590  max mem: 15821
[21:40:07.165469] Test:  [10/57]  eta: 0:00:09  loss: 0.4288 (0.4601)  time: 0.1972  data: 0.0327  max mem: 15821
[21:40:08.816641] Test:  [20/57]  eta: 0:00:06  loss: 0.4288 (0.4490)  time: 0.1649  data: 0.0001  max mem: 15821
[21:40:10.472238] Test:  [30/57]  eta: 0:00:04  loss: 0.3046 (0.3941)  time: 0.1653  data: 0.0001  max mem: 15821
[21:40:12.132820] Test:  [40/57]  eta: 0:00:02  loss: 0.2873 (0.3719)  time: 0.1657  data: 0.0001  max mem: 15821
[21:40:13.798255] Test:  [50/57]  eta: 0:00:01  loss: 0.3153 (0.3706)  time: 0.1662  data: 0.0001  max mem: 15821
[21:40:14.696790] Test:  [56/57]  eta: 0:00:00  loss: 0.3326 (0.3802)  time: 0.1614  data: 0.0001  max mem: 15821
[21:40:14.774054] Test: Total time: 0:00:09 (0.1716 s / it)
[21:40:16.530036] Dice score of the network on the train images: 0.813754, val images: 0.772668
[21:40:16.530224] saving best_prec_model_0 @ epoch 15
[21:40:17.650123] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:40:18.623939] Epoch: [16]  [  0/345]  eta: 0:05:35  lr: 0.000100  loss: 0.2263 (0.2263)  time: 0.9726  data: 0.3728  max mem: 15821
[21:40:30.594466] Epoch: [16]  [ 20/345]  eta: 0:03:20  lr: 0.000100  loss: 0.2302 (0.2334)  time: 0.5985  data: 0.0001  max mem: 15821
[21:40:42.596361] Epoch: [16]  [ 40/345]  eta: 0:03:05  lr: 0.000101  loss: 0.2193 (0.2287)  time: 0.6000  data: 0.0001  max mem: 15821
[21:40:54.616985] Epoch: [16]  [ 60/345]  eta: 0:02:52  lr: 0.000101  loss: 0.2271 (0.2292)  time: 0.6010  data: 0.0001  max mem: 15821
[21:41:06.671458] Epoch: [16]  [ 80/345]  eta: 0:02:40  lr: 0.000101  loss: 0.2171 (0.2294)  time: 0.6027  data: 0.0001  max mem: 15821
[21:41:18.741610] Epoch: [16]  [100/345]  eta: 0:02:28  lr: 0.000102  loss: 0.2354 (0.2301)  time: 0.6035  data: 0.0001  max mem: 15821
[21:41:30.822529] Epoch: [16]  [120/345]  eta: 0:02:16  lr: 0.000102  loss: 0.2123 (0.2276)  time: 0.6040  data: 0.0001  max mem: 15821
[21:41:42.925006] Epoch: [16]  [140/345]  eta: 0:02:03  lr: 0.000103  loss: 0.2216 (0.2272)  time: 0.6051  data: 0.0001  max mem: 15821
[21:41:55.026747] Epoch: [16]  [160/345]  eta: 0:01:51  lr: 0.000103  loss: 0.2225 (0.2274)  time: 0.6050  data: 0.0001  max mem: 15821
[21:42:07.112033] Epoch: [16]  [180/345]  eta: 0:01:39  lr: 0.000103  loss: 0.2133 (0.2266)  time: 0.6042  data: 0.0001  max mem: 15821
[21:42:19.209828] Epoch: [16]  [200/345]  eta: 0:01:27  lr: 0.000104  loss: 0.2339 (0.2271)  time: 0.6048  data: 0.0001  max mem: 15821
[21:42:31.301497] Epoch: [16]  [220/345]  eta: 0:01:15  lr: 0.000104  loss: 0.2244 (0.2271)  time: 0.6045  data: 0.0001  max mem: 15821
[21:42:43.390989] Epoch: [16]  [240/345]  eta: 0:01:03  lr: 0.000104  loss: 0.2166 (0.2268)  time: 0.6044  data: 0.0001  max mem: 15821
[21:42:55.470909] Epoch: [16]  [260/345]  eta: 0:00:51  lr: 0.000105  loss: 0.2230 (0.2262)  time: 0.6039  data: 0.0001  max mem: 15821
[21:43:07.546500] Epoch: [16]  [280/345]  eta: 0:00:39  lr: 0.000105  loss: 0.2117 (0.2256)  time: 0.6037  data: 0.0001  max mem: 15821
[21:43:19.620412] Epoch: [16]  [300/345]  eta: 0:00:27  lr: 0.000105  loss: 0.2219 (0.2257)  time: 0.6036  data: 0.0001  max mem: 15821
[21:43:31.690377] Epoch: [16]  [320/345]  eta: 0:00:15  lr: 0.000106  loss: 0.2173 (0.2256)  time: 0.6035  data: 0.0001  max mem: 15821
[21:43:43.756134] Epoch: [16]  [340/345]  eta: 0:00:03  lr: 0.000106  loss: 0.2226 (0.2258)  time: 0.6032  data: 0.0001  max mem: 15821
[21:43:46.168250] Epoch: [16]  [344/345]  eta: 0:00:00  lr: 0.000106  loss: 0.2211 (0.2258)  time: 0.6031  data: 0.0001  max mem: 15821
[21:43:46.243637] Epoch: [16] Total time: 0:03:28 (0.6046 s / it)
[21:43:46.244003] Averaged stats: lr: 0.000106  loss: 0.2211 (0.2258)
[21:43:46.824719] Test:  [  0/345]  eta: 0:03:18  loss: 0.2079 (0.2079)  time: 0.5754  data: 0.4106  max mem: 15821
[21:43:48.491090] Test:  [ 10/345]  eta: 0:01:08  loss: 0.2101 (0.2098)  time: 0.2037  data: 0.0374  max mem: 15821
[21:43:50.161463] Test:  [ 20/345]  eta: 0:01:00  loss: 0.2101 (0.2139)  time: 0.1668  data: 0.0001  max mem: 15821
[21:43:51.834102] Test:  [ 30/345]  eta: 0:00:56  loss: 0.2046 (0.2130)  time: 0.1671  data: 0.0001  max mem: 15821
[21:43:53.511531] Test:  [ 40/345]  eta: 0:00:54  loss: 0.2037 (0.2107)  time: 0.1674  data: 0.0001  max mem: 15821
[21:43:55.191030] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2098 (0.2115)  time: 0.1678  data: 0.0001  max mem: 15821
[21:43:56.873771] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2070 (0.2100)  time: 0.1680  data: 0.0001  max mem: 15821
[21:43:58.561412] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2033 (0.2085)  time: 0.1685  data: 0.0001  max mem: 15821
[21:44:00.252112] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2041 (0.2088)  time: 0.1688  data: 0.0001  max mem: 15821
[21:44:01.946367] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2137 (0.2091)  time: 0.1692  data: 0.0001  max mem: 15821
[21:44:03.643707] Test:  [100/345]  eta: 0:00:42  loss: 0.2005 (0.2095)  time: 0.1695  data: 0.0001  max mem: 15821
[21:44:05.343655] Test:  [110/345]  eta: 0:00:40  loss: 0.2070 (0.2087)  time: 0.1698  data: 0.0001  max mem: 15821
[21:44:07.046927] Test:  [120/345]  eta: 0:00:38  loss: 0.2042 (0.2081)  time: 0.1701  data: 0.0001  max mem: 15821
[21:44:08.754134] Test:  [130/345]  eta: 0:00:36  loss: 0.2038 (0.2091)  time: 0.1705  data: 0.0001  max mem: 15821
[21:44:10.465079] Test:  [140/345]  eta: 0:00:35  loss: 0.2159 (0.2089)  time: 0.1708  data: 0.0001  max mem: 15821
[21:44:12.178850] Test:  [150/345]  eta: 0:00:33  loss: 0.2081 (0.2102)  time: 0.1712  data: 0.0001  max mem: 15821
[21:44:13.895335] Test:  [160/345]  eta: 0:00:31  loss: 0.2035 (0.2100)  time: 0.1715  data: 0.0001  max mem: 15821
[21:44:15.615723] Test:  [170/345]  eta: 0:00:30  loss: 0.2035 (0.2104)  time: 0.1718  data: 0.0001  max mem: 15821
[21:44:17.340655] Test:  [180/345]  eta: 0:00:28  loss: 0.2010 (0.2102)  time: 0.1722  data: 0.0001  max mem: 15821
[21:44:19.067165] Test:  [190/345]  eta: 0:00:26  loss: 0.1991 (0.2100)  time: 0.1725  data: 0.0001  max mem: 15821
[21:44:20.797740] Test:  [200/345]  eta: 0:00:24  loss: 0.2015 (0.2104)  time: 0.1728  data: 0.0001  max mem: 15821
[21:44:22.532613] Test:  [210/345]  eta: 0:00:23  loss: 0.2003 (0.2101)  time: 0.1732  data: 0.0001  max mem: 15821
[21:44:24.269557] Test:  [220/345]  eta: 0:00:21  loss: 0.1963 (0.2099)  time: 0.1735  data: 0.0001  max mem: 15821
[21:44:26.010220] Test:  [230/345]  eta: 0:00:19  loss: 0.1949 (0.2094)  time: 0.1738  data: 0.0001  max mem: 15821
[21:44:27.754545] Test:  [240/345]  eta: 0:00:18  loss: 0.2019 (0.2096)  time: 0.1742  data: 0.0001  max mem: 15821
[21:44:29.503643] Test:  [250/345]  eta: 0:00:16  loss: 0.2046 (0.2095)  time: 0.1746  data: 0.0001  max mem: 15821
[21:44:31.256519] Test:  [260/345]  eta: 0:00:14  loss: 0.2058 (0.2097)  time: 0.1750  data: 0.0001  max mem: 15821
[21:44:33.011987] Test:  [270/345]  eta: 0:00:12  loss: 0.2092 (0.2098)  time: 0.1754  data: 0.0001  max mem: 15821
[21:44:34.770390] Test:  [280/345]  eta: 0:00:11  loss: 0.2092 (0.2096)  time: 0.1756  data: 0.0001  max mem: 15821
[21:44:36.532965] Test:  [290/345]  eta: 0:00:09  loss: 0.2064 (0.2096)  time: 0.1760  data: 0.0001  max mem: 15821
[21:44:38.298180] Test:  [300/345]  eta: 0:00:07  loss: 0.2120 (0.2098)  time: 0.1763  data: 0.0001  max mem: 15821
[21:44:40.068008] Test:  [310/345]  eta: 0:00:06  loss: 0.2106 (0.2095)  time: 0.1767  data: 0.0001  max mem: 15821
[21:44:41.839538] Test:  [320/345]  eta: 0:00:04  loss: 0.2106 (0.2100)  time: 0.1770  data: 0.0001  max mem: 15821
[21:44:43.616069] Test:  [330/345]  eta: 0:00:02  loss: 0.2228 (0.2104)  time: 0.1773  data: 0.0001  max mem: 15821
[21:44:45.396027] Test:  [340/345]  eta: 0:00:00  loss: 0.2044 (0.2101)  time: 0.1778  data: 0.0001  max mem: 15821
[21:44:46.109350] Test:  [344/345]  eta: 0:00:00  loss: 0.2043 (0.2100)  time: 0.1779  data: 0.0001  max mem: 15821
[21:44:46.187889] Test: Total time: 0:00:59 (0.1737 s / it)
[21:44:56.687367] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4616 (0.4616)  time: 0.5404  data: 0.3779  max mem: 15821
[21:44:58.333856] Test:  [10/57]  eta: 0:00:09  loss: 0.4323 (0.4489)  time: 0.1987  data: 0.0344  max mem: 15821
[21:44:59.987918] Test:  [20/57]  eta: 0:00:06  loss: 0.4154 (0.4324)  time: 0.1650  data: 0.0001  max mem: 15821
[21:45:01.644910] Test:  [30/57]  eta: 0:00:04  loss: 0.2922 (0.3793)  time: 0.1655  data: 0.0001  max mem: 15821
[21:45:03.304703] Test:  [40/57]  eta: 0:00:02  loss: 0.2792 (0.3600)  time: 0.1658  data: 0.0001  max mem: 15821
[21:45:04.968920] Test:  [50/57]  eta: 0:00:01  loss: 0.3192 (0.3587)  time: 0.1661  data: 0.0001  max mem: 15821
[21:45:05.866980] Test:  [56/57]  eta: 0:00:00  loss: 0.3463 (0.3726)  time: 0.1613  data: 0.0000  max mem: 15821
[21:45:05.937302] Test: Total time: 0:00:09 (0.1718 s / it)
[21:45:07.736109] Dice score of the network on the train images: 0.828570, val images: 0.773033
[21:45:07.736356] saving best_prec_model_0 @ epoch 16
[21:45:08.791687] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:45:09.786010] Epoch: [17]  [  0/345]  eta: 0:05:42  lr: 0.000106  loss: 0.2049 (0.2049)  time: 0.9932  data: 0.3930  max mem: 15821
[21:45:21.768904] Epoch: [17]  [ 20/345]  eta: 0:03:20  lr: 0.000107  loss: 0.2157 (0.2174)  time: 0.5990  data: 0.0001  max mem: 15821
[21:45:33.758323] Epoch: [17]  [ 40/345]  eta: 0:03:05  lr: 0.000107  loss: 0.2120 (0.2178)  time: 0.5994  data: 0.0001  max mem: 15821
[21:45:45.781506] Epoch: [17]  [ 60/345]  eta: 0:02:52  lr: 0.000107  loss: 0.2060 (0.2156)  time: 0.6011  data: 0.0001  max mem: 15821
[21:45:57.834582] Epoch: [17]  [ 80/345]  eta: 0:02:40  lr: 0.000108  loss: 0.2179 (0.2166)  time: 0.6026  data: 0.0001  max mem: 15821
[21:46:10.019589] Epoch: [17]  [100/345]  eta: 0:02:28  lr: 0.000108  loss: 0.2252 (0.2184)  time: 0.6092  data: 0.0001  max mem: 15821
[21:46:22.097138] Epoch: [17]  [120/345]  eta: 0:02:16  lr: 0.000108  loss: 0.2128 (0.2182)  time: 0.6038  data: 0.0001  max mem: 15821
[21:46:34.181428] Epoch: [17]  [140/345]  eta: 0:02:04  lr: 0.000109  loss: 0.2036 (0.2177)  time: 0.6042  data: 0.0001  max mem: 15821
[21:46:46.262927] Epoch: [17]  [160/345]  eta: 0:01:51  lr: 0.000109  loss: 0.2082 (0.2168)  time: 0.6040  data: 0.0001  max mem: 15821
[21:46:58.345024] Epoch: [17]  [180/345]  eta: 0:01:39  lr: 0.000110  loss: 0.2203 (0.2180)  time: 0.6041  data: 0.0001  max mem: 15821
[21:47:10.434968] Epoch: [17]  [200/345]  eta: 0:01:27  lr: 0.000110  loss: 0.2211 (0.2187)  time: 0.6044  data: 0.0001  max mem: 15821
[21:47:22.521108] Epoch: [17]  [220/345]  eta: 0:01:15  lr: 0.000110  loss: 0.2195 (0.2193)  time: 0.6043  data: 0.0001  max mem: 15821
[21:47:34.600578] Epoch: [17]  [240/345]  eta: 0:01:03  lr: 0.000111  loss: 0.2142 (0.2198)  time: 0.6039  data: 0.0001  max mem: 15821
[21:47:46.675059] Epoch: [17]  [260/345]  eta: 0:00:51  lr: 0.000111  loss: 0.2170 (0.2195)  time: 0.6037  data: 0.0001  max mem: 15821
[21:47:58.757496] Epoch: [17]  [280/345]  eta: 0:00:39  lr: 0.000111  loss: 0.2019 (0.2185)  time: 0.6041  data: 0.0001  max mem: 15821
[21:48:10.819880] Epoch: [17]  [300/345]  eta: 0:00:27  lr: 0.000112  loss: 0.2117 (0.2181)  time: 0.6031  data: 0.0001  max mem: 15821
[21:48:22.902494] Epoch: [17]  [320/345]  eta: 0:00:15  lr: 0.000112  loss: 0.2191 (0.2183)  time: 0.6041  data: 0.0001  max mem: 15821
[21:48:35.059582] Epoch: [17]  [340/345]  eta: 0:00:03  lr: 0.000112  loss: 0.2124 (0.2183)  time: 0.6078  data: 0.0001  max mem: 15821
[21:48:37.473120] Epoch: [17]  [344/345]  eta: 0:00:00  lr: 0.000112  loss: 0.2108 (0.2183)  time: 0.6077  data: 0.0001  max mem: 15821
[21:48:37.546191] Epoch: [17] Total time: 0:03:28 (0.6051 s / it)
[21:48:37.546868] Averaged stats: lr: 0.000112  loss: 0.2108 (0.2183)
[21:48:38.149608] Test:  [  0/345]  eta: 0:03:26  loss: 0.2038 (0.2038)  time: 0.5973  data: 0.4331  max mem: 15821
[21:48:39.816882] Test:  [ 10/345]  eta: 0:01:08  loss: 0.2083 (0.2212)  time: 0.2058  data: 0.0395  max mem: 15821
[21:48:41.486491] Test:  [ 20/345]  eta: 0:01:00  loss: 0.2078 (0.2146)  time: 0.1668  data: 0.0001  max mem: 15821
[21:48:43.159819] Test:  [ 30/345]  eta: 0:00:56  loss: 0.2043 (0.2153)  time: 0.1671  data: 0.0001  max mem: 15821
[21:48:44.836770] Test:  [ 40/345]  eta: 0:00:54  loss: 0.2148 (0.2149)  time: 0.1674  data: 0.0001  max mem: 15821
[21:48:46.516025] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2221 (0.2147)  time: 0.1677  data: 0.0001  max mem: 15821
[21:48:48.197813] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2165 (0.2134)  time: 0.1680  data: 0.0001  max mem: 15821
[21:48:49.883241] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2017 (0.2122)  time: 0.1683  data: 0.0001  max mem: 15821
[21:48:51.573391] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1983 (0.2111)  time: 0.1687  data: 0.0001  max mem: 15821
[21:48:53.267552] Test:  [ 90/345]  eta: 0:00:44  loss: 0.2002 (0.2125)  time: 0.1691  data: 0.0001  max mem: 15821
[21:48:54.965370] Test:  [100/345]  eta: 0:00:42  loss: 0.2181 (0.2122)  time: 0.1695  data: 0.0001  max mem: 15821
[21:48:56.665353] Test:  [110/345]  eta: 0:00:40  loss: 0.2082 (0.2117)  time: 0.1698  data: 0.0001  max mem: 15821
[21:48:58.368725] Test:  [120/345]  eta: 0:00:38  loss: 0.2123 (0.2121)  time: 0.1701  data: 0.0001  max mem: 15821
[21:49:00.074830] Test:  [130/345]  eta: 0:00:36  loss: 0.1977 (0.2110)  time: 0.1704  data: 0.0001  max mem: 15821
[21:49:01.784641] Test:  [140/345]  eta: 0:00:35  loss: 0.2057 (0.2112)  time: 0.1707  data: 0.0001  max mem: 15821
[21:49:03.499076] Test:  [150/345]  eta: 0:00:33  loss: 0.2088 (0.2106)  time: 0.1711  data: 0.0001  max mem: 15821
[21:49:05.216632] Test:  [160/345]  eta: 0:00:31  loss: 0.2158 (0.2113)  time: 0.1715  data: 0.0001  max mem: 15821
[21:49:06.937335] Test:  [170/345]  eta: 0:00:30  loss: 0.2038 (0.2105)  time: 0.1718  data: 0.0001  max mem: 15821
[21:49:08.660266] Test:  [180/345]  eta: 0:00:28  loss: 0.1961 (0.2103)  time: 0.1721  data: 0.0001  max mem: 15821
[21:49:10.387993] Test:  [190/345]  eta: 0:00:26  loss: 0.1992 (0.2098)  time: 0.1725  data: 0.0001  max mem: 15821
[21:49:12.120058] Test:  [200/345]  eta: 0:00:24  loss: 0.2000 (0.2099)  time: 0.1729  data: 0.0001  max mem: 15821
[21:49:13.853549] Test:  [210/345]  eta: 0:00:23  loss: 0.2028 (0.2099)  time: 0.1732  data: 0.0001  max mem: 15821
[21:49:15.590207] Test:  [220/345]  eta: 0:00:21  loss: 0.2074 (0.2099)  time: 0.1734  data: 0.0001  max mem: 15821
[21:49:17.331728] Test:  [230/345]  eta: 0:00:19  loss: 0.2042 (0.2098)  time: 0.1738  data: 0.0001  max mem: 15821
[21:49:19.077524] Test:  [240/345]  eta: 0:00:18  loss: 0.2079 (0.2097)  time: 0.1743  data: 0.0001  max mem: 15821
[21:49:20.826753] Test:  [250/345]  eta: 0:00:16  loss: 0.2180 (0.2105)  time: 0.1747  data: 0.0001  max mem: 15821
[21:49:22.579762] Test:  [260/345]  eta: 0:00:14  loss: 0.2102 (0.2100)  time: 0.1750  data: 0.0001  max mem: 15821
[21:49:24.335350] Test:  [270/345]  eta: 0:00:12  loss: 0.1997 (0.2098)  time: 0.1754  data: 0.0001  max mem: 15821
[21:49:26.094244] Test:  [280/345]  eta: 0:00:11  loss: 0.2039 (0.2101)  time: 0.1757  data: 0.0001  max mem: 15821
[21:49:27.856431] Test:  [290/345]  eta: 0:00:09  loss: 0.2076 (0.2101)  time: 0.1760  data: 0.0001  max mem: 15821
[21:49:29.621472] Test:  [300/345]  eta: 0:00:07  loss: 0.1950 (0.2097)  time: 0.1763  data: 0.0001  max mem: 15821
[21:49:31.391304] Test:  [310/345]  eta: 0:00:06  loss: 0.1924 (0.2095)  time: 0.1767  data: 0.0001  max mem: 15821
[21:49:33.163641] Test:  [320/345]  eta: 0:00:04  loss: 0.2055 (0.2096)  time: 0.1770  data: 0.0001  max mem: 15821
[21:49:34.939979] Test:  [330/345]  eta: 0:00:02  loss: 0.2159 (0.2098)  time: 0.1774  data: 0.0001  max mem: 15821
[21:49:36.720313] Test:  [340/345]  eta: 0:00:00  loss: 0.2133 (0.2098)  time: 0.1778  data: 0.0001  max mem: 15821
[21:49:37.434219] Test:  [344/345]  eta: 0:00:00  loss: 0.2090 (0.2097)  time: 0.1780  data: 0.0001  max mem: 15821
[21:49:37.503168] Test: Total time: 0:00:59 (0.1738 s / it)
[21:49:47.982026] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4687 (0.4687)  time: 0.5368  data: 0.3742  max mem: 15821
[21:49:49.629734] Test:  [10/57]  eta: 0:00:09  loss: 0.4312 (0.4562)  time: 0.1985  data: 0.0341  max mem: 15821
[21:49:51.282150] Test:  [20/57]  eta: 0:00:06  loss: 0.4090 (0.4349)  time: 0.1649  data: 0.0001  max mem: 15821
[21:49:52.939464] Test:  [30/57]  eta: 0:00:04  loss: 0.2653 (0.3703)  time: 0.1654  data: 0.0001  max mem: 15821
[21:49:54.599783] Test:  [40/57]  eta: 0:00:02  loss: 0.2444 (0.3393)  time: 0.1658  data: 0.0001  max mem: 15821
[21:49:56.264415] Test:  [50/57]  eta: 0:00:01  loss: 0.2454 (0.3312)  time: 0.1662  data: 0.0001  max mem: 15821
[21:49:57.161986] Test:  [56/57]  eta: 0:00:00  loss: 0.3247 (0.3433)  time: 0.1613  data: 0.0000  max mem: 15821
[21:49:57.223205] Test: Total time: 0:00:09 (0.1716 s / it)
[21:49:59.017311] Dice score of the network on the train images: 0.803816, val images: 0.802585
[21:49:59.017695] saving best_rec_model_0 @ epoch 17
[21:50:00.111935] saving best_dice_model_0 @ epoch 17
[21:50:01.550882] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:50:02.575198] Epoch: [18]  [  0/345]  eta: 0:05:52  lr: 0.000113  loss: 0.1825 (0.1825)  time: 1.0231  data: 0.4252  max mem: 15821
[21:50:14.528599] Epoch: [18]  [ 20/345]  eta: 0:03:20  lr: 0.000113  loss: 0.2067 (0.2035)  time: 0.5976  data: 0.0001  max mem: 15821
[21:50:26.533336] Epoch: [18]  [ 40/345]  eta: 0:03:05  lr: 0.000113  loss: 0.2144 (0.2102)  time: 0.6002  data: 0.0001  max mem: 15821
[21:50:38.557581] Epoch: [18]  [ 60/345]  eta: 0:02:52  lr: 0.000114  loss: 0.2118 (0.2104)  time: 0.6012  data: 0.0001  max mem: 15821
[21:50:50.621938] Epoch: [18]  [ 80/345]  eta: 0:02:40  lr: 0.000114  loss: 0.2182 (0.2133)  time: 0.6032  data: 0.0001  max mem: 15821
[21:51:02.699482] Epoch: [18]  [100/345]  eta: 0:02:28  lr: 0.000114  loss: 0.2191 (0.2155)  time: 0.6038  data: 0.0001  max mem: 15821
[21:51:14.797485] Epoch: [18]  [120/345]  eta: 0:02:16  lr: 0.000115  loss: 0.2115 (0.2151)  time: 0.6048  data: 0.0001  max mem: 15821
[21:51:27.028724] Epoch: [18]  [140/345]  eta: 0:02:04  lr: 0.000115  loss: 0.2165 (0.2152)  time: 0.6115  data: 0.0001  max mem: 15821

[21:51:39.113097] Epoch: [18]  [160/345]  eta: 0:01:52  lr: 0.000115  loss: 0.2025 (0.2145)  time: 0.6042  data: 0.0001  max mem: 15821
[21:51:51.193562] Epoch: [18]  [180/345]  eta: 0:01:39  lr: 0.000116  loss: 0.2016 (0.2141)  time: 0.6040  data: 0.0001  max mem: 15821
[21:52:03.270583] Epoch: [18]  [200/345]  eta: 0:01:27  lr: 0.000116  loss: 0.1966 (0.2130)  time: 0.6038  data: 0.0001  max mem: 15821
[21:52:15.337005] Epoch: [18]  [220/345]  eta: 0:01:15  lr: 0.000116  loss: 0.2088 (0.2130)  time: 0.6033  data: 0.0001  max mem: 15821
[21:52:27.421132] Epoch: [18]  [240/345]  eta: 0:01:03  lr: 0.000117  loss: 0.2067 (0.2123)  time: 0.6042  data: 0.0001  max mem: 15821
[21:52:39.487039] Epoch: [18]  [260/345]  eta: 0:00:51  lr: 0.000117  loss: 0.2122 (0.2123)  time: 0.6032  data: 0.0001  max mem: 15821
[21:52:51.547441] Epoch: [18]  [280/345]  eta: 0:00:39  lr: 0.000118  loss: 0.2014 (0.2120)  time: 0.6030  data: 0.0001  max mem: 15821
[21:53:03.610167] Epoch: [18]  [300/345]  eta: 0:00:27  lr: 0.000118  loss: 0.2099 (0.2123)  time: 0.6031  data: 0.0001  max mem: 15821
[21:53:15.685579] Epoch: [18]  [320/345]  eta: 0:00:15  lr: 0.000118  loss: 0.2004 (0.2123)  time: 0.6037  data: 0.0001  max mem: 15821
[21:53:27.737363] Epoch: [18]  [340/345]  eta: 0:00:03  lr: 0.000119  loss: 0.2061 (0.2121)  time: 0.6025  data: 0.0001  max mem: 15821
[21:53:30.147494] Epoch: [18]  [344/345]  eta: 0:00:00  lr: 0.000119  loss: 0.2150 (0.2122)  time: 0.6023  data: 0.0001  max mem: 15821
[21:53:30.221470] Epoch: [18] Total time: 0:03:28 (0.6048 s / it)
[21:53:30.221907] Averaged stats: lr: 0.000119  loss: 0.2150 (0.2122)
[21:53:30.798887] Test:  [  0/345]  eta: 0:03:17  loss: 0.2124 (0.2124)  time: 0.5715  data: 0.4074  max mem: 15821
[21:53:32.464954] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1976 (0.1998)  time: 0.2033  data: 0.0371  max mem: 15821
[21:53:34.134106] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1958 (0.2013)  time: 0.1667  data: 0.0001  max mem: 15821
[21:53:35.807465] Test:  [ 30/345]  eta: 0:00:56  loss: 0.2027 (0.1993)  time: 0.1671  data: 0.0001  max mem: 15821
[21:53:37.482861] Test:  [ 40/345]  eta: 0:00:53  loss: 0.2035 (0.2010)  time: 0.1674  data: 0.0001  max mem: 15821
[21:53:39.161629] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1972 (0.2012)  time: 0.1676  data: 0.0001  max mem: 15821
[21:53:40.843431] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1930 (0.2006)  time: 0.1680  data: 0.0001  max mem: 15821
[21:53:42.528430] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1953 (0.2022)  time: 0.1683  data: 0.0001  max mem: 15821
[21:53:44.217377] Test:  [ 80/345]  eta: 0:00:45  loss: 0.2025 (0.2026)  time: 0.1686  data: 0.0001  max mem: 15821
[21:53:45.910118] Test:  [ 90/345]  eta: 0:00:43  loss: 0.2025 (0.2042)  time: 0.1690  data: 0.0001  max mem: 15821
[21:53:47.606183] Test:  [100/345]  eta: 0:00:42  loss: 0.2008 (0.2030)  time: 0.1694  data: 0.0001  max mem: 15821
[21:53:49.306128] Test:  [110/345]  eta: 0:00:40  loss: 0.1874 (0.2023)  time: 0.1697  data: 0.0001  max mem: 15821
[21:53:51.007440] Test:  [120/345]  eta: 0:00:38  loss: 0.1912 (0.2017)  time: 0.1700  data: 0.0001  max mem: 15821
[21:53:52.714069] Test:  [130/345]  eta: 0:00:36  loss: 0.1912 (0.2009)  time: 0.1703  data: 0.0001  max mem: 15821
[21:53:54.424018] Test:  [140/345]  eta: 0:00:35  loss: 0.1815 (0.2003)  time: 0.1707  data: 0.0001  max mem: 15821
[21:53:56.137183] Test:  [150/345]  eta: 0:00:33  loss: 0.1937 (0.1999)  time: 0.1711  data: 0.0001  max mem: 15821
[21:53:57.853930] Test:  [160/345]  eta: 0:00:31  loss: 0.1910 (0.1995)  time: 0.1714  data: 0.0001  max mem: 15821
[21:53:59.576058] Test:  [170/345]  eta: 0:00:30  loss: 0.1924 (0.1997)  time: 0.1719  data: 0.0001  max mem: 15821
[21:54:01.299436] Test:  [180/345]  eta: 0:00:28  loss: 0.1935 (0.1991)  time: 0.1722  data: 0.0001  max mem: 15821
[21:54:03.026622] Test:  [190/345]  eta: 0:00:26  loss: 0.1997 (0.1995)  time: 0.1725  data: 0.0001  max mem: 15821
[21:54:04.757417] Test:  [200/345]  eta: 0:00:24  loss: 0.2044 (0.2000)  time: 0.1728  data: 0.0001  max mem: 15821
[21:54:06.489954] Test:  [210/345]  eta: 0:00:23  loss: 0.2166 (0.2010)  time: 0.1731  data: 0.0001  max mem: 15821
[21:54:08.227380] Test:  [220/345]  eta: 0:00:21  loss: 0.2075 (0.2009)  time: 0.1734  data: 0.0001  max mem: 15821
[21:54:09.968584] Test:  [230/345]  eta: 0:00:19  loss: 0.1987 (0.2011)  time: 0.1739  data: 0.0001  max mem: 15821
[21:54:11.712910] Test:  [240/345]  eta: 0:00:18  loss: 0.2023 (0.2015)  time: 0.1742  data: 0.0001  max mem: 15821
[21:54:13.459377] Test:  [250/345]  eta: 0:00:16  loss: 0.2053 (0.2019)  time: 0.1745  data: 0.0001  max mem: 15821
[21:54:15.210326] Test:  [260/345]  eta: 0:00:14  loss: 0.2053 (0.2021)  time: 0.1748  data: 0.0001  max mem: 15821
[21:54:16.964311] Test:  [270/345]  eta: 0:00:12  loss: 0.1989 (0.2015)  time: 0.1752  data: 0.0001  max mem: 15821
[21:54:18.722182] Test:  [280/345]  eta: 0:00:11  loss: 0.1966 (0.2017)  time: 0.1755  data: 0.0001  max mem: 15821
[21:54:20.482875] Test:  [290/345]  eta: 0:00:09  loss: 0.2029 (0.2017)  time: 0.1759  data: 0.0001  max mem: 15821
[21:54:22.247546] Test:  [300/345]  eta: 0:00:07  loss: 0.1949 (0.2014)  time: 0.1762  data: 0.0001  max mem: 15821
[21:54:24.017325] Test:  [310/345]  eta: 0:00:06  loss: 0.1913 (0.2016)  time: 0.1767  data: 0.0001  max mem: 15821
[21:54:25.789457] Test:  [320/345]  eta: 0:00:04  loss: 0.1954 (0.2018)  time: 0.1770  data: 0.0001  max mem: 15821
[21:54:27.566050] Test:  [330/345]  eta: 0:00:02  loss: 0.1933 (0.2016)  time: 0.1774  data: 0.0001  max mem: 15821
[21:54:29.344933] Test:  [340/345]  eta: 0:00:00  loss: 0.1940 (0.2019)  time: 0.1777  data: 0.0001  max mem: 15821
[21:54:30.057922] Test:  [344/345]  eta: 0:00:00  loss: 0.1969 (0.2020)  time: 0.1778  data: 0.0001  max mem: 15821
[21:54:30.126350] Test: Total time: 0:00:59 (0.1736 s / it)
[21:54:40.582190] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4755 (0.4755)  time: 0.5202  data: 0.3575  max mem: 15821
[21:54:42.228903] Test:  [10/57]  eta: 0:00:09  loss: 0.4122 (0.4543)  time: 0.1969  data: 0.0326  max mem: 15821
[21:54:43.880914] Test:  [20/57]  eta: 0:00:06  loss: 0.4122 (0.4411)  time: 0.1648  data: 0.0001  max mem: 15821
[21:54:45.536267] Test:  [30/57]  eta: 0:00:04  loss: 0.2749 (0.3818)  time: 0.1653  data: 0.0001  max mem: 15821
[21:54:47.196380] Test:  [40/57]  eta: 0:00:02  loss: 0.2565 (0.3557)  time: 0.1657  data: 0.0001  max mem: 15821
[21:54:48.861310] Test:  [50/57]  eta: 0:00:01  loss: 0.2801 (0.3514)  time: 0.1662  data: 0.0001  max mem: 15821
[21:54:49.758526] Test:  [56/57]  eta: 0:00:00  loss: 0.3477 (0.3756)  time: 0.1613  data: 0.0000  max mem: 15821
[21:54:49.836307] Test: Total time: 0:00:09 (0.1715 s / it)
[21:54:51.626551] Dice score of the network on the train images: 0.824387, val images: 0.768464
[21:54:51.630863] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:54:52.600494] Epoch: [19]  [  0/345]  eta: 0:05:34  lr: 0.000119  loss: 0.2040 (0.2040)  time: 0.9685  data: 0.3657  max mem: 15821
[21:55:04.574371] Epoch: [19]  [ 20/345]  eta: 0:03:20  lr: 0.000119  loss: 0.1982 (0.2063)  time: 0.5986  data: 0.0001  max mem: 15821
[21:55:16.579351] Epoch: [19]  [ 40/345]  eta: 0:03:05  lr: 0.000119  loss: 0.2000 (0.2066)  time: 0.6002  data: 0.0001  max mem: 15821
[21:55:28.591109] Epoch: [19]  [ 60/345]  eta: 0:02:52  lr: 0.000120  loss: 0.2120 (0.2073)  time: 0.6005  data: 0.0001  max mem: 15821
[21:55:40.624929] Epoch: [19]  [ 80/345]  eta: 0:02:40  lr: 0.000120  loss: 0.1964 (0.2054)  time: 0.6016  data: 0.0001  max mem: 15821
[21:55:52.693138] Epoch: [19]  [100/345]  eta: 0:02:28  lr: 0.000121  loss: 0.2134 (0.2077)  time: 0.6034  data: 0.0001  max mem: 15821
[21:56:04.775553] Epoch: [19]  [120/345]  eta: 0:02:16  lr: 0.000121  loss: 0.2099 (0.2072)  time: 0.6041  data: 0.0001  max mem: 15821
[21:56:16.867531] Epoch: [19]  [140/345]  eta: 0:02:03  lr: 0.000121  loss: 0.2028 (0.2070)  time: 0.6046  data: 0.0001  max mem: 15821
[21:56:28.962675] Epoch: [19]  [160/345]  eta: 0:01:51  lr: 0.000122  loss: 0.2015 (0.2068)  time: 0.6047  data: 0.0001  max mem: 15821
[21:56:41.053536] Epoch: [19]  [180/345]  eta: 0:01:39  lr: 0.000122  loss: 0.2158 (0.2085)  time: 0.6045  data: 0.0001  max mem: 15821
[21:56:53.127800] Epoch: [19]  [200/345]  eta: 0:01:27  lr: 0.000122  loss: 0.2095 (0.2086)  time: 0.6037  data: 0.0001  max mem: 15821
[21:57:05.222002] Epoch: [19]  [220/345]  eta: 0:01:15  lr: 0.000123  loss: 0.1989 (0.2082)  time: 0.6047  data: 0.0001  max mem: 15821
[21:57:17.304494] Epoch: [19]  [240/345]  eta: 0:01:03  lr: 0.000123  loss: 0.2007 (0.2078)  time: 0.6041  data: 0.0001  max mem: 15821
[21:57:29.367155] Epoch: [19]  [260/345]  eta: 0:00:51  lr: 0.000123  loss: 0.2142 (0.2084)  time: 0.6031  data: 0.0001  max mem: 15821
[21:57:41.423298] Epoch: [19]  [280/345]  eta: 0:00:39  lr: 0.000124  loss: 0.2113 (0.2086)  time: 0.6028  data: 0.0001  max mem: 15821

[21:57:53.557461] Epoch: [19]  [300/345]  eta: 0:00:27  lr: 0.000124  loss: 0.2002 (0.2081)  time: 0.6067  data: 0.0001  max mem: 15821
[21:58:05.620005] Epoch: [19]  [320/345]  eta: 0:00:15  lr: 0.000125  loss: 0.1993 (0.2082)  time: 0.6031  data: 0.0001  max mem: 15821
[21:58:17.666041] Epoch: [19]  [340/345]  eta: 0:00:03  lr: 0.000125  loss: 0.2126 (0.2086)  time: 0.6023  data: 0.0001  max mem: 15821
[21:58:20.077182] Epoch: [19]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.2017 (0.2085)  time: 0.6022  data: 0.0001  max mem: 15821
[21:58:20.153367] Epoch: [19] Total time: 0:03:28 (0.6044 s / it)
[21:58:20.153668] Averaged stats: lr: 0.000125  loss: 0.2017 (0.2085)
[21:58:20.726447] Test:  [  0/345]  eta: 0:03:15  loss: 0.2286 (0.2286)  time: 0.5658  data: 0.4013  max mem: 15821
[21:58:22.391951] Test:  [ 10/345]  eta: 0:01:07  loss: 0.2023 (0.2000)  time: 0.2028  data: 0.0366  max mem: 15821
[21:58:24.062479] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1975 (0.1995)  time: 0.1667  data: 0.0001  max mem: 15821
[21:58:25.734893] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1956 (0.2002)  time: 0.1671  data: 0.0001  max mem: 15821
[21:58:27.410858] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1958 (0.2016)  time: 0.1674  data: 0.0001  max mem: 15821
[21:58:29.090523] Test:  [ 50/345]  eta: 0:00:51  loss: 0.2084 (0.2023)  time: 0.1677  data: 0.0001  max mem: 15821
[21:58:30.773958] Test:  [ 60/345]  eta: 0:00:49  loss: 0.2089 (0.2037)  time: 0.1681  data: 0.0001  max mem: 15821
[21:58:32.459990] Test:  [ 70/345]  eta: 0:00:47  loss: 0.2009 (0.2030)  time: 0.1684  data: 0.0001  max mem: 15821
[21:58:34.149662] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1960 (0.2010)  time: 0.1687  data: 0.0001  max mem: 15821
[21:58:35.843286] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1853 (0.2000)  time: 0.1691  data: 0.0001  max mem: 15821
[21:58:37.540813] Test:  [100/345]  eta: 0:00:42  loss: 0.1818 (0.1984)  time: 0.1695  data: 0.0001  max mem: 15821
[21:58:39.241782] Test:  [110/345]  eta: 0:00:40  loss: 0.1818 (0.1969)  time: 0.1699  data: 0.0001  max mem: 15821
[21:58:40.944602] Test:  [120/345]  eta: 0:00:38  loss: 0.1842 (0.1966)  time: 0.1701  data: 0.0001  max mem: 15821
[21:58:42.651473] Test:  [130/345]  eta: 0:00:36  loss: 0.1863 (0.1964)  time: 0.1704  data: 0.0001  max mem: 15821
[21:58:44.361772] Test:  [140/345]  eta: 0:00:35  loss: 0.1926 (0.1962)  time: 0.1708  data: 0.0001  max mem: 15821
[21:58:46.074767] Test:  [150/345]  eta: 0:00:33  loss: 0.1894 (0.1953)  time: 0.1711  data: 0.0001  max mem: 15821
[21:58:47.791702] Test:  [160/345]  eta: 0:00:31  loss: 0.1875 (0.1958)  time: 0.1714  data: 0.0001  max mem: 15821
[21:58:49.513679] Test:  [170/345]  eta: 0:00:30  loss: 0.1960 (0.1955)  time: 0.1719  data: 0.0001  max mem: 15821
[21:58:51.239098] Test:  [180/345]  eta: 0:00:28  loss: 0.1955 (0.1954)  time: 0.1723  data: 0.0001  max mem: 15821
[21:58:52.965913] Test:  [190/345]  eta: 0:00:26  loss: 0.1926 (0.1954)  time: 0.1725  data: 0.0001  max mem: 15821
[21:58:54.696187] Test:  [200/345]  eta: 0:00:24  loss: 0.1930 (0.1952)  time: 0.1728  data: 0.0001  max mem: 15821
[21:58:56.430734] Test:  [210/345]  eta: 0:00:23  loss: 0.1959 (0.1957)  time: 0.1732  data: 0.0001  max mem: 15821
[21:58:58.168896] Test:  [220/345]  eta: 0:00:21  loss: 0.1929 (0.1956)  time: 0.1736  data: 0.0001  max mem: 15821
[21:58:59.911462] Test:  [230/345]  eta: 0:00:19  loss: 0.1918 (0.1958)  time: 0.1740  data: 0.0001  max mem: 15821
[21:59:01.656132] Test:  [240/345]  eta: 0:00:18  loss: 0.1968 (0.1960)  time: 0.1743  data: 0.0001  max mem: 15821
[21:59:03.404459] Test:  [250/345]  eta: 0:00:16  loss: 0.1857 (0.1956)  time: 0.1746  data: 0.0001  max mem: 15821
[21:59:05.155666] Test:  [260/345]  eta: 0:00:14  loss: 0.1810 (0.1952)  time: 0.1749  data: 0.0001  max mem: 15821
[21:59:06.910769] Test:  [270/345]  eta: 0:00:12  loss: 0.1874 (0.1954)  time: 0.1752  data: 0.0001  max mem: 15821
[21:59:08.669345] Test:  [280/345]  eta: 0:00:11  loss: 0.1972 (0.1956)  time: 0.1756  data: 0.0001  max mem: 15821
[21:59:10.430826] Test:  [290/345]  eta: 0:00:09  loss: 0.1982 (0.1955)  time: 0.1759  data: 0.0001  max mem: 15821
[21:59:12.195931] Test:  [300/345]  eta: 0:00:07  loss: 0.1982 (0.1958)  time: 0.1763  data: 0.0001  max mem: 15821
[21:59:13.966630] Test:  [310/345]  eta: 0:00:06  loss: 0.2036 (0.1960)  time: 0.1767  data: 0.0001  max mem: 15821
[21:59:15.739460] Test:  [320/345]  eta: 0:00:04  loss: 0.2036 (0.1964)  time: 0.1771  data: 0.0001  max mem: 15821
[21:59:17.515159] Test:  [330/345]  eta: 0:00:02  loss: 0.1930 (0.1961)  time: 0.1774  data: 0.0001  max mem: 15821
[21:59:19.296021] Test:  [340/345]  eta: 0:00:00  loss: 0.1930 (0.1964)  time: 0.1778  data: 0.0001  max mem: 15821
[21:59:20.010151] Test:  [344/345]  eta: 0:00:00  loss: 0.1810 (0.1962)  time: 0.1780  data: 0.0001  max mem: 15821
[21:59:20.087917] Test: Total time: 0:00:59 (0.1737 s / it)
[21:59:30.582339] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4436 (0.4436)  time: 0.5332  data: 0.3710  max mem: 15821
[21:59:32.230272] Test:  [10/57]  eta: 0:00:09  loss: 0.4131 (0.4332)  time: 0.1982  data: 0.0338  max mem: 15821
[21:59:33.883720] Test:  [20/57]  eta: 0:00:06  loss: 0.3924 (0.4123)  time: 0.1650  data: 0.0001  max mem: 15821
[21:59:35.542156] Test:  [30/57]  eta: 0:00:04  loss: 0.2708 (0.3572)  time: 0.1655  data: 0.0001  max mem: 15821
[21:59:37.203536] Test:  [40/57]  eta: 0:00:02  loss: 0.2578 (0.3337)  time: 0.1659  data: 0.0001  max mem: 15821
[21:59:38.867623] Test:  [50/57]  eta: 0:00:01  loss: 0.2817 (0.3345)  time: 0.1662  data: 0.0001  max mem: 15821
[21:59:39.765868] Test:  [56/57]  eta: 0:00:00  loss: 0.3220 (0.3517)  time: 0.1613  data: 0.0001  max mem: 15821
[21:59:39.841840] Test: Total time: 0:00:09 (0.1718 s / it)
[21:59:41.625256] Dice score of the network on the train images: 0.820676, val images: 0.784930
[21:59:41.629391] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[21:59:42.610357] Epoch: [20]  [  0/345]  eta: 0:05:38  lr: 0.000125  loss: 0.1656 (0.1656)  time: 0.9798  data: 0.3790  max mem: 15821
[21:59:54.594549] Epoch: [20]  [ 20/345]  eta: 0:03:20  lr: 0.000125  loss: 0.2112 (0.2093)  time: 0.5991  data: 0.0001  max mem: 15821
[22:00:06.602470] Epoch: [20]  [ 40/345]  eta: 0:03:05  lr: 0.000125  loss: 0.1931 (0.2029)  time: 0.6004  data: 0.0001  max mem: 15821
[22:00:18.638202] Epoch: [20]  [ 60/345]  eta: 0:02:52  lr: 0.000125  loss: 0.1907 (0.1998)  time: 0.6017  data: 0.0001  max mem: 15821
[22:00:30.696493] Epoch: [20]  [ 80/345]  eta: 0:02:40  lr: 0.000125  loss: 0.1822 (0.1976)  time: 0.6029  data: 0.0001  max mem: 15821
[22:00:42.767979] Epoch: [20]  [100/345]  eta: 0:02:28  lr: 0.000125  loss: 0.1994 (0.1992)  time: 0.6035  data: 0.0001  max mem: 15821
[22:00:54.858317] Epoch: [20]  [120/345]  eta: 0:02:16  lr: 0.000125  loss: 0.2005 (0.2001)  time: 0.6045  data: 0.0001  max mem: 15821
[22:01:06.946474] Epoch: [20]  [140/345]  eta: 0:02:04  lr: 0.000125  loss: 0.1852 (0.1993)  time: 0.6044  data: 0.0001  max mem: 15821
[22:01:19.033019] Epoch: [20]  [160/345]  eta: 0:01:51  lr: 0.000125  loss: 0.1979 (0.1995)  time: 0.6043  data: 0.0001  max mem: 15821
[22:01:31.119564] Epoch: [20]  [180/345]  eta: 0:01:39  lr: 0.000125  loss: 0.2056 (0.2003)  time: 0.6043  data: 0.0001  max mem: 15821
[22:01:43.337339] Epoch: [20]  [200/345]  eta: 0:01:27  lr: 0.000125  loss: 0.2014 (0.2005)  time: 0.6108  data: 0.0001  max mem: 15821
[22:01:55.429696] Epoch: [20]  [220/345]  eta: 0:01:15  lr: 0.000125  loss: 0.2058 (0.2012)  time: 0.6046  data: 0.0001  max mem: 15821
[22:02:07.508882] Epoch: [20]  [240/345]  eta: 0:01:03  lr: 0.000125  loss: 0.2124 (0.2026)  time: 0.6039  data: 0.0001  max mem: 15821
[22:02:19.594865] Epoch: [20]  [260/345]  eta: 0:00:51  lr: 0.000125  loss: 0.1998 (0.2023)  time: 0.6043  data: 0.0001  max mem: 15821
[22:02:31.680589] Epoch: [20]  [280/345]  eta: 0:00:39  lr: 0.000125  loss: 0.2098 (0.2029)  time: 0.6042  data: 0.0001  max mem: 15821
[22:02:43.753695] Epoch: [20]  [300/345]  eta: 0:00:27  lr: 0.000125  loss: 0.1997 (0.2029)  time: 0.6036  data: 0.0001  max mem: 15821
[22:02:55.822201] Epoch: [20]  [320/345]  eta: 0:00:15  lr: 0.000125  loss: 0.2089 (0.2036)  time: 0.6034  data: 0.0001  max mem: 15821
[22:03:07.887372] Epoch: [20]  [340/345]  eta: 0:00:03  lr: 0.000125  loss: 0.2048 (0.2041)  time: 0.6032  data: 0.0001  max mem: 15821
[22:03:10.302878] Epoch: [20]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.2048 (0.2041)  time: 0.6031  data: 0.0001  max mem: 15821
[22:03:10.367924] Epoch: [20] Total time: 0:03:28 (0.6050 s / it)
[22:03:10.368263] Averaged stats: lr: 0.000125  loss: 0.2048 (0.2041)
[22:03:10.939712] Test:  [  0/345]  eta: 0:03:15  loss: 0.1749 (0.1749)  time: 0.5658  data: 0.4014  max mem: 15821
[22:03:12.605188] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1857 (0.1855)  time: 0.2028  data: 0.0366  max mem: 15821
[22:03:14.273687] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1857 (0.1876)  time: 0.1666  data: 0.0001  max mem: 15821
[22:03:15.945428] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1895 (0.1902)  time: 0.1669  data: 0.0001  max mem: 15821
[22:03:17.621244] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1895 (0.1886)  time: 0.1673  data: 0.0001  max mem: 15821
[22:03:19.299453] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1849 (0.1902)  time: 0.1676  data: 0.0001  max mem: 15821
[22:03:20.981669] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1894 (0.1910)  time: 0.1680  data: 0.0001  max mem: 15821
[22:03:22.667394] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1894 (0.1913)  time: 0.1683  data: 0.0001  max mem: 15821
[22:03:24.354948] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1959 (0.1921)  time: 0.1686  data: 0.0001  max mem: 15821
[22:03:26.047263] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1959 (0.1925)  time: 0.1689  data: 0.0001  max mem: 15821
[22:03:27.743828] Test:  [100/345]  eta: 0:00:42  loss: 0.1872 (0.1931)  time: 0.1694  data: 0.0001  max mem: 15821
[22:03:29.443772] Test:  [110/345]  eta: 0:00:40  loss: 0.1963 (0.1941)  time: 0.1697  data: 0.0001  max mem: 15821
[22:03:31.147035] Test:  [120/345]  eta: 0:00:38  loss: 0.1963 (0.1937)  time: 0.1701  data: 0.0001  max mem: 15821
[22:03:32.852606] Test:  [130/345]  eta: 0:00:36  loss: 0.1924 (0.1939)  time: 0.1704  data: 0.0001  max mem: 15821
[22:03:34.562241] Test:  [140/345]  eta: 0:00:35  loss: 0.1847 (0.1943)  time: 0.1707  data: 0.0001  max mem: 15821
[22:03:36.274514] Test:  [150/345]  eta: 0:00:33  loss: 0.2096 (0.1953)  time: 0.1710  data: 0.0001  max mem: 15821
[22:03:37.992162] Test:  [160/345]  eta: 0:00:31  loss: 0.2096 (0.1960)  time: 0.1714  data: 0.0001  max mem: 15821
[22:03:39.712708] Test:  [170/345]  eta: 0:00:30  loss: 0.1989 (0.1962)  time: 0.1718  data: 0.0001  max mem: 15821
[22:03:41.437232] Test:  [180/345]  eta: 0:00:28  loss: 0.1972 (0.1962)  time: 0.1722  data: 0.0001  max mem: 15821
[22:03:43.164435] Test:  [190/345]  eta: 0:00:26  loss: 0.1894 (0.1954)  time: 0.1725  data: 0.0001  max mem: 15821
[22:03:44.894573] Test:  [200/345]  eta: 0:00:24  loss: 0.1894 (0.1957)  time: 0.1728  data: 0.0001  max mem: 15821
[22:03:46.628499] Test:  [210/345]  eta: 0:00:23  loss: 0.1898 (0.1955)  time: 0.1731  data: 0.0001  max mem: 15821
[22:03:48.365697] Test:  [220/345]  eta: 0:00:21  loss: 0.1905 (0.1957)  time: 0.1735  data: 0.0001  max mem: 15821
[22:03:50.106723] Test:  [230/345]  eta: 0:00:19  loss: 0.1958 (0.1960)  time: 0.1739  data: 0.0001  max mem: 15821
[22:03:51.851341] Test:  [240/345]  eta: 0:00:18  loss: 0.1912 (0.1955)  time: 0.1742  data: 0.0001  max mem: 15821
[22:03:53.599014] Test:  [250/345]  eta: 0:00:16  loss: 0.1816 (0.1948)  time: 0.1745  data: 0.0001  max mem: 15821
[22:03:55.350863] Test:  [260/345]  eta: 0:00:14  loss: 0.1862 (0.1950)  time: 0.1749  data: 0.0001  max mem: 15821
[22:03:57.105143] Test:  [270/345]  eta: 0:00:12  loss: 0.1907 (0.1951)  time: 0.1752  data: 0.0001  max mem: 15821
[22:03:58.862648] Test:  [280/345]  eta: 0:00:11  loss: 0.1907 (0.1949)  time: 0.1755  data: 0.0001  max mem: 15821
[22:04:00.625559] Test:  [290/345]  eta: 0:00:09  loss: 0.2021 (0.1955)  time: 0.1760  data: 0.0001  max mem: 15821
[22:04:02.390474] Test:  [300/345]  eta: 0:00:07  loss: 0.1936 (0.1954)  time: 0.1763  data: 0.0001  max mem: 15821
[22:04:04.159595] Test:  [310/345]  eta: 0:00:06  loss: 0.1863 (0.1951)  time: 0.1766  data: 0.0001  max mem: 15821
[22:04:05.931736] Test:  [320/345]  eta: 0:00:04  loss: 0.1855 (0.1948)  time: 0.1770  data: 0.0001  max mem: 15821
[22:04:07.708396] Test:  [330/345]  eta: 0:00:02  loss: 0.1939 (0.1951)  time: 0.1774  data: 0.0001  max mem: 15821
[22:04:09.486539] Test:  [340/345]  eta: 0:00:00  loss: 0.1939 (0.1948)  time: 0.1777  data: 0.0001  max mem: 15821
[22:04:10.199128] Test:  [344/345]  eta: 0:00:00  loss: 0.1893 (0.1948)  time: 0.1778  data: 0.0001  max mem: 15821
[22:04:10.264434] Test: Total time: 0:00:59 (0.1736 s / it)
[22:04:20.841798] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4620 (0.4620)  time: 0.5261  data: 0.3637  max mem: 15821
[22:04:22.488664] Test:  [10/57]  eta: 0:00:09  loss: 0.4579 (0.4771)  time: 0.1975  data: 0.0332  max mem: 15821
[22:04:24.141424] Test:  [20/57]  eta: 0:00:06  loss: 0.4240 (0.4588)  time: 0.1649  data: 0.0001  max mem: 15821
[22:04:25.798862] Test:  [30/57]  eta: 0:00:04  loss: 0.2724 (0.3875)  time: 0.1654  data: 0.0001  max mem: 15821
[22:04:27.459953] Test:  [40/57]  eta: 0:00:02  loss: 0.2502 (0.3602)  time: 0.1659  data: 0.0001  max mem: 15821
[22:04:29.125412] Test:  [50/57]  eta: 0:00:01  loss: 0.2844 (0.3573)  time: 0.1663  data: 0.0001  max mem: 15821
[22:04:30.023620] Test:  [56/57]  eta: 0:00:00  loss: 0.3675 (0.3719)  time: 0.1614  data: 0.0001  max mem: 15821
[22:04:30.099723] Test: Total time: 0:00:09 (0.1717 s / it)
[22:04:31.880516] Dice score of the network on the train images: 0.834212, val images: 0.789054
[22:04:31.880746] saving best_prec_model_0 @ epoch 20
[22:04:32.992711] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:04:33.966466] Epoch: [21]  [  0/345]  eta: 0:05:35  lr: 0.000125  loss: 0.1650 (0.1650)  time: 0.9725  data: 0.3745  max mem: 15821
[22:04:45.927985] Epoch: [21]  [ 20/345]  eta: 0:03:20  lr: 0.000125  loss: 0.2005 (0.2055)  time: 0.5980  data: 0.0001  max mem: 15821
[22:04:57.927142] Epoch: [21]  [ 40/345]  eta: 0:03:05  lr: 0.000125  loss: 0.1961 (0.2042)  time: 0.5999  data: 0.0001  max mem: 15821
[22:05:09.945752] Epoch: [21]  [ 60/345]  eta: 0:02:52  lr: 0.000125  loss: 0.2014 (0.2046)  time: 0.6009  data: 0.0001  max mem: 15821
[22:05:21.987172] Epoch: [21]  [ 80/345]  eta: 0:02:40  lr: 0.000124  loss: 0.1865 (0.2007)  time: 0.6020  data: 0.0001  max mem: 15821
[22:05:34.049506] Epoch: [21]  [100/345]  eta: 0:02:28  lr: 0.000124  loss: 0.1919 (0.2004)  time: 0.6031  data: 0.0001  max mem: 15821
[22:05:46.125458] Epoch: [21]  [120/345]  eta: 0:02:15  lr: 0.000124  loss: 0.1764 (0.1973)  time: 0.6038  data: 0.0001  max mem: 15821
[22:05:58.219845] Epoch: [21]  [140/345]  eta: 0:02:03  lr: 0.000124  loss: 0.1852 (0.1966)  time: 0.6047  data: 0.0001  max mem: 15821
[22:06:10.327323] Epoch: [21]  [160/345]  eta: 0:01:51  lr: 0.000124  loss: 0.1866 (0.1955)  time: 0.6053  data: 0.0001  max mem: 15821
[22:06:22.422859] Epoch: [21]  [180/345]  eta: 0:01:39  lr: 0.000124  loss: 0.1899 (0.1956)  time: 0.6047  data: 0.0001  max mem: 15821
[22:06:34.515351] Epoch: [21]  [200/345]  eta: 0:01:27  lr: 0.000124  loss: 0.1893 (0.1957)  time: 0.6046  data: 0.0001  max mem: 15821
[22:06:46.601206] Epoch: [21]  [220/345]  eta: 0:01:15  lr: 0.000124  loss: 0.1880 (0.1952)  time: 0.6042  data: 0.0001  max mem: 15821
[22:06:58.664398] Epoch: [21]  [240/345]  eta: 0:01:03  lr: 0.000124  loss: 0.1900 (0.1951)  time: 0.6031  data: 0.0001  max mem: 15821

[22:07:10.726383] Epoch: [21]  [260/345]  eta: 0:00:51  lr: 0.000124  loss: 0.1924 (0.1957)  time: 0.6031  data: 0.0001  max mem: 15821
[22:07:22.781915] Epoch: [21]  [280/345]  eta: 0:00:39  lr: 0.000124  loss: 0.1862 (0.1952)  time: 0.6027  data: 0.0001  max mem: 15821
[22:07:34.836255] Epoch: [21]  [300/345]  eta: 0:00:27  lr: 0.000124  loss: 0.1936 (0.1953)  time: 0.6027  data: 0.0001  max mem: 15821
[22:07:46.970551] Epoch: [21]  [320/345]  eta: 0:00:15  lr: 0.000124  loss: 0.1946 (0.1954)  time: 0.6067  data: 0.0001  max mem: 15821
[22:07:59.017688] Epoch: [21]  [340/345]  eta: 0:00:03  lr: 0.000124  loss: 0.1828 (0.1952)  time: 0.6023  data: 0.0001  max mem: 15821
[22:08:01.425429] Epoch: [21]  [344/345]  eta: 0:00:00  lr: 0.000124  loss: 0.1861 (0.1952)  time: 0.6023  data: 0.0001  max mem: 15821
[22:08:01.495503] Epoch: [21] Total time: 0:03:28 (0.6044 s / it)
[22:08:01.495797] Averaged stats: lr: 0.000124  loss: 0.1861 (0.1952)
[22:08:02.112005] Test:  [  0/345]  eta: 0:03:31  loss: 0.1917 (0.1917)  time: 0.6118  data: 0.4476  max mem: 15821
[22:08:03.777559] Test:  [ 10/345]  eta: 0:01:09  loss: 0.1802 (0.1876)  time: 0.2069  data: 0.0408  max mem: 15821
[22:08:05.446273] Test:  [ 20/345]  eta: 0:01:01  loss: 0.1921 (0.1938)  time: 0.1666  data: 0.0001  max mem: 15821
[22:08:07.118144] Test:  [ 30/345]  eta: 0:00:57  loss: 0.1921 (0.1897)  time: 0.1670  data: 0.0001  max mem: 15821
[22:08:08.793306] Test:  [ 40/345]  eta: 0:00:54  loss: 0.1799 (0.1883)  time: 0.1673  data: 0.0001  max mem: 15821
[22:08:10.471297] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1823 (0.1881)  time: 0.1676  data: 0.0001  max mem: 15821
[22:08:12.152482] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1830 (0.1879)  time: 0.1679  data: 0.0001  max mem: 15821
[22:08:13.838548] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1759 (0.1872)  time: 0.1683  data: 0.0001  max mem: 15821
[22:08:15.528047] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1744 (0.1858)  time: 0.1687  data: 0.0001  max mem: 15821
[22:08:17.221286] Test:  [ 90/345]  eta: 0:00:44  loss: 0.1760 (0.1857)  time: 0.1691  data: 0.0001  max mem: 15821
[22:08:18.917410] Test:  [100/345]  eta: 0:00:42  loss: 0.1865 (0.1864)  time: 0.1694  data: 0.0001  max mem: 15821
[22:08:20.616901] Test:  [110/345]  eta: 0:00:40  loss: 0.1854 (0.1854)  time: 0.1697  data: 0.0001  max mem: 15821
[22:08:22.320279] Test:  [120/345]  eta: 0:00:38  loss: 0.1854 (0.1861)  time: 0.1701  data: 0.0001  max mem: 15821
[22:08:24.025782] Test:  [130/345]  eta: 0:00:36  loss: 0.1933 (0.1874)  time: 0.1704  data: 0.0001  max mem: 15821
[22:08:25.736288] Test:  [140/345]  eta: 0:00:35  loss: 0.1861 (0.1872)  time: 0.1707  data: 0.0001  max mem: 15821
[22:08:27.448781] Test:  [150/345]  eta: 0:00:33  loss: 0.1795 (0.1872)  time: 0.1711  data: 0.0001  max mem: 15821
[22:08:29.166433] Test:  [160/345]  eta: 0:00:31  loss: 0.1838 (0.1873)  time: 0.1714  data: 0.0001  max mem: 15821
[22:08:30.887969] Test:  [170/345]  eta: 0:00:30  loss: 0.1850 (0.1868)  time: 0.1719  data: 0.0001  max mem: 15821
[22:08:32.612971] Test:  [180/345]  eta: 0:00:28  loss: 0.1850 (0.1875)  time: 0.1723  data: 0.0001  max mem: 15821
[22:08:34.339609] Test:  [190/345]  eta: 0:00:26  loss: 0.1918 (0.1878)  time: 0.1725  data: 0.0001  max mem: 15821
[22:08:36.070810] Test:  [200/345]  eta: 0:00:24  loss: 0.1809 (0.1877)  time: 0.1728  data: 0.0001  max mem: 15821
[22:08:37.804389] Test:  [210/345]  eta: 0:00:23  loss: 0.1800 (0.1871)  time: 0.1732  data: 0.0001  max mem: 15821
[22:08:39.541826] Test:  [220/345]  eta: 0:00:21  loss: 0.1780 (0.1872)  time: 0.1735  data: 0.0001  max mem: 15821
[22:08:41.281508] Test:  [230/345]  eta: 0:00:19  loss: 0.1884 (0.1875)  time: 0.1738  data: 0.0001  max mem: 15821
[22:08:43.025587] Test:  [240/345]  eta: 0:00:18  loss: 0.1892 (0.1875)  time: 0.1741  data: 0.0001  max mem: 15821
[22:08:44.774012] Test:  [250/345]  eta: 0:00:16  loss: 0.1695 (0.1870)  time: 0.1746  data: 0.0001  max mem: 15821
[22:08:46.525121] Test:  [260/345]  eta: 0:00:14  loss: 0.1738 (0.1868)  time: 0.1749  data: 0.0001  max mem: 15821
[22:08:48.280372] Test:  [270/345]  eta: 0:00:12  loss: 0.1738 (0.1866)  time: 0.1753  data: 0.0001  max mem: 15821
[22:08:50.038810] Test:  [280/345]  eta: 0:00:11  loss: 0.1763 (0.1869)  time: 0.1756  data: 0.0001  max mem: 15821
[22:08:51.800049] Test:  [290/345]  eta: 0:00:09  loss: 0.1878 (0.1871)  time: 0.1759  data: 0.0001  max mem: 15821
[22:08:53.565800] Test:  [300/345]  eta: 0:00:07  loss: 0.1864 (0.1873)  time: 0.1763  data: 0.0001  max mem: 15821
[22:08:55.335438] Test:  [310/345]  eta: 0:00:06  loss: 0.1832 (0.1869)  time: 0.1767  data: 0.0001  max mem: 15821
[22:08:57.107890] Test:  [320/345]  eta: 0:00:04  loss: 0.1794 (0.1871)  time: 0.1770  data: 0.0001  max mem: 15821
[22:08:58.882612] Test:  [330/345]  eta: 0:00:02  loss: 0.1783 (0.1870)  time: 0.1773  data: 0.0001  max mem: 15821
[22:09:00.662583] Test:  [340/345]  eta: 0:00:00  loss: 0.1792 (0.1871)  time: 0.1777  data: 0.0001  max mem: 15821
[22:09:01.375632] Test:  [344/345]  eta: 0:00:00  loss: 0.1792 (0.1871)  time: 0.1778  data: 0.0001  max mem: 15821
[22:09:01.454416] Test: Total time: 0:00:59 (0.1738 s / it)
[22:09:12.009169] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4702 (0.4702)  time: 0.5133  data: 0.3509  max mem: 15821
[22:09:13.655516] Test:  [10/57]  eta: 0:00:09  loss: 0.4390 (0.4683)  time: 0.1962  data: 0.0320  max mem: 15821
[22:09:15.308421] Test:  [20/57]  eta: 0:00:06  loss: 0.4350 (0.4572)  time: 0.1649  data: 0.0001  max mem: 15821
[22:09:16.965419] Test:  [30/57]  eta: 0:00:04  loss: 0.2895 (0.3925)  time: 0.1654  data: 0.0001  max mem: 15821
[22:09:18.626503] Test:  [40/57]  eta: 0:00:02  loss: 0.2536 (0.3680)  time: 0.1658  data: 0.0001  max mem: 15821
[22:09:20.292254] Test:  [50/57]  eta: 0:00:01  loss: 0.3152 (0.3684)  time: 0.1663  data: 0.0001  max mem: 15821
[22:09:21.190398] Test:  [56/57]  eta: 0:00:00  loss: 0.3372 (0.3894)  time: 0.1614  data: 0.0000  max mem: 15821
[22:09:21.262067] Test: Total time: 0:00:09 (0.1713 s / it)
[22:09:23.000693] Dice score of the network on the train images: 0.840125, val images: 0.765091
[22:09:23.005034] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:09:23.982740] Epoch: [22]  [  0/345]  eta: 0:05:36  lr: 0.000124  loss: 0.2451 (0.2451)  time: 0.9765  data: 0.3773  max mem: 15821
[22:09:35.963713] Epoch: [22]  [ 20/345]  eta: 0:03:20  lr: 0.000124  loss: 0.2021 (0.2031)  time: 0.5990  data: 0.0001  max mem: 15821
[22:09:47.970929] Epoch: [22]  [ 40/345]  eta: 0:03:05  lr: 0.000123  loss: 0.2012 (0.2001)  time: 0.6003  data: 0.0001  max mem: 15821
[22:09:59.990833] Epoch: [22]  [ 60/345]  eta: 0:02:52  lr: 0.000123  loss: 0.2009 (0.2012)  time: 0.6009  data: 0.0001  max mem: 15821
[22:10:12.011831] Epoch: [22]  [ 80/345]  eta: 0:02:40  lr: 0.000123  loss: 0.1840 (0.1978)  time: 0.6010  data: 0.0001  max mem: 15821
[22:10:24.084361] Epoch: [22]  [100/345]  eta: 0:02:28  lr: 0.000123  loss: 0.1765 (0.1959)  time: 0.6036  data: 0.0001  max mem: 15821
[22:10:36.180779] Epoch: [22]  [120/345]  eta: 0:02:16  lr: 0.000123  loss: 0.1793 (0.1947)  time: 0.6048  data: 0.0001  max mem: 15821
[22:10:48.273979] Epoch: [22]  [140/345]  eta: 0:02:03  lr: 0.000123  loss: 0.1901 (0.1949)  time: 0.6046  data: 0.0001  max mem: 15821
[22:11:00.372261] Epoch: [22]  [160/345]  eta: 0:01:51  lr: 0.000123  loss: 0.1976 (0.1961)  time: 0.6049  data: 0.0001  max mem: 15821
[22:11:12.465293] Epoch: [22]  [180/345]  eta: 0:01:39  lr: 0.000123  loss: 0.1856 (0.1949)  time: 0.6046  data: 0.0001  max mem: 15821
[22:11:24.538852] Epoch: [22]  [200/345]  eta: 0:01:27  lr: 0.000123  loss: 0.1781 (0.1945)  time: 0.6036  data: 0.0001  max mem: 15821
[22:11:36.621931] Epoch: [22]  [220/345]  eta: 0:01:15  lr: 0.000123  loss: 0.1730 (0.1933)  time: 0.6041  data: 0.0001  max mem: 15821
[22:11:48.708385] Epoch: [22]  [240/345]  eta: 0:01:03  lr: 0.000123  loss: 0.1948 (0.1938)  time: 0.6043  data: 0.0001  max mem: 15821
[22:12:00.771082] Epoch: [22]  [260/345]  eta: 0:00:51  lr: 0.000122  loss: 0.1795 (0.1931)  time: 0.6031  data: 0.0001  max mem: 15821
[22:12:12.835738] Epoch: [22]  [280/345]  eta: 0:00:39  lr: 0.000122  loss: 0.1723 (0.1920)  time: 0.6032  data: 0.0001  max mem: 15821
[22:12:24.917603] Epoch: [22]  [300/345]  eta: 0:00:27  lr: 0.000122  loss: 0.1926 (0.1917)  time: 0.6040  data: 0.0001  max mem: 15821
[22:12:36.993136] Epoch: [22]  [320/345]  eta: 0:00:15  lr: 0.000122  loss: 0.1934 (0.1921)  time: 0.6037  data: 0.0001  max mem: 15821
[22:12:49.063435] Epoch: [22]  [340/345]  eta: 0:00:03  lr: 0.000122  loss: 0.1792 (0.1918)  time: 0.6035  data: 0.0001  max mem: 15821
[22:12:51.474099] Epoch: [22]  [344/345]  eta: 0:00:00  lr: 0.000122  loss: 0.1805 (0.1916)  time: 0.6031  data: 0.0001  max mem: 15821
[22:12:51.551213] Epoch: [22] Total time: 0:03:28 (0.6045 s / it)
[22:12:51.551519] Averaged stats: lr: 0.000122  loss: 0.1805 (0.1916)
[22:12:52.127164] Test:  [  0/345]  eta: 0:03:16  loss: 0.1875 (0.1875)  time: 0.5699  data: 0.4053  max mem: 15821
[22:12:53.793453] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1806 (0.1860)  time: 0.2032  data: 0.0369  max mem: 15821
[22:12:55.462720] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1733 (0.1801)  time: 0.1667  data: 0.0001  max mem: 15821
[22:12:57.135495] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1729 (0.1774)  time: 0.1670  data: 0.0001  max mem: 15821
[22:12:58.811089] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1723 (0.1801)  time: 0.1674  data: 0.0001  max mem: 15821
[22:13:00.489763] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1747 (0.1802)  time: 0.1676  data: 0.0001  max mem: 15821
[22:13:02.171371] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1843 (0.1821)  time: 0.1679  data: 0.0001  max mem: 15821
[22:13:03.856549] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1843 (0.1816)  time: 0.1683  data: 0.0001  max mem: 15821
[22:13:05.544852] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1838 (0.1830)  time: 0.1686  data: 0.0001  max mem: 15821
[22:13:07.236368] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1848 (0.1832)  time: 0.1689  data: 0.0001  max mem: 15821
[22:13:08.932957] Test:  [100/345]  eta: 0:00:42  loss: 0.1779 (0.1820)  time: 0.1693  data: 0.0001  max mem: 15821
[22:13:10.633106] Test:  [110/345]  eta: 0:00:40  loss: 0.1733 (0.1819)  time: 0.1698  data: 0.0001  max mem: 15821
[22:13:12.337384] Test:  [120/345]  eta: 0:00:38  loss: 0.1709 (0.1803)  time: 0.1702  data: 0.0001  max mem: 15821
[22:13:14.043906] Test:  [130/345]  eta: 0:00:36  loss: 0.1730 (0.1804)  time: 0.1705  data: 0.0001  max mem: 15821
[22:13:15.753831] Test:  [140/345]  eta: 0:00:35  loss: 0.1804 (0.1808)  time: 0.1708  data: 0.0001  max mem: 15821
[22:13:17.468948] Test:  [150/345]  eta: 0:00:33  loss: 0.1763 (0.1801)  time: 0.1712  data: 0.0001  max mem: 15821
[22:13:19.186315] Test:  [160/345]  eta: 0:00:31  loss: 0.1700 (0.1806)  time: 0.1716  data: 0.0001  max mem: 15821
[22:13:20.907010] Test:  [170/345]  eta: 0:00:30  loss: 0.1916 (0.1819)  time: 0.1718  data: 0.0001  max mem: 15821
[22:13:22.630448] Test:  [180/345]  eta: 0:00:28  loss: 0.1968 (0.1822)  time: 0.1721  data: 0.0001  max mem: 15821
[22:13:24.357556] Test:  [190/345]  eta: 0:00:26  loss: 0.1771 (0.1823)  time: 0.1725  data: 0.0001  max mem: 15821
[22:13:26.087876] Test:  [200/345]  eta: 0:00:24  loss: 0.1758 (0.1818)  time: 0.1728  data: 0.0001  max mem: 15821
[22:13:27.821534] Test:  [210/345]  eta: 0:00:23  loss: 0.1724 (0.1815)  time: 0.1731  data: 0.0001  max mem: 15821
[22:13:29.559067] Test:  [220/345]  eta: 0:00:21  loss: 0.1724 (0.1812)  time: 0.1735  data: 0.0001  max mem: 15821
[22:13:31.299750] Test:  [230/345]  eta: 0:00:19  loss: 0.1745 (0.1814)  time: 0.1738  data: 0.0001  max mem: 15821
[22:13:33.043554] Test:  [240/345]  eta: 0:00:18  loss: 0.1745 (0.1808)  time: 0.1742  data: 0.0001  max mem: 15821
[22:13:34.791767] Test:  [250/345]  eta: 0:00:16  loss: 0.1730 (0.1811)  time: 0.1745  data: 0.0001  max mem: 15821
[22:13:36.542705] Test:  [260/345]  eta: 0:00:14  loss: 0.1838 (0.1810)  time: 0.1749  data: 0.0001  max mem: 15821
[22:13:38.297582] Test:  [270/345]  eta: 0:00:12  loss: 0.1878 (0.1813)  time: 0.1752  data: 0.0001  max mem: 15821
[22:13:40.055026] Test:  [280/345]  eta: 0:00:11  loss: 0.1919 (0.1820)  time: 0.1755  data: 0.0001  max mem: 15821
[22:13:41.816995] Test:  [290/345]  eta: 0:00:09  loss: 0.1953 (0.1818)  time: 0.1759  data: 0.0001  max mem: 15821
[22:13:43.581794] Test:  [300/345]  eta: 0:00:07  loss: 0.1761 (0.1819)  time: 0.1763  data: 0.0001  max mem: 15821
[22:13:45.350429] Test:  [310/345]  eta: 0:00:06  loss: 0.1800 (0.1819)  time: 0.1766  data: 0.0001  max mem: 15821
[22:13:47.123315] Test:  [320/345]  eta: 0:00:04  loss: 0.1806 (0.1819)  time: 0.1770  data: 0.0001  max mem: 15821
[22:13:48.899506] Test:  [330/345]  eta: 0:00:02  loss: 0.1693 (0.1816)  time: 0.1774  data: 0.0001  max mem: 15821
[22:13:50.678401] Test:  [340/345]  eta: 0:00:00  loss: 0.1718 (0.1814)  time: 0.1777  data: 0.0001  max mem: 15821
[22:13:51.390390] Test:  [344/345]  eta: 0:00:00  loss: 0.1718 (0.1812)  time: 0.1778  data: 0.0001  max mem: 15821
[22:13:51.460552] Test: Total time: 0:00:59 (0.1736 s / it)
[22:14:01.968039] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4550 (0.4550)  time: 0.5498  data: 0.3875  max mem: 15821
[22:14:03.612541] Test:  [10/57]  eta: 0:00:09  loss: 0.4026 (0.4318)  time: 0.1994  data: 0.0353  max mem: 15821
[22:14:05.263508] Test:  [20/57]  eta: 0:00:06  loss: 0.4012 (0.4193)  time: 0.1647  data: 0.0001  max mem: 15821
[22:14:06.920562] Test:  [30/57]  eta: 0:00:04  loss: 0.2604 (0.3616)  time: 0.1653  data: 0.0001  max mem: 15821
[22:14:08.581528] Test:  [40/57]  eta: 0:00:02  loss: 0.2409 (0.3366)  time: 0.1658  data: 0.0001  max mem: 15821
[22:14:10.246416] Test:  [50/57]  eta: 0:00:01  loss: 0.2607 (0.3333)  time: 0.1662  data: 0.0001  max mem: 15821
[22:14:11.145015] Test:  [56/57]  eta: 0:00:00  loss: 0.3254 (0.3534)  time: 0.1613  data: 0.0001  max mem: 15821
[22:14:11.220935] Test: Total time: 0:00:09 (0.1720 s / it)
[22:14:12.961305] Dice score of the network on the train images: 0.827695, val images: 0.789014
[22:14:12.965495] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:14:14.020797] Epoch: [23]  [  0/345]  eta: 0:06:03  lr: 0.000122  loss: 0.2011 (0.2011)  time: 1.0541  data: 0.4551  max mem: 15821
[22:14:25.999678] Epoch: [23]  [ 20/345]  eta: 0:03:21  lr: 0.000122  loss: 0.1881 (0.1949)  time: 0.5989  data: 0.0001  max mem: 15821
[22:14:37.991490] Epoch: [23]  [ 40/345]  eta: 0:03:06  lr: 0.000122  loss: 0.1870 (0.1916)  time: 0.5995  data: 0.0001  max mem: 15821
[22:14:49.996429] Epoch: [23]  [ 60/345]  eta: 0:02:52  lr: 0.000122  loss: 0.1894 (0.1909)  time: 0.6002  data: 0.0001  max mem: 15821
[22:15:02.039709] Epoch: [23]  [ 80/345]  eta: 0:02:40  lr: 0.000121  loss: 0.1787 (0.1883)  time: 0.6021  data: 0.0001  max mem: 15821
[22:15:14.103475] Epoch: [23]  [100/345]  eta: 0:02:28  lr: 0.000121  loss: 0.1694 (0.1860)  time: 0.6031  data: 0.0001  max mem: 15821
[22:15:26.192561] Epoch: [23]  [120/345]  eta: 0:02:16  lr: 0.000121  loss: 0.1944 (0.1881)  time: 0.6044  data: 0.0001  max mem: 15821
[22:15:38.289514] Epoch: [23]  [140/345]  eta: 0:02:04  lr: 0.000121  loss: 0.1860 (0.1893)  time: 0.6048  data: 0.0001  max mem: 15821
[22:15:50.388392] Epoch: [23]  [160/345]  eta: 0:01:51  lr: 0.000121  loss: 0.1755 (0.1885)  time: 0.6049  data: 0.0001  max mem: 15821
[22:16:02.481671] Epoch: [23]  [180/345]  eta: 0:01:39  lr: 0.000121  loss: 0.1749 (0.1881)  time: 0.6046  data: 0.0001  max mem: 15821
[22:16:14.579356] Epoch: [23]  [200/345]  eta: 0:01:27  lr: 0.000121  loss: 0.1968 (0.1889)  time: 0.6048  data: 0.0001  max mem: 15821
[22:16:26.673331] Epoch: [23]  [220/345]  eta: 0:01:15  lr: 0.000121  loss: 0.1878 (0.1885)  time: 0.6047  data: 0.0001  max mem: 15821
[22:16:38.771310] Epoch: [23]  [240/345]  eta: 0:01:03  lr: 0.000120  loss: 0.1873 (0.1883)  time: 0.6049  data: 0.0001  max mem: 15821
[22:16:50.858042] Epoch: [23]  [260/345]  eta: 0:00:51  lr: 0.000120  loss: 0.1741 (0.1879)  time: 0.6043  data: 0.0001  max mem: 15821
[22:17:02.946764] Epoch: [23]  [280/345]  eta: 0:00:39  lr: 0.000120  loss: 0.1823 (0.1877)  time: 0.6044  data: 0.0001  max mem: 15821
[22:17:15.102799] Epoch: [23]  [300/345]  eta: 0:00:27  lr: 0.000120  loss: 0.1745 (0.1868)  time: 0.6078  data: 0.0001  max mem: 15821
[22:17:27.178038] Epoch: [23]  [320/345]  eta: 0:00:15  lr: 0.000120  loss: 0.1917 (0.1873)  time: 0.6037  data: 0.0001  max mem: 15821
[22:17:39.242786] Epoch: [23]  [340/345]  eta: 0:00:03  lr: 0.000120  loss: 0.1822 (0.1872)  time: 0.6032  data: 0.0001  max mem: 15821
[22:17:41.654869] Epoch: [23]  [344/345]  eta: 0:00:00  lr: 0.000120  loss: 0.1822 (0.1872)  time: 0.6030  data: 0.0001  max mem: 15821
[22:17:41.727686] Epoch: [23] Total time: 0:03:28 (0.6051 s / it)
[22:17:41.727893] Averaged stats: lr: 0.000120  loss: 0.1822 (0.1872)
[22:17:42.300968] Test:  [  0/345]  eta: 0:03:15  loss: 0.1609 (0.1609)  time: 0.5675  data: 0.4027  max mem: 15821
[22:17:43.967052] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1757 (0.1835)  time: 0.2030  data: 0.0367  max mem: 15821
[22:17:45.636650] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1812 (0.1830)  time: 0.1667  data: 0.0001  max mem: 15821
[22:17:47.309217] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1800 (0.1832)  time: 0.1670  data: 0.0001  max mem: 15821
[22:17:48.985387] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1800 (0.1843)  time: 0.1674  data: 0.0001  max mem: 15821
[22:17:50.663689] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1800 (0.1831)  time: 0.1677  data: 0.0001  max mem: 15821
[22:17:52.346081] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1795 (0.1838)  time: 0.1680  data: 0.0001  max mem: 15821
[22:17:54.030920] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1842 (0.1842)  time: 0.1683  data: 0.0001  max mem: 15821
[22:17:55.719686] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1906 (0.1851)  time: 0.1686  data: 0.0001  max mem: 15821
[22:17:57.412537] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1882 (0.1846)  time: 0.1690  data: 0.0001  max mem: 15821
[22:17:59.108767] Test:  [100/345]  eta: 0:00:42  loss: 0.1882 (0.1860)  time: 0.1694  data: 0.0001  max mem: 15821
[22:18:00.809029] Test:  [110/345]  eta: 0:00:40  loss: 0.1915 (0.1861)  time: 0.1698  data: 0.0001  max mem: 15821
[22:18:02.512697] Test:  [120/345]  eta: 0:00:38  loss: 0.1763 (0.1861)  time: 0.1701  data: 0.0001  max mem: 15821
[22:18:04.218662] Test:  [130/345]  eta: 0:00:36  loss: 0.1786 (0.1864)  time: 0.1704  data: 0.0001  max mem: 15821
[22:18:05.929219] Test:  [140/345]  eta: 0:00:35  loss: 0.1791 (0.1867)  time: 0.1708  data: 0.0001  max mem: 15821
[22:18:07.641041] Test:  [150/345]  eta: 0:00:33  loss: 0.1831 (0.1870)  time: 0.1711  data: 0.0001  max mem: 15821
[22:18:09.357550] Test:  [160/345]  eta: 0:00:31  loss: 0.1890 (0.1871)  time: 0.1714  data: 0.0001  max mem: 15821
[22:18:11.079096] Test:  [170/345]  eta: 0:00:30  loss: 0.1866 (0.1878)  time: 0.1718  data: 0.0001  max mem: 15821
[22:18:12.804281] Test:  [180/345]  eta: 0:00:28  loss: 0.1866 (0.1880)  time: 0.1723  data: 0.0001  max mem: 15821
[22:18:14.531737] Test:  [190/345]  eta: 0:00:26  loss: 0.1830 (0.1877)  time: 0.1726  data: 0.0001  max mem: 15821
[22:18:16.263450] Test:  [200/345]  eta: 0:00:24  loss: 0.1809 (0.1876)  time: 0.1729  data: 0.0001  max mem: 15821
[22:18:17.997577] Test:  [210/345]  eta: 0:00:23  loss: 0.1756 (0.1873)  time: 0.1732  data: 0.0001  max mem: 15821
[22:18:19.733935] Test:  [220/345]  eta: 0:00:21  loss: 0.1814 (0.1875)  time: 0.1735  data: 0.0001  max mem: 15821
[22:18:21.475602] Test:  [230/345]  eta: 0:00:19  loss: 0.1839 (0.1874)  time: 0.1738  data: 0.0001  max mem: 15821
[22:18:23.220938] Test:  [240/345]  eta: 0:00:18  loss: 0.1903 (0.1877)  time: 0.1743  data: 0.0001  max mem: 15821
[22:18:24.968497] Test:  [250/345]  eta: 0:00:16  loss: 0.1794 (0.1873)  time: 0.1746  data: 0.0001  max mem: 15821
[22:18:26.719111] Test:  [260/345]  eta: 0:00:14  loss: 0.1742 (0.1870)  time: 0.1748  data: 0.0001  max mem: 15821
[22:18:28.474590] Test:  [270/345]  eta: 0:00:12  loss: 0.1821 (0.1872)  time: 0.1752  data: 0.0001  max mem: 15821
[22:18:30.231669] Test:  [280/345]  eta: 0:00:11  loss: 0.1945 (0.1877)  time: 0.1756  data: 0.0001  max mem: 15821
[22:18:31.993320] Test:  [290/345]  eta: 0:00:09  loss: 0.1945 (0.1875)  time: 0.1759  data: 0.0001  max mem: 15821
[22:18:33.757750] Test:  [300/345]  eta: 0:00:07  loss: 0.1787 (0.1873)  time: 0.1762  data: 0.0001  max mem: 15821
[22:18:35.528056] Test:  [310/345]  eta: 0:00:06  loss: 0.1787 (0.1870)  time: 0.1766  data: 0.0001  max mem: 15821
[22:18:37.300778] Test:  [320/345]  eta: 0:00:04  loss: 0.1807 (0.1868)  time: 0.1771  data: 0.0001  max mem: 15821
[22:18:39.076850] Test:  [330/345]  eta: 0:00:02  loss: 0.1809 (0.1870)  time: 0.1774  data: 0.0001  max mem: 15821
[22:18:40.856531] Test:  [340/345]  eta: 0:00:00  loss: 0.1865 (0.1868)  time: 0.1777  data: 0.0001  max mem: 15821
[22:18:41.570013] Test:  [344/345]  eta: 0:00:00  loss: 0.1846 (0.1868)  time: 0.1779  data: 0.0001  max mem: 15821
[22:18:41.646747] Test: Total time: 0:00:59 (0.1737 s / it)
[22:18:52.202096] Test:  [ 0/57]  eta: 0:00:33  loss: 0.4700 (0.4700)  time: 0.5791  data: 0.4170  max mem: 15821
[22:18:53.846409] Test:  [10/57]  eta: 0:00:09  loss: 0.4256 (0.4579)  time: 0.2021  data: 0.0380  max mem: 15821
[22:18:55.497720] Test:  [20/57]  eta: 0:00:06  loss: 0.4217 (0.4327)  time: 0.1647  data: 0.0001  max mem: 15821
[22:18:57.152963] Test:  [30/57]  eta: 0:00:04  loss: 0.3010 (0.3788)  time: 0.1653  data: 0.0001  max mem: 15821
[22:18:58.813364] Test:  [40/57]  eta: 0:00:02  loss: 0.2839 (0.3635)  time: 0.1657  data: 0.0001  max mem: 15821
[22:19:00.476690] Test:  [50/57]  eta: 0:00:01  loss: 0.3312 (0.3668)  time: 0.1661  data: 0.0001  max mem: 15821
[22:19:01.375077] Test:  [56/57]  eta: 0:00:00  loss: 0.3660 (0.3901)  time: 0.1612  data: 0.0000  max mem: 15821
[22:19:01.449243] Test: Total time: 0:00:09 (0.1724 s / it)
[22:19:03.180499] Dice score of the network on the train images: 0.849753, val images: 0.760412
[22:19:03.180728] saving best_prec_model_0 @ epoch 23
[22:19:04.262234] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:19:05.233605] Epoch: [24]  [  0/345]  eta: 0:05:34  lr: 0.000120  loss: 0.1842 (0.1842)  time: 0.9705  data: 0.3708  max mem: 15821
[22:19:17.219363] Epoch: [24]  [ 20/345]  eta: 0:03:20  lr: 0.000119  loss: 0.1824 (0.1868)  time: 0.5992  data: 0.0001  max mem: 15821
[22:19:29.224914] Epoch: [24]  [ 40/345]  eta: 0:03:05  lr: 0.000119  loss: 0.1727 (0.1850)  time: 0.6002  data: 0.0001  max mem: 15821
[22:19:41.255437] Epoch: [24]  [ 60/345]  eta: 0:02:52  lr: 0.000119  loss: 0.1748 (0.1835)  time: 0.6015  data: 0.0001  max mem: 15821
[22:19:53.299084] Epoch: [24]  [ 80/345]  eta: 0:02:40  lr: 0.000119  loss: 0.1901 (0.1856)  time: 0.6021  data: 0.0001  max mem: 15821
[22:20:05.359547] Epoch: [24]  [100/345]  eta: 0:02:28  lr: 0.000119  loss: 0.1657 (0.1827)  time: 0.6030  data: 0.0001  max mem: 15821
[22:20:17.450012] Epoch: [24]  [120/345]  eta: 0:02:16  lr: 0.000119  loss: 0.1750 (0.1827)  time: 0.6045  data: 0.0001  max mem: 15821
[22:20:29.540155] Epoch: [24]  [140/345]  eta: 0:02:03  lr: 0.000118  loss: 0.1705 (0.1817)  time: 0.6045  data: 0.0001  max mem: 15821
[22:20:41.631865] Epoch: [24]  [160/345]  eta: 0:01:51  lr: 0.000118  loss: 0.1875 (0.1830)  time: 0.6045  data: 0.0001  max mem: 15821

[22:20:53.733914] Epoch: [24]  [180/345]  eta: 0:01:39  lr: 0.000118  loss: 0.1882 (0.1838)  time: 0.6051  data: 0.0001  max mem: 15821
[22:21:05.832201] Epoch: [24]  [200/345]  eta: 0:01:27  lr: 0.000118  loss: 0.1698 (0.1826)  time: 0.6049  data: 0.0001  max mem: 15821
[22:21:17.909499] Epoch: [24]  [220/345]  eta: 0:01:15  lr: 0.000118  loss: 0.1799 (0.1825)  time: 0.6038  data: 0.0001  max mem: 15821
[22:21:29.984709] Epoch: [24]  [240/345]  eta: 0:01:03  lr: 0.000118  loss: 0.1679 (0.1815)  time: 0.6037  data: 0.0001  max mem: 15821
[22:21:42.065409] Epoch: [24]  [260/345]  eta: 0:00:51  lr: 0.000117  loss: 0.1746 (0.1812)  time: 0.6040  data: 0.0001  max mem: 15821
[22:21:54.137273] Epoch: [24]  [280/345]  eta: 0:00:39  lr: 0.000117  loss: 0.1831 (0.1816)  time: 0.6035  data: 0.0001  max mem: 15821
[22:22:06.206442] Epoch: [24]  [300/345]  eta: 0:00:27  lr: 0.000117  loss: 0.1707 (0.1819)  time: 0.6034  data: 0.0001  max mem: 15821
[22:22:18.267292] Epoch: [24]  [320/345]  eta: 0:00:15  lr: 0.000117  loss: 0.1663 (0.1814)  time: 0.6030  data: 0.0001  max mem: 15821
[22:22:30.320758] Epoch: [24]  [340/345]  eta: 0:00:03  lr: 0.000117  loss: 0.1854 (0.1813)  time: 0.6026  data: 0.0001  max mem: 15821
[22:22:32.731800] Epoch: [24]  [344/345]  eta: 0:00:00  lr: 0.000117  loss: 0.1774 (0.1814)  time: 0.6025  data: 0.0001  max mem: 15821
[22:22:32.811513] Epoch: [24] Total time: 0:03:28 (0.6045 s / it)
[22:22:32.811965] Averaged stats: lr: 0.000117  loss: 0.1774 (0.1814)
[22:22:33.441163] Test:  [  0/345]  eta: 0:03:35  loss: 0.1825 (0.1825)  time: 0.6242  data: 0.4597  max mem: 15821
[22:22:35.109412] Test:  [ 10/345]  eta: 0:01:09  loss: 0.1648 (0.1688)  time: 0.2083  data: 0.0419  max mem: 15821
[22:22:36.779448] Test:  [ 20/345]  eta: 0:01:01  loss: 0.1648 (0.1689)  time: 0.1668  data: 0.0001  max mem: 15821
[22:22:38.452711] Test:  [ 30/345]  eta: 0:00:57  loss: 0.1697 (0.1708)  time: 0.1671  data: 0.0001  max mem: 15821
[22:22:40.127702] Test:  [ 40/345]  eta: 0:00:54  loss: 0.1691 (0.1686)  time: 0.1673  data: 0.0001  max mem: 15821
[22:22:41.807153] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1660 (0.1694)  time: 0.1677  data: 0.0001  max mem: 15821
[22:22:43.490292] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1740 (0.1720)  time: 0.1681  data: 0.0001  max mem: 15821
[22:22:45.178462] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1695 (0.1717)  time: 0.1684  data: 0.0001  max mem: 15821
[22:22:46.868376] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1720 (0.1731)  time: 0.1687  data: 0.0001  max mem: 15821
[22:22:48.562586] Test:  [ 90/345]  eta: 0:00:44  loss: 0.1733 (0.1720)  time: 0.1691  data: 0.0001  max mem: 15821
[22:22:50.259643] Test:  [100/345]  eta: 0:00:42  loss: 0.1699 (0.1721)  time: 0.1695  data: 0.0001  max mem: 15821
[22:22:51.959984] Test:  [110/345]  eta: 0:00:40  loss: 0.1718 (0.1722)  time: 0.1698  data: 0.0001  max mem: 15821
[22:22:53.663051] Test:  [120/345]  eta: 0:00:38  loss: 0.1609 (0.1711)  time: 0.1701  data: 0.0001  max mem: 15821
[22:22:55.370378] Test:  [130/345]  eta: 0:00:36  loss: 0.1514 (0.1703)  time: 0.1704  data: 0.0001  max mem: 15821
[22:22:57.080857] Test:  [140/345]  eta: 0:00:35  loss: 0.1585 (0.1702)  time: 0.1708  data: 0.0001  max mem: 15821
[22:22:58.794404] Test:  [150/345]  eta: 0:00:33  loss: 0.1672 (0.1700)  time: 0.1711  data: 0.0001  max mem: 15821
[22:23:00.511700] Test:  [160/345]  eta: 0:00:31  loss: 0.1662 (0.1697)  time: 0.1715  data: 0.0001  max mem: 15821
[22:23:02.232192] Test:  [170/345]  eta: 0:00:30  loss: 0.1693 (0.1701)  time: 0.1718  data: 0.0001  max mem: 15821
[22:23:03.956996] Test:  [180/345]  eta: 0:00:28  loss: 0.1699 (0.1701)  time: 0.1722  data: 0.0001  max mem: 15821
[22:23:05.684014] Test:  [190/345]  eta: 0:00:26  loss: 0.1623 (0.1695)  time: 0.1725  data: 0.0001  max mem: 15821
[22:23:07.416436] Test:  [200/345]  eta: 0:00:24  loss: 0.1703 (0.1699)  time: 0.1729  data: 0.0001  max mem: 15821
[22:23:09.151021] Test:  [210/345]  eta: 0:00:23  loss: 0.1699 (0.1697)  time: 0.1733  data: 0.0001  max mem: 15821
[22:23:10.889358] Test:  [220/345]  eta: 0:00:21  loss: 0.1696 (0.1697)  time: 0.1736  data: 0.0001  max mem: 15821
[22:23:12.630237] Test:  [230/345]  eta: 0:00:19  loss: 0.1708 (0.1695)  time: 0.1739  data: 0.0001  max mem: 15821
[22:23:14.375152] Test:  [240/345]  eta: 0:00:18  loss: 0.1671 (0.1699)  time: 0.1742  data: 0.0001  max mem: 15821
[22:23:16.124691] Test:  [250/345]  eta: 0:00:16  loss: 0.1673 (0.1699)  time: 0.1746  data: 0.0001  max mem: 15821
[22:23:17.875850] Test:  [260/345]  eta: 0:00:14  loss: 0.1673 (0.1701)  time: 0.1750  data: 0.0001  max mem: 15821
[22:23:19.630239] Test:  [270/345]  eta: 0:00:12  loss: 0.1810 (0.1706)  time: 0.1752  data: 0.0001  max mem: 15821
[22:23:21.388235] Test:  [280/345]  eta: 0:00:11  loss: 0.1801 (0.1709)  time: 0.1756  data: 0.0001  max mem: 15821
[22:23:23.149620] Test:  [290/345]  eta: 0:00:09  loss: 0.1748 (0.1708)  time: 0.1759  data: 0.0001  max mem: 15821
[22:23:24.914768] Test:  [300/345]  eta: 0:00:07  loss: 0.1748 (0.1709)  time: 0.1763  data: 0.0001  max mem: 15821
[22:23:26.683685] Test:  [310/345]  eta: 0:00:06  loss: 0.1694 (0.1708)  time: 0.1766  data: 0.0001  max mem: 15821
[22:23:28.456914] Test:  [320/345]  eta: 0:00:04  loss: 0.1660 (0.1710)  time: 0.1770  data: 0.0001  max mem: 15821
[22:23:30.233179] Test:  [330/345]  eta: 0:00:02  loss: 0.1647 (0.1707)  time: 0.1774  data: 0.0001  max mem: 15821
[22:23:32.011881] Test:  [340/345]  eta: 0:00:00  loss: 0.1709 (0.1711)  time: 0.1777  data: 0.0001  max mem: 15821
[22:23:32.723846] Test:  [344/345]  eta: 0:00:00  loss: 0.1757 (0.1713)  time: 0.1778  data: 0.0001  max mem: 15821
[22:23:32.807052] Test: Total time: 0:00:59 (0.1739 s / it)
[22:23:43.219702] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4818 (0.4818)  time: 0.5219  data: 0.3597  max mem: 15821
[22:23:44.865450] Test:  [10/57]  eta: 0:00:09  loss: 0.4182 (0.4512)  time: 0.1970  data: 0.0328  max mem: 15821
[22:23:46.517070] Test:  [20/57]  eta: 0:00:06  loss: 0.4131 (0.4369)  time: 0.1648  data: 0.0001  max mem: 15821
[22:23:48.172436] Test:  [30/57]  eta: 0:00:04  loss: 0.2721 (0.3737)  time: 0.1653  data: 0.0001  max mem: 15821
[22:23:49.834739] Test:  [40/57]  eta: 0:00:02  loss: 0.2530 (0.3481)  time: 0.1658  data: 0.0001  max mem: 15821
[22:23:51.499375] Test:  [50/57]  eta: 0:00:01  loss: 0.2882 (0.3431)  time: 0.1663  data: 0.0001  max mem: 15821
[22:23:52.397713] Test:  [56/57]  eta: 0:00:00  loss: 0.3117 (0.3574)  time: 0.1614  data: 0.0000  max mem: 15821
[22:23:52.466594] Test: Total time: 0:00:09 (0.1714 s / it)
[22:23:54.214858] Dice score of the network on the train images: 0.851031, val images: 0.794438
[22:23:54.219356] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:23:55.195513] Epoch: [25]  [  0/345]  eta: 0:05:36  lr: 0.000117  loss: 0.1857 (0.1857)  time: 0.9750  data: 0.3752  max mem: 15821
[22:24:07.186953] Epoch: [25]  [ 20/345]  eta: 0:03:20  lr: 0.000116  loss: 0.1852 (0.1847)  time: 0.5995  data: 0.0001  max mem: 15821
[22:24:19.198332] Epoch: [25]  [ 40/345]  eta: 0:03:05  lr: 0.000116  loss: 0.1747 (0.1831)  time: 0.6005  data: 0.0001  max mem: 15821
[22:24:31.203840] Epoch: [25]  [ 60/345]  eta: 0:02:52  lr: 0.000116  loss: 0.1673 (0.1801)  time: 0.6002  data: 0.0001  max mem: 15821
[22:24:43.242877] Epoch: [25]  [ 80/345]  eta: 0:02:40  lr: 0.000116  loss: 0.1755 (0.1788)  time: 0.6019  data: 0.0001  max mem: 15821
[22:24:55.304024] Epoch: [25]  [100/345]  eta: 0:02:28  lr: 0.000116  loss: 0.1780 (0.1796)  time: 0.6030  data: 0.0001  max mem: 15821
[22:25:07.387305] Epoch: [25]  [120/345]  eta: 0:02:16  lr: 0.000115  loss: 0.1785 (0.1792)  time: 0.6041  data: 0.0001  max mem: 15821
[22:25:19.460247] Epoch: [25]  [140/345]  eta: 0:02:03  lr: 0.000115  loss: 0.1662 (0.1785)  time: 0.6036  data: 0.0001  max mem: 15821
[22:25:31.558040] Epoch: [25]  [160/345]  eta: 0:01:51  lr: 0.000115  loss: 0.1749 (0.1786)  time: 0.6048  data: 0.0001  max mem: 15821
[22:25:43.641827] Epoch: [25]  [180/345]  eta: 0:01:39  lr: 0.000115  loss: 0.1740 (0.1783)  time: 0.6041  data: 0.0001  max mem: 15821
[22:25:55.741269] Epoch: [25]  [200/345]  eta: 0:01:27  lr: 0.000115  loss: 0.1637 (0.1776)  time: 0.6049  data: 0.0001  max mem: 15821
[22:26:07.839706] Epoch: [25]  [220/345]  eta: 0:01:15  lr: 0.000114  loss: 0.1867 (0.1782)  time: 0.6049  data: 0.0001  max mem: 15821
[22:26:19.921738] Epoch: [25]  [240/345]  eta: 0:01:03  lr: 0.000114  loss: 0.1707 (0.1775)  time: 0.6041  data: 0.0001  max mem: 15821
[22:26:32.004870] Epoch: [25]  [260/345]  eta: 0:00:51  lr: 0.000114  loss: 0.1727 (0.1776)  time: 0.6041  data: 0.0001  max mem: 15821
[22:26:44.078288] Epoch: [25]  [280/345]  eta: 0:00:39  lr: 0.000114  loss: 0.1736 (0.1773)  time: 0.6036  data: 0.0001  max mem: 15821

[22:26:56.150359] Epoch: [25]  [300/345]  eta: 0:00:27  lr: 0.000114  loss: 0.1751 (0.1769)  time: 0.6036  data: 0.0001  max mem: 15821
[22:27:08.208414] Epoch: [25]  [320/345]  eta: 0:00:15  lr: 0.000113  loss: 0.1755 (0.1771)  time: 0.6029  data: 0.0001  max mem: 15821
[22:27:20.257273] Epoch: [25]  [340/345]  eta: 0:00:03  lr: 0.000113  loss: 0.1702 (0.1770)  time: 0.6024  data: 0.0001  max mem: 15821
[22:27:22.668902] Epoch: [25]  [344/345]  eta: 0:00:00  lr: 0.000113  loss: 0.1696 (0.1770)  time: 0.6024  data: 0.0001  max mem: 15821
[22:27:22.751607] Epoch: [25] Total time: 0:03:28 (0.6044 s / it)
[22:27:22.751838] Averaged stats: lr: 0.000113  loss: 0.1696 (0.1770)
[22:27:23.325665] Test:  [  0/345]  eta: 0:03:15  loss: 0.1681 (0.1681)  time: 0.5681  data: 0.4035  max mem: 15821
[22:27:24.992860] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1700 (0.1759)  time: 0.2031  data: 0.0368  max mem: 15821
[22:27:26.663223] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1710 (0.1776)  time: 0.1668  data: 0.0001  max mem: 15821
[22:27:28.335891] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1632 (0.1724)  time: 0.1671  data: 0.0001  max mem: 15821
[22:27:30.012882] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1580 (0.1692)  time: 0.1674  data: 0.0001  max mem: 15821
[22:27:31.692673] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1530 (0.1657)  time: 0.1678  data: 0.0001  max mem: 15821
[22:27:33.374706] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1535 (0.1645)  time: 0.1680  data: 0.0001  max mem: 15821
[22:27:35.061377] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1630 (0.1664)  time: 0.1684  data: 0.0001  max mem: 15821
[22:27:36.751156] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1656 (0.1664)  time: 0.1688  data: 0.0001  max mem: 15821
[22:27:38.444828] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1590 (0.1656)  time: 0.1691  data: 0.0001  max mem: 15821
[22:27:40.141876] Test:  [100/345]  eta: 0:00:42  loss: 0.1603 (0.1659)  time: 0.1695  data: 0.0001  max mem: 15821
[22:27:41.842074] Test:  [110/345]  eta: 0:00:40  loss: 0.1593 (0.1656)  time: 0.1698  data: 0.0001  max mem: 15821
[22:27:43.545467] Test:  [120/345]  eta: 0:00:38  loss: 0.1567 (0.1659)  time: 0.1701  data: 0.0001  max mem: 15821
[22:27:45.252458] Test:  [130/345]  eta: 0:00:36  loss: 0.1723 (0.1666)  time: 0.1705  data: 0.0001  max mem: 15821
[22:27:46.963651] Test:  [140/345]  eta: 0:00:35  loss: 0.1683 (0.1665)  time: 0.1708  data: 0.0001  max mem: 15821
[22:27:48.678288] Test:  [150/345]  eta: 0:00:33  loss: 0.1603 (0.1662)  time: 0.1712  data: 0.0001  max mem: 15821
[22:27:50.395255] Test:  [160/345]  eta: 0:00:31  loss: 0.1651 (0.1666)  time: 0.1715  data: 0.0001  max mem: 15821
[22:27:52.115773] Test:  [170/345]  eta: 0:00:30  loss: 0.1651 (0.1661)  time: 0.1718  data: 0.0001  max mem: 15821
[22:27:53.840213] Test:  [180/345]  eta: 0:00:28  loss: 0.1526 (0.1656)  time: 0.1722  data: 0.0001  max mem: 15821
[22:27:55.568370] Test:  [190/345]  eta: 0:00:26  loss: 0.1516 (0.1656)  time: 0.1726  data: 0.0001  max mem: 15821
[22:27:57.299748] Test:  [200/345]  eta: 0:00:24  loss: 0.1667 (0.1658)  time: 0.1729  data: 0.0001  max mem: 15821
[22:27:59.032988] Test:  [210/345]  eta: 0:00:23  loss: 0.1695 (0.1664)  time: 0.1732  data: 0.0001  max mem: 15821
[22:28:00.770454] Test:  [220/345]  eta: 0:00:21  loss: 0.1695 (0.1665)  time: 0.1735  data: 0.0001  max mem: 15821
[22:28:02.512969] Test:  [230/345]  eta: 0:00:19  loss: 0.1686 (0.1664)  time: 0.1739  data: 0.0001  max mem: 15821
[22:28:04.257394] Test:  [240/345]  eta: 0:00:18  loss: 0.1618 (0.1662)  time: 0.1743  data: 0.0001  max mem: 15821
[22:28:06.005473] Test:  [250/345]  eta: 0:00:16  loss: 0.1617 (0.1660)  time: 0.1746  data: 0.0001  max mem: 15821
[22:28:07.756170] Test:  [260/345]  eta: 0:00:14  loss: 0.1499 (0.1656)  time: 0.1749  data: 0.0001  max mem: 15821
[22:28:09.510746] Test:  [270/345]  eta: 0:00:12  loss: 0.1563 (0.1655)  time: 0.1752  data: 0.0001  max mem: 15821
[22:28:11.269471] Test:  [280/345]  eta: 0:00:11  loss: 0.1613 (0.1655)  time: 0.1756  data: 0.0001  max mem: 15821
[22:28:13.031728] Test:  [290/345]  eta: 0:00:09  loss: 0.1613 (0.1658)  time: 0.1760  data: 0.0001  max mem: 15821
[22:28:14.796722] Test:  [300/345]  eta: 0:00:07  loss: 0.1637 (0.1659)  time: 0.1763  data: 0.0001  max mem: 15821
[22:28:16.565526] Test:  [310/345]  eta: 0:00:06  loss: 0.1610 (0.1657)  time: 0.1766  data: 0.0001  max mem: 15821
[22:28:18.339453] Test:  [320/345]  eta: 0:00:04  loss: 0.1639 (0.1663)  time: 0.1771  data: 0.0001  max mem: 15821
[22:28:20.114942] Test:  [330/345]  eta: 0:00:02  loss: 0.1686 (0.1664)  time: 0.1774  data: 0.0001  max mem: 15821
[22:28:21.894627] Test:  [340/345]  eta: 0:00:00  loss: 0.1638 (0.1666)  time: 0.1777  data: 0.0001  max mem: 15821
[22:28:22.606798] Test:  [344/345]  eta: 0:00:00  loss: 0.1638 (0.1665)  time: 0.1778  data: 0.0001  max mem: 15821
[22:28:22.676275] Test: Total time: 0:00:59 (0.1737 s / it)
[22:28:33.109986] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4609 (0.4609)  time: 0.5226  data: 0.3603  max mem: 15821
[22:28:34.756412] Test:  [10/57]  eta: 0:00:09  loss: 0.4558 (0.4592)  time: 0.1971  data: 0.0328  max mem: 15821
[22:28:36.407927] Test:  [20/57]  eta: 0:00:06  loss: 0.4111 (0.4355)  time: 0.1648  data: 0.0001  max mem: 15821
[22:28:38.065339] Test:  [30/57]  eta: 0:00:04  loss: 0.2711 (0.3733)  time: 0.1654  data: 0.0001  max mem: 15821
[22:28:39.726742] Test:  [40/57]  eta: 0:00:02  loss: 0.2342 (0.3483)  time: 0.1659  data: 0.0001  max mem: 15821
[22:28:41.390979] Test:  [50/57]  eta: 0:00:01  loss: 0.2833 (0.3468)  time: 0.1662  data: 0.0001  max mem: 15821
[22:28:42.289073] Test:  [56/57]  eta: 0:00:00  loss: 0.3170 (0.3657)  time: 0.1613  data: 0.0000  max mem: 15821
[22:28:42.360869] Test: Total time: 0:00:09 (0.1715 s / it)
[22:28:44.115597] Dice score of the network on the train images: 0.847130, val images: 0.782476
[22:28:44.119711] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:28:45.117969] Epoch: [26]  [  0/345]  eta: 0:05:43  lr: 0.000113  loss: 0.1578 (0.1578)  time: 0.9970  data: 0.3967  max mem: 15821
[22:28:57.095771] Epoch: [26]  [ 20/345]  eta: 0:03:20  lr: 0.000113  loss: 0.1588 (0.1634)  time: 0.5988  data: 0.0001  max mem: 15821
[22:29:09.113384] Epoch: [26]  [ 40/345]  eta: 0:03:05  lr: 0.000113  loss: 0.1637 (0.1655)  time: 0.6008  data: 0.0001  max mem: 15821
[22:29:21.145645] Epoch: [26]  [ 60/345]  eta: 0:02:52  lr: 0.000112  loss: 0.1602 (0.1659)  time: 0.6016  data: 0.0001  max mem: 15821
[22:29:33.186417] Epoch: [26]  [ 80/345]  eta: 0:02:40  lr: 0.000112  loss: 0.1624 (0.1662)  time: 0.6020  data: 0.0001  max mem: 15821
[22:29:45.244751] Epoch: [26]  [100/345]  eta: 0:02:28  lr: 0.000112  loss: 0.1745 (0.1670)  time: 0.6029  data: 0.0001  max mem: 15821
[22:29:57.328361] Epoch: [26]  [120/345]  eta: 0:02:16  lr: 0.000112  loss: 0.1728 (0.1680)  time: 0.6041  data: 0.0001  max mem: 15821
[22:30:09.426830] Epoch: [26]  [140/345]  eta: 0:02:04  lr: 0.000111  loss: 0.1690 (0.1686)  time: 0.6049  data: 0.0001  max mem: 15821
[22:30:21.508722] Epoch: [26]  [160/345]  eta: 0:01:51  lr: 0.000111  loss: 0.1651 (0.1686)  time: 0.6041  data: 0.0001  max mem: 15821
[22:30:33.607170] Epoch: [26]  [180/345]  eta: 0:01:39  lr: 0.000111  loss: 0.1691 (0.1687)  time: 0.6049  data: 0.0001  max mem: 15821
[22:30:45.687682] Epoch: [26]  [200/345]  eta: 0:01:27  lr: 0.000111  loss: 0.1753 (0.1699)  time: 0.6040  data: 0.0001  max mem: 15821
[22:30:57.755958] Epoch: [26]  [220/345]  eta: 0:01:15  lr: 0.000110  loss: 0.1865 (0.1706)  time: 0.6034  data: 0.0001  max mem: 15821
[22:31:09.833299] Epoch: [26]  [240/345]  eta: 0:01:03  lr: 0.000110  loss: 0.1613 (0.1706)  time: 0.6038  data: 0.0001  max mem: 15821
[22:31:21.928608] Epoch: [26]  [260/345]  eta: 0:00:51  lr: 0.000110  loss: 0.1645 (0.1705)  time: 0.6047  data: 0.0001  max mem: 15821
[22:31:34.001137] Epoch: [26]  [280/345]  eta: 0:00:39  lr: 0.000110  loss: 0.1729 (0.1711)  time: 0.6036  data: 0.0001  max mem: 15821
[22:31:46.088326] Epoch: [26]  [300/345]  eta: 0:00:27  lr: 0.000110  loss: 0.1680 (0.1710)  time: 0.6043  data: 0.0001  max mem: 15821
[22:31:58.160010] Epoch: [26]  [320/345]  eta: 0:00:15  lr: 0.000109  loss: 0.1644 (0.1708)  time: 0.6035  data: 0.0001  max mem: 15821
[22:32:10.216037] Epoch: [26]  [340/345]  eta: 0:00:03  lr: 0.000109  loss: 0.1776 (0.1711)  time: 0.6028  data: 0.0001  max mem: 15821
[22:32:12.628356] Epoch: [26]  [344/345]  eta: 0:00:00  lr: 0.000109  loss: 0.1791 (0.1714)  time: 0.6027  data: 0.0001  max mem: 15821
[22:32:12.709287] Epoch: [26] Total time: 0:03:28 (0.6046 s / it)
[22:32:12.709664] Averaged stats: lr: 0.000109  loss: 0.1791 (0.1714)
[22:32:13.357231] Test:  [  0/345]  eta: 0:03:40  loss: 0.1839 (0.1839)  time: 0.6398  data: 0.4749  max mem: 15821
[22:32:15.025624] Test:  [ 10/345]  eta: 0:01:10  loss: 0.1610 (0.1634)  time: 0.2098  data: 0.0432  max mem: 15821
[22:32:16.697238] Test:  [ 20/345]  eta: 0:01:01  loss: 0.1595 (0.1638)  time: 0.1669  data: 0.0001  max mem: 15821
[22:32:18.370939] Test:  [ 30/345]  eta: 0:00:57  loss: 0.1602 (0.1661)  time: 0.1672  data: 0.0001  max mem: 15821
[22:32:20.047470] Test:  [ 40/345]  eta: 0:00:54  loss: 0.1602 (0.1649)  time: 0.1674  data: 0.0001  max mem: 15821
[22:32:21.727704] Test:  [ 50/345]  eta: 0:00:52  loss: 0.1593 (0.1649)  time: 0.1678  data: 0.0001  max mem: 15821
[22:32:23.410880] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1593 (0.1651)  time: 0.1681  data: 0.0001  max mem: 15821
[22:32:25.098263] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1673 (0.1669)  time: 0.1685  data: 0.0001  max mem: 15821
[22:32:26.788941] Test:  [ 80/345]  eta: 0:00:46  loss: 0.1673 (0.1660)  time: 0.1688  data: 0.0001  max mem: 15821
[22:32:28.482658] Test:  [ 90/345]  eta: 0:00:44  loss: 0.1631 (0.1661)  time: 0.1692  data: 0.0001  max mem: 15821
[22:32:30.179811] Test:  [100/345]  eta: 0:00:42  loss: 0.1626 (0.1660)  time: 0.1695  data: 0.0001  max mem: 15821
[22:32:31.881262] Test:  [110/345]  eta: 0:00:40  loss: 0.1563 (0.1649)  time: 0.1699  data: 0.0001  max mem: 15821
[22:32:33.584495] Test:  [120/345]  eta: 0:00:38  loss: 0.1563 (0.1650)  time: 0.1702  data: 0.0001  max mem: 15821
[22:32:35.292284] Test:  [130/345]  eta: 0:00:37  loss: 0.1610 (0.1648)  time: 0.1705  data: 0.0001  max mem: 15821
[22:32:37.003196] Test:  [140/345]  eta: 0:00:35  loss: 0.1622 (0.1653)  time: 0.1709  data: 0.0001  max mem: 15821
[22:32:38.716972] Test:  [150/345]  eta: 0:00:33  loss: 0.1517 (0.1644)  time: 0.1712  data: 0.0001  max mem: 15821
[22:32:40.435087] Test:  [160/345]  eta: 0:00:31  loss: 0.1517 (0.1644)  time: 0.1715  data: 0.0001  max mem: 15821
[22:32:42.157724] Test:  [170/345]  eta: 0:00:30  loss: 0.1643 (0.1645)  time: 0.1720  data: 0.0001  max mem: 15821
[22:32:43.882845] Test:  [180/345]  eta: 0:00:28  loss: 0.1598 (0.1645)  time: 0.1723  data: 0.0001  max mem: 15821
[22:32:45.611230] Test:  [190/345]  eta: 0:00:26  loss: 0.1598 (0.1648)  time: 0.1726  data: 0.0001  max mem: 15821
[22:32:47.343344] Test:  [200/345]  eta: 0:00:24  loss: 0.1645 (0.1652)  time: 0.1730  data: 0.0001  max mem: 15821
[22:32:49.078674] Test:  [210/345]  eta: 0:00:23  loss: 0.1640 (0.1648)  time: 0.1733  data: 0.0001  max mem: 15821
[22:32:50.816701] Test:  [220/345]  eta: 0:00:21  loss: 0.1524 (0.1643)  time: 0.1736  data: 0.0001  max mem: 15821
[22:32:52.558825] Test:  [230/345]  eta: 0:00:19  loss: 0.1539 (0.1642)  time: 0.1739  data: 0.0001  max mem: 15821
[22:32:54.304572] Test:  [240/345]  eta: 0:00:18  loss: 0.1620 (0.1641)  time: 0.1743  data: 0.0001  max mem: 15821
[22:32:56.053047] Test:  [250/345]  eta: 0:00:16  loss: 0.1627 (0.1641)  time: 0.1746  data: 0.0001  max mem: 15821
[22:32:57.806608] Test:  [260/345]  eta: 0:00:14  loss: 0.1686 (0.1643)  time: 0.1750  data: 0.0001  max mem: 15821
[22:32:59.562594] Test:  [270/345]  eta: 0:00:12  loss: 0.1672 (0.1646)  time: 0.1754  data: 0.0001  max mem: 15821
[22:33:01.323962] Test:  [280/345]  eta: 0:00:11  loss: 0.1624 (0.1646)  time: 0.1758  data: 0.0001  max mem: 15821
[22:33:03.086447] Test:  [290/345]  eta: 0:00:09  loss: 0.1624 (0.1645)  time: 0.1761  data: 0.0001  max mem: 15821
[22:33:04.851781] Test:  [300/345]  eta: 0:00:07  loss: 0.1676 (0.1648)  time: 0.1763  data: 0.0001  max mem: 15821
[22:33:06.622140] Test:  [310/345]  eta: 0:00:06  loss: 0.1601 (0.1648)  time: 0.1767  data: 0.0001  max mem: 15821
[22:33:08.394518] Test:  [320/345]  eta: 0:00:04  loss: 0.1592 (0.1646)  time: 0.1771  data: 0.0001  max mem: 15821
[22:33:10.172741] Test:  [330/345]  eta: 0:00:02  loss: 0.1602 (0.1649)  time: 0.1775  data: 0.0001  max mem: 15821
[22:33:11.953017] Test:  [340/345]  eta: 0:00:00  loss: 0.1634 (0.1648)  time: 0.1779  data: 0.0001  max mem: 15821
[22:33:12.667061] Test:  [344/345]  eta: 0:00:00  loss: 0.1680 (0.1648)  time: 0.1780  data: 0.0001  max mem: 15821
[22:33:12.745084] Test: Total time: 0:01:00 (0.1740 s / it)
[22:33:23.261131] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4636 (0.4636)  time: 0.5372  data: 0.3752  max mem: 15821
[22:33:24.906756] Test:  [10/57]  eta: 0:00:09  loss: 0.4502 (0.4557)  time: 0.1984  data: 0.0342  max mem: 15821
[22:33:26.557602] Test:  [20/57]  eta: 0:00:06  loss: 0.4260 (0.4322)  time: 0.1648  data: 0.0001  max mem: 15821
[22:33:28.212921] Test:  [30/57]  eta: 0:00:04  loss: 0.2677 (0.3686)  time: 0.1652  data: 0.0001  max mem: 15821
[22:33:29.873363] Test:  [40/57]  eta: 0:00:02  loss: 0.2320 (0.3435)  time: 0.1657  data: 0.0001  max mem: 15821
[22:33:31.540795] Test:  [50/57]  eta: 0:00:01  loss: 0.2884 (0.3413)  time: 0.1663  data: 0.0001  max mem: 15821
[22:33:32.439836] Test:  [56/57]  eta: 0:00:00  loss: 0.3281 (0.3580)  time: 0.1615  data: 0.0001  max mem: 15821
[22:33:32.508988] Test: Total time: 0:00:09 (0.1717 s / it)
[22:33:34.261836] Dice score of the network on the train images: 0.843504, val images: 0.797856
[22:33:34.266230] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:33:35.263093] Epoch: [27]  [  0/345]  eta: 0:05:43  lr: 0.000109  loss: 0.1513 (0.1513)  time: 0.9957  data: 0.3963  max mem: 15821
[22:33:47.252669] Epoch: [27]  [ 20/345]  eta: 0:03:20  lr: 0.000109  loss: 0.1717 (0.1712)  time: 0.5994  data: 0.0001  max mem: 15821
[22:33:59.267359] Epoch: [27]  [ 40/345]  eta: 0:03:05  lr: 0.000108  loss: 0.1552 (0.1655)  time: 0.6007  data: 0.0001  max mem: 15821
[22:34:11.295009] Epoch: [27]  [ 60/345]  eta: 0:02:52  lr: 0.000108  loss: 0.1610 (0.1648)  time: 0.6013  data: 0.0001  max mem: 15821
[22:34:23.340715] Epoch: [27]  [ 80/345]  eta: 0:02:40  lr: 0.000108  loss: 0.1592 (0.1655)  time: 0.6022  data: 0.0001  max mem: 15821
[22:34:35.392747] Epoch: [27]  [100/345]  eta: 0:02:28  lr: 0.000108  loss: 0.1648 (0.1653)  time: 0.6026  data: 0.0001  max mem: 15821
[22:34:47.454865] Epoch: [27]  [120/345]  eta: 0:02:16  lr: 0.000107  loss: 0.1671 (0.1657)  time: 0.6031  data: 0.0001  max mem: 15821
[22:34:59.536394] Epoch: [27]  [140/345]  eta: 0:02:03  lr: 0.000107  loss: 0.1692 (0.1670)  time: 0.6040  data: 0.0001  max mem: 15821
[22:35:11.634517] Epoch: [27]  [160/345]  eta: 0:01:51  lr: 0.000107  loss: 0.1607 (0.1665)  time: 0.6049  data: 0.0001  max mem: 15821
[22:35:23.737603] Epoch: [27]  [180/345]  eta: 0:01:39  lr: 0.000107  loss: 0.1667 (0.1671)  time: 0.6051  data: 0.0001  max mem: 15821
[22:35:35.835312] Epoch: [27]  [200/345]  eta: 0:01:27  lr: 0.000106  loss: 0.1632 (0.1672)  time: 0.6048  data: 0.0001  max mem: 15821
[22:35:48.048315] Epoch: [27]  [220/345]  eta: 0:01:15  lr: 0.000106  loss: 0.1708 (0.1679)  time: 0.6106  data: 0.0001  max mem: 15821
[22:36:00.122313] Epoch: [27]  [240/345]  eta: 0:01:03  lr: 0.000106  loss: 0.1551 (0.1670)  time: 0.6037  data: 0.0001  max mem: 15821
[22:36:12.182242] Epoch: [27]  [260/345]  eta: 0:00:51  lr: 0.000106  loss: 0.1670 (0.1674)  time: 0.6029  data: 0.0001  max mem: 15821
[22:36:24.249972] Epoch: [27]  [280/345]  eta: 0:00:39  lr: 0.000105  loss: 0.1580 (0.1670)  time: 0.6033  data: 0.0001  max mem: 15821
[22:36:36.316406] Epoch: [27]  [300/345]  eta: 0:00:27  lr: 0.000105  loss: 0.1785 (0.1679)  time: 0.6033  data: 0.0001  max mem: 15821
[22:36:48.376841] Epoch: [27]  [320/345]  eta: 0:00:15  lr: 0.000105  loss: 0.1752 (0.1679)  time: 0.6030  data: 0.0001  max mem: 15821
[22:37:00.427681] Epoch: [27]  [340/345]  eta: 0:00:03  lr: 0.000104  loss: 0.1613 (0.1681)  time: 0.6025  data: 0.0001  max mem: 15821
[22:37:02.840311] Epoch: [27]  [344/345]  eta: 0:00:00  lr: 0.000104  loss: 0.1581 (0.1680)  time: 0.6025  data: 0.0001  max mem: 15821
[22:37:02.907154] Epoch: [27] Total time: 0:03:28 (0.6048 s / it)
[22:37:02.907658] Averaged stats: lr: 0.000104  loss: 0.1581 (0.1680)
[22:37:03.479625] Test:  [  0/345]  eta: 0:03:15  loss: 0.1738 (0.1738)  time: 0.5664  data: 0.4018  max mem: 15821
[22:37:05.143847] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1445 (0.1495)  time: 0.2027  data: 0.0366  max mem: 15821
[22:37:06.812152] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1457 (0.1530)  time: 0.1666  data: 0.0001  max mem: 15821
[22:37:08.483246] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1593 (0.1576)  time: 0.1669  data: 0.0001  max mem: 15821
[22:37:10.157091] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1590 (0.1555)  time: 0.1672  data: 0.0001  max mem: 15821
[22:37:11.835300] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1492 (0.1553)  time: 0.1675  data: 0.0001  max mem: 15821
[22:37:13.515839] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1536 (0.1569)  time: 0.1679  data: 0.0001  max mem: 15821
[22:37:15.199842] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1530 (0.1561)  time: 0.1682  data: 0.0001  max mem: 15821
[22:37:16.887311] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1530 (0.1573)  time: 0.1685  data: 0.0001  max mem: 15821
[22:37:18.579121] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1570 (0.1579)  time: 0.1689  data: 0.0001  max mem: 15821
[22:37:20.275435] Test:  [100/345]  eta: 0:00:42  loss: 0.1528 (0.1573)  time: 0.1693  data: 0.0001  max mem: 15821
[22:37:21.974320] Test:  [110/345]  eta: 0:00:40  loss: 0.1515 (0.1572)  time: 0.1697  data: 0.0001  max mem: 15821
[22:37:23.674742] Test:  [120/345]  eta: 0:00:38  loss: 0.1520 (0.1581)  time: 0.1699  data: 0.0001  max mem: 15821
[22:37:25.378951] Test:  [130/345]  eta: 0:00:36  loss: 0.1520 (0.1573)  time: 0.1702  data: 0.0001  max mem: 15821
[22:37:27.087696] Test:  [140/345]  eta: 0:00:35  loss: 0.1410 (0.1568)  time: 0.1706  data: 0.0001  max mem: 15821
[22:37:28.798464] Test:  [150/345]  eta: 0:00:33  loss: 0.1455 (0.1573)  time: 0.1709  data: 0.0001  max mem: 15821
[22:37:30.513287] Test:  [160/345]  eta: 0:00:31  loss: 0.1614 (0.1577)  time: 0.1712  data: 0.0001  max mem: 15821
[22:37:32.232221] Test:  [170/345]  eta: 0:00:29  loss: 0.1565 (0.1573)  time: 0.1716  data: 0.0001  max mem: 15821
[22:37:33.954074] Test:  [180/345]  eta: 0:00:28  loss: 0.1500 (0.1570)  time: 0.1720  data: 0.0001  max mem: 15821
[22:37:35.678826] Test:  [190/345]  eta: 0:00:26  loss: 0.1500 (0.1569)  time: 0.1723  data: 0.0001  max mem: 15821
[22:37:37.406883] Test:  [200/345]  eta: 0:00:24  loss: 0.1501 (0.1565)  time: 0.1726  data: 0.0001  max mem: 15821
[22:37:39.139240] Test:  [210/345]  eta: 0:00:23  loss: 0.1455 (0.1560)  time: 0.1730  data: 0.0001  max mem: 15821
[22:37:40.875215] Test:  [220/345]  eta: 0:00:21  loss: 0.1454 (0.1558)  time: 0.1734  data: 0.0001  max mem: 15821
[22:37:42.614129] Test:  [230/345]  eta: 0:00:19  loss: 0.1482 (0.1556)  time: 0.1737  data: 0.0001  max mem: 15821
[22:37:44.356128] Test:  [240/345]  eta: 0:00:18  loss: 0.1511 (0.1560)  time: 0.1740  data: 0.0001  max mem: 15821
[22:37:46.102109] Test:  [250/345]  eta: 0:00:16  loss: 0.1607 (0.1562)  time: 0.1743  data: 0.0001  max mem: 15821
[22:37:47.852478] Test:  [260/345]  eta: 0:00:14  loss: 0.1603 (0.1564)  time: 0.1748  data: 0.0001  max mem: 15821
[22:37:49.605731] Test:  [270/345]  eta: 0:00:12  loss: 0.1478 (0.1561)  time: 0.1751  data: 0.0001  max mem: 15821
[22:37:51.362677] Test:  [280/345]  eta: 0:00:11  loss: 0.1585 (0.1565)  time: 0.1754  data: 0.0001  max mem: 15821
[22:37:53.122128] Test:  [290/345]  eta: 0:00:09  loss: 0.1590 (0.1564)  time: 0.1758  data: 0.0001  max mem: 15821
[22:37:54.886768] Test:  [300/345]  eta: 0:00:07  loss: 0.1550 (0.1567)  time: 0.1761  data: 0.0001  max mem: 15821
[22:37:56.654843] Test:  [310/345]  eta: 0:00:06  loss: 0.1618 (0.1568)  time: 0.1766  data: 0.0001  max mem: 15821
[22:37:58.426099] Test:  [320/345]  eta: 0:00:04  loss: 0.1558 (0.1567)  time: 0.1769  data: 0.0001  max mem: 15821
[22:38:00.198169] Test:  [330/345]  eta: 0:00:02  loss: 0.1503 (0.1567)  time: 0.1771  data: 0.0001  max mem: 15821
[22:38:01.976944] Test:  [340/345]  eta: 0:00:00  loss: 0.1536 (0.1571)  time: 0.1774  data: 0.0001  max mem: 15821
[22:38:02.689925] Test:  [344/345]  eta: 0:00:00  loss: 0.1557 (0.1573)  time: 0.1777  data: 0.0001  max mem: 15821
[22:38:02.758324] Test: Total time: 0:00:59 (0.1735 s / it)
[22:38:13.225531] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4630 (0.4630)  time: 0.5365  data: 0.3742  max mem: 15821
[22:38:14.871838] Test:  [10/57]  eta: 0:00:09  loss: 0.4369 (0.4518)  time: 0.1984  data: 0.0341  max mem: 15821
[22:38:16.523280] Test:  [20/57]  eta: 0:00:06  loss: 0.4155 (0.4337)  time: 0.1648  data: 0.0001  max mem: 15821
[22:38:18.178652] Test:  [30/57]  eta: 0:00:04  loss: 0.2603 (0.3673)  time: 0.1653  data: 0.0001  max mem: 15821
[22:38:19.838666] Test:  [40/57]  eta: 0:00:02  loss: 0.2201 (0.3390)  time: 0.1657  data: 0.0001  max mem: 15821
[22:38:21.502903] Test:  [50/57]  eta: 0:00:01  loss: 0.2729 (0.3341)  time: 0.1662  data: 0.0001  max mem: 15821
[22:38:22.400551] Test:  [56/57]  eta: 0:00:00  loss: 0.2869 (0.3481)  time: 0.1613  data: 0.0000  max mem: 15821
[22:38:22.482801] Test: Total time: 0:00:09 (0.1718 s / it)
[22:38:24.239348] Dice score of the network on the train images: 0.851630, val images: 0.801327
[22:38:24.243659] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:38:25.279232] Epoch: [28]  [  0/345]  eta: 0:05:56  lr: 0.000104  loss: 0.1719 (0.1719)  time: 1.0345  data: 0.4359  max mem: 15821
[22:38:37.245959] Epoch: [28]  [ 20/345]  eta: 0:03:21  lr: 0.000104  loss: 0.1593 (0.1661)  time: 0.5983  data: 0.0001  max mem: 15821
[22:38:49.247806] Epoch: [28]  [ 40/345]  eta: 0:03:05  lr: 0.000104  loss: 0.1556 (0.1626)  time: 0.6000  data: 0.0001  max mem: 15821
[22:39:01.264394] Epoch: [28]  [ 60/345]  eta: 0:02:52  lr: 0.000103  loss: 0.1594 (0.1636)  time: 0.6008  data: 0.0001  max mem: 15821
[22:39:13.286862] Epoch: [28]  [ 80/345]  eta: 0:02:40  lr: 0.000103  loss: 0.1497 (0.1608)  time: 0.6011  data: 0.0001  max mem: 15821
[22:39:25.324604] Epoch: [28]  [100/345]  eta: 0:02:28  lr: 0.000103  loss: 0.1602 (0.1609)  time: 0.6018  data: 0.0001  max mem: 15821
[22:39:37.382012] Epoch: [28]  [120/345]  eta: 0:02:15  lr: 0.000103  loss: 0.1689 (0.1623)  time: 0.6028  data: 0.0001  max mem: 15821
[22:39:49.455412] Epoch: [28]  [140/345]  eta: 0:02:03  lr: 0.000102  loss: 0.1606 (0.1625)  time: 0.6036  data: 0.0001  max mem: 15821
[22:40:01.557099] Epoch: [28]  [160/345]  eta: 0:01:51  lr: 0.000102  loss: 0.1564 (0.1617)  time: 0.6050  data: 0.0001  max mem: 15821
[22:40:13.655948] Epoch: [28]  [180/345]  eta: 0:01:39  lr: 0.000102  loss: 0.1546 (0.1623)  time: 0.6049  data: 0.0001  max mem: 15821
[22:40:25.747815] Epoch: [28]  [200/345]  eta: 0:01:27  lr: 0.000101  loss: 0.1608 (0.1627)  time: 0.6045  data: 0.0001  max mem: 15821
[22:40:37.836327] Epoch: [28]  [220/345]  eta: 0:01:15  lr: 0.000101  loss: 0.1648 (0.1629)  time: 0.6044  data: 0.0001  max mem: 15821
[22:40:49.929944] Epoch: [28]  [240/345]  eta: 0:01:03  lr: 0.000101  loss: 0.1582 (0.1627)  time: 0.6046  data: 0.0001  max mem: 15821
[22:41:02.001444] Epoch: [28]  [260/345]  eta: 0:00:51  lr: 0.000101  loss: 0.1607 (0.1626)  time: 0.6035  data: 0.0001  max mem: 15821
[22:41:14.066143] Epoch: [28]  [280/345]  eta: 0:00:39  lr: 0.000100  loss: 0.1610 (0.1626)  time: 0.6032  data: 0.0001  max mem: 15821
[22:41:26.129314] Epoch: [28]  [300/345]  eta: 0:00:27  lr: 0.000100  loss: 0.1626 (0.1631)  time: 0.6031  data: 0.0001  max mem: 15821
[22:41:38.186921] Epoch: [28]  [320/345]  eta: 0:00:15  lr: 0.000100  loss: 0.1579 (0.1631)  time: 0.6028  data: 0.0001  max mem: 15821
[22:41:50.243194] Epoch: [28]  [340/345]  eta: 0:00:03  lr: 0.000099  loss: 0.1605 (0.1632)  time: 0.6028  data: 0.0001  max mem: 15821
[22:41:52.651364] Epoch: [28]  [344/345]  eta: 0:00:00  lr: 0.000099  loss: 0.1622 (0.1634)  time: 0.6027  data: 0.0001  max mem: 15821
[22:41:52.723848] Epoch: [28] Total time: 0:03:28 (0.6043 s / it)
[22:41:52.724433] Averaged stats: lr: 0.000099  loss: 0.1622 (0.1634)
[22:41:53.328379] Test:  [  0/345]  eta: 0:03:26  loss: 0.1388 (0.1388)  time: 0.5988  data: 0.4347  max mem: 15821
[22:41:54.994243] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1562 (0.1535)  time: 0.2058  data: 0.0396  max mem: 15821
[22:41:56.662161] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1513 (0.1549)  time: 0.1666  data: 0.0001  max mem: 15821
[22:41:58.333762] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1515 (0.1545)  time: 0.1669  data: 0.0001  max mem: 15821
[22:42:00.008963] Test:  [ 40/345]  eta: 0:00:54  loss: 0.1530 (0.1539)  time: 0.1673  data: 0.0001  max mem: 15821
[22:42:01.687420] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1547 (0.1546)  time: 0.1676  data: 0.0001  max mem: 15821
[22:42:03.369084] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1532 (0.1542)  time: 0.1679  data: 0.0001  max mem: 15821
[22:42:05.052809] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1465 (0.1535)  time: 0.1682  data: 0.0001  max mem: 15821
[22:42:06.740536] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1555 (0.1538)  time: 0.1685  data: 0.0001  max mem: 15821
[22:42:08.432286] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1560 (0.1538)  time: 0.1689  data: 0.0001  max mem: 15821
[22:42:10.127961] Test:  [100/345]  eta: 0:00:42  loss: 0.1518 (0.1537)  time: 0.1693  data: 0.0001  max mem: 15821
[22:42:11.826634] Test:  [110/345]  eta: 0:00:40  loss: 0.1513 (0.1538)  time: 0.1697  data: 0.0001  max mem: 15821
[22:42:13.528632] Test:  [120/345]  eta: 0:00:38  loss: 0.1569 (0.1541)  time: 0.1700  data: 0.0001  max mem: 15821
[22:42:15.234939] Test:  [130/345]  eta: 0:00:36  loss: 0.1514 (0.1537)  time: 0.1704  data: 0.0001  max mem: 15821
[22:42:16.943827] Test:  [140/345]  eta: 0:00:35  loss: 0.1491 (0.1536)  time: 0.1707  data: 0.0001  max mem: 15821
[22:42:18.655386] Test:  [150/345]  eta: 0:00:33  loss: 0.1497 (0.1539)  time: 0.1710  data: 0.0001  max mem: 15821
[22:42:20.370973] Test:  [160/345]  eta: 0:00:31  loss: 0.1518 (0.1538)  time: 0.1713  data: 0.0001  max mem: 15821
[22:42:22.090198] Test:  [170/345]  eta: 0:00:30  loss: 0.1496 (0.1535)  time: 0.1717  data: 0.0001  max mem: 15821
[22:42:23.813044] Test:  [180/345]  eta: 0:00:28  loss: 0.1496 (0.1536)  time: 0.1720  data: 0.0001  max mem: 15821
[22:42:25.539980] Test:  [190/345]  eta: 0:00:26  loss: 0.1532 (0.1535)  time: 0.1724  data: 0.0001  max mem: 15821
[22:42:27.267388] Test:  [200/345]  eta: 0:00:24  loss: 0.1573 (0.1539)  time: 0.1727  data: 0.0001  max mem: 15821
[22:42:29.000893] Test:  [210/345]  eta: 0:00:23  loss: 0.1524 (0.1536)  time: 0.1730  data: 0.0001  max mem: 15821
[22:42:30.735454] Test:  [220/345]  eta: 0:00:21  loss: 0.1452 (0.1531)  time: 0.1733  data: 0.0001  max mem: 15821
[22:42:32.474669] Test:  [230/345]  eta: 0:00:19  loss: 0.1462 (0.1530)  time: 0.1736  data: 0.0001  max mem: 15821
[22:42:34.216742] Test:  [240/345]  eta: 0:00:18  loss: 0.1500 (0.1535)  time: 0.1740  data: 0.0001  max mem: 15821
[22:42:35.962077] Test:  [250/345]  eta: 0:00:16  loss: 0.1564 (0.1538)  time: 0.1743  data: 0.0001  max mem: 15821
[22:42:37.711856] Test:  [260/345]  eta: 0:00:14  loss: 0.1501 (0.1539)  time: 0.1747  data: 0.0001  max mem: 15821
[22:42:39.463176] Test:  [270/345]  eta: 0:00:12  loss: 0.1475 (0.1541)  time: 0.1750  data: 0.0001  max mem: 15821
[22:42:41.219984] Test:  [280/345]  eta: 0:00:11  loss: 0.1462 (0.1539)  time: 0.1753  data: 0.0001  max mem: 15821
[22:42:42.980557] Test:  [290/345]  eta: 0:00:09  loss: 0.1462 (0.1540)  time: 0.1758  data: 0.0001  max mem: 15821
[22:42:44.743390] Test:  [300/345]  eta: 0:00:07  loss: 0.1488 (0.1540)  time: 0.1761  data: 0.0001  max mem: 15821
[22:42:46.510942] Test:  [310/345]  eta: 0:00:06  loss: 0.1459 (0.1537)  time: 0.1765  data: 0.0001  max mem: 15821
[22:42:48.280794] Test:  [320/345]  eta: 0:00:04  loss: 0.1520 (0.1537)  time: 0.1768  data: 0.0001  max mem: 15821
[22:42:50.056310] Test:  [330/345]  eta: 0:00:02  loss: 0.1424 (0.1534)  time: 0.1772  data: 0.0001  max mem: 15821
[22:42:51.832598] Test:  [340/345]  eta: 0:00:00  loss: 0.1393 (0.1532)  time: 0.1775  data: 0.0001  max mem: 15821
[22:42:52.543859] Test:  [344/345]  eta: 0:00:00  loss: 0.1398 (0.1530)  time: 0.1775  data: 0.0001  max mem: 15821
[22:42:52.620639] Test: Total time: 0:00:59 (0.1736 s / it)
[22:43:03.220182] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4702 (0.4702)  time: 0.5476  data: 0.3850  max mem: 15821
[22:43:04.867123] Test:  [10/57]  eta: 0:00:09  loss: 0.4346 (0.4676)  time: 0.1994  data: 0.0351  max mem: 15821
[22:43:06.518767] Test:  [20/57]  eta: 0:00:06  loss: 0.4327 (0.4507)  time: 0.1648  data: 0.0001  max mem: 15821
[22:43:08.173337] Test:  [30/57]  eta: 0:00:04  loss: 0.2798 (0.3841)  time: 0.1652  data: 0.0001  max mem: 15821
[22:43:09.833451] Test:  [40/57]  eta: 0:00:02  loss: 0.2386 (0.3549)  time: 0.1657  data: 0.0001  max mem: 15821
[22:43:11.499199] Test:  [50/57]  eta: 0:00:01  loss: 0.2812 (0.3493)  time: 0.1662  data: 0.0001  max mem: 15821
[22:43:12.397600] Test:  [56/57]  eta: 0:00:00  loss: 0.3042 (0.3636)  time: 0.1614  data: 0.0000  max mem: 15821
[22:43:12.475388] Test: Total time: 0:00:09 (0.1720 s / it)
[22:43:14.239584] Dice score of the network on the train images: 0.860657, val images: 0.791839
[22:43:14.243470] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:43:15.271528] Epoch: [29]  [  0/345]  eta: 0:05:54  lr: 0.000099  loss: 0.1606 (0.1606)  time: 1.0272  data: 0.4257  max mem: 15821
[22:43:27.247321] Epoch: [29]  [ 20/345]  eta: 0:03:21  lr: 0.000099  loss: 0.1589 (0.1586)  time: 0.5987  data: 0.0001  max mem: 15821
[22:43:39.245689] Epoch: [29]  [ 40/345]  eta: 0:03:05  lr: 0.000099  loss: 0.1617 (0.1649)  time: 0.5999  data: 0.0001  max mem: 15821
[22:43:51.255382] Epoch: [29]  [ 60/345]  eta: 0:02:52  lr: 0.000098  loss: 0.1702 (0.1659)  time: 0.6004  data: 0.0001  max mem: 15821
[22:44:03.284996] Epoch: [29]  [ 80/345]  eta: 0:02:40  lr: 0.000098  loss: 0.1613 (0.1662)  time: 0.6014  data: 0.0001  max mem: 15821
[22:44:15.342171] Epoch: [29]  [100/345]  eta: 0:02:28  lr: 0.000098  loss: 0.1709 (0.1672)  time: 0.6028  data: 0.0001  max mem: 15821
[22:44:27.402324] Epoch: [29]  [120/345]  eta: 0:02:16  lr: 0.000097  loss: 0.1588 (0.1657)  time: 0.6030  data: 0.0001  max mem: 15821
[22:44:39.477600] Epoch: [29]  [140/345]  eta: 0:02:03  lr: 0.000097  loss: 0.1603 (0.1659)  time: 0.6037  data: 0.0001  max mem: 15821
[22:44:51.561388] Epoch: [29]  [160/345]  eta: 0:01:51  lr: 0.000097  loss: 0.1496 (0.1649)  time: 0.6041  data: 0.0001  max mem: 15821
[22:45:03.644309] Epoch: [29]  [180/345]  eta: 0:01:39  lr: 0.000096  loss: 0.1508 (0.1641)  time: 0.6041  data: 0.0001  max mem: 15821
[22:45:15.717117] Epoch: [29]  [200/345]  eta: 0:01:27  lr: 0.000096  loss: 0.1513 (0.1635)  time: 0.6036  data: 0.0001  max mem: 15821
[22:45:27.803001] Epoch: [29]  [220/345]  eta: 0:01:15  lr: 0.000096  loss: 0.1615 (0.1634)  time: 0.6042  data: 0.0001  max mem: 15821
[22:45:39.883880] Epoch: [29]  [240/345]  eta: 0:01:03  lr: 0.000095  loss: 0.1634 (0.1633)  time: 0.6040  data: 0.0001  max mem: 15821
[22:45:51.948255] Epoch: [29]  [260/345]  eta: 0:00:51  lr: 0.000095  loss: 0.1439 (0.1621)  time: 0.6032  data: 0.0001  max mem: 15821
[22:46:04.037988] Epoch: [29]  [280/345]  eta: 0:00:39  lr: 0.000095  loss: 0.1497 (0.1615)  time: 0.6044  data: 0.0001  max mem: 15821
[22:46:16.101541] Epoch: [29]  [300/345]  eta: 0:00:27  lr: 0.000094  loss: 0.1644 (0.1618)  time: 0.6031  data: 0.0001  max mem: 15821
[22:46:28.164497] Epoch: [29]  [320/345]  eta: 0:00:15  lr: 0.000094  loss: 0.1464 (0.1615)  time: 0.6031  data: 0.0001  max mem: 15821
[22:46:40.215817] Epoch: [29]  [340/345]  eta: 0:00:03  lr: 0.000094  loss: 0.1617 (0.1617)  time: 0.6025  data: 0.0001  max mem: 15821
[22:46:42.623058] Epoch: [29]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.1625 (0.1617)  time: 0.6023  data: 0.0001  max mem: 15821
[22:46:42.695588] Epoch: [29] Total time: 0:03:28 (0.6042 s / it)
[22:46:42.695997] Averaged stats: lr: 0.000094  loss: 0.1625 (0.1617)
[22:46:43.264665] Test:  [  0/345]  eta: 0:03:14  loss: 0.1362 (0.1362)  time: 0.5631  data: 0.3990  max mem: 15821
[22:46:44.930734] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1541 (0.1510)  time: 0.2026  data: 0.0364  max mem: 15821
[22:46:46.601658] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1504 (0.1490)  time: 0.1668  data: 0.0001  max mem: 15821
[22:46:48.275096] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1472 (0.1490)  time: 0.1672  data: 0.0001  max mem: 15821
[22:46:49.951431] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1512 (0.1525)  time: 0.1674  data: 0.0001  max mem: 15821
[22:46:51.630430] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1609 (0.1542)  time: 0.1677  data: 0.0001  max mem: 15821
[22:46:53.313509] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1499 (0.1538)  time: 0.1680  data: 0.0001  max mem: 15821
[22:46:54.999522] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1431 (0.1529)  time: 0.1684  data: 0.0001  max mem: 15821
[22:46:56.688883] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1446 (0.1526)  time: 0.1687  data: 0.0001  max mem: 15821
[22:46:58.382705] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1526 (0.1527)  time: 0.1691  data: 0.0001  max mem: 15821
[22:47:00.079447] Test:  [100/345]  eta: 0:00:42  loss: 0.1448 (0.1516)  time: 0.1695  data: 0.0001  max mem: 15821
[22:47:01.780940] Test:  [110/345]  eta: 0:00:40  loss: 0.1430 (0.1522)  time: 0.1698  data: 0.0001  max mem: 15821
[22:47:03.483947] Test:  [120/345]  eta: 0:00:38  loss: 0.1416 (0.1522)  time: 0.1702  data: 0.0001  max mem: 15821
[22:47:05.190758] Test:  [130/345]  eta: 0:00:36  loss: 0.1425 (0.1524)  time: 0.1704  data: 0.0001  max mem: 15821
[22:47:06.902093] Test:  [140/345]  eta: 0:00:35  loss: 0.1537 (0.1524)  time: 0.1708  data: 0.0001  max mem: 15821
[22:47:08.617154] Test:  [150/345]  eta: 0:00:33  loss: 0.1586 (0.1530)  time: 0.1713  data: 0.0001  max mem: 15821
[22:47:10.335536] Test:  [160/345]  eta: 0:00:31  loss: 0.1527 (0.1526)  time: 0.1716  data: 0.0001  max mem: 15821
[22:47:12.058707] Test:  [170/345]  eta: 0:00:30  loss: 0.1441 (0.1522)  time: 0.1720  data: 0.0001  max mem: 15821
[22:47:13.782631] Test:  [180/345]  eta: 0:00:28  loss: 0.1408 (0.1516)  time: 0.1723  data: 0.0001  max mem: 15821
[22:47:15.511349] Test:  [190/345]  eta: 0:00:26  loss: 0.1374 (0.1511)  time: 0.1726  data: 0.0001  max mem: 15821
[22:47:17.243082] Test:  [200/345]  eta: 0:00:24  loss: 0.1425 (0.1510)  time: 0.1730  data: 0.0001  max mem: 15821
[22:47:18.977232] Test:  [210/345]  eta: 0:00:23  loss: 0.1468 (0.1510)  time: 0.1732  data: 0.0001  max mem: 15821
[22:47:20.714857] Test:  [220/345]  eta: 0:00:21  loss: 0.1607 (0.1513)  time: 0.1735  data: 0.0001  max mem: 15821
[22:47:22.456739] Test:  [230/345]  eta: 0:00:19  loss: 0.1478 (0.1511)  time: 0.1739  data: 0.0001  max mem: 15821
[22:47:24.201182] Test:  [240/345]  eta: 0:00:18  loss: 0.1452 (0.1513)  time: 0.1742  data: 0.0001  max mem: 15821
[22:47:25.948687] Test:  [250/345]  eta: 0:00:16  loss: 0.1470 (0.1509)  time: 0.1745  data: 0.0001  max mem: 15821
[22:47:27.701289] Test:  [260/345]  eta: 0:00:14  loss: 0.1350 (0.1506)  time: 0.1749  data: 0.0001  max mem: 15821
[22:47:29.456916] Test:  [270/345]  eta: 0:00:12  loss: 0.1471 (0.1509)  time: 0.1753  data: 0.0001  max mem: 15821
[22:47:31.216636] Test:  [280/345]  eta: 0:00:11  loss: 0.1465 (0.1507)  time: 0.1757  data: 0.0001  max mem: 15821
[22:47:32.980219] Test:  [290/345]  eta: 0:00:09  loss: 0.1458 (0.1508)  time: 0.1761  data: 0.0001  max mem: 15821
[22:47:34.745374] Test:  [300/345]  eta: 0:00:07  loss: 0.1458 (0.1509)  time: 0.1764  data: 0.0001  max mem: 15821
[22:47:36.515525] Test:  [310/345]  eta: 0:00:06  loss: 0.1476 (0.1513)  time: 0.1767  data: 0.0001  max mem: 15821
[22:47:38.288682] Test:  [320/345]  eta: 0:00:04  loss: 0.1608 (0.1514)  time: 0.1771  data: 0.0001  max mem: 15821
[22:47:40.066779] Test:  [330/345]  eta: 0:00:02  loss: 0.1475 (0.1512)  time: 0.1775  data: 0.0001  max mem: 15821
[22:47:41.847254] Test:  [340/345]  eta: 0:00:00  loss: 0.1453 (0.1513)  time: 0.1779  data: 0.0001  max mem: 15821
[22:47:42.560827] Test:  [344/345]  eta: 0:00:00  loss: 0.1453 (0.1514)  time: 0.1780  data: 0.0001  max mem: 15821
[22:47:42.630564] Test: Total time: 0:00:59 (0.1737 s / it)
[22:47:53.091248] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4807 (0.4807)  time: 0.5245  data: 0.3626  max mem: 15821
[22:47:54.737283] Test:  [10/57]  eta: 0:00:09  loss: 0.4311 (0.4562)  time: 0.1972  data: 0.0330  max mem: 15821
[22:47:56.388419] Test:  [20/57]  eta: 0:00:06  loss: 0.4191 (0.4375)  time: 0.1648  data: 0.0001  max mem: 15821
[22:47:58.043084] Test:  [30/57]  eta: 0:00:04  loss: 0.2799 (0.3756)  time: 0.1652  data: 0.0001  max mem: 15821
[22:47:59.702674] Test:  [40/57]  eta: 0:00:02  loss: 0.2442 (0.3533)  time: 0.1656  data: 0.0001  max mem: 15821
[22:48:01.368205] Test:  [50/57]  eta: 0:00:01  loss: 0.2851 (0.3498)  time: 0.1662  data: 0.0001  max mem: 15821
[22:48:02.266073] Test:  [56/57]  eta: 0:00:00  loss: 0.3423 (0.3647)  time: 0.1613  data: 0.0000  max mem: 15821
[22:48:02.335241] Test: Total time: 0:00:09 (0.1714 s / it)
[22:48:04.123146] Dice score of the network on the train images: 0.858125, val images: 0.782998
[22:48:04.127418] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:48:05.110403] Epoch: [30]  [  0/345]  eta: 0:05:38  lr: 0.000094  loss: 0.1424 (0.1424)  time: 0.9820  data: 0.3821  max mem: 15821
[22:48:17.081306] Epoch: [30]  [ 20/345]  eta: 0:03:20  lr: 0.000093  loss: 0.1412 (0.1513)  time: 0.5985  data: 0.0001  max mem: 15821
[22:48:29.208114] Epoch: [30]  [ 40/345]  eta: 0:03:06  lr: 0.000093  loss: 0.1601 (0.1550)  time: 0.6063  data: 0.0001  max mem: 15821
[22:48:41.235021] Epoch: [30]  [ 60/345]  eta: 0:02:53  lr: 0.000093  loss: 0.1552 (0.1546)  time: 0.6013  data: 0.0001  max mem: 15821
[22:48:53.265552] Epoch: [30]  [ 80/345]  eta: 0:02:40  lr: 0.000092  loss: 0.1509 (0.1555)  time: 0.6015  data: 0.0001  max mem: 15821
[22:49:05.300358] Epoch: [30]  [100/345]  eta: 0:02:28  lr: 0.000092  loss: 0.1560 (0.1562)  time: 0.6017  data: 0.0001  max mem: 15821
[22:49:17.367346] Epoch: [30]  [120/345]  eta: 0:02:16  lr: 0.000092  loss: 0.1608 (0.1571)  time: 0.6033  data: 0.0001  max mem: 15821
[22:49:29.448966] Epoch: [30]  [140/345]  eta: 0:02:04  lr: 0.000091  loss: 0.1595 (0.1573)  time: 0.6040  data: 0.0001  max mem: 15821
[22:49:41.536464] Epoch: [30]  [160/345]  eta: 0:01:51  lr: 0.000091  loss: 0.1460 (0.1562)  time: 0.6043  data: 0.0001  max mem: 15821
[22:49:53.618670] Epoch: [30]  [180/345]  eta: 0:01:39  lr: 0.000091  loss: 0.1447 (0.1556)  time: 0.6041  data: 0.0001  max mem: 15821
[22:50:05.693551] Epoch: [30]  [200/345]  eta: 0:01:27  lr: 0.000090  loss: 0.1526 (0.1555)  time: 0.6037  data: 0.0001  max mem: 15821
[22:50:17.767865] Epoch: [30]  [220/345]  eta: 0:01:15  lr: 0.000090  loss: 0.1433 (0.1549)  time: 0.6037  data: 0.0001  max mem: 15821

[22:50:29.849290] Epoch: [30]  [240/345]  eta: 0:01:03  lr: 0.000090  loss: 0.1544 (0.1552)  time: 0.6040  data: 0.0001  max mem: 15821
[22:50:41.919928] Epoch: [30]  [260/345]  eta: 0:00:51  lr: 0.000089  loss: 0.1542 (0.1550)  time: 0.6035  data: 0.0001  max mem: 15821
[22:50:53.990201] Epoch: [30]  [280/345]  eta: 0:00:39  lr: 0.000089  loss: 0.1461 (0.1549)  time: 0.6035  data: 0.0001  max mem: 15821
[22:51:06.061319] Epoch: [30]  [300/345]  eta: 0:00:27  lr: 0.000089  loss: 0.1523 (0.1551)  time: 0.6035  data: 0.0001  max mem: 15821
[22:51:18.123343] Epoch: [30]  [320/345]  eta: 0:00:15  lr: 0.000088  loss: 0.1561 (0.1554)  time: 0.6031  data: 0.0001  max mem: 15821
[22:51:30.178015] Epoch: [30]  [340/345]  eta: 0:00:03  lr: 0.000088  loss: 0.1553 (0.1553)  time: 0.6027  data: 0.0001  max mem: 15821
[22:51:32.591873] Epoch: [30]  [344/345]  eta: 0:00:00  lr: 0.000088  loss: 0.1558 (0.1554)  time: 0.6029  data: 0.0001  max mem: 15821
[22:51:32.670726] Epoch: [30] Total time: 0:03:28 (0.6045 s / it)
[22:51:32.671155] Averaged stats: lr: 0.000088  loss: 0.1558 (0.1554)
[22:51:33.252798] Test:  [  0/345]  eta: 0:03:19  loss: 0.1663 (0.1663)  time: 0.5772  data: 0.4137  max mem: 15821
[22:51:34.917570] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1514 (0.1463)  time: 0.2037  data: 0.0377  max mem: 15821
[22:51:36.585236] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1487 (0.1501)  time: 0.1665  data: 0.0001  max mem: 15821
[22:51:38.255746] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1465 (0.1490)  time: 0.1668  data: 0.0001  max mem: 15821
[22:51:39.931067] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1478 (0.1518)  time: 0.1672  data: 0.0001  max mem: 15821
[22:51:41.608638] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1461 (0.1504)  time: 0.1676  data: 0.0001  max mem: 15821
[22:51:43.289099] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1427 (0.1492)  time: 0.1678  data: 0.0001  max mem: 15821
[22:51:44.973765] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1472 (0.1501)  time: 0.1682  data: 0.0001  max mem: 15821
[22:51:46.661766] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1412 (0.1485)  time: 0.1686  data: 0.0001  max mem: 15821
[22:51:48.355936] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1370 (0.1489)  time: 0.1690  data: 0.0001  max mem: 15821
[22:51:50.050840] Test:  [100/345]  eta: 0:00:42  loss: 0.1515 (0.1494)  time: 0.1694  data: 0.0001  max mem: 15821
[22:51:51.749067] Test:  [110/345]  eta: 0:00:40  loss: 0.1416 (0.1484)  time: 0.1696  data: 0.0001  max mem: 15821
[22:51:53.451584] Test:  [120/345]  eta: 0:00:38  loss: 0.1364 (0.1487)  time: 0.1700  data: 0.0001  max mem: 15821
[22:51:55.155648] Test:  [130/345]  eta: 0:00:36  loss: 0.1520 (0.1487)  time: 0.1703  data: 0.0001  max mem: 15821
[22:51:56.865471] Test:  [140/345]  eta: 0:00:35  loss: 0.1484 (0.1484)  time: 0.1706  data: 0.0001  max mem: 15821
[22:51:58.577105] Test:  [150/345]  eta: 0:00:33  loss: 0.1454 (0.1481)  time: 0.1710  data: 0.0001  max mem: 15821
[22:52:00.292268] Test:  [160/345]  eta: 0:00:31  loss: 0.1360 (0.1478)  time: 0.1713  data: 0.0001  max mem: 15821
[22:52:02.013332] Test:  [170/345]  eta: 0:00:30  loss: 0.1429 (0.1482)  time: 0.1717  data: 0.0001  max mem: 15821
[22:52:03.735648] Test:  [180/345]  eta: 0:00:28  loss: 0.1466 (0.1486)  time: 0.1721  data: 0.0001  max mem: 15821
[22:52:05.460309] Test:  [190/345]  eta: 0:00:26  loss: 0.1445 (0.1483)  time: 0.1723  data: 0.0001  max mem: 15821
[22:52:07.190414] Test:  [200/345]  eta: 0:00:24  loss: 0.1438 (0.1483)  time: 0.1727  data: 0.0001  max mem: 15821
[22:52:08.924340] Test:  [210/345]  eta: 0:00:23  loss: 0.1494 (0.1485)  time: 0.1731  data: 0.0001  max mem: 15821
[22:52:10.660731] Test:  [220/345]  eta: 0:00:21  loss: 0.1558 (0.1488)  time: 0.1734  data: 0.0001  max mem: 15821
[22:52:12.400602] Test:  [230/345]  eta: 0:00:19  loss: 0.1485 (0.1488)  time: 0.1738  data: 0.0001  max mem: 15821
[22:52:14.143860] Test:  [240/345]  eta: 0:00:18  loss: 0.1395 (0.1487)  time: 0.1741  data: 0.0001  max mem: 15821
[22:52:15.891968] Test:  [250/345]  eta: 0:00:16  loss: 0.1395 (0.1486)  time: 0.1745  data: 0.0001  max mem: 15821
[22:52:17.642749] Test:  [260/345]  eta: 0:00:14  loss: 0.1394 (0.1486)  time: 0.1749  data: 0.0001  max mem: 15821
[22:52:19.396238] Test:  [270/345]  eta: 0:00:12  loss: 0.1493 (0.1488)  time: 0.1751  data: 0.0001  max mem: 15821
[22:52:21.154718] Test:  [280/345]  eta: 0:00:11  loss: 0.1534 (0.1491)  time: 0.1755  data: 0.0001  max mem: 15821
[22:52:22.915396] Test:  [290/345]  eta: 0:00:09  loss: 0.1419 (0.1487)  time: 0.1759  data: 0.0001  max mem: 15821
[22:52:24.678179] Test:  [300/345]  eta: 0:00:07  loss: 0.1335 (0.1483)  time: 0.1761  data: 0.0001  max mem: 15821
[22:52:26.447573] Test:  [310/345]  eta: 0:00:06  loss: 0.1455 (0.1489)  time: 0.1765  data: 0.0001  max mem: 15821
[22:52:28.218112] Test:  [320/345]  eta: 0:00:04  loss: 0.1600 (0.1492)  time: 0.1769  data: 0.0001  max mem: 15821
[22:52:29.993563] Test:  [330/345]  eta: 0:00:02  loss: 0.1460 (0.1491)  time: 0.1772  data: 0.0001  max mem: 15821
[22:52:31.772386] Test:  [340/345]  eta: 0:00:00  loss: 0.1417 (0.1489)  time: 0.1777  data: 0.0001  max mem: 15821
[22:52:32.486048] Test:  [344/345]  eta: 0:00:00  loss: 0.1454 (0.1491)  time: 0.1778  data: 0.0001  max mem: 15821
[22:52:32.568644] Test: Total time: 0:00:59 (0.1736 s / it)
[22:52:43.099669] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4800 (0.4800)  time: 0.5484  data: 0.3860  max mem: 15821
[22:52:44.746637] Test:  [10/57]  eta: 0:00:09  loss: 0.4371 (0.4614)  time: 0.1995  data: 0.0352  max mem: 15821
[22:52:46.396926] Test:  [20/57]  eta: 0:00:06  loss: 0.4117 (0.4469)  time: 0.1648  data: 0.0001  max mem: 15821
[22:52:48.051515] Test:  [30/57]  eta: 0:00:04  loss: 0.2917 (0.3868)  time: 0.1652  data: 0.0001  max mem: 15821
[22:52:49.710963] Test:  [40/57]  eta: 0:00:02  loss: 0.2467 (0.3648)  time: 0.1656  data: 0.0001  max mem: 15821
[22:52:51.375769] Test:  [50/57]  eta: 0:00:01  loss: 0.3066 (0.3597)  time: 0.1662  data: 0.0001  max mem: 15821
[22:52:52.273286] Test:  [56/57]  eta: 0:00:00  loss: 0.3405 (0.3706)  time: 0.1613  data: 0.0000  max mem: 15821
[22:52:52.346028] Test: Total time: 0:00:09 (0.1719 s / it)
[22:52:54.111431] Dice score of the network on the train images: 0.856927, val images: 0.779093
[22:52:54.116268] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:52:55.096296] Epoch: [31]  [  0/345]  eta: 0:05:37  lr: 0.000088  loss: 0.1418 (0.1418)  time: 0.9788  data: 0.3779  max mem: 15821
[22:53:07.085495] Epoch: [31]  [ 20/345]  eta: 0:03:20  lr: 0.000088  loss: 0.1390 (0.1474)  time: 0.5994  data: 0.0001  max mem: 15821
[22:53:19.104970] Epoch: [31]  [ 40/345]  eta: 0:03:05  lr: 0.000087  loss: 0.1509 (0.1523)  time: 0.6009  data: 0.0001  max mem: 15821
[22:53:31.136555] Epoch: [31]  [ 60/345]  eta: 0:02:52  lr: 0.000087  loss: 0.1441 (0.1511)  time: 0.6015  data: 0.0001  max mem: 15821
[22:53:43.184445] Epoch: [31]  [ 80/345]  eta: 0:02:40  lr: 0.000087  loss: 0.1492 (0.1504)  time: 0.6023  data: 0.0001  max mem: 15821
[22:53:55.250887] Epoch: [31]  [100/345]  eta: 0:02:28  lr: 0.000086  loss: 0.1518 (0.1513)  time: 0.6033  data: 0.0001  max mem: 15821
[22:54:07.331364] Epoch: [31]  [120/345]  eta: 0:02:16  lr: 0.000086  loss: 0.1463 (0.1507)  time: 0.6040  data: 0.0001  max mem: 15821
[22:54:19.431460] Epoch: [31]  [140/345]  eta: 0:02:04  lr: 0.000085  loss: 0.1403 (0.1506)  time: 0.6050  data: 0.0001  max mem: 15821
[22:54:31.544903] Epoch: [31]  [160/345]  eta: 0:01:51  lr: 0.000085  loss: 0.1419 (0.1503)  time: 0.6056  data: 0.0001  max mem: 15821
[22:54:43.653692] Epoch: [31]  [180/345]  eta: 0:01:39  lr: 0.000085  loss: 0.1431 (0.1500)  time: 0.6054  data: 0.0001  max mem: 15821
[22:54:55.741727] Epoch: [31]  [200/345]  eta: 0:01:27  lr: 0.000084  loss: 0.1543 (0.1505)  time: 0.6043  data: 0.0001  max mem: 15821
[22:55:07.852372] Epoch: [31]  [220/345]  eta: 0:01:15  lr: 0.000084  loss: 0.1483 (0.1505)  time: 0.6055  data: 0.0001  max mem: 15821
[22:55:19.942951] Epoch: [31]  [240/345]  eta: 0:01:03  lr: 0.000084  loss: 0.1614 (0.1517)  time: 0.6045  data: 0.0001  max mem: 15821
[22:55:32.015278] Epoch: [31]  [260/345]  eta: 0:00:51  lr: 0.000083  loss: 0.1582 (0.1522)  time: 0.6036  data: 0.0001  max mem: 15821
[22:55:44.100301] Epoch: [31]  [280/345]  eta: 0:00:39  lr: 0.000083  loss: 0.1516 (0.1526)  time: 0.6042  data: 0.0001  max mem: 15821
[22:55:56.175678] Epoch: [31]  [300/345]  eta: 0:00:27  lr: 0.000083  loss: 0.1597 (0.1531)  time: 0.6037  data: 0.0001  max mem: 15821

[22:56:08.256573] Epoch: [31]  [320/345]  eta: 0:00:15  lr: 0.000082  loss: 0.1458 (0.1529)  time: 0.6040  data: 0.0001  max mem: 15821
[22:56:20.333216] Epoch: [31]  [340/345]  eta: 0:00:03  lr: 0.000082  loss: 0.1406 (0.1525)  time: 0.6038  data: 0.0001  max mem: 15821
[22:56:22.746184] Epoch: [31]  [344/345]  eta: 0:00:00  lr: 0.000082  loss: 0.1389 (0.1523)  time: 0.6035  data: 0.0001  max mem: 15821
[22:56:22.822987] Epoch: [31] Total time: 0:03:28 (0.6049 s / it)
[22:56:22.823555] Averaged stats: lr: 0.000082  loss: 0.1389 (0.1523)
[22:56:23.425448] Test:  [  0/345]  eta: 0:03:25  loss: 0.1502 (0.1502)  time: 0.5967  data: 0.4321  max mem: 15821
[22:56:25.093113] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1354 (0.1433)  time: 0.2058  data: 0.0394  max mem: 15821
[22:56:26.762081] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1354 (0.1462)  time: 0.1667  data: 0.0001  max mem: 15821
[22:56:28.435205] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1480 (0.1472)  time: 0.1670  data: 0.0001  max mem: 15821
[22:56:30.110838] Test:  [ 40/345]  eta: 0:00:54  loss: 0.1450 (0.1463)  time: 0.1674  data: 0.0001  max mem: 15821
[22:56:31.790616] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1362 (0.1454)  time: 0.1677  data: 0.0001  max mem: 15821
[22:56:33.474537] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1387 (0.1464)  time: 0.1681  data: 0.0001  max mem: 15821
[22:56:35.160218] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1510 (0.1472)  time: 0.1684  data: 0.0001  max mem: 15821
[22:56:36.850319] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1510 (0.1471)  time: 0.1687  data: 0.0001  max mem: 15821
[22:56:38.544166] Test:  [ 90/345]  eta: 0:00:44  loss: 0.1423 (0.1474)  time: 0.1691  data: 0.0001  max mem: 15821
[22:56:40.241142] Test:  [100/345]  eta: 0:00:42  loss: 0.1423 (0.1476)  time: 0.1695  data: 0.0001  max mem: 15821
[22:56:41.942451] Test:  [110/345]  eta: 0:00:40  loss: 0.1406 (0.1471)  time: 0.1698  data: 0.0001  max mem: 15821
[22:56:43.644745] Test:  [120/345]  eta: 0:00:38  loss: 0.1411 (0.1470)  time: 0.1701  data: 0.0001  max mem: 15821
[22:56:45.352224] Test:  [130/345]  eta: 0:00:36  loss: 0.1444 (0.1473)  time: 0.1704  data: 0.0001  max mem: 15821
[22:56:47.062086] Test:  [140/345]  eta: 0:00:35  loss: 0.1444 (0.1468)  time: 0.1708  data: 0.0001  max mem: 15821
[22:56:48.775793] Test:  [150/345]  eta: 0:00:33  loss: 0.1403 (0.1463)  time: 0.1711  data: 0.0001  max mem: 15821
[22:56:50.492281] Test:  [160/345]  eta: 0:00:31  loss: 0.1431 (0.1463)  time: 0.1714  data: 0.0001  max mem: 15821
[22:56:52.213311] Test:  [170/345]  eta: 0:00:30  loss: 0.1349 (0.1458)  time: 0.1718  data: 0.0001  max mem: 15821
[22:56:53.936855] Test:  [180/345]  eta: 0:00:28  loss: 0.1348 (0.1457)  time: 0.1722  data: 0.0001  max mem: 15821
[22:56:55.664591] Test:  [190/345]  eta: 0:00:26  loss: 0.1416 (0.1458)  time: 0.1725  data: 0.0001  max mem: 15821
[22:56:57.396198] Test:  [200/345]  eta: 0:00:24  loss: 0.1442 (0.1461)  time: 0.1729  data: 0.0001  max mem: 15821
[22:56:59.130164] Test:  [210/345]  eta: 0:00:23  loss: 0.1442 (0.1458)  time: 0.1732  data: 0.0001  max mem: 15821
[22:57:00.867440] Test:  [220/345]  eta: 0:00:21  loss: 0.1415 (0.1459)  time: 0.1735  data: 0.0001  max mem: 15821
[22:57:02.609758] Test:  [230/345]  eta: 0:00:19  loss: 0.1412 (0.1456)  time: 0.1739  data: 0.0001  max mem: 15821
[22:57:04.355814] Test:  [240/345]  eta: 0:00:18  loss: 0.1374 (0.1456)  time: 0.1744  data: 0.0001  max mem: 15821
[22:57:06.104041] Test:  [250/345]  eta: 0:00:16  loss: 0.1462 (0.1455)  time: 0.1746  data: 0.0001  max mem: 15821
[22:57:07.856600] Test:  [260/345]  eta: 0:00:14  loss: 0.1438 (0.1456)  time: 0.1750  data: 0.0001  max mem: 15821
[22:57:09.612353] Test:  [270/345]  eta: 0:00:12  loss: 0.1438 (0.1456)  time: 0.1753  data: 0.0001  max mem: 15821
[22:57:11.370831] Test:  [280/345]  eta: 0:00:11  loss: 0.1395 (0.1456)  time: 0.1756  data: 0.0001  max mem: 15821
[22:57:13.132192] Test:  [290/345]  eta: 0:00:09  loss: 0.1460 (0.1455)  time: 0.1759  data: 0.0001  max mem: 15821
[22:57:14.898319] Test:  [300/345]  eta: 0:00:07  loss: 0.1473 (0.1455)  time: 0.1763  data: 0.0001  max mem: 15821
[22:57:16.669377] Test:  [310/345]  eta: 0:00:06  loss: 0.1442 (0.1456)  time: 0.1768  data: 0.0001  max mem: 15821
[22:57:18.441699] Test:  [320/345]  eta: 0:00:04  loss: 0.1442 (0.1458)  time: 0.1771  data: 0.0001  max mem: 15821
[22:57:20.219022] Test:  [330/345]  eta: 0:00:02  loss: 0.1469 (0.1458)  time: 0.1774  data: 0.0001  max mem: 15821
[22:57:21.999065] Test:  [340/345]  eta: 0:00:00  loss: 0.1397 (0.1457)  time: 0.1778  data: 0.0001  max mem: 15821
[22:57:22.713156] Test:  [344/345]  eta: 0:00:00  loss: 0.1375 (0.1456)  time: 0.1780  data: 0.0001  max mem: 15821
[22:57:22.781647] Test: Total time: 0:00:59 (0.1738 s / it)
[22:57:33.264224] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4702 (0.4702)  time: 0.5401  data: 0.3778  max mem: 15821
[22:57:34.910053] Test:  [10/57]  eta: 0:00:09  loss: 0.3959 (0.4334)  time: 0.1986  data: 0.0344  max mem: 15821
[22:57:36.562269] Test:  [20/57]  eta: 0:00:06  loss: 0.4272 (0.4283)  time: 0.1648  data: 0.0001  max mem: 15821
[22:57:38.218289] Test:  [30/57]  eta: 0:00:04  loss: 0.2718 (0.3684)  time: 0.1653  data: 0.0001  max mem: 15821
[22:57:39.878005] Test:  [40/57]  eta: 0:00:02  loss: 0.2451 (0.3434)  time: 0.1657  data: 0.0001  max mem: 15821
[22:57:41.543244] Test:  [50/57]  eta: 0:00:01  loss: 0.2741 (0.3368)  time: 0.1662  data: 0.0001  max mem: 15821
[22:57:42.441627] Test:  [56/57]  eta: 0:00:00  loss: 0.3058 (0.3447)  time: 0.1614  data: 0.0000  max mem: 15821
[22:57:42.524362] Test: Total time: 0:00:09 (0.1719 s / it)
[22:57:44.287297] Dice score of the network on the train images: 0.857412, val images: 0.798802
[22:57:44.291517] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[22:57:45.275853] Epoch: [32]  [  0/345]  eta: 0:05:39  lr: 0.000082  loss: 0.1520 (0.1520)  time: 0.9835  data: 0.3822  max mem: 15821
[22:57:57.267464] Epoch: [32]  [ 20/345]  eta: 0:03:20  lr: 0.000081  loss: 0.1478 (0.1511)  time: 0.5995  data: 0.0001  max mem: 15821
[22:58:09.276608] Epoch: [32]  [ 40/345]  eta: 0:03:05  lr: 0.000081  loss: 0.1468 (0.1510)  time: 0.6004  data: 0.0001  max mem: 15821
[22:58:21.308001] Epoch: [32]  [ 60/345]  eta: 0:02:52  lr: 0.000081  loss: 0.1596 (0.1533)  time: 0.6015  data: 0.0001  max mem: 15821
[22:58:33.329852] Epoch: [32]  [ 80/345]  eta: 0:02:40  lr: 0.000080  loss: 0.1451 (0.1532)  time: 0.6010  data: 0.0001  max mem: 15821
[22:58:45.384890] Epoch: [32]  [100/345]  eta: 0:02:28  lr: 0.000080  loss: 0.1448 (0.1518)  time: 0.6027  data: 0.0001  max mem: 15821
[22:58:57.469398] Epoch: [32]  [120/345]  eta: 0:02:16  lr: 0.000080  loss: 0.1437 (0.1503)  time: 0.6042  data: 0.0001  max mem: 15821
[22:59:09.570933] Epoch: [32]  [140/345]  eta: 0:02:03  lr: 0.000079  loss: 0.1470 (0.1494)  time: 0.6050  data: 0.0001  max mem: 15821
[22:59:21.668144] Epoch: [32]  [160/345]  eta: 0:01:51  lr: 0.000079  loss: 0.1428 (0.1487)  time: 0.6048  data: 0.0001  max mem: 15821
[22:59:33.750467] Epoch: [32]  [180/345]  eta: 0:01:39  lr: 0.000079  loss: 0.1529 (0.1487)  time: 0.6041  data: 0.0001  max mem: 15821
[22:59:45.844424] Epoch: [32]  [200/345]  eta: 0:01:27  lr: 0.000078  loss: 0.1419 (0.1489)  time: 0.6046  data: 0.0001  max mem: 15821
[22:59:57.922532] Epoch: [32]  [220/345]  eta: 0:01:15  lr: 0.000078  loss: 0.1469 (0.1489)  time: 0.6039  data: 0.0001  max mem: 15821
[23:00:10.009526] Epoch: [32]  [240/345]  eta: 0:01:03  lr: 0.000077  loss: 0.1503 (0.1492)  time: 0.6043  data: 0.0001  max mem: 15821
[23:00:22.083882] Epoch: [32]  [260/345]  eta: 0:00:51  lr: 0.000077  loss: 0.1473 (0.1493)  time: 0.6037  data: 0.0001  max mem: 15821
[23:00:34.153821] Epoch: [32]  [280/345]  eta: 0:00:39  lr: 0.000077  loss: 0.1418 (0.1490)  time: 0.6034  data: 0.0001  max mem: 15821
[23:00:46.233913] Epoch: [32]  [300/345]  eta: 0:00:27  lr: 0.000076  loss: 0.1485 (0.1490)  time: 0.6040  data: 0.0001  max mem: 15821
[23:00:58.290260] Epoch: [32]  [320/345]  eta: 0:00:15  lr: 0.000076  loss: 0.1469 (0.1491)  time: 0.6028  data: 0.0001  max mem: 15821
[23:01:10.349245] Epoch: [32]  [340/345]  eta: 0:00:03  lr: 0.000076  loss: 0.1400 (0.1487)  time: 0.6029  data: 0.0001  max mem: 15821
[23:01:12.762421] Epoch: [32]  [344/345]  eta: 0:00:00  lr: 0.000076  loss: 0.1400 (0.1487)  time: 0.6030  data: 0.0001  max mem: 15821
[23:01:12.831519] Epoch: [32] Total time: 0:03:28 (0.6045 s / it)
[23:01:12.831875] Averaged stats: lr: 0.000076  loss: 0.1400 (0.1487)
[23:01:13.415504] Test:  [  0/345]  eta: 0:03:19  loss: 0.1340 (0.1340)  time: 0.5783  data: 0.4135  max mem: 15821
[23:01:15.082601] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1359 (0.1405)  time: 0.2040  data: 0.0377  max mem: 15821
[23:01:16.752203] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1359 (0.1378)  time: 0.1667  data: 0.0001  max mem: 15821
[23:01:18.424736] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1409 (0.1383)  time: 0.1670  data: 0.0001  max mem: 15821
[23:01:20.100528] Test:  [ 40/345]  eta: 0:00:54  loss: 0.1376 (0.1388)  time: 0.1674  data: 0.0001  max mem: 15821
[23:01:21.780330] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1335 (0.1400)  time: 0.1677  data: 0.0001  max mem: 15821
[23:01:23.462363] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1321 (0.1391)  time: 0.1680  data: 0.0001  max mem: 15821
[23:01:25.147721] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1309 (0.1390)  time: 0.1683  data: 0.0001  max mem: 15821
[23:01:26.837186] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1428 (0.1405)  time: 0.1687  data: 0.0001  max mem: 15821
[23:01:28.529550] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1423 (0.1396)  time: 0.1690  data: 0.0001  max mem: 15821
[23:01:30.225528] Test:  [100/345]  eta: 0:00:42  loss: 0.1342 (0.1394)  time: 0.1694  data: 0.0001  max mem: 15821
[23:01:31.925980] Test:  [110/345]  eta: 0:00:40  loss: 0.1331 (0.1384)  time: 0.1698  data: 0.0001  max mem: 15821
[23:01:33.628504] Test:  [120/345]  eta: 0:00:38  loss: 0.1331 (0.1387)  time: 0.1701  data: 0.0001  max mem: 15821
[23:01:35.334372] Test:  [130/345]  eta: 0:00:36  loss: 0.1448 (0.1394)  time: 0.1704  data: 0.0001  max mem: 15821
[23:01:37.044314] Test:  [140/345]  eta: 0:00:35  loss: 0.1446 (0.1397)  time: 0.1707  data: 0.0001  max mem: 15821
[23:01:38.757069] Test:  [150/345]  eta: 0:00:33  loss: 0.1266 (0.1395)  time: 0.1711  data: 0.0001  max mem: 15821
[23:01:40.473615] Test:  [160/345]  eta: 0:00:31  loss: 0.1326 (0.1396)  time: 0.1714  data: 0.0001  max mem: 15821
[23:01:42.193694] Test:  [170/345]  eta: 0:00:30  loss: 0.1359 (0.1397)  time: 0.1718  data: 0.0001  max mem: 15821
[23:01:43.917124] Test:  [180/345]  eta: 0:00:28  loss: 0.1371 (0.1402)  time: 0.1721  data: 0.0001  max mem: 15821
[23:01:45.644338] Test:  [190/345]  eta: 0:00:26  loss: 0.1373 (0.1402)  time: 0.1725  data: 0.0001  max mem: 15821
[23:01:47.374279] Test:  [200/345]  eta: 0:00:24  loss: 0.1324 (0.1398)  time: 0.1728  data: 0.0001  max mem: 15821
[23:01:49.108126] Test:  [210/345]  eta: 0:00:23  loss: 0.1384 (0.1399)  time: 0.1731  data: 0.0001  max mem: 15821
[23:01:50.844968] Test:  [220/345]  eta: 0:00:21  loss: 0.1389 (0.1400)  time: 0.1735  data: 0.0001  max mem: 15821
[23:01:52.584843] Test:  [230/345]  eta: 0:00:19  loss: 0.1420 (0.1401)  time: 0.1738  data: 0.0001  max mem: 15821
[23:01:54.328937] Test:  [240/345]  eta: 0:00:18  loss: 0.1439 (0.1401)  time: 0.1741  data: 0.0001  max mem: 15821
[23:01:56.078206] Test:  [250/345]  eta: 0:00:16  loss: 0.1329 (0.1400)  time: 0.1746  data: 0.0001  max mem: 15821
[23:01:57.829387] Test:  [260/345]  eta: 0:00:14  loss: 0.1280 (0.1399)  time: 0.1750  data: 0.0001  max mem: 15821
[23:01:59.585364] Test:  [270/345]  eta: 0:00:12  loss: 0.1390 (0.1404)  time: 0.1753  data: 0.0001  max mem: 15821
[23:02:01.343846] Test:  [280/345]  eta: 0:00:11  loss: 0.1406 (0.1407)  time: 0.1757  data: 0.0001  max mem: 15821
[23:02:03.105560] Test:  [290/345]  eta: 0:00:09  loss: 0.1345 (0.1406)  time: 0.1759  data: 0.0001  max mem: 15821
[23:02:04.871341] Test:  [300/345]  eta: 0:00:07  loss: 0.1345 (0.1408)  time: 0.1763  data: 0.0001  max mem: 15821
[23:02:06.640081] Test:  [310/345]  eta: 0:00:06  loss: 0.1448 (0.1410)  time: 0.1767  data: 0.0001  max mem: 15821
[23:02:08.411682] Test:  [320/345]  eta: 0:00:04  loss: 0.1410 (0.1408)  time: 0.1770  data: 0.0001  max mem: 15821
[23:02:10.188019] Test:  [330/345]  eta: 0:00:02  loss: 0.1386 (0.1408)  time: 0.1773  data: 0.0001  max mem: 15821
[23:02:11.967172] Test:  [340/345]  eta: 0:00:00  loss: 0.1388 (0.1407)  time: 0.1777  data: 0.0001  max mem: 15821
[23:02:12.680389] Test:  [344/345]  eta: 0:00:00  loss: 0.1415 (0.1408)  time: 0.1779  data: 0.0001  max mem: 15821
[23:02:12.741486] Test: Total time: 0:00:59 (0.1736 s / it)
[23:02:23.206034] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4845 (0.4845)  time: 0.5184  data: 0.3560  max mem: 15821
[23:02:24.851958] Test:  [10/57]  eta: 0:00:09  loss: 0.3905 (0.4479)  time: 0.1967  data: 0.0325  max mem: 15821
[23:02:26.503705] Test:  [20/57]  eta: 0:00:06  loss: 0.3905 (0.4347)  time: 0.1648  data: 0.0001  max mem: 15821
[23:02:28.160179] Test:  [30/57]  eta: 0:00:04  loss: 0.2817 (0.3736)  time: 0.1653  data: 0.0001  max mem: 15821
[23:02:29.820987] Test:  [40/57]  eta: 0:00:02  loss: 0.2380 (0.3483)  time: 0.1658  data: 0.0001  max mem: 15821
[23:02:31.486140] Test:  [50/57]  eta: 0:00:01  loss: 0.2869 (0.3437)  time: 0.1662  data: 0.0001  max mem: 15821
[23:02:32.385323] Test:  [56/57]  eta: 0:00:00  loss: 0.3172 (0.3523)  time: 0.1614  data: 0.0001  max mem: 15821
[23:02:32.445300] Test: Total time: 0:00:09 (0.1712 s / it)
[23:02:34.205400] Dice score of the network on the train images: 0.863556, val images: 0.798909
[23:02:34.209887] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[23:02:35.175469] Epoch: [33]  [  0/345]  eta: 0:05:32  lr: 0.000075  loss: 0.1202 (0.1202)  time: 0.9644  data: 0.3630  max mem: 15821
[23:02:47.174539] Epoch: [33]  [ 20/345]  eta: 0:03:20  lr: 0.000075  loss: 0.1379 (0.1420)  time: 0.5999  data: 0.0001  max mem: 15821
[23:02:59.179295] Epoch: [33]  [ 40/345]  eta: 0:03:05  lr: 0.000075  loss: 0.1434 (0.1434)  time: 0.6002  data: 0.0001  max mem: 15821
[23:03:11.212411] Epoch: [33]  [ 60/345]  eta: 0:02:52  lr: 0.000074  loss: 0.1399 (0.1444)  time: 0.6016  data: 0.0001  max mem: 15821
[23:03:23.259607] Epoch: [33]  [ 80/345]  eta: 0:02:40  lr: 0.000074  loss: 0.1416 (0.1446)  time: 0.6023  data: 0.0001  max mem: 15821
[23:03:35.304525] Epoch: [33]  [100/345]  eta: 0:02:28  lr: 0.000074  loss: 0.1432 (0.1456)  time: 0.6022  data: 0.0001  max mem: 15821
[23:03:47.388154] Epoch: [33]  [120/345]  eta: 0:02:16  lr: 0.000073  loss: 0.1468 (0.1461)  time: 0.6041  data: 0.0001  max mem: 15821
[23:03:59.500697] Epoch: [33]  [140/345]  eta: 0:02:03  lr: 0.000073  loss: 0.1399 (0.1460)  time: 0.6056  data: 0.0001  max mem: 15821
[23:04:11.601649] Epoch: [33]  [160/345]  eta: 0:01:51  lr: 0.000073  loss: 0.1491 (0.1467)  time: 0.6050  data: 0.0001  max mem: 15821
[23:04:23.680651] Epoch: [33]  [180/345]  eta: 0:01:39  lr: 0.000072  loss: 0.1366 (0.1459)  time: 0.6039  data: 0.0001  max mem: 15821
[23:04:35.761533] Epoch: [33]  [200/345]  eta: 0:01:27  lr: 0.000072  loss: 0.1496 (0.1463)  time: 0.6040  data: 0.0001  max mem: 15821
[23:04:47.847891] Epoch: [33]  [220/345]  eta: 0:01:15  lr: 0.000071  loss: 0.1405 (0.1459)  time: 0.6043  data: 0.0001  max mem: 15821
[23:05:00.067822] Epoch: [33]  [240/345]  eta: 0:01:03  lr: 0.000071  loss: 0.1465 (0.1465)  time: 0.6109  data: 0.0001  max mem: 15821
[23:05:12.161426] Epoch: [33]  [260/345]  eta: 0:00:51  lr: 0.000071  loss: 0.1372 (0.1463)  time: 0.6046  data: 0.0001  max mem: 15821
[23:05:24.250956] Epoch: [33]  [280/345]  eta: 0:00:39  lr: 0.000070  loss: 0.1375 (0.1465)  time: 0.6044  data: 0.0001  max mem: 15821
[23:05:36.332562] Epoch: [33]  [300/345]  eta: 0:00:27  lr: 0.000070  loss: 0.1452 (0.1463)  time: 0.6040  data: 0.0001  max mem: 15821
[23:05:48.419964] Epoch: [33]  [320/345]  eta: 0:00:15  lr: 0.000070  loss: 0.1320 (0.1456)  time: 0.6043  data: 0.0001  max mem: 15821
[23:06:00.493896] Epoch: [33]  [340/345]  eta: 0:00:03  lr: 0.000069  loss: 0.1369 (0.1452)  time: 0.6036  data: 0.0001  max mem: 15821
[23:06:02.913205] Epoch: [33]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.1419 (0.1452)  time: 0.6038  data: 0.0001  max mem: 15821
[23:06:02.986398] Epoch: [33] Total time: 0:03:28 (0.6051 s / it)
[23:06:02.986622] Averaged stats: lr: 0.000069  loss: 0.1419 (0.1452)
[23:06:03.585596] Test:  [  0/345]  eta: 0:03:24  loss: 0.1178 (0.1178)  time: 0.5935  data: 0.4291  max mem: 15821
[23:06:05.250197] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1275 (0.1292)  time: 0.2052  data: 0.0391  max mem: 15821
[23:06:06.917748] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1282 (0.1338)  time: 0.1665  data: 0.0001  max mem: 15821
[23:06:08.589944] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1286 (0.1322)  time: 0.1669  data: 0.0001  max mem: 15821
[23:06:10.264708] Test:  [ 40/345]  eta: 0:00:54  loss: 0.1287 (0.1332)  time: 0.1673  data: 0.0001  max mem: 15821
[23:06:11.942351] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1302 (0.1338)  time: 0.1675  data: 0.0001  max mem: 15821
[23:06:13.622949] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1275 (0.1332)  time: 0.1678  data: 0.0001  max mem: 15821
[23:06:15.308074] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1318 (0.1343)  time: 0.1682  data: 0.0001  max mem: 15821
[23:06:16.996544] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1355 (0.1342)  time: 0.1686  data: 0.0001  max mem: 15821
[23:06:18.687806] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1296 (0.1341)  time: 0.1689  data: 0.0001  max mem: 15821
[23:06:20.382202] Test:  [100/345]  eta: 0:00:42  loss: 0.1371 (0.1354)  time: 0.1692  data: 0.0001  max mem: 15821
[23:06:22.080742] Test:  [110/345]  eta: 0:00:40  loss: 0.1389 (0.1359)  time: 0.1696  data: 0.0001  max mem: 15821
[23:06:23.783550] Test:  [120/345]  eta: 0:00:38  loss: 0.1365 (0.1360)  time: 0.1700  data: 0.0001  max mem: 15821
[23:06:25.487927] Test:  [130/345]  eta: 0:00:36  loss: 0.1358 (0.1363)  time: 0.1703  data: 0.0001  max mem: 15821
[23:06:27.196120] Test:  [140/345]  eta: 0:00:35  loss: 0.1346 (0.1360)  time: 0.1706  data: 0.0001  max mem: 15821
[23:06:28.909133] Test:  [150/345]  eta: 0:00:33  loss: 0.1232 (0.1351)  time: 0.1710  data: 0.0001  max mem: 15821
[23:06:30.623597] Test:  [160/345]  eta: 0:00:31  loss: 0.1255 (0.1352)  time: 0.1713  data: 0.0001  max mem: 15821
[23:06:32.342893] Test:  [170/345]  eta: 0:00:30  loss: 0.1367 (0.1357)  time: 0.1716  data: 0.0001  max mem: 15821
[23:06:34.064049] Test:  [180/345]  eta: 0:00:28  loss: 0.1411 (0.1362)  time: 0.1720  data: 0.0001  max mem: 15821
[23:06:35.789090] Test:  [190/345]  eta: 0:00:26  loss: 0.1379 (0.1360)  time: 0.1722  data: 0.0001  max mem: 15821
[23:06:37.516437] Test:  [200/345]  eta: 0:00:24  loss: 0.1375 (0.1362)  time: 0.1726  data: 0.0001  max mem: 15821
[23:06:39.247795] Test:  [210/345]  eta: 0:00:23  loss: 0.1389 (0.1368)  time: 0.1729  data: 0.0001  max mem: 15821
[23:06:40.981646] Test:  [220/345]  eta: 0:00:21  loss: 0.1426 (0.1367)  time: 0.1732  data: 0.0001  max mem: 15821
[23:06:42.721674] Test:  [230/345]  eta: 0:00:19  loss: 0.1337 (0.1365)  time: 0.1736  data: 0.0001  max mem: 15821
[23:06:44.462651] Test:  [240/345]  eta: 0:00:18  loss: 0.1337 (0.1366)  time: 0.1740  data: 0.0001  max mem: 15821
[23:06:46.210324] Test:  [250/345]  eta: 0:00:16  loss: 0.1351 (0.1364)  time: 0.1744  data: 0.0001  max mem: 15821
[23:06:47.958359] Test:  [260/345]  eta: 0:00:14  loss: 0.1287 (0.1362)  time: 0.1747  data: 0.0001  max mem: 15821
[23:06:49.711800] Test:  [270/345]  eta: 0:00:12  loss: 0.1286 (0.1360)  time: 0.1750  data: 0.0001  max mem: 15821
[23:06:51.469306] Test:  [280/345]  eta: 0:00:11  loss: 0.1390 (0.1364)  time: 0.1755  data: 0.0001  max mem: 15821
[23:06:53.227847] Test:  [290/345]  eta: 0:00:09  loss: 0.1441 (0.1367)  time: 0.1757  data: 0.0001  max mem: 15821
[23:06:54.990405] Test:  [300/345]  eta: 0:00:07  loss: 0.1490 (0.1368)  time: 0.1760  data: 0.0001  max mem: 15821
[23:06:56.757459] Test:  [310/345]  eta: 0:00:06  loss: 0.1292 (0.1366)  time: 0.1764  data: 0.0001  max mem: 15821
[23:06:58.527918] Test:  [320/345]  eta: 0:00:04  loss: 0.1245 (0.1364)  time: 0.1768  data: 0.0001  max mem: 15821
[23:07:00.302179] Test:  [330/345]  eta: 0:00:02  loss: 0.1376 (0.1365)  time: 0.1772  data: 0.0001  max mem: 15821
[23:07:02.080305] Test:  [340/345]  eta: 0:00:00  loss: 0.1384 (0.1367)  time: 0.1776  data: 0.0001  max mem: 15821
[23:07:02.791796] Test:  [344/345]  eta: 0:00:00  loss: 0.1331 (0.1366)  time: 0.1777  data: 0.0001  max mem: 15821
[23:07:02.858788] Test: Total time: 0:00:59 (0.1735 s / it)
[23:07:13.317873] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4642 (0.4642)  time: 0.5147  data: 0.3525  max mem: 15821
[23:07:14.965141] Test:  [10/57]  eta: 0:00:09  loss: 0.4380 (0.4578)  time: 0.1964  data: 0.0321  max mem: 15821
[23:07:16.616558] Test:  [20/57]  eta: 0:00:06  loss: 0.4190 (0.4412)  time: 0.1648  data: 0.0001  max mem: 15821
[23:07:18.271219] Test:  [30/57]  eta: 0:00:04  loss: 0.3031 (0.3827)  time: 0.1652  data: 0.0001  max mem: 15821
[23:07:19.930330] Test:  [40/57]  eta: 0:00:02  loss: 0.2574 (0.3610)  time: 0.1656  data: 0.0001  max mem: 15821
[23:07:21.596420] Test:  [50/57]  eta: 0:00:01  loss: 0.3100 (0.3561)  time: 0.1662  data: 0.0001  max mem: 15821
[23:07:22.494874] Test:  [56/57]  eta: 0:00:00  loss: 0.3482 (0.3686)  time: 0.1614  data: 0.0000  max mem: 15821
[23:07:22.561228] Test: Total time: 0:00:09 (0.1712 s / it)
[23:07:24.343643] Dice score of the network on the train images: 0.872409, val images: 0.789724
[23:07:24.347778] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[23:07:25.369104] Epoch: [34]  [  0/345]  eta: 0:05:52  lr: 0.000069  loss: 0.1397 (0.1397)  time: 1.0205  data: 0.4226  max mem: 15821
[23:07:37.338033] Epoch: [34]  [ 20/345]  eta: 0:03:21  lr: 0.000069  loss: 0.1426 (0.1396)  time: 0.5984  data: 0.0001  max mem: 15821
[23:07:49.345386] Epoch: [34]  [ 40/345]  eta: 0:03:05  lr: 0.000068  loss: 0.1394 (0.1413)  time: 0.6003  data: 0.0001  max mem: 15821
[23:08:01.377285] Epoch: [34]  [ 60/345]  eta: 0:02:52  lr: 0.000068  loss: 0.1421 (0.1425)  time: 0.6016  data: 0.0001  max mem: 15821
[23:08:13.414716] Epoch: [34]  [ 80/345]  eta: 0:02:40  lr: 0.000068  loss: 0.1522 (0.1442)  time: 0.6018  data: 0.0001  max mem: 15821
[23:08:25.463886] Epoch: [34]  [100/345]  eta: 0:02:28  lr: 0.000067  loss: 0.1333 (0.1429)  time: 0.6024  data: 0.0001  max mem: 15821
[23:08:37.536352] Epoch: [34]  [120/345]  eta: 0:02:16  lr: 0.000067  loss: 0.1431 (0.1438)  time: 0.6036  data: 0.0001  max mem: 15821
[23:08:49.749900] Epoch: [34]  [140/345]  eta: 0:02:04  lr: 0.000066  loss: 0.1354 (0.1431)  time: 0.6106  data: 0.0001  max mem: 15821
[23:09:01.833779] Epoch: [34]  [160/345]  eta: 0:01:52  lr: 0.000066  loss: 0.1478 (0.1437)  time: 0.6041  data: 0.0001  max mem: 15821
[23:09:13.922229] Epoch: [34]  [180/345]  eta: 0:01:39  lr: 0.000066  loss: 0.1434 (0.1438)  time: 0.6044  data: 0.0001  max mem: 15821
[23:09:26.017667] Epoch: [34]  [200/345]  eta: 0:01:27  lr: 0.000065  loss: 0.1286 (0.1425)  time: 0.6047  data: 0.0001  max mem: 15821
[23:09:38.103639] Epoch: [34]  [220/345]  eta: 0:01:15  lr: 0.000065  loss: 0.1363 (0.1421)  time: 0.6042  data: 0.0001  max mem: 15821
[23:09:50.193647] Epoch: [34]  [240/345]  eta: 0:01:03  lr: 0.000064  loss: 0.1404 (0.1420)  time: 0.6045  data: 0.0001  max mem: 15821
[23:10:02.275564] Epoch: [34]  [260/345]  eta: 0:00:51  lr: 0.000064  loss: 0.1347 (0.1420)  time: 0.6041  data: 0.0001  max mem: 15821
[23:10:14.361220] Epoch: [34]  [280/345]  eta: 0:00:39  lr: 0.000064  loss: 0.1334 (0.1420)  time: 0.6042  data: 0.0001  max mem: 15821
[23:10:26.437833] Epoch: [34]  [300/345]  eta: 0:00:27  lr: 0.000063  loss: 0.1433 (0.1422)  time: 0.6038  data: 0.0001  max mem: 15821
[23:10:38.515653] Epoch: [34]  [320/345]  eta: 0:00:15  lr: 0.000063  loss: 0.1389 (0.1421)  time: 0.6038  data: 0.0001  max mem: 15821
[23:10:50.583849] Epoch: [34]  [340/345]  eta: 0:00:03  lr: 0.000063  loss: 0.1331 (0.1417)  time: 0.6034  data: 0.0001  max mem: 15821
[23:10:52.997234] Epoch: [34]  [344/345]  eta: 0:00:00  lr: 0.000063  loss: 0.1321 (0.1416)  time: 0.6032  data: 0.0001  max mem: 15821
[23:10:53.080492] Epoch: [34] Total time: 0:03:28 (0.6050 s / it)
[23:10:53.080751] Averaged stats: lr: 0.000063  loss: 0.1321 (0.1416)
[23:10:53.683315] Test:  [  0/345]  eta: 0:03:25  loss: 0.1539 (0.1539)  time: 0.5963  data: 0.4323  max mem: 15821
[23:10:55.347815] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1375 (0.1389)  time: 0.2054  data: 0.0394  max mem: 15821
[23:10:57.016118] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1348 (0.1409)  time: 0.1666  data: 0.0001  max mem: 15821
[23:10:58.688570] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1346 (0.1383)  time: 0.1670  data: 0.0001  max mem: 15821
[23:11:00.363358] Test:  [ 40/345]  eta: 0:00:54  loss: 0.1361 (0.1380)  time: 0.1673  data: 0.0001  max mem: 15821
[23:11:02.041375] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1334 (0.1362)  time: 0.1676  data: 0.0001  max mem: 15821
[23:11:03.722766] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1280 (0.1355)  time: 0.1679  data: 0.0001  max mem: 15821
[23:11:05.407233] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1306 (0.1355)  time: 0.1682  data: 0.0001  max mem: 15821
[23:11:07.095115] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1291 (0.1347)  time: 0.1685  data: 0.0001  max mem: 15821
[23:11:08.786576] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1339 (0.1350)  time: 0.1689  data: 0.0001  max mem: 15821
[23:11:10.481315] Test:  [100/345]  eta: 0:00:42  loss: 0.1421 (0.1370)  time: 0.1692  data: 0.0001  max mem: 15821
[23:11:12.180178] Test:  [110/345]  eta: 0:00:40  loss: 0.1395 (0.1370)  time: 0.1696  data: 0.0001  max mem: 15821
[23:11:13.880837] Test:  [120/345]  eta: 0:00:38  loss: 0.1332 (0.1371)  time: 0.1699  data: 0.0001  max mem: 15821
[23:11:15.585114] Test:  [130/345]  eta: 0:00:36  loss: 0.1347 (0.1370)  time: 0.1702  data: 0.0001  max mem: 15821
[23:11:17.295105] Test:  [140/345]  eta: 0:00:35  loss: 0.1253 (0.1361)  time: 0.1706  data: 0.0001  max mem: 15821
[23:11:19.006369] Test:  [150/345]  eta: 0:00:33  loss: 0.1253 (0.1363)  time: 0.1710  data: 0.0001  max mem: 15821
[23:11:20.721445] Test:  [160/345]  eta: 0:00:31  loss: 0.1253 (0.1355)  time: 0.1713  data: 0.0001  max mem: 15821
[23:11:22.442538] Test:  [170/345]  eta: 0:00:30  loss: 0.1223 (0.1354)  time: 0.1717  data: 0.0001  max mem: 15821
[23:11:24.165621] Test:  [180/345]  eta: 0:00:28  loss: 0.1272 (0.1354)  time: 0.1721  data: 0.0001  max mem: 15821
[23:11:25.892287] Test:  [190/345]  eta: 0:00:26  loss: 0.1291 (0.1354)  time: 0.1724  data: 0.0001  max mem: 15821
[23:11:27.622161] Test:  [200/345]  eta: 0:00:24  loss: 0.1307 (0.1351)  time: 0.1728  data: 0.0001  max mem: 15821
[23:11:29.357345] Test:  [210/345]  eta: 0:00:23  loss: 0.1271 (0.1349)  time: 0.1732  data: 0.0001  max mem: 15821
[23:11:31.094768] Test:  [220/345]  eta: 0:00:21  loss: 0.1243 (0.1345)  time: 0.1736  data: 0.0001  max mem: 15821
[23:11:32.835261] Test:  [230/345]  eta: 0:00:19  loss: 0.1315 (0.1348)  time: 0.1738  data: 0.0001  max mem: 15821
[23:11:34.578262] Test:  [240/345]  eta: 0:00:18  loss: 0.1315 (0.1345)  time: 0.1741  data: 0.0001  max mem: 15821
[23:11:36.323919] Test:  [250/345]  eta: 0:00:16  loss: 0.1277 (0.1345)  time: 0.1744  data: 0.0001  max mem: 15821
[23:11:38.072838] Test:  [260/345]  eta: 0:00:14  loss: 0.1305 (0.1347)  time: 0.1747  data: 0.0001  max mem: 15821
[23:11:39.823944] Test:  [270/345]  eta: 0:00:12  loss: 0.1391 (0.1348)  time: 0.1749  data: 0.0001  max mem: 15821
[23:11:41.580078] Test:  [280/345]  eta: 0:00:11  loss: 0.1259 (0.1342)  time: 0.1753  data: 0.0001  max mem: 15821
[23:11:43.340615] Test:  [290/345]  eta: 0:00:09  loss: 0.1211 (0.1341)  time: 0.1758  data: 0.0001  max mem: 15821
[23:11:45.104558] Test:  [300/345]  eta: 0:00:07  loss: 0.1238 (0.1342)  time: 0.1762  data: 0.0001  max mem: 15821
[23:11:46.872092] Test:  [310/345]  eta: 0:00:06  loss: 0.1338 (0.1345)  time: 0.1765  data: 0.0001  max mem: 15821
[23:11:48.642729] Test:  [320/345]  eta: 0:00:04  loss: 0.1323 (0.1344)  time: 0.1768  data: 0.0001  max mem: 15821
[23:11:50.417503] Test:  [330/345]  eta: 0:00:02  loss: 0.1342 (0.1346)  time: 0.1772  data: 0.0001  max mem: 15821
[23:11:52.194837] Test:  [340/345]  eta: 0:00:00  loss: 0.1377 (0.1348)  time: 0.1775  data: 0.0001  max mem: 15821
[23:11:52.906346] Test:  [344/345]  eta: 0:00:00  loss: 0.1375 (0.1347)  time: 0.1776  data: 0.0001  max mem: 15821
[23:11:52.979202] Test: Total time: 0:00:59 (0.1736 s / it)
[23:12:03.493537] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4607 (0.4607)  time: 0.5250  data: 0.3625  max mem: 15821
[23:12:05.139595] Test:  [10/57]  eta: 0:00:09  loss: 0.3913 (0.4351)  time: 0.1973  data: 0.0330  max mem: 15821
[23:12:06.791593] Test:  [20/57]  eta: 0:00:06  loss: 0.3920 (0.4269)  time: 0.1648  data: 0.0001  max mem: 15821
[23:12:08.446105] Test:  [30/57]  eta: 0:00:04  loss: 0.2876 (0.3685)  time: 0.1653  data: 0.0001  max mem: 15821
[23:12:10.105056] Test:  [40/57]  eta: 0:00:02  loss: 0.2356 (0.3454)  time: 0.1656  data: 0.0001  max mem: 15821
[23:12:11.770380] Test:  [50/57]  eta: 0:00:01  loss: 0.2943 (0.3395)  time: 0.1662  data: 0.0001  max mem: 15821
[23:12:12.668322] Test:  [56/57]  eta: 0:00:00  loss: 0.3228 (0.3514)  time: 0.1613  data: 0.0001  max mem: 15821
[23:12:12.754020] Test: Total time: 0:00:09 (0.1717 s / it)
[23:12:14.518045] Dice score of the network on the train images: 0.868319, val images: 0.795494
[23:12:14.522845] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[23:12:15.535957] Epoch: [35]  [  0/345]  eta: 0:05:49  lr: 0.000063  loss: 0.1320 (0.1320)  time: 1.0119  data: 0.4119  max mem: 15821
[23:12:27.504266] Epoch: [35]  [ 20/345]  eta: 0:03:20  lr: 0.000062  loss: 0.1342 (0.1377)  time: 0.5984  data: 0.0001  max mem: 15821
[23:12:39.515552] Epoch: [35]  [ 40/345]  eta: 0:03:05  lr: 0.000062  loss: 0.1365 (0.1388)  time: 0.6005  data: 0.0001  max mem: 15821
[23:12:51.540495] Epoch: [35]  [ 60/345]  eta: 0:02:52  lr: 0.000061  loss: 0.1401 (0.1394)  time: 0.6012  data: 0.0001  max mem: 15821
[23:13:03.584711] Epoch: [35]  [ 80/345]  eta: 0:02:40  lr: 0.000061  loss: 0.1416 (0.1402)  time: 0.6022  data: 0.0001  max mem: 15821
[23:13:15.640086] Epoch: [35]  [100/345]  eta: 0:02:28  lr: 0.000061  loss: 0.1347 (0.1402)  time: 0.6027  data: 0.0001  max mem: 15821
[23:13:27.721489] Epoch: [35]  [120/345]  eta: 0:02:16  lr: 0.000060  loss: 0.1286 (0.1391)  time: 0.6040  data: 0.0001  max mem: 15821
[23:13:39.815304] Epoch: [35]  [140/345]  eta: 0:02:03  lr: 0.000060  loss: 0.1266 (0.1383)  time: 0.6046  data: 0.0001  max mem: 15821
[23:13:51.895994] Epoch: [35]  [160/345]  eta: 0:01:51  lr: 0.000059  loss: 0.1308 (0.1382)  time: 0.6040  data: 0.0001  max mem: 15821
[23:14:03.988914] Epoch: [35]  [180/345]  eta: 0:01:39  lr: 0.000059  loss: 0.1356 (0.1383)  time: 0.6046  data: 0.0001  max mem: 15821
[23:14:16.084240] Epoch: [35]  [200/345]  eta: 0:01:27  lr: 0.000059  loss: 0.1358 (0.1385)  time: 0.6047  data: 0.0001  max mem: 15821
[23:14:28.170891] Epoch: [35]  [220/345]  eta: 0:01:15  lr: 0.000058  loss: 0.1344 (0.1386)  time: 0.6043  data: 0.0001  max mem: 15821
[23:14:40.259320] Epoch: [35]  [240/345]  eta: 0:01:03  lr: 0.000058  loss: 0.1270 (0.1379)  time: 0.6044  data: 0.0001  max mem: 15821
[23:14:52.347932] Epoch: [35]  [260/345]  eta: 0:00:51  lr: 0.000058  loss: 0.1348 (0.1379)  time: 0.6044  data: 0.0001  max mem: 15821
[23:15:04.434017] Epoch: [35]  [280/345]  eta: 0:00:39  lr: 0.000057  loss: 0.1429 (0.1386)  time: 0.6043  data: 0.0001  max mem: 15821
[23:15:16.518727] Epoch: [35]  [300/345]  eta: 0:00:27  lr: 0.000057  loss: 0.1358 (0.1385)  time: 0.6042  data: 0.0001  max mem: 15821
[23:15:28.596606] Epoch: [35]  [320/345]  eta: 0:00:15  lr: 0.000056  loss: 0.1335 (0.1382)  time: 0.6039  data: 0.0001  max mem: 15821
[23:15:40.676471] Epoch: [35]  [340/345]  eta: 0:00:03  lr: 0.000056  loss: 0.1269 (0.1376)  time: 0.6039  data: 0.0001  max mem: 15821
[23:15:43.091992] Epoch: [35]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.1286 (0.1376)  time: 0.6039  data: 0.0001  max mem: 15821
[23:15:43.165963] Epoch: [35] Total time: 0:03:28 (0.6048 s / it)
[23:15:43.166503] Averaged stats: lr: 0.000056  loss: 0.1286 (0.1376)
[23:15:43.743091] Test:  [  0/345]  eta: 0:03:16  loss: 0.1269 (0.1269)  time: 0.5694  data: 0.4051  max mem: 15821
[23:15:45.408886] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1279 (0.1288)  time: 0.2031  data: 0.0369  max mem: 15821
[23:15:47.079412] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1283 (0.1309)  time: 0.1667  data: 0.0001  max mem: 15821
[23:15:48.752026] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1336 (0.1318)  time: 0.1671  data: 0.0001  max mem: 15821
[23:15:50.428240] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1284 (0.1301)  time: 0.1674  data: 0.0001  max mem: 15821
[23:15:52.107430] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1213 (0.1306)  time: 0.1677  data: 0.0001  max mem: 15821
[23:15:53.790546] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1220 (0.1308)  time: 0.1681  data: 0.0001  max mem: 15821
[23:15:55.476524] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1213 (0.1306)  time: 0.1684  data: 0.0001  max mem: 15821
[23:15:57.165897] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1200 (0.1302)  time: 0.1687  data: 0.0001  max mem: 15821
[23:15:58.859384] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1335 (0.1307)  time: 0.1691  data: 0.0001  max mem: 15821
[23:16:00.556588] Test:  [100/345]  eta: 0:00:42  loss: 0.1260 (0.1300)  time: 0.1695  data: 0.0001  max mem: 15821
[23:16:02.256435] Test:  [110/345]  eta: 0:00:40  loss: 0.1252 (0.1307)  time: 0.1698  data: 0.0001  max mem: 15821
[23:16:03.960147] Test:  [120/345]  eta: 0:00:38  loss: 0.1262 (0.1307)  time: 0.1701  data: 0.0001  max mem: 15821
[23:16:05.666363] Test:  [130/345]  eta: 0:00:36  loss: 0.1289 (0.1312)  time: 0.1704  data: 0.0001  max mem: 15821
[23:16:07.378204] Test:  [140/345]  eta: 0:00:35  loss: 0.1264 (0.1315)  time: 0.1708  data: 0.0001  max mem: 15821
[23:16:09.092073] Test:  [150/345]  eta: 0:00:33  loss: 0.1256 (0.1313)  time: 0.1712  data: 0.0001  max mem: 15821
[23:16:10.808769] Test:  [160/345]  eta: 0:00:31  loss: 0.1246 (0.1313)  time: 0.1715  data: 0.0001  max mem: 15821
[23:16:12.528706] Test:  [170/345]  eta: 0:00:30  loss: 0.1369 (0.1315)  time: 0.1718  data: 0.0001  max mem: 15821
[23:16:14.253670] Test:  [180/345]  eta: 0:00:28  loss: 0.1227 (0.1308)  time: 0.1722  data: 0.0001  max mem: 15821
[23:16:15.982206] Test:  [190/345]  eta: 0:00:26  loss: 0.1227 (0.1312)  time: 0.1726  data: 0.0001  max mem: 15821
[23:16:17.712539] Test:  [200/345]  eta: 0:00:24  loss: 0.1251 (0.1311)  time: 0.1729  data: 0.0001  max mem: 15821
[23:16:19.446462] Test:  [210/345]  eta: 0:00:23  loss: 0.1251 (0.1317)  time: 0.1731  data: 0.0001  max mem: 15821
[23:16:21.185491] Test:  [220/345]  eta: 0:00:21  loss: 0.1249 (0.1312)  time: 0.1736  data: 0.0001  max mem: 15821
[23:16:22.926068] Test:  [230/345]  eta: 0:00:19  loss: 0.1236 (0.1316)  time: 0.1739  data: 0.0001  max mem: 15821
[23:16:24.671134] Test:  [240/345]  eta: 0:00:18  loss: 0.1337 (0.1315)  time: 0.1742  data: 0.0001  max mem: 15821
[23:16:26.419913] Test:  [250/345]  eta: 0:00:16  loss: 0.1317 (0.1317)  time: 0.1746  data: 0.0001  max mem: 15821
[23:16:28.171055] Test:  [260/345]  eta: 0:00:14  loss: 0.1317 (0.1318)  time: 0.1749  data: 0.0001  max mem: 15821
[23:16:29.925313] Test:  [270/345]  eta: 0:00:12  loss: 0.1340 (0.1319)  time: 0.1752  data: 0.0001  max mem: 15821
[23:16:31.685150] Test:  [280/345]  eta: 0:00:11  loss: 0.1270 (0.1318)  time: 0.1756  data: 0.0001  max mem: 15821
[23:16:33.446671] Test:  [290/345]  eta: 0:00:09  loss: 0.1344 (0.1322)  time: 0.1760  data: 0.0001  max mem: 15821
[23:16:35.212777] Test:  [300/345]  eta: 0:00:07  loss: 0.1402 (0.1323)  time: 0.1763  data: 0.0001  max mem: 15821
[23:16:36.982374] Test:  [310/345]  eta: 0:00:06  loss: 0.1303 (0.1321)  time: 0.1767  data: 0.0001  max mem: 15821
[23:16:38.755009] Test:  [320/345]  eta: 0:00:04  loss: 0.1235 (0.1320)  time: 0.1770  data: 0.0001  max mem: 15821
[23:16:40.532331] Test:  [330/345]  eta: 0:00:02  loss: 0.1301 (0.1319)  time: 0.1774  data: 0.0001  max mem: 15821
[23:16:42.310897] Test:  [340/345]  eta: 0:00:00  loss: 0.1318 (0.1320)  time: 0.1777  data: 0.0001  max mem: 15821
[23:16:43.023909] Test:  [344/345]  eta: 0:00:00  loss: 0.1329 (0.1320)  time: 0.1779  data: 0.0001  max mem: 15821
[23:16:43.090924] Test: Total time: 0:00:59 (0.1737 s / it)
[23:16:53.585913] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4771 (0.4771)  time: 0.5211  data: 0.3586  max mem: 15821
[23:16:55.231538] Test:  [10/57]  eta: 0:00:09  loss: 0.4239 (0.4525)  time: 0.1969  data: 0.0327  max mem: 15821
[23:16:56.881940] Test:  [20/57]  eta: 0:00:06  loss: 0.4224 (0.4396)  time: 0.1647  data: 0.0001  max mem: 15821
[23:16:58.538276] Test:  [30/57]  eta: 0:00:04  loss: 0.3145 (0.3830)  time: 0.1653  data: 0.0001  max mem: 15821
[23:17:00.200872] Test:  [40/57]  eta: 0:00:02  loss: 0.2652 (0.3632)  time: 0.1659  data: 0.0001  max mem: 15821
[23:17:01.865028] Test:  [50/57]  eta: 0:00:01  loss: 0.3160 (0.3592)  time: 0.1663  data: 0.0001  max mem: 15821
[23:17:02.762695] Test:  [56/57]  eta: 0:00:00  loss: 0.3602 (0.3756)  time: 0.1613  data: 0.0001  max mem: 15821
[23:17:02.830127] Test: Total time: 0:00:09 (0.1713 s / it)
[23:17:04.616367] Dice score of the network on the train images: 0.875823, val images: 0.772581
[23:17:04.620831] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[23:17:05.590221] Epoch: [36]  [  0/345]  eta: 0:05:34  lr: 0.000056  loss: 0.1715 (0.1715)  time: 0.9683  data: 0.3686  max mem: 15821
[23:17:17.574374] Epoch: [36]  [ 20/345]  eta: 0:03:20  lr: 0.000056  loss: 0.1386 (0.1427)  time: 0.5991  data: 0.0001  max mem: 15821
[23:17:29.582986] Epoch: [36]  [ 40/345]  eta: 0:03:05  lr: 0.000055  loss: 0.1246 (0.1354)  time: 0.6004  data: 0.0001  max mem: 15821
[23:17:41.602927] Epoch: [36]  [ 60/345]  eta: 0:02:52  lr: 0.000055  loss: 0.1284 (0.1362)  time: 0.6010  data: 0.0001  max mem: 15821
[23:17:53.646827] Epoch: [36]  [ 80/345]  eta: 0:02:40  lr: 0.000054  loss: 0.1314 (0.1354)  time: 0.6021  data: 0.0001  max mem: 15821
[23:18:05.703124] Epoch: [36]  [100/345]  eta: 0:02:28  lr: 0.000054  loss: 0.1276 (0.1351)  time: 0.6028  data: 0.0001  max mem: 15821
[23:18:17.781536] Epoch: [36]  [120/345]  eta: 0:02:16  lr: 0.000054  loss: 0.1358 (0.1359)  time: 0.6039  data: 0.0001  max mem: 15821
[23:18:29.880304] Epoch: [36]  [140/345]  eta: 0:02:03  lr: 0.000053  loss: 0.1241 (0.1345)  time: 0.6049  data: 0.0001  max mem: 15821
[23:18:41.970178] Epoch: [36]  [160/345]  eta: 0:01:51  lr: 0.000053  loss: 0.1243 (0.1342)  time: 0.6044  data: 0.0001  max mem: 15821
[23:18:54.062880] Epoch: [36]  [180/345]  eta: 0:01:39  lr: 0.000053  loss: 0.1326 (0.1348)  time: 0.6046  data: 0.0001  max mem: 15821
[23:19:06.156566] Epoch: [36]  [200/345]  eta: 0:01:27  lr: 0.000052  loss: 0.1246 (0.1344)  time: 0.6046  data: 0.0001  max mem: 15821
[23:19:18.247897] Epoch: [36]  [220/345]  eta: 0:01:15  lr: 0.000052  loss: 0.1325 (0.1347)  time: 0.6045  data: 0.0001  max mem: 15821
[23:19:30.335377] Epoch: [36]  [240/345]  eta: 0:01:03  lr: 0.000051  loss: 0.1271 (0.1342)  time: 0.6043  data: 0.0001  max mem: 15821
[23:19:42.414236] Epoch: [36]  [260/345]  eta: 0:00:51  lr: 0.000051  loss: 0.1395 (0.1346)  time: 0.6039  data: 0.0001  max mem: 15821
[23:19:54.491863] Epoch: [36]  [280/345]  eta: 0:00:39  lr: 0.000051  loss: 0.1214 (0.1339)  time: 0.6038  data: 0.0001  max mem: 15821
[23:20:06.569686] Epoch: [36]  [300/345]  eta: 0:00:27  lr: 0.000050  loss: 0.1312 (0.1342)  time: 0.6038  data: 0.0001  max mem: 15821
[23:20:18.731609] Epoch: [36]  [320/345]  eta: 0:00:15  lr: 0.000050  loss: 0.1304 (0.1339)  time: 0.6080  data: 0.0001  max mem: 15821
[23:20:30.792331] Epoch: [36]  [340/345]  eta: 0:00:03  lr: 0.000050  loss: 0.1294 (0.1341)  time: 0.6030  data: 0.0001  max mem: 15821
[23:20:33.206510] Epoch: [36]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.1318 (0.1341)  time: 0.6029  data: 0.0001  max mem: 15821
[23:20:33.287579] Epoch: [36] Total time: 0:03:28 (0.6048 s / it)
[23:20:33.288045] Averaged stats: lr: 0.000050  loss: 0.1318 (0.1341)
[23:20:33.860920] Test:  [  0/345]  eta: 0:03:15  loss: 0.1591 (0.1591)  time: 0.5680  data: 0.4034  max mem: 15821
[23:20:35.527744] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1215 (0.1264)  time: 0.2031  data: 0.0368  max mem: 15821
[23:20:37.196523] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1215 (0.1275)  time: 0.1667  data: 0.0001  max mem: 15821
[23:20:38.869256] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1249 (0.1290)  time: 0.1670  data: 0.0001  max mem: 15821
[23:20:40.544580] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1262 (0.1280)  time: 0.1673  data: 0.0001  max mem: 15821
[23:20:42.224591] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1306 (0.1297)  time: 0.1677  data: 0.0001  max mem: 15821
[23:20:43.907385] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1284 (0.1301)  time: 0.1681  data: 0.0001  max mem: 15821
[23:20:45.592900] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1255 (0.1308)  time: 0.1684  data: 0.0001  max mem: 15821
[23:20:47.282966] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1327 (0.1316)  time: 0.1687  data: 0.0001  max mem: 15821
[23:20:48.977137] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1270 (0.1313)  time: 0.1692  data: 0.0001  max mem: 15821
[23:20:50.672744] Test:  [100/345]  eta: 0:00:42  loss: 0.1196 (0.1303)  time: 0.1694  data: 0.0001  max mem: 15821
[23:20:52.372053] Test:  [110/345]  eta: 0:00:40  loss: 0.1176 (0.1304)  time: 0.1697  data: 0.0001  max mem: 15821
[23:20:54.074924] Test:  [120/345]  eta: 0:00:38  loss: 0.1207 (0.1300)  time: 0.1700  data: 0.0001  max mem: 15821
[23:20:55.782395] Test:  [130/345]  eta: 0:00:36  loss: 0.1242 (0.1304)  time: 0.1704  data: 0.0001  max mem: 15821
[23:20:57.492412] Test:  [140/345]  eta: 0:00:35  loss: 0.1306 (0.1304)  time: 0.1708  data: 0.0001  max mem: 15821
[23:20:59.207247] Test:  [150/345]  eta: 0:00:33  loss: 0.1299 (0.1303)  time: 0.1712  data: 0.0001  max mem: 15821
[23:21:00.925019] Test:  [160/345]  eta: 0:00:31  loss: 0.1212 (0.1299)  time: 0.1716  data: 0.0001  max mem: 15821
[23:21:02.646651] Test:  [170/345]  eta: 0:00:30  loss: 0.1212 (0.1295)  time: 0.1719  data: 0.0001  max mem: 15821
[23:21:04.372369] Test:  [180/345]  eta: 0:00:28  loss: 0.1273 (0.1301)  time: 0.1723  data: 0.0001  max mem: 15821
[23:21:06.100844] Test:  [190/345]  eta: 0:00:26  loss: 0.1325 (0.1304)  time: 0.1726  data: 0.0001  max mem: 15821
[23:21:07.833765] Test:  [200/345]  eta: 0:00:24  loss: 0.1299 (0.1305)  time: 0.1730  data: 0.0001  max mem: 15821
[23:21:09.570014] Test:  [210/345]  eta: 0:00:23  loss: 0.1188 (0.1302)  time: 0.1733  data: 0.0001  max mem: 15821
[23:21:11.307081] Test:  [220/345]  eta: 0:00:21  loss: 0.1204 (0.1299)  time: 0.1736  data: 0.0001  max mem: 15821
[23:21:13.047750] Test:  [230/345]  eta: 0:00:19  loss: 0.1251 (0.1298)  time: 0.1738  data: 0.0001  max mem: 15821
[23:21:14.792271] Test:  [240/345]  eta: 0:00:18  loss: 0.1190 (0.1296)  time: 0.1742  data: 0.0001  max mem: 15821
[23:21:16.540144] Test:  [250/345]  eta: 0:00:16  loss: 0.1226 (0.1296)  time: 0.1746  data: 0.0001  max mem: 15821
[23:21:18.291897] Test:  [260/345]  eta: 0:00:14  loss: 0.1315 (0.1297)  time: 0.1749  data: 0.0001  max mem: 15821
[23:21:20.048557] Test:  [270/345]  eta: 0:00:12  loss: 0.1198 (0.1295)  time: 0.1754  data: 0.0001  max mem: 15821
[23:21:21.806790] Test:  [280/345]  eta: 0:00:11  loss: 0.1214 (0.1295)  time: 0.1757  data: 0.0001  max mem: 15821
[23:21:23.569784] Test:  [290/345]  eta: 0:00:09  loss: 0.1163 (0.1291)  time: 0.1760  data: 0.0001  max mem: 15821
[23:21:25.335759] Test:  [300/345]  eta: 0:00:07  loss: 0.1151 (0.1289)  time: 0.1764  data: 0.0001  max mem: 15821
[23:21:27.106059] Test:  [310/345]  eta: 0:00:06  loss: 0.1151 (0.1288)  time: 0.1768  data: 0.0001  max mem: 15821
[23:21:28.879133] Test:  [320/345]  eta: 0:00:04  loss: 0.1167 (0.1288)  time: 0.1771  data: 0.0001  max mem: 15821
[23:21:30.656262] Test:  [330/345]  eta: 0:00:02  loss: 0.1246 (0.1286)  time: 0.1774  data: 0.0001  max mem: 15821
[23:21:32.436547] Test:  [340/345]  eta: 0:00:00  loss: 0.1227 (0.1284)  time: 0.1778  data: 0.0001  max mem: 15821
[23:21:33.149624] Test:  [344/345]  eta: 0:00:00  loss: 0.1205 (0.1282)  time: 0.1780  data: 0.0001  max mem: 15821
[23:21:33.231552] Test: Total time: 0:00:59 (0.1737 s / it)
[23:21:43.706437] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4793 (0.4793)  time: 0.5203  data: 0.3580  max mem: 15821
[23:21:45.353271] Test:  [10/57]  eta: 0:00:09  loss: 0.4079 (0.4458)  time: 0.1969  data: 0.0326  max mem: 15821
[23:21:47.005132] Test:  [20/57]  eta: 0:00:06  loss: 0.4079 (0.4337)  time: 0.1648  data: 0.0001  max mem: 15821
[23:21:48.663116] Test:  [30/57]  eta: 0:00:04  loss: 0.2882 (0.3707)  time: 0.1654  data: 0.0001  max mem: 15821
[23:21:50.325948] Test:  [40/57]  eta: 0:00:02  loss: 0.2337 (0.3440)  time: 0.1660  data: 0.0001  max mem: 15821
[23:21:51.991575] Test:  [50/57]  eta: 0:00:01  loss: 0.2767 (0.3375)  time: 0.1664  data: 0.0001  max mem: 15821
[23:21:52.891006] Test:  [56/57]  eta: 0:00:00  loss: 0.3073 (0.3481)  time: 0.1614  data: 0.0001  max mem: 15821
[23:21:52.974891] Test: Total time: 0:00:09 (0.1717 s / it)
[23:21:54.744709] Dice score of the network on the train images: 0.867305, val images: 0.805275
[23:21:54.744932] saving best_dice_model_0 @ epoch 36
[23:21:55.831962] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[23:21:56.838492] Epoch: [37]  [  0/345]  eta: 0:05:46  lr: 0.000050  loss: 0.1354 (0.1354)  time: 1.0056  data: 0.4053  max mem: 15821
[23:22:08.811623] Epoch: [37]  [ 20/345]  eta: 0:03:20  lr: 0.000049  loss: 0.1355 (0.1429)  time: 0.5986  data: 0.0001  max mem: 15821
[23:22:20.820132] Epoch: [37]  [ 40/345]  eta: 0:03:05  lr: 0.000049  loss: 0.1299 (0.1379)  time: 0.6004  data: 0.0001  max mem: 15821
[23:22:32.845329] Epoch: [37]  [ 60/345]  eta: 0:02:52  lr: 0.000048  loss: 0.1260 (0.1351)  time: 0.6012  data: 0.0001  max mem: 15821
[23:22:44.864764] Epoch: [37]  [ 80/345]  eta: 0:02:40  lr: 0.000048  loss: 0.1328 (0.1343)  time: 0.6009  data: 0.0001  max mem: 15821
[23:22:56.906830] Epoch: [37]  [100/345]  eta: 0:02:28  lr: 0.000048  loss: 0.1309 (0.1330)  time: 0.6021  data: 0.0001  max mem: 15821
[23:23:08.972765] Epoch: [37]  [120/345]  eta: 0:02:15  lr: 0.000047  loss: 0.1157 (0.1311)  time: 0.6033  data: 0.0001  max mem: 15821
[23:23:21.055330] Epoch: [37]  [140/345]  eta: 0:02:03  lr: 0.000047  loss: 0.1175 (0.1303)  time: 0.6041  data: 0.0001  max mem: 15821
[23:23:33.149506] Epoch: [37]  [160/345]  eta: 0:01:51  lr: 0.000047  loss: 0.1397 (0.1322)  time: 0.6047  data: 0.0001  max mem: 15821
[23:23:45.238847] Epoch: [37]  [180/345]  eta: 0:01:39  lr: 0.000046  loss: 0.1217 (0.1313)  time: 0.6044  data: 0.0001  max mem: 15821
[23:23:57.328866] Epoch: [37]  [200/345]  eta: 0:01:27  lr: 0.000046  loss: 0.1359 (0.1313)  time: 0.6045  data: 0.0001  max mem: 15821
[23:24:09.398967] Epoch: [37]  [220/345]  eta: 0:01:15  lr: 0.000045  loss: 0.1344 (0.1315)  time: 0.6035  data: 0.0001  max mem: 15821
[23:24:21.466110] Epoch: [37]  [240/345]  eta: 0:01:03  lr: 0.000045  loss: 0.1249 (0.1311)  time: 0.6033  data: 0.0001  max mem: 15821
[23:24:33.528894] Epoch: [37]  [260/345]  eta: 0:00:51  lr: 0.000045  loss: 0.1221 (0.1309)  time: 0.6031  data: 0.0001  max mem: 15821
[23:24:45.589270] Epoch: [37]  [280/345]  eta: 0:00:39  lr: 0.000044  loss: 0.1265 (0.1308)  time: 0.6030  data: 0.0001  max mem: 15821
[23:24:57.658692] Epoch: [37]  [300/345]  eta: 0:00:27  lr: 0.000044  loss: 0.1342 (0.1313)  time: 0.6034  data: 0.0001  max mem: 15821
[23:25:09.725478] Epoch: [37]  [320/345]  eta: 0:00:15  lr: 0.000044  loss: 0.1207 (0.1309)  time: 0.6033  data: 0.0001  max mem: 15821
[23:25:21.777316] Epoch: [37]  [340/345]  eta: 0:00:03  lr: 0.000043  loss: 0.1355 (0.1311)  time: 0.6025  data: 0.0001  max mem: 15821
[23:25:24.184120] Epoch: [37]  [344/345]  eta: 0:00:00  lr: 0.000043  loss: 0.1395 (0.1312)  time: 0.6023  data: 0.0001  max mem: 15821
[23:25:24.261700] Epoch: [37] Total time: 0:03:28 (0.6041 s / it)
[23:25:24.261942] Averaged stats: lr: 0.000043  loss: 0.1395 (0.1312)
[23:25:24.877143] Test:  [  0/345]  eta: 0:03:30  loss: 0.1119 (0.1119)  time: 0.6111  data: 0.4466  max mem: 15821
[23:25:26.544957] Test:  [ 10/345]  eta: 0:01:09  loss: 0.1179 (0.1187)  time: 0.2071  data: 0.0407  max mem: 15821
[23:25:28.214090] Test:  [ 20/345]  eta: 0:01:01  loss: 0.1191 (0.1237)  time: 0.1668  data: 0.0001  max mem: 15821
[23:25:29.887403] Test:  [ 30/345]  eta: 0:00:57  loss: 0.1276 (0.1266)  time: 0.1671  data: 0.0001  max mem: 15821
[23:25:31.563402] Test:  [ 40/345]  eta: 0:00:54  loss: 0.1315 (0.1278)  time: 0.1674  data: 0.0001  max mem: 15821
[23:25:33.241270] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1232 (0.1262)  time: 0.1676  data: 0.0001  max mem: 15821
[23:25:34.923789] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1129 (0.1256)  time: 0.1680  data: 0.0001  max mem: 15821
[23:25:36.609991] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1155 (0.1255)  time: 0.1684  data: 0.0001  max mem: 15821
[23:25:38.299313] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1166 (0.1250)  time: 0.1687  data: 0.0001  max mem: 15821
[23:25:39.992917] Test:  [ 90/345]  eta: 0:00:44  loss: 0.1236 (0.1255)  time: 0.1691  data: 0.0001  max mem: 15821
[23:25:41.690446] Test:  [100/345]  eta: 0:00:42  loss: 0.1235 (0.1258)  time: 0.1695  data: 0.0001  max mem: 15821
[23:25:43.390347] Test:  [110/345]  eta: 0:00:40  loss: 0.1172 (0.1255)  time: 0.1698  data: 0.0001  max mem: 15821
[23:25:45.095052] Test:  [120/345]  eta: 0:00:38  loss: 0.1242 (0.1261)  time: 0.1702  data: 0.0001  max mem: 15821
[23:25:46.800848] Test:  [130/345]  eta: 0:00:36  loss: 0.1239 (0.1260)  time: 0.1705  data: 0.0001  max mem: 15821
[23:25:48.512537] Test:  [140/345]  eta: 0:00:35  loss: 0.1183 (0.1256)  time: 0.1708  data: 0.0001  max mem: 15821
[23:25:50.226710] Test:  [150/345]  eta: 0:00:33  loss: 0.1247 (0.1259)  time: 0.1712  data: 0.0001  max mem: 15821
[23:25:51.943972] Test:  [160/345]  eta: 0:00:31  loss: 0.1179 (0.1252)  time: 0.1715  data: 0.0001  max mem: 15821
[23:25:53.665737] Test:  [170/345]  eta: 0:00:30  loss: 0.1058 (0.1248)  time: 0.1719  data: 0.0001  max mem: 15821
[23:25:55.391386] Test:  [180/345]  eta: 0:00:28  loss: 0.1174 (0.1243)  time: 0.1723  data: 0.0001  max mem: 15821
[23:25:57.119533] Test:  [190/345]  eta: 0:00:26  loss: 0.1189 (0.1240)  time: 0.1726  data: 0.0001  max mem: 15821
[23:25:58.850910] Test:  [200/345]  eta: 0:00:24  loss: 0.1171 (0.1236)  time: 0.1729  data: 0.0001  max mem: 15821
[23:26:00.585915] Test:  [210/345]  eta: 0:00:23  loss: 0.1096 (0.1237)  time: 0.1732  data: 0.0001  max mem: 15821
[23:26:02.323403] Test:  [220/345]  eta: 0:00:21  loss: 0.1281 (0.1240)  time: 0.1736  data: 0.0001  max mem: 15821
[23:26:04.064564] Test:  [230/345]  eta: 0:00:19  loss: 0.1281 (0.1242)  time: 0.1739  data: 0.0001  max mem: 15821
[23:26:05.809061] Test:  [240/345]  eta: 0:00:18  loss: 0.1171 (0.1238)  time: 0.1742  data: 0.0001  max mem: 15821
[23:26:07.557249] Test:  [250/345]  eta: 0:00:16  loss: 0.1150 (0.1236)  time: 0.1746  data: 0.0001  max mem: 15821
[23:26:09.310112] Test:  [260/345]  eta: 0:00:14  loss: 0.1126 (0.1232)  time: 0.1750  data: 0.0001  max mem: 15821
[23:26:11.065473] Test:  [270/345]  eta: 0:00:12  loss: 0.1170 (0.1234)  time: 0.1753  data: 0.0001  max mem: 15821
[23:26:12.825741] Test:  [280/345]  eta: 0:00:11  loss: 0.1170 (0.1233)  time: 0.1757  data: 0.0001  max mem: 15821
[23:26:14.587117] Test:  [290/345]  eta: 0:00:09  loss: 0.1169 (0.1235)  time: 0.1760  data: 0.0001  max mem: 15821
[23:26:16.351167] Test:  [300/345]  eta: 0:00:07  loss: 0.1242 (0.1236)  time: 0.1762  data: 0.0001  max mem: 15821
[23:26:18.121362] Test:  [310/345]  eta: 0:00:06  loss: 0.1257 (0.1236)  time: 0.1766  data: 0.0001  max mem: 15821
[23:26:19.894253] Test:  [320/345]  eta: 0:00:04  loss: 0.1176 (0.1237)  time: 0.1771  data: 0.0001  max mem: 15821
[23:26:21.671603] Test:  [330/345]  eta: 0:00:02  loss: 0.1254 (0.1239)  time: 0.1774  data: 0.0001  max mem: 15821
[23:26:23.452002] Test:  [340/345]  eta: 0:00:00  loss: 0.1286 (0.1239)  time: 0.1778  data: 0.0001  max mem: 15821
[23:26:24.165200] Test:  [344/345]  eta: 0:00:00  loss: 0.1257 (0.1239)  time: 0.1779  data: 0.0001  max mem: 15821
[23:26:24.239140] Test: Total time: 0:00:59 (0.1738 s / it)
[23:26:34.739327] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4788 (0.4788)  time: 0.5306  data: 0.3685  max mem: 15821
[23:26:36.384888] Test:  [10/57]  eta: 0:00:09  loss: 0.4152 (0.4474)  time: 0.1977  data: 0.0336  max mem: 15821
[23:26:38.036167] Test:  [20/57]  eta: 0:00:06  loss: 0.4152 (0.4368)  time: 0.1648  data: 0.0001  max mem: 15821
[23:26:39.693083] Test:  [30/57]  eta: 0:00:04  loss: 0.2802 (0.3736)  time: 0.1653  data: 0.0001  max mem: 15821
[23:26:41.353919] Test:  [40/57]  eta: 0:00:02  loss: 0.2375 (0.3475)  time: 0.1658  data: 0.0001  max mem: 15821
[23:26:43.018000] Test:  [50/57]  eta: 0:00:01  loss: 0.2779 (0.3427)  time: 0.1662  data: 0.0001  max mem: 15821
[23:26:43.916787] Test:  [56/57]  eta: 0:00:00  loss: 0.3248 (0.3556)  time: 0.1613  data: 0.0001  max mem: 15821
[23:26:43.996718] Test: Total time: 0:00:09 (0.1717 s / it)
[23:26:45.758488] Dice score of the network on the train images: 0.875845, val images: 0.796510
[23:26:45.762629] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[23:26:46.776119] Epoch: [38]  [  0/345]  eta: 0:05:49  lr: 0.000043  loss: 0.1386 (0.1386)  time: 1.0126  data: 0.4124  max mem: 15821
[23:26:58.765395] Epoch: [38]  [ 20/345]  eta: 0:03:21  lr: 0.000043  loss: 0.1260 (0.1344)  time: 0.5994  data: 0.0001  max mem: 15821
[23:27:10.767111] Epoch: [38]  [ 40/345]  eta: 0:03:05  lr: 0.000042  loss: 0.1206 (0.1296)  time: 0.6000  data: 0.0001  max mem: 15821
[23:27:22.791361] Epoch: [38]  [ 60/345]  eta: 0:02:52  lr: 0.000042  loss: 0.1345 (0.1324)  time: 0.6012  data: 0.0001  max mem: 15821
[23:27:34.832952] Epoch: [38]  [ 80/345]  eta: 0:02:40  lr: 0.000042  loss: 0.1309 (0.1318)  time: 0.6020  data: 0.0001  max mem: 15821
[23:27:46.889398] Epoch: [38]  [100/345]  eta: 0:02:28  lr: 0.000041  loss: 0.1216 (0.1304)  time: 0.6028  data: 0.0001  max mem: 15821
[23:27:58.976946] Epoch: [38]  [120/345]  eta: 0:02:16  lr: 0.000041  loss: 0.1241 (0.1303)  time: 0.6043  data: 0.0001  max mem: 15821
[23:28:11.077435] Epoch: [38]  [140/345]  eta: 0:02:04  lr: 0.000041  loss: 0.1257 (0.1296)  time: 0.6050  data: 0.0001  max mem: 15821

[23:28:23.167809] Epoch: [38]  [160/345]  eta: 0:01:51  lr: 0.000040  loss: 0.1203 (0.1292)  time: 0.6045  data: 0.0001  max mem: 15821
[23:28:35.270929] Epoch: [38]  [180/345]  eta: 0:01:39  lr: 0.000040  loss: 0.1252 (0.1289)  time: 0.6051  data: 0.0001  max mem: 15821
[23:28:47.369147] Epoch: [38]  [200/345]  eta: 0:01:27  lr: 0.000040  loss: 0.1204 (0.1288)  time: 0.6049  data: 0.0001  max mem: 15821
[23:28:59.465941] Epoch: [38]  [220/345]  eta: 0:01:15  lr: 0.000039  loss: 0.1184 (0.1285)  time: 0.6048  data: 0.0001  max mem: 15821
[23:29:11.532610] Epoch: [38]  [240/345]  eta: 0:01:03  lr: 0.000039  loss: 0.1254 (0.1282)  time: 0.6033  data: 0.0001  max mem: 15821
[23:29:23.600421] Epoch: [38]  [260/345]  eta: 0:00:51  lr: 0.000039  loss: 0.1234 (0.1282)  time: 0.6034  data: 0.0001  max mem: 15821
[23:29:35.685308] Epoch: [38]  [280/345]  eta: 0:00:39  lr: 0.000038  loss: 0.1190 (0.1275)  time: 0.6042  data: 0.0001  max mem: 15821
[23:29:47.765303] Epoch: [38]  [300/345]  eta: 0:00:27  lr: 0.000038  loss: 0.1277 (0.1279)  time: 0.6040  data: 0.0001  max mem: 15821
[23:29:59.851426] Epoch: [38]  [320/345]  eta: 0:00:15  lr: 0.000038  loss: 0.1318 (0.1280)  time: 0.6043  data: 0.0001  max mem: 15821
[23:30:11.916844] Epoch: [38]  [340/345]  eta: 0:00:03  lr: 0.000037  loss: 0.1281 (0.1283)  time: 0.6032  data: 0.0001  max mem: 15821
[23:30:14.326591] Epoch: [38]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 0.1290 (0.1284)  time: 0.6029  data: 0.0001  max mem: 15821
[23:30:14.392253] Epoch: [38] Total time: 0:03:28 (0.6047 s / it)
[23:30:14.392950] Averaged stats: lr: 0.000037  loss: 0.1290 (0.1284)
[23:30:14.989029] Test:  [  0/345]  eta: 0:03:23  loss: 0.1770 (0.1770)  time: 0.5906  data: 0.4260  max mem: 15821
[23:30:16.655805] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1196 (0.1256)  time: 0.2051  data: 0.0388  max mem: 15821
[23:30:18.324100] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1185 (0.1214)  time: 0.1667  data: 0.0001  max mem: 15821
[23:30:19.998782] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1104 (0.1187)  time: 0.1671  data: 0.0001  max mem: 15821
[23:30:21.674594] Test:  [ 40/345]  eta: 0:00:54  loss: 0.1143 (0.1191)  time: 0.1675  data: 0.0001  max mem: 15821
[23:30:23.353913] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1223 (0.1201)  time: 0.1677  data: 0.0001  max mem: 15821
[23:30:25.036700] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1233 (0.1217)  time: 0.1680  data: 0.0001  max mem: 15821
[23:30:26.723429] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1176 (0.1207)  time: 0.1684  data: 0.0001  max mem: 15821
[23:30:28.413026] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1125 (0.1203)  time: 0.1687  data: 0.0001  max mem: 15821
[23:30:30.107027] Test:  [ 90/345]  eta: 0:00:44  loss: 0.1143 (0.1202)  time: 0.1691  data: 0.0001  max mem: 15821
[23:30:31.804714] Test:  [100/345]  eta: 0:00:42  loss: 0.1152 (0.1203)  time: 0.1695  data: 0.0001  max mem: 15821
[23:30:33.504525] Test:  [110/345]  eta: 0:00:40  loss: 0.1159 (0.1206)  time: 0.1698  data: 0.0001  max mem: 15821
[23:30:35.208372] Test:  [120/345]  eta: 0:00:38  loss: 0.1186 (0.1203)  time: 0.1701  data: 0.0001  max mem: 15821
[23:30:36.915043] Test:  [130/345]  eta: 0:00:36  loss: 0.1169 (0.1203)  time: 0.1704  data: 0.0001  max mem: 15821
[23:30:38.625465] Test:  [140/345]  eta: 0:00:35  loss: 0.1203 (0.1204)  time: 0.1707  data: 0.0001  max mem: 15821
[23:30:40.338487] Test:  [150/345]  eta: 0:00:33  loss: 0.1195 (0.1204)  time: 0.1711  data: 0.0001  max mem: 15821
[23:30:42.056076] Test:  [160/345]  eta: 0:00:31  loss: 0.1175 (0.1202)  time: 0.1715  data: 0.0001  max mem: 15821
[23:30:43.776698] Test:  [170/345]  eta: 0:00:30  loss: 0.1146 (0.1197)  time: 0.1718  data: 0.0001  max mem: 15821
[23:30:45.501003] Test:  [180/345]  eta: 0:00:28  loss: 0.1096 (0.1195)  time: 0.1722  data: 0.0001  max mem: 15821
[23:30:47.228594] Test:  [190/345]  eta: 0:00:26  loss: 0.1160 (0.1202)  time: 0.1725  data: 0.0001  max mem: 15821
[23:30:48.958522] Test:  [200/345]  eta: 0:00:24  loss: 0.1227 (0.1205)  time: 0.1728  data: 0.0001  max mem: 15821
[23:30:50.693048] Test:  [210/345]  eta: 0:00:23  loss: 0.1223 (0.1205)  time: 0.1732  data: 0.0001  max mem: 15821
[23:30:52.430347] Test:  [220/345]  eta: 0:00:21  loss: 0.1182 (0.1205)  time: 0.1735  data: 0.0001  max mem: 15821
[23:30:54.172018] Test:  [230/345]  eta: 0:00:19  loss: 0.1178 (0.1208)  time: 0.1739  data: 0.0001  max mem: 15821
[23:30:55.915729] Test:  [240/345]  eta: 0:00:18  loss: 0.1138 (0.1207)  time: 0.1742  data: 0.0001  max mem: 15821
[23:30:57.663423] Test:  [250/345]  eta: 0:00:16  loss: 0.1118 (0.1207)  time: 0.1745  data: 0.0001  max mem: 15821
[23:30:59.415439] Test:  [260/345]  eta: 0:00:14  loss: 0.1225 (0.1212)  time: 0.1749  data: 0.0001  max mem: 15821
[23:31:01.169524] Test:  [270/345]  eta: 0:00:12  loss: 0.1251 (0.1213)  time: 0.1752  data: 0.0001  max mem: 15821
[23:31:02.928199] Test:  [280/345]  eta: 0:00:11  loss: 0.1194 (0.1211)  time: 0.1756  data: 0.0001  max mem: 15821
[23:31:04.690106] Test:  [290/345]  eta: 0:00:09  loss: 0.1157 (0.1210)  time: 0.1760  data: 0.0001  max mem: 15821
[23:31:06.454282] Test:  [300/345]  eta: 0:00:07  loss: 0.1163 (0.1210)  time: 0.1762  data: 0.0001  max mem: 15821
[23:31:08.222927] Test:  [310/345]  eta: 0:00:06  loss: 0.1264 (0.1212)  time: 0.1766  data: 0.0001  max mem: 15821
[23:31:09.996030] Test:  [320/345]  eta: 0:00:04  loss: 0.1251 (0.1214)  time: 0.1770  data: 0.0001  max mem: 15821
[23:31:11.772729] Test:  [330/345]  eta: 0:00:02  loss: 0.1218 (0.1213)  time: 0.1774  data: 0.0001  max mem: 15821
[23:31:13.554969] Test:  [340/345]  eta: 0:00:00  loss: 0.1212 (0.1215)  time: 0.1779  data: 0.0001  max mem: 15821
[23:31:14.268073] Test:  [344/345]  eta: 0:00:00  loss: 0.1211 (0.1215)  time: 0.1780  data: 0.0001  max mem: 15821
[23:31:14.331517] Test: Total time: 0:00:59 (0.1737 s / it)
[23:31:24.821293] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4865 (0.4865)  time: 0.5378  data: 0.3756  max mem: 15821
[23:31:26.466476] Test:  [10/57]  eta: 0:00:09  loss: 0.4391 (0.4625)  time: 0.1984  data: 0.0343  max mem: 15821
[23:31:28.118270] Test:  [20/57]  eta: 0:00:06  loss: 0.4244 (0.4493)  time: 0.1648  data: 0.0001  max mem: 15821
[23:31:29.774922] Test:  [30/57]  eta: 0:00:04  loss: 0.2964 (0.3838)  time: 0.1654  data: 0.0001  max mem: 15821
[23:31:31.436052] Test:  [40/57]  eta: 0:00:02  loss: 0.2425 (0.3578)  time: 0.1658  data: 0.0001  max mem: 15821
[23:31:33.101286] Test:  [50/57]  eta: 0:00:01  loss: 0.2966 (0.3529)  time: 0.1663  data: 0.0001  max mem: 15821
[23:31:34.000312] Test:  [56/57]  eta: 0:00:00  loss: 0.3215 (0.3645)  time: 0.1614  data: 0.0000  max mem: 15821
[23:31:34.060090] Test: Total time: 0:00:09 (0.1715 s / it)
[23:31:35.839640] Dice score of the network on the train images: 0.879184, val images: 0.795054
[23:31:35.843717] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[23:31:36.894461] Epoch: [39]  [  0/345]  eta: 0:06:02  lr: 0.000037  loss: 0.1055 (0.1055)  time: 1.0498  data: 0.4485  max mem: 15821
[23:31:48.886565] Epoch: [39]  [ 20/345]  eta: 0:03:21  lr: 0.000037  loss: 0.1223 (0.1263)  time: 0.5995  data: 0.0001  max mem: 15821
[23:32:01.012936] Epoch: [39]  [ 40/345]  eta: 0:03:07  lr: 0.000036  loss: 0.1290 (0.1303)  time: 0.6063  data: 0.0001  max mem: 15821
[23:32:13.027195] Epoch: [39]  [ 60/345]  eta: 0:02:53  lr: 0.000036  loss: 0.1210 (0.1297)  time: 0.6007  data: 0.0001  max mem: 15821
[23:32:25.071349] Epoch: [39]  [ 80/345]  eta: 0:02:41  lr: 0.000036  loss: 0.1184 (0.1276)  time: 0.6022  data: 0.0001  max mem: 15821
[23:32:37.112753] Epoch: [39]  [100/345]  eta: 0:02:28  lr: 0.000035  loss: 0.1268 (0.1273)  time: 0.6020  data: 0.0001  max mem: 15821
[23:32:49.183606] Epoch: [39]  [120/345]  eta: 0:02:16  lr: 0.000035  loss: 0.1211 (0.1273)  time: 0.6035  data: 0.0001  max mem: 15821
[23:33:01.268705] Epoch: [39]  [140/345]  eta: 0:02:04  lr: 0.000035  loss: 0.1200 (0.1265)  time: 0.6042  data: 0.0001  max mem: 15821
[23:33:13.370549] Epoch: [39]  [160/345]  eta: 0:01:52  lr: 0.000034  loss: 0.1159 (0.1255)  time: 0.6050  data: 0.0001  max mem: 15821
[23:33:25.448339] Epoch: [39]  [180/345]  eta: 0:01:39  lr: 0.000034  loss: 0.1183 (0.1254)  time: 0.6039  data: 0.0001  max mem: 15821
[23:33:37.522834] Epoch: [39]  [200/345]  eta: 0:01:27  lr: 0.000034  loss: 0.1205 (0.1252)  time: 0.6037  data: 0.0001  max mem: 15821
[23:33:49.597055] Epoch: [39]  [220/345]  eta: 0:01:15  lr: 0.000033  loss: 0.1185 (0.1248)  time: 0.6037  data: 0.0001  max mem: 15821
[23:34:01.670443] Epoch: [39]  [240/345]  eta: 0:01:03  lr: 0.000033  loss: 0.1160 (0.1245)  time: 0.6036  data: 0.0001  max mem: 15821
[23:34:13.736516] Epoch: [39]  [260/345]  eta: 0:00:51  lr: 0.000033  loss: 0.1172 (0.1244)  time: 0.6033  data: 0.0001  max mem: 15821
[23:34:25.888016] Epoch: [39]  [280/345]  eta: 0:00:39  lr: 0.000032  loss: 0.1263 (0.1251)  time: 0.6075  data: 0.0001  max mem: 15821
[23:34:37.962750] Epoch: [39]  [300/345]  eta: 0:00:27  lr: 0.000032  loss: 0.1247 (0.1256)  time: 0.6036  data: 0.0001  max mem: 15821
[23:34:50.018429] Epoch: [39]  [320/345]  eta: 0:00:15  lr: 0.000032  loss: 0.1241 (0.1256)  time: 0.6027  data: 0.0001  max mem: 15821
[23:35:02.070748] Epoch: [39]  [340/345]  eta: 0:00:03  lr: 0.000031  loss: 0.1219 (0.1255)  time: 0.6026  data: 0.0001  max mem: 15821
[23:35:04.489664] Epoch: [39]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 0.1220 (0.1255)  time: 0.6029  data: 0.0001  max mem: 15821
[23:35:04.559865] Epoch: [39] Total time: 0:03:28 (0.6050 s / it)
[23:35:04.560180] Averaged stats: lr: 0.000031  loss: 0.1220 (0.1255)
[23:35:05.122018] Test:  [  0/345]  eta: 0:03:11  loss: 0.1381 (0.1381)  time: 0.5560  data: 0.3916  max mem: 15821
[23:35:06.787179] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1150 (0.1206)  time: 0.2018  data: 0.0357  max mem: 15821
[23:35:08.455533] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1158 (0.1234)  time: 0.1666  data: 0.0001  max mem: 15821
[23:35:10.128155] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1195 (0.1235)  time: 0.1670  data: 0.0001  max mem: 15821
[23:35:11.803461] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1111 (0.1205)  time: 0.1673  data: 0.0001  max mem: 15821
[23:35:13.483003] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1082 (0.1189)  time: 0.1677  data: 0.0001  max mem: 15821
[23:35:15.165494] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1099 (0.1186)  time: 0.1680  data: 0.0001  max mem: 15821
[23:35:16.851181] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1144 (0.1184)  time: 0.1683  data: 0.0001  max mem: 15821
[23:35:18.540533] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1100 (0.1179)  time: 0.1687  data: 0.0001  max mem: 15821
[23:35:20.232316] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1098 (0.1167)  time: 0.1690  data: 0.0001  max mem: 15821
[23:35:21.928212] Test:  [100/345]  eta: 0:00:42  loss: 0.1124 (0.1164)  time: 0.1693  data: 0.0001  max mem: 15821
[23:35:23.627513] Test:  [110/345]  eta: 0:00:40  loss: 0.1124 (0.1166)  time: 0.1697  data: 0.0001  max mem: 15821
[23:35:25.329308] Test:  [120/345]  eta: 0:00:38  loss: 0.1192 (0.1171)  time: 0.1700  data: 0.0001  max mem: 15821
[23:35:27.035709] Test:  [130/345]  eta: 0:00:36  loss: 0.1178 (0.1173)  time: 0.1703  data: 0.0001  max mem: 15821
[23:35:28.744809] Test:  [140/345]  eta: 0:00:35  loss: 0.1192 (0.1181)  time: 0.1707  data: 0.0001  max mem: 15821
[23:35:30.458423] Test:  [150/345]  eta: 0:00:33  loss: 0.1192 (0.1182)  time: 0.1711  data: 0.0001  max mem: 15821
[23:35:32.175953] Test:  [160/345]  eta: 0:00:31  loss: 0.1214 (0.1188)  time: 0.1715  data: 0.0001  max mem: 15821
[23:35:33.896476] Test:  [170/345]  eta: 0:00:30  loss: 0.1214 (0.1188)  time: 0.1718  data: 0.0001  max mem: 15821
[23:35:35.620288] Test:  [180/345]  eta: 0:00:28  loss: 0.1178 (0.1192)  time: 0.1722  data: 0.0001  max mem: 15821
[23:35:37.347596] Test:  [190/345]  eta: 0:00:26  loss: 0.1184 (0.1194)  time: 0.1725  data: 0.0001  max mem: 15821
[23:35:39.078017] Test:  [200/345]  eta: 0:00:24  loss: 0.1173 (0.1193)  time: 0.1728  data: 0.0001  max mem: 15821
[23:35:40.811236] Test:  [210/345]  eta: 0:00:23  loss: 0.1173 (0.1196)  time: 0.1731  data: 0.0001  max mem: 15821
[23:35:42.547778] Test:  [220/345]  eta: 0:00:21  loss: 0.1169 (0.1194)  time: 0.1734  data: 0.0001  max mem: 15821
[23:35:44.287899] Test:  [230/345]  eta: 0:00:19  loss: 0.1141 (0.1192)  time: 0.1738  data: 0.0001  max mem: 15821
[23:35:46.031795] Test:  [240/345]  eta: 0:00:18  loss: 0.1109 (0.1188)  time: 0.1741  data: 0.0001  max mem: 15821
[23:35:47.779524] Test:  [250/345]  eta: 0:00:16  loss: 0.1084 (0.1186)  time: 0.1745  data: 0.0001  max mem: 15821
[23:35:49.529904] Test:  [260/345]  eta: 0:00:14  loss: 0.1094 (0.1189)  time: 0.1748  data: 0.0001  max mem: 15821
[23:35:51.284085] Test:  [270/345]  eta: 0:00:12  loss: 0.1208 (0.1190)  time: 0.1752  data: 0.0001  max mem: 15821
[23:35:53.042979] Test:  [280/345]  eta: 0:00:11  loss: 0.1154 (0.1188)  time: 0.1756  data: 0.0001  max mem: 15821
[23:35:54.804515] Test:  [290/345]  eta: 0:00:09  loss: 0.1096 (0.1186)  time: 0.1760  data: 0.0001  max mem: 15821
[23:35:56.569896] Test:  [300/345]  eta: 0:00:07  loss: 0.1132 (0.1185)  time: 0.1763  data: 0.0001  max mem: 15821
[23:35:58.339981] Test:  [310/345]  eta: 0:00:06  loss: 0.1096 (0.1182)  time: 0.1767  data: 0.0001  max mem: 15821
[23:36:00.112637] Test:  [320/345]  eta: 0:00:04  loss: 0.1077 (0.1180)  time: 0.1771  data: 0.0001  max mem: 15821
[23:36:01.888196] Test:  [330/345]  eta: 0:00:02  loss: 0.1124 (0.1180)  time: 0.1773  data: 0.0001  max mem: 15821
[23:36:03.666803] Test:  [340/345]  eta: 0:00:00  loss: 0.1137 (0.1177)  time: 0.1777  data: 0.0001  max mem: 15821
[23:36:04.380408] Test:  [344/345]  eta: 0:00:00  loss: 0.1148 (0.1179)  time: 0.1778  data: 0.0001  max mem: 15821
[23:36:04.447215] Test: Total time: 0:00:59 (0.1736 s / it)
[23:36:14.966350] Test:  [ 0/57]  eta: 0:00:29  loss: 0.4892 (0.4892)  time: 0.5241  data: 0.3618  max mem: 15821
[23:36:16.611824] Test:  [10/57]  eta: 0:00:09  loss: 0.4292 (0.4597)  time: 0.1971  data: 0.0330  max mem: 15821
[23:36:18.264859] Test:  [20/57]  eta: 0:00:06  loss: 0.4161 (0.4464)  time: 0.1648  data: 0.0001  max mem: 15821
[23:36:19.919772] Test:  [30/57]  eta: 0:00:04  loss: 0.2833 (0.3802)  time: 0.1653  data: 0.0001  max mem: 15821
[23:36:21.581254] Test:  [40/57]  eta: 0:00:02  loss: 0.2278 (0.3519)  time: 0.1658  data: 0.0001  max mem: 15821
[23:36:23.245985] Test:  [50/57]  eta: 0:00:01  loss: 0.2794 (0.3467)  time: 0.1662  data: 0.0001  max mem: 15821
[23:36:24.145081] Test:  [56/57]  eta: 0:00:00  loss: 0.3186 (0.3609)  time: 0.1614  data: 0.0001  max mem: 15821
[23:36:24.218144] Test: Total time: 0:00:09 (0.1715 s / it)
[23:36:25.976417] Dice score of the network on the train images: 0.879099, val images: 0.799120
[23:36:25.981031] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[23:36:26.956448] Epoch: [40]  [  0/345]  eta: 0:05:36  lr: 0.000031  loss: 0.1048 (0.1048)  time: 0.9743  data: 0.3727  max mem: 15821
[23:36:38.944088] Epoch: [40]  [ 20/345]  eta: 0:03:20  lr: 0.000031  loss: 0.1180 (0.1204)  time: 0.5993  data: 0.0001  max mem: 15821
[23:36:50.955537] Epoch: [40]  [ 40/345]  eta: 0:03:05  lr: 0.000031  loss: 0.1174 (0.1206)  time: 0.6005  data: 0.0001  max mem: 15821
[23:37:02.983704] Epoch: [40]  [ 60/345]  eta: 0:02:52  lr: 0.000030  loss: 0.1203 (0.1225)  time: 0.6014  data: 0.0001  max mem: 15821
[23:37:15.026842] Epoch: [40]  [ 80/345]  eta: 0:02:40  lr: 0.000030  loss: 0.1144 (0.1217)  time: 0.6021  data: 0.0001  max mem: 15821
[23:37:27.072118] Epoch: [40]  [100/345]  eta: 0:02:28  lr: 0.000030  loss: 0.1200 (0.1221)  time: 0.6022  data: 0.0001  max mem: 15821
[23:37:39.150148] Epoch: [40]  [120/345]  eta: 0:02:16  lr: 0.000029  loss: 0.1121 (0.1216)  time: 0.6039  data: 0.0001  max mem: 15821
[23:37:51.228152] Epoch: [40]  [140/345]  eta: 0:02:03  lr: 0.000029  loss: 0.1251 (0.1220)  time: 0.6039  data: 0.0001  max mem: 15821
[23:38:03.311778] Epoch: [40]  [160/345]  eta: 0:01:51  lr: 0.000029  loss: 0.1235 (0.1225)  time: 0.6041  data: 0.0001  max mem: 15821
[23:38:15.393166] Epoch: [40]  [180/345]  eta: 0:01:39  lr: 0.000028  loss: 0.1206 (0.1226)  time: 0.6040  data: 0.0001  max mem: 15821
[23:38:27.467254] Epoch: [40]  [200/345]  eta: 0:01:27  lr: 0.000028  loss: 0.1167 (0.1229)  time: 0.6037  data: 0.0001  max mem: 15821
[23:38:39.539471] Epoch: [40]  [220/345]  eta: 0:01:15  lr: 0.000028  loss: 0.1214 (0.1232)  time: 0.6036  data: 0.0001  max mem: 15821
[23:38:51.605038] Epoch: [40]  [240/345]  eta: 0:01:03  lr: 0.000027  loss: 0.1206 (0.1232)  time: 0.6032  data: 0.0001  max mem: 15821
[23:39:03.664535] Epoch: [40]  [260/345]  eta: 0:00:51  lr: 0.000027  loss: 0.1206 (0.1229)  time: 0.6029  data: 0.0001  max mem: 15821
[23:39:15.727539] Epoch: [40]  [280/345]  eta: 0:00:39  lr: 0.000027  loss: 0.1238 (0.1230)  time: 0.6031  data: 0.0001  max mem: 15821
[23:39:27.783426] Epoch: [40]  [300/345]  eta: 0:00:27  lr: 0.000026  loss: 0.1193 (0.1230)  time: 0.6027  data: 0.0001  max mem: 15821
[23:39:39.846634] Epoch: [40]  [320/345]  eta: 0:00:15  lr: 0.000026  loss: 0.1274 (0.1233)  time: 0.6031  data: 0.0001  max mem: 15821
[23:39:51.900205] Epoch: [40]  [340/345]  eta: 0:00:03  lr: 0.000026  loss: 0.1160 (0.1228)  time: 0.6026  data: 0.0001  max mem: 15821
[23:39:54.309445] Epoch: [40]  [344/345]  eta: 0:00:00  lr: 0.000026  loss: 0.1122 (0.1227)  time: 0.6024  data: 0.0001  max mem: 15821
[23:39:54.375158] Epoch: [40] Total time: 0:03:28 (0.6040 s / it)
[23:39:54.375305] Averaged stats: lr: 0.000026  loss: 0.1122 (0.1227)
[23:39:54.944582] Test:  [  0/345]  eta: 0:03:14  loss: 0.0960 (0.0960)  time: 0.5652  data: 0.4007  max mem: 15821
[23:39:56.610390] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1151 (0.1155)  time: 0.2027  data: 0.0365  max mem: 15821
[23:39:58.279467] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1198 (0.1214)  time: 0.1667  data: 0.0001  max mem: 15821
[23:39:59.952899] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1222 (0.1225)  time: 0.1671  data: 0.0001  max mem: 15821
[23:40:01.628068] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1187 (0.1192)  time: 0.1674  data: 0.0001  max mem: 15821
[23:40:03.306903] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1045 (0.1154)  time: 0.1676  data: 0.0001  max mem: 15821
[23:40:04.989301] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1018 (0.1142)  time: 0.1680  data: 0.0001  max mem: 15821
[23:40:06.674876] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1051 (0.1141)  time: 0.1683  data: 0.0001  max mem: 15821
[23:40:08.363726] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1125 (0.1153)  time: 0.1686  data: 0.0001  max mem: 15821
[23:40:10.056939] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1089 (0.1144)  time: 0.1690  data: 0.0001  max mem: 15821
[23:40:11.752225] Test:  [100/345]  eta: 0:00:42  loss: 0.1093 (0.1149)  time: 0.1694  data: 0.0001  max mem: 15821
[23:40:13.450558] Test:  [110/345]  eta: 0:00:40  loss: 0.1208 (0.1154)  time: 0.1696  data: 0.0001  max mem: 15821
[23:40:15.152110] Test:  [120/345]  eta: 0:00:38  loss: 0.1208 (0.1163)  time: 0.1699  data: 0.0001  max mem: 15821
[23:40:16.857954] Test:  [130/345]  eta: 0:00:36  loss: 0.1161 (0.1163)  time: 0.1703  data: 0.0001  max mem: 15821
[23:40:18.566507] Test:  [140/345]  eta: 0:00:35  loss: 0.1140 (0.1160)  time: 0.1707  data: 0.0001  max mem: 15821
[23:40:20.280077] Test:  [150/345]  eta: 0:00:33  loss: 0.1140 (0.1157)  time: 0.1710  data: 0.0001  max mem: 15821
[23:40:21.995557] Test:  [160/345]  eta: 0:00:31  loss: 0.1118 (0.1157)  time: 0.1714  data: 0.0001  max mem: 15821
[23:40:23.716508] Test:  [170/345]  eta: 0:00:30  loss: 0.1130 (0.1157)  time: 0.1718  data: 0.0001  max mem: 15821
[23:40:25.440490] Test:  [180/345]  eta: 0:00:28  loss: 0.1176 (0.1164)  time: 0.1722  data: 0.0001  max mem: 15821
[23:40:27.166854] Test:  [190/345]  eta: 0:00:26  loss: 0.1216 (0.1168)  time: 0.1725  data: 0.0001  max mem: 15821
[23:40:28.896946] Test:  [200/345]  eta: 0:00:24  loss: 0.1078 (0.1163)  time: 0.1728  data: 0.0001  max mem: 15821
[23:40:30.629808] Test:  [210/345]  eta: 0:00:23  loss: 0.1081 (0.1165)  time: 0.1731  data: 0.0001  max mem: 15821
[23:40:32.366300] Test:  [220/345]  eta: 0:00:21  loss: 0.1120 (0.1164)  time: 0.1734  data: 0.0001  max mem: 15821
[23:40:34.107046] Test:  [230/345]  eta: 0:00:19  loss: 0.1117 (0.1162)  time: 0.1738  data: 0.0001  max mem: 15821
[23:40:35.849918] Test:  [240/345]  eta: 0:00:18  loss: 0.1117 (0.1164)  time: 0.1741  data: 0.0001  max mem: 15821
[23:40:37.596621] Test:  [250/345]  eta: 0:00:16  loss: 0.1002 (0.1157)  time: 0.1744  data: 0.0001  max mem: 15821
[23:40:39.346998] Test:  [260/345]  eta: 0:00:14  loss: 0.1002 (0.1155)  time: 0.1748  data: 0.0001  max mem: 15821
[23:40:41.100026] Test:  [270/345]  eta: 0:00:12  loss: 0.1075 (0.1153)  time: 0.1751  data: 0.0001  max mem: 15821
[23:40:42.856869] Test:  [280/345]  eta: 0:00:11  loss: 0.1124 (0.1155)  time: 0.1754  data: 0.0001  max mem: 15821
[23:40:44.618130] Test:  [290/345]  eta: 0:00:09  loss: 0.1124 (0.1155)  time: 0.1758  data: 0.0001  max mem: 15821
[23:40:46.383023] Test:  [300/345]  eta: 0:00:07  loss: 0.1107 (0.1154)  time: 0.1762  data: 0.0001  max mem: 15821
[23:40:48.149994] Test:  [310/345]  eta: 0:00:06  loss: 0.1139 (0.1155)  time: 0.1765  data: 0.0001  max mem: 15821
[23:40:49.920854] Test:  [320/345]  eta: 0:00:04  loss: 0.1161 (0.1158)  time: 0.1768  data: 0.0001  max mem: 15821
[23:40:51.697057] Test:  [330/345]  eta: 0:00:02  loss: 0.1152 (0.1160)  time: 0.1773  data: 0.0001  max mem: 15821
[23:40:53.476786] Test:  [340/345]  eta: 0:00:00  loss: 0.1132 (0.1158)  time: 0.1777  data: 0.0001  max mem: 15821
[23:40:54.189132] Test:  [344/345]  eta: 0:00:00  loss: 0.1079 (0.1155)  time: 0.1778  data: 0.0001  max mem: 15821
[23:40:54.263115] Test: Total time: 0:00:59 (0.1736 s / it)
[23:41:04.863732] Test:  [ 0/57]  eta: 0:00:32  loss: 0.4932 (0.4932)  time: 0.5689  data: 0.4066  max mem: 15821
[23:41:06.507856] Test:  [10/57]  eta: 0:00:09  loss: 0.4234 (0.4546)  time: 0.2011  data: 0.0370  max mem: 15821
[23:41:08.157703] Test:  [20/57]  eta: 0:00:06  loss: 0.4234 (0.4451)  time: 0.1646  data: 0.0001  max mem: 15821
[23:41:09.812313] Test:  [30/57]  eta: 0:00:04  loss: 0.2929 (0.3816)  time: 0.1651  data: 0.0001  max mem: 15821
[23:41:11.472574] Test:  [40/57]  eta: 0:00:02  loss: 0.2414 (0.3557)  time: 0.1657  data: 0.0001  max mem: 15821
[23:41:13.137579] Test:  [50/57]  eta: 0:00:01  loss: 0.2962 (0.3502)  time: 0.1662  data: 0.0001  max mem: 15821
[23:41:14.035276] Test:  [56/57]  eta: 0:00:00  loss: 0.3286 (0.3629)  time: 0.1613  data: 0.0000  max mem: 15821
[23:41:14.106536] Test: Total time: 0:00:09 (0.1721 s / it)
[23:41:15.890814] Dice score of the network on the train images: 0.882853, val images: 0.793860
[23:41:15.895320] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[23:41:16.876911] Epoch: [41]  [  0/345]  eta: 0:05:38  lr: 0.000026  loss: 0.1219 (0.1219)  time: 0.9805  data: 0.3799  max mem: 15821
[23:41:28.851328] Epoch: [41]  [ 20/345]  eta: 0:03:20  lr: 0.000025  loss: 0.1162 (0.1188)  time: 0.5987  data: 0.0001  max mem: 15821
[23:41:40.843538] Epoch: [41]  [ 40/345]  eta: 0:03:05  lr: 0.000025  loss: 0.1187 (0.1224)  time: 0.5996  data: 0.0001  max mem: 15821
[23:41:52.848783] Epoch: [41]  [ 60/345]  eta: 0:02:52  lr: 0.000025  loss: 0.1207 (0.1227)  time: 0.6002  data: 0.0001  max mem: 15821
[23:42:04.885272] Epoch: [41]  [ 80/345]  eta: 0:02:40  lr: 0.000025  loss: 0.1223 (0.1236)  time: 0.6018  data: 0.0001  max mem: 15821
[23:42:16.950914] Epoch: [41]  [100/345]  eta: 0:02:28  lr: 0.000024  loss: 0.1157 (0.1224)  time: 0.6032  data: 0.0001  max mem: 15821
[23:42:29.036187] Epoch: [41]  [120/345]  eta: 0:02:15  lr: 0.000024  loss: 0.1190 (0.1222)  time: 0.6042  data: 0.0001  max mem: 15821
[23:42:41.136439] Epoch: [41]  [140/345]  eta: 0:02:03  lr: 0.000024  loss: 0.1197 (0.1217)  time: 0.6050  data: 0.0001  max mem: 15821
[23:42:53.222221] Epoch: [41]  [160/345]  eta: 0:01:51  lr: 0.000023  loss: 0.1158 (0.1215)  time: 0.6042  data: 0.0001  max mem: 15821
[23:43:05.314977] Epoch: [41]  [180/345]  eta: 0:01:39  lr: 0.000023  loss: 0.1131 (0.1207)  time: 0.6046  data: 0.0001  max mem: 15821
[23:43:17.404725] Epoch: [41]  [200/345]  eta: 0:01:27  lr: 0.000023  loss: 0.1214 (0.1207)  time: 0.6044  data: 0.0001  max mem: 15821
[23:43:29.488301] Epoch: [41]  [220/345]  eta: 0:01:15  lr: 0.000022  loss: 0.1199 (0.1209)  time: 0.6041  data: 0.0001  max mem: 15821
[23:43:41.571503] Epoch: [41]  [240/345]  eta: 0:01:03  lr: 0.000022  loss: 0.1259 (0.1211)  time: 0.6041  data: 0.0001  max mem: 15821
[23:43:53.643702] Epoch: [41]  [260/345]  eta: 0:00:51  lr: 0.000022  loss: 0.1160 (0.1210)  time: 0.6036  data: 0.0001  max mem: 15821
[23:44:05.806941] Epoch: [41]  [280/345]  eta: 0:00:39  lr: 0.000022  loss: 0.1146 (0.1207)  time: 0.6081  data: 0.0001  max mem: 15821
[23:44:17.868770] Epoch: [41]  [300/345]  eta: 0:00:27  lr: 0.000021  loss: 0.1232 (0.1209)  time: 0.6030  data: 0.0001  max mem: 15821
[23:44:29.928727] Epoch: [41]  [320/345]  eta: 0:00:15  lr: 0.000021  loss: 0.1100 (0.1205)  time: 0.6030  data: 0.0001  max mem: 15821
[23:44:41.972949] Epoch: [41]  [340/345]  eta: 0:00:03  lr: 0.000021  loss: 0.1181 (0.1207)  time: 0.6022  data: 0.0001  max mem: 15821
[23:44:44.382810] Epoch: [41]  [344/345]  eta: 0:00:00  lr: 0.000021  loss: 0.1154 (0.1206)  time: 0.6022  data: 0.0001  max mem: 15821
[23:44:44.465325] Epoch: [41] Total time: 0:03:28 (0.6046 s / it)
[23:44:44.465659] Averaged stats: lr: 0.000021  loss: 0.1154 (0.1206)
[23:44:45.034262] Test:  [  0/345]  eta: 0:03:14  loss: 0.0941 (0.0941)  time: 0.5628  data: 0.3982  max mem: 15821
[23:44:46.699907] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1083 (0.1097)  time: 0.2025  data: 0.0363  max mem: 15821
[23:44:48.368181] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1083 (0.1118)  time: 0.1666  data: 0.0001  max mem: 15821
[23:44:50.040796] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1082 (0.1111)  time: 0.1670  data: 0.0001  max mem: 15821
[23:44:51.716230] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1091 (0.1134)  time: 0.1673  data: 0.0001  max mem: 15821
[23:44:53.394836] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1125 (0.1126)  time: 0.1676  data: 0.0001  max mem: 15821
[23:44:55.076669] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1112 (0.1121)  time: 0.1680  data: 0.0001  max mem: 15821
[23:44:56.762193] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1083 (0.1124)  time: 0.1683  data: 0.0001  max mem: 15821
[23:44:58.450659] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1115 (0.1135)  time: 0.1686  data: 0.0001  max mem: 15821
[23:45:00.143281] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1121 (0.1134)  time: 0.1690  data: 0.0001  max mem: 15821
[23:45:01.838290] Test:  [100/345]  eta: 0:00:42  loss: 0.1033 (0.1129)  time: 0.1693  data: 0.0001  max mem: 15821
[23:45:03.538273] Test:  [110/345]  eta: 0:00:40  loss: 0.1078 (0.1137)  time: 0.1697  data: 0.0001  max mem: 15821
[23:45:05.240520] Test:  [120/345]  eta: 0:00:38  loss: 0.1170 (0.1142)  time: 0.1700  data: 0.0001  max mem: 15821
[23:45:06.947448] Test:  [130/345]  eta: 0:00:36  loss: 0.1138 (0.1143)  time: 0.1704  data: 0.0001  max mem: 15821
[23:45:08.656795] Test:  [140/345]  eta: 0:00:35  loss: 0.1094 (0.1140)  time: 0.1707  data: 0.0001  max mem: 15821
[23:45:10.370304] Test:  [150/345]  eta: 0:00:33  loss: 0.1073 (0.1133)  time: 0.1711  data: 0.0001  max mem: 15821
[23:45:12.088436] Test:  [160/345]  eta: 0:00:31  loss: 0.1078 (0.1139)  time: 0.1715  data: 0.0001  max mem: 15821
[23:45:13.808968] Test:  [170/345]  eta: 0:00:30  loss: 0.1128 (0.1138)  time: 0.1719  data: 0.0001  max mem: 15821
[23:45:15.531690] Test:  [180/345]  eta: 0:00:28  loss: 0.1080 (0.1134)  time: 0.1721  data: 0.0001  max mem: 15821
[23:45:17.259490] Test:  [190/345]  eta: 0:00:26  loss: 0.1071 (0.1133)  time: 0.1725  data: 0.0001  max mem: 15821
[23:45:18.989624] Test:  [200/345]  eta: 0:00:24  loss: 0.1090 (0.1132)  time: 0.1728  data: 0.0001  max mem: 15821
[23:45:20.722434] Test:  [210/345]  eta: 0:00:23  loss: 0.1166 (0.1134)  time: 0.1731  data: 0.0001  max mem: 15821
[23:45:22.458477] Test:  [220/345]  eta: 0:00:21  loss: 0.1210 (0.1144)  time: 0.1734  data: 0.0001  max mem: 15821
[23:45:24.200105] Test:  [230/345]  eta: 0:00:19  loss: 0.1180 (0.1143)  time: 0.1738  data: 0.0001  max mem: 15821
[23:45:25.944457] Test:  [240/345]  eta: 0:00:18  loss: 0.1088 (0.1144)  time: 0.1742  data: 0.0001  max mem: 15821
[23:45:27.690796] Test:  [250/345]  eta: 0:00:16  loss: 0.1120 (0.1145)  time: 0.1745  data: 0.0001  max mem: 15821
[23:45:29.440293] Test:  [260/345]  eta: 0:00:14  loss: 0.1120 (0.1145)  time: 0.1747  data: 0.0001  max mem: 15821
[23:45:31.193745] Test:  [270/345]  eta: 0:00:12  loss: 0.1230 (0.1149)  time: 0.1751  data: 0.0001  max mem: 15821
[23:45:32.952097] Test:  [280/345]  eta: 0:00:11  loss: 0.1136 (0.1149)  time: 0.1755  data: 0.0001  max mem: 15821
[23:45:34.713693] Test:  [290/345]  eta: 0:00:09  loss: 0.1064 (0.1153)  time: 0.1759  data: 0.0001  max mem: 15821
[23:45:36.477830] Test:  [300/345]  eta: 0:00:07  loss: 0.1116 (0.1153)  time: 0.1762  data: 0.0001  max mem: 15821
[23:45:38.246976] Test:  [310/345]  eta: 0:00:06  loss: 0.1085 (0.1150)  time: 0.1766  data: 0.0001  max mem: 15821
[23:45:40.017774] Test:  [320/345]  eta: 0:00:04  loss: 0.1085 (0.1149)  time: 0.1769  data: 0.0001  max mem: 15821
[23:45:41.794352] Test:  [330/345]  eta: 0:00:02  loss: 0.1093 (0.1148)  time: 0.1773  data: 0.0001  max mem: 15821
[23:45:43.573835] Test:  [340/345]  eta: 0:00:00  loss: 0.1092 (0.1149)  time: 0.1777  data: 0.0001  max mem: 15821
[23:45:44.286832] Test:  [344/345]  eta: 0:00:00  loss: 0.1092 (0.1148)  time: 0.1778  data: 0.0001  max mem: 15821
[23:45:44.358872] Test: Total time: 0:00:59 (0.1736 s / it)
[23:45:54.872500] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4909 (0.4909)  time: 0.5382  data: 0.3761  max mem: 15821
[23:45:56.516375] Test:  [10/57]  eta: 0:00:09  loss: 0.4123 (0.4509)  time: 0.1983  data: 0.0343  max mem: 15821
[23:45:58.167565] Test:  [20/57]  eta: 0:00:06  loss: 0.4123 (0.4422)  time: 0.1647  data: 0.0001  max mem: 15821
[23:45:59.823987] Test:  [30/57]  eta: 0:00:04  loss: 0.2783 (0.3782)  time: 0.1653  data: 0.0001  max mem: 15821
[23:46:01.486241] Test:  [40/57]  eta: 0:00:02  loss: 0.2301 (0.3507)  time: 0.1659  data: 0.0001  max mem: 15821
[23:46:03.150329] Test:  [50/57]  eta: 0:00:01  loss: 0.2794 (0.3442)  time: 0.1663  data: 0.0001  max mem: 15821
[23:46:04.047589] Test:  [56/57]  eta: 0:00:00  loss: 0.3013 (0.3545)  time: 0.1613  data: 0.0000  max mem: 15821
[23:46:04.110931] Test: Total time: 0:00:09 (0.1715 s / it)
[23:46:05.893060] Dice score of the network on the train images: 0.883159, val images: 0.801733
[23:46:05.897308] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[23:46:06.866249] Epoch: [42]  [  0/345]  eta: 0:05:33  lr: 0.000021  loss: 0.1623 (0.1623)  time: 0.9680  data: 0.3675  max mem: 15821
[23:46:18.857044] Epoch: [42]  [ 20/345]  eta: 0:03:20  lr: 0.000020  loss: 0.1142 (0.1183)  time: 0.5995  data: 0.0001  max mem: 15821
[23:46:30.862625] Epoch: [42]  [ 40/345]  eta: 0:03:05  lr: 0.000020  loss: 0.1142 (0.1174)  time: 0.6002  data: 0.0001  max mem: 15821
[23:46:42.876657] Epoch: [42]  [ 60/345]  eta: 0:02:52  lr: 0.000020  loss: 0.1257 (0.1204)  time: 0.6006  data: 0.0001  max mem: 15821
[23:46:54.899226] Epoch: [42]  [ 80/345]  eta: 0:02:40  lr: 0.000020  loss: 0.1104 (0.1197)  time: 0.6011  data: 0.0001  max mem: 15821
[23:47:06.956094] Epoch: [42]  [100/345]  eta: 0:02:28  lr: 0.000019  loss: 0.1147 (0.1195)  time: 0.6028  data: 0.0001  max mem: 15821
[23:47:19.033065] Epoch: [42]  [120/345]  eta: 0:02:15  lr: 0.000019  loss: 0.1156 (0.1198)  time: 0.6038  data: 0.0001  max mem: 15821
[23:47:31.117740] Epoch: [42]  [140/345]  eta: 0:02:03  lr: 0.000019  loss: 0.1197 (0.1204)  time: 0.6042  data: 0.0001  max mem: 15821
[23:47:43.205519] Epoch: [42]  [160/345]  eta: 0:01:51  lr: 0.000018  loss: 0.1182 (0.1202)  time: 0.6043  data: 0.0001  max mem: 15821
[23:47:55.292768] Epoch: [42]  [180/345]  eta: 0:01:39  lr: 0.000018  loss: 0.1167 (0.1198)  time: 0.6043  data: 0.0001  max mem: 15821
[23:48:07.387530] Epoch: [42]  [200/345]  eta: 0:01:27  lr: 0.000018  loss: 0.1085 (0.1192)  time: 0.6047  data: 0.0001  max mem: 15821
[23:48:19.476530] Epoch: [42]  [220/345]  eta: 0:01:15  lr: 0.000018  loss: 0.1186 (0.1194)  time: 0.6044  data: 0.0001  max mem: 15821
[23:48:31.563519] Epoch: [42]  [240/345]  eta: 0:01:03  lr: 0.000017  loss: 0.1103 (0.1187)  time: 0.6043  data: 0.0001  max mem: 15821
[23:48:43.646750] Epoch: [42]  [260/345]  eta: 0:00:51  lr: 0.000017  loss: 0.1181 (0.1186)  time: 0.6041  data: 0.0001  max mem: 15821
[23:48:55.724839] Epoch: [42]  [280/345]  eta: 0:00:39  lr: 0.000017  loss: 0.1180 (0.1185)  time: 0.6039  data: 0.0001  max mem: 15821
[23:49:07.798279] Epoch: [42]  [300/345]  eta: 0:00:27  lr: 0.000017  loss: 0.1234 (0.1188)  time: 0.6036  data: 0.0001  max mem: 15821
[23:49:19.877259] Epoch: [42]  [320/345]  eta: 0:00:15  lr: 0.000016  loss: 0.1097 (0.1189)  time: 0.6039  data: 0.0001  max mem: 15821
[23:49:31.944649] Epoch: [42]  [340/345]  eta: 0:00:03  lr: 0.000016  loss: 0.1120 (0.1186)  time: 0.6033  data: 0.0001  max mem: 15821
[23:49:34.355508] Epoch: [42]  [344/345]  eta: 0:00:00  lr: 0.000016  loss: 0.1120 (0.1186)  time: 0.6031  data: 0.0001  max mem: 15821
[23:49:34.430677] Epoch: [42] Total time: 0:03:28 (0.6044 s / it)
[23:49:34.431309] Averaged stats: lr: 0.000016  loss: 0.1120 (0.1186)
[23:49:34.993305] Test:  [  0/345]  eta: 0:03:11  loss: 0.1065 (0.1065)  time: 0.5563  data: 0.3925  max mem: 15821
[23:49:36.658441] Test:  [ 10/345]  eta: 0:01:07  loss: 0.1126 (0.1159)  time: 0.2019  data: 0.0358  max mem: 15821
[23:49:38.325625] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1145 (0.1162)  time: 0.1665  data: 0.0001  max mem: 15821
[23:49:39.997081] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1145 (0.1148)  time: 0.1669  data: 0.0001  max mem: 15821
[23:49:41.671618] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1070 (0.1143)  time: 0.1672  data: 0.0001  max mem: 15821
[23:49:43.350946] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1043 (0.1137)  time: 0.1676  data: 0.0001  max mem: 15821
[23:49:45.032715] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1108 (0.1133)  time: 0.1680  data: 0.0001  max mem: 15821
[23:49:46.719359] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1121 (0.1140)  time: 0.1684  data: 0.0001  max mem: 15821
[23:49:48.408855] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1132 (0.1145)  time: 0.1687  data: 0.0001  max mem: 15821
[23:49:50.101312] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1081 (0.1135)  time: 0.1690  data: 0.0001  max mem: 15821
[23:49:51.797853] Test:  [100/345]  eta: 0:00:42  loss: 0.1078 (0.1134)  time: 0.1694  data: 0.0001  max mem: 15821
[23:49:53.498606] Test:  [110/345]  eta: 0:00:40  loss: 0.1080 (0.1138)  time: 0.1698  data: 0.0001  max mem: 15821
[23:49:55.202733] Test:  [120/345]  eta: 0:00:38  loss: 0.1048 (0.1132)  time: 0.1702  data: 0.0001  max mem: 15821
[23:49:56.908366] Test:  [130/345]  eta: 0:00:36  loss: 0.1121 (0.1133)  time: 0.1704  data: 0.0001  max mem: 15821
[23:49:58.617781] Test:  [140/345]  eta: 0:00:35  loss: 0.1121 (0.1134)  time: 0.1707  data: 0.0001  max mem: 15821
[23:50:00.332511] Test:  [150/345]  eta: 0:00:33  loss: 0.1048 (0.1128)  time: 0.1711  data: 0.0001  max mem: 15821
[23:50:02.049667] Test:  [160/345]  eta: 0:00:31  loss: 0.1053 (0.1128)  time: 0.1715  data: 0.0001  max mem: 15821
[23:50:03.770223] Test:  [170/345]  eta: 0:00:30  loss: 0.1071 (0.1129)  time: 0.1718  data: 0.0001  max mem: 15821
[23:50:05.493760] Test:  [180/345]  eta: 0:00:28  loss: 0.1052 (0.1124)  time: 0.1721  data: 0.0001  max mem: 15821
[23:50:07.220678] Test:  [190/345]  eta: 0:00:26  loss: 0.1037 (0.1126)  time: 0.1725  data: 0.0001  max mem: 15821
[23:50:08.949249] Test:  [200/345]  eta: 0:00:24  loss: 0.1084 (0.1124)  time: 0.1727  data: 0.0001  max mem: 15821
[23:50:10.681435] Test:  [210/345]  eta: 0:00:23  loss: 0.1105 (0.1124)  time: 0.1730  data: 0.0001  max mem: 15821
[23:50:12.418288] Test:  [220/345]  eta: 0:00:21  loss: 0.1044 (0.1120)  time: 0.1734  data: 0.0001  max mem: 15821
[23:50:14.159254] Test:  [230/345]  eta: 0:00:19  loss: 0.1052 (0.1121)  time: 0.1738  data: 0.0001  max mem: 15821
[23:50:15.901861] Test:  [240/345]  eta: 0:00:18  loss: 0.1110 (0.1120)  time: 0.1741  data: 0.0001  max mem: 15821
[23:50:17.649419] Test:  [250/345]  eta: 0:00:16  loss: 0.1123 (0.1121)  time: 0.1744  data: 0.0001  max mem: 15821
[23:50:19.400595] Test:  [260/345]  eta: 0:00:14  loss: 0.1123 (0.1120)  time: 0.1749  data: 0.0001  max mem: 15821
[23:50:21.154730] Test:  [270/345]  eta: 0:00:12  loss: 0.1192 (0.1124)  time: 0.1752  data: 0.0001  max mem: 15821
[23:50:22.911771] Test:  [280/345]  eta: 0:00:11  loss: 0.1139 (0.1123)  time: 0.1755  data: 0.0001  max mem: 15821
[23:50:24.672619] Test:  [290/345]  eta: 0:00:09  loss: 0.1077 (0.1125)  time: 0.1758  data: 0.0001  max mem: 15821
[23:50:26.437538] Test:  [300/345]  eta: 0:00:07  loss: 0.1077 (0.1122)  time: 0.1762  data: 0.0001  max mem: 15821
[23:50:28.206332] Test:  [310/345]  eta: 0:00:06  loss: 0.1030 (0.1121)  time: 0.1766  data: 0.0001  max mem: 15821
[23:50:29.978946] Test:  [320/345]  eta: 0:00:04  loss: 0.1033 (0.1119)  time: 0.1770  data: 0.0001  max mem: 15821
[23:50:31.754736] Test:  [330/345]  eta: 0:00:02  loss: 0.1085 (0.1120)  time: 0.1774  data: 0.0001  max mem: 15821
[23:50:33.533195] Test:  [340/345]  eta: 0:00:00  loss: 0.1084 (0.1119)  time: 0.1777  data: 0.0001  max mem: 15821
[23:50:34.245927] Test:  [344/345]  eta: 0:00:00  loss: 0.1048 (0.1120)  time: 0.1778  data: 0.0001  max mem: 15821
[23:50:34.320431] Test: Total time: 0:00:59 (0.1736 s / it)
[23:50:45.433630] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4978 (0.4978)  time: 0.5296  data: 0.3671  max mem: 15821
[23:50:47.078463] Test:  [10/57]  eta: 0:00:09  loss: 0.4228 (0.4639)  time: 0.1976  data: 0.0335  max mem: 15821
[23:50:48.728875] Test:  [20/57]  eta: 0:00:06  loss: 0.4228 (0.4534)  time: 0.1647  data: 0.0001  max mem: 15821
[23:50:50.383051] Test:  [30/57]  eta: 0:00:04  loss: 0.2858 (0.3871)  time: 0.1652  data: 0.0001  max mem: 15821
[23:50:52.043234] Test:  [40/57]  eta: 0:00:02  loss: 0.2359 (0.3592)  time: 0.1657  data: 0.0001  max mem: 15821
[23:50:53.706974] Test:  [50/57]  eta: 0:00:01  loss: 0.2959 (0.3533)  time: 0.1661  data: 0.0001  max mem: 15821
[23:50:54.604834] Test:  [56/57]  eta: 0:00:00  loss: 0.3248 (0.3666)  time: 0.1612  data: 0.0000  max mem: 15821
[23:50:54.669666] Test: Total time: 0:00:09 (0.1713 s / it)
[23:50:56.565844] Dice score of the network on the train images: 0.883116, val images: 0.796404
[23:50:56.571067] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[23:50:57.552151] Epoch: [43]  [  0/345]  eta: 0:05:38  lr: 0.000016  loss: 0.1062 (0.1062)  time: 0.9801  data: 0.3808  max mem: 15821
[23:51:09.529978] Epoch: [43]  [ 20/345]  eta: 0:03:20  lr: 0.000016  loss: 0.1094 (0.1153)  time: 0.5988  data: 0.0001  max mem: 15821
[23:51:21.535573] Epoch: [43]  [ 40/345]  eta: 0:03:05  lr: 0.000016  loss: 0.1176 (0.1156)  time: 0.6002  data: 0.0001  max mem: 15821
[23:51:33.545157] Epoch: [43]  [ 60/345]  eta: 0:02:52  lr: 0.000015  loss: 0.1121 (0.1172)  time: 0.6004  data: 0.0001  max mem: 15821
[23:51:45.588525] Epoch: [43]  [ 80/345]  eta: 0:02:40  lr: 0.000015  loss: 0.1063 (0.1158)  time: 0.6021  data: 0.0001  max mem: 15821
[23:51:57.662203] Epoch: [43]  [100/345]  eta: 0:02:28  lr: 0.000015  loss: 0.1121 (0.1155)  time: 0.6036  data: 0.0001  max mem: 15821
[23:52:09.749231] Epoch: [43]  [120/345]  eta: 0:02:16  lr: 0.000015  loss: 0.1231 (0.1168)  time: 0.6043  data: 0.0001  max mem: 15821
[23:52:21.836621] Epoch: [43]  [140/345]  eta: 0:02:03  lr: 0.000014  loss: 0.1120 (0.1161)  time: 0.6043  data: 0.0001  max mem: 15821
[23:52:33.923640] Epoch: [43]  [160/345]  eta: 0:01:51  lr: 0.000014  loss: 0.1068 (0.1156)  time: 0.6043  data: 0.0001  max mem: 15821
[23:52:46.002698] Epoch: [43]  [180/345]  eta: 0:01:39  lr: 0.000014  loss: 0.1252 (0.1164)  time: 0.6039  data: 0.0001  max mem: 15821
[23:52:58.079840] Epoch: [43]  [200/345]  eta: 0:01:27  lr: 0.000014  loss: 0.1149 (0.1167)  time: 0.6038  data: 0.0001  max mem: 15821
[23:53:10.166069] Epoch: [43]  [220/345]  eta: 0:01:15  lr: 0.000013  loss: 0.1115 (0.1167)  time: 0.6043  data: 0.0001  max mem: 15821
[23:53:22.363683] Epoch: [43]  [240/345]  eta: 0:01:03  lr: 0.000013  loss: 0.1063 (0.1160)  time: 0.6098  data: 0.0001  max mem: 15821
[23:53:34.421665] Epoch: [43]  [260/345]  eta: 0:00:51  lr: 0.000013  loss: 0.1098 (0.1160)  time: 0.6029  data: 0.0001  max mem: 15821
[23:53:46.466379] Epoch: [43]  [280/345]  eta: 0:00:39  lr: 0.000013  loss: 0.1201 (0.1163)  time: 0.6022  data: 0.0001  max mem: 15821
[23:53:58.518416] Epoch: [43]  [300/345]  eta: 0:00:27  lr: 0.000012  loss: 0.1100 (0.1162)  time: 0.6026  data: 0.0001  max mem: 15821
[23:54:10.561191] Epoch: [43]  [320/345]  eta: 0:00:15  lr: 0.000012  loss: 0.1153 (0.1164)  time: 0.6021  data: 0.0001  max mem: 15821
[23:54:22.600223] Epoch: [43]  [340/345]  eta: 0:00:03  lr: 0.000012  loss: 0.1192 (0.1167)  time: 0.6019  data: 0.0001  max mem: 15821
[23:54:25.008503] Epoch: [43]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 0.1166 (0.1168)  time: 0.6018  data: 0.0001  max mem: 15821
[23:54:25.085447] Epoch: [43] Total time: 0:03:28 (0.6044 s / it)
[23:54:25.085741] Averaged stats: lr: 0.000012  loss: 0.1166 (0.1168)
[23:54:25.688528] Test:  [  0/345]  eta: 0:03:25  loss: 0.1121 (0.1121)  time: 0.5957  data: 0.4315  max mem: 15821
[23:54:27.354861] Test:  [ 10/345]  eta: 0:01:08  loss: 0.0969 (0.1089)  time: 0.2055  data: 0.0393  max mem: 15821
[23:54:29.024365] Test:  [ 20/345]  eta: 0:01:00  loss: 0.0991 (0.1098)  time: 0.1667  data: 0.0001  max mem: 15821
[23:54:30.697542] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1068 (0.1125)  time: 0.1671  data: 0.0001  max mem: 15821
[23:54:32.372755] Test:  [ 40/345]  eta: 0:00:54  loss: 0.1068 (0.1119)  time: 0.1673  data: 0.0001  max mem: 15821
[23:54:34.051397] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1047 (0.1104)  time: 0.1676  data: 0.0001  max mem: 15821
[23:54:35.733199] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1037 (0.1101)  time: 0.1680  data: 0.0001  max mem: 15821
[23:54:37.419415] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1058 (0.1102)  time: 0.1683  data: 0.0001  max mem: 15821
[23:54:39.107809] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1055 (0.1102)  time: 0.1687  data: 0.0001  max mem: 15821
[23:54:40.800241] Test:  [ 90/345]  eta: 0:00:43  loss: 0.0992 (0.1093)  time: 0.1690  data: 0.0001  max mem: 15821
[23:54:42.495831] Test:  [100/345]  eta: 0:00:42  loss: 0.0992 (0.1088)  time: 0.1693  data: 0.0001  max mem: 15821
[23:54:44.195471] Test:  [110/345]  eta: 0:00:40  loss: 0.0982 (0.1086)  time: 0.1697  data: 0.0001  max mem: 15821
[23:54:45.898957] Test:  [120/345]  eta: 0:00:38  loss: 0.1051 (0.1084)  time: 0.1701  data: 0.0001  max mem: 15821
[23:54:47.604294] Test:  [130/345]  eta: 0:00:36  loss: 0.1063 (0.1085)  time: 0.1704  data: 0.0001  max mem: 15821
[23:54:49.312232] Test:  [140/345]  eta: 0:00:35  loss: 0.1054 (0.1087)  time: 0.1706  data: 0.0001  max mem: 15821
[23:54:51.025319] Test:  [150/345]  eta: 0:00:33  loss: 0.1054 (0.1085)  time: 0.1710  data: 0.0001  max mem: 15821
[23:54:52.741139] Test:  [160/345]  eta: 0:00:31  loss: 0.1058 (0.1083)  time: 0.1714  data: 0.0001  max mem: 15821
[23:54:54.461154] Test:  [170/345]  eta: 0:00:30  loss: 0.1005 (0.1084)  time: 0.1717  data: 0.0001  max mem: 15821
[23:54:56.183125] Test:  [180/345]  eta: 0:00:28  loss: 0.1077 (0.1084)  time: 0.1720  data: 0.0001  max mem: 15821
[23:54:57.908694] Test:  [190/345]  eta: 0:00:26  loss: 0.1034 (0.1085)  time: 0.1723  data: 0.0001  max mem: 15821
[23:54:59.638393] Test:  [200/345]  eta: 0:00:24  loss: 0.1004 (0.1085)  time: 0.1727  data: 0.0001  max mem: 15821
[23:55:01.370879] Test:  [210/345]  eta: 0:00:23  loss: 0.1025 (0.1083)  time: 0.1730  data: 0.0001  max mem: 15821
[23:55:03.107911] Test:  [220/345]  eta: 0:00:21  loss: 0.1022 (0.1086)  time: 0.1734  data: 0.0001  max mem: 15821
[23:55:04.850004] Test:  [230/345]  eta: 0:00:19  loss: 0.1079 (0.1089)  time: 0.1739  data: 0.0001  max mem: 15821
[23:55:06.593560] Test:  [240/345]  eta: 0:00:18  loss: 0.1079 (0.1087)  time: 0.1742  data: 0.0001  max mem: 15821
[23:55:08.339479] Test:  [250/345]  eta: 0:00:16  loss: 0.1039 (0.1089)  time: 0.1744  data: 0.0001  max mem: 15821
[23:55:10.089418] Test:  [260/345]  eta: 0:00:14  loss: 0.1117 (0.1093)  time: 0.1747  data: 0.0001  max mem: 15821
[23:55:11.845229] Test:  [270/345]  eta: 0:00:12  loss: 0.1117 (0.1096)  time: 0.1752  data: 0.0001  max mem: 15821
[23:55:13.601882] Test:  [280/345]  eta: 0:00:11  loss: 0.1065 (0.1096)  time: 0.1756  data: 0.0001  max mem: 15821
[23:55:15.362462] Test:  [290/345]  eta: 0:00:09  loss: 0.1000 (0.1095)  time: 0.1758  data: 0.0001  max mem: 15821
[23:55:17.126458] Test:  [300/345]  eta: 0:00:07  loss: 0.1027 (0.1094)  time: 0.1762  data: 0.0001  max mem: 15821
[23:55:18.894963] Test:  [310/345]  eta: 0:00:06  loss: 0.1064 (0.1095)  time: 0.1766  data: 0.0001  max mem: 15821
[23:55:20.667410] Test:  [320/345]  eta: 0:00:04  loss: 0.1097 (0.1095)  time: 0.1770  data: 0.0001  max mem: 15821
[23:55:22.444141] Test:  [330/345]  eta: 0:00:02  loss: 0.1022 (0.1094)  time: 0.1774  data: 0.0001  max mem: 15821
[23:55:24.223371] Test:  [340/345]  eta: 0:00:00  loss: 0.1022 (0.1095)  time: 0.1777  data: 0.0001  max mem: 15821
[23:55:24.936229] Test:  [344/345]  eta: 0:00:00  loss: 0.1022 (0.1095)  time: 0.1779  data: 0.0001  max mem: 15821
[23:55:25.009527] Test: Total time: 0:00:59 (0.1737 s / it)
[23:55:36.077816] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4980 (0.4980)  time: 0.5276  data: 0.3658  max mem: 15821
[23:55:37.722837] Test:  [10/57]  eta: 0:00:09  loss: 0.4301 (0.4634)  time: 0.1974  data: 0.0333  max mem: 15821
[23:55:39.373025] Test:  [20/57]  eta: 0:00:06  loss: 0.4301 (0.4534)  time: 0.1647  data: 0.0001  max mem: 15821
[23:55:41.028206] Test:  [30/57]  eta: 0:00:04  loss: 0.2880 (0.3875)  time: 0.1652  data: 0.0001  max mem: 15821
[23:55:42.688874] Test:  [40/57]  eta: 0:00:02  loss: 0.2403 (0.3607)  time: 0.1657  data: 0.0001  max mem: 15821
[23:55:44.354315] Test:  [50/57]  eta: 0:00:01  loss: 0.2938 (0.3556)  time: 0.1662  data: 0.0001  max mem: 15821
[23:55:45.252208] Test:  [56/57]  eta: 0:00:00  loss: 0.3290 (0.3679)  time: 0.1613  data: 0.0001  max mem: 15821
[23:55:45.332485] Test: Total time: 0:00:09 (0.1716 s / it)
[23:55:47.254934] Dice score of the network on the train images: 0.886785, val images: 0.796148
[23:55:47.259236] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[23:55:48.230223] Epoch: [44]  [  0/345]  eta: 0:05:34  lr: 0.000012  loss: 0.1474 (0.1474)  time: 0.9698  data: 0.3711  max mem: 15821
[23:56:00.206056] Epoch: [44]  [ 20/345]  eta: 0:03:20  lr: 0.000012  loss: 0.1143 (0.1168)  time: 0.5987  data: 0.0001  max mem: 15821
[23:56:12.211866] Epoch: [44]  [ 40/345]  eta: 0:03:05  lr: 0.000011  loss: 0.1084 (0.1158)  time: 0.6002  data: 0.0001  max mem: 15821
[23:56:24.230164] Epoch: [44]  [ 60/345]  eta: 0:02:52  lr: 0.000011  loss: 0.1225 (0.1187)  time: 0.6009  data: 0.0001  max mem: 15821
[23:56:36.271076] Epoch: [44]  [ 80/345]  eta: 0:02:40  lr: 0.000011  loss: 0.1101 (0.1172)  time: 0.6020  data: 0.0001  max mem: 15821
[23:56:48.345520] Epoch: [44]  [100/345]  eta: 0:02:28  lr: 0.000011  loss: 0.1117 (0.1169)  time: 0.6037  data: 0.0001  max mem: 15821
[23:57:00.428918] Epoch: [44]  [120/345]  eta: 0:02:16  lr: 0.000011  loss: 0.1079 (0.1156)  time: 0.6041  data: 0.0001  max mem: 15821
[23:57:12.521248] Epoch: [44]  [140/345]  eta: 0:02:03  lr: 0.000010  loss: 0.1122 (0.1159)  time: 0.6046  data: 0.0001  max mem: 15821
[23:57:24.618005] Epoch: [44]  [160/345]  eta: 0:01:51  lr: 0.000010  loss: 0.1086 (0.1155)  time: 0.6048  data: 0.0001  max mem: 15821
[23:57:36.707637] Epoch: [44]  [180/345]  eta: 0:01:39  lr: 0.000010  loss: 0.1052 (0.1151)  time: 0.6044  data: 0.0001  max mem: 15821
[23:57:48.789238] Epoch: [44]  [200/345]  eta: 0:01:27  lr: 0.000010  loss: 0.1096 (0.1149)  time: 0.6040  data: 0.0001  max mem: 15821
[23:58:00.870152] Epoch: [44]  [220/345]  eta: 0:01:15  lr: 0.000010  loss: 0.1060 (0.1145)  time: 0.6040  data: 0.0001  max mem: 15821
[23:58:12.930361] Epoch: [44]  [240/345]  eta: 0:01:03  lr: 0.000009  loss: 0.1081 (0.1143)  time: 0.6030  data: 0.0001  max mem: 15821
[23:58:24.995453] Epoch: [44]  [260/345]  eta: 0:00:51  lr: 0.000009  loss: 0.1136 (0.1144)  time: 0.6032  data: 0.0001  max mem: 15821
[23:58:37.049478] Epoch: [44]  [280/345]  eta: 0:00:39  lr: 0.000009  loss: 0.1167 (0.1146)  time: 0.6027  data: 0.0001  max mem: 15821
[23:58:49.113857] Epoch: [44]  [300/345]  eta: 0:00:27  lr: 0.000009  loss: 0.1090 (0.1144)  time: 0.6032  data: 0.0001  max mem: 15821
[23:59:01.164046] Epoch: [44]  [320/345]  eta: 0:00:15  lr: 0.000009  loss: 0.1078 (0.1143)  time: 0.6025  data: 0.0001  max mem: 15821
[23:59:13.199912] Epoch: [44]  [340/345]  eta: 0:00:03  lr: 0.000008  loss: 0.1167 (0.1148)  time: 0.6017  data: 0.0001  max mem: 15821
[23:59:15.607617] Epoch: [44]  [344/345]  eta: 0:00:00  lr: 0.000008  loss: 0.1167 (0.1149)  time: 0.6017  data: 0.0001  max mem: 15821
[23:59:15.682057] Epoch: [44] Total time: 0:03:28 (0.6041 s / it)
[23:59:15.682288] Averaged stats: lr: 0.000008  loss: 0.1167 (0.1149)
[23:59:16.257042] Test:  [  0/345]  eta: 0:03:16  loss: 0.0916 (0.0916)  time: 0.5705  data: 0.4062  max mem: 15821
[23:59:17.923069] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1050 (0.1124)  time: 0.2032  data: 0.0370  max mem: 15821
[23:59:19.591945] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1055 (0.1093)  time: 0.1666  data: 0.0001  max mem: 15821
[23:59:21.264893] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1055 (0.1084)  time: 0.1670  data: 0.0001  max mem: 15821
[23:59:22.939873] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1023 (0.1079)  time: 0.1673  data: 0.0001  max mem: 15821
[23:59:24.617293] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1011 (0.1066)  time: 0.1675  data: 0.0001  max mem: 15821
[23:59:26.299954] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1068 (0.1080)  time: 0.1679  data: 0.0001  max mem: 15821
[23:59:27.986652] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1077 (0.1074)  time: 0.1684  data: 0.0001  max mem: 15821
[23:59:29.674120] Test:  [ 80/345]  eta: 0:00:45  loss: 0.0975 (0.1069)  time: 0.1686  data: 0.0001  max mem: 15821
[23:59:31.365360] Test:  [ 90/345]  eta: 0:00:43  loss: 0.0987 (0.1066)  time: 0.1689  data: 0.0001  max mem: 15821
[23:59:33.060438] Test:  [100/345]  eta: 0:00:42  loss: 0.1046 (0.1070)  time: 0.1692  data: 0.0001  max mem: 15821
[23:59:34.759727] Test:  [110/345]  eta: 0:00:40  loss: 0.1058 (0.1071)  time: 0.1697  data: 0.0001  max mem: 15821
[23:59:36.462307] Test:  [120/345]  eta: 0:00:38  loss: 0.1046 (0.1074)  time: 0.1700  data: 0.0001  max mem: 15821
[23:59:38.167306] Test:  [130/345]  eta: 0:00:36  loss: 0.1019 (0.1071)  time: 0.1703  data: 0.0001  max mem: 15821
[23:59:39.875769] Test:  [140/345]  eta: 0:00:35  loss: 0.1055 (0.1073)  time: 0.1706  data: 0.0001  max mem: 15821
[23:59:41.588979] Test:  [150/345]  eta: 0:00:33  loss: 0.1088 (0.1077)  time: 0.1710  data: 0.0001  max mem: 15821
[23:59:43.303889] Test:  [160/345]  eta: 0:00:31  loss: 0.1117 (0.1080)  time: 0.1713  data: 0.0001  max mem: 15821
[23:59:45.024986] Test:  [170/345]  eta: 0:00:30  loss: 0.1060 (0.1080)  time: 0.1717  data: 0.0001  max mem: 15821
[23:59:46.749083] Test:  [180/345]  eta: 0:00:28  loss: 0.1018 (0.1078)  time: 0.1722  data: 0.0001  max mem: 15821
[23:59:48.476143] Test:  [190/345]  eta: 0:00:26  loss: 0.1004 (0.1076)  time: 0.1725  data: 0.0001  max mem: 15821
[23:59:50.205137] Test:  [200/345]  eta: 0:00:24  loss: 0.0928 (0.1071)  time: 0.1727  data: 0.0001  max mem: 15821
[23:59:51.938781] Test:  [210/345]  eta: 0:00:23  loss: 0.1023 (0.1077)  time: 0.1731  data: 0.0001  max mem: 15821
[23:59:53.675129] Test:  [220/345]  eta: 0:00:21  loss: 0.1023 (0.1074)  time: 0.1734  data: 0.0001  max mem: 15821
[23:59:55.415196] Test:  [230/345]  eta: 0:00:19  loss: 0.1024 (0.1080)  time: 0.1738  data: 0.0001  max mem: 15821
[23:59:57.158734] Test:  [240/345]  eta: 0:00:18  loss: 0.1024 (0.1077)  time: 0.1741  data: 0.0001  max mem: 15821
[23:59:58.906540] Test:  [250/345]  eta: 0:00:16  loss: 0.0996 (0.1076)  time: 0.1745  data: 0.0001  max mem: 15821
[00:00:00.657341] Test:  [260/345]  eta: 0:00:14  loss: 0.1083 (0.1079)  time: 0.1749  data: 0.0001  max mem: 15821
[00:00:02.411025] Test:  [270/345]  eta: 0:00:12  loss: 0.1096 (0.1081)  time: 0.1752  data: 0.0001  max mem: 15821
[00:00:04.169094] Test:  [280/345]  eta: 0:00:11  loss: 0.1085 (0.1082)  time: 0.1755  data: 0.0001  max mem: 15821
[00:00:05.929898] Test:  [290/345]  eta: 0:00:09  loss: 0.1051 (0.1082)  time: 0.1759  data: 0.0001  max mem: 15821
[00:00:07.693891] Test:  [300/345]  eta: 0:00:07  loss: 0.1057 (0.1085)  time: 0.1762  data: 0.0001  max mem: 15821
[00:00:09.461595] Test:  [310/345]  eta: 0:00:06  loss: 0.1024 (0.1084)  time: 0.1765  data: 0.0001  max mem: 15821
[00:00:11.233148] Test:  [320/345]  eta: 0:00:04  loss: 0.1021 (0.1082)  time: 0.1769  data: 0.0001  max mem: 15821
[00:00:13.009546] Test:  [330/345]  eta: 0:00:02  loss: 0.1068 (0.1084)  time: 0.1773  data: 0.0001  max mem: 15821
[00:00:14.788343] Test:  [340/345]  eta: 0:00:00  loss: 0.1052 (0.1085)  time: 0.1777  data: 0.0001  max mem: 15821
[00:00:15.501095] Test:  [344/345]  eta: 0:00:00  loss: 0.1036 (0.1084)  time: 0.1778  data: 0.0001  max mem: 15821
[00:00:15.567183] Test: Total time: 0:00:59 (0.1736 s / it)
[00:00:26.550412] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4952 (0.4952)  time: 0.5298  data: 0.3675  max mem: 15821
[00:00:28.194628] Test:  [10/57]  eta: 0:00:09  loss: 0.4271 (0.4598)  time: 0.1975  data: 0.0335  max mem: 15821
[00:00:29.844323] Test:  [20/57]  eta: 0:00:06  loss: 0.4271 (0.4510)  time: 0.1646  data: 0.0001  max mem: 15821
[00:00:31.498229] Test:  [30/57]  eta: 0:00:04  loss: 0.2900 (0.3856)  time: 0.1651  data: 0.0001  max mem: 15821
[00:00:33.157962] Test:  [40/57]  eta: 0:00:02  loss: 0.2387 (0.3583)  time: 0.1656  data: 0.0001  max mem: 15821
[00:00:34.822185] Test:  [50/57]  eta: 0:00:01  loss: 0.2893 (0.3523)  time: 0.1661  data: 0.0001  max mem: 15821
[00:00:35.720536] Test:  [56/57]  eta: 0:00:00  loss: 0.3213 (0.3652)  time: 0.1613  data: 0.0001  max mem: 15821
[00:00:35.795934] Test: Total time: 0:00:09 (0.1715 s / it)
[00:00:37.738177] Dice score of the network on the train images: 0.887645, val images: 0.796536
[00:00:37.742980] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[00:00:38.712110] Epoch: [45]  [  0/345]  eta: 0:05:33  lr: 0.000008  loss: 0.1047 (0.1047)  time: 0.9680  data: 0.3719  max mem: 15821
[00:00:50.683056] Epoch: [45]  [ 20/345]  eta: 0:03:20  lr: 0.000008  loss: 0.1095 (0.1112)  time: 0.5985  data: 0.0001  max mem: 15821
[00:01:02.801870] Epoch: [45]  [ 40/345]  eta: 0:03:06  lr: 0.000008  loss: 0.1125 (0.1126)  time: 0.6059  data: 0.0001  max mem: 15821
[00:01:14.827478] Epoch: [45]  [ 60/345]  eta: 0:02:53  lr: 0.000008  loss: 0.1127 (0.1141)  time: 0.6012  data: 0.0001  max mem: 15821
[00:01:26.877518] Epoch: [45]  [ 80/345]  eta: 0:02:40  lr: 0.000008  loss: 0.1034 (0.1137)  time: 0.6025  data: 0.0001  max mem: 15821
[00:01:38.957231] Epoch: [45]  [100/345]  eta: 0:02:28  lr: 0.000007  loss: 0.1104 (0.1139)  time: 0.6039  data: 0.0001  max mem: 15821
[00:01:51.044298] Epoch: [45]  [120/345]  eta: 0:02:16  lr: 0.000007  loss: 0.1087 (0.1142)  time: 0.6043  data: 0.0001  max mem: 15821
[00:02:03.130956] Epoch: [45]  [140/345]  eta: 0:02:04  lr: 0.000007  loss: 0.1120 (0.1145)  time: 0.6043  data: 0.0001  max mem: 15821
[00:02:15.225963] Epoch: [45]  [160/345]  eta: 0:01:52  lr: 0.000007  loss: 0.1128 (0.1146)  time: 0.6047  data: 0.0001  max mem: 15821
[00:02:27.315215] Epoch: [45]  [180/345]  eta: 0:01:39  lr: 0.000007  loss: 0.1082 (0.1141)  time: 0.6044  data: 0.0001  max mem: 15821
[00:02:39.395469] Epoch: [45]  [200/345]  eta: 0:01:27  lr: 0.000007  loss: 0.1006 (0.1132)  time: 0.6040  data: 0.0001  max mem: 15821
[00:02:51.457039] Epoch: [45]  [220/345]  eta: 0:01:15  lr: 0.000006  loss: 0.1116 (0.1136)  time: 0.6030  data: 0.0001  max mem: 15821
[00:03:03.531590] Epoch: [45]  [240/345]  eta: 0:01:03  lr: 0.000006  loss: 0.1077 (0.1132)  time: 0.6037  data: 0.0001  max mem: 15821
[00:03:15.609350] Epoch: [45]  [260/345]  eta: 0:00:51  lr: 0.000006  loss: 0.1183 (0.1134)  time: 0.6038  data: 0.0001  max mem: 15821
[00:03:27.755873] Epoch: [45]  [280/345]  eta: 0:00:39  lr: 0.000006  loss: 0.1063 (0.1139)  time: 0.6073  data: 0.0001  max mem: 15821
[00:03:39.814487] Epoch: [45]  [300/345]  eta: 0:00:27  lr: 0.000006  loss: 0.1051 (0.1137)  time: 0.6029  data: 0.0001  max mem: 15821
[00:03:51.883570] Epoch: [45]  [320/345]  eta: 0:00:15  lr: 0.000006  loss: 0.1136 (0.1137)  time: 0.6034  data: 0.0001  max mem: 15821
[00:04:03.941492] Epoch: [45]  [340/345]  eta: 0:00:03  lr: 0.000005  loss: 0.1120 (0.1139)  time: 0.6028  data: 0.0001  max mem: 15821
[00:04:06.352899] Epoch: [45]  [344/345]  eta: 0:00:00  lr: 0.000005  loss: 0.1183 (0.1140)  time: 0.6028  data: 0.0001  max mem: 15821
[00:04:06.434561] Epoch: [45] Total time: 0:03:28 (0.6049 s / it)
[00:04:06.435168] Averaged stats: lr: 0.000005  loss: 0.1183 (0.1140)
[00:04:07.025415] Test:  [  0/345]  eta: 0:03:21  loss: 0.0933 (0.0933)  time: 0.5833  data: 0.4185  max mem: 15821
[00:04:08.693597] Test:  [ 10/345]  eta: 0:01:08  loss: 0.0981 (0.1024)  time: 0.2046  data: 0.0381  max mem: 15821
[00:04:10.363132] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1002 (0.1015)  time: 0.1668  data: 0.0001  max mem: 15821
[00:04:12.036292] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1022 (0.1057)  time: 0.1671  data: 0.0001  max mem: 15821
[00:04:13.712131] Test:  [ 40/345]  eta: 0:00:54  loss: 0.1015 (0.1073)  time: 0.1674  data: 0.0001  max mem: 15821
[00:04:15.391237] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1074 (0.1088)  time: 0.1677  data: 0.0001  max mem: 15821
[00:04:17.073962] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1095 (0.1091)  time: 0.1680  data: 0.0001  max mem: 15821
[00:04:18.761024] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1126 (0.1091)  time: 0.1684  data: 0.0001  max mem: 15821
[00:04:20.451533] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1099 (0.1084)  time: 0.1688  data: 0.0001  max mem: 15821
[00:04:22.145589] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1041 (0.1086)  time: 0.1692  data: 0.0001  max mem: 15821
[00:04:23.841594] Test:  [100/345]  eta: 0:00:42  loss: 0.1082 (0.1092)  time: 0.1694  data: 0.0001  max mem: 15821
[00:04:25.541195] Test:  [110/345]  eta: 0:00:40  loss: 0.1107 (0.1096)  time: 0.1697  data: 0.0001  max mem: 15821
[00:04:27.244636] Test:  [120/345]  eta: 0:00:38  loss: 0.1096 (0.1097)  time: 0.1701  data: 0.0001  max mem: 15821
[00:04:28.950631] Test:  [130/345]  eta: 0:00:36  loss: 0.1051 (0.1099)  time: 0.1704  data: 0.0001  max mem: 15821
[00:04:30.660687] Test:  [140/345]  eta: 0:00:35  loss: 0.1035 (0.1096)  time: 0.1707  data: 0.0001  max mem: 15821
[00:04:32.374834] Test:  [150/345]  eta: 0:00:33  loss: 0.0979 (0.1089)  time: 0.1711  data: 0.0001  max mem: 15821
[00:04:34.092400] Test:  [160/345]  eta: 0:00:31  loss: 0.0928 (0.1081)  time: 0.1715  data: 0.0001  max mem: 15821
[00:04:35.813753] Test:  [170/345]  eta: 0:00:30  loss: 0.0992 (0.1081)  time: 0.1719  data: 0.0001  max mem: 15821
[00:04:37.537087] Test:  [180/345]  eta: 0:00:28  loss: 0.1025 (0.1079)  time: 0.1722  data: 0.0001  max mem: 15821
[00:04:39.263038] Test:  [190/345]  eta: 0:00:26  loss: 0.1027 (0.1078)  time: 0.1724  data: 0.0001  max mem: 15821
[00:04:40.995513] Test:  [200/345]  eta: 0:00:24  loss: 0.1007 (0.1074)  time: 0.1729  data: 0.0001  max mem: 15821
[00:04:42.730155] Test:  [210/345]  eta: 0:00:23  loss: 0.1024 (0.1074)  time: 0.1733  data: 0.0001  max mem: 15821
[00:04:44.467278] Test:  [220/345]  eta: 0:00:21  loss: 0.1032 (0.1072)  time: 0.1735  data: 0.0001  max mem: 15821
[00:04:46.208311] Test:  [230/345]  eta: 0:00:19  loss: 0.0992 (0.1073)  time: 0.1738  data: 0.0001  max mem: 15821
[00:04:47.951837] Test:  [240/345]  eta: 0:00:18  loss: 0.1083 (0.1073)  time: 0.1742  data: 0.0001  max mem: 15821
[00:04:49.698773] Test:  [250/345]  eta: 0:00:16  loss: 0.1067 (0.1074)  time: 0.1745  data: 0.0001  max mem: 15821
[00:04:51.449846] Test:  [260/345]  eta: 0:00:14  loss: 0.0983 (0.1071)  time: 0.1748  data: 0.0001  max mem: 15821
[00:04:53.203435] Test:  [270/345]  eta: 0:00:12  loss: 0.0988 (0.1071)  time: 0.1752  data: 0.0001  max mem: 15821
[00:04:54.962218] Test:  [280/345]  eta: 0:00:11  loss: 0.1017 (0.1070)  time: 0.1756  data: 0.0001  max mem: 15821
[00:04:56.724478] Test:  [290/345]  eta: 0:00:09  loss: 0.1017 (0.1069)  time: 0.1760  data: 0.0001  max mem: 15821
[00:04:58.489444] Test:  [300/345]  eta: 0:00:07  loss: 0.0953 (0.1067)  time: 0.1763  data: 0.0001  max mem: 15821
[00:05:00.258144] Test:  [310/345]  eta: 0:00:06  loss: 0.0977 (0.1071)  time: 0.1766  data: 0.0001  max mem: 15821
[00:05:02.031161] Test:  [320/345]  eta: 0:00:04  loss: 0.1012 (0.1072)  time: 0.1770  data: 0.0001  max mem: 15821
[00:05:03.808141] Test:  [330/345]  eta: 0:00:02  loss: 0.1075 (0.1073)  time: 0.1774  data: 0.0001  max mem: 15821
[00:05:05.587354] Test:  [340/345]  eta: 0:00:00  loss: 0.1106 (0.1073)  time: 0.1778  data: 0.0001  max mem: 15821
[00:05:06.300023] Test:  [344/345]  eta: 0:00:00  loss: 0.1051 (0.1074)  time: 0.1779  data: 0.0001  max mem: 15821
[00:05:06.380641] Test: Total time: 0:00:59 (0.1737 s / it)
[00:05:17.456251] Test:  [ 0/57]  eta: 0:00:32  loss: 0.4967 (0.4967)  time: 0.5786  data: 0.4160  max mem: 15821
[00:05:19.100961] Test:  [10/57]  eta: 0:00:09  loss: 0.4302 (0.4648)  time: 0.2020  data: 0.0379  max mem: 15821
[00:05:20.751695] Test:  [20/57]  eta: 0:00:06  loss: 0.4302 (0.4574)  time: 0.1647  data: 0.0001  max mem: 15821
[00:05:22.406738] Test:  [30/57]  eta: 0:00:04  loss: 0.2996 (0.3917)  time: 0.1652  data: 0.0001  max mem: 15821
[00:05:24.068060] Test:  [40/57]  eta: 0:00:02  loss: 0.2435 (0.3653)  time: 0.1658  data: 0.0001  max mem: 15821
[00:05:25.734541] Test:  [50/57]  eta: 0:00:01  loss: 0.3021 (0.3596)  time: 0.1663  data: 0.0001  max mem: 15821
[00:05:26.632442] Test:  [56/57]  eta: 0:00:00  loss: 0.3275 (0.3718)  time: 0.1614  data: 0.0000  max mem: 15821
[00:05:26.697748] Test: Total time: 0:00:09 (0.1723 s / it)
[00:05:28.624940] Dice score of the network on the train images: 0.890556, val images: 0.793718
[00:05:28.629033] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[00:05:29.596772] Epoch: [46]  [  0/345]  eta: 0:05:33  lr: 0.000005  loss: 0.1154 (0.1154)  time: 0.9668  data: 0.3678  max mem: 15821
[00:05:41.565994] Epoch: [46]  [ 20/345]  eta: 0:03:20  lr: 0.000005  loss: 0.1054 (0.1108)  time: 0.5984  data: 0.0001  max mem: 15821
[00:05:53.568783] Epoch: [46]  [ 40/345]  eta: 0:03:05  lr: 0.000005  loss: 0.1100 (0.1127)  time: 0.6001  data: 0.0001  max mem: 15821
[00:06:05.595845] Epoch: [46]  [ 60/345]  eta: 0:02:52  lr: 0.000005  loss: 0.1069 (0.1120)  time: 0.6013  data: 0.0001  max mem: 15821
[00:06:17.634902] Epoch: [46]  [ 80/345]  eta: 0:02:40  lr: 0.000005  loss: 0.1165 (0.1137)  time: 0.6019  data: 0.0001  max mem: 15821
[00:06:29.704542] Epoch: [46]  [100/345]  eta: 0:02:28  lr: 0.000005  loss: 0.1084 (0.1132)  time: 0.6034  data: 0.0001  max mem: 15821
[00:06:41.796290] Epoch: [46]  [120/345]  eta: 0:02:16  lr: 0.000005  loss: 0.1127 (0.1131)  time: 0.6045  data: 0.0001  max mem: 15821
[00:06:53.888119] Epoch: [46]  [140/345]  eta: 0:02:03  lr: 0.000004  loss: 0.1076 (0.1131)  time: 0.6045  data: 0.0001  max mem: 15821

[00:07:05.971287] Epoch: [46]  [160/345]  eta: 0:01:51  lr: 0.000004  loss: 0.1109 (0.1131)  time: 0.6041  data: 0.0001  max mem: 15821
[00:07:18.048662] Epoch: [46]  [180/345]  eta: 0:01:39  lr: 0.000004  loss: 0.1116 (0.1133)  time: 0.6038  data: 0.0001  max mem: 15821
[00:07:30.128514] Epoch: [46]  [200/345]  eta: 0:01:27  lr: 0.000004  loss: 0.1184 (0.1140)  time: 0.6039  data: 0.0001  max mem: 15821
[00:07:42.202711] Epoch: [46]  [220/345]  eta: 0:01:15  lr: 0.000004  loss: 0.1138 (0.1141)  time: 0.6037  data: 0.0001  max mem: 15821
[00:07:54.273966] Epoch: [46]  [240/345]  eta: 0:01:03  lr: 0.000004  loss: 0.1150 (0.1144)  time: 0.6035  data: 0.0001  max mem: 15821
[00:08:06.342892] Epoch: [46]  [260/345]  eta: 0:00:51  lr: 0.000004  loss: 0.1069 (0.1142)  time: 0.6034  data: 0.0001  max mem: 15821
[00:08:18.403401] Epoch: [46]  [280/345]  eta: 0:00:39  lr: 0.000003  loss: 0.1135 (0.1142)  time: 0.6030  data: 0.0001  max mem: 15821
[00:08:30.453511] Epoch: [46]  [300/345]  eta: 0:00:27  lr: 0.000003  loss: 0.1105 (0.1141)  time: 0.6025  data: 0.0001  max mem: 15821
[00:08:42.515413] Epoch: [46]  [320/345]  eta: 0:00:15  lr: 0.000003  loss: 0.1025 (0.1136)  time: 0.6030  data: 0.0001  max mem: 15821
[00:08:54.558041] Epoch: [46]  [340/345]  eta: 0:00:03  lr: 0.000003  loss: 0.1032 (0.1132)  time: 0.6021  data: 0.0001  max mem: 15821
[00:08:56.966446] Epoch: [46]  [344/345]  eta: 0:00:00  lr: 0.000003  loss: 0.1037 (0.1131)  time: 0.6018  data: 0.0001  max mem: 15821
[00:08:57.046416] Epoch: [46] Total time: 0:03:28 (0.6041 s / it)
[00:08:57.047000] Averaged stats: lr: 0.000003  loss: 0.1037 (0.1131)
[00:08:57.622039] Test:  [  0/345]  eta: 0:03:16  loss: 0.0948 (0.0948)  time: 0.5709  data: 0.4069  max mem: 15821
[00:08:59.288262] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1066 (0.1111)  time: 0.2033  data: 0.0371  max mem: 15821
[00:09:00.957650] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1002 (0.1056)  time: 0.1667  data: 0.0001  max mem: 15821
[00:09:02.630637] Test:  [ 30/345]  eta: 0:00:56  loss: 0.0967 (0.1082)  time: 0.1670  data: 0.0001  max mem: 15821
[00:09:04.307447] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1084 (0.1080)  time: 0.1674  data: 0.0001  max mem: 15821
[00:09:05.987182] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1079 (0.1085)  time: 0.1678  data: 0.0001  max mem: 15821
[00:09:07.669588] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1099 (0.1091)  time: 0.1680  data: 0.0001  max mem: 15821
[00:09:09.357379] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1071 (0.1085)  time: 0.1684  data: 0.0001  max mem: 15821
[00:09:11.046298] Test:  [ 80/345]  eta: 0:00:45  loss: 0.0979 (0.1075)  time: 0.1688  data: 0.0001  max mem: 15821
[00:09:12.741413] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1000 (0.1074)  time: 0.1691  data: 0.0001  max mem: 15821
[00:09:14.438132] Test:  [100/345]  eta: 0:00:42  loss: 0.1054 (0.1071)  time: 0.1695  data: 0.0001  max mem: 15821
[00:09:16.137495] Test:  [110/345]  eta: 0:00:40  loss: 0.1094 (0.1074)  time: 0.1697  data: 0.0001  max mem: 15821
[00:09:17.841670] Test:  [120/345]  eta: 0:00:38  loss: 0.1058 (0.1072)  time: 0.1701  data: 0.0001  max mem: 15821
[00:09:19.547889] Test:  [130/345]  eta: 0:00:36  loss: 0.1046 (0.1074)  time: 0.1705  data: 0.0001  max mem: 15821
[00:09:21.259415] Test:  [140/345]  eta: 0:00:35  loss: 0.1054 (0.1078)  time: 0.1708  data: 0.0001  max mem: 15821
[00:09:22.972429] Test:  [150/345]  eta: 0:00:33  loss: 0.1017 (0.1071)  time: 0.1711  data: 0.0001  max mem: 15821
[00:09:24.690526] Test:  [160/345]  eta: 0:00:31  loss: 0.1015 (0.1073)  time: 0.1715  data: 0.0001  max mem: 15821
[00:09:26.411101] Test:  [170/345]  eta: 0:00:30  loss: 0.0991 (0.1074)  time: 0.1719  data: 0.0001  max mem: 15821
[00:09:28.135565] Test:  [180/345]  eta: 0:00:28  loss: 0.0984 (0.1071)  time: 0.1722  data: 0.0001  max mem: 15821
[00:09:29.862660] Test:  [190/345]  eta: 0:00:26  loss: 0.0963 (0.1067)  time: 0.1725  data: 0.0001  max mem: 15821
[00:09:31.593217] Test:  [200/345]  eta: 0:00:24  loss: 0.1036 (0.1068)  time: 0.1728  data: 0.0001  max mem: 15821
[00:09:33.327950] Test:  [210/345]  eta: 0:00:23  loss: 0.1059 (0.1075)  time: 0.1732  data: 0.0001  max mem: 15821
[00:09:35.064480] Test:  [220/345]  eta: 0:00:21  loss: 0.1079 (0.1076)  time: 0.1735  data: 0.0001  max mem: 15821
[00:09:36.806326] Test:  [230/345]  eta: 0:00:19  loss: 0.1057 (0.1077)  time: 0.1739  data: 0.0001  max mem: 15821
[00:09:38.550269] Test:  [240/345]  eta: 0:00:18  loss: 0.1022 (0.1075)  time: 0.1742  data: 0.0001  max mem: 15821
[00:09:40.298724] Test:  [250/345]  eta: 0:00:16  loss: 0.1009 (0.1072)  time: 0.1746  data: 0.0001  max mem: 15821
[00:09:42.049277] Test:  [260/345]  eta: 0:00:14  loss: 0.1011 (0.1071)  time: 0.1749  data: 0.0001  max mem: 15821
[00:09:43.804095] Test:  [270/345]  eta: 0:00:12  loss: 0.1033 (0.1072)  time: 0.1752  data: 0.0001  max mem: 15821
[00:09:45.562279] Test:  [280/345]  eta: 0:00:11  loss: 0.1011 (0.1071)  time: 0.1756  data: 0.0001  max mem: 15821
[00:09:47.325582] Test:  [290/345]  eta: 0:00:09  loss: 0.1011 (0.1070)  time: 0.1760  data: 0.0001  max mem: 15821
[00:09:49.089036] Test:  [300/345]  eta: 0:00:07  loss: 0.1016 (0.1069)  time: 0.1763  data: 0.0001  max mem: 15821
[00:09:50.858764] Test:  [310/345]  eta: 0:00:06  loss: 0.1011 (0.1069)  time: 0.1766  data: 0.0001  max mem: 15821
[00:09:52.629845] Test:  [320/345]  eta: 0:00:04  loss: 0.1059 (0.1068)  time: 0.1770  data: 0.0001  max mem: 15821
[00:09:54.404635] Test:  [330/345]  eta: 0:00:02  loss: 0.1068 (0.1069)  time: 0.1772  data: 0.0001  max mem: 15821
[00:09:56.182766] Test:  [340/345]  eta: 0:00:00  loss: 0.1065 (0.1068)  time: 0.1776  data: 0.0001  max mem: 15821
[00:09:56.895761] Test:  [344/345]  eta: 0:00:00  loss: 0.1079 (0.1069)  time: 0.1777  data: 0.0001  max mem: 15821
[00:09:56.981360] Test: Total time: 0:00:59 (0.1737 s / it)
[00:10:08.039478] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4989 (0.4989)  time: 0.5472  data: 0.3851  max mem: 15821
[00:10:09.683293] Test:  [10/57]  eta: 0:00:09  loss: 0.4300 (0.4615)  time: 0.1991  data: 0.0351  max mem: 15821
[00:10:11.332742] Test:  [20/57]  eta: 0:00:06  loss: 0.4300 (0.4542)  time: 0.1646  data: 0.0001  max mem: 15821
[00:10:12.986741] Test:  [30/57]  eta: 0:00:04  loss: 0.2947 (0.3885)  time: 0.1651  data: 0.0001  max mem: 15821
[00:10:14.646775] Test:  [40/57]  eta: 0:00:02  loss: 0.2410 (0.3614)  time: 0.1656  data: 0.0001  max mem: 15821
[00:10:16.310702] Test:  [50/57]  eta: 0:00:01  loss: 0.2934 (0.3557)  time: 0.1661  data: 0.0001  max mem: 15821
[00:10:17.209007] Test:  [56/57]  eta: 0:00:00  loss: 0.3219 (0.3681)  time: 0.1613  data: 0.0001  max mem: 15821
[00:10:17.279534] Test: Total time: 0:00:09 (0.1717 s / it)
[00:10:19.176234] Dice score of the network on the train images: 0.888993, val images: 0.795719
[00:10:19.180518] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft

[00:10:20.181661] Epoch: [47]  [  0/345]  eta: 0:05:45  lr: 0.000003  loss: 0.1187 (0.1187)  time: 1.0001  data: 0.4016  max mem: 15821
[00:10:32.145729] Epoch: [47]  [ 20/345]  eta: 0:03:20  lr: 0.000003  loss: 0.1031 (0.1071)  time: 0.5981  data: 0.0001  max mem: 15821
[00:10:44.147020] Epoch: [47]  [ 40/345]  eta: 0:03:05  lr: 0.000003  loss: 0.1083 (0.1087)  time: 0.6000  data: 0.0001  max mem: 15821
[00:10:56.160656] Epoch: [47]  [ 60/345]  eta: 0:02:52  lr: 0.000003  loss: 0.1145 (0.1110)  time: 0.6006  data: 0.0001  max mem: 15821
[00:11:08.204583] Epoch: [47]  [ 80/345]  eta: 0:02:40  lr: 0.000003  loss: 0.1076 (0.1110)  time: 0.6021  data: 0.0001  max mem: 15821

[00:11:20.263972] Epoch: [47]  [100/345]  eta: 0:02:28  lr: 0.000003  loss: 0.1043 (0.1109)  time: 0.6029  data: 0.0001  max mem: 15821
[00:11:32.337972] Epoch: [47]  [120/345]  eta: 0:02:16  lr: 0.000002  loss: 0.1045 (0.1107)  time: 0.6036  data: 0.0001  max mem: 15821
[00:11:44.426995] Epoch: [47]  [140/345]  eta: 0:02:03  lr: 0.000002  loss: 0.1182 (0.1118)  time: 0.6044  data: 0.0001  max mem: 15821
[00:11:56.517060] Epoch: [47]  [160/345]  eta: 0:01:51  lr: 0.000002  loss: 0.1072 (0.1120)  time: 0.6044  data: 0.0001  max mem: 15821
[00:12:08.614063] Epoch: [47]  [180/345]  eta: 0:01:39  lr: 0.000002  loss: 0.1080 (0.1118)  time: 0.6048  data: 0.0001  max mem: 15821
[00:12:20.695341] Epoch: [47]  [200/345]  eta: 0:01:27  lr: 0.000002  loss: 0.1145 (0.1126)  time: 0.6040  data: 0.0001  max mem: 15821
[00:12:32.762303] Epoch: [47]  [220/345]  eta: 0:01:15  lr: 0.000002  loss: 0.1107 (0.1123)  time: 0.6033  data: 0.0001  max mem: 15821
[00:12:44.833693] Epoch: [47]  [240/345]  eta: 0:01:03  lr: 0.000002  loss: 0.1035 (0.1121)  time: 0.6035  data: 0.0001  max mem: 15821
[00:12:56.899393] Epoch: [47]  [260/345]  eta: 0:00:51  lr: 0.000002  loss: 0.1108 (0.1130)  time: 0.6032  data: 0.0001  max mem: 15821
[00:13:08.967248] Epoch: [47]  [280/345]  eta: 0:00:39  lr: 0.000002  loss: 0.1089 (0.1128)  time: 0.6033  data: 0.0001  max mem: 15821
[00:13:21.027845] Epoch: [47]  [300/345]  eta: 0:00:27  lr: 0.000002  loss: 0.1063 (0.1125)  time: 0.6030  data: 0.0001  max mem: 15821
[00:13:33.092296] Epoch: [47]  [320/345]  eta: 0:00:15  lr: 0.000001  loss: 0.1106 (0.1125)  time: 0.6032  data: 0.0001  max mem: 15821
[00:13:45.146441] Epoch: [47]  [340/345]  eta: 0:00:03  lr: 0.000001  loss: 0.1041 (0.1122)  time: 0.6027  data: 0.0001  max mem: 15821
[00:13:47.559028] Epoch: [47]  [344/345]  eta: 0:00:00  lr: 0.000001  loss: 0.1041 (0.1123)  time: 0.6027  data: 0.0001  max mem: 15821
[00:13:47.637219] Epoch: [47] Total time: 0:03:28 (0.6042 s / it)
[00:13:47.637594] Averaged stats: lr: 0.000001  loss: 0.1041 (0.1123)
[00:13:48.224074] Test:  [  0/345]  eta: 0:03:20  loss: 0.0832 (0.0832)  time: 0.5799  data: 0.4155  max mem: 15821
[00:13:49.890178] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1108 (0.1058)  time: 0.2041  data: 0.0379  max mem: 15821
[00:13:51.558988] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1033 (0.1096)  time: 0.1667  data: 0.0001  max mem: 15821
[00:13:53.230101] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1033 (0.1097)  time: 0.1669  data: 0.0001  max mem: 15821
[00:13:54.904875] Test:  [ 40/345]  eta: 0:00:53  loss: 0.1071 (0.1088)  time: 0.1672  data: 0.0001  max mem: 15821
[00:13:56.584270] Test:  [ 50/345]  eta: 0:00:51  loss: 0.0995 (0.1069)  time: 0.1676  data: 0.0001  max mem: 15821
[00:13:58.265262] Test:  [ 60/345]  eta: 0:00:49  loss: 0.0995 (0.1061)  time: 0.1680  data: 0.0001  max mem: 15821
[00:13:59.949184] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1020 (0.1057)  time: 0.1682  data: 0.0001  max mem: 15821
[00:14:01.637200] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1020 (0.1060)  time: 0.1685  data: 0.0001  max mem: 15821
[00:14:03.330849] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1018 (0.1060)  time: 0.1690  data: 0.0001  max mem: 15821
[00:14:05.026605] Test:  [100/345]  eta: 0:00:42  loss: 0.0978 (0.1054)  time: 0.1694  data: 0.0001  max mem: 15821
[00:14:06.727221] Test:  [110/345]  eta: 0:00:40  loss: 0.1034 (0.1052)  time: 0.1698  data: 0.0001  max mem: 15821
[00:14:08.430473] Test:  [120/345]  eta: 0:00:38  loss: 0.1034 (0.1057)  time: 0.1701  data: 0.0001  max mem: 15821
[00:14:10.137745] Test:  [130/345]  eta: 0:00:36  loss: 0.0978 (0.1053)  time: 0.1704  data: 0.0001  max mem: 15821
[00:14:11.847530] Test:  [140/345]  eta: 0:00:35  loss: 0.1055 (0.1058)  time: 0.1708  data: 0.0001  max mem: 15821
[00:14:13.560381] Test:  [150/345]  eta: 0:00:33  loss: 0.1135 (0.1066)  time: 0.1711  data: 0.0001  max mem: 15821
[00:14:15.276289] Test:  [160/345]  eta: 0:00:31  loss: 0.1091 (0.1068)  time: 0.1714  data: 0.0001  max mem: 15821
[00:14:16.998368] Test:  [170/345]  eta: 0:00:30  loss: 0.1024 (0.1064)  time: 0.1718  data: 0.0001  max mem: 15821
[00:14:18.722131] Test:  [180/345]  eta: 0:00:28  loss: 0.0998 (0.1062)  time: 0.1722  data: 0.0001  max mem: 15821
[00:14:20.448756] Test:  [190/345]  eta: 0:00:26  loss: 0.0998 (0.1061)  time: 0.1725  data: 0.0001  max mem: 15821
[00:14:22.180168] Test:  [200/345]  eta: 0:00:24  loss: 0.1012 (0.1063)  time: 0.1728  data: 0.0001  max mem: 15821
[00:14:23.913375] Test:  [210/345]  eta: 0:00:23  loss: 0.1016 (0.1062)  time: 0.1732  data: 0.0001  max mem: 15821
[00:14:25.651061] Test:  [220/345]  eta: 0:00:21  loss: 0.1020 (0.1062)  time: 0.1735  data: 0.0001  max mem: 15821
[00:14:27.392456] Test:  [230/345]  eta: 0:00:19  loss: 0.1020 (0.1062)  time: 0.1739  data: 0.0001  max mem: 15821
[00:14:29.137392] Test:  [240/345]  eta: 0:00:18  loss: 0.1009 (0.1062)  time: 0.1743  data: 0.0001  max mem: 15821
[00:14:30.885410] Test:  [250/345]  eta: 0:00:16  loss: 0.1009 (0.1063)  time: 0.1746  data: 0.0001  max mem: 15821
[00:14:32.634867] Test:  [260/345]  eta: 0:00:14  loss: 0.0981 (0.1059)  time: 0.1748  data: 0.0001  max mem: 15821
[00:14:34.388979] Test:  [270/345]  eta: 0:00:12  loss: 0.1002 (0.1058)  time: 0.1751  data: 0.0001  max mem: 15821
[00:14:36.147001] Test:  [280/345]  eta: 0:00:11  loss: 0.1039 (0.1061)  time: 0.1755  data: 0.0001  max mem: 15821
[00:14:37.907824] Test:  [290/345]  eta: 0:00:09  loss: 0.1043 (0.1063)  time: 0.1759  data: 0.0001  max mem: 15821
[00:14:39.671775] Test:  [300/345]  eta: 0:00:07  loss: 0.1111 (0.1065)  time: 0.1762  data: 0.0001  max mem: 15821
[00:14:41.440097] Test:  [310/345]  eta: 0:00:06  loss: 0.1111 (0.1067)  time: 0.1766  data: 0.0001  max mem: 15821
[00:14:43.212761] Test:  [320/345]  eta: 0:00:04  loss: 0.0973 (0.1063)  time: 0.1770  data: 0.0001  max mem: 15821
[00:14:44.988590] Test:  [330/345]  eta: 0:00:02  loss: 0.0973 (0.1064)  time: 0.1774  data: 0.0001  max mem: 15821
[00:14:46.768422] Test:  [340/345]  eta: 0:00:00  loss: 0.1084 (0.1065)  time: 0.1777  data: 0.0001  max mem: 15821
[00:14:47.481699] Test:  [344/345]  eta: 0:00:00  loss: 0.1084 (0.1065)  time: 0.1779  data: 0.0001  max mem: 15821
[00:14:47.553916] Test: Total time: 0:00:59 (0.1737 s / it)
[00:14:58.588185] Test:  [ 0/57]  eta: 0:00:31  loss: 0.5015 (0.5015)  time: 0.5448  data: 0.3825  max mem: 15821
[00:15:00.231271] Test:  [10/57]  eta: 0:00:09  loss: 0.4279 (0.4629)  time: 0.1988  data: 0.0349  max mem: 15821
[00:15:01.881257] Test:  [20/57]  eta: 0:00:06  loss: 0.4279 (0.4551)  time: 0.1646  data: 0.0001  max mem: 15821
[00:15:03.537996] Test:  [30/57]  eta: 0:00:04  loss: 0.2955 (0.3893)  time: 0.1653  data: 0.0001  max mem: 15821
[00:15:05.198507] Test:  [40/57]  eta: 0:00:02  loss: 0.2416 (0.3624)  time: 0.1658  data: 0.0001  max mem: 15821
[00:15:06.862402] Test:  [50/57]  eta: 0:00:01  loss: 0.2952 (0.3569)  time: 0.1662  data: 0.0001  max mem: 15821
[00:15:07.759803] Test:  [56/57]  eta: 0:00:00  loss: 0.3285 (0.3694)  time: 0.1613  data: 0.0000  max mem: 15821
[00:15:07.834540] Test: Total time: 0:00:09 (0.1718 s / it)
[00:15:09.741351] Dice score of the network on the train images: 0.889490, val images: 0.794976
[00:15:09.745667] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[00:15:10.761649] Epoch: [48]  [  0/345]  eta: 0:05:50  lr: 0.000001  loss: 0.0923 (0.0923)  time: 1.0149  data: 0.4161  max mem: 15821
[00:15:22.735447] Epoch: [48]  [ 20/345]  eta: 0:03:20  lr: 0.000001  loss: 0.1092 (0.1128)  time: 0.5986  data: 0.0001  max mem: 15821
[00:15:34.731266] Epoch: [48]  [ 40/345]  eta: 0:03:05  lr: 0.000001  loss: 0.1050 (0.1118)  time: 0.5997  data: 0.0001  max mem: 15821
[00:15:46.740289] Epoch: [48]  [ 60/345]  eta: 0:02:52  lr: 0.000001  loss: 0.1084 (0.1121)  time: 0.6004  data: 0.0001  max mem: 15821
[00:15:58.771340] Epoch: [48]  [ 80/345]  eta: 0:02:40  lr: 0.000001  loss: 0.1031 (0.1104)  time: 0.6015  data: 0.0001  max mem: 15821
[00:16:10.842161] Epoch: [48]  [100/345]  eta: 0:02:28  lr: 0.000001  loss: 0.1056 (0.1106)  time: 0.6035  data: 0.0001  max mem: 15821
[00:16:22.916352] Epoch: [48]  [120/345]  eta: 0:02:16  lr: 0.000001  loss: 0.1109 (0.1110)  time: 0.6037  data: 0.0001  max mem: 15821
[00:16:34.999371] Epoch: [48]  [140/345]  eta: 0:02:03  lr: 0.000001  loss: 0.1157 (0.1122)  time: 0.6041  data: 0.0001  max mem: 15821
[00:16:47.075276] Epoch: [48]  [160/345]  eta: 0:01:51  lr: 0.000001  loss: 0.1038 (0.1113)  time: 0.6037  data: 0.0001  max mem: 15821
[00:16:59.163258] Epoch: [48]  [180/345]  eta: 0:01:39  lr: 0.000001  loss: 0.1086 (0.1112)  time: 0.6044  data: 0.0001  max mem: 15821
[00:17:11.233199] Epoch: [48]  [200/345]  eta: 0:01:27  lr: 0.000001  loss: 0.1078 (0.1116)  time: 0.6035  data: 0.0001  max mem: 15821
[00:17:23.306111] Epoch: [48]  [220/345]  eta: 0:01:15  lr: 0.000001  loss: 0.1102 (0.1117)  time: 0.6036  data: 0.0001  max mem: 15821
[00:17:35.374118] Epoch: [48]  [240/345]  eta: 0:01:03  lr: 0.000001  loss: 0.1105 (0.1118)  time: 0.6034  data: 0.0001  max mem: 15821
[00:17:47.437165] Epoch: [48]  [260/345]  eta: 0:00:51  lr: 0.000001  loss: 0.1062 (0.1119)  time: 0.6031  data: 0.0001  max mem: 15821
[00:17:59.506861] Epoch: [48]  [280/345]  eta: 0:00:39  lr: 0.000000  loss: 0.1147 (0.1121)  time: 0.6034  data: 0.0001  max mem: 15821
[00:18:11.567505] Epoch: [48]  [300/345]  eta: 0:00:27  lr: 0.000000  loss: 0.1056 (0.1119)  time: 0.6030  data: 0.0001  max mem: 15821
[00:18:23.637023] Epoch: [48]  [320/345]  eta: 0:00:15  lr: 0.000000  loss: 0.1100 (0.1119)  time: 0.6034  data: 0.0001  max mem: 15821
[00:18:35.682656] Epoch: [48]  [340/345]  eta: 0:00:03  lr: 0.000000  loss: 0.1135 (0.1121)  time: 0.6022  data: 0.0001  max mem: 15821
[00:18:38.092779] Epoch: [48]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.1133 (0.1120)  time: 0.6022  data: 0.0001  max mem: 15821
[00:18:38.170452] Epoch: [48] Total time: 0:03:28 (0.6041 s / it)
[00:18:38.170663] Averaged stats: lr: 0.000000  loss: 0.1133 (0.1120)
[00:18:38.751139] Test:  [  0/345]  eta: 0:03:18  loss: 0.1100 (0.1100)  time: 0.5753  data: 0.4108  max mem: 15821
[00:18:40.418329] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1100 (0.1187)  time: 0.2038  data: 0.0374  max mem: 15821
[00:18:42.088587] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1041 (0.1102)  time: 0.1668  data: 0.0001  max mem: 15821
[00:18:43.762613] Test:  [ 30/345]  eta: 0:00:56  loss: 0.0981 (0.1069)  time: 0.1672  data: 0.0001  max mem: 15821
[00:18:45.438795] Test:  [ 40/345]  eta: 0:00:54  loss: 0.1010 (0.1061)  time: 0.1674  data: 0.0001  max mem: 15821
[00:18:47.118978] Test:  [ 50/345]  eta: 0:00:51  loss: 0.1012 (0.1069)  time: 0.1677  data: 0.0001  max mem: 15821
[00:18:48.802052] Test:  [ 60/345]  eta: 0:00:49  loss: 0.0981 (0.1060)  time: 0.1681  data: 0.0001  max mem: 15821
[00:18:50.488621] Test:  [ 70/345]  eta: 0:00:47  loss: 0.0998 (0.1066)  time: 0.1684  data: 0.0001  max mem: 15821
[00:18:52.177936] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1063 (0.1062)  time: 0.1687  data: 0.0001  max mem: 15821
[00:18:53.872128] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1100 (0.1068)  time: 0.1691  data: 0.0001  max mem: 15821
[00:18:55.568429] Test:  [100/345]  eta: 0:00:42  loss: 0.1012 (0.1065)  time: 0.1695  data: 0.0001  max mem: 15821
[00:18:57.267377] Test:  [110/345]  eta: 0:00:40  loss: 0.1000 (0.1066)  time: 0.1697  data: 0.0001  max mem: 15821
[00:18:58.970819] Test:  [120/345]  eta: 0:00:38  loss: 0.1060 (0.1069)  time: 0.1701  data: 0.0001  max mem: 15821
[00:19:00.678301] Test:  [130/345]  eta: 0:00:36  loss: 0.1035 (0.1069)  time: 0.1705  data: 0.0001  max mem: 15821
[00:19:02.389636] Test:  [140/345]  eta: 0:00:35  loss: 0.0975 (0.1064)  time: 0.1709  data: 0.0001  max mem: 15821
[00:19:04.103307] Test:  [150/345]  eta: 0:00:33  loss: 0.1039 (0.1070)  time: 0.1712  data: 0.0001  max mem: 15821
[00:19:05.819311] Test:  [160/345]  eta: 0:00:31  loss: 0.1093 (0.1074)  time: 0.1714  data: 0.0001  max mem: 15821
[00:19:07.540425] Test:  [170/345]  eta: 0:00:30  loss: 0.1079 (0.1074)  time: 0.1718  data: 0.0001  max mem: 15821
[00:19:09.264685] Test:  [180/345]  eta: 0:00:28  loss: 0.1041 (0.1073)  time: 0.1722  data: 0.0001  max mem: 15821
[00:19:10.992839] Test:  [190/345]  eta: 0:00:26  loss: 0.0980 (0.1072)  time: 0.1726  data: 0.0001  max mem: 15821
[00:19:12.723235] Test:  [200/345]  eta: 0:00:24  loss: 0.1019 (0.1073)  time: 0.1729  data: 0.0001  max mem: 15821
[00:19:14.457009] Test:  [210/345]  eta: 0:00:23  loss: 0.1060 (0.1073)  time: 0.1731  data: 0.0001  max mem: 15821
[00:19:16.195170] Test:  [220/345]  eta: 0:00:21  loss: 0.1060 (0.1073)  time: 0.1735  data: 0.0001  max mem: 15821
[00:19:17.936461] Test:  [230/345]  eta: 0:00:19  loss: 0.1069 (0.1072)  time: 0.1739  data: 0.0001  max mem: 15821
[00:19:19.680815] Test:  [240/345]  eta: 0:00:18  loss: 0.1059 (0.1070)  time: 0.1742  data: 0.0001  max mem: 15821
[00:19:21.429874] Test:  [250/345]  eta: 0:00:16  loss: 0.1041 (0.1072)  time: 0.1746  data: 0.0001  max mem: 15821
[00:19:23.180815] Test:  [260/345]  eta: 0:00:14  loss: 0.1037 (0.1069)  time: 0.1749  data: 0.0001  max mem: 15821
[00:19:24.935245] Test:  [270/345]  eta: 0:00:12  loss: 0.1023 (0.1069)  time: 0.1752  data: 0.0001  max mem: 15821
[00:19:26.693425] Test:  [280/345]  eta: 0:00:11  loss: 0.1049 (0.1067)  time: 0.1756  data: 0.0001  max mem: 15821
[00:19:28.454889] Test:  [290/345]  eta: 0:00:09  loss: 0.1004 (0.1065)  time: 0.1759  data: 0.0001  max mem: 15821
[00:19:30.219082] Test:  [300/345]  eta: 0:00:07  loss: 0.1000 (0.1065)  time: 0.1762  data: 0.0001  max mem: 15821
[00:19:31.988989] Test:  [310/345]  eta: 0:00:06  loss: 0.1044 (0.1067)  time: 0.1766  data: 0.0001  max mem: 15821
[00:19:33.762461] Test:  [320/345]  eta: 0:00:04  loss: 0.1044 (0.1066)  time: 0.1771  data: 0.0001  max mem: 15821
[00:19:35.539054] Test:  [330/345]  eta: 0:00:02  loss: 0.0985 (0.1064)  time: 0.1774  data: 0.0001  max mem: 15821
[00:19:37.320005] Test:  [340/345]  eta: 0:00:00  loss: 0.1018 (0.1064)  time: 0.1778  data: 0.0001  max mem: 15821
[00:19:38.033300] Test:  [344/345]  eta: 0:00:00  loss: 0.1018 (0.1063)  time: 0.1780  data: 0.0001  max mem: 15821
[00:19:38.102041] Test: Total time: 0:00:59 (0.1737 s / it)
[00:19:49.101670] Test:  [ 0/57]  eta: 0:00:31  loss: 0.5006 (0.5006)  time: 0.5449  data: 0.3828  max mem: 15821
[00:19:50.747441] Test:  [10/57]  eta: 0:00:09  loss: 0.4281 (0.4626)  time: 0.1991  data: 0.0349  max mem: 15821
[00:19:52.398092] Test:  [20/57]  eta: 0:00:06  loss: 0.4281 (0.4545)  time: 0.1647  data: 0.0001  max mem: 15821
[00:19:54.055164] Test:  [30/57]  eta: 0:00:04  loss: 0.2957 (0.3889)  time: 0.1653  data: 0.0001  max mem: 15821
[00:19:55.716374] Test:  [40/57]  eta: 0:00:02  loss: 0.2408 (0.3620)  time: 0.1658  data: 0.0001  max mem: 15821
[00:19:57.381459] Test:  [50/57]  eta: 0:00:01  loss: 0.2962 (0.3566)  time: 0.1663  data: 0.0001  max mem: 15821
[00:19:58.279875] Test:  [56/57]  eta: 0:00:00  loss: 0.3282 (0.3691)  time: 0.1614  data: 0.0001  max mem: 15821
[00:19:58.358483] Test: Total time: 0:00:09 (0.1720 s / it)
[00:20:00.268522] Dice score of the network on the train images: 0.889572, val images: 0.795136
[00:20:00.273336] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[00:20:01.271159] Epoch: [49]  [  0/345]  eta: 0:05:43  lr: 0.000000  loss: 0.0920 (0.0920)  time: 0.9966  data: 0.3957  max mem: 15821
[00:20:13.257834] Epoch: [49]  [ 20/345]  eta: 0:03:20  lr: 0.000000  loss: 0.1021 (0.1119)  time: 0.5993  data: 0.0001  max mem: 15821
[00:20:25.264816] Epoch: [49]  [ 40/345]  eta: 0:03:05  lr: 0.000000  loss: 0.1099 (0.1117)  time: 0.6003  data: 0.0001  max mem: 15821
[00:20:37.261080] Epoch: [49]  [ 60/345]  eta: 0:02:52  lr: 0.000000  loss: 0.1091 (0.1123)  time: 0.5998  data: 0.0001  max mem: 15821
[00:20:49.282689] Epoch: [49]  [ 80/345]  eta: 0:02:40  lr: 0.000000  loss: 0.1058 (0.1119)  time: 0.6010  data: 0.0001  max mem: 15821
[00:21:01.351601] Epoch: [49]  [100/345]  eta: 0:02:28  lr: 0.000000  loss: 0.1126 (0.1122)  time: 0.6034  data: 0.0001  max mem: 15821
[00:21:13.432379] Epoch: [49]  [120/345]  eta: 0:02:16  lr: 0.000000  loss: 0.1036 (0.1107)  time: 0.6040  data: 0.0001  max mem: 15821
[00:21:25.509934] Epoch: [49]  [140/345]  eta: 0:02:03  lr: 0.000000  loss: 0.1094 (0.1106)  time: 0.6038  data: 0.0001  max mem: 15821
[00:21:37.593044] Epoch: [49]  [160/345]  eta: 0:01:51  lr: 0.000000  loss: 0.1032 (0.1099)  time: 0.6041  data: 0.0001  max mem: 15821
[00:21:49.657926] Epoch: [49]  [180/345]  eta: 0:01:39  lr: 0.000000  loss: 0.1129 (0.1104)  time: 0.6032  data: 0.0001  max mem: 15821
[00:22:01.715868] Epoch: [49]  [200/345]  eta: 0:01:27  lr: 0.000000  loss: 0.1094 (0.1107)  time: 0.6028  data: 0.0001  max mem: 15821
[00:22:13.793927] Epoch: [49]  [220/345]  eta: 0:01:15  lr: 0.000000  loss: 0.1055 (0.1106)  time: 0.6038  data: 0.0001  max mem: 15821
[00:22:25.868453] Epoch: [49]  [240/345]  eta: 0:01:03  lr: 0.000000  loss: 0.1089 (0.1106)  time: 0.6037  data: 0.0001  max mem: 15821
[00:22:37.943922] Epoch: [49]  [260/345]  eta: 0:00:51  lr: 0.000000  loss: 0.1180 (0.1115)  time: 0.6037  data: 0.0001  max mem: 15821
[00:22:50.007309] Epoch: [49]  [280/345]  eta: 0:00:39  lr: 0.000000  loss: 0.1149 (0.1120)  time: 0.6031  data: 0.0001  max mem: 15821
[00:23:02.070130] Epoch: [49]  [300/345]  eta: 0:00:27  lr: 0.000000  loss: 0.1091 (0.1119)  time: 0.6031  data: 0.0001  max mem: 15821
[00:23:14.145328] Epoch: [49]  [320/345]  eta: 0:00:15  lr: 0.000000  loss: 0.1071 (0.1120)  time: 0.6037  data: 0.0001  max mem: 15821
[00:23:26.206026] Epoch: [49]  [340/345]  eta: 0:00:03  lr: 0.000000  loss: 0.1064 (0.1120)  time: 0.6030  data: 0.0001  max mem: 15821
[00:23:28.618915] Epoch: [49]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.1064 (0.1120)  time: 0.6027  data: 0.0001  max mem: 15821
[00:23:28.695975] Epoch: [49] Total time: 0:03:28 (0.6041 s / it)
[00:23:28.696098] Averaged stats: lr: 0.000000  loss: 0.1064 (0.1120)
[00:23:29.280346] Test:  [  0/345]  eta: 0:03:19  loss: 0.1085 (0.1085)  time: 0.5796  data: 0.4152  max mem: 15821
[00:23:30.947084] Test:  [ 10/345]  eta: 0:01:08  loss: 0.1085 (0.1081)  time: 0.2041  data: 0.0378  max mem: 15821
[00:23:32.617919] Test:  [ 20/345]  eta: 0:01:00  loss: 0.1057 (0.1053)  time: 0.1668  data: 0.0001  max mem: 15821
[00:23:34.290934] Test:  [ 30/345]  eta: 0:00:56  loss: 0.1057 (0.1091)  time: 0.1671  data: 0.0001  max mem: 15821
[00:23:35.967742] Test:  [ 40/345]  eta: 0:00:54  loss: 0.1040 (0.1062)  time: 0.1674  data: 0.0001  max mem: 15821
[00:23:37.646557] Test:  [ 50/345]  eta: 0:00:51  loss: 0.0938 (0.1054)  time: 0.1677  data: 0.0001  max mem: 15821
[00:23:39.330437] Test:  [ 60/345]  eta: 0:00:49  loss: 0.1016 (0.1062)  time: 0.1681  data: 0.0001  max mem: 15821
[00:23:41.016576] Test:  [ 70/345]  eta: 0:00:47  loss: 0.1078 (0.1064)  time: 0.1684  data: 0.0001  max mem: 15821
[00:23:42.704990] Test:  [ 80/345]  eta: 0:00:45  loss: 0.1032 (0.1058)  time: 0.1687  data: 0.0001  max mem: 15821
[00:23:44.398525] Test:  [ 90/345]  eta: 0:00:43  loss: 0.1008 (0.1057)  time: 0.1690  data: 0.0001  max mem: 15821
[00:23:46.094934] Test:  [100/345]  eta: 0:00:42  loss: 0.1027 (0.1050)  time: 0.1694  data: 0.0001  max mem: 15821
[00:23:47.794381] Test:  [110/345]  eta: 0:00:40  loss: 0.0989 (0.1048)  time: 0.1697  data: 0.0001  max mem: 15821
[00:23:49.497434] Test:  [120/345]  eta: 0:00:38  loss: 0.1027 (0.1051)  time: 0.1701  data: 0.0001  max mem: 15821
[00:23:51.204048] Test:  [130/345]  eta: 0:00:36  loss: 0.1027 (0.1052)  time: 0.1704  data: 0.0001  max mem: 15821
[00:23:52.914550] Test:  [140/345]  eta: 0:00:35  loss: 0.1015 (0.1054)  time: 0.1708  data: 0.0001  max mem: 15821
[00:23:54.629049] Test:  [150/345]  eta: 0:00:33  loss: 0.1001 (0.1051)  time: 0.1712  data: 0.0001  max mem: 15821
[00:23:56.346168] Test:  [160/345]  eta: 0:00:31  loss: 0.1058 (0.1061)  time: 0.1715  data: 0.0001  max mem: 15821
[00:23:58.067475] Test:  [170/345]  eta: 0:00:30  loss: 0.1019 (0.1057)  time: 0.1719  data: 0.0001  max mem: 15821
[00:23:59.792124] Test:  [180/345]  eta: 0:00:28  loss: 0.0987 (0.1055)  time: 0.1722  data: 0.0001  max mem: 15821
[00:24:01.519666] Test:  [190/345]  eta: 0:00:26  loss: 0.0957 (0.1049)  time: 0.1725  data: 0.0001  max mem: 15821
[00:24:03.251918] Test:  [200/345]  eta: 0:00:24  loss: 0.0943 (0.1051)  time: 0.1729  data: 0.0001  max mem: 15821
[00:24:04.985812] Test:  [210/345]  eta: 0:00:23  loss: 0.1002 (0.1049)  time: 0.1732  data: 0.0001  max mem: 15821
[00:24:06.722707] Test:  [220/345]  eta: 0:00:21  loss: 0.1045 (0.1052)  time: 0.1735  data: 0.0001  max mem: 15821
[00:24:08.464436] Test:  [230/345]  eta: 0:00:19  loss: 0.1081 (0.1056)  time: 0.1739  data: 0.0001  max mem: 15821
[00:24:10.207235] Test:  [240/345]  eta: 0:00:18  loss: 0.1120 (0.1058)  time: 0.1742  data: 0.0001  max mem: 15821
[00:24:11.955303] Test:  [250/345]  eta: 0:00:16  loss: 0.1036 (0.1057)  time: 0.1745  data: 0.0001  max mem: 15821
[00:24:13.707121] Test:  [260/345]  eta: 0:00:14  loss: 0.1004 (0.1057)  time: 0.1749  data: 0.0001  max mem: 15821
[00:24:15.463245] Test:  [270/345]  eta: 0:00:12  loss: 0.0994 (0.1053)  time: 0.1753  data: 0.0001  max mem: 15821
[00:24:17.220906] Test:  [280/345]  eta: 0:00:11  loss: 0.1040 (0.1055)  time: 0.1756  data: 0.0001  max mem: 15821
[00:24:18.983478] Test:  [290/345]  eta: 0:00:09  loss: 0.1081 (0.1056)  time: 0.1759  data: 0.0001  max mem: 15821
[00:24:20.748529] Test:  [300/345]  eta: 0:00:07  loss: 0.0994 (0.1054)  time: 0.1763  data: 0.0001  max mem: 15821
[00:24:22.518272] Test:  [310/345]  eta: 0:00:06  loss: 0.1023 (0.1057)  time: 0.1767  data: 0.0001  max mem: 15821
[00:24:24.291672] Test:  [320/345]  eta: 0:00:04  loss: 0.1031 (0.1055)  time: 0.1771  data: 0.0001  max mem: 15821
[00:24:26.069558] Test:  [330/345]  eta: 0:00:02  loss: 0.1025 (0.1058)  time: 0.1775  data: 0.0001  max mem: 15821
[00:24:27.849622] Test:  [340/345]  eta: 0:00:00  loss: 0.1034 (0.1059)  time: 0.1778  data: 0.0001  max mem: 15821
[00:24:28.561774] Test:  [344/345]  eta: 0:00:00  loss: 0.1086 (0.1061)  time: 0.1779  data: 0.0001  max mem: 15821
[00:24:28.635008] Test: Total time: 0:00:59 (0.1737 s / it)
[00:24:39.707750] Test:  [ 0/57]  eta: 0:00:30  loss: 0.5015 (0.5015)  time: 0.5374  data: 0.3753  max mem: 15821
[00:24:41.353841] Test:  [10/57]  eta: 0:00:09  loss: 0.4286 (0.4635)  time: 0.1984  data: 0.0342  max mem: 15821
[00:24:43.004492] Test:  [20/57]  eta: 0:00:06  loss: 0.4286 (0.4555)  time: 0.1648  data: 0.0001  max mem: 15821
[00:24:44.661923] Test:  [30/57]  eta: 0:00:04  loss: 0.2967 (0.3899)  time: 0.1653  data: 0.0001  max mem: 15821
[00:24:46.322641] Test:  [40/57]  eta: 0:00:02  loss: 0.2413 (0.3631)  time: 0.1658  data: 0.0001  max mem: 15821
[00:24:47.987195] Test:  [50/57]  eta: 0:00:01  loss: 0.2976 (0.3577)  time: 0.1662  data: 0.0001  max mem: 15821
[00:24:48.885743] Test:  [56/57]  eta: 0:00:00  loss: 0.3301 (0.3701)  time: 0.1613  data: 0.0001  max mem: 15821
[00:24:48.962206] Test: Total time: 0:00:09 (0.1718 s / it)
[00:24:50.908105] Dice score of the network on the train images: 0.890015, val images: 0.794658
[00:24:50.909592] Training time 4:02:32
[00:24:52.563055] Load pre-trained checkpoint from: /root/seg_framework/MS-Mamba/output_dir/mslesseg/checkpoints_0/checkpoint-best_dice_model_0.pth
[00:24:52.585269] <All keys matched successfully>
[00:24:55.694305] Test:  [  0/246]  eta: 0:12:25    time: 3.0322  data: 0.5548  max mem: 15821
[00:24:58.209191] Test:  [ 10/246]  eta: 0:01:58    time: 0.5042  data: 0.0505  max mem: 15821
[00:25:01.320773] ---------------------------------
[00:25:01.321005] Patient 1:
[00:25:01.321091]       precision: 0.44895777106285095
[00:25:01.321163]       recall: 0.5336721539497375
[00:25:01.321237]       dice_score: 0.48766326904296875
[00:25:01.324989] Test:  [ 20/246]  eta: 0:01:33    time: 0.2815  data: 0.0001  max mem: 15821
[00:25:03.836884] Test:  [ 30/246]  eta: 0:01:17    time: 0.2813  data: 0.0001  max mem: 15821
[00:25:06.920667] ---------------------------------
[00:25:06.920894] Patient 2:
[00:25:06.920977]       precision: 0.538886547088623
[00:25:06.921044]       recall: 0.62065589427948
[00:25:06.921104]       dice_score: 0.5768880844116211
[00:25:06.921645] Test:  [ 40/246]  eta: 0:01:11    time: 0.2798  data: 0.0001  max mem: 15821
[00:25:09.437870] Test:  [ 50/246]  eta: 0:01:04    time: 0.2800  data: 0.0001  max mem: 15821
[00:25:12.135879] Test:  [ 60/246]  eta: 0:00:59    time: 0.2607  data: 0.0001  max mem: 15821
[00:25:12.771908] ---------------------------------
[00:25:12.772145] Patient 3:
[00:25:12.772229]       precision: 0.3730650246143341
[00:25:12.772297]       recall: 0.5087071061134338
[00:25:12.772359]       dice_score: 0.43045324087142944
[00:25:15.022281] Test:  [ 70/246]  eta: 0:00:55    time: 0.2792  data: 0.0001  max mem: 15821
[00:25:17.723355] Test:  [ 80/246]  eta: 0:00:51    time: 0.2793  data: 0.0001  max mem: 15821
[00:25:18.387689] ---------------------------------
[00:25:18.387929] Patient 4:
[00:25:18.388012]       precision: 0.5792649388313293
[00:25:18.388079]       recall: 0.5168869495391846
[00:25:18.388143]       dice_score: 0.5463010668754578
[00:25:20.638939] Test:  [ 90/246]  eta: 0:00:47    time: 0.2808  data: 0.0001  max mem: 15821
[00:25:23.346269] Test:  [100/246]  eta: 0:00:44    time: 0.2811  data: 0.0001  max mem: 15821
[00:25:24.243806] ---------------------------------
[00:25:24.244025] Patient 5:
[00:25:24.244104]       precision: 0.4155421257019043
[00:25:24.244168]       recall: 0.4712401032447815
[00:25:24.244233]       dice_score: 0.4416419267654419
[00:25:26.229305] Test:  [110/246]  eta: 0:00:41    time: 0.2795  data: 0.0001  max mem: 15821
[00:25:28.939767] Test:  [120/246]  eta: 0:00:37    time: 0.2796  data: 0.0001  max mem: 15821
[00:25:29.881428] ---------------------------------
[00:25:29.881664] Patient 6:
[00:25:29.881742]       precision: 0.4177105724811554
[00:25:29.881806]       recall: 0.510290265083313
[00:25:29.881866]       dice_score: 0.45938241481781006
[00:25:31.868106] Test:  [130/246]  eta: 0:00:34    time: 0.2819  data: 0.0001  max mem: 15821
[00:25:34.579216] Test:  [140/246]  eta: 0:00:31    time: 0.2819  data: 0.0001  max mem: 15821
[00:25:35.768593] ---------------------------------
[00:25:35.768837] Patient 7:
[00:25:35.768912]       precision: 0.7880037426948547
[00:25:35.768973]       recall: 0.7951136827468872
[00:25:35.769031]       dice_score: 0.7915427088737488
[00:25:37.485844] Test:  [150/246]  eta: 0:00:28    time: 0.2808  data: 0.0001  max mem: 15821
[00:25:40.200083] Test:  [160/246]  eta: 0:00:25    time: 0.2810  data: 0.0001  max mem: 15821
[00:25:41.342999] ---------------------------------
[00:25:41.343263] Patient 8:
[00:25:41.343352]       precision: 0.8688260316848755
[00:25:41.343429]       recall: 0.5774710774421692
[00:25:41.343499]       dice_score: 0.693801999092102
[00:25:43.062029] Test:  [170/246]  eta: 0:00:22    time: 0.2788  data: 0.0001  max mem: 15821
[00:25:45.775495] Test:  [180/246]  eta: 0:00:19    time: 0.2787  data: 0.0001  max mem: 15821
[00:25:46.919588] ---------------------------------
[00:25:46.919776] Patient 9:
[00:25:46.919852]       precision: 0.7278081774711609
[00:25:46.919916]       recall: 0.8169529438018799
[00:25:46.919974]       dice_score: 0.7698084115982056
[00:25:48.647764] Test:  [190/246]  eta: 0:00:16    time: 0.2792  data: 0.0001  max mem: 15821
[00:25:51.364220] Test:  [200/246]  eta: 0:00:13    time: 0.2794  data: 0.0001  max mem: 15821
[00:25:52.785464] ---------------------------------
[00:25:52.785721] Patient 10:
[00:25:52.785810]       precision: 0.6659178733825684
[00:25:52.785885]       recall: 0.8749188184738159
[00:25:52.785955]       dice_score: 0.7562437653541565
[00:25:54.242987] Test:  [210/246]  eta: 0:00:10    time: 0.2797  data: 0.0001  max mem: 15821
[00:25:56.959293] Test:  [220/246]  eta: 0:00:07    time: 0.2797  data: 0.0001  max mem: 15821
[00:25:58.375974] ---------------------------------
[00:25:58.376225] Patient 11:
[00:25:58.376336]       precision: 0.889164924621582
[00:25:58.376418]       recall: 0.7401902675628662
[00:25:58.376479]       dice_score: 0.8078671097755432
[00:25:59.831949] Test:  [230/246]  eta: 0:00:04    time: 0.2794  data: 0.0001  max mem: 15821
[00:26:02.547154] Test:  [240/246]  eta: 0:00:01    time: 0.2793  data: 0.0001  max mem: 15821
[00:26:04.877574] ---------------------------------
[00:26:04.877828] Patient 12:
[00:26:04.877912]       precision: 0.6780876517295837
[00:26:04.877987]       recall: 0.7425829172134399
[00:26:04.878057]       dice_score: 0.7088713049888611
[00:26:04.878482] Test:  [245/246]  eta: 0:00:00    time: 0.3203  data: 0.0001  max mem: 15821
[00:26:04.971051] Test: Total time: 0:01:12 (0.2939 s / it)
[00:26:04.971234] ================================
[00:26:04.971296] Averaged over all patients:
[00:26:04.971561]       precision: 0.6159 ± 0.1734
[00:26:04.971693]       recall: 0.6424 ± 0.1367
[00:26:04.971816]       dice_score: 0.6225 ± 0.1406
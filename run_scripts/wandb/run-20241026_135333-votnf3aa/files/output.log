Not using distributed mode
[13:53:35.750443] job dir: /root/seg_framework/MS-Mamba/run_scripts
[13:53:35.750587] Namespace(accum_iter=1,
model='SegFormer3D',
in_channels=1,
lr=None,
blr=0.001,
min_lr=0,
dist_on_itp=False,
warmup_epochs=20,
device='cuda:0',
seed=42,
layer_decay=0.75,
clip_grad=None,
num_workers=1,
pin_mem=True,
resume='',
mask_mode='concatenate to image',
world_size=1,
embed_dim=1,
local_rank=-1,
dist_url='env://',
nb_classes=2,
data_dir='/root/MSLesSeg24/data',
datalist=None,
preprocess=False,
dim=2,
loss='mask tp1 tp2',
distributed=False)
[13:53:35.750701] device  cuda:0
[13:53:35.751373] Random seed set as 42
[13:53:35.751701] Starting for fold 0
[13:53:35.942648] Elements in data_dir_paths: 11052
[13:53:35.977130] Elements in data_dir_paths: 1803
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[13:53:37.821247] number of params: 47335447
[13:53:37.821498] model: Vivim2D(
  (encoder): mamba_block(
    (downsample_layers): SegformerEncoder(
      (patch_embeddings): ModuleList(
        (0): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(2, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (1): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (2): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (3): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (block): ModuleList(
        (0): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): Identity()
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.003703703870996833)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.007407407741993666)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.011111111380159855)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.014814815483987331)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.018518518656492233)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.02222222276031971)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (2): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.025925926864147186)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.029629630967974663)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03333333507180214)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03703703731298447)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04074074327945709)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04444444552063942)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.048148151487112045)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.051851850003004074)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0555555559694767)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.05925925821065903)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06296296417713165)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06666667014360428)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07037036865949631)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07407407462596893)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07777778059244156)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08148147910833359)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08518518507480621)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08888889104127884)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (3): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.09259259700775146)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0962962955236435)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.10000000149011612)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (layer_norm): ModuleList(
        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): SegformerDecodeHead(
    (linear_c): ModuleList(
      (0): SegformerMLP(
        (proj): Linear(in_features=64, out_features=768, bias=True)
      )
      (1): SegformerMLP(
        (proj): Linear(in_features=128, out_features=768, bias=True)
      )
      (2): SegformerMLP(
        (proj): Linear(in_features=320, out_features=768, bias=True)
      )
      (3): SegformerMLP(
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
    )
    (linear_fuse): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (batch_norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): ReLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Conv2d(768, 150, kernel_size=(1, 1), stride=(1, 1))
  )
  (out): Conv2d(768, 1, kernel_size=(1, 1), stride=(1, 1))
)
[13:53:37.823868] base lr: 1.00e-03
[13:53:37.823927] actual lr: 1.25e-04
[13:53:37.823981] accumulate grad iterations: 1
[13:53:37.824028] effective batch size: 32
[13:53:37.825253] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.000125
    maximize: False
    weight_decay: 0.01
)
[13:53:37.827500] Start training for 50 epochs
[13:53:37.828990] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:53:38.905172] Epoch: [0]  [  0/345]  eta: 0:06:10  lr: 0.000000  loss: 1.6960 (1.6960)  time: 1.0752  data: 0.2079  max mem: 10551
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
[13:53:43.776613] Epoch: [0]  [ 20/345]  eta: 0:01:32  lr: 0.000000  loss: 1.6900 (1.6908)  time: 0.2435  data: 0.0001  max mem: 10917
[13:53:48.636660] Epoch: [0]  [ 40/345]  eta: 0:01:20  lr: 0.000001  loss: 1.6888 (1.6902)  time: 0.2430  data: 0.0001  max mem: 10917
[13:53:53.492968] Epoch: [0]  [ 60/345]  eta: 0:01:13  lr: 0.000001  loss: 1.6859 (1.6889)  time: 0.2428  data: 0.0001  max mem: 10917
[13:53:58.361251] Epoch: [0]  [ 80/345]  eta: 0:01:07  lr: 0.000001  loss: 1.6809 (1.6870)  time: 0.2434  data: 0.0001  max mem: 10917
[13:54:03.241377] Epoch: [0]  [100/345]  eta: 0:01:01  lr: 0.000002  loss: 1.6779 (1.6852)  time: 0.2440  data: 0.0001  max mem: 10917
[13:54:08.129859] Epoch: [0]  [120/345]  eta: 0:00:56  lr: 0.000002  loss: 1.6719 (1.6830)  time: 0.2444  data: 0.0001  max mem: 10917
[13:54:13.024685] Epoch: [0]  [140/345]  eta: 0:00:51  lr: 0.000003  loss: 1.6633 (1.6804)  time: 0.2447  data: 0.0001  max mem: 10917
[13:54:17.935910] Epoch: [0]  [160/345]  eta: 0:00:46  lr: 0.000003  loss: 1.6554 (1.6773)  time: 0.2455  data: 0.0001  max mem: 10917
[13:54:22.869895] Epoch: [0]  [180/345]  eta: 0:00:41  lr: 0.000003  loss: 1.6421 (1.6736)  time: 0.2467  data: 0.0001  max mem: 10917
[13:54:27.814417] Epoch: [0]  [200/345]  eta: 0:00:36  lr: 0.000004  loss: 1.6268 (1.6690)  time: 0.2472  data: 0.0001  max mem: 10917
[13:54:32.766352] Epoch: [0]  [220/345]  eta: 0:00:31  lr: 0.000004  loss: 1.6131 (1.6640)  time: 0.2476  data: 0.0001  max mem: 10917
[13:54:37.725957] Epoch: [0]  [240/345]  eta: 0:00:26  lr: 0.000004  loss: 1.5986 (1.6588)  time: 0.2479  data: 0.0001  max mem: 10917
[13:54:42.697110] Epoch: [0]  [260/345]  eta: 0:00:21  lr: 0.000005  loss: 1.5842 (1.6531)  time: 0.2485  data: 0.0001  max mem: 10917
[13:54:47.672472] Epoch: [0]  [280/345]  eta: 0:00:16  lr: 0.000005  loss: 1.5702 (1.6472)  time: 0.2487  data: 0.0001  max mem: 10917
[13:54:52.653533] Epoch: [0]  [300/345]  eta: 0:00:11  lr: 0.000005  loss: 1.5530 (1.6409)  time: 0.2490  data: 0.0001  max mem: 10917

[13:54:57.642129] Epoch: [0]  [320/345]  eta: 0:00:06  lr: 0.000006  loss: 1.5361 (1.6344)  time: 0.2494  data: 0.0001  max mem: 10917
[13:55:02.638315] Epoch: [0]  [340/345]  eta: 0:00:01  lr: 0.000006  loss: 1.5210 (1.6278)  time: 0.2498  data: 0.0001  max mem: 10917
[13:55:03.636639] Epoch: [0]  [344/345]  eta: 0:00:00  lr: 0.000006  loss: 1.5196 (1.6265)  time: 0.2497  data: 0.0001  max mem: 10917
[13:55:03.692454] Epoch: [0] Total time: 0:01:25 (0.2489 s / it)
[13:55:03.692772] Averaged stats: lr: 0.000006  loss: 1.5196 (1.6265)
[13:55:03.932599] Test:  [  0/345]  eta: 0:01:21  loss: 1.5056 (1.5056)  time: 0.2364  data: 0.1572  max mem: 10917
[13:55:04.750400] Test:  [ 10/345]  eta: 0:00:32  loss: 1.5062 (1.5065)  time: 0.0958  data: 0.0149  max mem: 10917
[13:55:05.566978] Test:  [ 20/345]  eta: 0:00:28  loss: 1.5062 (1.5065)  time: 0.0816  data: 0.0004  max mem: 10917
[13:55:06.386596] Test:  [ 30/345]  eta: 0:00:27  loss: 1.5065 (1.5066)  time: 0.0818  data: 0.0001  max mem: 10917
[13:55:07.210123] Test:  [ 40/345]  eta: 0:00:26  loss: 1.5064 (1.5065)  time: 0.0821  data: 0.0001  max mem: 10917
[13:55:08.037936] Test:  [ 50/345]  eta: 0:00:25  loss: 1.5070 (1.5067)  time: 0.0825  data: 0.0001  max mem: 10917
[13:55:08.868165] Test:  [ 60/345]  eta: 0:00:24  loss: 1.5067 (1.5066)  time: 0.0829  data: 0.0001  max mem: 10917
[13:55:09.702347] Test:  [ 70/345]  eta: 0:00:23  loss: 1.5055 (1.5064)  time: 0.0832  data: 0.0001  max mem: 10917
[13:55:10.539701] Test:  [ 80/345]  eta: 0:00:22  loss: 1.5048 (1.5064)  time: 0.0835  data: 0.0001  max mem: 10917
[13:55:11.380744] Test:  [ 90/345]  eta: 0:00:21  loss: 1.5062 (1.5064)  time: 0.0839  data: 0.0001  max mem: 10917
[13:55:12.225467] Test:  [100/345]  eta: 0:00:20  loss: 1.5066 (1.5064)  time: 0.0842  data: 0.0001  max mem: 10917
[13:55:13.074881] Test:  [110/345]  eta: 0:00:19  loss: 1.5057 (1.5064)  time: 0.0847  data: 0.0001  max mem: 10917
[13:55:13.928507] Test:  [120/345]  eta: 0:00:19  loss: 1.5058 (1.5064)  time: 0.0851  data: 0.0001  max mem: 10917
[13:55:14.786218] Test:  [130/345]  eta: 0:00:18  loss: 1.5059 (1.5063)  time: 0.0855  data: 0.0001  max mem: 10917
[13:55:15.646416] Test:  [140/345]  eta: 0:00:17  loss: 1.5059 (1.5063)  time: 0.0858  data: 0.0001  max mem: 10917
[13:55:16.510239] Test:  [150/345]  eta: 0:00:16  loss: 1.5058 (1.5063)  time: 0.0862  data: 0.0001  max mem: 10917
[13:55:17.378338] Test:  [160/345]  eta: 0:00:15  loss: 1.5061 (1.5063)  time: 0.0865  data: 0.0001  max mem: 10917
[13:55:18.249739] Test:  [170/345]  eta: 0:00:14  loss: 1.5067 (1.5064)  time: 0.0869  data: 0.0001  max mem: 10917
[13:55:19.125607] Test:  [180/345]  eta: 0:00:14  loss: 1.5062 (1.5063)  time: 0.0873  data: 0.0001  max mem: 10917
[13:55:20.004264] Test:  [190/345]  eta: 0:00:13  loss: 1.5061 (1.5064)  time: 0.0877  data: 0.0001  max mem: 10917
[13:55:20.885970] Test:  [200/345]  eta: 0:00:12  loss: 1.5061 (1.5063)  time: 0.0880  data: 0.0001  max mem: 10917
[13:55:22.136278] Test:  [210/345]  eta: 0:00:11  loss: 1.5056 (1.5063)  time: 0.1066  data: 0.0001  max mem: 10917
[13:55:23.058792] Test:  [220/345]  eta: 0:00:10  loss: 1.5056 (1.5063)  time: 0.1086  data: 0.0001  max mem: 10917
[13:55:24.114458] Test:  [230/345]  eta: 0:00:10  loss: 1.5070 (1.5063)  time: 0.0989  data: 0.0001  max mem: 10917
[13:55:25.038803] Test:  [240/345]  eta: 0:00:09  loss: 1.5075 (1.5063)  time: 0.0990  data: 0.0001  max mem: 10917
[13:55:26.184380] Test:  [250/345]  eta: 0:00:08  loss: 1.5057 (1.5063)  time: 0.1034  data: 0.0001  max mem: 10917
[13:55:27.331338] Test:  [260/345]  eta: 0:00:07  loss: 1.5057 (1.5063)  time: 0.1146  data: 0.0001  max mem: 10917
[13:55:28.267462] Test:  [270/345]  eta: 0:00:06  loss: 1.5058 (1.5063)  time: 0.1041  data: 0.0001  max mem: 10917
[13:55:29.478194] Test:  [280/345]  eta: 0:00:05  loss: 1.5051 (1.5063)  time: 0.1073  data: 0.0001  max mem: 10917
[13:55:30.666494] Test:  [290/345]  eta: 0:00:05  loss: 1.5071 (1.5063)  time: 0.1199  data: 0.0001  max mem: 10917
[13:55:31.919511] Test:  [300/345]  eta: 0:00:04  loss: 1.5060 (1.5063)  time: 0.1220  data: 0.0001  max mem: 10917
[13:55:33.119655] Test:  [310/345]  eta: 0:00:03  loss: 1.5059 (1.5063)  time: 0.1226  data: 0.0001  max mem: 10917
[13:55:34.209813] Test:  [320/345]  eta: 0:00:02  loss: 1.5060 (1.5062)  time: 0.1145  data: 0.0001  max mem: 10917
[13:55:35.334988] Test:  [330/345]  eta: 0:00:01  loss: 1.5051 (1.5062)  time: 0.1107  data: 0.0001  max mem: 10917
[13:55:36.705863] Test:  [340/345]  eta: 0:00:00  loss: 1.5057 (1.5062)  time: 0.1248  data: 0.0001  max mem: 10917
[13:55:37.310523] Test:  [344/345]  eta: 0:00:00  loss: 1.5061 (1.5062)  time: 0.1283  data: 0.0001  max mem: 10917
[13:55:37.367907] Test: Total time: 0:00:33 (0.0976 s / it)
[13:55:48.015436] Test:  [ 0/57]  eta: 0:00:12  loss: 1.5115 (1.5115)  time: 0.2177  data: 0.1386  max mem: 10917
[13:55:48.826939] Test:  [10/57]  eta: 0:00:04  loss: 1.5087 (1.5089)  time: 0.0935  data: 0.0127  max mem: 10917
[13:55:49.640773] Test:  [20/57]  eta: 0:00:03  loss: 1.5093 (1.5080)  time: 0.0812  data: 0.0001  max mem: 10917
[13:55:50.458063] Test:  [30/57]  eta: 0:00:02  loss: 1.5080 (1.5048)  time: 0.0815  data: 0.0001  max mem: 10917
[13:55:51.280520] Test:  [40/57]  eta: 0:00:01  loss: 1.4966 (1.5025)  time: 0.0819  data: 0.0001  max mem: 10917
[13:55:52.105312] Test:  [50/57]  eta: 0:00:00  loss: 1.4966 (1.5016)  time: 0.0823  data: 0.0001  max mem: 10917
[13:55:52.580731] Test:  [56/57]  eta: 0:00:00  loss: 1.4989 (1.5016)  time: 0.0814  data: 0.0001  max mem: 10917
[13:55:52.637951] Test: Total time: 0:00:04 (0.0849 s / it)
[13:55:54.472815] Dice score of the network on the train images: 0.000000, val images: 0.000000
[13:55:54.473053] saving best_dice_model_0 @ epoch 0
[13:55:55.157645] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:55:55.557554] Epoch: [1]  [  0/345]  eta: 0:02:17  lr: 0.000006  loss: 1.5158 (1.5158)  time: 0.3987  data: 0.1474  max mem: 10917
[13:56:00.530637] Epoch: [1]  [ 20/345]  eta: 0:01:23  lr: 0.000007  loss: 1.5031 (1.5047)  time: 0.2486  data: 0.0001  max mem: 10917
[13:56:05.508943] Epoch: [1]  [ 40/345]  eta: 0:01:16  lr: 0.000007  loss: 1.4936 (1.4991)  time: 0.2489  data: 0.0001  max mem: 10917
[13:56:10.489243] Epoch: [1]  [ 60/345]  eta: 0:01:11  lr: 0.000007  loss: 1.4792 (1.4928)  time: 0.2490  data: 0.0001  max mem: 10917
[13:56:15.475205] Epoch: [1]  [ 80/345]  eta: 0:01:06  lr: 0.000008  loss: 1.4672 (1.4869)  time: 0.2493  data: 0.0001  max mem: 10917
[13:56:20.462531] Epoch: [1]  [100/345]  eta: 0:01:01  lr: 0.000008  loss: 1.4561 (1.4809)  time: 0.2493  data: 0.0001  max mem: 10917
[13:56:25.456948] Epoch: [1]  [120/345]  eta: 0:00:56  lr: 0.000008  loss: 1.4482 (1.4756)  time: 0.2497  data: 0.0001  max mem: 10917
[13:56:30.464138] Epoch: [1]  [140/345]  eta: 0:00:51  lr: 0.000009  loss: 1.4378 (1.4703)  time: 0.2503  data: 0.0001  max mem: 10917
[13:56:35.487341] Epoch: [1]  [160/345]  eta: 0:00:46  lr: 0.000009  loss: 1.4295 (1.4651)  time: 0.2511  data: 0.0001  max mem: 10917
[13:56:40.511002] Epoch: [1]  [180/345]  eta: 0:00:41  lr: 0.000010  loss: 1.4227 (1.4604)  time: 0.2511  data: 0.0001  max mem: 10917
[13:56:45.540143] Epoch: [1]  [200/345]  eta: 0:00:36  lr: 0.000010  loss: 1.4117 (1.4556)  time: 0.2514  data: 0.0000  max mem: 10917
[13:56:50.569500] Epoch: [1]  [220/345]  eta: 0:00:31  lr: 0.000010  loss: 1.4049 (1.4510)  time: 0.2514  data: 0.0001  max mem: 10917
[13:56:55.581759] Epoch: [1]  [240/345]  eta: 0:00:26  lr: 0.000011  loss: 1.3984 (1.4467)  time: 0.2506  data: 0.0001  max mem: 10917
[13:57:00.598699] Epoch: [1]  [260/345]  eta: 0:00:21  lr: 0.000011  loss: 1.3906 (1.4424)  time: 0.2508  data: 0.0001  max mem: 10917
[13:57:05.620849] Epoch: [1]  [280/345]  eta: 0:00:16  lr: 0.000011  loss: 1.3855 (1.4384)  time: 0.2511  data: 0.0001  max mem: 10917
[13:57:10.644265] Epoch: [1]  [300/345]  eta: 0:00:11  lr: 0.000012  loss: 1.3786 (1.4345)  time: 0.2511  data: 0.0001  max mem: 10917
[13:57:15.670684] Epoch: [1]  [320/345]  eta: 0:00:06  lr: 0.000012  loss: 1.3731 (1.4307)  time: 0.2513  data: 0.0001  max mem: 10917
[13:57:20.708157] Epoch: [1]  [340/345]  eta: 0:00:01  lr: 0.000012  loss: 1.3677 (1.4270)  time: 0.2518  data: 0.0001  max mem: 10917
[13:57:21.715430] Epoch: [1]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 1.3673 (1.4263)  time: 0.2519  data: 0.0001  max mem: 10917
[13:57:21.772808] Epoch: [1] Total time: 0:01:26 (0.2511 s / it)
[13:57:21.773290] Averaged stats: lr: 0.000012  loss: 1.3673 (1.4263)
[13:57:22.010759] Test:  [  0/345]  eta: 0:01:20  loss: 1.3687 (1.3687)  time: 0.2339  data: 0.1543  max mem: 10917
[13:57:22.829598] Test:  [ 10/345]  eta: 0:00:32  loss: 1.3653 (1.3652)  time: 0.0956  data: 0.0141  max mem: 10917
[13:57:23.653373] Test:  [ 20/345]  eta: 0:00:29  loss: 1.3652 (1.3654)  time: 0.0821  data: 0.0001  max mem: 10917
[13:57:24.479264] Test:  [ 30/345]  eta: 0:00:27  loss: 1.3652 (1.3652)  time: 0.0824  data: 0.0001  max mem: 10917
[13:57:25.309271] Test:  [ 40/345]  eta: 0:00:26  loss: 1.3648 (1.3651)  time: 0.0827  data: 0.0001  max mem: 10917
[13:57:26.143088] Test:  [ 50/345]  eta: 0:00:25  loss: 1.3648 (1.3649)  time: 0.0831  data: 0.0001  max mem: 10917
[13:57:26.980115] Test:  [ 60/345]  eta: 0:00:24  loss: 1.3646 (1.3649)  time: 0.0835  data: 0.0001  max mem: 10917
[13:57:27.819738] Test:  [ 70/345]  eta: 0:00:23  loss: 1.3646 (1.3649)  time: 0.0838  data: 0.0001  max mem: 10917
[13:57:28.662653] Test:  [ 80/345]  eta: 0:00:22  loss: 1.3641 (1.3648)  time: 0.0841  data: 0.0001  max mem: 10917
[13:57:29.510141] Test:  [ 90/345]  eta: 0:00:21  loss: 1.3639 (1.3648)  time: 0.0845  data: 0.0001  max mem: 10917
[13:57:30.360564] Test:  [100/345]  eta: 0:00:20  loss: 1.3647 (1.3648)  time: 0.0848  data: 0.0001  max mem: 10917
[13:57:31.216061] Test:  [110/345]  eta: 0:00:19  loss: 1.3640 (1.3649)  time: 0.0852  data: 0.0001  max mem: 10917
[13:57:32.074926] Test:  [120/345]  eta: 0:00:19  loss: 1.3640 (1.3648)  time: 0.0856  data: 0.0001  max mem: 10917
[13:57:32.936767] Test:  [130/345]  eta: 0:00:18  loss: 1.3647 (1.3648)  time: 0.0860  data: 0.0001  max mem: 10917
[13:57:33.801385] Test:  [140/345]  eta: 0:00:17  loss: 1.3648 (1.3648)  time: 0.0863  data: 0.0001  max mem: 10917
[13:57:34.669393] Test:  [150/345]  eta: 0:00:16  loss: 1.3648 (1.3648)  time: 0.0866  data: 0.0001  max mem: 10917
[13:57:35.540930] Test:  [160/345]  eta: 0:00:15  loss: 1.3650 (1.3648)  time: 0.0869  data: 0.0001  max mem: 10917
[13:57:36.416621] Test:  [170/345]  eta: 0:00:14  loss: 1.3644 (1.3648)  time: 0.0873  data: 0.0001  max mem: 10917
[13:57:37.295237] Test:  [180/345]  eta: 0:00:14  loss: 1.3636 (1.3646)  time: 0.0877  data: 0.0001  max mem: 10917
[13:57:38.177059] Test:  [190/345]  eta: 0:00:13  loss: 1.3638 (1.3647)  time: 0.0880  data: 0.0001  max mem: 10917
[13:57:39.063344] Test:  [200/345]  eta: 0:00:12  loss: 1.3652 (1.3647)  time: 0.0884  data: 0.0001  max mem: 10917
[13:57:39.952542] Test:  [210/345]  eta: 0:00:11  loss: 1.3656 (1.3647)  time: 0.0887  data: 0.0001  max mem: 10917
[13:57:40.844870] Test:  [220/345]  eta: 0:00:10  loss: 1.3653 (1.3647)  time: 0.0890  data: 0.0001  max mem: 10917
[13:57:41.741253] Test:  [230/345]  eta: 0:00:09  loss: 1.3647 (1.3647)  time: 0.0894  data: 0.0001  max mem: 10917
[13:57:42.640983] Test:  [240/345]  eta: 0:00:09  loss: 1.3646 (1.3647)  time: 0.0898  data: 0.0001  max mem: 10917
[13:57:43.543411] Test:  [250/345]  eta: 0:00:08  loss: 1.3650 (1.3648)  time: 0.0901  data: 0.0001  max mem: 10917
[13:57:44.449702] Test:  [260/345]  eta: 0:00:07  loss: 1.3652 (1.3648)  time: 0.0904  data: 0.0001  max mem: 10917
[13:57:45.360617] Test:  [270/345]  eta: 0:00:06  loss: 1.3648 (1.3648)  time: 0.0908  data: 0.0001  max mem: 10917
[13:57:46.275080] Test:  [280/345]  eta: 0:00:05  loss: 1.3644 (1.3647)  time: 0.0912  data: 0.0001  max mem: 10917
[13:57:47.192008] Test:  [290/345]  eta: 0:00:04  loss: 1.3647 (1.3647)  time: 0.0915  data: 0.0001  max mem: 10917
[13:57:48.112398] Test:  [300/345]  eta: 0:00:03  loss: 1.3647 (1.3647)  time: 0.0918  data: 0.0001  max mem: 10917
[13:57:49.035786] Test:  [310/345]  eta: 0:00:03  loss: 1.3641 (1.3647)  time: 0.0921  data: 0.0001  max mem: 10917
[13:57:49.963736] Test:  [320/345]  eta: 0:00:02  loss: 1.3634 (1.3647)  time: 0.0925  data: 0.0001  max mem: 10917
[13:57:50.894834] Test:  [330/345]  eta: 0:00:01  loss: 1.3638 (1.3647)  time: 0.0929  data: 0.0001  max mem: 10917
[13:57:51.828754] Test:  [340/345]  eta: 0:00:00  loss: 1.3640 (1.3647)  time: 0.0932  data: 0.0001  max mem: 10917
[13:57:52.203798] Test:  [344/345]  eta: 0:00:00  loss: 1.3640 (1.3647)  time: 0.0933  data: 0.0001  max mem: 10917
[13:57:52.260571] Test: Total time: 0:00:30 (0.0884 s / it)
[13:58:02.865558] Test:  [ 0/57]  eta: 0:00:12  loss: 1.3699 (1.3699)  time: 0.2192  data: 0.1395  max mem: 10917
[13:58:03.683979] Test:  [10/57]  eta: 0:00:04  loss: 1.3686 (1.3671)  time: 0.0942  data: 0.0132  max mem: 10917
[13:58:04.501030] Test:  [20/57]  eta: 0:00:03  loss: 1.3685 (1.3664)  time: 0.0817  data: 0.0003  max mem: 10917
[13:58:05.321383] Test:  [30/57]  eta: 0:00:02  loss: 1.3640 (1.3637)  time: 0.0818  data: 0.0001  max mem: 10917
[13:58:06.144738] Test:  [40/57]  eta: 0:00:01  loss: 1.3588 (1.3618)  time: 0.0821  data: 0.0001  max mem: 10917
[13:58:06.972074] Test:  [50/57]  eta: 0:00:00  loss: 1.3585 (1.3609)  time: 0.0825  data: 0.0001  max mem: 10917
[13:58:07.421721] Test:  [56/57]  eta: 0:00:00  loss: 1.3586 (1.3606)  time: 0.0803  data: 0.0001  max mem: 10917
[13:58:07.477155] Test: Total time: 0:00:04 (0.0848 s / it)
[13:58:09.290867] Dice score of the network on the train images: 0.000000, val images: 0.000000
[13:58:09.294459] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:58:09.692442] Epoch: [2]  [  0/345]  eta: 0:02:16  lr: 0.000013  loss: 1.3689 (1.3689)  time: 0.3971  data: 0.1445  max mem: 10917
[13:58:14.700703] Epoch: [2]  [ 20/345]  eta: 0:01:23  lr: 0.000013  loss: 1.3616 (1.3635)  time: 0.2504  data: 0.0001  max mem: 10917
[13:58:19.712399] Epoch: [2]  [ 40/345]  eta: 0:01:17  lr: 0.000013  loss: 1.3551 (1.3600)  time: 0.2505  data: 0.0001  max mem: 10917
[13:58:24.733918] Epoch: [2]  [ 60/345]  eta: 0:01:12  lr: 0.000014  loss: 1.3536 (1.3578)  time: 0.2510  data: 0.0000  max mem: 10917
[13:58:29.755360] Epoch: [2]  [ 80/345]  eta: 0:01:06  lr: 0.000014  loss: 1.3473 (1.3553)  time: 0.2510  data: 0.0001  max mem: 10917
[13:58:34.781048] Epoch: [2]  [100/345]  eta: 0:01:01  lr: 0.000014  loss: 1.3437 (1.3530)  time: 0.2512  data: 0.0001  max mem: 10917
[13:58:39.810521] Epoch: [2]  [120/345]  eta: 0:00:56  lr: 0.000015  loss: 1.3398 (1.3508)  time: 0.2514  data: 0.0001  max mem: 10917
[13:58:44.846656] Epoch: [2]  [140/345]  eta: 0:00:51  lr: 0.000015  loss: 1.3362 (1.3487)  time: 0.2518  data: 0.0001  max mem: 10917
[13:58:49.876245] Epoch: [2]  [160/345]  eta: 0:00:46  lr: 0.000015  loss: 1.3335 (1.3469)  time: 0.2514  data: 0.0001  max mem: 10917
[13:58:54.911062] Epoch: [2]  [180/345]  eta: 0:00:41  lr: 0.000016  loss: 1.3299 (1.3451)  time: 0.2517  data: 0.0000  max mem: 10917

[13:58:59.947501] Epoch: [2]  [200/345]  eta: 0:00:36  lr: 0.000016  loss: 1.3257 (1.3431)  time: 0.2518  data: 0.0001  max mem: 10917
[13:59:04.987969] Epoch: [2]  [220/345]  eta: 0:00:31  lr: 0.000016  loss: 1.3236 (1.3414)  time: 0.2520  data: 0.0001  max mem: 10917
[13:59:10.029337] Epoch: [2]  [240/345]  eta: 0:00:26  lr: 0.000017  loss: 1.3210 (1.3397)  time: 0.2520  data: 0.0001  max mem: 10917
[13:59:15.070739] Epoch: [2]  [260/345]  eta: 0:00:21  lr: 0.000017  loss: 1.3170 (1.3380)  time: 0.2520  data: 0.0000  max mem: 10917
[13:59:20.116730] Epoch: [2]  [280/345]  eta: 0:00:16  lr: 0.000018  loss: 1.3161 (1.3365)  time: 0.2523  data: 0.0001  max mem: 10917
[13:59:25.166254] Epoch: [2]  [300/345]  eta: 0:00:11  lr: 0.000018  loss: 1.3120 (1.3348)  time: 0.2524  data: 0.0001  max mem: 10917
[13:59:30.212907] Epoch: [2]  [320/345]  eta: 0:00:06  lr: 0.000018  loss: 1.3093 (1.3333)  time: 0.2523  data: 0.0000  max mem: 10917
[13:59:35.260020] Epoch: [2]  [340/345]  eta: 0:00:01  lr: 0.000019  loss: 1.3071 (1.3317)  time: 0.2523  data: 0.0000  max mem: 10917
[13:59:36.273275] Epoch: [2]  [344/345]  eta: 0:00:00  lr: 0.000019  loss: 1.3062 (1.3314)  time: 0.2525  data: 0.0001  max mem: 10917
[13:59:36.330801] Epoch: [2] Total time: 0:01:27 (0.2523 s / it)
[13:59:36.331191] Averaged stats: lr: 0.000019  loss: 1.3062 (1.3314)
[13:59:36.565096] Test:  [  0/345]  eta: 0:01:19  loss: 1.3039 (1.3039)  time: 0.2299  data: 0.1504  max mem: 10917
[13:59:37.387930] Test:  [ 10/345]  eta: 0:00:32  loss: 1.3029 (1.3018)  time: 0.0956  data: 0.0140  max mem: 10917
[13:59:38.211508] Test:  [ 20/345]  eta: 0:00:29  loss: 1.3012 (1.3007)  time: 0.0822  data: 0.0002  max mem: 10917
[13:59:39.038927] Test:  [ 30/345]  eta: 0:00:27  loss: 1.2997 (1.3005)  time: 0.0825  data: 0.0001  max mem: 10917
[13:59:39.870502] Test:  [ 40/345]  eta: 0:00:26  loss: 1.2997 (1.3005)  time: 0.0829  data: 0.0001  max mem: 10917
[13:59:40.704446] Test:  [ 50/345]  eta: 0:00:25  loss: 1.2997 (1.3004)  time: 0.0832  data: 0.0001  max mem: 10917
[13:59:41.541588] Test:  [ 60/345]  eta: 0:00:24  loss: 1.3004 (1.3004)  time: 0.0835  data: 0.0001  max mem: 10917
[13:59:42.382752] Test:  [ 70/345]  eta: 0:00:23  loss: 1.2992 (1.3001)  time: 0.0839  data: 0.0001  max mem: 10917
[13:59:43.227993] Test:  [ 80/345]  eta: 0:00:22  loss: 1.2986 (1.3000)  time: 0.0843  data: 0.0001  max mem: 10917
[13:59:44.076527] Test:  [ 90/345]  eta: 0:00:21  loss: 1.2996 (1.3002)  time: 0.0846  data: 0.0001  max mem: 10917
[13:59:44.929020] Test:  [100/345]  eta: 0:00:20  loss: 1.2998 (1.3000)  time: 0.0850  data: 0.0001  max mem: 10917
[13:59:45.783984] Test:  [110/345]  eta: 0:00:19  loss: 1.2996 (1.3002)  time: 0.0853  data: 0.0001  max mem: 10917
[13:59:46.642974] Test:  [120/345]  eta: 0:00:19  loss: 1.3003 (1.3002)  time: 0.0856  data: 0.0001  max mem: 10917
[13:59:47.505123] Test:  [130/345]  eta: 0:00:18  loss: 1.3013 (1.3003)  time: 0.0860  data: 0.0001  max mem: 10917
[13:59:48.370920] Test:  [140/345]  eta: 0:00:17  loss: 1.3012 (1.3003)  time: 0.0863  data: 0.0001  max mem: 10917
[13:59:49.239532] Test:  [150/345]  eta: 0:00:16  loss: 1.3011 (1.3004)  time: 0.0867  data: 0.0001  max mem: 10917
[13:59:50.112231] Test:  [160/345]  eta: 0:00:15  loss: 1.3012 (1.3004)  time: 0.0870  data: 0.0001  max mem: 10917
[13:59:50.988314] Test:  [170/345]  eta: 0:00:14  loss: 1.3012 (1.3005)  time: 0.0874  data: 0.0001  max mem: 10917
[13:59:51.868246] Test:  [180/345]  eta: 0:00:14  loss: 1.3012 (1.3005)  time: 0.0877  data: 0.0001  max mem: 10917
[13:59:52.752047] Test:  [190/345]  eta: 0:00:13  loss: 1.3016 (1.3005)  time: 0.0881  data: 0.0001  max mem: 10917
[13:59:53.638766] Test:  [200/345]  eta: 0:00:12  loss: 1.3017 (1.3006)  time: 0.0885  data: 0.0001  max mem: 10917
[13:59:54.528899] Test:  [210/345]  eta: 0:00:11  loss: 1.3008 (1.3005)  time: 0.0888  data: 0.0001  max mem: 10917
[13:59:55.422298] Test:  [220/345]  eta: 0:00:10  loss: 1.3009 (1.3006)  time: 0.0891  data: 0.0001  max mem: 10917
[13:59:56.319752] Test:  [230/345]  eta: 0:00:09  loss: 1.3019 (1.3007)  time: 0.0895  data: 0.0001  max mem: 10917
[13:59:57.220908] Test:  [240/345]  eta: 0:00:09  loss: 1.3010 (1.3007)  time: 0.0899  data: 0.0001  max mem: 10917
[13:59:58.124684] Test:  [250/345]  eta: 0:00:08  loss: 1.3005 (1.3007)  time: 0.0902  data: 0.0001  max mem: 10917
[13:59:59.032524] Test:  [260/345]  eta: 0:00:07  loss: 1.2997 (1.3007)  time: 0.0905  data: 0.0001  max mem: 10917
[13:59:59.943151] Test:  [270/345]  eta: 0:00:06  loss: 1.2995 (1.3007)  time: 0.0909  data: 0.0001  max mem: 10917
[14:00:00.857598] Test:  [280/345]  eta: 0:00:05  loss: 1.3013 (1.3007)  time: 0.0912  data: 0.0001  max mem: 10917
[14:00:01.776271] Test:  [290/345]  eta: 0:00:04  loss: 1.3004 (1.3007)  time: 0.0916  data: 0.0001  max mem: 10917
[14:00:02.697470] Test:  [300/345]  eta: 0:00:03  loss: 1.2998 (1.3006)  time: 0.0919  data: 0.0001  max mem: 10917
[14:00:03.621581] Test:  [310/345]  eta: 0:00:03  loss: 1.2999 (1.3007)  time: 0.0922  data: 0.0001  max mem: 10917
[14:00:04.550563] Test:  [320/345]  eta: 0:00:02  loss: 1.3015 (1.3007)  time: 0.0926  data: 0.0001  max mem: 10917
[14:00:05.482693] Test:  [330/345]  eta: 0:00:01  loss: 1.3011 (1.3007)  time: 0.0930  data: 0.0001  max mem: 10917
[14:00:06.417771] Test:  [340/345]  eta: 0:00:00  loss: 1.3011 (1.3007)  time: 0.0933  data: 0.0001  max mem: 10917
[14:00:06.793438] Test:  [344/345]  eta: 0:00:00  loss: 1.3006 (1.3007)  time: 0.0935  data: 0.0001  max mem: 10917
[14:00:06.849220] Test: Total time: 0:00:30 (0.0884 s / it)
[14:00:17.444022] Test:  [ 0/57]  eta: 0:00:12  loss: 1.3070 (1.3070)  time: 0.2221  data: 0.1424  max mem: 10917
[14:00:18.257354] Test:  [10/57]  eta: 0:00:04  loss: 1.3044 (1.3038)  time: 0.0941  data: 0.0130  max mem: 10917
[14:00:19.073894] Test:  [20/57]  eta: 0:00:03  loss: 1.3049 (1.3035)  time: 0.0814  data: 0.0001  max mem: 10917
[14:00:19.894088] Test:  [30/57]  eta: 0:00:02  loss: 1.2963 (1.2996)  time: 0.0818  data: 0.0001  max mem: 10917
[14:00:20.718239] Test:  [40/57]  eta: 0:00:01  loss: 1.2908 (1.2969)  time: 0.0822  data: 0.0001  max mem: 10917
[14:00:21.546602] Test:  [50/57]  eta: 0:00:00  loss: 1.2901 (1.2958)  time: 0.0826  data: 0.0001  max mem: 10917
[14:00:21.996392] Test:  [56/57]  eta: 0:00:00  loss: 1.2933 (1.2956)  time: 0.0804  data: 0.0001  max mem: 10917
[14:00:22.051652] Test: Total time: 0:00:04 (0.0847 s / it)
[14:00:23.864689] Dice score of the network on the train images: 0.000000, val images: 0.000000
[14:00:23.868351] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:00:24.264153] Epoch: [3]  [  0/345]  eta: 0:02:16  lr: 0.000019  loss: 1.3071 (1.3071)  time: 0.3949  data: 0.1428  max mem: 10917
[14:00:29.255890] Epoch: [3]  [ 20/345]  eta: 0:01:23  lr: 0.000019  loss: 1.3039 (1.3047)  time: 0.2495  data: 0.0001  max mem: 10917
[14:00:34.287747] Epoch: [3]  [ 40/345]  eta: 0:01:17  lr: 0.000019  loss: 1.3022 (1.3035)  time: 0.2515  data: 0.0001  max mem: 10917
[14:00:39.311704] Epoch: [3]  [ 60/345]  eta: 0:01:12  lr: 0.000020  loss: 1.3002 (1.3025)  time: 0.2512  data: 0.0001  max mem: 10917
[14:00:44.314855] Epoch: [3]  [ 80/345]  eta: 0:01:06  lr: 0.000020  loss: 1.2985 (1.3011)  time: 0.2501  data: 0.0001  max mem: 10917
[14:00:49.320772] Epoch: [3]  [100/345]  eta: 0:01:01  lr: 0.000021  loss: 1.2964 (1.3002)  time: 0.2503  data: 0.0001  max mem: 10917
[14:00:54.324395] Epoch: [3]  [120/345]  eta: 0:00:56  lr: 0.000021  loss: 1.2953 (1.2994)  time: 0.2501  data: 0.0001  max mem: 10917
[14:00:59.332052] Epoch: [3]  [140/345]  eta: 0:00:51  lr: 0.000021  loss: 1.2902 (1.2981)  time: 0.2503  data: 0.0001  max mem: 10917
[14:01:04.348914] Epoch: [3]  [160/345]  eta: 0:00:46  lr: 0.000022  loss: 1.2891 (1.2970)  time: 0.2508  data: 0.0001  max mem: 10917
[14:01:09.362007] Epoch: [3]  [180/345]  eta: 0:00:41  lr: 0.000022  loss: 1.2878 (1.2960)  time: 0.2506  data: 0.0001  max mem: 10917
[14:01:14.380421] Epoch: [3]  [200/345]  eta: 0:00:36  lr: 0.000022  loss: 1.2856 (1.2950)  time: 0.2509  data: 0.0000  max mem: 10917
[14:01:19.396256] Epoch: [3]  [220/345]  eta: 0:00:31  lr: 0.000023  loss: 1.2823 (1.2939)  time: 0.2508  data: 0.0000  max mem: 10917
[14:01:24.417283] Epoch: [3]  [240/345]  eta: 0:00:26  lr: 0.000023  loss: 1.2811 (1.2929)  time: 0.2510  data: 0.0000  max mem: 10917
[14:01:29.438752] Epoch: [3]  [260/345]  eta: 0:00:21  lr: 0.000023  loss: 1.2748 (1.2916)  time: 0.2510  data: 0.0000  max mem: 10917
[14:01:34.461540] Epoch: [3]  [280/345]  eta: 0:00:16  lr: 0.000024  loss: 1.2729 (1.2902)  time: 0.2511  data: 0.0000  max mem: 10917
[14:01:39.486138] Epoch: [3]  [300/345]  eta: 0:00:11  lr: 0.000024  loss: 1.2641 (1.2886)  time: 0.2512  data: 0.0000  max mem: 10917
[14:01:44.516332] Epoch: [3]  [320/345]  eta: 0:00:06  lr: 0.000025  loss: 1.2621 (1.2870)  time: 0.2515  data: 0.0000  max mem: 10917
[14:01:49.547522] Epoch: [3]  [340/345]  eta: 0:00:01  lr: 0.000025  loss: 1.2587 (1.2853)  time: 0.2515  data: 0.0001  max mem: 10917
[14:01:50.555204] Epoch: [3]  [344/345]  eta: 0:00:00  lr: 0.000025  loss: 1.2557 (1.2849)  time: 0.2516  data: 0.0001  max mem: 10917
[14:01:50.612908] Epoch: [3] Total time: 0:01:26 (0.2514 s / it)
[14:01:50.613421] Averaged stats: lr: 0.000025  loss: 1.2557 (1.2849)
[14:01:50.848450] Test:  [  0/345]  eta: 0:01:20  loss: 1.2441 (1.2441)  time: 0.2321  data: 0.1515  max mem: 10917
[14:01:51.702924] Test:  [ 10/345]  eta: 0:00:33  loss: 1.2385 (1.2379)  time: 0.0987  data: 0.0172  max mem: 10917
[14:01:52.527908] Test:  [ 20/345]  eta: 0:00:29  loss: 1.2385 (1.2406)  time: 0.0839  data: 0.0020  max mem: 10917
[14:01:53.354169] Test:  [ 30/345]  eta: 0:00:27  loss: 1.2445 (1.2407)  time: 0.0825  data: 0.0001  max mem: 10917
[14:01:54.184931] Test:  [ 40/345]  eta: 0:00:26  loss: 1.2367 (1.2399)  time: 0.0828  data: 0.0001  max mem: 10917
[14:01:55.018719] Test:  [ 50/345]  eta: 0:00:25  loss: 1.2383 (1.2408)  time: 0.0832  data: 0.0001  max mem: 10917
[14:01:55.856571] Test:  [ 60/345]  eta: 0:00:24  loss: 1.2463 (1.2418)  time: 0.0835  data: 0.0001  max mem: 10917
[14:01:56.697119] Test:  [ 70/345]  eta: 0:00:23  loss: 1.2446 (1.2419)  time: 0.0839  data: 0.0001  max mem: 10917
[14:01:57.541724] Test:  [ 80/345]  eta: 0:00:22  loss: 1.2417 (1.2416)  time: 0.0842  data: 0.0001  max mem: 10917
[14:01:58.389721] Test:  [ 90/345]  eta: 0:00:21  loss: 1.2388 (1.2412)  time: 0.0846  data: 0.0001  max mem: 10917
[14:01:59.241201] Test:  [100/345]  eta: 0:00:20  loss: 1.2417 (1.2416)  time: 0.0849  data: 0.0001  max mem: 10917
[14:02:00.096203] Test:  [110/345]  eta: 0:00:20  loss: 1.2438 (1.2419)  time: 0.0853  data: 0.0001  max mem: 10917
[14:02:00.955262] Test:  [120/345]  eta: 0:00:19  loss: 1.2394 (1.2416)  time: 0.0857  data: 0.0001  max mem: 10917
[14:02:01.817132] Test:  [130/345]  eta: 0:00:18  loss: 1.2384 (1.2414)  time: 0.0860  data: 0.0001  max mem: 10917
[14:02:02.683292] Test:  [140/345]  eta: 0:00:17  loss: 1.2418 (1.2414)  time: 0.0863  data: 0.0001  max mem: 10917
[14:02:03.553050] Test:  [150/345]  eta: 0:00:16  loss: 1.2408 (1.2414)  time: 0.0867  data: 0.0001  max mem: 10917
[14:02:04.425527] Test:  [160/345]  eta: 0:00:15  loss: 1.2387 (1.2413)  time: 0.0871  data: 0.0001  max mem: 10917
[14:02:05.301819] Test:  [170/345]  eta: 0:00:15  loss: 1.2378 (1.2411)  time: 0.0874  data: 0.0001  max mem: 10917
[14:02:06.182008] Test:  [180/345]  eta: 0:00:14  loss: 1.2378 (1.2410)  time: 0.0878  data: 0.0001  max mem: 10917
[14:02:07.064532] Test:  [190/345]  eta: 0:00:13  loss: 1.2375 (1.2409)  time: 0.0881  data: 0.0001  max mem: 10917
[14:02:07.951309] Test:  [200/345]  eta: 0:00:12  loss: 1.2377 (1.2408)  time: 0.0884  data: 0.0001  max mem: 10917
[14:02:08.841976] Test:  [210/345]  eta: 0:00:11  loss: 1.2391 (1.2409)  time: 0.0888  data: 0.0001  max mem: 10917
[14:02:09.735427] Test:  [220/345]  eta: 0:00:10  loss: 1.2399 (1.2408)  time: 0.0892  data: 0.0001  max mem: 10917
[14:02:10.633479] Test:  [230/345]  eta: 0:00:09  loss: 1.2356 (1.2407)  time: 0.0895  data: 0.0001  max mem: 10917
[14:02:11.535492] Test:  [240/345]  eta: 0:00:09  loss: 1.2390 (1.2407)  time: 0.0900  data: 0.0001  max mem: 10917
[14:02:12.440014] Test:  [250/345]  eta: 0:00:08  loss: 1.2404 (1.2409)  time: 0.0903  data: 0.0001  max mem: 10917
[14:02:13.347585] Test:  [260/345]  eta: 0:00:07  loss: 1.2430 (1.2408)  time: 0.0906  data: 0.0001  max mem: 10917
[14:02:14.258679] Test:  [270/345]  eta: 0:00:06  loss: 1.2440 (1.2409)  time: 0.0909  data: 0.0001  max mem: 10917
[14:02:15.173757] Test:  [280/345]  eta: 0:00:05  loss: 1.2449 (1.2410)  time: 0.0913  data: 0.0001  max mem: 10917
[14:02:16.092246] Test:  [290/345]  eta: 0:00:04  loss: 1.2378 (1.2409)  time: 0.0916  data: 0.0001  max mem: 10917
[14:02:17.014926] Test:  [300/345]  eta: 0:00:03  loss: 1.2379 (1.2409)  time: 0.0920  data: 0.0001  max mem: 10917
[14:02:17.939907] Test:  [310/345]  eta: 0:00:03  loss: 1.2393 (1.2409)  time: 0.0923  data: 0.0001  max mem: 10917
[14:02:18.868173] Test:  [320/345]  eta: 0:00:02  loss: 1.2419 (1.2409)  time: 0.0926  data: 0.0001  max mem: 10917
[14:02:19.800090] Test:  [330/345]  eta: 0:00:01  loss: 1.2430 (1.2410)  time: 0.0930  data: 0.0001  max mem: 10917
[14:02:20.734812] Test:  [340/345]  eta: 0:00:00  loss: 1.2415 (1.2409)  time: 0.0933  data: 0.0001  max mem: 10917
[14:02:21.110360] Test:  [344/345]  eta: 0:00:00  loss: 1.2383 (1.2409)  time: 0.0934  data: 0.0001  max mem: 10917
[14:02:21.167428] Test: Total time: 0:00:30 (0.0886 s / it)
[14:02:31.758234] Test:  [ 0/57]  eta: 0:00:12  loss: 1.2613 (1.2613)  time: 0.2179  data: 0.1381  max mem: 10917
[14:02:32.571841] Test:  [10/57]  eta: 0:00:04  loss: 1.2598 (1.2550)  time: 0.0937  data: 0.0126  max mem: 10917
[14:02:33.387357] Test:  [20/57]  eta: 0:00:03  loss: 1.2599 (1.2536)  time: 0.0814  data: 0.0001  max mem: 10917
[14:02:34.207488] Test:  [30/57]  eta: 0:00:02  loss: 1.2243 (1.2366)  time: 0.0817  data: 0.0001  max mem: 10917
[14:02:35.031542] Test:  [40/57]  eta: 0:00:01  loss: 1.1918 (1.2256)  time: 0.0822  data: 0.0001  max mem: 10917
[14:02:35.859332] Test:  [50/57]  eta: 0:00:00  loss: 1.2010 (1.2217)  time: 0.0825  data: 0.0001  max mem: 10917
[14:02:36.309377] Test:  [56/57]  eta: 0:00:00  loss: 1.2167 (1.2220)  time: 0.0804  data: 0.0001  max mem: 10917
[14:02:36.367239] Test: Total time: 0:00:04 (0.0847 s / it)
[14:02:38.197987] Dice score of the network on the train images: 0.100642, val images: 0.098667
[14:02:38.198224] saving best_prec_model_0 @ epoch 3
[14:02:38.871960] saving best_rec_model_0 @ epoch 3
[14:02:39.424862] saving best_dice_model_0 @ epoch 3
[14:02:40.215346] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:02:40.607471] Epoch: [4]  [  0/345]  eta: 0:02:14  lr: 0.000025  loss: 1.2609 (1.2609)  time: 0.3911  data: 0.1384  max mem: 10917
[14:02:45.605950] Epoch: [4]  [ 20/345]  eta: 0:01:23  lr: 0.000025  loss: 1.2531 (1.2519)  time: 0.2499  data: 0.0001  max mem: 10917
[14:02:50.609565] Epoch: [4]  [ 40/345]  eta: 0:01:17  lr: 0.000026  loss: 1.2374 (1.2449)  time: 0.2501  data: 0.0000  max mem: 10917
[14:02:55.617367] Epoch: [4]  [ 60/345]  eta: 0:01:11  lr: 0.000026  loss: 1.2333 (1.2419)  time: 0.2503  data: 0.0001  max mem: 10917
[14:03:00.630992] Epoch: [4]  [ 80/345]  eta: 0:01:06  lr: 0.000026  loss: 1.2296 (1.2385)  time: 0.2506  data: 0.0000  max mem: 10917
[14:03:05.649559] Epoch: [4]  [100/345]  eta: 0:01:01  lr: 0.000027  loss: 1.2181 (1.2343)  time: 0.2509  data: 0.0001  max mem: 10917
[14:03:10.671754] Epoch: [4]  [120/345]  eta: 0:00:56  lr: 0.000027  loss: 1.2098 (1.2301)  time: 0.2511  data: 0.0001  max mem: 10917
[14:03:15.691363] Epoch: [4]  [140/345]  eta: 0:00:51  lr: 0.000028  loss: 1.1993 (1.2262)  time: 0.2509  data: 0.0001  max mem: 10917
[14:03:20.702642] Epoch: [4]  [160/345]  eta: 0:00:46  lr: 0.000028  loss: 1.2001 (1.2228)  time: 0.2505  data: 0.0001  max mem: 10917
[14:03:25.720942] Epoch: [4]  [180/345]  eta: 0:00:41  lr: 0.000028  loss: 1.1943 (1.2195)  time: 0.2509  data: 0.0001  max mem: 10917
[14:03:30.741997] Epoch: [4]  [200/345]  eta: 0:00:36  lr: 0.000029  loss: 1.1852 (1.2160)  time: 0.2510  data: 0.0001  max mem: 10917
[14:03:35.766465] Epoch: [4]  [220/345]  eta: 0:00:31  lr: 0.000029  loss: 1.1762 (1.2125)  time: 0.2512  data: 0.0001  max mem: 10917
[14:03:40.800991] Epoch: [4]  [240/345]  eta: 0:00:26  lr: 0.000029  loss: 1.1759 (1.2097)  time: 0.2517  data: 0.0001  max mem: 10917
[14:03:45.840853] Epoch: [4]  [260/345]  eta: 0:00:21  lr: 0.000030  loss: 1.1679 (1.2065)  time: 0.2519  data: 0.0001  max mem: 10917
[14:03:50.885789] Epoch: [4]  [280/345]  eta: 0:00:16  lr: 0.000030  loss: 1.1555 (1.2032)  time: 0.2522  data: 0.0001  max mem: 10917
[14:03:55.928432] Epoch: [4]  [300/345]  eta: 0:00:11  lr: 0.000030  loss: 1.1573 (1.2001)  time: 0.2521  data: 0.0001  max mem: 10917
[14:04:00.962883] Epoch: [4]  [320/345]  eta: 0:00:06  lr: 0.000031  loss: 1.1413 (1.1968)  time: 0.2517  data: 0.0001  max mem: 10917
[14:04:05.999896] Epoch: [4]  [340/345]  eta: 0:00:01  lr: 0.000031  loss: 1.1322 (1.1932)  time: 0.2518  data: 0.0001  max mem: 10917
[14:04:07.006865] Epoch: [4]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 1.1322 (1.1925)  time: 0.2518  data: 0.0001  max mem: 10917
[14:04:07.063724] Epoch: [4] Total time: 0:01:26 (0.2517 s / it)
[14:04:07.064089] Averaged stats: lr: 0.000031  loss: 1.1322 (1.1925)
[14:04:07.296777] Test:  [  0/345]  eta: 0:01:19  loss: 1.1235 (1.1235)  time: 0.2298  data: 0.1499  max mem: 10917
[14:04:08.130728] Test:  [ 10/345]  eta: 0:00:32  loss: 1.1188 (1.1221)  time: 0.0966  data: 0.0149  max mem: 10917
[14:04:08.955039] Test:  [ 20/345]  eta: 0:00:29  loss: 1.1242 (1.1240)  time: 0.0828  data: 0.0008  max mem: 10917
[14:04:09.782273] Test:  [ 30/345]  eta: 0:00:27  loss: 1.1277 (1.1231)  time: 0.0825  data: 0.0001  max mem: 10917
[14:04:10.612700] Test:  [ 40/345]  eta: 0:00:26  loss: 1.1191 (1.1201)  time: 0.0828  data: 0.0001  max mem: 10917
[14:04:11.447610] Test:  [ 50/345]  eta: 0:00:25  loss: 1.1191 (1.1206)  time: 0.0832  data: 0.0001  max mem: 10917
[14:04:12.285864] Test:  [ 60/345]  eta: 0:00:24  loss: 1.1212 (1.1217)  time: 0.0836  data: 0.0001  max mem: 10917
[14:04:13.126915] Test:  [ 70/345]  eta: 0:00:23  loss: 1.1212 (1.1218)  time: 0.0839  data: 0.0001  max mem: 10917
[14:04:13.971775] Test:  [ 80/345]  eta: 0:00:22  loss: 1.1141 (1.1210)  time: 0.0842  data: 0.0001  max mem: 10917
[14:04:14.821180] Test:  [ 90/345]  eta: 0:00:21  loss: 1.1166 (1.1222)  time: 0.0847  data: 0.0001  max mem: 10917
[14:04:15.672556] Test:  [100/345]  eta: 0:00:20  loss: 1.1205 (1.1214)  time: 0.0850  data: 0.0001  max mem: 10917
[14:04:16.527840] Test:  [110/345]  eta: 0:00:20  loss: 1.1184 (1.1214)  time: 0.0853  data: 0.0001  max mem: 10917
[14:04:17.386958] Test:  [120/345]  eta: 0:00:19  loss: 1.1225 (1.1213)  time: 0.0857  data: 0.0001  max mem: 10917
[14:04:18.249168] Test:  [130/345]  eta: 0:00:18  loss: 1.1156 (1.1213)  time: 0.0860  data: 0.0001  max mem: 10917
[14:04:19.115766] Test:  [140/345]  eta: 0:00:17  loss: 1.1177 (1.1217)  time: 0.0864  data: 0.0001  max mem: 10917
[14:04:19.985927] Test:  [150/345]  eta: 0:00:16  loss: 1.1195 (1.1217)  time: 0.0868  data: 0.0001  max mem: 10917
[14:04:20.859680] Test:  [160/345]  eta: 0:00:15  loss: 1.1177 (1.1213)  time: 0.0871  data: 0.0001  max mem: 10917
[14:04:21.736626] Test:  [170/345]  eta: 0:00:15  loss: 1.1177 (1.1213)  time: 0.0875  data: 0.0001  max mem: 10917
[14:04:22.616852] Test:  [180/345]  eta: 0:00:14  loss: 1.1221 (1.1215)  time: 0.0878  data: 0.0001  max mem: 10917
[14:04:23.500863] Test:  [190/345]  eta: 0:00:13  loss: 1.1142 (1.1210)  time: 0.0882  data: 0.0001  max mem: 10917
[14:04:24.388001] Test:  [200/345]  eta: 0:00:12  loss: 1.1187 (1.1211)  time: 0.0885  data: 0.0001  max mem: 10917
[14:04:25.278795] Test:  [210/345]  eta: 0:00:11  loss: 1.1228 (1.1214)  time: 0.0888  data: 0.0001  max mem: 10917
[14:04:26.173396] Test:  [220/345]  eta: 0:00:10  loss: 1.1228 (1.1213)  time: 0.0892  data: 0.0001  max mem: 10917
[14:04:27.071878] Test:  [230/345]  eta: 0:00:09  loss: 1.1228 (1.1214)  time: 0.0896  data: 0.0001  max mem: 10917
[14:04:27.974006] Test:  [240/345]  eta: 0:00:09  loss: 1.1178 (1.1215)  time: 0.0900  data: 0.0001  max mem: 10917
[14:04:28.878510] Test:  [250/345]  eta: 0:00:08  loss: 1.1306 (1.1220)  time: 0.0903  data: 0.0001  max mem: 10917
[14:04:29.786619] Test:  [260/345]  eta: 0:00:07  loss: 1.1307 (1.1219)  time: 0.0906  data: 0.0001  max mem: 10917
[14:04:30.697889] Test:  [270/345]  eta: 0:00:06  loss: 1.1190 (1.1218)  time: 0.0909  data: 0.0001  max mem: 10917
[14:04:31.613018] Test:  [280/345]  eta: 0:00:05  loss: 1.1190 (1.1216)  time: 0.0913  data: 0.0001  max mem: 10917
[14:04:32.530709] Test:  [290/345]  eta: 0:00:04  loss: 1.1220 (1.1215)  time: 0.0916  data: 0.0001  max mem: 10917
[14:04:33.453391] Test:  [300/345]  eta: 0:00:03  loss: 1.1301 (1.1216)  time: 0.0920  data: 0.0001  max mem: 10917
[14:04:34.379068] Test:  [310/345]  eta: 0:00:03  loss: 1.1319 (1.1218)  time: 0.0924  data: 0.0001  max mem: 10917
[14:04:35.308492] Test:  [320/345]  eta: 0:00:02  loss: 1.1235 (1.1216)  time: 0.0927  data: 0.0001  max mem: 10917
[14:04:36.240919] Test:  [330/345]  eta: 0:00:01  loss: 1.1202 (1.1217)  time: 0.0930  data: 0.0001  max mem: 10917
[14:04:37.176887] Test:  [340/345]  eta: 0:00:00  loss: 1.1192 (1.1217)  time: 0.0934  data: 0.0001  max mem: 10917
[14:04:37.552912] Test:  [344/345]  eta: 0:00:00  loss: 1.1125 (1.1217)  time: 0.0935  data: 0.0001  max mem: 10917
[14:04:37.590965] Test: Total time: 0:00:30 (0.0885 s / it)
[14:04:48.180910] Test:  [ 0/57]  eta: 0:00:12  loss: 1.1865 (1.1865)  time: 0.2183  data: 0.1387  max mem: 10917
[14:04:48.994736] Test:  [10/57]  eta: 0:00:04  loss: 1.1842 (1.1615)  time: 0.0938  data: 0.0127  max mem: 10917
[14:04:49.812408] Test:  [20/57]  eta: 0:00:03  loss: 1.1786 (1.1600)  time: 0.0815  data: 0.0001  max mem: 10917
[14:04:50.633564] Test:  [30/57]  eta: 0:00:02  loss: 1.1008 (1.1211)  time: 0.0819  data: 0.0001  max mem: 10917
[14:04:51.457707] Test:  [40/57]  eta: 0:00:01  loss: 1.0148 (1.0958)  time: 0.0822  data: 0.0001  max mem: 10917
[14:04:52.287522] Test:  [50/57]  eta: 0:00:00  loss: 1.0268 (1.0871)  time: 0.0826  data: 0.0001  max mem: 10917
[14:04:52.737332] Test:  [56/57]  eta: 0:00:00  loss: 1.0602 (1.0897)  time: 0.0804  data: 0.0001  max mem: 10917
[14:04:52.791772] Test: Total time: 0:00:04 (0.0847 s / it)
[14:04:54.519474] Dice score of the network on the train images: 0.618391, val images: 0.679112
[14:04:54.519686] saving best_rec_model_0 @ epoch 4
[14:04:55.329412] saving best_dice_model_0 @ epoch 4
[14:04:56.114812] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:04:56.507542] Epoch: [5]  [  0/345]  eta: 0:02:15  lr: 0.000031  loss: 1.1239 (1.1239)  time: 0.3916  data: 0.1406  max mem: 10917
[14:05:01.485874] Epoch: [5]  [ 20/345]  eta: 0:01:23  lr: 0.000032  loss: 1.1284 (1.1335)  time: 0.2489  data: 0.0001  max mem: 10917

[14:05:06.472396] Epoch: [5]  [ 40/345]  eta: 0:01:17  lr: 0.000032  loss: 1.1288 (1.1291)  time: 0.2493  data: 0.0001  max mem: 10917
[14:05:11.460237] Epoch: [5]  [ 60/345]  eta: 0:01:11  lr: 0.000032  loss: 1.1181 (1.1262)  time: 0.2493  data: 0.0001  max mem: 10917

[14:05:16.465840] Epoch: [5]  [ 80/345]  eta: 0:01:06  lr: 0.000033  loss: 1.1181 (1.1239)  time: 0.2502  data: 0.0001  max mem: 10917
[14:05:21.483539] Epoch: [5]  [100/345]  eta: 0:01:01  lr: 0.000033  loss: 1.0945 (1.1183)  time: 0.2508  data: 0.0001  max mem: 10917
[14:05:26.505562] Epoch: [5]  [120/345]  eta: 0:00:56  lr: 0.000033  loss: 1.1090 (1.1159)  time: 0.2511  data: 0.0000  max mem: 10917
[14:05:31.529319] Epoch: [5]  [140/345]  eta: 0:00:51  lr: 0.000034  loss: 1.0901 (1.1129)  time: 0.2511  data: 0.0001  max mem: 10917
[14:05:36.565621] Epoch: [5]  [160/345]  eta: 0:00:46  lr: 0.000034  loss: 1.0965 (1.1111)  time: 0.2518  data: 0.0001  max mem: 10917
[14:05:41.593612] Epoch: [5]  [180/345]  eta: 0:00:41  lr: 0.000035  loss: 1.0752 (1.1072)  time: 0.2514  data: 0.0001  max mem: 10917
[14:05:46.605705] Epoch: [5]  [200/345]  eta: 0:00:36  lr: 0.000035  loss: 1.0716 (1.1039)  time: 0.2506  data: 0.0001  max mem: 10917
[14:05:51.633691] Epoch: [5]  [220/345]  eta: 0:00:31  lr: 0.000035  loss: 1.0843 (1.1017)  time: 0.2514  data: 0.0001  max mem: 10917
[14:05:56.664603] Epoch: [5]  [240/345]  eta: 0:00:26  lr: 0.000036  loss: 1.0584 (1.0985)  time: 0.2515  data: 0.0001  max mem: 10917
[14:06:01.702591] Epoch: [5]  [260/345]  eta: 0:00:21  lr: 0.000036  loss: 1.0508 (1.0947)  time: 0.2519  data: 0.0001  max mem: 10917
[14:06:06.744942] Epoch: [5]  [280/345]  eta: 0:00:16  lr: 0.000036  loss: 1.0351 (1.0903)  time: 0.2521  data: 0.0001  max mem: 10917
[14:06:11.794377] Epoch: [5]  [300/345]  eta: 0:00:11  lr: 0.000037  loss: 1.0281 (1.0866)  time: 0.2524  data: 0.0001  max mem: 10917
[14:06:16.843571] Epoch: [5]  [320/345]  eta: 0:00:06  lr: 0.000037  loss: 1.0281 (1.0831)  time: 0.2524  data: 0.0001  max mem: 10917
[14:06:21.891615] Epoch: [5]  [340/345]  eta: 0:00:01  lr: 0.000037  loss: 1.0256 (1.0798)  time: 0.2524  data: 0.0000  max mem: 10917
[14:06:22.900947] Epoch: [5]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 1.0265 (1.0792)  time: 0.2523  data: 0.0001  max mem: 10917
[14:06:22.955753] Epoch: [5] Total time: 0:01:26 (0.2517 s / it)
[14:06:22.956057] Averaged stats: lr: 0.000037  loss: 1.0265 (1.0792)
[14:06:23.190449] Test:  [  0/345]  eta: 0:01:19  loss: 1.0214 (1.0214)  time: 0.2304  data: 0.1502  max mem: 10917
[14:06:24.010186] Test:  [ 10/345]  eta: 0:00:31  loss: 1.0114 (1.0135)  time: 0.0954  data: 0.0137  max mem: 10917
[14:06:24.832983] Test:  [ 20/345]  eta: 0:00:28  loss: 1.0164 (1.0179)  time: 0.0821  data: 0.0001  max mem: 10917
[14:06:25.660164] Test:  [ 30/345]  eta: 0:00:27  loss: 1.0164 (1.0188)  time: 0.0824  data: 0.0001  max mem: 10917
[14:06:26.489381] Test:  [ 40/345]  eta: 0:00:26  loss: 1.0085 (1.0163)  time: 0.0828  data: 0.0001  max mem: 10917
[14:06:27.323170] Test:  [ 50/345]  eta: 0:00:25  loss: 1.0149 (1.0183)  time: 0.0831  data: 0.0001  max mem: 10917
[14:06:28.161156] Test:  [ 60/345]  eta: 0:00:24  loss: 1.0282 (1.0171)  time: 0.0835  data: 0.0001  max mem: 10917
[14:06:29.001982] Test:  [ 70/345]  eta: 0:00:23  loss: 1.0193 (1.0165)  time: 0.0839  data: 0.0001  max mem: 10917
[14:06:29.845963] Test:  [ 80/345]  eta: 0:00:22  loss: 1.0095 (1.0157)  time: 0.0842  data: 0.0001  max mem: 10917
[14:06:30.693551] Test:  [ 90/345]  eta: 0:00:21  loss: 1.0164 (1.0157)  time: 0.0845  data: 0.0001  max mem: 10917
[14:06:31.545988] Test:  [100/345]  eta: 0:00:20  loss: 1.0164 (1.0160)  time: 0.0849  data: 0.0001  max mem: 10917
[14:06:32.401163] Test:  [110/345]  eta: 0:00:19  loss: 1.0119 (1.0163)  time: 0.0853  data: 0.0001  max mem: 10917
[14:06:33.259419] Test:  [120/345]  eta: 0:00:19  loss: 1.0121 (1.0159)  time: 0.0856  data: 0.0001  max mem: 10917
[14:06:34.121419] Test:  [130/345]  eta: 0:00:18  loss: 1.0079 (1.0144)  time: 0.0860  data: 0.0001  max mem: 10917
[14:06:34.985951] Test:  [140/345]  eta: 0:00:17  loss: 0.9958 (1.0126)  time: 0.0863  data: 0.0001  max mem: 10917
[14:06:35.854264] Test:  [150/345]  eta: 0:00:16  loss: 1.0091 (1.0136)  time: 0.0866  data: 0.0001  max mem: 10917
[14:06:36.726483] Test:  [160/345]  eta: 0:00:15  loss: 1.0102 (1.0133)  time: 0.0870  data: 0.0001  max mem: 10917
[14:06:37.602791] Test:  [170/345]  eta: 0:00:14  loss: 1.0043 (1.0129)  time: 0.0874  data: 0.0001  max mem: 10917
[14:06:38.481923] Test:  [180/345]  eta: 0:00:14  loss: 1.0060 (1.0132)  time: 0.0877  data: 0.0001  max mem: 10917
[14:06:39.365248] Test:  [190/345]  eta: 0:00:13  loss: 1.0062 (1.0129)  time: 0.0881  data: 0.0001  max mem: 10917
[14:06:40.252102] Test:  [200/345]  eta: 0:00:12  loss: 1.0091 (1.0129)  time: 0.0885  data: 0.0001  max mem: 10917
[14:06:41.143041] Test:  [210/345]  eta: 0:00:11  loss: 1.0091 (1.0126)  time: 0.0888  data: 0.0001  max mem: 10917
[14:06:42.036426] Test:  [220/345]  eta: 0:00:10  loss: 1.0074 (1.0126)  time: 0.0892  data: 0.0001  max mem: 10917
[14:06:42.933816] Test:  [230/345]  eta: 0:00:09  loss: 1.0062 (1.0119)  time: 0.0895  data: 0.0001  max mem: 10917
[14:06:43.834973] Test:  [240/345]  eta: 0:00:09  loss: 1.0096 (1.0120)  time: 0.0899  data: 0.0001  max mem: 10917
[14:06:44.739069] Test:  [250/345]  eta: 0:00:08  loss: 1.0136 (1.0124)  time: 0.0902  data: 0.0001  max mem: 10917
[14:06:45.647100] Test:  [260/345]  eta: 0:00:07  loss: 1.0017 (1.0118)  time: 0.0906  data: 0.0001  max mem: 10917
[14:06:46.559631] Test:  [270/345]  eta: 0:00:06  loss: 1.0067 (1.0121)  time: 0.0910  data: 0.0001  max mem: 10917
[14:06:47.472431] Test:  [280/345]  eta: 0:00:05  loss: 1.0174 (1.0123)  time: 0.0912  data: 0.0001  max mem: 10917
[14:06:48.390627] Test:  [290/345]  eta: 0:00:04  loss: 1.0202 (1.0119)  time: 0.0915  data: 0.0001  max mem: 10917
[14:06:49.311737] Test:  [300/345]  eta: 0:00:03  loss: 0.9915 (1.0112)  time: 0.0919  data: 0.0001  max mem: 10917
[14:06:50.236255] Test:  [310/345]  eta: 0:00:03  loss: 1.0052 (1.0115)  time: 0.0922  data: 0.0001  max mem: 10917
[14:06:51.164842] Test:  [320/345]  eta: 0:00:02  loss: 1.0121 (1.0110)  time: 0.0926  data: 0.0001  max mem: 10917
[14:06:52.097722] Test:  [330/345]  eta: 0:00:01  loss: 1.0000 (1.0110)  time: 0.0930  data: 0.0001  max mem: 10917
[14:06:53.033450] Test:  [340/345]  eta: 0:00:00  loss: 1.0150 (1.0111)  time: 0.0934  data: 0.0001  max mem: 10917
[14:06:53.409169] Test:  [344/345]  eta: 0:00:00  loss: 1.0134 (1.0110)  time: 0.0935  data: 0.0001  max mem: 10917
[14:06:53.464451] Test: Total time: 0:00:30 (0.0884 s / it)
[14:07:04.766793] Test:  [ 0/57]  eta: 0:00:12  loss: 1.0801 (1.0801)  time: 0.2198  data: 0.1400  max mem: 10917
[14:07:05.577925] Test:  [10/57]  eta: 0:00:04  loss: 1.0728 (1.0546)  time: 0.0936  data: 0.0128  max mem: 10917
[14:07:06.393250] Test:  [20/57]  eta: 0:00:03  loss: 1.0579 (1.0535)  time: 0.0813  data: 0.0001  max mem: 10917
[14:07:07.213439] Test:  [30/57]  eta: 0:00:02  loss: 0.9946 (1.0092)  time: 0.0817  data: 0.0001  max mem: 10917
[14:07:08.036692] Test:  [40/57]  eta: 0:00:01  loss: 0.8961 (0.9808)  time: 0.0821  data: 0.0001  max mem: 10917
[14:07:08.864444] Test:  [50/57]  eta: 0:00:00  loss: 0.9164 (0.9706)  time: 0.0825  data: 0.0001  max mem: 10917
[14:07:09.313799] Test:  [56/57]  eta: 0:00:00  loss: 0.9330 (0.9732)  time: 0.0803  data: 0.0001  max mem: 10917
[14:07:09.371918] Test: Total time: 0:00:04 (0.0847 s / it)
[14:07:11.368696] Dice score of the network on the train images: 0.658531, val images: 0.732914
[14:07:11.368934] saving best_rec_model_0 @ epoch 5
[14:07:12.335778] saving best_dice_model_0 @ epoch 5
[14:07:13.125817] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:07:13.520411] Epoch: [6]  [  0/345]  eta: 0:02:15  lr: 0.000038  loss: 1.0136 (1.0136)  time: 0.3936  data: 0.1417  max mem: 10917
[14:07:18.520835] Epoch: [6]  [ 20/345]  eta: 0:01:23  lr: 0.000038  loss: 1.0197 (1.0161)  time: 0.2500  data: 0.0001  max mem: 10917
[14:07:23.524262] Epoch: [6]  [ 40/345]  eta: 0:01:17  lr: 0.000038  loss: 1.0107 (1.0140)  time: 0.2501  data: 0.0001  max mem: 10917
[14:07:28.528808] Epoch: [6]  [ 60/345]  eta: 0:01:11  lr: 0.000039  loss: 1.0020 (1.0127)  time: 0.2502  data: 0.0001  max mem: 10917
[14:07:33.544199] Epoch: [6]  [ 80/345]  eta: 0:01:06  lr: 0.000039  loss: 0.9902 (1.0075)  time: 0.2507  data: 0.0001  max mem: 10917
[14:07:38.566092] Epoch: [6]  [100/345]  eta: 0:01:01  lr: 0.000039  loss: 0.9886 (1.0040)  time: 0.2511  data: 0.0000  max mem: 10917
[14:07:43.602855] Epoch: [6]  [120/345]  eta: 0:00:56  lr: 0.000040  loss: 0.9804 (1.0014)  time: 0.2518  data: 0.0001  max mem: 10917
[14:07:48.628309] Epoch: [6]  [140/345]  eta: 0:00:51  lr: 0.000040  loss: 0.9782 (0.9984)  time: 0.2512  data: 0.0001  max mem: 10917
[14:07:53.655362] Epoch: [6]  [160/345]  eta: 0:00:46  lr: 0.000040  loss: 0.9756 (0.9962)  time: 0.2513  data: 0.0001  max mem: 10917

[14:07:58.686064] Epoch: [6]  [180/345]  eta: 0:00:41  lr: 0.000041  loss: 0.9711 (0.9941)  time: 0.2515  data: 0.0001  max mem: 10917
[14:08:03.720958] Epoch: [6]  [200/345]  eta: 0:00:36  lr: 0.000041  loss: 0.9581 (0.9908)  time: 0.2517  data: 0.0000  max mem: 10917
[14:08:08.754882] Epoch: [6]  [220/345]  eta: 0:00:31  lr: 0.000041  loss: 0.9585 (0.9883)  time: 0.2517  data: 0.0001  max mem: 10917
[14:08:13.790789] Epoch: [6]  [240/345]  eta: 0:00:26  lr: 0.000042  loss: 0.9444 (0.9847)  time: 0.2518  data: 0.0000  max mem: 10917
[14:08:18.831701] Epoch: [6]  [260/345]  eta: 0:00:21  lr: 0.000042  loss: 0.9592 (0.9825)  time: 0.2520  data: 0.0001  max mem: 10917
[14:08:23.880815] Epoch: [6]  [280/345]  eta: 0:00:16  lr: 0.000043  loss: 0.9454 (0.9800)  time: 0.2524  data: 0.0001  max mem: 10917
[14:08:28.926621] Epoch: [6]  [300/345]  eta: 0:00:11  lr: 0.000043  loss: 0.9468 (0.9778)  time: 0.2522  data: 0.0001  max mem: 10917
[14:08:33.979079] Epoch: [6]  [320/345]  eta: 0:00:06  lr: 0.000043  loss: 0.9362 (0.9749)  time: 0.2526  data: 0.0001  max mem: 10917
[14:08:39.031796] Epoch: [6]  [340/345]  eta: 0:00:01  lr: 0.000044  loss: 0.9218 (0.9722)  time: 0.2526  data: 0.0001  max mem: 10917
[14:08:40.040963] Epoch: [6]  [344/345]  eta: 0:00:00  lr: 0.000044  loss: 0.9191 (0.9718)  time: 0.2525  data: 0.0001  max mem: 10917
[14:08:40.097039] Epoch: [6] Total time: 0:01:26 (0.2521 s / it)
[14:08:40.097397] Averaged stats: lr: 0.000044  loss: 0.9191 (0.9718)
[14:08:40.338607] Test:  [  0/345]  eta: 0:01:21  loss: 0.9236 (0.9236)  time: 0.2374  data: 0.1571  max mem: 10917
[14:08:41.160854] Test:  [ 10/345]  eta: 0:00:32  loss: 0.9111 (0.9121)  time: 0.0962  data: 0.0146  max mem: 10917
[14:08:41.984354] Test:  [ 20/345]  eta: 0:00:29  loss: 0.9070 (0.9081)  time: 0.0822  data: 0.0002  max mem: 10917
[14:08:42.811835] Test:  [ 30/345]  eta: 0:00:27  loss: 0.9003 (0.9081)  time: 0.0825  data: 0.0001  max mem: 10917
[14:08:43.641888] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8981 (0.9072)  time: 0.0828  data: 0.0001  max mem: 10917
[14:08:44.476260] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8984 (0.9094)  time: 0.0832  data: 0.0001  max mem: 10917
[14:08:45.314568] Test:  [ 60/345]  eta: 0:00:24  loss: 0.9000 (0.9099)  time: 0.0836  data: 0.0001  max mem: 10917
[14:08:46.156370] Test:  [ 70/345]  eta: 0:00:23  loss: 0.9038 (0.9087)  time: 0.0840  data: 0.0001  max mem: 10917
[14:08:47.000986] Test:  [ 80/345]  eta: 0:00:22  loss: 0.9069 (0.9090)  time: 0.0843  data: 0.0001  max mem: 10917
[14:08:47.849349] Test:  [ 90/345]  eta: 0:00:21  loss: 0.9180 (0.9113)  time: 0.0846  data: 0.0001  max mem: 10917
[14:08:48.700999] Test:  [100/345]  eta: 0:00:20  loss: 0.9180 (0.9112)  time: 0.0849  data: 0.0001  max mem: 10917
[14:08:49.557368] Test:  [110/345]  eta: 0:00:20  loss: 0.9067 (0.9114)  time: 0.0853  data: 0.0001  max mem: 10917
[14:08:50.416186] Test:  [120/345]  eta: 0:00:19  loss: 0.9130 (0.9117)  time: 0.0857  data: 0.0001  max mem: 10917
[14:08:51.278698] Test:  [130/345]  eta: 0:00:18  loss: 0.9085 (0.9118)  time: 0.0860  data: 0.0001  max mem: 10917
[14:08:52.144272] Test:  [140/345]  eta: 0:00:17  loss: 0.9059 (0.9108)  time: 0.0864  data: 0.0001  max mem: 10917
[14:08:53.013888] Test:  [150/345]  eta: 0:00:16  loss: 0.9165 (0.9126)  time: 0.0867  data: 0.0001  max mem: 10917
[14:08:53.886294] Test:  [160/345]  eta: 0:00:15  loss: 0.9193 (0.9122)  time: 0.0871  data: 0.0001  max mem: 10917
[14:08:54.762932] Test:  [170/345]  eta: 0:00:14  loss: 0.9100 (0.9124)  time: 0.0874  data: 0.0001  max mem: 10917
[14:08:55.643621] Test:  [180/345]  eta: 0:00:14  loss: 0.9166 (0.9129)  time: 0.0878  data: 0.0001  max mem: 10917
[14:08:56.526707] Test:  [190/345]  eta: 0:00:13  loss: 0.9166 (0.9131)  time: 0.0881  data: 0.0001  max mem: 10917
[14:08:57.414226] Test:  [200/345]  eta: 0:00:12  loss: 0.9167 (0.9131)  time: 0.0885  data: 0.0001  max mem: 10917
[14:08:58.304771] Test:  [210/345]  eta: 0:00:11  loss: 0.9105 (0.9127)  time: 0.0889  data: 0.0001  max mem: 10917
[14:08:59.199973] Test:  [220/345]  eta: 0:00:10  loss: 0.9008 (0.9126)  time: 0.0892  data: 0.0001  max mem: 10917
[14:09:00.097939] Test:  [230/345]  eta: 0:00:09  loss: 0.9097 (0.9125)  time: 0.0896  data: 0.0001  max mem: 10917
[14:09:00.998197] Test:  [240/345]  eta: 0:00:09  loss: 0.9153 (0.9126)  time: 0.0899  data: 0.0001  max mem: 10917
[14:09:01.903238] Test:  [250/345]  eta: 0:00:08  loss: 0.9100 (0.9125)  time: 0.0902  data: 0.0001  max mem: 10917
[14:09:02.813193] Test:  [260/345]  eta: 0:00:07  loss: 0.9100 (0.9127)  time: 0.0907  data: 0.0001  max mem: 10917
[14:09:03.725353] Test:  [270/345]  eta: 0:00:06  loss: 0.9182 (0.9129)  time: 0.0911  data: 0.0001  max mem: 10917
[14:09:04.640563] Test:  [280/345]  eta: 0:00:05  loss: 0.9086 (0.9129)  time: 0.0913  data: 0.0001  max mem: 10917
[14:09:05.559334] Test:  [290/345]  eta: 0:00:04  loss: 0.9020 (0.9128)  time: 0.0917  data: 0.0001  max mem: 10917
[14:09:06.480889] Test:  [300/345]  eta: 0:00:03  loss: 0.9034 (0.9126)  time: 0.0920  data: 0.0001  max mem: 10917
[14:09:07.406753] Test:  [310/345]  eta: 0:00:03  loss: 0.9112 (0.9126)  time: 0.0923  data: 0.0001  max mem: 10917
[14:09:08.335523] Test:  [320/345]  eta: 0:00:02  loss: 0.9112 (0.9127)  time: 0.0927  data: 0.0001  max mem: 10917
[14:09:09.268862] Test:  [330/345]  eta: 0:00:01  loss: 0.9026 (0.9127)  time: 0.0931  data: 0.0001  max mem: 10917
[14:09:10.204854] Test:  [340/345]  eta: 0:00:00  loss: 0.9059 (0.9127)  time: 0.0934  data: 0.0001  max mem: 10917
[14:09:10.581063] Test:  [344/345]  eta: 0:00:00  loss: 0.9059 (0.9127)  time: 0.0936  data: 0.0001  max mem: 10917
[14:09:10.639054] Test: Total time: 0:00:30 (0.0885 s / it)
[14:09:21.805584] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9838 (0.9838)  time: 0.2207  data: 0.1412  max mem: 10917
[14:09:22.618858] Test:  [10/57]  eta: 0:00:04  loss: 0.9697 (0.9680)  time: 0.0939  data: 0.0129  max mem: 10917
[14:09:23.435109] Test:  [20/57]  eta: 0:00:03  loss: 0.9551 (0.9661)  time: 0.0814  data: 0.0001  max mem: 10917
[14:09:24.256362] Test:  [30/57]  eta: 0:00:02  loss: 0.8978 (0.9321)  time: 0.0818  data: 0.0001  max mem: 10917
[14:09:25.080970] Test:  [40/57]  eta: 0:00:01  loss: 0.8474 (0.9123)  time: 0.0822  data: 0.0001  max mem: 10917
[14:09:25.908710] Test:  [50/57]  eta: 0:00:00  loss: 0.8474 (0.9051)  time: 0.0826  data: 0.0001  max mem: 10917
[14:09:26.358665] Test:  [56/57]  eta: 0:00:00  loss: 0.8748 (0.9076)  time: 0.0804  data: 0.0001  max mem: 10917
[14:09:26.413149] Test: Total time: 0:00:04 (0.0847 s / it)
[14:09:28.441379] Dice score of the network on the train images: 0.732226, val images: 0.720835
[14:09:28.444933] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:09:28.845171] Epoch: [7]  [  0/345]  eta: 0:02:17  lr: 0.000044  loss: 0.8952 (0.8952)  time: 0.3992  data: 0.1466  max mem: 10917
[14:09:33.844793] Epoch: [7]  [ 20/345]  eta: 0:01:23  lr: 0.000044  loss: 0.9386 (0.9365)  time: 0.2499  data: 0.0001  max mem: 10917

[14:09:38.850773] Epoch: [7]  [ 40/345]  eta: 0:01:17  lr: 0.000044  loss: 0.9301 (0.9347)  time: 0.2503  data: 0.0001  max mem: 10917
[14:09:43.862630] Epoch: [7]  [ 60/345]  eta: 0:01:12  lr: 0.000045  loss: 0.9195 (0.9325)  time: 0.2505  data: 0.0001  max mem: 10917
[14:09:48.890314] Epoch: [7]  [ 80/345]  eta: 0:01:06  lr: 0.000045  loss: 0.9138 (0.9287)  time: 0.2513  data: 0.0001  max mem: 10917
[14:09:53.914127] Epoch: [7]  [100/345]  eta: 0:01:01  lr: 0.000046  loss: 0.9060 (0.9249)  time: 0.2511  data: 0.0001  max mem: 10917
[14:09:58.938435] Epoch: [7]  [120/345]  eta: 0:00:56  lr: 0.000046  loss: 0.9010 (0.9222)  time: 0.2512  data: 0.0001  max mem: 10917
[14:10:03.962935] Epoch: [7]  [140/345]  eta: 0:00:51  lr: 0.000046  loss: 0.9114 (0.9212)  time: 0.2512  data: 0.0000  max mem: 10917
[14:10:08.991894] Epoch: [7]  [160/345]  eta: 0:00:46  lr: 0.000047  loss: 0.9083 (0.9201)  time: 0.2514  data: 0.0000  max mem: 10917
[14:10:14.022983] Epoch: [7]  [180/345]  eta: 0:00:41  lr: 0.000047  loss: 0.9135 (0.9199)  time: 0.2515  data: 0.0000  max mem: 10917
[14:10:19.055704] Epoch: [7]  [200/345]  eta: 0:00:36  lr: 0.000047  loss: 0.9109 (0.9188)  time: 0.2516  data: 0.0000  max mem: 10917
[14:10:24.084994] Epoch: [7]  [220/345]  eta: 0:00:31  lr: 0.000048  loss: 0.9101 (0.9184)  time: 0.2514  data: 0.0001  max mem: 10917
[14:10:29.109579] Epoch: [7]  [240/345]  eta: 0:00:26  lr: 0.000048  loss: 0.8962 (0.9171)  time: 0.2512  data: 0.0001  max mem: 10917
[14:10:34.136332] Epoch: [7]  [260/345]  eta: 0:00:21  lr: 0.000048  loss: 0.8956 (0.9158)  time: 0.2513  data: 0.0000  max mem: 10917
[14:10:39.163975] Epoch: [7]  [280/345]  eta: 0:00:16  lr: 0.000049  loss: 0.8832 (0.9137)  time: 0.2513  data: 0.0001  max mem: 10917
[14:10:44.194428] Epoch: [7]  [300/345]  eta: 0:00:11  lr: 0.000049  loss: 0.9004 (0.9129)  time: 0.2515  data: 0.0001  max mem: 10917
[14:10:49.231606] Epoch: [7]  [320/345]  eta: 0:00:06  lr: 0.000050  loss: 0.9073 (0.9123)  time: 0.2518  data: 0.0001  max mem: 10917
[14:10:54.278235] Epoch: [7]  [340/345]  eta: 0:00:01  lr: 0.000050  loss: 0.8973 (0.9114)  time: 0.2523  data: 0.0000  max mem: 10917
[14:10:55.288627] Epoch: [7]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.8973 (0.9111)  time: 0.2523  data: 0.0001  max mem: 10917
[14:10:55.346466] Epoch: [7] Total time: 0:01:26 (0.2519 s / it)
[14:10:55.346586] Averaged stats: lr: 0.000050  loss: 0.8973 (0.9111)
[14:10:55.582603] Test:  [  0/345]  eta: 0:01:20  loss: 0.8508 (0.8508)  time: 0.2323  data: 0.1521  max mem: 10917
[14:10:56.404797] Test:  [ 10/345]  eta: 0:00:32  loss: 0.8517 (0.8577)  time: 0.0958  data: 0.0141  max mem: 10917
[14:10:57.228784] Test:  [ 20/345]  eta: 0:00:29  loss: 0.8580 (0.8545)  time: 0.0822  data: 0.0002  max mem: 10917
[14:10:58.055812] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8551 (0.8554)  time: 0.0825  data: 0.0001  max mem: 10917
[14:10:58.886842] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8528 (0.8584)  time: 0.0828  data: 0.0001  max mem: 10917
[14:10:59.720273] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8528 (0.8565)  time: 0.0832  data: 0.0001  max mem: 10917
[14:11:00.557250] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8606 (0.8580)  time: 0.0835  data: 0.0001  max mem: 10917
[14:11:01.398865] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8640 (0.8591)  time: 0.0839  data: 0.0001  max mem: 10917
[14:11:02.242911] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8535 (0.8590)  time: 0.0842  data: 0.0001  max mem: 10917
[14:11:03.091310] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8595 (0.8606)  time: 0.0846  data: 0.0001  max mem: 10917
[14:11:03.943098] Test:  [100/345]  eta: 0:00:20  loss: 0.8657 (0.8610)  time: 0.0850  data: 0.0001  max mem: 10917
[14:11:04.797964] Test:  [110/345]  eta: 0:00:19  loss: 0.8641 (0.8618)  time: 0.0853  data: 0.0001  max mem: 10917
[14:11:05.656623] Test:  [120/345]  eta: 0:00:19  loss: 0.8642 (0.8617)  time: 0.0856  data: 0.0001  max mem: 10917
[14:11:06.518952] Test:  [130/345]  eta: 0:00:18  loss: 0.8652 (0.8622)  time: 0.0860  data: 0.0001  max mem: 10917
[14:11:07.384182] Test:  [140/345]  eta: 0:00:17  loss: 0.8611 (0.8625)  time: 0.0863  data: 0.0001  max mem: 10917
[14:11:08.253535] Test:  [150/345]  eta: 0:00:16  loss: 0.8611 (0.8628)  time: 0.0867  data: 0.0001  max mem: 10917
[14:11:09.126535] Test:  [160/345]  eta: 0:00:15  loss: 0.8542 (0.8622)  time: 0.0871  data: 0.0001  max mem: 10917
[14:11:10.002495] Test:  [170/345]  eta: 0:00:14  loss: 0.8596 (0.8625)  time: 0.0874  data: 0.0001  max mem: 10917
[14:11:10.881803] Test:  [180/345]  eta: 0:00:14  loss: 0.8547 (0.8623)  time: 0.0877  data: 0.0001  max mem: 10917
[14:11:11.764755] Test:  [190/345]  eta: 0:00:13  loss: 0.8634 (0.8626)  time: 0.0881  data: 0.0001  max mem: 10917
[14:11:12.652184] Test:  [200/345]  eta: 0:00:12  loss: 0.8646 (0.8628)  time: 0.0885  data: 0.0001  max mem: 10917
[14:11:13.542777] Test:  [210/345]  eta: 0:00:11  loss: 0.8609 (0.8620)  time: 0.0889  data: 0.0001  max mem: 10917
[14:11:14.436262] Test:  [220/345]  eta: 0:00:10  loss: 0.8546 (0.8624)  time: 0.0892  data: 0.0001  max mem: 10917
[14:11:15.332608] Test:  [230/345]  eta: 0:00:09  loss: 0.8695 (0.8627)  time: 0.0894  data: 0.0001  max mem: 10917
[14:11:16.233700] Test:  [240/345]  eta: 0:00:09  loss: 0.8559 (0.8624)  time: 0.0898  data: 0.0001  max mem: 10917
[14:11:17.137196] Test:  [250/345]  eta: 0:00:08  loss: 0.8663 (0.8630)  time: 0.0902  data: 0.0001  max mem: 10917
[14:11:18.044897] Test:  [260/345]  eta: 0:00:07  loss: 0.8723 (0.8633)  time: 0.0905  data: 0.0001  max mem: 10917
[14:11:18.956435] Test:  [270/345]  eta: 0:00:06  loss: 0.8724 (0.8635)  time: 0.0909  data: 0.0001  max mem: 10917
[14:11:19.871506] Test:  [280/345]  eta: 0:00:05  loss: 0.8610 (0.8630)  time: 0.0913  data: 0.0001  max mem: 10917
[14:11:20.789753] Test:  [290/345]  eta: 0:00:04  loss: 0.8560 (0.8628)  time: 0.0916  data: 0.0001  max mem: 10917
[14:11:21.712078] Test:  [300/345]  eta: 0:00:03  loss: 0.8593 (0.8629)  time: 0.0920  data: 0.0001  max mem: 10917
[14:11:22.637092] Test:  [310/345]  eta: 0:00:03  loss: 0.8692 (0.8632)  time: 0.0923  data: 0.0001  max mem: 10917
[14:11:23.565661] Test:  [320/345]  eta: 0:00:02  loss: 0.8781 (0.8636)  time: 0.0926  data: 0.0001  max mem: 10917
[14:11:24.498174] Test:  [330/345]  eta: 0:00:01  loss: 0.8543 (0.8631)  time: 0.0930  data: 0.0001  max mem: 10917
[14:11:25.434170] Test:  [340/345]  eta: 0:00:00  loss: 0.8543 (0.8636)  time: 0.0934  data: 0.0001  max mem: 10917
[14:11:25.810043] Test:  [344/345]  eta: 0:00:00  loss: 0.8543 (0.8636)  time: 0.0935  data: 0.0001  max mem: 10917
[14:11:25.866591] Test: Total time: 0:00:30 (0.0885 s / it)
[14:11:37.109670] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9393 (0.9393)  time: 0.2233  data: 0.1435  max mem: 10917
[14:11:37.922406] Test:  [10/57]  eta: 0:00:04  loss: 0.9299 (0.9284)  time: 0.0941  data: 0.0131  max mem: 10917
[14:11:38.740071] Test:  [20/57]  eta: 0:00:03  loss: 0.9218 (0.9223)  time: 0.0815  data: 0.0001  max mem: 10917
[14:11:39.560528] Test:  [30/57]  eta: 0:00:02  loss: 0.8385 (0.8821)  time: 0.0818  data: 0.0001  max mem: 10917
[14:11:40.384524] Test:  [40/57]  eta: 0:00:01  loss: 0.7921 (0.8574)  time: 0.0822  data: 0.0001  max mem: 10917
[14:11:41.213345] Test:  [50/57]  eta: 0:00:00  loss: 0.7921 (0.8494)  time: 0.0826  data: 0.0001  max mem: 10917
[14:11:41.663290] Test:  [56/57]  eta: 0:00:00  loss: 0.8249 (0.8531)  time: 0.0803  data: 0.0001  max mem: 10917
[14:11:41.721033] Test: Total time: 0:00:04 (0.0848 s / it)
[14:11:43.734646] Dice score of the network on the train images: 0.736643, val images: 0.794322
[14:11:43.734886] saving best_rec_model_0 @ epoch 7
[14:11:44.616309] saving best_dice_model_0 @ epoch 7
[14:11:45.400414] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:11:45.806802] Epoch: [8]  [  0/345]  eta: 0:02:19  lr: 0.000050  loss: 0.8743 (0.8743)  time: 0.4054  data: 0.1526  max mem: 10917
[14:11:50.807477] Epoch: [8]  [ 20/345]  eta: 0:01:23  lr: 0.000050  loss: 0.8808 (0.8835)  time: 0.2500  data: 0.0001  max mem: 10917
[14:11:55.817693] Epoch: [8]  [ 40/345]  eta: 0:01:17  lr: 0.000051  loss: 0.8949 (0.8888)  time: 0.2505  data: 0.0001  max mem: 10917
[14:12:00.829556] Epoch: [8]  [ 60/345]  eta: 0:01:12  lr: 0.000051  loss: 0.8943 (0.8887)  time: 0.2505  data: 0.0001  max mem: 10917
[14:12:05.934431] Epoch: [8]  [ 80/345]  eta: 0:01:07  lr: 0.000051  loss: 0.8785 (0.8877)  time: 0.2552  data: 0.0001  max mem: 10917
[14:12:10.959416] Epoch: [8]  [100/345]  eta: 0:01:01  lr: 0.000052  loss: 0.8765 (0.8863)  time: 0.2512  data: 0.0001  max mem: 10917
[14:12:15.987304] Epoch: [8]  [120/345]  eta: 0:00:56  lr: 0.000052  loss: 0.8875 (0.8863)  time: 0.2514  data: 0.0001  max mem: 10917
[14:12:21.016565] Epoch: [8]  [140/345]  eta: 0:00:51  lr: 0.000053  loss: 0.8757 (0.8857)  time: 0.2514  data: 0.0001  max mem: 10917
[14:12:26.046229] Epoch: [8]  [160/345]  eta: 0:00:46  lr: 0.000053  loss: 0.8912 (0.8858)  time: 0.2514  data: 0.0001  max mem: 10917

[14:12:31.079418] Epoch: [8]  [180/345]  eta: 0:00:41  lr: 0.000053  loss: 0.8679 (0.8842)  time: 0.2516  data: 0.0001  max mem: 10917
[14:12:36.117112] Epoch: [8]  [200/345]  eta: 0:00:36  lr: 0.000054  loss: 0.8807 (0.8841)  time: 0.2518  data: 0.0001  max mem: 10917
[14:12:41.159163] Epoch: [8]  [220/345]  eta: 0:00:31  lr: 0.000054  loss: 0.8945 (0.8850)  time: 0.2521  data: 0.0000  max mem: 10917
[14:12:46.203442] Epoch: [8]  [240/345]  eta: 0:00:26  lr: 0.000054  loss: 0.8668 (0.8836)  time: 0.2522  data: 0.0000  max mem: 10917
[14:12:51.246804] Epoch: [8]  [260/345]  eta: 0:00:21  lr: 0.000055  loss: 0.8682 (0.8829)  time: 0.2521  data: 0.0000  max mem: 10917
[14:12:56.296680] Epoch: [8]  [280/345]  eta: 0:00:16  lr: 0.000055  loss: 0.8629 (0.8821)  time: 0.2524  data: 0.0001  max mem: 10917
[14:13:01.347028] Epoch: [8]  [300/345]  eta: 0:00:11  lr: 0.000055  loss: 0.8679 (0.8815)  time: 0.2525  data: 0.0000  max mem: 10917
[14:13:06.403353] Epoch: [8]  [320/345]  eta: 0:00:06  lr: 0.000056  loss: 0.8861 (0.8814)  time: 0.2528  data: 0.0001  max mem: 10917
[14:13:11.457141] Epoch: [8]  [340/345]  eta: 0:00:01  lr: 0.000056  loss: 0.8717 (0.8805)  time: 0.2526  data: 0.0000  max mem: 10917
[14:13:12.468781] Epoch: [8]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.8717 (0.8804)  time: 0.2527  data: 0.0001  max mem: 10917
[14:13:12.533389] Epoch: [8] Total time: 0:01:27 (0.2526 s / it)
[14:13:12.533857] Averaged stats: lr: 0.000056  loss: 0.8717 (0.8804)
[14:13:12.777966] Test:  [  0/345]  eta: 0:01:22  loss: 0.8955 (0.8955)  time: 0.2401  data: 0.1598  max mem: 10917
[14:13:13.636342] Test:  [ 10/345]  eta: 0:00:33  loss: 0.8411 (0.8423)  time: 0.0998  data: 0.0182  max mem: 10917
[14:13:14.459945] Test:  [ 20/345]  eta: 0:00:29  loss: 0.8367 (0.8386)  time: 0.0840  data: 0.0021  max mem: 10917
[14:13:15.287121] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8254 (0.8353)  time: 0.0825  data: 0.0001  max mem: 10917
[14:13:16.116697] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8236 (0.8362)  time: 0.0828  data: 0.0001  max mem: 10917
[14:13:16.950660] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8299 (0.8360)  time: 0.0831  data: 0.0001  max mem: 10917
[14:13:17.788519] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8270 (0.8343)  time: 0.0835  data: 0.0001  max mem: 10917
[14:13:18.629467] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8245 (0.8347)  time: 0.0839  data: 0.0001  max mem: 10917
[14:13:19.474165] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8272 (0.8357)  time: 0.0842  data: 0.0001  max mem: 10917
[14:13:20.322945] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8362 (0.8363)  time: 0.0846  data: 0.0001  max mem: 10917
[14:13:21.173874] Test:  [100/345]  eta: 0:00:20  loss: 0.8369 (0.8376)  time: 0.0849  data: 0.0001  max mem: 10917
[14:13:22.029429] Test:  [110/345]  eta: 0:00:20  loss: 0.8472 (0.8383)  time: 0.0853  data: 0.0001  max mem: 10917
[14:13:22.888282] Test:  [120/345]  eta: 0:00:19  loss: 0.8504 (0.8392)  time: 0.0857  data: 0.0001  max mem: 10917
[14:13:23.750351] Test:  [130/345]  eta: 0:00:18  loss: 0.8520 (0.8392)  time: 0.0860  data: 0.0001  max mem: 10917
[14:13:24.616246] Test:  [140/345]  eta: 0:00:17  loss: 0.8424 (0.8399)  time: 0.0864  data: 0.0001  max mem: 10917
[14:13:25.486105] Test:  [150/345]  eta: 0:00:16  loss: 0.8431 (0.8402)  time: 0.0867  data: 0.0001  max mem: 10917
[14:13:26.358886] Test:  [160/345]  eta: 0:00:15  loss: 0.8278 (0.8390)  time: 0.0871  data: 0.0001  max mem: 10917
[14:13:27.235514] Test:  [170/345]  eta: 0:00:15  loss: 0.8243 (0.8392)  time: 0.0874  data: 0.0001  max mem: 10917
[14:13:28.116088] Test:  [180/345]  eta: 0:00:14  loss: 0.8416 (0.8393)  time: 0.0878  data: 0.0001  max mem: 10917
[14:13:28.999571] Test:  [190/345]  eta: 0:00:13  loss: 0.8328 (0.8389)  time: 0.0882  data: 0.0001  max mem: 10917
[14:13:29.887617] Test:  [200/345]  eta: 0:00:12  loss: 0.8372 (0.8392)  time: 0.0885  data: 0.0001  max mem: 10917
[14:13:30.778936] Test:  [210/345]  eta: 0:00:11  loss: 0.8374 (0.8392)  time: 0.0889  data: 0.0001  max mem: 10917
[14:13:31.672617] Test:  [220/345]  eta: 0:00:10  loss: 0.8332 (0.8391)  time: 0.0892  data: 0.0001  max mem: 10917
[14:13:32.570761] Test:  [230/345]  eta: 0:00:09  loss: 0.8345 (0.8389)  time: 0.0895  data: 0.0001  max mem: 10917
[14:13:33.471335] Test:  [240/345]  eta: 0:00:09  loss: 0.8424 (0.8391)  time: 0.0899  data: 0.0001  max mem: 10917
[14:13:34.376671] Test:  [250/345]  eta: 0:00:08  loss: 0.8427 (0.8394)  time: 0.0902  data: 0.0001  max mem: 10917
[14:13:35.285434] Test:  [260/345]  eta: 0:00:07  loss: 0.8434 (0.8395)  time: 0.0907  data: 0.0001  max mem: 10917
[14:13:36.196598] Test:  [270/345]  eta: 0:00:06  loss: 0.8505 (0.8400)  time: 0.0909  data: 0.0001  max mem: 10917
[14:13:37.111737] Test:  [280/345]  eta: 0:00:05  loss: 0.8356 (0.8398)  time: 0.0913  data: 0.0001  max mem: 10917
[14:13:38.030631] Test:  [290/345]  eta: 0:00:04  loss: 0.8340 (0.8396)  time: 0.0917  data: 0.0001  max mem: 10917
[14:13:38.953295] Test:  [300/345]  eta: 0:00:03  loss: 0.8403 (0.8397)  time: 0.0920  data: 0.0001  max mem: 10917
[14:13:39.878855] Test:  [310/345]  eta: 0:00:03  loss: 0.8458 (0.8396)  time: 0.0924  data: 0.0001  max mem: 10917
[14:13:40.808932] Test:  [320/345]  eta: 0:00:02  loss: 0.8458 (0.8398)  time: 0.0927  data: 0.0001  max mem: 10917
[14:13:41.741635] Test:  [330/345]  eta: 0:00:01  loss: 0.8330 (0.8395)  time: 0.0931  data: 0.0001  max mem: 10917
[14:13:42.676932] Test:  [340/345]  eta: 0:00:00  loss: 0.8288 (0.8395)  time: 0.0934  data: 0.0001  max mem: 10917
[14:13:43.053422] Test:  [344/345]  eta: 0:00:00  loss: 0.8321 (0.8396)  time: 0.0935  data: 0.0001  max mem: 10917
[14:13:43.109084] Test: Total time: 0:00:30 (0.0886 s / it)
[14:13:54.267285] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9330 (0.9330)  time: 0.2251  data: 0.1453  max mem: 10917
[14:13:55.079501] Test:  [10/57]  eta: 0:00:04  loss: 0.9043 (0.9146)  time: 0.0942  data: 0.0133  max mem: 10917
[14:13:55.896753] Test:  [20/57]  eta: 0:00:03  loss: 0.9043 (0.9085)  time: 0.0814  data: 0.0001  max mem: 10917
[14:13:56.718005] Test:  [30/57]  eta: 0:00:02  loss: 0.8159 (0.8708)  time: 0.0819  data: 0.0001  max mem: 10917
[14:13:57.542504] Test:  [40/57]  eta: 0:00:01  loss: 0.7915 (0.8479)  time: 0.0822  data: 0.0001  max mem: 10917
[14:13:58.371256] Test:  [50/57]  eta: 0:00:00  loss: 0.7915 (0.8406)  time: 0.0826  data: 0.0001  max mem: 10917
[14:13:58.820876] Test:  [56/57]  eta: 0:00:00  loss: 0.8177 (0.8437)  time: 0.0803  data: 0.0001  max mem: 10917
[14:13:58.878498] Test: Total time: 0:00:04 (0.0849 s / it)
[14:14:00.847511] Dice score of the network on the train images: 0.749578, val images: 0.785469
[14:14:00.850998] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:14:01.251635] Epoch: [9]  [  0/345]  eta: 0:02:17  lr: 0.000056  loss: 0.8375 (0.8375)  time: 0.3978  data: 0.1455  max mem: 10917
[14:14:06.259478] Epoch: [9]  [ 20/345]  eta: 0:01:23  lr: 0.000057  loss: 0.8661 (0.8670)  time: 0.2503  data: 0.0001  max mem: 10917
[14:14:11.270064] Epoch: [9]  [ 40/345]  eta: 0:01:17  lr: 0.000057  loss: 0.8747 (0.8734)  time: 0.2505  data: 0.0001  max mem: 10917
[14:14:16.284292] Epoch: [9]  [ 60/345]  eta: 0:01:12  lr: 0.000057  loss: 0.8705 (0.8733)  time: 0.2507  data: 0.0001  max mem: 10917
[14:14:21.304460] Epoch: [9]  [ 80/345]  eta: 0:01:06  lr: 0.000058  loss: 0.8659 (0.8717)  time: 0.2510  data: 0.0000  max mem: 10917
[14:14:26.329379] Epoch: [9]  [100/345]  eta: 0:01:01  lr: 0.000058  loss: 0.8572 (0.8692)  time: 0.2512  data: 0.0001  max mem: 10917
[14:14:31.355687] Epoch: [9]  [120/345]  eta: 0:00:56  lr: 0.000058  loss: 0.8552 (0.8677)  time: 0.2513  data: 0.0000  max mem: 10917
[14:14:36.385835] Epoch: [9]  [140/345]  eta: 0:00:51  lr: 0.000059  loss: 0.8518 (0.8658)  time: 0.2515  data: 0.0001  max mem: 10917
[14:14:41.415869] Epoch: [9]  [160/345]  eta: 0:00:46  lr: 0.000059  loss: 0.8696 (0.8668)  time: 0.2515  data: 0.0001  max mem: 10917
[14:14:46.449360] Epoch: [9]  [180/345]  eta: 0:00:41  lr: 0.000060  loss: 0.8629 (0.8665)  time: 0.2516  data: 0.0001  max mem: 10917
[14:14:51.488164] Epoch: [9]  [200/345]  eta: 0:00:36  lr: 0.000060  loss: 0.8505 (0.8649)  time: 0.2519  data: 0.0001  max mem: 10917
[14:14:56.524136] Epoch: [9]  [220/345]  eta: 0:00:31  lr: 0.000060  loss: 0.8524 (0.8636)  time: 0.2518  data: 0.0001  max mem: 10917
[14:15:01.562106] Epoch: [9]  [240/345]  eta: 0:00:26  lr: 0.000061  loss: 0.8511 (0.8632)  time: 0.2519  data: 0.0000  max mem: 10917
[14:15:06.606449] Epoch: [9]  [260/345]  eta: 0:00:21  lr: 0.000061  loss: 0.8739 (0.8643)  time: 0.2522  data: 0.0001  max mem: 10917
[14:15:11.652580] Epoch: [9]  [280/345]  eta: 0:00:16  lr: 0.000061  loss: 0.8572 (0.8639)  time: 0.2523  data: 0.0001  max mem: 10917
[14:15:16.697448] Epoch: [9]  [300/345]  eta: 0:00:11  lr: 0.000062  loss: 0.8553 (0.8637)  time: 0.2522  data: 0.0001  max mem: 10917
[14:15:21.745412] Epoch: [9]  [320/345]  eta: 0:00:06  lr: 0.000062  loss: 0.8502 (0.8638)  time: 0.2524  data: 0.0001  max mem: 10917
[14:15:26.794759] Epoch: [9]  [340/345]  eta: 0:00:01  lr: 0.000062  loss: 0.8528 (0.8632)  time: 0.2524  data: 0.0000  max mem: 10917
[14:15:27.803909] Epoch: [9]  [344/345]  eta: 0:00:00  lr: 0.000062  loss: 0.8520 (0.8632)  time: 0.2523  data: 0.0001  max mem: 10917
[14:15:27.860707] Epoch: [9] Total time: 0:01:27 (0.2522 s / it)
[14:15:27.861161] Averaged stats: lr: 0.000062  loss: 0.8520 (0.8632)
[14:15:28.097325] Test:  [  0/345]  eta: 0:01:20  loss: 0.8423 (0.8423)  time: 0.2322  data: 0.1523  max mem: 10917
[14:15:28.949770] Test:  [ 10/345]  eta: 0:00:33  loss: 0.8250 (0.8249)  time: 0.0985  data: 0.0170  max mem: 10917
[14:15:29.773482] Test:  [ 20/345]  eta: 0:00:29  loss: 0.8278 (0.8294)  time: 0.0837  data: 0.0018  max mem: 10917
[14:15:30.601873] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8314 (0.8282)  time: 0.0826  data: 0.0001  max mem: 10917
[14:15:31.432355] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8296 (0.8299)  time: 0.0829  data: 0.0001  max mem: 10917
[14:15:32.266213] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8292 (0.8289)  time: 0.0832  data: 0.0001  max mem: 10917
[14:15:33.103703] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8154 (0.8262)  time: 0.0835  data: 0.0001  max mem: 10917
[14:15:33.945467] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8091 (0.8258)  time: 0.0839  data: 0.0001  max mem: 10917
[14:15:34.789575] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8227 (0.8262)  time: 0.0842  data: 0.0001  max mem: 10917
[14:15:35.638523] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8395 (0.8271)  time: 0.0846  data: 0.0001  max mem: 10917
[14:15:36.490242] Test:  [100/345]  eta: 0:00:20  loss: 0.8327 (0.8271)  time: 0.0850  data: 0.0001  max mem: 10917
[14:15:37.345668] Test:  [110/345]  eta: 0:00:20  loss: 0.8328 (0.8284)  time: 0.0853  data: 0.0001  max mem: 10917
[14:15:38.204712] Test:  [120/345]  eta: 0:00:19  loss: 0.8228 (0.8274)  time: 0.0857  data: 0.0001  max mem: 10917
[14:15:39.066610] Test:  [130/345]  eta: 0:00:18  loss: 0.8163 (0.8268)  time: 0.0860  data: 0.0001  max mem: 10917
[14:15:39.932759] Test:  [140/345]  eta: 0:00:17  loss: 0.8243 (0.8271)  time: 0.0864  data: 0.0001  max mem: 10917
[14:15:40.801988] Test:  [150/345]  eta: 0:00:16  loss: 0.8311 (0.8275)  time: 0.0867  data: 0.0001  max mem: 10917
[14:15:41.675218] Test:  [160/345]  eta: 0:00:15  loss: 0.8399 (0.8287)  time: 0.0871  data: 0.0001  max mem: 10917
[14:15:42.551039] Test:  [170/345]  eta: 0:00:15  loss: 0.8431 (0.8288)  time: 0.0874  data: 0.0001  max mem: 10917
[14:15:43.430982] Test:  [180/345]  eta: 0:00:14  loss: 0.8282 (0.8286)  time: 0.0877  data: 0.0001  max mem: 10917
[14:15:44.313852] Test:  [190/345]  eta: 0:00:13  loss: 0.8273 (0.8288)  time: 0.0881  data: 0.0001  max mem: 10917
[14:15:45.200698] Test:  [200/345]  eta: 0:00:12  loss: 0.8399 (0.8297)  time: 0.0884  data: 0.0001  max mem: 10917
[14:15:46.090408] Test:  [210/345]  eta: 0:00:11  loss: 0.8224 (0.8286)  time: 0.0888  data: 0.0001  max mem: 10917
[14:15:46.983534] Test:  [220/345]  eta: 0:00:10  loss: 0.8083 (0.8280)  time: 0.0891  data: 0.0001  max mem: 10917
[14:15:47.880909] Test:  [230/345]  eta: 0:00:09  loss: 0.8081 (0.8275)  time: 0.0895  data: 0.0001  max mem: 10917
[14:15:48.782755] Test:  [240/345]  eta: 0:00:09  loss: 0.8134 (0.8276)  time: 0.0899  data: 0.0001  max mem: 10917
[14:15:49.687007] Test:  [250/345]  eta: 0:00:08  loss: 0.8221 (0.8276)  time: 0.0903  data: 0.0001  max mem: 10917
[14:15:50.595081] Test:  [260/345]  eta: 0:00:07  loss: 0.8226 (0.8275)  time: 0.0906  data: 0.0001  max mem: 10917
[14:15:51.507027] Test:  [270/345]  eta: 0:00:06  loss: 0.8245 (0.8277)  time: 0.0910  data: 0.0001  max mem: 10917
[14:15:52.421536] Test:  [280/345]  eta: 0:00:05  loss: 0.8249 (0.8277)  time: 0.0913  data: 0.0001  max mem: 10917
[14:15:53.340053] Test:  [290/345]  eta: 0:00:04  loss: 0.8225 (0.8278)  time: 0.0916  data: 0.0001  max mem: 10917
[14:15:54.262272] Test:  [300/345]  eta: 0:00:03  loss: 0.8432 (0.8283)  time: 0.0920  data: 0.0001  max mem: 10917
[14:15:55.187875] Test:  [310/345]  eta: 0:00:03  loss: 0.8358 (0.8281)  time: 0.0923  data: 0.0001  max mem: 10917
[14:15:56.115997] Test:  [320/345]  eta: 0:00:02  loss: 0.8123 (0.8278)  time: 0.0926  data: 0.0001  max mem: 10917
[14:15:57.048878] Test:  [330/345]  eta: 0:00:01  loss: 0.8240 (0.8280)  time: 0.0930  data: 0.0001  max mem: 10917
[14:15:57.984321] Test:  [340/345]  eta: 0:00:00  loss: 0.8251 (0.8280)  time: 0.0934  data: 0.0001  max mem: 10917
[14:15:58.360062] Test:  [344/345]  eta: 0:00:00  loss: 0.8257 (0.8280)  time: 0.0935  data: 0.0001  max mem: 10917
[14:15:58.417346] Test: Total time: 0:00:30 (0.0886 s / it)
[14:16:09.578571] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9187 (0.9187)  time: 0.2230  data: 0.1433  max mem: 10917
[14:16:10.391579] Test:  [10/57]  eta: 0:00:04  loss: 0.9187 (0.9170)  time: 0.0941  data: 0.0131  max mem: 10917
[14:16:11.207857] Test:  [20/57]  eta: 0:00:03  loss: 0.9109 (0.9114)  time: 0.0814  data: 0.0001  max mem: 10917
[14:16:12.028705] Test:  [30/57]  eta: 0:00:02  loss: 0.8096 (0.8720)  time: 0.0818  data: 0.0001  max mem: 10917
[14:16:12.852325] Test:  [40/57]  eta: 0:00:01  loss: 0.7927 (0.8491)  time: 0.0822  data: 0.0001  max mem: 10917
[14:16:13.679966] Test:  [50/57]  eta: 0:00:00  loss: 0.7927 (0.8413)  time: 0.0825  data: 0.0001  max mem: 10917
[14:16:14.130005] Test:  [56/57]  eta: 0:00:00  loss: 0.8069 (0.8439)  time: 0.0803  data: 0.0001  max mem: 10917
[14:16:14.184155] Test: Total time: 0:00:04 (0.0847 s / it)
[14:16:16.175556] Dice score of the network on the train images: 0.769099, val images: 0.795850
[14:16:16.175796] saving best_dice_model_0 @ epoch 9
[14:16:17.047994] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:16:17.448562] Epoch: [10]  [  0/345]  eta: 0:02:17  lr: 0.000063  loss: 0.7999 (0.7999)  time: 0.3993  data: 0.1480  max mem: 10917
[14:16:22.449359] Epoch: [10]  [ 20/345]  eta: 0:01:23  lr: 0.000063  loss: 0.8570 (0.8514)  time: 0.2500  data: 0.0001  max mem: 10917
[14:16:27.451267] Epoch: [10]  [ 40/345]  eta: 0:01:17  lr: 0.000063  loss: 0.8591 (0.8546)  time: 0.2500  data: 0.0001  max mem: 10917
[14:16:32.460571] Epoch: [10]  [ 60/345]  eta: 0:01:11  lr: 0.000064  loss: 0.8507 (0.8529)  time: 0.2504  data: 0.0000  max mem: 10917
[14:16:37.482393] Epoch: [10]  [ 80/345]  eta: 0:01:06  lr: 0.000064  loss: 0.8614 (0.8548)  time: 0.2510  data: 0.0001  max mem: 10917
[14:16:42.504002] Epoch: [10]  [100/345]  eta: 0:01:01  lr: 0.000064  loss: 0.8492 (0.8539)  time: 0.2510  data: 0.0001  max mem: 10917
[14:16:47.531555] Epoch: [10]  [120/345]  eta: 0:00:56  lr: 0.000065  loss: 0.8472 (0.8534)  time: 0.2513  data: 0.0001  max mem: 10917
[14:16:52.557279] Epoch: [10]  [140/345]  eta: 0:00:51  lr: 0.000065  loss: 0.8320 (0.8515)  time: 0.2512  data: 0.0000  max mem: 10917
[14:16:57.590646] Epoch: [10]  [160/345]  eta: 0:00:46  lr: 0.000065  loss: 0.8446 (0.8504)  time: 0.2516  data: 0.0000  max mem: 10917
[14:17:02.624894] Epoch: [10]  [180/345]  eta: 0:00:41  lr: 0.000066  loss: 0.8499 (0.8502)  time: 0.2517  data: 0.0000  max mem: 10917
[14:17:07.657782] Epoch: [10]  [200/345]  eta: 0:00:36  lr: 0.000066  loss: 0.8518 (0.8502)  time: 0.2516  data: 0.0000  max mem: 10917
[14:17:12.699822] Epoch: [10]  [220/345]  eta: 0:00:31  lr: 0.000066  loss: 0.8478 (0.8499)  time: 0.2521  data: 0.0001  max mem: 10917
[14:17:17.740884] Epoch: [10]  [240/345]  eta: 0:00:26  lr: 0.000067  loss: 0.8377 (0.8495)  time: 0.2520  data: 0.0000  max mem: 10917
[14:17:22.784739] Epoch: [10]  [260/345]  eta: 0:00:21  lr: 0.000067  loss: 0.8652 (0.8505)  time: 0.2521  data: 0.0001  max mem: 10917
[14:17:27.828888] Epoch: [10]  [280/345]  eta: 0:00:16  lr: 0.000068  loss: 0.8569 (0.8510)  time: 0.2522  data: 0.0000  max mem: 10917
[14:17:32.875446] Epoch: [10]  [300/345]  eta: 0:00:11  lr: 0.000068  loss: 0.8536 (0.8513)  time: 0.2523  data: 0.0000  max mem: 10917
[14:17:37.923790] Epoch: [10]  [320/345]  eta: 0:00:06  lr: 0.000068  loss: 0.8602 (0.8519)  time: 0.2524  data: 0.0001  max mem: 10917
[14:17:42.967186] Epoch: [10]  [340/345]  eta: 0:00:01  lr: 0.000069  loss: 0.8457 (0.8519)  time: 0.2521  data: 0.0000  max mem: 10917
[14:17:43.976258] Epoch: [10]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.8382 (0.8517)  time: 0.2521  data: 0.0001  max mem: 10917
[14:17:44.032681] Epoch: [10] Total time: 0:01:26 (0.2521 s / it)
[14:17:44.033190] Averaged stats: lr: 0.000069  loss: 0.8382 (0.8517)
[14:17:44.277828] Test:  [  0/345]  eta: 0:01:23  loss: 0.8162 (0.8162)  time: 0.2409  data: 0.1609  max mem: 10917
[14:17:45.138539] Test:  [ 10/345]  eta: 0:00:33  loss: 0.8155 (0.8196)  time: 0.1001  data: 0.0185  max mem: 10917
[14:17:45.961555] Test:  [ 20/345]  eta: 0:00:29  loss: 0.8155 (0.8190)  time: 0.0841  data: 0.0022  max mem: 10917
[14:17:46.787380] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8145 (0.8189)  time: 0.0824  data: 0.0001  max mem: 10917
[14:17:47.617897] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8134 (0.8177)  time: 0.0828  data: 0.0001  max mem: 10917
[14:17:48.451001] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8146 (0.8205)  time: 0.0831  data: 0.0001  max mem: 10917
[14:17:49.287726] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8213 (0.8218)  time: 0.0834  data: 0.0001  max mem: 10917
[14:17:50.128146] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8192 (0.8209)  time: 0.0838  data: 0.0001  max mem: 10917
[14:17:50.971643] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8146 (0.8200)  time: 0.0841  data: 0.0001  max mem: 10917
[14:17:51.819552] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8138 (0.8202)  time: 0.0845  data: 0.0001  max mem: 10917
[14:17:52.671363] Test:  [100/345]  eta: 0:00:20  loss: 0.8259 (0.8212)  time: 0.0849  data: 0.0001  max mem: 10917
[14:17:53.526244] Test:  [110/345]  eta: 0:00:20  loss: 0.8242 (0.8204)  time: 0.0853  data: 0.0001  max mem: 10917
[14:17:54.384829] Test:  [120/345]  eta: 0:00:19  loss: 0.8116 (0.8196)  time: 0.0856  data: 0.0001  max mem: 10917
[14:17:55.247275] Test:  [130/345]  eta: 0:00:18  loss: 0.8210 (0.8201)  time: 0.0860  data: 0.0001  max mem: 10917
[14:17:56.112534] Test:  [140/345]  eta: 0:00:17  loss: 0.8147 (0.8192)  time: 0.0863  data: 0.0001  max mem: 10917
[14:17:56.981654] Test:  [150/345]  eta: 0:00:16  loss: 0.8077 (0.8190)  time: 0.0867  data: 0.0001  max mem: 10917
[14:17:57.854994] Test:  [160/345]  eta: 0:00:15  loss: 0.8061 (0.8191)  time: 0.0871  data: 0.0001  max mem: 10917
[14:17:58.731442] Test:  [170/345]  eta: 0:00:15  loss: 0.8183 (0.8191)  time: 0.0874  data: 0.0001  max mem: 10917
[14:17:59.611217] Test:  [180/345]  eta: 0:00:14  loss: 0.8149 (0.8186)  time: 0.0878  data: 0.0001  max mem: 10917
[14:18:00.493585] Test:  [190/345]  eta: 0:00:13  loss: 0.8080 (0.8184)  time: 0.0881  data: 0.0001  max mem: 10917
[14:18:01.380400] Test:  [200/345]  eta: 0:00:12  loss: 0.8154 (0.8187)  time: 0.0884  data: 0.0001  max mem: 10917
[14:18:02.271097] Test:  [210/345]  eta: 0:00:11  loss: 0.8144 (0.8186)  time: 0.0888  data: 0.0001  max mem: 10917
[14:18:03.164680] Test:  [220/345]  eta: 0:00:10  loss: 0.8108 (0.8185)  time: 0.0892  data: 0.0001  max mem: 10917
[14:18:04.062777] Test:  [230/345]  eta: 0:00:09  loss: 0.7953 (0.8176)  time: 0.0895  data: 0.0001  max mem: 10917
[14:18:04.963537] Test:  [240/345]  eta: 0:00:09  loss: 0.8038 (0.8179)  time: 0.0899  data: 0.0001  max mem: 10917
[14:18:05.866769] Test:  [250/345]  eta: 0:00:08  loss: 0.8254 (0.8183)  time: 0.0902  data: 0.0001  max mem: 10917
[14:18:06.774594] Test:  [260/345]  eta: 0:00:07  loss: 0.8235 (0.8184)  time: 0.0905  data: 0.0001  max mem: 10917
[14:18:07.685785] Test:  [270/345]  eta: 0:00:06  loss: 0.8188 (0.8182)  time: 0.0909  data: 0.0001  max mem: 10917
[14:18:08.599984] Test:  [280/345]  eta: 0:00:05  loss: 0.8056 (0.8180)  time: 0.0912  data: 0.0001  max mem: 10917
[14:18:09.518845] Test:  [290/345]  eta: 0:00:04  loss: 0.8084 (0.8180)  time: 0.0916  data: 0.0001  max mem: 10917
[14:18:10.440235] Test:  [300/345]  eta: 0:00:03  loss: 0.8148 (0.8183)  time: 0.0920  data: 0.0001  max mem: 10917
[14:18:11.365699] Test:  [310/345]  eta: 0:00:03  loss: 0.8225 (0.8185)  time: 0.0923  data: 0.0001  max mem: 10917
[14:18:12.293923] Test:  [320/345]  eta: 0:00:02  loss: 0.8269 (0.8187)  time: 0.0926  data: 0.0001  max mem: 10917
[14:18:13.225704] Test:  [330/345]  eta: 0:00:01  loss: 0.8233 (0.8187)  time: 0.0930  data: 0.0001  max mem: 10917
[14:18:14.159732] Test:  [340/345]  eta: 0:00:00  loss: 0.8151 (0.8186)  time: 0.0932  data: 0.0001  max mem: 10917
[14:18:14.534855] Test:  [344/345]  eta: 0:00:00  loss: 0.8188 (0.8189)  time: 0.0934  data: 0.0001  max mem: 10917
[14:18:14.590435] Test: Total time: 0:00:30 (0.0886 s / it)
[14:18:25.598567] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9163 (0.9163)  time: 0.2225  data: 0.1429  max mem: 10917
[14:18:26.411388] Test:  [10/57]  eta: 0:00:04  loss: 0.9138 (0.9116)  time: 0.0940  data: 0.0131  max mem: 10917
[14:18:27.228527] Test:  [20/57]  eta: 0:00:03  loss: 0.9026 (0.9076)  time: 0.0814  data: 0.0001  max mem: 10917
[14:18:28.049117] Test:  [30/57]  eta: 0:00:02  loss: 0.8064 (0.8693)  time: 0.0818  data: 0.0001  max mem: 10917
[14:18:28.873455] Test:  [40/57]  eta: 0:00:01  loss: 0.7843 (0.8470)  time: 0.0822  data: 0.0001  max mem: 10917
[14:18:29.702349] Test:  [50/57]  eta: 0:00:00  loss: 0.7843 (0.8396)  time: 0.0826  data: 0.0001  max mem: 10917
[14:18:30.152616] Test:  [56/57]  eta: 0:00:00  loss: 0.8068 (0.8425)  time: 0.0804  data: 0.0001  max mem: 10917
[14:18:30.212440] Test: Total time: 0:00:04 (0.0849 s / it)
[14:18:32.136743] Dice score of the network on the train images: 0.774502, val images: 0.799470
[14:18:32.137004] saving best_dice_model_0 @ epoch 10
[14:18:33.100897] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:18:33.501415] Epoch: [11]  [  0/345]  eta: 0:02:17  lr: 0.000069  loss: 0.8380 (0.8380)  time: 0.3992  data: 0.1466  max mem: 10917
[14:18:38.505188] Epoch: [11]  [ 20/345]  eta: 0:01:23  lr: 0.000069  loss: 0.8316 (0.8320)  time: 0.2501  data: 0.0001  max mem: 10917
[14:18:43.511344] Epoch: [11]  [ 40/345]  eta: 0:01:17  lr: 0.000069  loss: 0.8374 (0.8369)  time: 0.2503  data: 0.0000  max mem: 10917
[14:18:48.525236] Epoch: [11]  [ 60/345]  eta: 0:01:12  lr: 0.000070  loss: 0.8305 (0.8388)  time: 0.2506  data: 0.0001  max mem: 10917
[14:18:53.547171] Epoch: [11]  [ 80/345]  eta: 0:01:06  lr: 0.000070  loss: 0.8441 (0.8402)  time: 0.2511  data: 0.0000  max mem: 10917
[14:18:58.574575] Epoch: [11]  [100/345]  eta: 0:01:01  lr: 0.000071  loss: 0.8445 (0.8405)  time: 0.2513  data: 0.0001  max mem: 10917
[14:19:03.605017] Epoch: [11]  [120/345]  eta: 0:00:56  lr: 0.000071  loss: 0.8395 (0.8410)  time: 0.2515  data: 0.0000  max mem: 10917
[14:19:08.638452] Epoch: [11]  [140/345]  eta: 0:00:51  lr: 0.000071  loss: 0.8517 (0.8425)  time: 0.2516  data: 0.0000  max mem: 10917
[14:19:13.669756] Epoch: [11]  [160/345]  eta: 0:00:46  lr: 0.000072  loss: 0.8487 (0.8434)  time: 0.2515  data: 0.0000  max mem: 10917
[14:19:18.708645] Epoch: [11]  [180/345]  eta: 0:00:41  lr: 0.000072  loss: 0.8371 (0.8438)  time: 0.2519  data: 0.0001  max mem: 10917
[14:19:23.745161] Epoch: [11]  [200/345]  eta: 0:00:36  lr: 0.000072  loss: 0.8344 (0.8436)  time: 0.2518  data: 0.0000  max mem: 10917
[14:19:28.777150] Epoch: [11]  [220/345]  eta: 0:00:31  lr: 0.000073  loss: 0.8372 (0.8436)  time: 0.2516  data: 0.0000  max mem: 10917
[14:19:33.803859] Epoch: [11]  [240/345]  eta: 0:00:26  lr: 0.000073  loss: 0.8398 (0.8430)  time: 0.2513  data: 0.0001  max mem: 10917
[14:19:38.839917] Epoch: [11]  [260/345]  eta: 0:00:21  lr: 0.000073  loss: 0.8363 (0.8430)  time: 0.2518  data: 0.0000  max mem: 10917
[14:19:43.881669] Epoch: [11]  [280/345]  eta: 0:00:16  lr: 0.000074  loss: 0.8402 (0.8430)  time: 0.2520  data: 0.0000  max mem: 10917
[14:19:48.925817] Epoch: [11]  [300/345]  eta: 0:00:11  lr: 0.000074  loss: 0.8389 (0.8430)  time: 0.2522  data: 0.0001  max mem: 10917
[14:19:53.969816] Epoch: [11]  [320/345]  eta: 0:00:06  lr: 0.000075  loss: 0.8424 (0.8428)  time: 0.2522  data: 0.0000  max mem: 10917
[14:19:59.015645] Epoch: [11]  [340/345]  eta: 0:00:01  lr: 0.000075  loss: 0.8362 (0.8425)  time: 0.2522  data: 0.0001  max mem: 10917
[14:20:00.027141] Epoch: [11]  [344/345]  eta: 0:00:00  lr: 0.000075  loss: 0.8276 (0.8422)  time: 0.2524  data: 0.0001  max mem: 10917
[14:20:00.084702] Epoch: [11] Total time: 0:01:26 (0.2521 s / it)
[14:20:00.085179] Averaged stats: lr: 0.000075  loss: 0.8276 (0.8422)
[14:20:00.324250] Test:  [  0/345]  eta: 0:01:21  loss: 0.8110 (0.8110)  time: 0.2354  data: 0.1556  max mem: 10917
[14:20:01.156255] Test:  [ 10/345]  eta: 0:00:32  loss: 0.8116 (0.8134)  time: 0.0970  data: 0.0153  max mem: 10917
[14:20:01.979280] Test:  [ 20/345]  eta: 0:00:29  loss: 0.8116 (0.8091)  time: 0.0827  data: 0.0007  max mem: 10917
[14:20:02.805714] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8104 (0.8085)  time: 0.0824  data: 0.0001  max mem: 10917
[14:20:03.635452] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8104 (0.8075)  time: 0.0828  data: 0.0001  max mem: 10917
[14:20:04.468610] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7954 (0.8047)  time: 0.0831  data: 0.0001  max mem: 10917
[14:20:05.305230] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7961 (0.8043)  time: 0.0834  data: 0.0001  max mem: 10917
[14:20:06.146149] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7992 (0.8026)  time: 0.0838  data: 0.0001  max mem: 10917
[14:20:06.990550] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7962 (0.8022)  time: 0.0842  data: 0.0001  max mem: 10917
[14:20:07.837889] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7995 (0.8027)  time: 0.0845  data: 0.0001  max mem: 10917
[14:20:08.689374] Test:  [100/345]  eta: 0:00:20  loss: 0.7995 (0.8024)  time: 0.0849  data: 0.0001  max mem: 10917
[14:20:09.544233] Test:  [110/345]  eta: 0:00:20  loss: 0.8044 (0.8031)  time: 0.0852  data: 0.0001  max mem: 10917
[14:20:10.402436] Test:  [120/345]  eta: 0:00:19  loss: 0.8019 (0.8030)  time: 0.0856  data: 0.0001  max mem: 10917
[14:20:11.264085] Test:  [130/345]  eta: 0:00:18  loss: 0.8000 (0.8031)  time: 0.0859  data: 0.0001  max mem: 10917
[14:20:12.129079] Test:  [140/345]  eta: 0:00:17  loss: 0.8009 (0.8035)  time: 0.0863  data: 0.0001  max mem: 10917
[14:20:12.998019] Test:  [150/345]  eta: 0:00:16  loss: 0.8009 (0.8026)  time: 0.0867  data: 0.0001  max mem: 10917
[14:20:13.870762] Test:  [160/345]  eta: 0:00:15  loss: 0.7964 (0.8025)  time: 0.0870  data: 0.0001  max mem: 10917
[14:20:14.747026] Test:  [170/345]  eta: 0:00:14  loss: 0.7995 (0.8030)  time: 0.0874  data: 0.0001  max mem: 10917
[14:20:15.626639] Test:  [180/345]  eta: 0:00:14  loss: 0.8067 (0.8031)  time: 0.0877  data: 0.0001  max mem: 10917
[14:20:16.510283] Test:  [190/345]  eta: 0:00:13  loss: 0.8129 (0.8036)  time: 0.0881  data: 0.0001  max mem: 10917
[14:20:17.396990] Test:  [200/345]  eta: 0:00:12  loss: 0.8122 (0.8035)  time: 0.0885  data: 0.0001  max mem: 10917
[14:20:18.286683] Test:  [210/345]  eta: 0:00:11  loss: 0.7959 (0.8035)  time: 0.0888  data: 0.0001  max mem: 10917
[14:20:19.180514] Test:  [220/345]  eta: 0:00:10  loss: 0.8000 (0.8032)  time: 0.0891  data: 0.0001  max mem: 10917
[14:20:20.076498] Test:  [230/345]  eta: 0:00:09  loss: 0.8053 (0.8038)  time: 0.0894  data: 0.0001  max mem: 10917
[14:20:20.976663] Test:  [240/345]  eta: 0:00:09  loss: 0.8024 (0.8032)  time: 0.0898  data: 0.0001  max mem: 10917
[14:20:21.880202] Test:  [250/345]  eta: 0:00:08  loss: 0.7995 (0.8034)  time: 0.0901  data: 0.0001  max mem: 10917
[14:20:22.787881] Test:  [260/345]  eta: 0:00:07  loss: 0.8040 (0.8033)  time: 0.0905  data: 0.0001  max mem: 10917
[14:20:23.699545] Test:  [270/345]  eta: 0:00:06  loss: 0.8054 (0.8033)  time: 0.0909  data: 0.0001  max mem: 10917
[14:20:24.613877] Test:  [280/345]  eta: 0:00:05  loss: 0.8053 (0.8033)  time: 0.0913  data: 0.0001  max mem: 10917
[14:20:25.531452] Test:  [290/345]  eta: 0:00:04  loss: 0.8009 (0.8036)  time: 0.0915  data: 0.0001  max mem: 10917
[14:20:26.452739] Test:  [300/345]  eta: 0:00:03  loss: 0.8009 (0.8036)  time: 0.0919  data: 0.0001  max mem: 10917
[14:20:27.377904] Test:  [310/345]  eta: 0:00:03  loss: 0.8003 (0.8036)  time: 0.0923  data: 0.0001  max mem: 10917
[14:20:28.306728] Test:  [320/345]  eta: 0:00:02  loss: 0.7993 (0.8037)  time: 0.0927  data: 0.0001  max mem: 10917
[14:20:29.239442] Test:  [330/345]  eta: 0:00:01  loss: 0.8072 (0.8039)  time: 0.0930  data: 0.0001  max mem: 10917
[14:20:30.175264] Test:  [340/345]  eta: 0:00:00  loss: 0.8059 (0.8039)  time: 0.0934  data: 0.0001  max mem: 10917
[14:20:30.550613] Test:  [344/345]  eta: 0:00:00  loss: 0.8047 (0.8038)  time: 0.0935  data: 0.0001  max mem: 10917
[14:20:30.608888] Test: Total time: 0:00:30 (0.0885 s / it)
[14:20:41.688587] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8931 (0.8931)  time: 0.2218  data: 0.1422  max mem: 10917
[14:20:42.502317] Test:  [10/57]  eta: 0:00:04  loss: 0.9012 (0.9135)  time: 0.0941  data: 0.0130  max mem: 10917
[14:20:43.320174] Test:  [20/57]  eta: 0:00:03  loss: 0.9089 (0.9089)  time: 0.0815  data: 0.0001  max mem: 10917
[14:20:44.141370] Test:  [30/57]  eta: 0:00:02  loss: 0.7935 (0.8664)  time: 0.0819  data: 0.0001  max mem: 10917
[14:20:44.966074] Test:  [40/57]  eta: 0:00:01  loss: 0.7779 (0.8422)  time: 0.0822  data: 0.0001  max mem: 10917
[14:20:45.794592] Test:  [50/57]  eta: 0:00:00  loss: 0.7779 (0.8338)  time: 0.0826  data: 0.0001  max mem: 10917
[14:20:46.244503] Test:  [56/57]  eta: 0:00:00  loss: 0.7946 (0.8378)  time: 0.0804  data: 0.0001  max mem: 10917
[14:20:46.305293] Test: Total time: 0:00:04 (0.0849 s / it)
[14:20:48.290812] Dice score of the network on the train images: 0.772054, val images: 0.802613
[14:20:48.291047] saving best_dice_model_0 @ epoch 11
[14:20:49.151850] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:20:49.550750] Epoch: [12]  [  0/345]  eta: 0:02:17  lr: 0.000075  loss: 0.7996 (0.7996)  time: 0.3979  data: 0.1450  max mem: 10917
[14:20:54.551758] Epoch: [12]  [ 20/345]  eta: 0:01:23  lr: 0.000075  loss: 0.8164 (0.8262)  time: 0.2500  data: 0.0000  max mem: 10917
[14:20:59.558134] Epoch: [12]  [ 40/345]  eta: 0:01:17  lr: 0.000076  loss: 0.8372 (0.8313)  time: 0.2503  data: 0.0000  max mem: 10917
[14:21:04.562450] Epoch: [12]  [ 60/345]  eta: 0:01:11  lr: 0.000076  loss: 0.8386 (0.8354)  time: 0.2502  data: 0.0000  max mem: 10917
[14:21:09.575699] Epoch: [12]  [ 80/345]  eta: 0:01:06  lr: 0.000076  loss: 0.8398 (0.8355)  time: 0.2506  data: 0.0000  max mem: 10917
[14:21:14.596509] Epoch: [12]  [100/345]  eta: 0:01:01  lr: 0.000077  loss: 0.8337 (0.8345)  time: 0.2510  data: 0.0000  max mem: 10917
[14:21:19.621736] Epoch: [12]  [120/345]  eta: 0:00:56  lr: 0.000077  loss: 0.8437 (0.8355)  time: 0.2512  data: 0.0000  max mem: 10917
[14:21:24.647217] Epoch: [12]  [140/345]  eta: 0:00:51  lr: 0.000078  loss: 0.8405 (0.8362)  time: 0.2512  data: 0.0000  max mem: 10917
[14:21:29.675969] Epoch: [12]  [160/345]  eta: 0:00:46  lr: 0.000078  loss: 0.8330 (0.8357)  time: 0.2514  data: 0.0000  max mem: 10917
[14:21:34.695154] Epoch: [12]  [180/345]  eta: 0:00:41  lr: 0.000078  loss: 0.8211 (0.8349)  time: 0.2509  data: 0.0001  max mem: 10917
[14:21:39.724133] Epoch: [12]  [200/345]  eta: 0:00:36  lr: 0.000079  loss: 0.8245 (0.8341)  time: 0.2514  data: 0.0001  max mem: 10917
[14:21:44.752519] Epoch: [12]  [220/345]  eta: 0:00:31  lr: 0.000079  loss: 0.8343 (0.8339)  time: 0.2514  data: 0.0000  max mem: 10917
[14:21:49.785907] Epoch: [12]  [240/345]  eta: 0:00:26  lr: 0.000079  loss: 0.8364 (0.8339)  time: 0.2516  data: 0.0000  max mem: 10917
[14:21:54.824662] Epoch: [12]  [260/345]  eta: 0:00:21  lr: 0.000080  loss: 0.8337 (0.8347)  time: 0.2519  data: 0.0000  max mem: 10917
[14:21:59.863825] Epoch: [12]  [280/345]  eta: 0:00:16  lr: 0.000080  loss: 0.8203 (0.8341)  time: 0.2519  data: 0.0000  max mem: 10917
[14:22:04.905896] Epoch: [12]  [300/345]  eta: 0:00:11  lr: 0.000080  loss: 0.8242 (0.8336)  time: 0.2521  data: 0.0000  max mem: 10917
[14:22:09.949454] Epoch: [12]  [320/345]  eta: 0:00:06  lr: 0.000081  loss: 0.8305 (0.8335)  time: 0.2521  data: 0.0001  max mem: 10917
[14:22:14.991064] Epoch: [12]  [340/345]  eta: 0:00:01  lr: 0.000081  loss: 0.8291 (0.8331)  time: 0.2520  data: 0.0000  max mem: 10917
[14:22:16.000595] Epoch: [12]  [344/345]  eta: 0:00:00  lr: 0.000081  loss: 0.8301 (0.8332)  time: 0.2521  data: 0.0001  max mem: 10917
[14:22:16.058868] Epoch: [12] Total time: 0:01:26 (0.2519 s / it)
[14:22:16.059194] Averaged stats: lr: 0.000081  loss: 0.8301 (0.8332)
[14:22:16.296245] Test:  [  0/345]  eta: 0:01:20  loss: 0.7807 (0.7807)  time: 0.2334  data: 0.1533  max mem: 10917
[14:22:17.136013] Test:  [ 10/345]  eta: 0:00:32  loss: 0.8316 (0.8264)  time: 0.0975  data: 0.0160  max mem: 10917
[14:22:17.959282] Test:  [ 20/345]  eta: 0:00:29  loss: 0.8271 (0.8243)  time: 0.0831  data: 0.0012  max mem: 10917
[14:22:18.787076] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8186 (0.8240)  time: 0.0825  data: 0.0001  max mem: 10917
[14:22:19.617452] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8219 (0.8243)  time: 0.0829  data: 0.0001  max mem: 10917
[14:22:20.451081] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8329 (0.8242)  time: 0.0832  data: 0.0001  max mem: 10917
[14:22:21.289206] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8173 (0.8239)  time: 0.0835  data: 0.0001  max mem: 10917
[14:22:22.130099] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8168 (0.8234)  time: 0.0839  data: 0.0001  max mem: 10917
[14:22:22.974831] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8093 (0.8226)  time: 0.0842  data: 0.0001  max mem: 10917
[14:22:23.823763] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8206 (0.8234)  time: 0.0846  data: 0.0001  max mem: 10917
[14:22:24.675886] Test:  [100/345]  eta: 0:00:20  loss: 0.8288 (0.8241)  time: 0.0850  data: 0.0001  max mem: 10917
[14:22:25.531737] Test:  [110/345]  eta: 0:00:20  loss: 0.8229 (0.8236)  time: 0.0854  data: 0.0001  max mem: 10917
[14:22:26.391131] Test:  [120/345]  eta: 0:00:19  loss: 0.8092 (0.8231)  time: 0.0857  data: 0.0001  max mem: 10917
[14:22:27.252905] Test:  [130/345]  eta: 0:00:18  loss: 0.8120 (0.8231)  time: 0.0860  data: 0.0001  max mem: 10917
[14:22:28.118521] Test:  [140/345]  eta: 0:00:17  loss: 0.8166 (0.8232)  time: 0.0863  data: 0.0001  max mem: 10917
[14:22:28.988918] Test:  [150/345]  eta: 0:00:16  loss: 0.8175 (0.8235)  time: 0.0868  data: 0.0001  max mem: 10917
[14:22:29.861870] Test:  [160/345]  eta: 0:00:15  loss: 0.8205 (0.8234)  time: 0.0871  data: 0.0001  max mem: 10917
[14:22:30.738610] Test:  [170/345]  eta: 0:00:15  loss: 0.8188 (0.8235)  time: 0.0874  data: 0.0001  max mem: 10917
[14:22:31.618195] Test:  [180/345]  eta: 0:00:14  loss: 0.8255 (0.8239)  time: 0.0877  data: 0.0001  max mem: 10917
[14:22:32.501360] Test:  [190/345]  eta: 0:00:13  loss: 0.8140 (0.8236)  time: 0.0881  data: 0.0001  max mem: 10917
[14:22:33.388276] Test:  [200/345]  eta: 0:00:12  loss: 0.8140 (0.8232)  time: 0.0885  data: 0.0001  max mem: 10917
[14:22:34.278758] Test:  [210/345]  eta: 0:00:11  loss: 0.8165 (0.8229)  time: 0.0888  data: 0.0001  max mem: 10917
[14:22:35.172778] Test:  [220/345]  eta: 0:00:10  loss: 0.8165 (0.8230)  time: 0.0892  data: 0.0001  max mem: 10917
[14:22:36.071118] Test:  [230/345]  eta: 0:00:09  loss: 0.8187 (0.8233)  time: 0.0896  data: 0.0001  max mem: 10917
[14:22:36.973035] Test:  [240/345]  eta: 0:00:09  loss: 0.8184 (0.8235)  time: 0.0900  data: 0.0001  max mem: 10917
[14:22:37.877657] Test:  [250/345]  eta: 0:00:08  loss: 0.8189 (0.8232)  time: 0.0903  data: 0.0001  max mem: 10917
[14:22:38.784741] Test:  [260/345]  eta: 0:00:07  loss: 0.8147 (0.8228)  time: 0.0905  data: 0.0001  max mem: 10917
[14:22:39.697101] Test:  [270/345]  eta: 0:00:06  loss: 0.8280 (0.8232)  time: 0.0909  data: 0.0001  max mem: 10917
[14:22:40.612411] Test:  [280/345]  eta: 0:00:05  loss: 0.8302 (0.8233)  time: 0.0913  data: 0.0001  max mem: 10917
[14:22:41.530482] Test:  [290/345]  eta: 0:00:04  loss: 0.8283 (0.8236)  time: 0.0916  data: 0.0001  max mem: 10917
[14:22:42.452843] Test:  [300/345]  eta: 0:00:03  loss: 0.8343 (0.8241)  time: 0.0920  data: 0.0001  max mem: 10917
[14:22:43.378335] Test:  [310/345]  eta: 0:00:03  loss: 0.8243 (0.8239)  time: 0.0923  data: 0.0001  max mem: 10917
[14:22:44.308362] Test:  [320/345]  eta: 0:00:02  loss: 0.8215 (0.8238)  time: 0.0927  data: 0.0001  max mem: 10917
[14:22:45.240941] Test:  [330/345]  eta: 0:00:01  loss: 0.8141 (0.8238)  time: 0.0931  data: 0.0001  max mem: 10917
[14:22:46.176657] Test:  [340/345]  eta: 0:00:00  loss: 0.8247 (0.8241)  time: 0.0934  data: 0.0001  max mem: 10917
[14:22:46.552468] Test:  [344/345]  eta: 0:00:00  loss: 0.8247 (0.8239)  time: 0.0935  data: 0.0001  max mem: 10917
[14:22:46.593141] Test: Total time: 0:00:30 (0.0885 s / it)
[14:22:57.709034] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8969 (0.8969)  time: 0.2180  data: 0.1384  max mem: 10917
[14:22:58.545030] Test:  [10/57]  eta: 0:00:04  loss: 0.8855 (0.9066)  time: 0.0957  data: 0.0148  max mem: 10917
[14:22:59.362143] Test:  [20/57]  eta: 0:00:03  loss: 0.9024 (0.9037)  time: 0.0826  data: 0.0013  max mem: 10917
[14:23:00.183167] Test:  [30/57]  eta: 0:00:02  loss: 0.8057 (0.8656)  time: 0.0819  data: 0.0001  max mem: 10917
[14:23:01.007246] Test:  [40/57]  eta: 0:00:01  loss: 0.7791 (0.8430)  time: 0.0822  data: 0.0001  max mem: 10917
[14:23:01.835778] Test:  [50/57]  eta: 0:00:00  loss: 0.7667 (0.8350)  time: 0.0826  data: 0.0001  max mem: 10917
[14:23:02.285661] Test:  [56/57]  eta: 0:00:00  loss: 0.8080 (0.8393)  time: 0.0803  data: 0.0001  max mem: 10917
[14:23:02.343483] Test: Total time: 0:00:04 (0.0851 s / it)
[14:23:04.307622] Dice score of the network on the train images: 0.744854, val images: 0.795042
[14:23:04.307859] saving best_rec_model_0 @ epoch 12
[14:23:05.134368] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:23:05.536318] Epoch: [13]  [  0/345]  eta: 0:02:18  lr: 0.000081  loss: 0.8723 (0.8723)  time: 0.4011  data: 0.1499  max mem: 10917
[14:23:10.532006] Epoch: [13]  [ 20/345]  eta: 0:01:23  lr: 0.000082  loss: 0.8495 (0.8552)  time: 0.2497  data: 0.0001  max mem: 10917
[14:23:15.535826] Epoch: [13]  [ 40/345]  eta: 0:01:17  lr: 0.000082  loss: 0.8265 (0.8411)  time: 0.2502  data: 0.0000  max mem: 10917
[14:23:20.544476] Epoch: [13]  [ 60/345]  eta: 0:01:11  lr: 0.000082  loss: 0.8274 (0.8364)  time: 0.2504  data: 0.0000  max mem: 10917
[14:23:25.558450] Epoch: [13]  [ 80/345]  eta: 0:01:06  lr: 0.000083  loss: 0.8290 (0.8348)  time: 0.2507  data: 0.0000  max mem: 10917
[14:23:30.578577] Epoch: [13]  [100/345]  eta: 0:01:01  lr: 0.000083  loss: 0.8160 (0.8328)  time: 0.2510  data: 0.0000  max mem: 10917
[14:23:35.602466] Epoch: [13]  [120/345]  eta: 0:00:56  lr: 0.000083  loss: 0.8345 (0.8336)  time: 0.2512  data: 0.0000  max mem: 10917
[14:23:40.629630] Epoch: [13]  [140/345]  eta: 0:00:51  lr: 0.000084  loss: 0.8346 (0.8340)  time: 0.2513  data: 0.0001  max mem: 10917
[14:23:45.651103] Epoch: [13]  [160/345]  eta: 0:00:46  lr: 0.000084  loss: 0.8226 (0.8332)  time: 0.2510  data: 0.0001  max mem: 10917
[14:23:50.677499] Epoch: [13]  [180/345]  eta: 0:00:41  lr: 0.000085  loss: 0.8223 (0.8329)  time: 0.2513  data: 0.0000  max mem: 10917
[14:23:55.707677] Epoch: [13]  [200/345]  eta: 0:00:36  lr: 0.000085  loss: 0.8337 (0.8332)  time: 0.2515  data: 0.0000  max mem: 10917
[14:24:00.739527] Epoch: [13]  [220/345]  eta: 0:00:31  lr: 0.000085  loss: 0.8251 (0.8325)  time: 0.2516  data: 0.0000  max mem: 10917
[14:24:05.778703] Epoch: [13]  [240/345]  eta: 0:00:26  lr: 0.000086  loss: 0.8184 (0.8315)  time: 0.2519  data: 0.0000  max mem: 10917
[14:24:10.817143] Epoch: [13]  [260/345]  eta: 0:00:21  lr: 0.000086  loss: 0.8310 (0.8314)  time: 0.2519  data: 0.0000  max mem: 10917
[14:24:15.851847] Epoch: [13]  [280/345]  eta: 0:00:16  lr: 0.000086  loss: 0.8246 (0.8309)  time: 0.2517  data: 0.0001  max mem: 10917
[14:24:20.960261] Epoch: [13]  [300/345]  eta: 0:00:11  lr: 0.000087  loss: 0.8230 (0.8309)  time: 0.2554  data: 0.0001  max mem: 10917
[14:24:25.989185] Epoch: [13]  [320/345]  eta: 0:00:06  lr: 0.000087  loss: 0.8176 (0.8305)  time: 0.2514  data: 0.0001  max mem: 10917
[14:24:31.021374] Epoch: [13]  [340/345]  eta: 0:00:01  lr: 0.000087  loss: 0.8169 (0.8297)  time: 0.2516  data: 0.0001  max mem: 10917
[14:24:32.026201] Epoch: [13]  [344/345]  eta: 0:00:00  lr: 0.000087  loss: 0.8164 (0.8293)  time: 0.2515  data: 0.0001  max mem: 10917
[14:24:32.088815] Epoch: [13] Total time: 0:01:26 (0.2520 s / it)
[14:24:32.089313] Averaged stats: lr: 0.000087  loss: 0.8164 (0.8293)
[14:24:32.331555] Test:  [  0/345]  eta: 0:01:22  loss: 0.7751 (0.7751)  time: 0.2393  data: 0.1589  max mem: 10917
[14:24:33.212475] Test:  [ 10/345]  eta: 0:00:34  loss: 0.7833 (0.7814)  time: 0.1018  data: 0.0203  max mem: 10917
[14:24:34.096269] Test:  [ 20/345]  eta: 0:00:30  loss: 0.7811 (0.7827)  time: 0.0882  data: 0.0064  max mem: 10917
[14:24:34.966099] Test:  [ 30/345]  eta: 0:00:29  loss: 0.7864 (0.7880)  time: 0.0876  data: 0.0055  max mem: 10917
[14:24:35.795517] Test:  [ 40/345]  eta: 0:00:27  loss: 0.7906 (0.7869)  time: 0.0849  data: 0.0023  max mem: 10917
[14:24:36.629902] Test:  [ 50/345]  eta: 0:00:26  loss: 0.7815 (0.7868)  time: 0.0831  data: 0.0001  max mem: 10917
[14:24:37.468556] Test:  [ 60/345]  eta: 0:00:25  loss: 0.7984 (0.7900)  time: 0.0836  data: 0.0001  max mem: 10917
[14:24:38.308805] Test:  [ 70/345]  eta: 0:00:24  loss: 0.7986 (0.7897)  time: 0.0839  data: 0.0001  max mem: 10917
[14:24:39.153131] Test:  [ 80/345]  eta: 0:00:23  loss: 0.7875 (0.7894)  time: 0.0842  data: 0.0001  max mem: 10917
[14:24:40.001776] Test:  [ 90/345]  eta: 0:00:22  loss: 0.7785 (0.7888)  time: 0.0846  data: 0.0001  max mem: 10917
[14:24:40.853758] Test:  [100/345]  eta: 0:00:21  loss: 0.7785 (0.7885)  time: 0.0850  data: 0.0001  max mem: 10917
[14:24:41.709619] Test:  [110/345]  eta: 0:00:20  loss: 0.7954 (0.7892)  time: 0.0853  data: 0.0001  max mem: 10917
[14:24:42.568819] Test:  [120/345]  eta: 0:00:19  loss: 0.7813 (0.7878)  time: 0.0857  data: 0.0001  max mem: 10917
[14:24:43.430770] Test:  [130/345]  eta: 0:00:18  loss: 0.7782 (0.7876)  time: 0.0860  data: 0.0001  max mem: 10917
[14:24:44.295850] Test:  [140/345]  eta: 0:00:17  loss: 0.7828 (0.7870)  time: 0.0863  data: 0.0001  max mem: 10917
[14:24:45.165762] Test:  [150/345]  eta: 0:00:16  loss: 0.7769 (0.7868)  time: 0.0867  data: 0.0001  max mem: 10917
[14:24:46.038836] Test:  [160/345]  eta: 0:00:16  loss: 0.7792 (0.7860)  time: 0.0871  data: 0.0001  max mem: 10917
[14:24:46.914698] Test:  [170/345]  eta: 0:00:15  loss: 0.7777 (0.7858)  time: 0.0874  data: 0.0001  max mem: 10917
[14:24:47.795238] Test:  [180/345]  eta: 0:00:14  loss: 0.7791 (0.7859)  time: 0.0878  data: 0.0001  max mem: 10917
[14:24:48.678671] Test:  [190/345]  eta: 0:00:13  loss: 0.7786 (0.7853)  time: 0.0882  data: 0.0001  max mem: 10917
[14:24:49.565962] Test:  [200/345]  eta: 0:00:12  loss: 0.7769 (0.7849)  time: 0.0885  data: 0.0001  max mem: 10917
[14:24:50.457354] Test:  [210/345]  eta: 0:00:11  loss: 0.7741 (0.7847)  time: 0.0889  data: 0.0001  max mem: 10917
[14:24:51.351827] Test:  [220/345]  eta: 0:00:10  loss: 0.7705 (0.7844)  time: 0.0892  data: 0.0001  max mem: 10917
[14:24:52.249651] Test:  [230/345]  eta: 0:00:10  loss: 0.7837 (0.7841)  time: 0.0896  data: 0.0001  max mem: 10917
[14:24:53.150918] Test:  [240/345]  eta: 0:00:09  loss: 0.7837 (0.7842)  time: 0.0899  data: 0.0001  max mem: 10917
[14:24:54.055635] Test:  [250/345]  eta: 0:00:08  loss: 0.7844 (0.7844)  time: 0.0903  data: 0.0001  max mem: 10917
[14:24:54.963448] Test:  [260/345]  eta: 0:00:07  loss: 0.7810 (0.7842)  time: 0.0906  data: 0.0001  max mem: 10917
[14:24:55.875175] Test:  [270/345]  eta: 0:00:06  loss: 0.7775 (0.7841)  time: 0.0909  data: 0.0001  max mem: 10917
[14:24:56.790423] Test:  [280/345]  eta: 0:00:05  loss: 0.7850 (0.7843)  time: 0.0913  data: 0.0001  max mem: 10917
[14:24:57.708794] Test:  [290/345]  eta: 0:00:04  loss: 0.7850 (0.7841)  time: 0.0916  data: 0.0001  max mem: 10917
[14:24:58.631462] Test:  [300/345]  eta: 0:00:03  loss: 0.7773 (0.7839)  time: 0.0920  data: 0.0001  max mem: 10917
[14:24:59.557359] Test:  [310/345]  eta: 0:00:03  loss: 0.7780 (0.7837)  time: 0.0924  data: 0.0001  max mem: 10917
[14:25:00.487354] Test:  [320/345]  eta: 0:00:02  loss: 0.7832 (0.7839)  time: 0.0927  data: 0.0001  max mem: 10917
[14:25:01.420281] Test:  [330/345]  eta: 0:00:01  loss: 0.7876 (0.7838)  time: 0.0931  data: 0.0001  max mem: 10917
[14:25:02.356959] Test:  [340/345]  eta: 0:00:00  loss: 0.7792 (0.7837)  time: 0.0934  data: 0.0001  max mem: 10917
[14:25:02.732916] Test:  [344/345]  eta: 0:00:00  loss: 0.7774 (0.7835)  time: 0.0936  data: 0.0001  max mem: 10917
[14:25:02.790133] Test: Total time: 0:00:30 (0.0890 s / it)
[14:25:13.987735] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8830 (0.8830)  time: 0.2226  data: 0.1428  max mem: 10917
[14:25:14.800125] Test:  [10/57]  eta: 0:00:04  loss: 0.8856 (0.9046)  time: 0.0940  data: 0.0130  max mem: 10917
[14:25:15.617231] Test:  [20/57]  eta: 0:00:03  loss: 0.8902 (0.8910)  time: 0.0814  data: 0.0001  max mem: 10917
[14:25:16.438509] Test:  [30/57]  eta: 0:00:02  loss: 0.7933 (0.8530)  time: 0.0819  data: 0.0001  max mem: 10917
[14:25:17.262187] Test:  [40/57]  eta: 0:00:01  loss: 0.7813 (0.8314)  time: 0.0822  data: 0.0001  max mem: 10917
[14:25:18.090039] Test:  [50/57]  eta: 0:00:00  loss: 0.7790 (0.8235)  time: 0.0825  data: 0.0001  max mem: 10917
[14:25:18.540322] Test:  [56/57]  eta: 0:00:00  loss: 0.7859 (0.8273)  time: 0.0803  data: 0.0001  max mem: 10917
[14:25:18.600156] Test: Total time: 0:00:04 (0.0848 s / it)
[14:25:20.559691] Dice score of the network on the train images: 0.782240, val images: 0.808956
[14:25:20.559926] saving best_dice_model_0 @ epoch 13
[14:25:21.403637] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:25:21.803759] Epoch: [14]  [  0/345]  eta: 0:02:17  lr: 0.000087  loss: 0.7772 (0.7772)  time: 0.3992  data: 0.1465  max mem: 10917
[14:25:26.794709] Epoch: [14]  [ 20/345]  eta: 0:01:23  lr: 0.000088  loss: 0.8118 (0.8100)  time: 0.2495  data: 0.0000  max mem: 10917
[14:25:31.794346] Epoch: [14]  [ 40/345]  eta: 0:01:17  lr: 0.000088  loss: 0.8197 (0.8168)  time: 0.2499  data: 0.0000  max mem: 10917
[14:25:36.800962] Epoch: [14]  [ 60/345]  eta: 0:01:11  lr: 0.000089  loss: 0.8176 (0.8194)  time: 0.2503  data: 0.0000  max mem: 10917
[14:25:41.816897] Epoch: [14]  [ 80/345]  eta: 0:01:06  lr: 0.000089  loss: 0.8059 (0.8170)  time: 0.2508  data: 0.0000  max mem: 10917
[14:25:46.835500] Epoch: [14]  [100/345]  eta: 0:01:01  lr: 0.000089  loss: 0.8136 (0.8173)  time: 0.2509  data: 0.0000  max mem: 10917
[14:25:51.856990] Epoch: [14]  [120/345]  eta: 0:00:56  lr: 0.000090  loss: 0.8343 (0.8204)  time: 0.2510  data: 0.0000  max mem: 10917
[14:25:56.880440] Epoch: [14]  [140/345]  eta: 0:00:51  lr: 0.000090  loss: 0.8189 (0.8205)  time: 0.2511  data: 0.0000  max mem: 10917
[14:26:01.906190] Epoch: [14]  [160/345]  eta: 0:00:46  lr: 0.000090  loss: 0.8207 (0.8204)  time: 0.2513  data: 0.0000  max mem: 10917
[14:26:06.935511] Epoch: [14]  [180/345]  eta: 0:00:41  lr: 0.000091  loss: 0.8225 (0.8206)  time: 0.2514  data: 0.0000  max mem: 10917
[14:26:11.965343] Epoch: [14]  [200/345]  eta: 0:00:36  lr: 0.000091  loss: 0.8149 (0.8203)  time: 0.2515  data: 0.0000  max mem: 10917
[14:26:16.998096] Epoch: [14]  [220/345]  eta: 0:00:31  lr: 0.000091  loss: 0.8196 (0.8207)  time: 0.2516  data: 0.0000  max mem: 10917
[14:26:22.033628] Epoch: [14]  [240/345]  eta: 0:00:26  lr: 0.000092  loss: 0.8205 (0.8208)  time: 0.2517  data: 0.0000  max mem: 10917
[14:26:27.071909] Epoch: [14]  [260/345]  eta: 0:00:21  lr: 0.000092  loss: 0.8221 (0.8211)  time: 0.2519  data: 0.0000  max mem: 10917
[14:26:32.110540] Epoch: [14]  [280/345]  eta: 0:00:16  lr: 0.000093  loss: 0.8209 (0.8212)  time: 0.2519  data: 0.0000  max mem: 10917
[14:26:37.151685] Epoch: [14]  [300/345]  eta: 0:00:11  lr: 0.000093  loss: 0.8228 (0.8217)  time: 0.2520  data: 0.0000  max mem: 10917
[14:26:42.195741] Epoch: [14]  [320/345]  eta: 0:00:06  lr: 0.000093  loss: 0.8261 (0.8222)  time: 0.2522  data: 0.0000  max mem: 10917
[14:26:47.239588] Epoch: [14]  [340/345]  eta: 0:00:01  lr: 0.000094  loss: 0.8239 (0.8227)  time: 0.2522  data: 0.0000  max mem: 10917
[14:26:48.247706] Epoch: [14]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.8274 (0.8229)  time: 0.2521  data: 0.0001  max mem: 10917
[14:26:48.301623] Epoch: [14] Total time: 0:01:26 (0.2519 s / it)
[14:26:48.302085] Averaged stats: lr: 0.000094  loss: 0.8274 (0.8229)
[14:26:48.545694] Test:  [  0/345]  eta: 0:01:22  loss: 0.7751 (0.7751)  time: 0.2399  data: 0.1595  max mem: 10917
[14:26:49.374829] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7861 (0.7888)  time: 0.0971  data: 0.0155  max mem: 10917
[14:26:50.199134] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7861 (0.7888)  time: 0.0826  data: 0.0006  max mem: 10917
[14:26:51.026319] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7806 (0.7862)  time: 0.0825  data: 0.0001  max mem: 10917
[14:26:51.857806] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7759 (0.7860)  time: 0.0829  data: 0.0001  max mem: 10917
[14:26:52.691268] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7832 (0.7872)  time: 0.0832  data: 0.0001  max mem: 10917
[14:26:53.529147] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7867 (0.7889)  time: 0.0835  data: 0.0001  max mem: 10917
[14:26:54.371995] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7867 (0.7881)  time: 0.0839  data: 0.0001  max mem: 10917
[14:26:55.217230] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7875 (0.7895)  time: 0.0843  data: 0.0001  max mem: 10917
[14:26:56.066172] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7911 (0.7888)  time: 0.0847  data: 0.0001  max mem: 10917
[14:26:56.918593] Test:  [100/345]  eta: 0:00:20  loss: 0.7843 (0.7889)  time: 0.0850  data: 0.0001  max mem: 10917
[14:26:57.773851] Test:  [110/345]  eta: 0:00:20  loss: 0.7885 (0.7894)  time: 0.0853  data: 0.0001  max mem: 10917
[14:26:58.632753] Test:  [120/345]  eta: 0:00:19  loss: 0.7956 (0.7904)  time: 0.0857  data: 0.0001  max mem: 10917
[14:26:59.495232] Test:  [130/345]  eta: 0:00:18  loss: 0.7967 (0.7908)  time: 0.0860  data: 0.0001  max mem: 10917
[14:27:00.361408] Test:  [140/345]  eta: 0:00:17  loss: 0.7874 (0.7905)  time: 0.0864  data: 0.0001  max mem: 10917
[14:27:01.231304] Test:  [150/345]  eta: 0:00:16  loss: 0.7874 (0.7910)  time: 0.0867  data: 0.0001  max mem: 10917
[14:27:02.105016] Test:  [160/345]  eta: 0:00:15  loss: 0.7875 (0.7909)  time: 0.0871  data: 0.0001  max mem: 10917
[14:27:02.982536] Test:  [170/345]  eta: 0:00:15  loss: 0.7898 (0.7908)  time: 0.0875  data: 0.0001  max mem: 10917
[14:27:03.863801] Test:  [180/345]  eta: 0:00:14  loss: 0.7904 (0.7910)  time: 0.0879  data: 0.0001  max mem: 10917
[14:27:04.747312] Test:  [190/345]  eta: 0:00:13  loss: 0.7935 (0.7908)  time: 0.0882  data: 0.0001  max mem: 10917
[14:27:05.634892] Test:  [200/345]  eta: 0:00:12  loss: 0.7884 (0.7905)  time: 0.0885  data: 0.0001  max mem: 10917
[14:27:06.526252] Test:  [210/345]  eta: 0:00:11  loss: 0.7809 (0.7905)  time: 0.0889  data: 0.0001  max mem: 10917
[14:27:07.420529] Test:  [220/345]  eta: 0:00:10  loss: 0.7809 (0.7908)  time: 0.0892  data: 0.0001  max mem: 10917
[14:27:08.318474] Test:  [230/345]  eta: 0:00:09  loss: 0.7881 (0.7907)  time: 0.0896  data: 0.0001  max mem: 10917
[14:27:09.220440] Test:  [240/345]  eta: 0:00:09  loss: 0.7911 (0.7913)  time: 0.0899  data: 0.0001  max mem: 10917
[14:27:10.125636] Test:  [250/345]  eta: 0:00:08  loss: 0.7958 (0.7914)  time: 0.0903  data: 0.0001  max mem: 10917
[14:27:11.033242] Test:  [260/345]  eta: 0:00:07  loss: 0.7897 (0.7915)  time: 0.0906  data: 0.0001  max mem: 10917
[14:27:11.944649] Test:  [270/345]  eta: 0:00:06  loss: 0.7942 (0.7915)  time: 0.0909  data: 0.0001  max mem: 10917
[14:27:12.859333] Test:  [280/345]  eta: 0:00:05  loss: 0.7856 (0.7912)  time: 0.0913  data: 0.0001  max mem: 10917
[14:27:13.778289] Test:  [290/345]  eta: 0:00:04  loss: 0.7810 (0.7910)  time: 0.0916  data: 0.0001  max mem: 10917
[14:27:14.701034] Test:  [300/345]  eta: 0:00:03  loss: 0.7864 (0.7914)  time: 0.0920  data: 0.0001  max mem: 10917
[14:27:15.627101] Test:  [310/345]  eta: 0:00:03  loss: 0.7928 (0.7912)  time: 0.0924  data: 0.0001  max mem: 10917
[14:27:16.556729] Test:  [320/345]  eta: 0:00:02  loss: 0.7860 (0.7910)  time: 0.0927  data: 0.0001  max mem: 10917
[14:27:17.490027] Test:  [330/345]  eta: 0:00:01  loss: 0.7902 (0.7912)  time: 0.0931  data: 0.0001  max mem: 10917
[14:27:18.426071] Test:  [340/345]  eta: 0:00:00  loss: 0.7902 (0.7911)  time: 0.0934  data: 0.0001  max mem: 10917
[14:27:18.801847] Test:  [344/345]  eta: 0:00:00  loss: 0.7918 (0.7913)  time: 0.0936  data: 0.0001  max mem: 10917
[14:27:18.860378] Test: Total time: 0:00:30 (0.0886 s / it)
[14:27:30.006150] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8935 (0.8935)  time: 0.2262  data: 0.1462  max mem: 10917
[14:27:30.818002] Test:  [10/57]  eta: 0:00:04  loss: 0.8935 (0.8959)  time: 0.0943  data: 0.0134  max mem: 10917
[14:27:31.635994] Test:  [20/57]  eta: 0:00:03  loss: 0.8923 (0.8893)  time: 0.0814  data: 0.0001  max mem: 10917
[14:27:32.456965] Test:  [30/57]  eta: 0:00:02  loss: 0.7842 (0.8511)  time: 0.0819  data: 0.0001  max mem: 10917
[14:27:33.281130] Test:  [40/57]  eta: 0:00:01  loss: 0.7768 (0.8300)  time: 0.0822  data: 0.0001  max mem: 10917
[14:27:34.108845] Test:  [50/57]  eta: 0:00:00  loss: 0.7584 (0.8213)  time: 0.0825  data: 0.0001  max mem: 10917
[14:27:34.558576] Test:  [56/57]  eta: 0:00:00  loss: 0.7913 (0.8258)  time: 0.0803  data: 0.0001  max mem: 10917
[14:27:34.616869] Test: Total time: 0:00:04 (0.0849 s / it)
[14:27:36.550201] Dice score of the network on the train images: 0.765912, val images: 0.801017
[14:27:36.553321] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:27:36.951546] Epoch: [15]  [  0/345]  eta: 0:02:17  lr: 0.000094  loss: 0.8004 (0.8004)  time: 0.3974  data: 0.1452  max mem: 10917
[14:27:41.941556] Epoch: [15]  [ 20/345]  eta: 0:01:23  lr: 0.000094  loss: 0.8235 (0.8216)  time: 0.2495  data: 0.0000  max mem: 10917
[14:27:46.940961] Epoch: [15]  [ 40/345]  eta: 0:01:17  lr: 0.000094  loss: 0.8225 (0.8233)  time: 0.2499  data: 0.0000  max mem: 10917
[14:27:51.950080] Epoch: [15]  [ 60/345]  eta: 0:01:11  lr: 0.000095  loss: 0.8078 (0.8196)  time: 0.2504  data: 0.0001  max mem: 10917
[14:27:56.962884] Epoch: [15]  [ 80/345]  eta: 0:01:06  lr: 0.000095  loss: 0.8136 (0.8195)  time: 0.2506  data: 0.0000  max mem: 10917
[14:28:01.981269] Epoch: [15]  [100/345]  eta: 0:01:01  lr: 0.000096  loss: 0.8183 (0.8199)  time: 0.2509  data: 0.0000  max mem: 10917
[14:28:07.005905] Epoch: [15]  [120/345]  eta: 0:00:56  lr: 0.000096  loss: 0.8254 (0.8218)  time: 0.2512  data: 0.0000  max mem: 10917
[14:28:12.024476] Epoch: [15]  [140/345]  eta: 0:00:51  lr: 0.000096  loss: 0.8292 (0.8233)  time: 0.2509  data: 0.0000  max mem: 10917
[14:28:17.044296] Epoch: [15]  [160/345]  eta: 0:00:46  lr: 0.000097  loss: 0.8185 (0.8230)  time: 0.2510  data: 0.0000  max mem: 10917
[14:28:22.070175] Epoch: [15]  [180/345]  eta: 0:00:41  lr: 0.000097  loss: 0.8266 (0.8233)  time: 0.2513  data: 0.0000  max mem: 10917
[14:28:27.098657] Epoch: [15]  [200/345]  eta: 0:00:36  lr: 0.000097  loss: 0.8385 (0.8254)  time: 0.2514  data: 0.0000  max mem: 10917
[14:28:32.130875] Epoch: [15]  [220/345]  eta: 0:00:31  lr: 0.000098  loss: 0.8253 (0.8254)  time: 0.2516  data: 0.0000  max mem: 10917
[14:28:37.165937] Epoch: [15]  [240/345]  eta: 0:00:26  lr: 0.000098  loss: 0.8125 (0.8243)  time: 0.2517  data: 0.0000  max mem: 10917
[14:28:42.189878] Epoch: [15]  [260/345]  eta: 0:00:21  lr: 0.000098  loss: 0.8225 (0.8237)  time: 0.2512  data: 0.0000  max mem: 10917
[14:28:47.222458] Epoch: [15]  [280/345]  eta: 0:00:16  lr: 0.000099  loss: 0.8155 (0.8233)  time: 0.2516  data: 0.0001  max mem: 10917
[14:28:52.266097] Epoch: [15]  [300/345]  eta: 0:00:11  lr: 0.000099  loss: 0.8396 (0.8242)  time: 0.2521  data: 0.0001  max mem: 10917
[14:28:57.309278] Epoch: [15]  [320/345]  eta: 0:00:06  lr: 0.000100  loss: 0.8349 (0.8247)  time: 0.2521  data: 0.0000  max mem: 10917
[14:29:02.341144] Epoch: [15]  [340/345]  eta: 0:00:01  lr: 0.000100  loss: 0.8195 (0.8243)  time: 0.2515  data: 0.0001  max mem: 10917
[14:29:03.348151] Epoch: [15]  [344/345]  eta: 0:00:00  lr: 0.000100  loss: 0.8195 (0.8244)  time: 0.2515  data: 0.0001  max mem: 10917
[14:29:03.405362] Epoch: [15] Total time: 0:01:26 (0.2517 s / it)
[14:29:03.405845] Averaged stats: lr: 0.000100  loss: 0.8195 (0.8244)
[14:29:03.644315] Test:  [  0/345]  eta: 0:01:21  loss: 0.7742 (0.7742)  time: 0.2355  data: 0.1548  max mem: 10917
[14:29:04.470420] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7848 (0.7820)  time: 0.0964  data: 0.0147  max mem: 10917
[14:29:05.294533] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7819 (0.7811)  time: 0.0824  data: 0.0004  max mem: 10917
[14:29:06.121121] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7820 (0.7836)  time: 0.0825  data: 0.0001  max mem: 10917
[14:29:06.951337] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7778 (0.7798)  time: 0.0828  data: 0.0001  max mem: 10917
[14:29:07.785019] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7745 (0.7807)  time: 0.0831  data: 0.0001  max mem: 10917
[14:29:08.623478] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7815 (0.7804)  time: 0.0836  data: 0.0001  max mem: 10917
[14:29:09.465563] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7793 (0.7802)  time: 0.0840  data: 0.0001  max mem: 10917
[14:29:10.310246] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7793 (0.7800)  time: 0.0843  data: 0.0001  max mem: 10917
[14:29:11.158903] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7764 (0.7796)  time: 0.0846  data: 0.0001  max mem: 10917
[14:29:12.010835] Test:  [100/345]  eta: 0:00:20  loss: 0.7742 (0.7793)  time: 0.0850  data: 0.0001  max mem: 10917
[14:29:12.866199] Test:  [110/345]  eta: 0:00:20  loss: 0.7858 (0.7811)  time: 0.0853  data: 0.0001  max mem: 10917
[14:29:13.725380] Test:  [120/345]  eta: 0:00:19  loss: 0.7889 (0.7806)  time: 0.0857  data: 0.0001  max mem: 10917
[14:29:14.587551] Test:  [130/345]  eta: 0:00:18  loss: 0.7669 (0.7803)  time: 0.0860  data: 0.0001  max mem: 10917
[14:29:15.454553] Test:  [140/345]  eta: 0:00:17  loss: 0.7841 (0.7807)  time: 0.0864  data: 0.0001  max mem: 10917
[14:29:16.324221] Test:  [150/345]  eta: 0:00:16  loss: 0.7873 (0.7816)  time: 0.0868  data: 0.0001  max mem: 10917
[14:29:17.197159] Test:  [160/345]  eta: 0:00:15  loss: 0.7873 (0.7817)  time: 0.0871  data: 0.0001  max mem: 10917
[14:29:18.073542] Test:  [170/345]  eta: 0:00:14  loss: 0.7735 (0.7813)  time: 0.0874  data: 0.0001  max mem: 10917
[14:29:18.953522] Test:  [180/345]  eta: 0:00:14  loss: 0.7757 (0.7810)  time: 0.0878  data: 0.0001  max mem: 10917
[14:29:19.837036] Test:  [190/345]  eta: 0:00:13  loss: 0.7813 (0.7811)  time: 0.0881  data: 0.0001  max mem: 10917
[14:29:20.723627] Test:  [200/345]  eta: 0:00:12  loss: 0.7845 (0.7815)  time: 0.0885  data: 0.0001  max mem: 10917
[14:29:21.613809] Test:  [210/345]  eta: 0:00:11  loss: 0.7826 (0.7815)  time: 0.0888  data: 0.0001  max mem: 10917
[14:29:22.507665] Test:  [220/345]  eta: 0:00:10  loss: 0.7826 (0.7817)  time: 0.0892  data: 0.0001  max mem: 10917
[14:29:23.405370] Test:  [230/345]  eta: 0:00:09  loss: 0.7900 (0.7821)  time: 0.0895  data: 0.0001  max mem: 10917
[14:29:24.307606] Test:  [240/345]  eta: 0:00:09  loss: 0.7877 (0.7819)  time: 0.0899  data: 0.0001  max mem: 10917
[14:29:25.211024] Test:  [250/345]  eta: 0:00:08  loss: 0.7763 (0.7818)  time: 0.0902  data: 0.0001  max mem: 10917
[14:29:26.119333] Test:  [260/345]  eta: 0:00:07  loss: 0.7765 (0.7819)  time: 0.0905  data: 0.0001  max mem: 10917
[14:29:27.030932] Test:  [270/345]  eta: 0:00:06  loss: 0.7772 (0.7817)  time: 0.0909  data: 0.0001  max mem: 10917
[14:29:27.946312] Test:  [280/345]  eta: 0:00:05  loss: 0.7823 (0.7818)  time: 0.0913  data: 0.0001  max mem: 10917
[14:29:28.865046] Test:  [290/345]  eta: 0:00:04  loss: 0.7906 (0.7821)  time: 0.0917  data: 0.0001  max mem: 10917
[14:29:29.787550] Test:  [300/345]  eta: 0:00:03  loss: 0.7828 (0.7820)  time: 0.0920  data: 0.0001  max mem: 10917
[14:29:30.712489] Test:  [310/345]  eta: 0:00:03  loss: 0.7743 (0.7819)  time: 0.0923  data: 0.0001  max mem: 10917
[14:29:31.641778] Test:  [320/345]  eta: 0:00:02  loss: 0.7727 (0.7815)  time: 0.0927  data: 0.0001  max mem: 10917
[14:29:32.573788] Test:  [330/345]  eta: 0:00:01  loss: 0.7727 (0.7817)  time: 0.0930  data: 0.0001  max mem: 10917
[14:29:33.509576] Test:  [340/345]  eta: 0:00:00  loss: 0.7738 (0.7814)  time: 0.0933  data: 0.0001  max mem: 10917
[14:29:33.885868] Test:  [344/345]  eta: 0:00:00  loss: 0.7738 (0.7812)  time: 0.0935  data: 0.0001  max mem: 10917
[14:29:33.943437] Test: Total time: 0:00:30 (0.0885 s / it)
[14:29:45.051888] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8514 (0.8514)  time: 0.2234  data: 0.1436  max mem: 10917
[14:29:45.865758] Test:  [10/57]  eta: 0:00:04  loss: 0.8952 (0.8945)  time: 0.0942  data: 0.0131  max mem: 10917
[14:29:46.684113] Test:  [20/57]  eta: 0:00:03  loss: 0.8952 (0.8861)  time: 0.0815  data: 0.0001  max mem: 10917
[14:29:47.504587] Test:  [30/57]  eta: 0:00:02  loss: 0.7732 (0.8459)  time: 0.0819  data: 0.0001  max mem: 10917
[14:29:48.328688] Test:  [40/57]  eta: 0:00:01  loss: 0.7618 (0.8236)  time: 0.0822  data: 0.0001  max mem: 10917
[14:29:49.156882] Test:  [50/57]  eta: 0:00:00  loss: 0.7509 (0.8154)  time: 0.0826  data: 0.0001  max mem: 10917
[14:29:49.606705] Test:  [56/57]  eta: 0:00:00  loss: 0.7890 (0.8195)  time: 0.0803  data: 0.0001  max mem: 10917
[14:29:49.665626] Test: Total time: 0:00:04 (0.0849 s / it)
[14:29:51.630968] Dice score of the network on the train images: 0.766874, val images: 0.809640
[14:29:51.631204] saving best_rec_model_0 @ epoch 15
[14:29:52.490324] saving best_dice_model_0 @ epoch 15
[14:29:53.297750] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:29:53.695780] Epoch: [16]  [  0/345]  eta: 0:02:16  lr: 0.000100  loss: 0.8094 (0.8094)  time: 0.3970  data: 0.1443  max mem: 10917
[14:29:58.770183] Epoch: [16]  [ 20/345]  eta: 0:01:24  lr: 0.000100  loss: 0.8237 (0.8255)  time: 0.2537  data: 0.0001  max mem: 10917
[14:30:03.773431] Epoch: [16]  [ 40/345]  eta: 0:01:17  lr: 0.000101  loss: 0.8182 (0.8248)  time: 0.2501  data: 0.0000  max mem: 10917
[14:30:08.776678] Epoch: [16]  [ 60/345]  eta: 0:01:12  lr: 0.000101  loss: 0.8092 (0.8209)  time: 0.2501  data: 0.0000  max mem: 10917
[14:30:13.785279] Epoch: [16]  [ 80/345]  eta: 0:01:07  lr: 0.000101  loss: 0.7972 (0.8170)  time: 0.2504  data: 0.0000  max mem: 10917
[14:30:18.800990] Epoch: [16]  [100/345]  eta: 0:01:01  lr: 0.000102  loss: 0.8012 (0.8145)  time: 0.2507  data: 0.0000  max mem: 10917
[14:30:23.822393] Epoch: [16]  [120/345]  eta: 0:00:56  lr: 0.000102  loss: 0.7983 (0.8135)  time: 0.2510  data: 0.0000  max mem: 10917
[14:30:28.842694] Epoch: [16]  [140/345]  eta: 0:00:51  lr: 0.000103  loss: 0.8131 (0.8135)  time: 0.2510  data: 0.0000  max mem: 10917
[14:30:33.863600] Epoch: [16]  [160/345]  eta: 0:00:46  lr: 0.000103  loss: 0.8151 (0.8144)  time: 0.2510  data: 0.0000  max mem: 10917
[14:30:38.888690] Epoch: [16]  [180/345]  eta: 0:00:41  lr: 0.000103  loss: 0.8242 (0.8164)  time: 0.2512  data: 0.0000  max mem: 10917
[14:30:43.921030] Epoch: [16]  [200/345]  eta: 0:00:36  lr: 0.000104  loss: 0.8246 (0.8169)  time: 0.2516  data: 0.0000  max mem: 10917
[14:30:48.957405] Epoch: [16]  [220/345]  eta: 0:00:31  lr: 0.000104  loss: 0.8121 (0.8169)  time: 0.2518  data: 0.0001  max mem: 10917
[14:30:53.995787] Epoch: [16]  [240/345]  eta: 0:00:26  lr: 0.000104  loss: 0.8160 (0.8169)  time: 0.2519  data: 0.0000  max mem: 10917

[14:30:59.036744] Epoch: [16]  [260/345]  eta: 0:00:21  lr: 0.000105  loss: 0.8072 (0.8167)  time: 0.2520  data: 0.0000  max mem: 10917
[14:31:04.077505] Epoch: [16]  [280/345]  eta: 0:00:16  lr: 0.000105  loss: 0.8171 (0.8165)  time: 0.2520  data: 0.0000  max mem: 10917
[14:31:09.119125] Epoch: [16]  [300/345]  eta: 0:00:11  lr: 0.000105  loss: 0.8080 (0.8159)  time: 0.2520  data: 0.0000  max mem: 10917
[14:31:14.162877] Epoch: [16]  [320/345]  eta: 0:00:06  lr: 0.000106  loss: 0.8169 (0.8159)  time: 0.2522  data: 0.0001  max mem: 10917
[14:31:19.211184] Epoch: [16]  [340/345]  eta: 0:00:01  lr: 0.000106  loss: 0.8141 (0.8160)  time: 0.2524  data: 0.0000  max mem: 10917
[14:31:20.220622] Epoch: [16]  [344/345]  eta: 0:00:00  lr: 0.000106  loss: 0.8171 (0.8161)  time: 0.2524  data: 0.0001  max mem: 10917
[14:31:20.282206] Epoch: [16] Total time: 0:01:26 (0.2521 s / it)
[14:31:20.282428] Averaged stats: lr: 0.000106  loss: 0.8171 (0.8161)
[14:31:20.527454] Test:  [  0/345]  eta: 0:01:23  loss: 0.8274 (0.8274)  time: 0.2413  data: 0.1614  max mem: 10917
[14:31:21.362606] Test:  [ 10/345]  eta: 0:00:32  loss: 0.8222 (0.8194)  time: 0.0978  data: 0.0161  max mem: 10917
[14:31:22.186662] Test:  [ 20/345]  eta: 0:00:29  loss: 0.8228 (0.8210)  time: 0.0829  data: 0.0008  max mem: 10917
[14:31:23.013869] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8216 (0.8198)  time: 0.0825  data: 0.0001  max mem: 10917
[14:31:23.844533] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8170 (0.8205)  time: 0.0828  data: 0.0001  max mem: 10917
[14:31:24.678974] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8152 (0.8200)  time: 0.0832  data: 0.0001  max mem: 10917
[14:31:25.517437] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8273 (0.8214)  time: 0.0836  data: 0.0001  max mem: 10917
[14:31:26.358591] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8273 (0.8207)  time: 0.0839  data: 0.0001  max mem: 10917
[14:31:27.203973] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8186 (0.8212)  time: 0.0843  data: 0.0001  max mem: 10917
[14:31:28.052831] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8215 (0.8214)  time: 0.0847  data: 0.0001  max mem: 10917
[14:31:28.904820] Test:  [100/345]  eta: 0:00:20  loss: 0.8191 (0.8211)  time: 0.0850  data: 0.0001  max mem: 10917
[14:31:29.760133] Test:  [110/345]  eta: 0:00:20  loss: 0.8191 (0.8208)  time: 0.0853  data: 0.0001  max mem: 10917
[14:31:30.620292] Test:  [120/345]  eta: 0:00:19  loss: 0.8209 (0.8210)  time: 0.0857  data: 0.0001  max mem: 10917
[14:31:31.482718] Test:  [130/345]  eta: 0:00:18  loss: 0.8278 (0.8220)  time: 0.0861  data: 0.0001  max mem: 10917
[14:31:32.349053] Test:  [140/345]  eta: 0:00:17  loss: 0.8278 (0.8223)  time: 0.0864  data: 0.0001  max mem: 10917
[14:31:33.218504] Test:  [150/345]  eta: 0:00:16  loss: 0.8252 (0.8222)  time: 0.0867  data: 0.0001  max mem: 10917
[14:31:34.091289] Test:  [160/345]  eta: 0:00:15  loss: 0.8137 (0.8223)  time: 0.0871  data: 0.0001  max mem: 10917
[14:31:34.968085] Test:  [170/345]  eta: 0:00:15  loss: 0.8187 (0.8221)  time: 0.0874  data: 0.0001  max mem: 10917
[14:31:35.847711] Test:  [180/345]  eta: 0:00:14  loss: 0.8187 (0.8228)  time: 0.0878  data: 0.0001  max mem: 10917
[14:31:36.731175] Test:  [190/345]  eta: 0:00:13  loss: 0.8203 (0.8223)  time: 0.0881  data: 0.0001  max mem: 10917
[14:31:37.617753] Test:  [200/345]  eta: 0:00:12  loss: 0.8163 (0.8220)  time: 0.0885  data: 0.0001  max mem: 10917
[14:31:38.508621] Test:  [210/345]  eta: 0:00:11  loss: 0.8245 (0.8225)  time: 0.0888  data: 0.0001  max mem: 10917
[14:31:39.402519] Test:  [220/345]  eta: 0:00:10  loss: 0.8299 (0.8224)  time: 0.0892  data: 0.0001  max mem: 10917
[14:31:40.300107] Test:  [230/345]  eta: 0:00:09  loss: 0.8270 (0.8225)  time: 0.0895  data: 0.0001  max mem: 10917
[14:31:41.201961] Test:  [240/345]  eta: 0:00:09  loss: 0.8176 (0.8221)  time: 0.0899  data: 0.0001  max mem: 10917
[14:31:42.106233] Test:  [250/345]  eta: 0:00:08  loss: 0.8138 (0.8222)  time: 0.0902  data: 0.0001  max mem: 10917
[14:31:43.015151] Test:  [260/345]  eta: 0:00:07  loss: 0.8301 (0.8230)  time: 0.0906  data: 0.0001  max mem: 10917
[14:31:43.927078] Test:  [270/345]  eta: 0:00:06  loss: 0.8183 (0.8231)  time: 0.0910  data: 0.0001  max mem: 10917
[14:31:44.842413] Test:  [280/345]  eta: 0:00:05  loss: 0.8183 (0.8233)  time: 0.0913  data: 0.0001  max mem: 10917
[14:31:45.761135] Test:  [290/345]  eta: 0:00:04  loss: 0.8149 (0.8229)  time: 0.0917  data: 0.0001  max mem: 10917
[14:31:46.683744] Test:  [300/345]  eta: 0:00:03  loss: 0.8157 (0.8231)  time: 0.0920  data: 0.0001  max mem: 10917
[14:31:47.609095] Test:  [310/345]  eta: 0:00:03  loss: 0.8226 (0.8230)  time: 0.0924  data: 0.0001  max mem: 10917
[14:31:48.539090] Test:  [320/345]  eta: 0:00:02  loss: 0.8215 (0.8230)  time: 0.0927  data: 0.0001  max mem: 10917
[14:31:49.470936] Test:  [330/345]  eta: 0:00:01  loss: 0.8277 (0.8232)  time: 0.0930  data: 0.0001  max mem: 10917
[14:31:50.406464] Test:  [340/345]  eta: 0:00:00  loss: 0.8256 (0.8229)  time: 0.0933  data: 0.0001  max mem: 10917
[14:31:50.781851] Test:  [344/345]  eta: 0:00:00  loss: 0.8259 (0.8230)  time: 0.0935  data: 0.0001  max mem: 10917
[14:31:50.838545] Test: Total time: 0:00:30 (0.0886 s / it)
[14:32:01.878578] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9559 (0.9559)  time: 0.2243  data: 0.1446  max mem: 10917
[14:32:02.690316] Test:  [10/57]  eta: 0:00:04  loss: 0.9508 (0.9512)  time: 0.0941  data: 0.0132  max mem: 10917
[14:32:03.505537] Test:  [20/57]  eta: 0:00:03  loss: 0.9504 (0.9364)  time: 0.0813  data: 0.0001  max mem: 10917
[14:32:04.325530] Test:  [30/57]  eta: 0:00:02  loss: 0.8210 (0.8907)  time: 0.0817  data: 0.0001  max mem: 10917
[14:32:05.149543] Test:  [40/57]  eta: 0:00:01  loss: 0.8042 (0.8656)  time: 0.0822  data: 0.0001  max mem: 10917
[14:32:05.977600] Test:  [50/57]  eta: 0:00:00  loss: 0.7932 (0.8577)  time: 0.0826  data: 0.0001  max mem: 10917
[14:32:06.427172] Test:  [56/57]  eta: 0:00:00  loss: 0.8092 (0.8603)  time: 0.0803  data: 0.0001  max mem: 10917
[14:32:06.486389] Test: Total time: 0:00:04 (0.0848 s / it)
[14:32:08.471831] Dice score of the network on the train images: 0.776810, val images: 0.779506
[14:32:08.474966] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:32:08.875250] Epoch: [17]  [  0/345]  eta: 0:02:17  lr: 0.000106  loss: 0.8359 (0.8359)  time: 0.3995  data: 0.1478  max mem: 10917
[14:32:13.874029] Epoch: [17]  [ 20/345]  eta: 0:01:23  lr: 0.000107  loss: 0.8177 (0.8175)  time: 0.2499  data: 0.0000  max mem: 10917
[14:32:18.880662] Epoch: [17]  [ 40/345]  eta: 0:01:17  lr: 0.000107  loss: 0.8173 (0.8180)  time: 0.2503  data: 0.0000  max mem: 10917
[14:32:23.888382] Epoch: [17]  [ 60/345]  eta: 0:01:11  lr: 0.000107  loss: 0.8077 (0.8144)  time: 0.2503  data: 0.0000  max mem: 10917
[14:32:28.906328] Epoch: [17]  [ 80/345]  eta: 0:01:06  lr: 0.000108  loss: 0.7998 (0.8123)  time: 0.2509  data: 0.0000  max mem: 10917
[14:32:33.925402] Epoch: [17]  [100/345]  eta: 0:01:01  lr: 0.000108  loss: 0.8026 (0.8116)  time: 0.2509  data: 0.0001  max mem: 10917
[14:32:38.948555] Epoch: [17]  [120/345]  eta: 0:00:56  lr: 0.000108  loss: 0.8115 (0.8121)  time: 0.2511  data: 0.0001  max mem: 10917
[14:32:43.971393] Epoch: [17]  [140/345]  eta: 0:00:51  lr: 0.000109  loss: 0.8049 (0.8112)  time: 0.2511  data: 0.0000  max mem: 10917
[14:32:48.999136] Epoch: [17]  [160/345]  eta: 0:00:46  lr: 0.000109  loss: 0.8240 (0.8128)  time: 0.2513  data: 0.0001  max mem: 10917
[14:32:54.032658] Epoch: [17]  [180/345]  eta: 0:00:41  lr: 0.000110  loss: 0.8327 (0.8148)  time: 0.2516  data: 0.0000  max mem: 10917
[14:32:59.064124] Epoch: [17]  [200/345]  eta: 0:00:36  lr: 0.000110  loss: 0.8147 (0.8148)  time: 0.2515  data: 0.0001  max mem: 10917
[14:33:04.097742] Epoch: [17]  [220/345]  eta: 0:00:31  lr: 0.000110  loss: 0.8225 (0.8152)  time: 0.2516  data: 0.0001  max mem: 10917
[14:33:09.135511] Epoch: [17]  [240/345]  eta: 0:00:26  lr: 0.000111  loss: 0.8158 (0.8149)  time: 0.2519  data: 0.0000  max mem: 10917
[14:33:14.171800] Epoch: [17]  [260/345]  eta: 0:00:21  lr: 0.000111  loss: 0.7986 (0.8138)  time: 0.2518  data: 0.0000  max mem: 10917

[14:33:19.212409] Epoch: [17]  [280/345]  eta: 0:00:16  lr: 0.000111  loss: 0.8071 (0.8132)  time: 0.2520  data: 0.0001  max mem: 10917
[14:33:24.251689] Epoch: [17]  [300/345]  eta: 0:00:11  lr: 0.000112  loss: 0.8029 (0.8124)  time: 0.2519  data: 0.0001  max mem: 10917
[14:33:29.296008] Epoch: [17]  [320/345]  eta: 0:00:06  lr: 0.000112  loss: 0.7996 (0.8116)  time: 0.2522  data: 0.0000  max mem: 10917
[14:33:34.339662] Epoch: [17]  [340/345]  eta: 0:00:01  lr: 0.000112  loss: 0.7904 (0.8107)  time: 0.2521  data: 0.0000  max mem: 10917
[14:33:35.349032] Epoch: [17]  [344/345]  eta: 0:00:00  lr: 0.000112  loss: 0.7905 (0.8106)  time: 0.2522  data: 0.0001  max mem: 10917
[14:33:35.407572] Epoch: [17] Total time: 0:01:26 (0.2520 s / it)
[14:33:35.407935] Averaged stats: lr: 0.000112  loss: 0.7905 (0.8106)
[14:33:35.643496] Test:  [  0/345]  eta: 0:01:19  loss: 0.8030 (0.8030)  time: 0.2319  data: 0.1518  max mem: 10917
[14:33:36.466217] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7793 (0.7811)  time: 0.0958  data: 0.0140  max mem: 10917
[14:33:37.288981] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7758 (0.7756)  time: 0.0822  data: 0.0002  max mem: 10917
[14:33:38.115551] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7767 (0.7761)  time: 0.0824  data: 0.0001  max mem: 10917
[14:33:38.947046] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7788 (0.7764)  time: 0.0829  data: 0.0001  max mem: 10917
[14:33:39.780931] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7721 (0.7750)  time: 0.0832  data: 0.0001  max mem: 10917
[14:33:40.618297] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7646 (0.7730)  time: 0.0835  data: 0.0001  max mem: 10917
[14:33:41.459517] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7676 (0.7729)  time: 0.0839  data: 0.0001  max mem: 10917
[14:33:42.303953] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7704 (0.7727)  time: 0.0842  data: 0.0001  max mem: 10917
[14:33:43.152483] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7714 (0.7728)  time: 0.0846  data: 0.0001  max mem: 10917
[14:33:44.004471] Test:  [100/345]  eta: 0:00:20  loss: 0.7714 (0.7723)  time: 0.0850  data: 0.0001  max mem: 10917
[14:33:44.859682] Test:  [110/345]  eta: 0:00:19  loss: 0.7643 (0.7718)  time: 0.0853  data: 0.0001  max mem: 10917
[14:33:45.719015] Test:  [120/345]  eta: 0:00:19  loss: 0.7629 (0.7709)  time: 0.0857  data: 0.0001  max mem: 10917
[14:33:46.581582] Test:  [130/345]  eta: 0:00:18  loss: 0.7718 (0.7711)  time: 0.0860  data: 0.0001  max mem: 10917
[14:33:47.447371] Test:  [140/345]  eta: 0:00:17  loss: 0.7766 (0.7718)  time: 0.0864  data: 0.0001  max mem: 10917
[14:33:48.316069] Test:  [150/345]  eta: 0:00:16  loss: 0.7773 (0.7720)  time: 0.0867  data: 0.0001  max mem: 10917
[14:33:49.188702] Test:  [160/345]  eta: 0:00:15  loss: 0.7707 (0.7724)  time: 0.0870  data: 0.0001  max mem: 10917
[14:33:50.065047] Test:  [170/345]  eta: 0:00:14  loss: 0.7757 (0.7725)  time: 0.0874  data: 0.0001  max mem: 10917
[14:33:50.945452] Test:  [180/345]  eta: 0:00:14  loss: 0.7757 (0.7726)  time: 0.0878  data: 0.0001  max mem: 10917
[14:33:51.827672] Test:  [190/345]  eta: 0:00:13  loss: 0.7712 (0.7724)  time: 0.0881  data: 0.0001  max mem: 10917
[14:33:52.715278] Test:  [200/345]  eta: 0:00:12  loss: 0.7650 (0.7720)  time: 0.0884  data: 0.0001  max mem: 10917
[14:33:53.605675] Test:  [210/345]  eta: 0:00:11  loss: 0.7691 (0.7721)  time: 0.0889  data: 0.0001  max mem: 10917
[14:33:54.500039] Test:  [220/345]  eta: 0:00:10  loss: 0.7648 (0.7716)  time: 0.0892  data: 0.0001  max mem: 10917
[14:33:55.397749] Test:  [230/345]  eta: 0:00:09  loss: 0.7635 (0.7713)  time: 0.0896  data: 0.0001  max mem: 10917
[14:33:56.299582] Test:  [240/345]  eta: 0:00:09  loss: 0.7685 (0.7716)  time: 0.0899  data: 0.0001  max mem: 10917
[14:33:57.202875] Test:  [250/345]  eta: 0:00:08  loss: 0.7655 (0.7714)  time: 0.0902  data: 0.0001  max mem: 10917
[14:33:58.112606] Test:  [260/345]  eta: 0:00:07  loss: 0.7609 (0.7711)  time: 0.0906  data: 0.0001  max mem: 10917
[14:33:59.025087] Test:  [270/345]  eta: 0:00:06  loss: 0.7609 (0.7708)  time: 0.0911  data: 0.0001  max mem: 10917
[14:33:59.940358] Test:  [280/345]  eta: 0:00:05  loss: 0.7642 (0.7706)  time: 0.0913  data: 0.0001  max mem: 10917
[14:34:00.858726] Test:  [290/345]  eta: 0:00:04  loss: 0.7679 (0.7708)  time: 0.0916  data: 0.0001  max mem: 10917
[14:34:01.781090] Test:  [300/345]  eta: 0:00:03  loss: 0.7705 (0.7708)  time: 0.0920  data: 0.0001  max mem: 10917
[14:34:02.707468] Test:  [310/345]  eta: 0:00:03  loss: 0.7618 (0.7706)  time: 0.0924  data: 0.0001  max mem: 10917
[14:34:03.637093] Test:  [320/345]  eta: 0:00:02  loss: 0.7583 (0.7703)  time: 0.0928  data: 0.0001  max mem: 10917
[14:34:04.569797] Test:  [330/345]  eta: 0:00:01  loss: 0.7679 (0.7704)  time: 0.0931  data: 0.0001  max mem: 10917
[14:34:05.506714] Test:  [340/345]  eta: 0:00:00  loss: 0.7712 (0.7703)  time: 0.0934  data: 0.0001  max mem: 10917
[14:34:05.882025] Test:  [344/345]  eta: 0:00:00  loss: 0.7712 (0.7704)  time: 0.0935  data: 0.0001  max mem: 10917
[14:34:05.936902] Test: Total time: 0:00:30 (0.0885 s / it)
[14:34:16.969223] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8906 (0.8906)  time: 0.2210  data: 0.1413  max mem: 10917
[14:34:17.781464] Test:  [10/57]  eta: 0:00:04  loss: 0.8971 (0.9074)  time: 0.0939  data: 0.0129  max mem: 10917
[14:34:18.598390] Test:  [20/57]  eta: 0:00:03  loss: 0.8971 (0.8935)  time: 0.0814  data: 0.0001  max mem: 10917
[14:34:19.419081] Test:  [30/57]  eta: 0:00:02  loss: 0.7939 (0.8541)  time: 0.0818  data: 0.0001  max mem: 10917
[14:34:20.243055] Test:  [40/57]  eta: 0:00:01  loss: 0.7670 (0.8330)  time: 0.0822  data: 0.0001  max mem: 10917
[14:34:21.071440] Test:  [50/57]  eta: 0:00:00  loss: 0.7670 (0.8249)  time: 0.0826  data: 0.0001  max mem: 10917
[14:34:21.520993] Test:  [56/57]  eta: 0:00:00  loss: 0.7854 (0.8289)  time: 0.0803  data: 0.0001  max mem: 10917
[14:34:21.562849] Test: Total time: 0:00:04 (0.0845 s / it)
[14:34:23.566334] Dice score of the network on the train images: 0.796419, val images: 0.802742
[14:34:23.569442] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:34:23.974586] Epoch: [18]  [  0/345]  eta: 0:02:19  lr: 0.000113  loss: 0.7862 (0.7862)  time: 0.4043  data: 0.1521  max mem: 10917
[14:34:28.970110] Epoch: [18]  [ 20/345]  eta: 0:01:23  lr: 0.000113  loss: 0.8006 (0.8022)  time: 0.2497  data: 0.0001  max mem: 10917
[14:34:33.961298] Epoch: [18]  [ 40/345]  eta: 0:01:17  lr: 0.000113  loss: 0.7972 (0.8012)  time: 0.2495  data: 0.0001  max mem: 10917
[14:34:38.953357] Epoch: [18]  [ 60/345]  eta: 0:01:11  lr: 0.000114  loss: 0.8009 (0.8016)  time: 0.2496  data: 0.0001  max mem: 10917
[14:34:43.954642] Epoch: [18]  [ 80/345]  eta: 0:01:06  lr: 0.000114  loss: 0.8026 (0.8029)  time: 0.2500  data: 0.0001  max mem: 10917
[14:34:48.958588] Epoch: [18]  [100/345]  eta: 0:01:01  lr: 0.000114  loss: 0.8034 (0.8040)  time: 0.2502  data: 0.0001  max mem: 10917
[14:34:53.967223] Epoch: [18]  [120/345]  eta: 0:00:56  lr: 0.000115  loss: 0.8049 (0.8047)  time: 0.2504  data: 0.0001  max mem: 10917
[14:34:59.001719] Epoch: [18]  [140/345]  eta: 0:00:51  lr: 0.000115  loss: 0.8090 (0.8055)  time: 0.2517  data: 0.0001  max mem: 10917
[14:35:04.032097] Epoch: [18]  [160/345]  eta: 0:00:46  lr: 0.000115  loss: 0.7959 (0.8049)  time: 0.2515  data: 0.0000  max mem: 10917
[14:35:09.063445] Epoch: [18]  [180/345]  eta: 0:00:41  lr: 0.000116  loss: 0.8060 (0.8046)  time: 0.2515  data: 0.0001  max mem: 10917
[14:35:14.096947] Epoch: [18]  [200/345]  eta: 0:00:36  lr: 0.000116  loss: 0.7960 (0.8044)  time: 0.2516  data: 0.0000  max mem: 10917
[14:35:19.129570] Epoch: [18]  [220/345]  eta: 0:00:31  lr: 0.000116  loss: 0.8003 (0.8042)  time: 0.2516  data: 0.0000  max mem: 10917
[14:35:24.166731] Epoch: [18]  [240/345]  eta: 0:00:26  lr: 0.000117  loss: 0.7999 (0.8040)  time: 0.2518  data: 0.0000  max mem: 10917
[14:35:29.207527] Epoch: [18]  [260/345]  eta: 0:00:21  lr: 0.000117  loss: 0.8031 (0.8040)  time: 0.2520  data: 0.0001  max mem: 10917
[14:35:34.234280] Epoch: [18]  [280/345]  eta: 0:00:16  lr: 0.000118  loss: 0.8073 (0.8045)  time: 0.2513  data: 0.0001  max mem: 10917
[14:35:39.271234] Epoch: [18]  [300/345]  eta: 0:00:11  lr: 0.000118  loss: 0.8099 (0.8051)  time: 0.2518  data: 0.0001  max mem: 10917
[14:35:44.309854] Epoch: [18]  [320/345]  eta: 0:00:06  lr: 0.000118  loss: 0.8241 (0.8062)  time: 0.2519  data: 0.0000  max mem: 10917
[14:35:49.347933] Epoch: [18]  [340/345]  eta: 0:00:01  lr: 0.000119  loss: 0.8208 (0.8072)  time: 0.2519  data: 0.0000  max mem: 10917
[14:35:50.356731] Epoch: [18]  [344/345]  eta: 0:00:00  lr: 0.000119  loss: 0.8233 (0.8074)  time: 0.2519  data: 0.0001  max mem: 10917
[14:35:50.415419] Epoch: [18] Total time: 0:01:26 (0.2517 s / it)
[14:35:50.415898] Averaged stats: lr: 0.000119  loss: 0.8233 (0.8074)
[14:35:50.654455] Test:  [  0/345]  eta: 0:01:21  loss: 0.7864 (0.7864)  time: 0.2348  data: 0.1548  max mem: 10917
[14:35:51.474493] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7752 (0.7789)  time: 0.0958  data: 0.0141  max mem: 10917
[14:35:52.298625] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7752 (0.7774)  time: 0.0821  data: 0.0001  max mem: 10917
[14:35:53.125630] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7793 (0.7788)  time: 0.0825  data: 0.0001  max mem: 10917
[14:35:53.955619] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7756 (0.7786)  time: 0.0828  data: 0.0001  max mem: 10917
[14:35:54.789195] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7756 (0.7788)  time: 0.0831  data: 0.0001  max mem: 10917
[14:35:55.627825] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7835 (0.7806)  time: 0.0836  data: 0.0001  max mem: 10917
[14:35:56.469014] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7835 (0.7809)  time: 0.0839  data: 0.0001  max mem: 10917
[14:35:57.313900] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7761 (0.7804)  time: 0.0843  data: 0.0001  max mem: 10917
[14:35:58.163249] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7775 (0.7810)  time: 0.0847  data: 0.0001  max mem: 10917
[14:35:59.015018] Test:  [100/345]  eta: 0:00:20  loss: 0.7881 (0.7817)  time: 0.0850  data: 0.0001  max mem: 10917
[14:35:59.870134] Test:  [110/345]  eta: 0:00:19  loss: 0.7838 (0.7810)  time: 0.0853  data: 0.0001  max mem: 10917
[14:36:00.728851] Test:  [120/345]  eta: 0:00:19  loss: 0.7782 (0.7823)  time: 0.0856  data: 0.0001  max mem: 10917
[14:36:01.591723] Test:  [130/345]  eta: 0:00:18  loss: 0.7895 (0.7819)  time: 0.0860  data: 0.0001  max mem: 10917
[14:36:02.458114] Test:  [140/345]  eta: 0:00:17  loss: 0.7761 (0.7812)  time: 0.0864  data: 0.0001  max mem: 10917
[14:36:03.327297] Test:  [150/345]  eta: 0:00:16  loss: 0.7763 (0.7815)  time: 0.0867  data: 0.0001  max mem: 10917
[14:36:04.200593] Test:  [160/345]  eta: 0:00:15  loss: 0.7889 (0.7817)  time: 0.0871  data: 0.0001  max mem: 10917
[14:36:05.077088] Test:  [170/345]  eta: 0:00:14  loss: 0.7838 (0.7817)  time: 0.0874  data: 0.0001  max mem: 10917
[14:36:05.956928] Test:  [180/345]  eta: 0:00:14  loss: 0.7844 (0.7822)  time: 0.0878  data: 0.0001  max mem: 10917
[14:36:06.840387] Test:  [190/345]  eta: 0:00:13  loss: 0.7862 (0.7822)  time: 0.0881  data: 0.0001  max mem: 10917
[14:36:07.727393] Test:  [200/345]  eta: 0:00:12  loss: 0.7862 (0.7826)  time: 0.0885  data: 0.0001  max mem: 10917
[14:36:08.618098] Test:  [210/345]  eta: 0:00:11  loss: 0.7963 (0.7831)  time: 0.0888  data: 0.0001  max mem: 10917
[14:36:09.512069] Test:  [220/345]  eta: 0:00:10  loss: 0.7874 (0.7832)  time: 0.0892  data: 0.0001  max mem: 10917
[14:36:10.410965] Test:  [230/345]  eta: 0:00:09  loss: 0.7812 (0.7832)  time: 0.0896  data: 0.0001  max mem: 10917
[14:36:11.313164] Test:  [240/345]  eta: 0:00:09  loss: 0.7799 (0.7832)  time: 0.0900  data: 0.0001  max mem: 10917
[14:36:12.217566] Test:  [250/345]  eta: 0:00:08  loss: 0.7847 (0.7837)  time: 0.0903  data: 0.0001  max mem: 10917
[14:36:13.126397] Test:  [260/345]  eta: 0:00:07  loss: 0.7847 (0.7839)  time: 0.0906  data: 0.0001  max mem: 10917
[14:36:14.039399] Test:  [270/345]  eta: 0:00:06  loss: 0.7776 (0.7836)  time: 0.0910  data: 0.0001  max mem: 10917
[14:36:14.954436] Test:  [280/345]  eta: 0:00:05  loss: 0.7768 (0.7832)  time: 0.0914  data: 0.0001  max mem: 10917
[14:36:15.872526] Test:  [290/345]  eta: 0:00:04  loss: 0.7782 (0.7835)  time: 0.0916  data: 0.0001  max mem: 10917
[14:36:16.793778] Test:  [300/345]  eta: 0:00:03  loss: 0.7828 (0.7836)  time: 0.0919  data: 0.0001  max mem: 10917
[14:36:17.718793] Test:  [310/345]  eta: 0:00:03  loss: 0.7894 (0.7839)  time: 0.0923  data: 0.0001  max mem: 10917
[14:36:18.647992] Test:  [320/345]  eta: 0:00:02  loss: 0.7771 (0.7837)  time: 0.0927  data: 0.0001  max mem: 10917
[14:36:19.579994] Test:  [330/345]  eta: 0:00:01  loss: 0.7892 (0.7841)  time: 0.0930  data: 0.0001  max mem: 10917
[14:36:20.515314] Test:  [340/345]  eta: 0:00:00  loss: 0.7938 (0.7841)  time: 0.0933  data: 0.0001  max mem: 10917
[14:36:20.892513] Test:  [344/345]  eta: 0:00:00  loss: 0.7929 (0.7840)  time: 0.0935  data: 0.0001  max mem: 10917
[14:36:20.950020] Test: Total time: 0:00:30 (0.0885 s / it)
[14:36:31.997294] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9433 (0.9433)  time: 0.2225  data: 0.1429  max mem: 10917
[14:36:32.809957] Test:  [10/57]  eta: 0:00:04  loss: 0.9247 (0.9157)  time: 0.0940  data: 0.0130  max mem: 10917
[14:36:33.626050] Test:  [20/57]  eta: 0:00:03  loss: 0.9029 (0.9012)  time: 0.0814  data: 0.0001  max mem: 10917
[14:36:34.445833] Test:  [30/57]  eta: 0:00:02  loss: 0.7894 (0.8591)  time: 0.0817  data: 0.0001  max mem: 10917
[14:36:35.269285] Test:  [40/57]  eta: 0:00:01  loss: 0.7824 (0.8356)  time: 0.0821  data: 0.0001  max mem: 10917
[14:36:36.095874] Test:  [50/57]  eta: 0:00:00  loss: 0.7688 (0.8272)  time: 0.0825  data: 0.0001  max mem: 10917
[14:36:36.545610] Test:  [56/57]  eta: 0:00:00  loss: 0.7887 (0.8320)  time: 0.0803  data: 0.0001  max mem: 10917
[14:36:36.600927] Test: Total time: 0:00:04 (0.0847 s / it)
[14:36:38.554104] Dice score of the network on the train images: 0.782039, val images: 0.797495
[14:36:38.557782] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:36:38.956803] Epoch: [19]  [  0/345]  eta: 0:02:17  lr: 0.000119  loss: 0.8188 (0.8188)  time: 0.3980  data: 0.1458  max mem: 10917
[14:36:43.952481] Epoch: [19]  [ 20/345]  eta: 0:01:23  lr: 0.000119  loss: 0.8084 (0.8139)  time: 0.2497  data: 0.0000  max mem: 10917
[14:36:48.954812] Epoch: [19]  [ 40/345]  eta: 0:01:17  lr: 0.000119  loss: 0.8399 (0.8272)  time: 0.2501  data: 0.0000  max mem: 10917
[14:36:53.957294] Epoch: [19]  [ 60/345]  eta: 0:01:11  lr: 0.000120  loss: 0.8201 (0.8249)  time: 0.2501  data: 0.0000  max mem: 10917
[14:36:58.971329] Epoch: [19]  [ 80/345]  eta: 0:01:06  lr: 0.000120  loss: 0.8053 (0.8206)  time: 0.2507  data: 0.0000  max mem: 10917
[14:37:03.988657] Epoch: [19]  [100/345]  eta: 0:01:01  lr: 0.000121  loss: 0.8110 (0.8186)  time: 0.2508  data: 0.0000  max mem: 10917
[14:37:09.011872] Epoch: [19]  [120/345]  eta: 0:00:56  lr: 0.000121  loss: 0.8001 (0.8158)  time: 0.2511  data: 0.0000  max mem: 10917
[14:37:14.035429] Epoch: [19]  [140/345]  eta: 0:00:51  lr: 0.000121  loss: 0.8047 (0.8148)  time: 0.2511  data: 0.0000  max mem: 10917
[14:37:19.061436] Epoch: [19]  [160/345]  eta: 0:00:46  lr: 0.000122  loss: 0.7953 (0.8126)  time: 0.2513  data: 0.0000  max mem: 10917
[14:37:24.087422] Epoch: [19]  [180/345]  eta: 0:00:41  lr: 0.000122  loss: 0.7922 (0.8106)  time: 0.2512  data: 0.0001  max mem: 10917
[14:37:29.117471] Epoch: [19]  [200/345]  eta: 0:00:36  lr: 0.000122  loss: 0.8013 (0.8100)  time: 0.2515  data: 0.0000  max mem: 10917
[14:37:34.151373] Epoch: [19]  [220/345]  eta: 0:00:31  lr: 0.000123  loss: 0.8025 (0.8093)  time: 0.2517  data: 0.0000  max mem: 10917
[14:37:39.184643] Epoch: [19]  [240/345]  eta: 0:00:26  lr: 0.000123  loss: 0.8009 (0.8089)  time: 0.2516  data: 0.0000  max mem: 10917
[14:37:44.222631] Epoch: [19]  [260/345]  eta: 0:00:21  lr: 0.000123  loss: 0.7960 (0.8085)  time: 0.2519  data: 0.0000  max mem: 10917
[14:37:49.345124] Epoch: [19]  [280/345]  eta: 0:00:16  lr: 0.000124  loss: 0.8248 (0.8094)  time: 0.2561  data: 0.0000  max mem: 10917
[14:37:54.388238] Epoch: [19]  [300/345]  eta: 0:00:11  lr: 0.000124  loss: 0.8015 (0.8092)  time: 0.2521  data: 0.0000  max mem: 10917
[14:37:59.430362] Epoch: [19]  [320/345]  eta: 0:00:06  lr: 0.000125  loss: 0.7995 (0.8087)  time: 0.2521  data: 0.0000  max mem: 10917
[14:38:04.475090] Epoch: [19]  [340/345]  eta: 0:00:01  lr: 0.000125  loss: 0.8062 (0.8088)  time: 0.2522  data: 0.0000  max mem: 10917
[14:38:05.484085] Epoch: [19]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.8078 (0.8086)  time: 0.2522  data: 0.0001  max mem: 10917
[14:38:05.548834] Epoch: [19] Total time: 0:01:26 (0.2521 s / it)
[14:38:05.549300] Averaged stats: lr: 0.000125  loss: 0.8078 (0.8086)
[14:38:05.785782] Test:  [  0/345]  eta: 0:01:20  loss: 0.7775 (0.7775)  time: 0.2327  data: 0.1525  max mem: 10917
[14:38:06.608882] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7775 (0.7780)  time: 0.0959  data: 0.0142  max mem: 10917
[14:38:07.432697] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7806 (0.7798)  time: 0.0823  data: 0.0002  max mem: 10917
[14:38:08.260169] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7724 (0.7765)  time: 0.0825  data: 0.0001  max mem: 10917
[14:38:09.090998] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7779 (0.7791)  time: 0.0829  data: 0.0001  max mem: 10917
[14:38:09.925200] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7861 (0.7797)  time: 0.0832  data: 0.0001  max mem: 10917
[14:38:10.763720] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7668 (0.7772)  time: 0.0836  data: 0.0001  max mem: 10917
[14:38:11.605172] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7656 (0.7772)  time: 0.0840  data: 0.0001  max mem: 10917
[14:38:12.449893] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7646 (0.7752)  time: 0.0843  data: 0.0001  max mem: 10917
[14:38:13.298474] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7646 (0.7748)  time: 0.0846  data: 0.0001  max mem: 10917
[14:38:14.149757] Test:  [100/345]  eta: 0:00:20  loss: 0.7702 (0.7744)  time: 0.0849  data: 0.0001  max mem: 10917
[14:38:15.005413] Test:  [110/345]  eta: 0:00:19  loss: 0.7691 (0.7744)  time: 0.0853  data: 0.0001  max mem: 10917
[14:38:15.865510] Test:  [120/345]  eta: 0:00:19  loss: 0.7691 (0.7746)  time: 0.0857  data: 0.0001  max mem: 10917
[14:38:16.728522] Test:  [130/345]  eta: 0:00:18  loss: 0.7729 (0.7744)  time: 0.0861  data: 0.0001  max mem: 10917
[14:38:17.594290] Test:  [140/345]  eta: 0:00:17  loss: 0.7729 (0.7741)  time: 0.0864  data: 0.0001  max mem: 10917
[14:38:18.463750] Test:  [150/345]  eta: 0:00:16  loss: 0.7654 (0.7736)  time: 0.0867  data: 0.0001  max mem: 10917
[14:38:19.337073] Test:  [160/345]  eta: 0:00:15  loss: 0.7641 (0.7731)  time: 0.0871  data: 0.0001  max mem: 10917
[14:38:20.214205] Test:  [170/345]  eta: 0:00:14  loss: 0.7638 (0.7729)  time: 0.0875  data: 0.0001  max mem: 10917
[14:38:21.093707] Test:  [180/345]  eta: 0:00:14  loss: 0.7657 (0.7724)  time: 0.0878  data: 0.0001  max mem: 10917
[14:38:21.977090] Test:  [190/345]  eta: 0:00:13  loss: 0.7750 (0.7731)  time: 0.0881  data: 0.0001  max mem: 10917
[14:38:22.864309] Test:  [200/345]  eta: 0:00:12  loss: 0.7801 (0.7732)  time: 0.0885  data: 0.0001  max mem: 10917
[14:38:23.754904] Test:  [210/345]  eta: 0:00:11  loss: 0.7705 (0.7729)  time: 0.0888  data: 0.0001  max mem: 10917
[14:38:24.648507] Test:  [220/345]  eta: 0:00:10  loss: 0.7705 (0.7731)  time: 0.0892  data: 0.0001  max mem: 10917
[14:38:25.547185] Test:  [230/345]  eta: 0:00:09  loss: 0.7705 (0.7729)  time: 0.0896  data: 0.0001  max mem: 10917
[14:38:26.449127] Test:  [240/345]  eta: 0:00:09  loss: 0.7611 (0.7731)  time: 0.0900  data: 0.0001  max mem: 10917
[14:38:27.353719] Test:  [250/345]  eta: 0:00:08  loss: 0.7741 (0.7735)  time: 0.0903  data: 0.0001  max mem: 10917
[14:38:28.262216] Test:  [260/345]  eta: 0:00:07  loss: 0.7734 (0.7736)  time: 0.0906  data: 0.0001  max mem: 10917
[14:38:29.174277] Test:  [270/345]  eta: 0:00:06  loss: 0.7811 (0.7740)  time: 0.0910  data: 0.0001  max mem: 10917
[14:38:30.090147] Test:  [280/345]  eta: 0:00:05  loss: 0.7834 (0.7742)  time: 0.0913  data: 0.0001  max mem: 10917
[14:38:31.009580] Test:  [290/345]  eta: 0:00:04  loss: 0.7630 (0.7738)  time: 0.0917  data: 0.0001  max mem: 10917
[14:38:31.931457] Test:  [300/345]  eta: 0:00:03  loss: 0.7630 (0.7739)  time: 0.0920  data: 0.0001  max mem: 10917
[14:38:32.855866] Test:  [310/345]  eta: 0:00:03  loss: 0.7704 (0.7738)  time: 0.0923  data: 0.0001  max mem: 10917
[14:38:33.785240] Test:  [320/345]  eta: 0:00:02  loss: 0.7704 (0.7737)  time: 0.0926  data: 0.0001  max mem: 10917
[14:38:34.718195] Test:  [330/345]  eta: 0:00:01  loss: 0.7694 (0.7738)  time: 0.0931  data: 0.0001  max mem: 10917
[14:38:35.654371] Test:  [340/345]  eta: 0:00:00  loss: 0.7695 (0.7738)  time: 0.0934  data: 0.0001  max mem: 10917
[14:38:36.029912] Test:  [344/345]  eta: 0:00:00  loss: 0.7695 (0.7737)  time: 0.0935  data: 0.0001  max mem: 10917
[14:38:36.087187] Test: Total time: 0:00:30 (0.0885 s / it)
[14:38:47.231676] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8719 (0.8719)  time: 0.2246  data: 0.1445  max mem: 10917
[14:38:48.051118] Test:  [10/57]  eta: 0:00:04  loss: 0.8950 (0.9014)  time: 0.0948  data: 0.0139  max mem: 10917
[14:38:48.868698] Test:  [20/57]  eta: 0:00:03  loss: 0.8950 (0.8936)  time: 0.0818  data: 0.0005  max mem: 10917
[14:38:49.689705] Test:  [30/57]  eta: 0:00:02  loss: 0.7835 (0.8535)  time: 0.0819  data: 0.0001  max mem: 10917
[14:38:50.514125] Test:  [40/57]  eta: 0:00:01  loss: 0.7803 (0.8327)  time: 0.0822  data: 0.0001  max mem: 10917
[14:38:51.343015] Test:  [50/57]  eta: 0:00:00  loss: 0.7715 (0.8251)  time: 0.0826  data: 0.0001  max mem: 10917
[14:38:51.793589] Test:  [56/57]  eta: 0:00:00  loss: 0.7964 (0.8300)  time: 0.0804  data: 0.0001  max mem: 10917
[14:38:51.850499] Test: Total time: 0:00:04 (0.0850 s / it)
[14:38:53.829527] Dice score of the network on the train images: 0.786259, val images: 0.797240
[14:38:53.832599] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:38:54.231775] Epoch: [20]  [  0/345]  eta: 0:02:17  lr: 0.000125  loss: 0.7713 (0.7713)  time: 0.3983  data: 0.1459  max mem: 10917
[14:38:59.232660] Epoch: [20]  [ 20/345]  eta: 0:01:23  lr: 0.000125  loss: 0.8032 (0.7996)  time: 0.2500  data: 0.0001  max mem: 10917
[14:39:04.233394] Epoch: [20]  [ 40/345]  eta: 0:01:17  lr: 0.000125  loss: 0.8018 (0.8017)  time: 0.2500  data: 0.0001  max mem: 10917
[14:39:09.221316] Epoch: [20]  [ 60/345]  eta: 0:01:11  lr: 0.000125  loss: 0.8009 (0.8020)  time: 0.2494  data: 0.0001  max mem: 10917
[14:39:14.220463] Epoch: [20]  [ 80/345]  eta: 0:01:06  lr: 0.000125  loss: 0.8367 (0.8108)  time: 0.2499  data: 0.0001  max mem: 10917
[14:39:19.219311] Epoch: [20]  [100/345]  eta: 0:01:01  lr: 0.000125  loss: 0.8155 (0.8129)  time: 0.2499  data: 0.0000  max mem: 10917
[14:39:24.223757] Epoch: [20]  [120/345]  eta: 0:00:56  lr: 0.000125  loss: 0.8065 (0.8117)  time: 0.2502  data: 0.0000  max mem: 10917
[14:39:29.235365] Epoch: [20]  [140/345]  eta: 0:00:51  lr: 0.000125  loss: 0.8026 (0.8106)  time: 0.2505  data: 0.0001  max mem: 10917
[14:39:34.259776] Epoch: [20]  [160/345]  eta: 0:00:46  lr: 0.000125  loss: 0.8001 (0.8095)  time: 0.2512  data: 0.0001  max mem: 10917
[14:39:39.290804] Epoch: [20]  [180/345]  eta: 0:00:41  lr: 0.000125  loss: 0.8011 (0.8088)  time: 0.2515  data: 0.0001  max mem: 10917
[14:39:44.323186] Epoch: [20]  [200/345]  eta: 0:00:36  lr: 0.000125  loss: 0.8150 (0.8100)  time: 0.2516  data: 0.0001  max mem: 10917
[14:39:49.355588] Epoch: [20]  [220/345]  eta: 0:00:31  lr: 0.000125  loss: 0.8051 (0.8095)  time: 0.2516  data: 0.0001  max mem: 10917
[14:39:54.379765] Epoch: [20]  [240/345]  eta: 0:00:26  lr: 0.000125  loss: 0.7997 (0.8089)  time: 0.2512  data: 0.0001  max mem: 10917
[14:39:59.402946] Epoch: [20]  [260/345]  eta: 0:00:21  lr: 0.000125  loss: 0.7892 (0.8081)  time: 0.2511  data: 0.0001  max mem: 10917
[14:40:04.430858] Epoch: [20]  [280/345]  eta: 0:00:16  lr: 0.000125  loss: 0.8079 (0.8080)  time: 0.2513  data: 0.0001  max mem: 10917
[14:40:09.457014] Epoch: [20]  [300/345]  eta: 0:00:11  lr: 0.000125  loss: 0.7954 (0.8072)  time: 0.2513  data: 0.0001  max mem: 10917
[14:40:14.488663] Epoch: [20]  [320/345]  eta: 0:00:06  lr: 0.000125  loss: 0.7969 (0.8067)  time: 0.2515  data: 0.0001  max mem: 10917
[14:40:19.520162] Epoch: [20]  [340/345]  eta: 0:00:01  lr: 0.000125  loss: 0.8012 (0.8064)  time: 0.2515  data: 0.0001  max mem: 10917
[14:40:20.526864] Epoch: [20]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.8018 (0.8065)  time: 0.2515  data: 0.0001  max mem: 10917
[14:40:20.585350] Epoch: [20] Total time: 0:01:26 (0.2515 s / it)
[14:40:20.585851] Averaged stats: lr: 0.000125  loss: 0.8018 (0.8065)
[14:40:20.832921] Test:  [  0/345]  eta: 0:01:24  loss: 0.7535 (0.7535)  time: 0.2442  data: 0.1644  max mem: 10917
[14:40:21.714521] Test:  [ 10/345]  eta: 0:00:34  loss: 0.7587 (0.7624)  time: 0.1023  data: 0.0208  max mem: 10917
[14:40:22.563012] Test:  [ 20/345]  eta: 0:00:30  loss: 0.7587 (0.7629)  time: 0.0864  data: 0.0046  max mem: 10917
[14:40:23.422106] Test:  [ 30/345]  eta: 0:00:28  loss: 0.7739 (0.7690)  time: 0.0853  data: 0.0031  max mem: 10917
[14:40:24.252321] Test:  [ 40/345]  eta: 0:00:27  loss: 0.7736 (0.7695)  time: 0.0844  data: 0.0018  max mem: 10917
[14:40:25.086137] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7726 (0.7700)  time: 0.0831  data: 0.0001  max mem: 10917
[14:40:25.924050] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7636 (0.7681)  time: 0.0835  data: 0.0001  max mem: 10917
[14:40:26.765545] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7615 (0.7677)  time: 0.0839  data: 0.0001  max mem: 10917
[14:40:27.610363] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7634 (0.7675)  time: 0.0843  data: 0.0001  max mem: 10917
[14:40:28.458815] Test:  [ 90/345]  eta: 0:00:22  loss: 0.7607 (0.7670)  time: 0.0846  data: 0.0001  max mem: 10917
[14:40:29.311184] Test:  [100/345]  eta: 0:00:21  loss: 0.7566 (0.7662)  time: 0.0850  data: 0.0001  max mem: 10917
[14:40:30.166443] Test:  [110/345]  eta: 0:00:20  loss: 0.7594 (0.7662)  time: 0.0853  data: 0.0001  max mem: 10917
[14:40:31.025660] Test:  [120/345]  eta: 0:00:19  loss: 0.7638 (0.7663)  time: 0.0857  data: 0.0001  max mem: 10917
[14:40:31.888509] Test:  [130/345]  eta: 0:00:18  loss: 0.7663 (0.7664)  time: 0.0861  data: 0.0001  max mem: 10917
[14:40:32.755262] Test:  [140/345]  eta: 0:00:17  loss: 0.7659 (0.7666)  time: 0.0864  data: 0.0001  max mem: 10917
[14:40:33.624300] Test:  [150/345]  eta: 0:00:16  loss: 0.7635 (0.7664)  time: 0.0867  data: 0.0001  max mem: 10917
[14:40:34.497372] Test:  [160/345]  eta: 0:00:15  loss: 0.7599 (0.7659)  time: 0.0871  data: 0.0001  max mem: 10917
[14:40:35.374048] Test:  [170/345]  eta: 0:00:15  loss: 0.7617 (0.7662)  time: 0.0874  data: 0.0001  max mem: 10917
[14:40:36.254761] Test:  [180/345]  eta: 0:00:14  loss: 0.7649 (0.7663)  time: 0.0878  data: 0.0001  max mem: 10917
[14:40:37.137231] Test:  [190/345]  eta: 0:00:13  loss: 0.7570 (0.7660)  time: 0.0881  data: 0.0001  max mem: 10917
[14:40:38.023943] Test:  [200/345]  eta: 0:00:12  loss: 0.7596 (0.7661)  time: 0.0884  data: 0.0001  max mem: 10917
[14:40:38.915437] Test:  [210/345]  eta: 0:00:11  loss: 0.7673 (0.7660)  time: 0.0889  data: 0.0001  max mem: 10917
[14:40:39.809816] Test:  [220/345]  eta: 0:00:10  loss: 0.7613 (0.7657)  time: 0.0892  data: 0.0001  max mem: 10917
[14:40:40.706705] Test:  [230/345]  eta: 0:00:10  loss: 0.7597 (0.7657)  time: 0.0895  data: 0.0001  max mem: 10917
[14:40:41.607829] Test:  [240/345]  eta: 0:00:09  loss: 0.7597 (0.7654)  time: 0.0899  data: 0.0001  max mem: 10917
[14:40:42.511376] Test:  [250/345]  eta: 0:00:08  loss: 0.7596 (0.7654)  time: 0.0902  data: 0.0001  max mem: 10917
[14:40:43.419902] Test:  [260/345]  eta: 0:00:07  loss: 0.7665 (0.7655)  time: 0.0906  data: 0.0001  max mem: 10917
[14:40:44.330993] Test:  [270/345]  eta: 0:00:06  loss: 0.7675 (0.7656)  time: 0.0909  data: 0.0001  max mem: 10917
[14:40:45.245587] Test:  [280/345]  eta: 0:00:05  loss: 0.7675 (0.7655)  time: 0.0912  data: 0.0001  max mem: 10917
[14:40:46.164335] Test:  [290/345]  eta: 0:00:04  loss: 0.7654 (0.7654)  time: 0.0916  data: 0.0001  max mem: 10917
[14:40:47.085715] Test:  [300/345]  eta: 0:00:03  loss: 0.7557 (0.7653)  time: 0.0920  data: 0.0001  max mem: 10917
[14:40:48.011476] Test:  [310/345]  eta: 0:00:03  loss: 0.7637 (0.7656)  time: 0.0923  data: 0.0001  max mem: 10917
[14:40:48.940792] Test:  [320/345]  eta: 0:00:02  loss: 0.7665 (0.7655)  time: 0.0927  data: 0.0001  max mem: 10917
[14:40:49.873662] Test:  [330/345]  eta: 0:00:01  loss: 0.7660 (0.7658)  time: 0.0931  data: 0.0001  max mem: 10917
[14:40:50.809897] Test:  [340/345]  eta: 0:00:00  loss: 0.7611 (0.7656)  time: 0.0934  data: 0.0001  max mem: 10917
[14:40:51.185755] Test:  [344/345]  eta: 0:00:00  loss: 0.7552 (0.7655)  time: 0.0936  data: 0.0001  max mem: 10917
[14:40:51.242469] Test: Total time: 0:00:30 (0.0889 s / it)
[14:41:02.345230] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9074 (0.9074)  time: 0.2265  data: 0.1468  max mem: 10917
[14:41:03.161804] Test:  [10/57]  eta: 0:00:04  loss: 0.9074 (0.9110)  time: 0.0947  data: 0.0136  max mem: 10917
[14:41:03.978895] Test:  [20/57]  eta: 0:00:03  loss: 0.9042 (0.8952)  time: 0.0816  data: 0.0002  max mem: 10917
[14:41:04.799056] Test:  [30/57]  eta: 0:00:02  loss: 0.7818 (0.8529)  time: 0.0818  data: 0.0001  max mem: 10917
[14:41:05.623778] Test:  [40/57]  eta: 0:00:01  loss: 0.7722 (0.8299)  time: 0.0822  data: 0.0001  max mem: 10917
[14:41:06.451001] Test:  [50/57]  eta: 0:00:00  loss: 0.7632 (0.8227)  time: 0.0826  data: 0.0001  max mem: 10917
[14:41:06.900717] Test:  [56/57]  eta: 0:00:00  loss: 0.7823 (0.8268)  time: 0.0803  data: 0.0001  max mem: 10917
[14:41:06.956728] Test: Total time: 0:00:04 (0.0849 s / it)
[14:41:08.937364] Dice score of the network on the train images: 0.783377, val images: 0.800029
[14:41:08.940907] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:41:09.345781] Epoch: [21]  [  0/345]  eta: 0:02:19  lr: 0.000125  loss: 0.8255 (0.8255)  time: 0.4037  data: 0.1527  max mem: 10917
[14:41:14.325967] Epoch: [21]  [ 20/345]  eta: 0:01:23  lr: 0.000125  loss: 0.7891 (0.7947)  time: 0.2490  data: 0.0001  max mem: 10917
[14:41:19.313279] Epoch: [21]  [ 40/345]  eta: 0:01:17  lr: 0.000125  loss: 0.7851 (0.7916)  time: 0.2493  data: 0.0001  max mem: 10917
[14:41:24.301841] Epoch: [21]  [ 60/345]  eta: 0:01:11  lr: 0.000125  loss: 0.7905 (0.7917)  time: 0.2494  data: 0.0001  max mem: 10917
[14:41:29.297372] Epoch: [21]  [ 80/345]  eta: 0:01:06  lr: 0.000124  loss: 0.7862 (0.7907)  time: 0.2497  data: 0.0001  max mem: 10917
[14:41:34.295847] Epoch: [21]  [100/345]  eta: 0:01:01  lr: 0.000124  loss: 0.7867 (0.7901)  time: 0.2499  data: 0.0001  max mem: 10917
[14:41:39.300526] Epoch: [21]  [120/345]  eta: 0:00:56  lr: 0.000124  loss: 0.7970 (0.7905)  time: 0.2502  data: 0.0001  max mem: 10917
[14:41:44.322175] Epoch: [21]  [140/345]  eta: 0:00:51  lr: 0.000124  loss: 0.7841 (0.7904)  time: 0.2510  data: 0.0001  max mem: 10917
[14:41:49.350393] Epoch: [21]  [160/345]  eta: 0:00:46  lr: 0.000124  loss: 0.7840 (0.7896)  time: 0.2514  data: 0.0001  max mem: 10917
[14:41:54.379030] Epoch: [21]  [180/345]  eta: 0:00:41  lr: 0.000124  loss: 0.7959 (0.7905)  time: 0.2514  data: 0.0001  max mem: 10917
[14:41:59.403834] Epoch: [21]  [200/345]  eta: 0:00:36  lr: 0.000124  loss: 0.7890 (0.7904)  time: 0.2512  data: 0.0000  max mem: 10917
[14:42:04.438854] Epoch: [21]  [220/345]  eta: 0:00:31  lr: 0.000124  loss: 0.7931 (0.7903)  time: 0.2517  data: 0.0001  max mem: 10917
[14:42:09.473595] Epoch: [21]  [240/345]  eta: 0:00:26  lr: 0.000124  loss: 0.7883 (0.7904)  time: 0.2517  data: 0.0001  max mem: 10917
[14:42:14.508489] Epoch: [21]  [260/345]  eta: 0:00:21  lr: 0.000124  loss: 0.7959 (0.7912)  time: 0.2517  data: 0.0001  max mem: 10917
[14:42:19.549695] Epoch: [21]  [280/345]  eta: 0:00:16  lr: 0.000124  loss: 0.7833 (0.7909)  time: 0.2520  data: 0.0001  max mem: 10917
[14:42:24.590092] Epoch: [21]  [300/345]  eta: 0:00:11  lr: 0.000124  loss: 0.8007 (0.7917)  time: 0.2520  data: 0.0000  max mem: 10917
[14:42:29.636746] Epoch: [21]  [320/345]  eta: 0:00:06  lr: 0.000124  loss: 0.7880 (0.7916)  time: 0.2523  data: 0.0001  max mem: 10917
[14:42:34.683957] Epoch: [21]  [340/345]  eta: 0:00:01  lr: 0.000124  loss: 0.7876 (0.7918)  time: 0.2523  data: 0.0001  max mem: 10917
[14:42:35.693692] Epoch: [21]  [344/345]  eta: 0:00:00  lr: 0.000124  loss: 0.7945 (0.7919)  time: 0.2523  data: 0.0001  max mem: 10917
[14:42:35.750810] Epoch: [21] Total time: 0:01:26 (0.2516 s / it)
[14:42:35.751150] Averaged stats: lr: 0.000124  loss: 0.7945 (0.7919)
[14:42:35.989755] Test:  [  0/345]  eta: 0:01:21  loss: 0.7982 (0.7982)  time: 0.2349  data: 0.1551  max mem: 10917
[14:42:36.809665] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7548 (0.7608)  time: 0.0958  data: 0.0142  max mem: 10917
[14:42:37.633563] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7646 (0.7641)  time: 0.0821  data: 0.0001  max mem: 10917
[14:42:38.460179] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7655 (0.7630)  time: 0.0825  data: 0.0001  max mem: 10917
[14:42:39.291142] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7626 (0.7634)  time: 0.0828  data: 0.0001  max mem: 10917
[14:42:40.125240] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7598 (0.7632)  time: 0.0832  data: 0.0001  max mem: 10917
[14:42:40.963917] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7564 (0.7622)  time: 0.0836  data: 0.0001  max mem: 10917
[14:42:41.805522] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7637 (0.7628)  time: 0.0840  data: 0.0001  max mem: 10917
[14:42:42.651098] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7623 (0.7627)  time: 0.0843  data: 0.0001  max mem: 10917
[14:42:43.499189] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7618 (0.7629)  time: 0.0846  data: 0.0001  max mem: 10917
[14:42:44.351917] Test:  [100/345]  eta: 0:00:20  loss: 0.7618 (0.7631)  time: 0.0850  data: 0.0001  max mem: 10917
[14:42:45.206993] Test:  [110/345]  eta: 0:00:19  loss: 0.7545 (0.7625)  time: 0.0853  data: 0.0001  max mem: 10917
[14:42:46.066013] Test:  [120/345]  eta: 0:00:19  loss: 0.7540 (0.7630)  time: 0.0857  data: 0.0001  max mem: 10917
[14:42:46.928761] Test:  [130/345]  eta: 0:00:18  loss: 0.7560 (0.7626)  time: 0.0860  data: 0.0001  max mem: 10917
[14:42:47.795452] Test:  [140/345]  eta: 0:00:17  loss: 0.7662 (0.7628)  time: 0.0864  data: 0.0001  max mem: 10917
[14:42:48.665281] Test:  [150/345]  eta: 0:00:16  loss: 0.7586 (0.7624)  time: 0.0868  data: 0.0001  max mem: 10917
[14:42:49.538346] Test:  [160/345]  eta: 0:00:15  loss: 0.7586 (0.7628)  time: 0.0871  data: 0.0001  max mem: 10917
[14:42:50.416535] Test:  [170/345]  eta: 0:00:14  loss: 0.7603 (0.7626)  time: 0.0875  data: 0.0001  max mem: 10917
[14:42:51.297524] Test:  [180/345]  eta: 0:00:14  loss: 0.7548 (0.7627)  time: 0.0879  data: 0.0001  max mem: 10917
[14:42:52.180026] Test:  [190/345]  eta: 0:00:13  loss: 0.7631 (0.7634)  time: 0.0881  data: 0.0001  max mem: 10917
[14:42:53.067734] Test:  [200/345]  eta: 0:00:12  loss: 0.7692 (0.7637)  time: 0.0885  data: 0.0001  max mem: 10917
[14:42:53.959704] Test:  [210/345]  eta: 0:00:11  loss: 0.7626 (0.7635)  time: 0.0889  data: 0.0001  max mem: 10917
[14:42:54.853944] Test:  [220/345]  eta: 0:00:10  loss: 0.7560 (0.7630)  time: 0.0893  data: 0.0001  max mem: 10917
[14:42:55.752252] Test:  [230/345]  eta: 0:00:09  loss: 0.7599 (0.7631)  time: 0.0896  data: 0.0001  max mem: 10917
[14:42:56.653748] Test:  [240/345]  eta: 0:00:09  loss: 0.7665 (0.7634)  time: 0.0899  data: 0.0001  max mem: 10917
[14:42:57.557984] Test:  [250/345]  eta: 0:00:08  loss: 0.7605 (0.7630)  time: 0.0902  data: 0.0001  max mem: 10917
[14:42:58.467557] Test:  [260/345]  eta: 0:00:07  loss: 0.7593 (0.7631)  time: 0.0906  data: 0.0001  max mem: 10917
[14:42:59.379946] Test:  [270/345]  eta: 0:00:06  loss: 0.7600 (0.7632)  time: 0.0911  data: 0.0001  max mem: 10917
[14:43:00.295478] Test:  [280/345]  eta: 0:00:05  loss: 0.7639 (0.7632)  time: 0.0913  data: 0.0001  max mem: 10917
[14:43:01.215240] Test:  [290/345]  eta: 0:00:04  loss: 0.7659 (0.7636)  time: 0.0917  data: 0.0001  max mem: 10917
[14:43:02.137352] Test:  [300/345]  eta: 0:00:03  loss: 0.7667 (0.7636)  time: 0.0920  data: 0.0001  max mem: 10917
[14:43:03.063467] Test:  [310/345]  eta: 0:00:03  loss: 0.7633 (0.7639)  time: 0.0924  data: 0.0001  max mem: 10917
[14:43:03.992743] Test:  [320/345]  eta: 0:00:02  loss: 0.7728 (0.7642)  time: 0.0927  data: 0.0001  max mem: 10917
[14:43:04.924608] Test:  [330/345]  eta: 0:00:01  loss: 0.7603 (0.7640)  time: 0.0930  data: 0.0001  max mem: 10917
[14:43:05.861358] Test:  [340/345]  eta: 0:00:00  loss: 0.7577 (0.7639)  time: 0.0934  data: 0.0001  max mem: 10917
[14:43:06.237488] Test:  [344/345]  eta: 0:00:00  loss: 0.7603 (0.7640)  time: 0.0936  data: 0.0001  max mem: 10917
[14:43:06.293850] Test: Total time: 0:00:30 (0.0885 s / it)
[14:43:17.539946] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9160 (0.9160)  time: 0.2226  data: 0.1426  max mem: 10917
[14:43:18.352958] Test:  [10/57]  eta: 0:00:04  loss: 0.9187 (0.9177)  time: 0.0941  data: 0.0130  max mem: 10917
[14:43:19.169339] Test:  [20/57]  eta: 0:00:03  loss: 0.9080 (0.9010)  time: 0.0814  data: 0.0001  max mem: 10917
[14:43:19.989838] Test:  [30/57]  eta: 0:00:02  loss: 0.7938 (0.8581)  time: 0.0818  data: 0.0001  max mem: 10917
[14:43:20.814382] Test:  [40/57]  eta: 0:00:01  loss: 0.7687 (0.8357)  time: 0.0822  data: 0.0001  max mem: 10917
[14:43:21.642258] Test:  [50/57]  eta: 0:00:00  loss: 0.7700 (0.8278)  time: 0.0826  data: 0.0001  max mem: 10917
[14:43:22.092098] Test:  [56/57]  eta: 0:00:00  loss: 0.7959 (0.8313)  time: 0.0804  data: 0.0001  max mem: 10917
[14:43:22.132908] Test: Total time: 0:00:04 (0.0845 s / it)
[14:43:24.040387] Dice score of the network on the train images: 0.783802, val images: 0.805431
[14:43:24.044277] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:43:24.441358] Epoch: [22]  [  0/345]  eta: 0:02:16  lr: 0.000124  loss: 0.7730 (0.7730)  time: 0.3960  data: 0.1443  max mem: 10917
[14:43:29.442080] Epoch: [22]  [ 20/345]  eta: 0:01:23  lr: 0.000124  loss: 0.7938 (0.7934)  time: 0.2500  data: 0.0001  max mem: 10917
[14:43:34.431069] Epoch: [22]  [ 40/345]  eta: 0:01:17  lr: 0.000123  loss: 0.7894 (0.7929)  time: 0.2494  data: 0.0000  max mem: 10917
[14:43:39.422802] Epoch: [22]  [ 60/345]  eta: 0:01:11  lr: 0.000123  loss: 0.7920 (0.7923)  time: 0.2495  data: 0.0000  max mem: 10917
[14:43:44.427296] Epoch: [22]  [ 80/345]  eta: 0:01:06  lr: 0.000123  loss: 0.7915 (0.7928)  time: 0.2502  data: 0.0000  max mem: 10917
[14:43:49.447120] Epoch: [22]  [100/345]  eta: 0:01:01  lr: 0.000123  loss: 0.7822 (0.7916)  time: 0.2509  data: 0.0000  max mem: 10917
[14:43:54.468004] Epoch: [22]  [120/345]  eta: 0:00:56  lr: 0.000123  loss: 0.7849 (0.7905)  time: 0.2510  data: 0.0001  max mem: 10917
[14:43:59.492891] Epoch: [22]  [140/345]  eta: 0:00:51  lr: 0.000123  loss: 0.8100 (0.7935)  time: 0.2512  data: 0.0000  max mem: 10917
[14:44:04.514295] Epoch: [22]  [160/345]  eta: 0:00:46  lr: 0.000123  loss: 0.7987 (0.7944)  time: 0.2510  data: 0.0000  max mem: 10917
[14:44:09.541129] Epoch: [22]  [180/345]  eta: 0:00:41  lr: 0.000123  loss: 0.8107 (0.7968)  time: 0.2513  data: 0.0000  max mem: 10917
[14:44:14.569819] Epoch: [22]  [200/345]  eta: 0:00:36  lr: 0.000123  loss: 0.8102 (0.7985)  time: 0.2514  data: 0.0000  max mem: 10917
[14:44:19.590778] Epoch: [22]  [220/345]  eta: 0:00:31  lr: 0.000123  loss: 0.8029 (0.7992)  time: 0.2510  data: 0.0001  max mem: 10917
[14:44:24.613339] Epoch: [22]  [240/345]  eta: 0:00:26  lr: 0.000123  loss: 0.8090 (0.8004)  time: 0.2511  data: 0.0001  max mem: 10917
[14:44:29.636144] Epoch: [22]  [260/345]  eta: 0:00:21  lr: 0.000122  loss: 0.8184 (0.8020)  time: 0.2511  data: 0.0000  max mem: 10917
[14:44:34.657948] Epoch: [22]  [280/345]  eta: 0:00:16  lr: 0.000122  loss: 0.7937 (0.8018)  time: 0.2510  data: 0.0000  max mem: 10917
[14:44:39.687754] Epoch: [22]  [300/345]  eta: 0:00:11  lr: 0.000122  loss: 0.7902 (0.8009)  time: 0.2514  data: 0.0001  max mem: 10917
[14:44:44.719391] Epoch: [22]  [320/345]  eta: 0:00:06  lr: 0.000122  loss: 0.7901 (0.8003)  time: 0.2515  data: 0.0001  max mem: 10917
[14:44:49.747510] Epoch: [22]  [340/345]  eta: 0:00:01  lr: 0.000122  loss: 0.7853 (0.7996)  time: 0.2514  data: 0.0001  max mem: 10917
[14:44:50.754446] Epoch: [22]  [344/345]  eta: 0:00:00  lr: 0.000122  loss: 0.7866 (0.7995)  time: 0.2514  data: 0.0001  max mem: 10917
[14:44:50.812636] Epoch: [22] Total time: 0:01:26 (0.2515 s / it)
[14:44:50.813084] Averaged stats: lr: 0.000122  loss: 0.7866 (0.7995)
[14:44:51.055682] Test:  [  0/345]  eta: 0:01:22  loss: 0.7477 (0.7477)  time: 0.2397  data: 0.1593  max mem: 10917
[14:44:51.904291] Test:  [ 10/345]  eta: 0:00:33  loss: 0.7537 (0.7599)  time: 0.0989  data: 0.0173  max mem: 10917
[14:44:52.728531] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7575 (0.7649)  time: 0.0836  data: 0.0016  max mem: 10917
[14:44:53.554962] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7621 (0.7627)  time: 0.0825  data: 0.0001  max mem: 10917
[14:44:54.386101] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7586 (0.7617)  time: 0.0828  data: 0.0001  max mem: 10917
[14:44:55.219978] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7562 (0.7620)  time: 0.0832  data: 0.0001  max mem: 10917
[14:44:56.058460] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7626 (0.7629)  time: 0.0836  data: 0.0001  max mem: 10917
[14:44:56.899361] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7648 (0.7623)  time: 0.0839  data: 0.0001  max mem: 10917
[14:44:57.744755] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7593 (0.7632)  time: 0.0843  data: 0.0001  max mem: 10917
[14:44:58.593086] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7619 (0.7624)  time: 0.0846  data: 0.0001  max mem: 10917
[14:44:59.444627] Test:  [100/345]  eta: 0:00:20  loss: 0.7639 (0.7628)  time: 0.0849  data: 0.0001  max mem: 10917
[14:45:00.299397] Test:  [110/345]  eta: 0:00:20  loss: 0.7627 (0.7627)  time: 0.0853  data: 0.0001  max mem: 10917
[14:45:01.159050] Test:  [120/345]  eta: 0:00:19  loss: 0.7523 (0.7620)  time: 0.0857  data: 0.0001  max mem: 10917
[14:45:02.021462] Test:  [130/345]  eta: 0:00:18  loss: 0.7523 (0.7621)  time: 0.0861  data: 0.0001  max mem: 10917
[14:45:02.887515] Test:  [140/345]  eta: 0:00:17  loss: 0.7580 (0.7618)  time: 0.0864  data: 0.0001  max mem: 10917
[14:45:03.756832] Test:  [150/345]  eta: 0:00:16  loss: 0.7629 (0.7621)  time: 0.0867  data: 0.0001  max mem: 10917
[14:45:04.630625] Test:  [160/345]  eta: 0:00:15  loss: 0.7644 (0.7620)  time: 0.0871  data: 0.0001  max mem: 10917
[14:45:05.506619] Test:  [170/345]  eta: 0:00:15  loss: 0.7533 (0.7614)  time: 0.0874  data: 0.0001  max mem: 10917
[14:45:06.387645] Test:  [180/345]  eta: 0:00:14  loss: 0.7588 (0.7614)  time: 0.0878  data: 0.0001  max mem: 10917
[14:45:07.271760] Test:  [190/345]  eta: 0:00:13  loss: 0.7601 (0.7613)  time: 0.0882  data: 0.0001  max mem: 10917
[14:45:08.159139] Test:  [200/345]  eta: 0:00:12  loss: 0.7606 (0.7615)  time: 0.0885  data: 0.0001  max mem: 10917
[14:45:09.050419] Test:  [210/345]  eta: 0:00:11  loss: 0.7576 (0.7611)  time: 0.0889  data: 0.0001  max mem: 10917
[14:45:09.944336] Test:  [220/345]  eta: 0:00:10  loss: 0.7576 (0.7614)  time: 0.0892  data: 0.0001  max mem: 10917
[14:45:10.842499] Test:  [230/345]  eta: 0:00:09  loss: 0.7656 (0.7616)  time: 0.0895  data: 0.0001  max mem: 10917
[14:45:11.744523] Test:  [240/345]  eta: 0:00:09  loss: 0.7675 (0.7614)  time: 0.0900  data: 0.0001  max mem: 10917
[14:45:12.649810] Test:  [250/345]  eta: 0:00:08  loss: 0.7649 (0.7618)  time: 0.0903  data: 0.0001  max mem: 10917
[14:45:13.558423] Test:  [260/345]  eta: 0:00:07  loss: 0.7583 (0.7616)  time: 0.0906  data: 0.0001  max mem: 10917
[14:45:14.470147] Test:  [270/345]  eta: 0:00:06  loss: 0.7547 (0.7619)  time: 0.0910  data: 0.0001  max mem: 10917
[14:45:15.384666] Test:  [280/345]  eta: 0:00:05  loss: 0.7580 (0.7619)  time: 0.0913  data: 0.0001  max mem: 10917
[14:45:16.302872] Test:  [290/345]  eta: 0:00:04  loss: 0.7516 (0.7615)  time: 0.0916  data: 0.0001  max mem: 10917
[14:45:17.225301] Test:  [300/345]  eta: 0:00:03  loss: 0.7513 (0.7613)  time: 0.0920  data: 0.0001  max mem: 10917
[14:45:18.151567] Test:  [310/345]  eta: 0:00:03  loss: 0.7579 (0.7617)  time: 0.0924  data: 0.0001  max mem: 10917
[14:45:19.081079] Test:  [320/345]  eta: 0:00:02  loss: 0.7579 (0.7617)  time: 0.0927  data: 0.0001  max mem: 10917
[14:45:20.014280] Test:  [330/345]  eta: 0:00:01  loss: 0.7534 (0.7616)  time: 0.0931  data: 0.0001  max mem: 10917
[14:45:20.950794] Test:  [340/345]  eta: 0:00:00  loss: 0.7558 (0.7616)  time: 0.0934  data: 0.0001  max mem: 10917
[14:45:21.327085] Test:  [344/345]  eta: 0:00:00  loss: 0.7622 (0.7617)  time: 0.0936  data: 0.0001  max mem: 10917
[14:45:21.382804] Test: Total time: 0:00:30 (0.0886 s / it)
[14:45:32.522083] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9128 (0.9128)  time: 0.2225  data: 0.1426  max mem: 10917
[14:45:33.340762] Test:  [10/57]  eta: 0:00:04  loss: 0.9128 (0.9182)  time: 0.0946  data: 0.0137  max mem: 10917
[14:45:34.157555] Test:  [20/57]  eta: 0:00:03  loss: 0.9001 (0.8954)  time: 0.0817  data: 0.0004  max mem: 10917
[14:45:34.978277] Test:  [30/57]  eta: 0:00:02  loss: 0.7893 (0.8546)  time: 0.0818  data: 0.0001  max mem: 10917
[14:45:35.801696] Test:  [40/57]  eta: 0:00:01  loss: 0.7672 (0.8327)  time: 0.0822  data: 0.0001  max mem: 10917
[14:45:36.630572] Test:  [50/57]  eta: 0:00:00  loss: 0.7564 (0.8249)  time: 0.0826  data: 0.0001  max mem: 10917
[14:45:37.080838] Test:  [56/57]  eta: 0:00:00  loss: 0.7869 (0.8295)  time: 0.0804  data: 0.0001  max mem: 10917
[14:45:37.121370] Test: Total time: 0:00:04 (0.0846 s / it)
[14:45:39.094367] Dice score of the network on the train images: 0.797769, val images: 0.805274
[14:45:39.098432] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:45:39.495193] Epoch: [23]  [  0/345]  eta: 0:02:16  lr: 0.000122  loss: 0.7842 (0.7842)  time: 0.3957  data: 0.1434  max mem: 10917
[14:45:44.497127] Epoch: [23]  [ 20/345]  eta: 0:01:23  lr: 0.000122  loss: 0.7949 (0.7920)  time: 0.2500  data: 0.0000  max mem: 10917
[14:45:49.501505] Epoch: [23]  [ 40/345]  eta: 0:01:17  lr: 0.000122  loss: 0.7846 (0.7902)  time: 0.2502  data: 0.0001  max mem: 10917
[14:45:54.509619] Epoch: [23]  [ 60/345]  eta: 0:01:11  lr: 0.000122  loss: 0.7855 (0.7899)  time: 0.2504  data: 0.0000  max mem: 10917
[14:45:59.521885] Epoch: [23]  [ 80/345]  eta: 0:01:06  lr: 0.000121  loss: 0.7828 (0.7889)  time: 0.2506  data: 0.0000  max mem: 10917
[14:46:04.542001] Epoch: [23]  [100/345]  eta: 0:01:01  lr: 0.000121  loss: 0.7939 (0.7889)  time: 0.2510  data: 0.0000  max mem: 10917
[14:46:09.557589] Epoch: [23]  [120/345]  eta: 0:00:56  lr: 0.000121  loss: 0.7827 (0.7881)  time: 0.2507  data: 0.0001  max mem: 10917
[14:46:14.570347] Epoch: [23]  [140/345]  eta: 0:00:51  lr: 0.000121  loss: 0.7773 (0.7871)  time: 0.2506  data: 0.0001  max mem: 10917
[14:46:19.661953] Epoch: [23]  [160/345]  eta: 0:00:46  lr: 0.000121  loss: 0.7796 (0.7863)  time: 0.2545  data: 0.0001  max mem: 10917
[14:46:24.677535] Epoch: [23]  [180/345]  eta: 0:00:41  lr: 0.000121  loss: 0.7728 (0.7850)  time: 0.2507  data: 0.0001  max mem: 10917
[14:46:29.683748] Epoch: [23]  [200/345]  eta: 0:00:36  lr: 0.000121  loss: 0.7818 (0.7850)  time: 0.2503  data: 0.0000  max mem: 10917
[14:46:34.698667] Epoch: [23]  [220/345]  eta: 0:00:31  lr: 0.000121  loss: 0.7830 (0.7848)  time: 0.2507  data: 0.0001  max mem: 10917
[14:46:39.711679] Epoch: [23]  [240/345]  eta: 0:00:26  lr: 0.000120  loss: 0.7826 (0.7848)  time: 0.2506  data: 0.0000  max mem: 10917
[14:46:44.739681] Epoch: [23]  [260/345]  eta: 0:00:21  lr: 0.000120  loss: 0.7815 (0.7850)  time: 0.2514  data: 0.0000  max mem: 10917
[14:46:49.771685] Epoch: [23]  [280/345]  eta: 0:00:16  lr: 0.000120  loss: 0.7880 (0.7851)  time: 0.2516  data: 0.0001  max mem: 10917
[14:46:54.796274] Epoch: [23]  [300/345]  eta: 0:00:11  lr: 0.000120  loss: 0.7854 (0.7848)  time: 0.2512  data: 0.0001  max mem: 10917
[14:46:59.820940] Epoch: [23]  [320/345]  eta: 0:00:06  lr: 0.000120  loss: 0.7792 (0.7843)  time: 0.2512  data: 0.0001  max mem: 10917
[14:47:04.847477] Epoch: [23]  [340/345]  eta: 0:00:01  lr: 0.000120  loss: 0.8004 (0.7854)  time: 0.2513  data: 0.0001  max mem: 10917
[14:47:05.855416] Epoch: [23]  [344/345]  eta: 0:00:00  lr: 0.000120  loss: 0.7976 (0.7855)  time: 0.2514  data: 0.0001  max mem: 10917
[14:47:05.918943] Epoch: [23] Total time: 0:01:26 (0.2517 s / it)
[14:47:05.919434] Averaged stats: lr: 0.000120  loss: 0.7976 (0.7855)
[14:47:06.157562] Test:  [  0/345]  eta: 0:01:21  loss: 0.7559 (0.7559)  time: 0.2350  data: 0.1550  max mem: 10917
[14:47:07.005735] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7597 (0.7657)  time: 0.0984  data: 0.0168  max mem: 10917
[14:47:07.840116] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7586 (0.7638)  time: 0.0841  data: 0.0021  max mem: 10917
[14:47:08.667711] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7506 (0.7610)  time: 0.0830  data: 0.0006  max mem: 10917
[14:47:09.498814] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7506 (0.7592)  time: 0.0829  data: 0.0001  max mem: 10917
[14:47:10.332607] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7564 (0.7593)  time: 0.0832  data: 0.0001  max mem: 10917
[14:47:11.170612] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7577 (0.7605)  time: 0.0835  data: 0.0001  max mem: 10917
[14:47:12.012395] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7647 (0.7603)  time: 0.0839  data: 0.0001  max mem: 10917
[14:47:12.857157] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7522 (0.7594)  time: 0.0843  data: 0.0001  max mem: 10917
[14:47:13.706302] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7505 (0.7600)  time: 0.0846  data: 0.0001  max mem: 10917
[14:47:14.558695] Test:  [100/345]  eta: 0:00:20  loss: 0.7540 (0.7591)  time: 0.0850  data: 0.0001  max mem: 10917
[14:47:15.414335] Test:  [110/345]  eta: 0:00:20  loss: 0.7540 (0.7592)  time: 0.0854  data: 0.0001  max mem: 10917
[14:47:16.273993] Test:  [120/345]  eta: 0:00:19  loss: 0.7509 (0.7601)  time: 0.0857  data: 0.0001  max mem: 10917
[14:47:17.136441] Test:  [130/345]  eta: 0:00:18  loss: 0.7592 (0.7599)  time: 0.0861  data: 0.0001  max mem: 10917
[14:47:18.003421] Test:  [140/345]  eta: 0:00:17  loss: 0.7610 (0.7606)  time: 0.0864  data: 0.0001  max mem: 10917
[14:47:18.872831] Test:  [150/345]  eta: 0:00:16  loss: 0.7653 (0.7609)  time: 0.0868  data: 0.0001  max mem: 10917
[14:47:19.746273] Test:  [160/345]  eta: 0:00:15  loss: 0.7561 (0.7602)  time: 0.0871  data: 0.0001  max mem: 10917
[14:47:20.622619] Test:  [170/345]  eta: 0:00:15  loss: 0.7522 (0.7599)  time: 0.0874  data: 0.0001  max mem: 10917
[14:47:21.503278] Test:  [180/345]  eta: 0:00:14  loss: 0.7574 (0.7596)  time: 0.0878  data: 0.0001  max mem: 10917
[14:47:22.386675] Test:  [190/345]  eta: 0:00:13  loss: 0.7496 (0.7589)  time: 0.0882  data: 0.0001  max mem: 10917
[14:47:23.274056] Test:  [200/345]  eta: 0:00:12  loss: 0.7489 (0.7586)  time: 0.0885  data: 0.0001  max mem: 10917
[14:47:24.166419] Test:  [210/345]  eta: 0:00:11  loss: 0.7619 (0.7588)  time: 0.0889  data: 0.0001  max mem: 10917
[14:47:25.060495] Test:  [220/345]  eta: 0:00:10  loss: 0.7637 (0.7588)  time: 0.0893  data: 0.0001  max mem: 10917
[14:47:25.959276] Test:  [230/345]  eta: 0:00:09  loss: 0.7569 (0.7589)  time: 0.0896  data: 0.0001  max mem: 10917
[14:47:26.861696] Test:  [240/345]  eta: 0:00:09  loss: 0.7598 (0.7592)  time: 0.0900  data: 0.0001  max mem: 10917
[14:47:27.767088] Test:  [250/345]  eta: 0:00:08  loss: 0.7572 (0.7590)  time: 0.0903  data: 0.0001  max mem: 10917
[14:47:28.675412] Test:  [260/345]  eta: 0:00:07  loss: 0.7511 (0.7588)  time: 0.0906  data: 0.0001  max mem: 10917
[14:47:29.587754] Test:  [270/345]  eta: 0:00:06  loss: 0.7577 (0.7588)  time: 0.0910  data: 0.0001  max mem: 10917
[14:47:30.503342] Test:  [280/345]  eta: 0:00:05  loss: 0.7616 (0.7586)  time: 0.0913  data: 0.0001  max mem: 10917
[14:47:31.422613] Test:  [290/345]  eta: 0:00:04  loss: 0.7529 (0.7585)  time: 0.0917  data: 0.0001  max mem: 10917
[14:47:32.345505] Test:  [300/345]  eta: 0:00:03  loss: 0.7598 (0.7585)  time: 0.0921  data: 0.0001  max mem: 10917
[14:47:33.271048] Test:  [310/345]  eta: 0:00:03  loss: 0.7569 (0.7582)  time: 0.0924  data: 0.0001  max mem: 10917
[14:47:34.201151] Test:  [320/345]  eta: 0:00:02  loss: 0.7523 (0.7582)  time: 0.0927  data: 0.0001  max mem: 10917
[14:47:35.134559] Test:  [330/345]  eta: 0:00:01  loss: 0.7596 (0.7584)  time: 0.0931  data: 0.0001  max mem: 10917
[14:47:36.071378] Test:  [340/345]  eta: 0:00:00  loss: 0.7629 (0.7585)  time: 0.0935  data: 0.0001  max mem: 10917
[14:47:36.448171] Test:  [344/345]  eta: 0:00:00  loss: 0.7611 (0.7584)  time: 0.0937  data: 0.0001  max mem: 10917
[14:47:36.505946] Test: Total time: 0:00:30 (0.0887 s / it)
[14:47:47.628485] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9102 (0.9102)  time: 0.2169  data: 0.1367  max mem: 10917
[14:47:48.440825] Test:  [10/57]  eta: 0:00:04  loss: 0.9102 (0.9104)  time: 0.0935  data: 0.0125  max mem: 10917
[14:47:49.258448] Test:  [20/57]  eta: 0:00:03  loss: 0.9051 (0.8998)  time: 0.0814  data: 0.0001  max mem: 10917
[14:47:50.079545] Test:  [30/57]  eta: 0:00:02  loss: 0.8108 (0.8628)  time: 0.0819  data: 0.0001  max mem: 10917
[14:47:50.904860] Test:  [40/57]  eta: 0:00:01  loss: 0.7935 (0.8434)  time: 0.0823  data: 0.0001  max mem: 10917
[14:47:51.732998] Test:  [50/57]  eta: 0:00:00  loss: 0.7890 (0.8358)  time: 0.0826  data: 0.0001  max mem: 10917
[14:47:52.182821] Test:  [56/57]  eta: 0:00:00  loss: 0.7937 (0.8396)  time: 0.0804  data: 0.0001  max mem: 10917
[14:47:52.241046] Test: Total time: 0:00:04 (0.0847 s / it)
[14:47:54.220181] Dice score of the network on the train images: 0.800559, val images: 0.789255
[14:47:54.223545] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:47:54.622390] Epoch: [24]  [  0/345]  eta: 0:02:17  lr: 0.000120  loss: 0.8173 (0.8173)  time: 0.3977  data: 0.1449  max mem: 10917
[14:47:59.623500] Epoch: [24]  [ 20/345]  eta: 0:01:23  lr: 0.000119  loss: 0.7926 (0.7926)  time: 0.2500  data: 0.0000  max mem: 10917
[14:48:04.623695] Epoch: [24]  [ 40/345]  eta: 0:01:17  lr: 0.000119  loss: 0.7800 (0.7897)  time: 0.2500  data: 0.0000  max mem: 10917
[14:48:09.641053] Epoch: [24]  [ 60/345]  eta: 0:01:12  lr: 0.000119  loss: 0.7910 (0.7894)  time: 0.2508  data: 0.0001  max mem: 10917
[14:48:14.676083] Epoch: [24]  [ 80/345]  eta: 0:01:06  lr: 0.000119  loss: 0.7877 (0.7902)  time: 0.2517  data: 0.0001  max mem: 10917
[14:48:19.712182] Epoch: [24]  [100/345]  eta: 0:01:01  lr: 0.000119  loss: 0.7826 (0.7890)  time: 0.2518  data: 0.0001  max mem: 10917
[14:48:24.751528] Epoch: [24]  [120/345]  eta: 0:00:56  lr: 0.000119  loss: 0.7779 (0.7868)  time: 0.2519  data: 0.0001  max mem: 10917
[14:48:29.798470] Epoch: [24]  [140/345]  eta: 0:00:51  lr: 0.000118  loss: 0.7757 (0.7858)  time: 0.2523  data: 0.0001  max mem: 10917
[14:48:34.841431] Epoch: [24]  [160/345]  eta: 0:00:46  lr: 0.000118  loss: 0.7975 (0.7881)  time: 0.2521  data: 0.0001  max mem: 10917
[14:48:39.886631] Epoch: [24]  [180/345]  eta: 0:00:41  lr: 0.000118  loss: 0.8143 (0.7907)  time: 0.2522  data: 0.0001  max mem: 10917
[14:48:44.930978] Epoch: [24]  [200/345]  eta: 0:00:36  lr: 0.000118  loss: 0.7944 (0.7910)  time: 0.2522  data: 0.0001  max mem: 10917
[14:48:49.983456] Epoch: [24]  [220/345]  eta: 0:00:31  lr: 0.000118  loss: 0.7848 (0.7911)  time: 0.2526  data: 0.0001  max mem: 10917
[14:48:55.026832] Epoch: [24]  [240/345]  eta: 0:00:26  lr: 0.000118  loss: 0.7878 (0.7906)  time: 0.2521  data: 0.0001  max mem: 10917
[14:49:00.063948] Epoch: [24]  [260/345]  eta: 0:00:21  lr: 0.000117  loss: 0.7880 (0.7909)  time: 0.2518  data: 0.0001  max mem: 10917
[14:49:05.100477] Epoch: [24]  [280/345]  eta: 0:00:16  lr: 0.000117  loss: 0.7898 (0.7910)  time: 0.2518  data: 0.0001  max mem: 10917
[14:49:10.140403] Epoch: [24]  [300/345]  eta: 0:00:11  lr: 0.000117  loss: 0.7832 (0.7908)  time: 0.2520  data: 0.0001  max mem: 10917
[14:49:15.181757] Epoch: [24]  [320/345]  eta: 0:00:06  lr: 0.000117  loss: 0.7876 (0.7906)  time: 0.2520  data: 0.0000  max mem: 10917
[14:49:20.219968] Epoch: [24]  [340/345]  eta: 0:00:01  lr: 0.000117  loss: 0.7844 (0.7905)  time: 0.2519  data: 0.0001  max mem: 10917
[14:49:21.229805] Epoch: [24]  [344/345]  eta: 0:00:00  lr: 0.000117  loss: 0.7844 (0.7906)  time: 0.2519  data: 0.0001  max mem: 10917
[14:49:21.269494] Epoch: [24] Total time: 0:01:27 (0.2523 s / it)
[14:49:21.269891] Averaged stats: lr: 0.000117  loss: 0.7844 (0.7906)
[14:49:21.505319] Test:  [  0/345]  eta: 0:01:19  loss: 0.7669 (0.7669)  time: 0.2314  data: 0.1511  max mem: 10917
[14:49:22.329390] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7669 (0.7599)  time: 0.0959  data: 0.0141  max mem: 10917
[14:49:23.153893] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7621 (0.7588)  time: 0.0824  data: 0.0002  max mem: 10917
[14:49:23.981553] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7544 (0.7550)  time: 0.0826  data: 0.0001  max mem: 10917
[14:49:24.813008] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7429 (0.7524)  time: 0.0829  data: 0.0001  max mem: 10917
[14:49:25.647004] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7429 (0.7514)  time: 0.0832  data: 0.0001  max mem: 10917
[14:49:26.484739] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7445 (0.7511)  time: 0.0835  data: 0.0001  max mem: 10917
[14:49:27.326686] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7497 (0.7513)  time: 0.0839  data: 0.0001  max mem: 10917
[14:49:28.170869] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7444 (0.7503)  time: 0.0843  data: 0.0001  max mem: 10917
[14:49:29.019707] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7382 (0.7491)  time: 0.0846  data: 0.0001  max mem: 10917
[14:49:29.871437] Test:  [100/345]  eta: 0:00:20  loss: 0.7383 (0.7493)  time: 0.0850  data: 0.0001  max mem: 10917
[14:49:30.726537] Test:  [110/345]  eta: 0:00:20  loss: 0.7463 (0.7483)  time: 0.0853  data: 0.0001  max mem: 10917
[14:49:31.585234] Test:  [120/345]  eta: 0:00:19  loss: 0.7389 (0.7477)  time: 0.0856  data: 0.0001  max mem: 10917
[14:49:32.447855] Test:  [130/345]  eta: 0:00:18  loss: 0.7489 (0.7479)  time: 0.0860  data: 0.0001  max mem: 10917
[14:49:33.313635] Test:  [140/345]  eta: 0:00:17  loss: 0.7566 (0.7486)  time: 0.0864  data: 0.0001  max mem: 10917
[14:49:34.183324] Test:  [150/345]  eta: 0:00:16  loss: 0.7529 (0.7488)  time: 0.0867  data: 0.0001  max mem: 10917
[14:49:35.055739] Test:  [160/345]  eta: 0:00:15  loss: 0.7488 (0.7487)  time: 0.0871  data: 0.0001  max mem: 10917
[14:49:35.931973] Test:  [170/345]  eta: 0:00:14  loss: 0.7482 (0.7491)  time: 0.0874  data: 0.0001  max mem: 10917
[14:49:36.812326] Test:  [180/345]  eta: 0:00:14  loss: 0.7497 (0.7489)  time: 0.0878  data: 0.0001  max mem: 10917
[14:49:37.695504] Test:  [190/345]  eta: 0:00:13  loss: 0.7497 (0.7493)  time: 0.0881  data: 0.0001  max mem: 10917
[14:49:38.582507] Test:  [200/345]  eta: 0:00:12  loss: 0.7515 (0.7494)  time: 0.0885  data: 0.0001  max mem: 10917
[14:49:39.473618] Test:  [210/345]  eta: 0:00:11  loss: 0.7384 (0.7488)  time: 0.0889  data: 0.0001  max mem: 10917
[14:49:40.367717] Test:  [220/345]  eta: 0:00:10  loss: 0.7384 (0.7489)  time: 0.0892  data: 0.0001  max mem: 10917
[14:49:41.265480] Test:  [230/345]  eta: 0:00:09  loss: 0.7469 (0.7489)  time: 0.0895  data: 0.0001  max mem: 10917
[14:49:42.166730] Test:  [240/345]  eta: 0:00:09  loss: 0.7469 (0.7490)  time: 0.0899  data: 0.0001  max mem: 10917
[14:49:43.070681] Test:  [250/345]  eta: 0:00:08  loss: 0.7539 (0.7491)  time: 0.0902  data: 0.0001  max mem: 10917
[14:49:43.979909] Test:  [260/345]  eta: 0:00:07  loss: 0.7500 (0.7494)  time: 0.0906  data: 0.0001  max mem: 10917
[14:49:44.890945] Test:  [270/345]  eta: 0:00:06  loss: 0.7520 (0.7493)  time: 0.0910  data: 0.0001  max mem: 10917
[14:49:45.806161] Test:  [280/345]  eta: 0:00:05  loss: 0.7558 (0.7494)  time: 0.0913  data: 0.0001  max mem: 10917
[14:49:46.725476] Test:  [290/345]  eta: 0:00:04  loss: 0.7440 (0.7492)  time: 0.0917  data: 0.0001  max mem: 10917
[14:49:47.648253] Test:  [300/345]  eta: 0:00:03  loss: 0.7454 (0.7494)  time: 0.0921  data: 0.0001  max mem: 10917
[14:49:48.574163] Test:  [310/345]  eta: 0:00:03  loss: 0.7515 (0.7495)  time: 0.0924  data: 0.0001  max mem: 10917
[14:49:49.503647] Test:  [320/345]  eta: 0:00:02  loss: 0.7584 (0.7499)  time: 0.0927  data: 0.0001  max mem: 10917
[14:49:50.435593] Test:  [330/345]  eta: 0:00:01  loss: 0.7581 (0.7499)  time: 0.0930  data: 0.0001  max mem: 10917
[14:49:51.372191] Test:  [340/345]  eta: 0:00:00  loss: 0.7391 (0.7497)  time: 0.0934  data: 0.0001  max mem: 10917
[14:49:51.748268] Test:  [344/345]  eta: 0:00:00  loss: 0.7391 (0.7497)  time: 0.0936  data: 0.0001  max mem: 10917
[14:49:51.787811] Test: Total time: 0:00:30 (0.0884 s / it)
[14:50:02.884929] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8723 (0.8723)  time: 0.2248  data: 0.1449  max mem: 10917
[14:50:03.697037] Test:  [10/57]  eta: 0:00:04  loss: 0.8933 (0.9031)  time: 0.0942  data: 0.0132  max mem: 10917
[14:50:04.513472] Test:  [20/57]  eta: 0:00:03  loss: 0.8963 (0.8872)  time: 0.0814  data: 0.0001  max mem: 10917
[14:50:05.334781] Test:  [30/57]  eta: 0:00:02  loss: 0.7901 (0.8519)  time: 0.0818  data: 0.0001  max mem: 10917
[14:50:06.159832] Test:  [40/57]  eta: 0:00:01  loss: 0.7836 (0.8338)  time: 0.0823  data: 0.0001  max mem: 10917
[14:50:06.988135] Test:  [50/57]  eta: 0:00:00  loss: 0.7662 (0.8269)  time: 0.0826  data: 0.0001  max mem: 10917
[14:50:07.438035] Test:  [56/57]  eta: 0:00:00  loss: 0.7940 (0.8303)  time: 0.0804  data: 0.0001  max mem: 10917
[14:50:07.479030] Test: Total time: 0:00:04 (0.0846 s / it)
[14:50:09.487751] Dice score of the network on the train images: 0.801739, val images: 0.806824
[14:50:09.491556] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:50:09.890072] Epoch: [25]  [  0/345]  eta: 0:02:17  lr: 0.000117  loss: 0.7639 (0.7639)  time: 0.3974  data: 0.1455  max mem: 10917
[14:50:14.880802] Epoch: [25]  [ 20/345]  eta: 0:01:23  lr: 0.000116  loss: 0.7823 (0.7866)  time: 0.2495  data: 0.0001  max mem: 10917
[14:50:19.879252] Epoch: [25]  [ 40/345]  eta: 0:01:17  lr: 0.000116  loss: 0.7743 (0.7828)  time: 0.2499  data: 0.0001  max mem: 10917
[14:50:24.880357] Epoch: [25]  [ 60/345]  eta: 0:01:11  lr: 0.000116  loss: 0.7892 (0.7852)  time: 0.2500  data: 0.0001  max mem: 10917
[14:50:29.888466] Epoch: [25]  [ 80/345]  eta: 0:01:06  lr: 0.000116  loss: 0.7875 (0.7858)  time: 0.2504  data: 0.0001  max mem: 10917
[14:50:34.903575] Epoch: [25]  [100/345]  eta: 0:01:01  lr: 0.000116  loss: 0.7787 (0.7847)  time: 0.2507  data: 0.0001  max mem: 10917
[14:50:39.923142] Epoch: [25]  [120/345]  eta: 0:00:56  lr: 0.000115  loss: 0.7747 (0.7832)  time: 0.2509  data: 0.0001  max mem: 10917
[14:50:44.944932] Epoch: [25]  [140/345]  eta: 0:00:51  lr: 0.000115  loss: 0.7818 (0.7837)  time: 0.2510  data: 0.0000  max mem: 10917
[14:50:49.967821] Epoch: [25]  [160/345]  eta: 0:00:46  lr: 0.000115  loss: 0.7740 (0.7828)  time: 0.2511  data: 0.0001  max mem: 10917
[14:50:54.992460] Epoch: [25]  [180/345]  eta: 0:00:41  lr: 0.000115  loss: 0.7824 (0.7827)  time: 0.2512  data: 0.0001  max mem: 10917
[14:51:00.019028] Epoch: [25]  [200/345]  eta: 0:00:36  lr: 0.000115  loss: 0.7699 (0.7816)  time: 0.2513  data: 0.0001  max mem: 10917
[14:51:05.045653] Epoch: [25]  [220/345]  eta: 0:00:31  lr: 0.000114  loss: 0.7801 (0.7820)  time: 0.2513  data: 0.0001  max mem: 10917
[14:51:10.062698] Epoch: [25]  [240/345]  eta: 0:00:26  lr: 0.000114  loss: 0.7823 (0.7820)  time: 0.2508  data: 0.0000  max mem: 10917
[14:51:15.081550] Epoch: [25]  [260/345]  eta: 0:00:21  lr: 0.000114  loss: 0.7930 (0.7826)  time: 0.2509  data: 0.0000  max mem: 10917
[14:51:20.103960] Epoch: [25]  [280/345]  eta: 0:00:16  lr: 0.000114  loss: 0.7792 (0.7826)  time: 0.2511  data: 0.0001  max mem: 10917
[14:51:25.128234] Epoch: [25]  [300/345]  eta: 0:00:11  lr: 0.000114  loss: 0.7859 (0.7826)  time: 0.2512  data: 0.0001  max mem: 10917
[14:51:30.153333] Epoch: [25]  [320/345]  eta: 0:00:06  lr: 0.000113  loss: 0.7744 (0.7820)  time: 0.2512  data: 0.0001  max mem: 10917
[14:51:35.180621] Epoch: [25]  [340/345]  eta: 0:00:01  lr: 0.000113  loss: 0.7716 (0.7816)  time: 0.2513  data: 0.0000  max mem: 10917
[14:51:36.187984] Epoch: [25]  [344/345]  eta: 0:00:00  lr: 0.000113  loss: 0.7777 (0.7816)  time: 0.2514  data: 0.0001  max mem: 10917
[14:51:36.241960] Epoch: [25] Total time: 0:01:26 (0.2515 s / it)
[14:51:36.242464] Averaged stats: lr: 0.000113  loss: 0.7777 (0.7816)
[14:51:36.477765] Test:  [  0/345]  eta: 0:01:20  loss: 0.7353 (0.7353)  time: 0.2323  data: 0.1522  max mem: 10917
[14:51:37.306899] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7353 (0.7355)  time: 0.0964  data: 0.0147  max mem: 10917
[14:51:38.130599] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7402 (0.7397)  time: 0.0826  data: 0.0005  max mem: 10917
[14:51:38.958527] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7433 (0.7425)  time: 0.0825  data: 0.0001  max mem: 10917
[14:51:39.789496] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7429 (0.7436)  time: 0.0829  data: 0.0001  max mem: 10917
[14:51:40.623351] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7345 (0.7422)  time: 0.0832  data: 0.0001  max mem: 10917
[14:51:41.461363] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7356 (0.7420)  time: 0.0835  data: 0.0001  max mem: 10917
[14:51:42.303260] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7385 (0.7425)  time: 0.0839  data: 0.0001  max mem: 10917
[14:51:43.148205] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7388 (0.7419)  time: 0.0843  data: 0.0001  max mem: 10917
[14:51:43.997249] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7371 (0.7417)  time: 0.0847  data: 0.0001  max mem: 10917
[14:51:44.849484] Test:  [100/345]  eta: 0:00:20  loss: 0.7321 (0.7415)  time: 0.0850  data: 0.0001  max mem: 10917
[14:51:45.705047] Test:  [110/345]  eta: 0:00:20  loss: 0.7341 (0.7415)  time: 0.0853  data: 0.0001  max mem: 10917
[14:51:46.564741] Test:  [120/345]  eta: 0:00:19  loss: 0.7460 (0.7421)  time: 0.0857  data: 0.0001  max mem: 10917
[14:51:47.427861] Test:  [130/345]  eta: 0:00:18  loss: 0.7466 (0.7424)  time: 0.0861  data: 0.0001  max mem: 10917
[14:51:48.294578] Test:  [140/345]  eta: 0:00:17  loss: 0.7432 (0.7423)  time: 0.0864  data: 0.0001  max mem: 10917
[14:51:49.164974] Test:  [150/345]  eta: 0:00:16  loss: 0.7351 (0.7419)  time: 0.0868  data: 0.0001  max mem: 10917
[14:51:50.038274] Test:  [160/345]  eta: 0:00:15  loss: 0.7327 (0.7415)  time: 0.0871  data: 0.0001  max mem: 10917
[14:51:50.915898] Test:  [170/345]  eta: 0:00:15  loss: 0.7390 (0.7420)  time: 0.0875  data: 0.0001  max mem: 10917
[14:51:51.796569] Test:  [180/345]  eta: 0:00:14  loss: 0.7417 (0.7417)  time: 0.0878  data: 0.0001  max mem: 10917
[14:51:52.679660] Test:  [190/345]  eta: 0:00:13  loss: 0.7400 (0.7416)  time: 0.0881  data: 0.0001  max mem: 10917
[14:51:53.566905] Test:  [200/345]  eta: 0:00:12  loss: 0.7416 (0.7417)  time: 0.0885  data: 0.0001  max mem: 10917
[14:51:54.458264] Test:  [210/345]  eta: 0:00:11  loss: 0.7487 (0.7425)  time: 0.0889  data: 0.0001  max mem: 10917
[14:51:55.352476] Test:  [220/345]  eta: 0:00:10  loss: 0.7457 (0.7426)  time: 0.0892  data: 0.0001  max mem: 10917
[14:51:56.249991] Test:  [230/345]  eta: 0:00:09  loss: 0.7370 (0.7423)  time: 0.0895  data: 0.0001  max mem: 10917
[14:51:57.152472] Test:  [240/345]  eta: 0:00:09  loss: 0.7426 (0.7429)  time: 0.0900  data: 0.0001  max mem: 10917
[14:51:58.058363] Test:  [250/345]  eta: 0:00:08  loss: 0.7512 (0.7429)  time: 0.0904  data: 0.0001  max mem: 10917
[14:51:58.967137] Test:  [260/345]  eta: 0:00:07  loss: 0.7455 (0.7428)  time: 0.0907  data: 0.0001  max mem: 10917
[14:51:59.880319] Test:  [270/345]  eta: 0:00:06  loss: 0.7415 (0.7429)  time: 0.0911  data: 0.0001  max mem: 10917
[14:52:00.795642] Test:  [280/345]  eta: 0:00:05  loss: 0.7395 (0.7428)  time: 0.0914  data: 0.0001  max mem: 10917
[14:52:01.715049] Test:  [290/345]  eta: 0:00:04  loss: 0.7389 (0.7427)  time: 0.0917  data: 0.0001  max mem: 10917
[14:52:02.637194] Test:  [300/345]  eta: 0:00:03  loss: 0.7411 (0.7429)  time: 0.0920  data: 0.0001  max mem: 10917
[14:52:03.563216] Test:  [310/345]  eta: 0:00:03  loss: 0.7457 (0.7430)  time: 0.0924  data: 0.0001  max mem: 10917
[14:52:04.492642] Test:  [320/345]  eta: 0:00:02  loss: 0.7415 (0.7429)  time: 0.0927  data: 0.0001  max mem: 10917
[14:52:05.425519] Test:  [330/345]  eta: 0:00:01  loss: 0.7405 (0.7428)  time: 0.0931  data: 0.0001  max mem: 10917
[14:52:06.362578] Test:  [340/345]  eta: 0:00:00  loss: 0.7443 (0.7428)  time: 0.0934  data: 0.0001  max mem: 10917
[14:52:06.738998] Test:  [344/345]  eta: 0:00:00  loss: 0.7438 (0.7429)  time: 0.0936  data: 0.0001  max mem: 10917
[14:52:06.796838] Test: Total time: 0:00:30 (0.0886 s / it)
[14:52:17.880286] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9058 (0.9058)  time: 0.2221  data: 0.1423  max mem: 10917
[14:52:18.691602] Test:  [10/57]  eta: 0:00:04  loss: 0.9025 (0.8980)  time: 0.0939  data: 0.0130  max mem: 10917
[14:52:19.507923] Test:  [20/57]  eta: 0:00:03  loss: 0.8912 (0.8813)  time: 0.0813  data: 0.0001  max mem: 10917
[14:52:20.328149] Test:  [30/57]  eta: 0:00:02  loss: 0.7805 (0.8423)  time: 0.0818  data: 0.0001  max mem: 10917
[14:52:21.152997] Test:  [40/57]  eta: 0:00:01  loss: 0.7615 (0.8216)  time: 0.0822  data: 0.0001  max mem: 10917
[14:52:21.981387] Test:  [50/57]  eta: 0:00:00  loss: 0.7679 (0.8164)  time: 0.0826  data: 0.0001  max mem: 10917
[14:52:22.430973] Test:  [56/57]  eta: 0:00:00  loss: 0.7905 (0.8209)  time: 0.0803  data: 0.0001  max mem: 10917
[14:52:22.488812] Test: Total time: 0:00:04 (0.0848 s / it)
[14:52:24.419059] Dice score of the network on the train images: 0.792509, val images: 0.807344
[14:52:24.422987] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:52:24.820786] Epoch: [26]  [  0/345]  eta: 0:02:16  lr: 0.000113  loss: 0.7835 (0.7835)  time: 0.3968  data: 0.1458  max mem: 10917
[14:52:29.802874] Epoch: [26]  [ 20/345]  eta: 0:01:23  lr: 0.000113  loss: 0.7816 (0.7800)  time: 0.2491  data: 0.0001  max mem: 10917

[14:52:34.792300] Epoch: [26]  [ 40/345]  eta: 0:01:17  lr: 0.000113  loss: 0.7822 (0.7788)  time: 0.2494  data: 0.0001  max mem: 10917
[14:52:39.794120] Epoch: [26]  [ 60/345]  eta: 0:01:11  lr: 0.000112  loss: 0.7713 (0.7764)  time: 0.2501  data: 0.0000  max mem: 10917

[14:52:44.797811] Epoch: [26]  [ 80/345]  eta: 0:01:06  lr: 0.000112  loss: 0.7724 (0.7770)  time: 0.2501  data: 0.0001  max mem: 10917
[14:52:49.795585] Epoch: [26]  [100/345]  eta: 0:01:01  lr: 0.000112  loss: 0.7747 (0.7776)  time: 0.2498  data: 0.0001  max mem: 10917

[14:52:54.799681] Epoch: [26]  [120/345]  eta: 0:00:56  lr: 0.000112  loss: 0.7744 (0.7771)  time: 0.2502  data: 0.0001  max mem: 10917
[14:52:59.802617] Epoch: [26]  [140/345]  eta: 0:00:51  lr: 0.000111  loss: 0.7769 (0.7770)  time: 0.2501  data: 0.0001  max mem: 10917

[14:53:04.807599] Epoch: [26]  [160/345]  eta: 0:00:46  lr: 0.000111  loss: 0.7655 (0.7759)  time: 0.2502  data: 0.0000  max mem: 10917
[14:53:09.816988] Epoch: [26]  [180/345]  eta: 0:00:41  lr: 0.000111  loss: 0.7687 (0.7753)  time: 0.2504  data: 0.0001  max mem: 10917

[14:53:14.828066] Epoch: [26]  [200/345]  eta: 0:00:36  lr: 0.000111  loss: 0.7763 (0.7755)  time: 0.2505  data: 0.0001  max mem: 10917
[14:53:19.842762] Epoch: [26]  [220/345]  eta: 0:00:31  lr: 0.000110  loss: 0.7726 (0.7758)  time: 0.2507  data: 0.0000  max mem: 10917

[14:53:24.862194] Epoch: [26]  [240/345]  eta: 0:00:26  lr: 0.000110  loss: 0.7760 (0.7762)  time: 0.2509  data: 0.0001  max mem: 10917
[14:53:29.880849] Epoch: [26]  [260/345]  eta: 0:00:21  lr: 0.000110  loss: 0.7995 (0.7782)  time: 0.2509  data: 0.0001  max mem: 10917
[14:53:34.905268] Epoch: [26]  [280/345]  eta: 0:00:16  lr: 0.000110  loss: 0.7829 (0.7785)  time: 0.2512  data: 0.0000  max mem: 10917
[14:53:39.930002] Epoch: [26]  [300/345]  eta: 0:00:11  lr: 0.000110  loss: 0.7811 (0.7788)  time: 0.2512  data: 0.0001  max mem: 10917
[14:53:44.958378] Epoch: [26]  [320/345]  eta: 0:00:06  lr: 0.000109  loss: 0.7626 (0.7782)  time: 0.2514  data: 0.0000  max mem: 10917
[14:53:50.001137] Epoch: [26]  [340/345]  eta: 0:00:01  lr: 0.000109  loss: 0.7695 (0.7779)  time: 0.2521  data: 0.0000  max mem: 10917
[14:53:51.008827] Epoch: [26]  [344/345]  eta: 0:00:00  lr: 0.000109  loss: 0.7695 (0.7781)  time: 0.2520  data: 0.0001  max mem: 10917
[14:53:51.065471] Epoch: [26] Total time: 0:01:26 (0.2511 s / it)
[14:53:51.065794] Averaged stats: lr: 0.000109  loss: 0.7695 (0.7781)
[14:53:51.304918] Test:  [  0/345]  eta: 0:01:21  loss: 0.7398 (0.7398)  time: 0.2356  data: 0.1557  max mem: 10917
[14:53:52.138396] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7317 (0.7345)  time: 0.0971  data: 0.0155  max mem: 10917
[14:53:52.962180] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7317 (0.7366)  time: 0.0828  data: 0.0008  max mem: 10917
[14:53:53.789504] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7407 (0.7398)  time: 0.0825  data: 0.0001  max mem: 10917
[14:53:54.619866] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7419 (0.7400)  time: 0.0828  data: 0.0001  max mem: 10917
[14:53:55.454247] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7403 (0.7397)  time: 0.0832  data: 0.0001  max mem: 10917
[14:53:56.292545] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7447 (0.7408)  time: 0.0836  data: 0.0001  max mem: 10917
[14:53:57.133943] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7447 (0.7413)  time: 0.0839  data: 0.0001  max mem: 10917
[14:53:57.978308] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7438 (0.7418)  time: 0.0842  data: 0.0001  max mem: 10917
[14:53:58.827038] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7393 (0.7410)  time: 0.0846  data: 0.0001  max mem: 10917
[14:53:59.678377] Test:  [100/345]  eta: 0:00:20  loss: 0.7394 (0.7409)  time: 0.0850  data: 0.0001  max mem: 10917
[14:54:00.533418] Test:  [110/345]  eta: 0:00:20  loss: 0.7430 (0.7414)  time: 0.0853  data: 0.0001  max mem: 10917
[14:54:01.391840] Test:  [120/345]  eta: 0:00:19  loss: 0.7418 (0.7415)  time: 0.0856  data: 0.0001  max mem: 10917
[14:54:02.253795] Test:  [130/345]  eta: 0:00:18  loss: 0.7418 (0.7417)  time: 0.0860  data: 0.0001  max mem: 10917
[14:54:03.118441] Test:  [140/345]  eta: 0:00:17  loss: 0.7407 (0.7418)  time: 0.0863  data: 0.0001  max mem: 10917
[14:54:03.987286] Test:  [150/345]  eta: 0:00:16  loss: 0.7373 (0.7416)  time: 0.0866  data: 0.0001  max mem: 10917
[14:54:04.859776] Test:  [160/345]  eta: 0:00:15  loss: 0.7373 (0.7415)  time: 0.0870  data: 0.0001  max mem: 10917
[14:54:05.736984] Test:  [170/345]  eta: 0:00:15  loss: 0.7382 (0.7414)  time: 0.0874  data: 0.0001  max mem: 10917
[14:54:06.616658] Test:  [180/345]  eta: 0:00:14  loss: 0.7407 (0.7421)  time: 0.0878  data: 0.0001  max mem: 10917
[14:54:07.500238] Test:  [190/345]  eta: 0:00:13  loss: 0.7479 (0.7423)  time: 0.0881  data: 0.0001  max mem: 10917
[14:54:08.386742] Test:  [200/345]  eta: 0:00:12  loss: 0.7479 (0.7428)  time: 0.0885  data: 0.0001  max mem: 10917
[14:54:09.277451] Test:  [210/345]  eta: 0:00:11  loss: 0.7475 (0.7429)  time: 0.0888  data: 0.0001  max mem: 10917
[14:54:10.170715] Test:  [220/345]  eta: 0:00:10  loss: 0.7431 (0.7431)  time: 0.0892  data: 0.0001  max mem: 10917
[14:54:11.069484] Test:  [230/345]  eta: 0:00:09  loss: 0.7394 (0.7432)  time: 0.0896  data: 0.0001  max mem: 10917
[14:54:11.970882] Test:  [240/345]  eta: 0:00:09  loss: 0.7354 (0.7429)  time: 0.0900  data: 0.0001  max mem: 10917
[14:54:12.874831] Test:  [250/345]  eta: 0:00:08  loss: 0.7383 (0.7429)  time: 0.0902  data: 0.0001  max mem: 10917
[14:54:13.782728] Test:  [260/345]  eta: 0:00:07  loss: 0.7448 (0.7432)  time: 0.0905  data: 0.0001  max mem: 10917
[14:54:14.694032] Test:  [270/345]  eta: 0:00:06  loss: 0.7365 (0.7431)  time: 0.0909  data: 0.0001  max mem: 10917
[14:54:15.609141] Test:  [280/345]  eta: 0:00:05  loss: 0.7368 (0.7431)  time: 0.0913  data: 0.0001  max mem: 10917
[14:54:16.526856] Test:  [290/345]  eta: 0:00:04  loss: 0.7431 (0.7431)  time: 0.0916  data: 0.0001  max mem: 10917
[14:54:17.449355] Test:  [300/345]  eta: 0:00:03  loss: 0.7431 (0.7431)  time: 0.0920  data: 0.0001  max mem: 10917
[14:54:18.374268] Test:  [310/345]  eta: 0:00:03  loss: 0.7409 (0.7432)  time: 0.0923  data: 0.0001  max mem: 10917
[14:54:19.303505] Test:  [320/345]  eta: 0:00:02  loss: 0.7391 (0.7431)  time: 0.0927  data: 0.0001  max mem: 10917
[14:54:20.235724] Test:  [330/345]  eta: 0:00:01  loss: 0.7363 (0.7431)  time: 0.0930  data: 0.0001  max mem: 10917
[14:54:21.172349] Test:  [340/345]  eta: 0:00:00  loss: 0.7363 (0.7431)  time: 0.0934  data: 0.0001  max mem: 10917
[14:54:21.547985] Test:  [344/345]  eta: 0:00:00  loss: 0.7411 (0.7432)  time: 0.0935  data: 0.0001  max mem: 10917
[14:54:21.605170] Test: Total time: 0:00:30 (0.0885 s / it)
[14:54:32.653221] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8896 (0.8896)  time: 0.2215  data: 0.1419  max mem: 10917
[14:54:33.465986] Test:  [10/57]  eta: 0:00:04  loss: 0.9007 (0.9116)  time: 0.0940  data: 0.0130  max mem: 10917
[14:54:34.283842] Test:  [20/57]  eta: 0:00:03  loss: 0.8962 (0.8907)  time: 0.0815  data: 0.0001  max mem: 10917
[14:54:35.105286] Test:  [30/57]  eta: 0:00:02  loss: 0.7877 (0.8507)  time: 0.0819  data: 0.0001  max mem: 10917
[14:54:35.929535] Test:  [40/57]  eta: 0:00:01  loss: 0.7737 (0.8298)  time: 0.0822  data: 0.0001  max mem: 10917
[14:54:36.758962] Test:  [50/57]  eta: 0:00:00  loss: 0.7585 (0.8217)  time: 0.0826  data: 0.0001  max mem: 10917
[14:54:37.209109] Test:  [56/57]  eta: 0:00:00  loss: 0.7907 (0.8258)  time: 0.0804  data: 0.0001  max mem: 10917
[14:54:37.264613] Test: Total time: 0:00:04 (0.0848 s / it)
[14:54:39.229129] Dice score of the network on the train images: 0.801855, val images: 0.815460
[14:54:39.229375] saving best_dice_model_0 @ epoch 26
[14:54:40.174111] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:54:40.571638] Epoch: [27]  [  0/345]  eta: 0:02:16  lr: 0.000109  loss: 0.7954 (0.7954)  time: 0.3963  data: 0.1441  max mem: 10917
[14:54:45.568044] Epoch: [27]  [ 20/345]  eta: 0:01:23  lr: 0.000109  loss: 0.7781 (0.7818)  time: 0.2498  data: 0.0001  max mem: 10917
[14:54:50.563876] Epoch: [27]  [ 40/345]  eta: 0:01:17  lr: 0.000108  loss: 0.7622 (0.7770)  time: 0.2498  data: 0.0001  max mem: 10917
[14:54:55.551132] Epoch: [27]  [ 60/345]  eta: 0:01:11  lr: 0.000108  loss: 0.7701 (0.7758)  time: 0.2493  data: 0.0001  max mem: 10917
[14:55:00.538475] Epoch: [27]  [ 80/345]  eta: 0:01:06  lr: 0.000108  loss: 0.7706 (0.7746)  time: 0.2493  data: 0.0001  max mem: 10917
[14:55:05.536071] Epoch: [27]  [100/345]  eta: 0:01:01  lr: 0.000108  loss: 0.7632 (0.7729)  time: 0.2498  data: 0.0001  max mem: 10917
[14:55:10.536029] Epoch: [27]  [120/345]  eta: 0:00:56  lr: 0.000107  loss: 0.7690 (0.7721)  time: 0.2500  data: 0.0001  max mem: 10917
[14:55:15.537458] Epoch: [27]  [140/345]  eta: 0:00:51  lr: 0.000107  loss: 0.7655 (0.7716)  time: 0.2500  data: 0.0000  max mem: 10917
[14:55:20.537516] Epoch: [27]  [160/345]  eta: 0:00:46  lr: 0.000107  loss: 0.7761 (0.7721)  time: 0.2500  data: 0.0001  max mem: 10917
[14:55:25.548284] Epoch: [27]  [180/345]  eta: 0:00:41  lr: 0.000107  loss: 0.7757 (0.7723)  time: 0.2505  data: 0.0000  max mem: 10917
[14:55:30.564364] Epoch: [27]  [200/345]  eta: 0:00:36  lr: 0.000106  loss: 0.7750 (0.7728)  time: 0.2508  data: 0.0001  max mem: 10917
[14:55:35.580942] Epoch: [27]  [220/345]  eta: 0:00:31  lr: 0.000106  loss: 0.7820 (0.7735)  time: 0.2508  data: 0.0001  max mem: 10917
[14:55:40.597654] Epoch: [27]  [240/345]  eta: 0:00:26  lr: 0.000106  loss: 0.7750 (0.7737)  time: 0.2508  data: 0.0001  max mem: 10917
[14:55:45.619643] Epoch: [27]  [260/345]  eta: 0:00:21  lr: 0.000106  loss: 0.7677 (0.7733)  time: 0.2511  data: 0.0001  max mem: 10917
[14:55:50.651529] Epoch: [27]  [280/345]  eta: 0:00:16  lr: 0.000105  loss: 0.7623 (0.7726)  time: 0.2515  data: 0.0001  max mem: 10917
[14:55:55.688879] Epoch: [27]  [300/345]  eta: 0:00:11  lr: 0.000105  loss: 0.7708 (0.7726)  time: 0.2518  data: 0.0001  max mem: 10917
[14:56:00.720874] Epoch: [27]  [320/345]  eta: 0:00:06  lr: 0.000105  loss: 0.7665 (0.7724)  time: 0.2516  data: 0.0001  max mem: 10917
[14:56:05.747025] Epoch: [27]  [340/345]  eta: 0:00:01  lr: 0.000104  loss: 0.7714 (0.7722)  time: 0.2513  data: 0.0000  max mem: 10917
[14:56:06.752846] Epoch: [27]  [344/345]  eta: 0:00:00  lr: 0.000104  loss: 0.7685 (0.7722)  time: 0.2513  data: 0.0001  max mem: 10917
[14:56:06.806429] Epoch: [27] Total time: 0:01:26 (0.2511 s / it)
[14:56:06.806890] Averaged stats: lr: 0.000104  loss: 0.7685 (0.7722)
[14:56:07.049067] Test:  [  0/345]  eta: 0:01:22  loss: 0.7047 (0.7047)  time: 0.2394  data: 0.1594  max mem: 10917
[14:56:07.964756] Test:  [ 10/345]  eta: 0:00:35  loss: 0.7396 (0.7382)  time: 0.1049  data: 0.0238  max mem: 10917
[14:56:08.792782] Test:  [ 20/345]  eta: 0:00:30  loss: 0.7407 (0.7422)  time: 0.0871  data: 0.0055  max mem: 10917
[14:56:09.619398] Test:  [ 30/345]  eta: 0:00:28  loss: 0.7349 (0.7405)  time: 0.0827  data: 0.0004  max mem: 10917
[14:56:10.450102] Test:  [ 40/345]  eta: 0:00:27  loss: 0.7254 (0.7380)  time: 0.0828  data: 0.0001  max mem: 10917
[14:56:11.284005] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7312 (0.7378)  time: 0.0832  data: 0.0001  max mem: 10917
[14:56:12.121097] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7351 (0.7369)  time: 0.0835  data: 0.0001  max mem: 10917
[14:56:12.962054] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7299 (0.7361)  time: 0.0839  data: 0.0001  max mem: 10917
[14:56:13.807004] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7390 (0.7377)  time: 0.0842  data: 0.0001  max mem: 10917
[14:56:14.655168] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7390 (0.7370)  time: 0.0846  data: 0.0001  max mem: 10917
[14:56:15.507032] Test:  [100/345]  eta: 0:00:21  loss: 0.7320 (0.7362)  time: 0.0850  data: 0.0001  max mem: 10917
[14:56:16.360950] Test:  [110/345]  eta: 0:00:20  loss: 0.7297 (0.7366)  time: 0.0852  data: 0.0001  max mem: 10917
[14:56:17.220005] Test:  [120/345]  eta: 0:00:19  loss: 0.7384 (0.7366)  time: 0.0856  data: 0.0001  max mem: 10917
[14:56:18.082761] Test:  [130/345]  eta: 0:00:18  loss: 0.7347 (0.7364)  time: 0.0860  data: 0.0001  max mem: 10917
[14:56:18.948673] Test:  [140/345]  eta: 0:00:17  loss: 0.7382 (0.7367)  time: 0.0864  data: 0.0001  max mem: 10917
[14:56:19.817507] Test:  [150/345]  eta: 0:00:16  loss: 0.7357 (0.7366)  time: 0.0867  data: 0.0001  max mem: 10917
[14:56:20.690900] Test:  [160/345]  eta: 0:00:15  loss: 0.7320 (0.7368)  time: 0.0871  data: 0.0001  max mem: 10917
[14:56:21.567753] Test:  [170/345]  eta: 0:00:15  loss: 0.7368 (0.7370)  time: 0.0875  data: 0.0001  max mem: 10917
[14:56:22.447758] Test:  [180/345]  eta: 0:00:14  loss: 0.7412 (0.7374)  time: 0.0878  data: 0.0001  max mem: 10917
[14:56:23.330071] Test:  [190/345]  eta: 0:00:13  loss: 0.7412 (0.7376)  time: 0.0881  data: 0.0001  max mem: 10917
[14:56:24.216577] Test:  [200/345]  eta: 0:00:12  loss: 0.7364 (0.7373)  time: 0.0884  data: 0.0001  max mem: 10917
[14:56:25.107220] Test:  [210/345]  eta: 0:00:11  loss: 0.7364 (0.7372)  time: 0.0888  data: 0.0001  max mem: 10917
[14:56:26.001480] Test:  [220/345]  eta: 0:00:10  loss: 0.7316 (0.7370)  time: 0.0892  data: 0.0001  max mem: 10917
[14:56:26.898821] Test:  [230/345]  eta: 0:00:09  loss: 0.7335 (0.7370)  time: 0.0895  data: 0.0001  max mem: 10917
[14:56:27.799745] Test:  [240/345]  eta: 0:00:09  loss: 0.7335 (0.7369)  time: 0.0898  data: 0.0001  max mem: 10917
[14:56:28.703774] Test:  [250/345]  eta: 0:00:08  loss: 0.7320 (0.7368)  time: 0.0902  data: 0.0001  max mem: 10917
[14:56:29.612463] Test:  [260/345]  eta: 0:00:07  loss: 0.7326 (0.7368)  time: 0.0906  data: 0.0001  max mem: 10917
[14:56:30.524332] Test:  [270/345]  eta: 0:00:06  loss: 0.7366 (0.7370)  time: 0.0910  data: 0.0001  max mem: 10917
[14:56:31.439292] Test:  [280/345]  eta: 0:00:05  loss: 0.7383 (0.7369)  time: 0.0913  data: 0.0001  max mem: 10917
[14:56:32.358887] Test:  [290/345]  eta: 0:00:04  loss: 0.7337 (0.7369)  time: 0.0917  data: 0.0001  max mem: 10917
[14:56:33.280524] Test:  [300/345]  eta: 0:00:03  loss: 0.7353 (0.7369)  time: 0.0920  data: 0.0001  max mem: 10917
[14:56:34.205664] Test:  [310/345]  eta: 0:00:03  loss: 0.7353 (0.7368)  time: 0.0923  data: 0.0001  max mem: 10917
[14:56:35.135634] Test:  [320/345]  eta: 0:00:02  loss: 0.7327 (0.7366)  time: 0.0927  data: 0.0001  max mem: 10917
[14:56:36.068012] Test:  [330/345]  eta: 0:00:01  loss: 0.7307 (0.7364)  time: 0.0931  data: 0.0001  max mem: 10917
[14:56:37.004651] Test:  [340/345]  eta: 0:00:00  loss: 0.7310 (0.7363)  time: 0.0934  data: 0.0001  max mem: 10917
[14:56:37.380340] Test:  [344/345]  eta: 0:00:00  loss: 0.7324 (0.7363)  time: 0.0935  data: 0.0001  max mem: 10917
[14:56:37.437904] Test: Total time: 0:00:30 (0.0888 s / it)
[14:56:48.593085] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9031 (0.9031)  time: 0.2222  data: 0.1426  max mem: 10917
[14:56:49.404275] Test:  [10/57]  eta: 0:00:04  loss: 0.9020 (0.9070)  time: 0.0939  data: 0.0130  max mem: 10917
[14:56:50.220328] Test:  [20/57]  eta: 0:00:03  loss: 0.8837 (0.8885)  time: 0.0813  data: 0.0001  max mem: 10917
[14:56:51.040859] Test:  [30/57]  eta: 0:00:02  loss: 0.7879 (0.8501)  time: 0.0818  data: 0.0001  max mem: 10917
[14:56:51.864333] Test:  [40/57]  eta: 0:00:01  loss: 0.7813 (0.8301)  time: 0.0821  data: 0.0001  max mem: 10917
[14:56:52.692113] Test:  [50/57]  eta: 0:00:00  loss: 0.7807 (0.8247)  time: 0.0825  data: 0.0001  max mem: 10917
[14:56:53.142216] Test:  [56/57]  eta: 0:00:00  loss: 0.7923 (0.8290)  time: 0.0803  data: 0.0001  max mem: 10917
[14:56:53.198080] Test: Total time: 0:00:04 (0.0847 s / it)
[14:56:55.175117] Dice score of the network on the train images: 0.810735, val images: 0.807742
[14:56:55.178606] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:56:55.578677] Epoch: [28]  [  0/345]  eta: 0:02:17  lr: 0.000104  loss: 0.7577 (0.7577)  time: 0.3990  data: 0.1473  max mem: 10917
[14:57:00.577893] Epoch: [28]  [ 20/345]  eta: 0:01:23  lr: 0.000104  loss: 0.7633 (0.7628)  time: 0.2499  data: 0.0001  max mem: 10917
[14:57:05.582763] Epoch: [28]  [ 40/345]  eta: 0:01:17  lr: 0.000104  loss: 0.7680 (0.7655)  time: 0.2502  data: 0.0001  max mem: 10917
[14:57:10.587599] Epoch: [28]  [ 60/345]  eta: 0:01:11  lr: 0.000103  loss: 0.7732 (0.7690)  time: 0.2502  data: 0.0001  max mem: 10917
[14:57:15.600191] Epoch: [28]  [ 80/345]  eta: 0:01:06  lr: 0.000103  loss: 0.7761 (0.7711)  time: 0.2506  data: 0.0001  max mem: 10917
[14:57:20.616103] Epoch: [28]  [100/345]  eta: 0:01:01  lr: 0.000103  loss: 0.7693 (0.7709)  time: 0.2507  data: 0.0000  max mem: 10917
[14:57:25.636675] Epoch: [28]  [120/345]  eta: 0:00:56  lr: 0.000103  loss: 0.7675 (0.7710)  time: 0.2510  data: 0.0001  max mem: 10917
[14:57:30.656945] Epoch: [28]  [140/345]  eta: 0:00:51  lr: 0.000102  loss: 0.7693 (0.7710)  time: 0.2510  data: 0.0001  max mem: 10917
[14:57:35.681110] Epoch: [28]  [160/345]  eta: 0:00:46  lr: 0.000102  loss: 0.7674 (0.7714)  time: 0.2512  data: 0.0000  max mem: 10917
[14:57:40.707259] Epoch: [28]  [180/345]  eta: 0:00:41  lr: 0.000102  loss: 0.7620 (0.7707)  time: 0.2513  data: 0.0000  max mem: 10917
[14:57:45.730936] Epoch: [28]  [200/345]  eta: 0:00:36  lr: 0.000101  loss: 0.7774 (0.7711)  time: 0.2511  data: 0.0000  max mem: 10917
[14:57:50.760952] Epoch: [28]  [220/345]  eta: 0:00:31  lr: 0.000101  loss: 0.7627 (0.7705)  time: 0.2515  data: 0.0001  max mem: 10917
[14:57:55.792782] Epoch: [28]  [240/345]  eta: 0:00:26  lr: 0.000101  loss: 0.7689 (0.7703)  time: 0.2515  data: 0.0001  max mem: 10917
[14:58:00.826920] Epoch: [28]  [260/345]  eta: 0:00:21  lr: 0.000101  loss: 0.7668 (0.7699)  time: 0.2517  data: 0.0001  max mem: 10917
[14:58:05.862964] Epoch: [28]  [280/345]  eta: 0:00:16  lr: 0.000100  loss: 0.7670 (0.7697)  time: 0.2518  data: 0.0001  max mem: 10917
[14:58:10.897393] Epoch: [28]  [300/345]  eta: 0:00:11  lr: 0.000100  loss: 0.7719 (0.7701)  time: 0.2517  data: 0.0000  max mem: 10917
[14:58:15.937968] Epoch: [28]  [320/345]  eta: 0:00:06  lr: 0.000100  loss: 0.7745 (0.7704)  time: 0.2520  data: 0.0000  max mem: 10917
[14:58:20.981540] Epoch: [28]  [340/345]  eta: 0:00:01  lr: 0.000099  loss: 0.7681 (0.7704)  time: 0.2521  data: 0.0001  max mem: 10917
[14:58:21.988852] Epoch: [28]  [344/345]  eta: 0:00:00  lr: 0.000099  loss: 0.7671 (0.7704)  time: 0.2520  data: 0.0001  max mem: 10917
[14:58:22.046516] Epoch: [28] Total time: 0:01:26 (0.2518 s / it)
[14:58:22.047005] Averaged stats: lr: 0.000099  loss: 0.7671 (0.7704)
[14:58:22.283801] Test:  [  0/345]  eta: 0:01:20  loss: 0.7477 (0.7477)  time: 0.2333  data: 0.1530  max mem: 10917
[14:58:23.103599] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7374 (0.7361)  time: 0.0957  data: 0.0140  max mem: 10917
[14:58:23.927502] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7325 (0.7349)  time: 0.0821  data: 0.0001  max mem: 10917
[14:58:24.754167] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7338 (0.7355)  time: 0.0825  data: 0.0001  max mem: 10917
[14:58:25.585274] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7365 (0.7362)  time: 0.0828  data: 0.0001  max mem: 10917
[14:58:26.420055] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7361 (0.7362)  time: 0.0832  data: 0.0001  max mem: 10917
[14:58:27.258566] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7350 (0.7374)  time: 0.0836  data: 0.0001  max mem: 10917
[14:58:28.100141] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7360 (0.7381)  time: 0.0840  data: 0.0001  max mem: 10917
[14:58:28.945639] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7347 (0.7366)  time: 0.0843  data: 0.0001  max mem: 10917
[14:58:29.793990] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7328 (0.7362)  time: 0.0846  data: 0.0001  max mem: 10917
[14:58:30.646012] Test:  [100/345]  eta: 0:00:20  loss: 0.7328 (0.7360)  time: 0.0850  data: 0.0001  max mem: 10917
[14:58:31.501700] Test:  [110/345]  eta: 0:00:19  loss: 0.7243 (0.7354)  time: 0.0853  data: 0.0001  max mem: 10917
[14:58:32.361382] Test:  [120/345]  eta: 0:00:19  loss: 0.7266 (0.7353)  time: 0.0857  data: 0.0001  max mem: 10917
[14:58:33.224059] Test:  [130/345]  eta: 0:00:18  loss: 0.7441 (0.7358)  time: 0.0861  data: 0.0001  max mem: 10917
[14:58:34.090551] Test:  [140/345]  eta: 0:00:17  loss: 0.7342 (0.7356)  time: 0.0864  data: 0.0001  max mem: 10917
[14:58:34.959620] Test:  [150/345]  eta: 0:00:16  loss: 0.7316 (0.7354)  time: 0.0867  data: 0.0001  max mem: 10917
[14:58:35.832577] Test:  [160/345]  eta: 0:00:15  loss: 0.7322 (0.7352)  time: 0.0871  data: 0.0001  max mem: 10917
[14:58:36.709540] Test:  [170/345]  eta: 0:00:14  loss: 0.7329 (0.7353)  time: 0.0875  data: 0.0001  max mem: 10917
[14:58:37.590002] Test:  [180/345]  eta: 0:00:14  loss: 0.7295 (0.7354)  time: 0.0878  data: 0.0001  max mem: 10917
[14:58:38.473648] Test:  [190/345]  eta: 0:00:13  loss: 0.7295 (0.7354)  time: 0.0882  data: 0.0001  max mem: 10917
[14:58:39.361041] Test:  [200/345]  eta: 0:00:12  loss: 0.7267 (0.7351)  time: 0.0885  data: 0.0001  max mem: 10917
[14:58:40.251551] Test:  [210/345]  eta: 0:00:11  loss: 0.7267 (0.7349)  time: 0.0888  data: 0.0001  max mem: 10917
[14:58:41.145054] Test:  [220/345]  eta: 0:00:10  loss: 0.7408 (0.7352)  time: 0.0892  data: 0.0001  max mem: 10917
[14:58:42.042756] Test:  [230/345]  eta: 0:00:09  loss: 0.7304 (0.7349)  time: 0.0895  data: 0.0001  max mem: 10917
[14:58:42.944900] Test:  [240/345]  eta: 0:00:09  loss: 0.7312 (0.7352)  time: 0.0899  data: 0.0001  max mem: 10917
[14:58:43.848876] Test:  [250/345]  eta: 0:00:08  loss: 0.7406 (0.7356)  time: 0.0903  data: 0.0001  max mem: 10917
[14:58:44.757536] Test:  [260/345]  eta: 0:00:07  loss: 0.7390 (0.7356)  time: 0.0906  data: 0.0001  max mem: 10917
[14:58:45.670461] Test:  [270/345]  eta: 0:00:06  loss: 0.7361 (0.7356)  time: 0.0910  data: 0.0001  max mem: 10917
[14:58:46.586471] Test:  [280/345]  eta: 0:00:05  loss: 0.7353 (0.7357)  time: 0.0914  data: 0.0001  max mem: 10917
[14:58:47.505257] Test:  [290/345]  eta: 0:00:04  loss: 0.7324 (0.7354)  time: 0.0917  data: 0.0001  max mem: 10917
[14:58:48.427609] Test:  [300/345]  eta: 0:00:03  loss: 0.7288 (0.7352)  time: 0.0920  data: 0.0001  max mem: 10917
[14:58:49.352565] Test:  [310/345]  eta: 0:00:03  loss: 0.7261 (0.7348)  time: 0.0923  data: 0.0001  max mem: 10917
[14:58:50.282090] Test:  [320/345]  eta: 0:00:02  loss: 0.7285 (0.7351)  time: 0.0927  data: 0.0001  max mem: 10917
[14:58:51.214689] Test:  [330/345]  eta: 0:00:01  loss: 0.7418 (0.7351)  time: 0.0931  data: 0.0001  max mem: 10917
[14:58:52.150768] Test:  [340/345]  eta: 0:00:00  loss: 0.7294 (0.7351)  time: 0.0934  data: 0.0001  max mem: 10917
[14:58:52.526596] Test:  [344/345]  eta: 0:00:00  loss: 0.7356 (0.7351)  time: 0.0935  data: 0.0001  max mem: 10917
[14:58:52.588660] Test: Total time: 0:00:30 (0.0885 s / it)
[14:59:03.657491] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9109 (0.9109)  time: 0.2268  data: 0.1470  max mem: 10917
[14:59:04.470708] Test:  [10/57]  eta: 0:00:04  loss: 0.9217 (0.9118)  time: 0.0945  data: 0.0134  max mem: 10917
[14:59:05.286879] Test:  [20/57]  eta: 0:00:03  loss: 0.9078 (0.8931)  time: 0.0814  data: 0.0001  max mem: 10917
[14:59:06.106807] Test:  [30/57]  eta: 0:00:02  loss: 0.7826 (0.8529)  time: 0.0818  data: 0.0001  max mem: 10917
[14:59:06.931176] Test:  [40/57]  eta: 0:00:01  loss: 0.7709 (0.8315)  time: 0.0822  data: 0.0001  max mem: 10917
[14:59:07.757749] Test:  [50/57]  eta: 0:00:00  loss: 0.7658 (0.8234)  time: 0.0825  data: 0.0001  max mem: 10917
[14:59:08.207156] Test:  [56/57]  eta: 0:00:00  loss: 0.8004 (0.8275)  time: 0.0803  data: 0.0001  max mem: 10917
[14:59:08.263594] Test: Total time: 0:00:04 (0.0848 s / it)
[14:59:10.156640] Dice score of the network on the train images: 0.802376, val images: 0.809510
[14:59:10.160531] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:59:10.554985] Epoch: [29]  [  0/345]  eta: 0:02:15  lr: 0.000099  loss: 0.7428 (0.7428)  time: 0.3935  data: 0.1415  max mem: 10917
[14:59:15.549150] Epoch: [29]  [ 20/345]  eta: 0:01:23  lr: 0.000099  loss: 0.7686 (0.7636)  time: 0.2497  data: 0.0000  max mem: 10917
[14:59:20.552074] Epoch: [29]  [ 40/345]  eta: 0:01:17  lr: 0.000099  loss: 0.7721 (0.7681)  time: 0.2501  data: 0.0001  max mem: 10917
[14:59:25.558620] Epoch: [29]  [ 60/345]  eta: 0:01:11  lr: 0.000098  loss: 0.7745 (0.7706)  time: 0.2503  data: 0.0000  max mem: 10917
[14:59:30.566879] Epoch: [29]  [ 80/345]  eta: 0:01:06  lr: 0.000098  loss: 0.7706 (0.7712)  time: 0.2504  data: 0.0001  max mem: 10917
[14:59:35.581833] Epoch: [29]  [100/345]  eta: 0:01:01  lr: 0.000098  loss: 0.7644 (0.7702)  time: 0.2507  data: 0.0001  max mem: 10917
[14:59:40.599966] Epoch: [29]  [120/345]  eta: 0:00:56  lr: 0.000097  loss: 0.7708 (0.7701)  time: 0.2509  data: 0.0001  max mem: 10917
[14:59:45.623606] Epoch: [29]  [140/345]  eta: 0:00:51  lr: 0.000097  loss: 0.7637 (0.7693)  time: 0.2511  data: 0.0000  max mem: 10917
[14:59:50.648082] Epoch: [29]  [160/345]  eta: 0:00:46  lr: 0.000097  loss: 0.7767 (0.7703)  time: 0.2512  data: 0.0001  max mem: 10917
[14:59:55.672950] Epoch: [29]  [180/345]  eta: 0:00:41  lr: 0.000096  loss: 0.7668 (0.7707)  time: 0.2512  data: 0.0000  max mem: 10917
[15:00:00.702784] Epoch: [29]  [200/345]  eta: 0:00:36  lr: 0.000096  loss: 0.7573 (0.7699)  time: 0.2515  data: 0.0000  max mem: 10917
[15:00:05.731413] Epoch: [29]  [220/345]  eta: 0:00:31  lr: 0.000096  loss: 0.7616 (0.7694)  time: 0.2514  data: 0.0001  max mem: 10917
[15:00:10.765010] Epoch: [29]  [240/345]  eta: 0:00:26  lr: 0.000095  loss: 0.7622 (0.7692)  time: 0.2516  data: 0.0000  max mem: 10917
[15:00:15.798850] Epoch: [29]  [260/345]  eta: 0:00:21  lr: 0.000095  loss: 0.7557 (0.7684)  time: 0.2517  data: 0.0000  max mem: 10917
[15:00:20.833497] Epoch: [29]  [280/345]  eta: 0:00:16  lr: 0.000095  loss: 0.7683 (0.7682)  time: 0.2517  data: 0.0001  max mem: 10917
[15:00:25.871181] Epoch: [29]  [300/345]  eta: 0:00:11  lr: 0.000094  loss: 0.7552 (0.7678)  time: 0.2518  data: 0.0000  max mem: 10917
[15:00:30.908715] Epoch: [29]  [320/345]  eta: 0:00:06  lr: 0.000094  loss: 0.7686 (0.7678)  time: 0.2518  data: 0.0000  max mem: 10917
[15:00:35.948336] Epoch: [29]  [340/345]  eta: 0:00:01  lr: 0.000094  loss: 0.7655 (0.7677)  time: 0.2519  data: 0.0000  max mem: 10917
[15:00:36.958050] Epoch: [29]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.7634 (0.7677)  time: 0.2520  data: 0.0001  max mem: 10917
[15:00:36.997855] Epoch: [29] Total time: 0:01:26 (0.2517 s / it)
[15:00:36.998101] Averaged stats: lr: 0.000094  loss: 0.7634 (0.7677)
[15:00:37.236236] Test:  [  0/345]  eta: 0:01:20  loss: 0.7355 (0.7355)  time: 0.2346  data: 0.1545  max mem: 10917
[15:00:38.079813] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7355 (0.7356)  time: 0.0979  data: 0.0163  max mem: 10917
[15:00:38.902716] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7295 (0.7297)  time: 0.0833  data: 0.0013  max mem: 10917
[15:00:39.729916] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7265 (0.7310)  time: 0.0825  data: 0.0001  max mem: 10917
[15:00:40.561122] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7349 (0.7314)  time: 0.0829  data: 0.0001  max mem: 10917
[15:00:41.395653] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7349 (0.7315)  time: 0.0832  data: 0.0001  max mem: 10917
[15:00:42.233756] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7332 (0.7316)  time: 0.0836  data: 0.0001  max mem: 10917
[15:00:43.074542] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7297 (0.7317)  time: 0.0839  data: 0.0001  max mem: 10917
[15:00:43.919610] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7320 (0.7321)  time: 0.0842  data: 0.0001  max mem: 10917
[15:00:44.767802] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7288 (0.7322)  time: 0.0846  data: 0.0001  max mem: 10917
[15:00:45.620783] Test:  [100/345]  eta: 0:00:20  loss: 0.7288 (0.7324)  time: 0.0850  data: 0.0001  max mem: 10917
[15:00:46.476506] Test:  [110/345]  eta: 0:00:20  loss: 0.7355 (0.7328)  time: 0.0854  data: 0.0001  max mem: 10917
[15:00:47.335732] Test:  [120/345]  eta: 0:00:19  loss: 0.7309 (0.7323)  time: 0.0857  data: 0.0001  max mem: 10917
[15:00:48.198627] Test:  [130/345]  eta: 0:00:18  loss: 0.7321 (0.7329)  time: 0.0861  data: 0.0001  max mem: 10917
[15:00:49.065313] Test:  [140/345]  eta: 0:00:17  loss: 0.7380 (0.7333)  time: 0.0864  data: 0.0001  max mem: 10917
[15:00:49.935245] Test:  [150/345]  eta: 0:00:16  loss: 0.7355 (0.7335)  time: 0.0868  data: 0.0001  max mem: 10917
[15:00:50.808960] Test:  [160/345]  eta: 0:00:15  loss: 0.7320 (0.7337)  time: 0.0871  data: 0.0001  max mem: 10917
[15:00:51.686372] Test:  [170/345]  eta: 0:00:15  loss: 0.7344 (0.7339)  time: 0.0875  data: 0.0001  max mem: 10917
[15:00:52.566731] Test:  [180/345]  eta: 0:00:14  loss: 0.7352 (0.7341)  time: 0.0878  data: 0.0001  max mem: 10917
[15:00:53.451190] Test:  [190/345]  eta: 0:00:13  loss: 0.7347 (0.7340)  time: 0.0882  data: 0.0001  max mem: 10917
[15:00:54.337894] Test:  [200/345]  eta: 0:00:12  loss: 0.7315 (0.7340)  time: 0.0885  data: 0.0001  max mem: 10917
[15:00:55.229198] Test:  [210/345]  eta: 0:00:11  loss: 0.7315 (0.7340)  time: 0.0889  data: 0.0001  max mem: 10917
[15:00:56.122730] Test:  [220/345]  eta: 0:00:10  loss: 0.7247 (0.7333)  time: 0.0892  data: 0.0001  max mem: 10917
[15:00:57.020616] Test:  [230/345]  eta: 0:00:09  loss: 0.7237 (0.7335)  time: 0.0895  data: 0.0001  max mem: 10917
[15:00:57.921540] Test:  [240/345]  eta: 0:00:09  loss: 0.7288 (0.7335)  time: 0.0899  data: 0.0001  max mem: 10917
[15:00:58.825761] Test:  [250/345]  eta: 0:00:08  loss: 0.7290 (0.7336)  time: 0.0902  data: 0.0001  max mem: 10917
[15:00:59.734340] Test:  [260/345]  eta: 0:00:07  loss: 0.7290 (0.7336)  time: 0.0906  data: 0.0001  max mem: 10917
[15:01:00.647016] Test:  [270/345]  eta: 0:00:06  loss: 0.7296 (0.7337)  time: 0.0910  data: 0.0001  max mem: 10917
[15:01:01.562300] Test:  [280/345]  eta: 0:00:05  loss: 0.7301 (0.7337)  time: 0.0914  data: 0.0001  max mem: 10917
[15:01:02.480913] Test:  [290/345]  eta: 0:00:04  loss: 0.7358 (0.7340)  time: 0.0916  data: 0.0001  max mem: 10917
[15:01:03.403543] Test:  [300/345]  eta: 0:00:03  loss: 0.7356 (0.7338)  time: 0.0920  data: 0.0001  max mem: 10917
[15:01:04.328244] Test:  [310/345]  eta: 0:00:03  loss: 0.7264 (0.7338)  time: 0.0923  data: 0.0001  max mem: 10917
[15:01:05.257896] Test:  [320/345]  eta: 0:00:02  loss: 0.7306 (0.7337)  time: 0.0927  data: 0.0001  max mem: 10917
[15:01:06.191384] Test:  [330/345]  eta: 0:00:01  loss: 0.7311 (0.7338)  time: 0.0931  data: 0.0001  max mem: 10917
[15:01:07.127868] Test:  [340/345]  eta: 0:00:00  loss: 0.7320 (0.7337)  time: 0.0935  data: 0.0001  max mem: 10917
[15:01:07.504323] Test:  [344/345]  eta: 0:00:00  loss: 0.7267 (0.7336)  time: 0.0936  data: 0.0001  max mem: 10917
[15:01:07.560455] Test: Total time: 0:00:30 (0.0886 s / it)
[15:01:18.588714] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9142 (0.9142)  time: 0.2220  data: 0.1422  max mem: 10917
[15:01:19.402451] Test:  [10/57]  eta: 0:00:04  loss: 0.9142 (0.9102)  time: 0.0941  data: 0.0130  max mem: 10917
[15:01:20.219771] Test:  [20/57]  eta: 0:00:03  loss: 0.8918 (0.8911)  time: 0.0815  data: 0.0001  max mem: 10917
[15:01:21.040522] Test:  [30/57]  eta: 0:00:02  loss: 0.7884 (0.8523)  time: 0.0819  data: 0.0001  max mem: 10917
[15:01:21.865630] Test:  [40/57]  eta: 0:00:01  loss: 0.7807 (0.8326)  time: 0.0822  data: 0.0001  max mem: 10917
[15:01:22.693325] Test:  [50/57]  eta: 0:00:00  loss: 0.7715 (0.8253)  time: 0.0826  data: 0.0001  max mem: 10917
[15:01:23.143042] Test:  [56/57]  eta: 0:00:00  loss: 0.7979 (0.8294)  time: 0.0804  data: 0.0001  max mem: 10917
[15:01:23.198468] Test: Total time: 0:00:04 (0.0848 s / it)
[15:01:25.136061] Dice score of the network on the train images: 0.814781, val images: 0.812210
[15:01:25.140306] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:01:25.537944] Epoch: [30]  [  0/345]  eta: 0:02:16  lr: 0.000094  loss: 0.7876 (0.7876)  time: 0.3965  data: 0.1438  max mem: 10917
[15:01:30.539075] Epoch: [30]  [ 20/345]  eta: 0:01:23  lr: 0.000093  loss: 0.7608 (0.7636)  time: 0.2500  data: 0.0001  max mem: 10917

[15:01:35.529095] Epoch: [30]  [ 40/345]  eta: 0:01:17  lr: 0.000093  loss: 0.7587 (0.7619)  time: 0.2495  data: 0.0001  max mem: 10917
[15:01:40.521116] Epoch: [30]  [ 60/345]  eta: 0:01:11  lr: 0.000093  loss: 0.7674 (0.7623)  time: 0.2496  data: 0.0000  max mem: 10917

[15:01:45.516052] Epoch: [30]  [ 80/345]  eta: 0:01:06  lr: 0.000092  loss: 0.7560 (0.7617)  time: 0.2497  data: 0.0001  max mem: 10917
[15:01:50.520894] Epoch: [30]  [100/345]  eta: 0:01:01  lr: 0.000092  loss: 0.7671 (0.7625)  time: 0.2502  data: 0.0001  max mem: 10917

[15:01:55.529942] Epoch: [30]  [120/345]  eta: 0:00:56  lr: 0.000092  loss: 0.7716 (0.7647)  time: 0.2504  data: 0.0001  max mem: 10917
[15:02:00.539605] Epoch: [30]  [140/345]  eta: 0:00:51  lr: 0.000091  loss: 0.7700 (0.7663)  time: 0.2504  data: 0.0001  max mem: 10917

[15:02:05.552573] Epoch: [30]  [160/345]  eta: 0:00:46  lr: 0.000091  loss: 0.7616 (0.7663)  time: 0.2506  data: 0.0001  max mem: 10917
[15:02:10.644438] Epoch: [30]  [180/345]  eta: 0:00:41  lr: 0.000091  loss: 0.7675 (0.7665)  time: 0.2546  data: 0.0001  max mem: 10917
[15:02:15.657616] Epoch: [30]  [200/345]  eta: 0:00:36  lr: 0.000090  loss: 0.7654 (0.7665)  time: 0.2506  data: 0.0000  max mem: 10917
[15:02:20.675643] Epoch: [30]  [220/345]  eta: 0:00:31  lr: 0.000090  loss: 0.7651 (0.7668)  time: 0.2509  data: 0.0000  max mem: 10917
[15:02:25.697199] Epoch: [30]  [240/345]  eta: 0:00:26  lr: 0.000090  loss: 0.7626 (0.7669)  time: 0.2510  data: 0.0000  max mem: 10917
[15:02:30.720425] Epoch: [30]  [260/345]  eta: 0:00:21  lr: 0.000089  loss: 0.7617 (0.7665)  time: 0.2511  data: 0.0000  max mem: 10917
[15:02:35.745120] Epoch: [30]  [280/345]  eta: 0:00:16  lr: 0.000089  loss: 0.7572 (0.7659)  time: 0.2512  data: 0.0000  max mem: 10917
[15:02:40.771765] Epoch: [30]  [300/345]  eta: 0:00:11  lr: 0.000089  loss: 0.7593 (0.7656)  time: 0.2513  data: 0.0001  max mem: 10917
[15:02:45.799842] Epoch: [30]  [320/345]  eta: 0:00:06  lr: 0.000088  loss: 0.7555 (0.7652)  time: 0.2514  data: 0.0001  max mem: 10917
[15:02:50.830421] Epoch: [30]  [340/345]  eta: 0:00:01  lr: 0.000088  loss: 0.7640 (0.7650)  time: 0.2515  data: 0.0001  max mem: 10917
[15:02:51.837160] Epoch: [30]  [344/345]  eta: 0:00:00  lr: 0.000088  loss: 0.7657 (0.7651)  time: 0.2515  data: 0.0001  max mem: 10917
[15:02:51.900691] Epoch: [30] Total time: 0:01:26 (0.2515 s / it)
[15:02:51.901176] Averaged stats: lr: 0.000088  loss: 0.7657 (0.7651)
[15:02:52.140179] Test:  [  0/345]  eta: 0:01:21  loss: 0.7582 (0.7582)  time: 0.2362  data: 0.1560  max mem: 10917
[15:02:52.967646] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7651 (0.7778)  time: 0.0966  data: 0.0149  max mem: 10917
[15:02:53.795486] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7727 (0.7795)  time: 0.0827  data: 0.0006  max mem: 10917
[15:02:54.622165] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7758 (0.7806)  time: 0.0827  data: 0.0003  max mem: 10917
[15:02:55.453498] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7671 (0.7772)  time: 0.0829  data: 0.0001  max mem: 10917
[15:02:56.287615] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7652 (0.7780)  time: 0.0832  data: 0.0001  max mem: 10917
[15:02:57.125787] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7701 (0.7780)  time: 0.0836  data: 0.0001  max mem: 10917
[15:02:57.968239] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7851 (0.7796)  time: 0.0840  data: 0.0001  max mem: 10917
[15:02:58.814045] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7851 (0.7799)  time: 0.0844  data: 0.0001  max mem: 10917
[15:02:59.662850] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7760 (0.7800)  time: 0.0847  data: 0.0001  max mem: 10917
[15:03:00.515312] Test:  [100/345]  eta: 0:00:20  loss: 0.7731 (0.7785)  time: 0.0850  data: 0.0001  max mem: 10917
[15:03:01.371259] Test:  [110/345]  eta: 0:00:20  loss: 0.7673 (0.7785)  time: 0.0854  data: 0.0001  max mem: 10917
[15:03:02.230238] Test:  [120/345]  eta: 0:00:19  loss: 0.7874 (0.7792)  time: 0.0857  data: 0.0001  max mem: 10917
[15:03:03.093283] Test:  [130/345]  eta: 0:00:18  loss: 0.7893 (0.7796)  time: 0.0861  data: 0.0001  max mem: 10917
[15:03:03.958837] Test:  [140/345]  eta: 0:00:17  loss: 0.7858 (0.7801)  time: 0.0864  data: 0.0001  max mem: 10917
[15:03:04.827609] Test:  [150/345]  eta: 0:00:16  loss: 0.7832 (0.7804)  time: 0.0867  data: 0.0001  max mem: 10917
[15:03:05.700683] Test:  [160/345]  eta: 0:00:15  loss: 0.7792 (0.7795)  time: 0.0870  data: 0.0001  max mem: 10917
[15:03:06.577831] Test:  [170/345]  eta: 0:00:15  loss: 0.7792 (0.7796)  time: 0.0875  data: 0.0001  max mem: 10917
[15:03:07.458019] Test:  [180/345]  eta: 0:00:14  loss: 0.7778 (0.7795)  time: 0.0878  data: 0.0001  max mem: 10917
[15:03:08.342613] Test:  [190/345]  eta: 0:00:13  loss: 0.7796 (0.7797)  time: 0.0882  data: 0.0001  max mem: 10917
[15:03:09.230836] Test:  [200/345]  eta: 0:00:12  loss: 0.7743 (0.7793)  time: 0.0886  data: 0.0001  max mem: 10917
[15:03:10.122046] Test:  [210/345]  eta: 0:00:11  loss: 0.7743 (0.7794)  time: 0.0889  data: 0.0001  max mem: 10917
[15:03:11.017102] Test:  [220/345]  eta: 0:00:10  loss: 0.7808 (0.7799)  time: 0.0893  data: 0.0001  max mem: 10917
[15:03:11.915737] Test:  [230/345]  eta: 0:00:09  loss: 0.7790 (0.7798)  time: 0.0896  data: 0.0001  max mem: 10917
[15:03:12.817276] Test:  [240/345]  eta: 0:00:09  loss: 0.7781 (0.7800)  time: 0.0900  data: 0.0001  max mem: 10917
[15:03:13.723080] Test:  [250/345]  eta: 0:00:08  loss: 0.7788 (0.7800)  time: 0.0903  data: 0.0001  max mem: 10917
[15:03:14.631881] Test:  [260/345]  eta: 0:00:07  loss: 0.7792 (0.7799)  time: 0.0907  data: 0.0001  max mem: 10917
[15:03:15.544266] Test:  [270/345]  eta: 0:00:06  loss: 0.7813 (0.7801)  time: 0.0910  data: 0.0001  max mem: 10917
[15:03:16.459882] Test:  [280/345]  eta: 0:00:05  loss: 0.7778 (0.7797)  time: 0.0914  data: 0.0001  max mem: 10917
[15:03:17.379006] Test:  [290/345]  eta: 0:00:04  loss: 0.7830 (0.7804)  time: 0.0917  data: 0.0001  max mem: 10917
[15:03:18.301878] Test:  [300/345]  eta: 0:00:03  loss: 0.7907 (0.7804)  time: 0.0921  data: 0.0001  max mem: 10917
[15:03:19.227701] Test:  [310/345]  eta: 0:00:03  loss: 0.7792 (0.7804)  time: 0.0924  data: 0.0001  max mem: 10917
[15:03:20.157802] Test:  [320/345]  eta: 0:00:02  loss: 0.7792 (0.7805)  time: 0.0927  data: 0.0001  max mem: 10917
[15:03:21.090482] Test:  [330/345]  eta: 0:00:01  loss: 0.7796 (0.7805)  time: 0.0931  data: 0.0001  max mem: 10917
[15:03:22.026903] Test:  [340/345]  eta: 0:00:00  loss: 0.7778 (0.7803)  time: 0.0934  data: 0.0001  max mem: 10917
[15:03:22.403661] Test:  [344/345]  eta: 0:00:00  loss: 0.7759 (0.7802)  time: 0.0936  data: 0.0001  max mem: 10917
[15:03:22.462278] Test: Total time: 0:00:30 (0.0886 s / it)
[15:03:33.549013] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9305 (0.9305)  time: 0.2223  data: 0.1422  max mem: 10917
[15:03:34.363175] Test:  [10/57]  eta: 0:00:04  loss: 0.9429 (0.9519)  time: 0.0941  data: 0.0131  max mem: 10917
[15:03:35.180517] Test:  [20/57]  eta: 0:00:03  loss: 0.9429 (0.9278)  time: 0.0815  data: 0.0001  max mem: 10917
[15:03:36.001361] Test:  [30/57]  eta: 0:00:02  loss: 0.8151 (0.8828)  time: 0.0819  data: 0.0001  max mem: 10917
[15:03:36.825588] Test:  [40/57]  eta: 0:00:01  loss: 0.7906 (0.8583)  time: 0.0822  data: 0.0001  max mem: 10917
[15:03:37.652738] Test:  [50/57]  eta: 0:00:00  loss: 0.7786 (0.8480)  time: 0.0825  data: 0.0001  max mem: 10917
[15:03:38.102594] Test:  [56/57]  eta: 0:00:00  loss: 0.8037 (0.8511)  time: 0.0803  data: 0.0001  max mem: 10917
[15:03:38.154645] Test: Total time: 0:00:04 (0.0847 s / it)
[15:03:40.114431] Dice score of the network on the train images: 0.796625, val images: 0.793140
[15:03:40.117894] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:03:40.521980] Epoch: [31]  [  0/345]  eta: 0:02:19  lr: 0.000088  loss: 0.8417 (0.8417)  time: 0.4029  data: 0.1502  max mem: 10917
[15:03:45.524806] Epoch: [31]  [ 20/345]  eta: 0:01:23  lr: 0.000088  loss: 0.7848 (0.7948)  time: 0.2501  data: 0.0001  max mem: 10917
[15:03:50.527943] Epoch: [31]  [ 40/345]  eta: 0:01:17  lr: 0.000087  loss: 0.7770 (0.7891)  time: 0.2501  data: 0.0001  max mem: 10917
[15:03:55.538344] Epoch: [31]  [ 60/345]  eta: 0:01:12  lr: 0.000087  loss: 0.7658 (0.7811)  time: 0.2505  data: 0.0001  max mem: 10917
[15:04:00.552853] Epoch: [31]  [ 80/345]  eta: 0:01:06  lr: 0.000087  loss: 0.7758 (0.7806)  time: 0.2507  data: 0.0001  max mem: 10917
[15:04:05.568735] Epoch: [31]  [100/345]  eta: 0:01:01  lr: 0.000086  loss: 0.7814 (0.7810)  time: 0.2507  data: 0.0001  max mem: 10917
[15:04:10.589831] Epoch: [31]  [120/345]  eta: 0:00:56  lr: 0.000086  loss: 0.7691 (0.7800)  time: 0.2510  data: 0.0001  max mem: 10917
[15:04:15.611650] Epoch: [31]  [140/345]  eta: 0:00:51  lr: 0.000085  loss: 0.7929 (0.7812)  time: 0.2510  data: 0.0001  max mem: 10917
[15:04:20.637030] Epoch: [31]  [160/345]  eta: 0:00:46  lr: 0.000085  loss: 0.7724 (0.7805)  time: 0.2512  data: 0.0001  max mem: 10917
[15:04:25.665872] Epoch: [31]  [180/345]  eta: 0:00:41  lr: 0.000085  loss: 0.7632 (0.7789)  time: 0.2514  data: 0.0000  max mem: 10917
[15:04:30.698041] Epoch: [31]  [200/345]  eta: 0:00:36  lr: 0.000084  loss: 0.7634 (0.7776)  time: 0.2516  data: 0.0000  max mem: 10917

[15:04:35.730737] Epoch: [31]  [220/345]  eta: 0:00:31  lr: 0.000084  loss: 0.7649 (0.7765)  time: 0.2516  data: 0.0000  max mem: 10917
[15:04:40.765710] Epoch: [31]  [240/345]  eta: 0:00:26  lr: 0.000084  loss: 0.7592 (0.7753)  time: 0.2517  data: 0.0001  max mem: 10917
[15:04:45.807236] Epoch: [31]  [260/345]  eta: 0:00:21  lr: 0.000083  loss: 0.7604 (0.7744)  time: 0.2520  data: 0.0001  max mem: 10917
[15:04:50.849647] Epoch: [31]  [280/345]  eta: 0:00:16  lr: 0.000083  loss: 0.7633 (0.7736)  time: 0.2521  data: 0.0000  max mem: 10917
[15:04:55.892870] Epoch: [31]  [300/345]  eta: 0:00:11  lr: 0.000083  loss: 0.7664 (0.7731)  time: 0.2521  data: 0.0001  max mem: 10917
[15:05:00.939161] Epoch: [31]  [320/345]  eta: 0:00:06  lr: 0.000082  loss: 0.7706 (0.7727)  time: 0.2523  data: 0.0001  max mem: 10917
[15:05:05.987870] Epoch: [31]  [340/345]  eta: 0:00:01  lr: 0.000082  loss: 0.7597 (0.7719)  time: 0.2524  data: 0.0000  max mem: 10917
[15:05:06.997112] Epoch: [31]  [344/345]  eta: 0:00:00  lr: 0.000082  loss: 0.7597 (0.7717)  time: 0.2523  data: 0.0001  max mem: 10917
[15:05:07.047562] Epoch: [31] Total time: 0:01:26 (0.2520 s / it)
[15:05:07.048052] Averaged stats: lr: 0.000082  loss: 0.7597 (0.7717)
[15:05:07.286980] Test:  [  0/345]  eta: 0:01:21  loss: 0.7235 (0.7235)  time: 0.2354  data: 0.1558  max mem: 10917
[15:05:08.146807] Test:  [ 10/345]  eta: 0:00:33  loss: 0.7267 (0.7282)  time: 0.0995  data: 0.0181  max mem: 10917
[15:05:08.971125] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7284 (0.7309)  time: 0.0841  data: 0.0022  max mem: 10917
[15:05:09.797888] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7323 (0.7322)  time: 0.0825  data: 0.0001  max mem: 10917
[15:05:10.629515] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7285 (0.7309)  time: 0.0829  data: 0.0001  max mem: 10917
[15:05:11.463432] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7373 (0.7327)  time: 0.0832  data: 0.0001  max mem: 10917
[15:05:12.301174] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7327 (0.7311)  time: 0.0835  data: 0.0001  max mem: 10917
[15:05:13.142832] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7280 (0.7324)  time: 0.0839  data: 0.0001  max mem: 10917
[15:05:13.988385] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7321 (0.7323)  time: 0.0843  data: 0.0001  max mem: 10917
[15:05:14.836591] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7323 (0.7328)  time: 0.0846  data: 0.0001  max mem: 10917
[15:05:15.688284] Test:  [100/345]  eta: 0:00:20  loss: 0.7360 (0.7330)  time: 0.0849  data: 0.0001  max mem: 10917
[15:05:16.542989] Test:  [110/345]  eta: 0:00:20  loss: 0.7343 (0.7338)  time: 0.0853  data: 0.0001  max mem: 10917
[15:05:17.401596] Test:  [120/345]  eta: 0:00:19  loss: 0.7340 (0.7337)  time: 0.0856  data: 0.0001  max mem: 10917
[15:05:18.263847] Test:  [130/345]  eta: 0:00:18  loss: 0.7340 (0.7340)  time: 0.0860  data: 0.0001  max mem: 10917
[15:05:19.129944] Test:  [140/345]  eta: 0:00:17  loss: 0.7290 (0.7336)  time: 0.0864  data: 0.0001  max mem: 10917
[15:05:19.999634] Test:  [150/345]  eta: 0:00:16  loss: 0.7284 (0.7331)  time: 0.0867  data: 0.0001  max mem: 10917
[15:05:20.872290] Test:  [160/345]  eta: 0:00:15  loss: 0.7295 (0.7335)  time: 0.0871  data: 0.0001  max mem: 10917
[15:05:21.749435] Test:  [170/345]  eta: 0:00:15  loss: 0.7295 (0.7336)  time: 0.0874  data: 0.0001  max mem: 10917
[15:05:22.630044] Test:  [180/345]  eta: 0:00:14  loss: 0.7291 (0.7335)  time: 0.0878  data: 0.0001  max mem: 10917
[15:05:23.514901] Test:  [190/345]  eta: 0:00:13  loss: 0.7253 (0.7333)  time: 0.0882  data: 0.0001  max mem: 10917
[15:05:24.402632] Test:  [200/345]  eta: 0:00:12  loss: 0.7234 (0.7331)  time: 0.0886  data: 0.0001  max mem: 10917
[15:05:25.293895] Test:  [210/345]  eta: 0:00:11  loss: 0.7260 (0.7330)  time: 0.0889  data: 0.0001  max mem: 10917
[15:05:26.188184] Test:  [220/345]  eta: 0:00:10  loss: 0.7365 (0.7333)  time: 0.0892  data: 0.0001  max mem: 10917
[15:05:27.086059] Test:  [230/345]  eta: 0:00:09  loss: 0.7370 (0.7337)  time: 0.0896  data: 0.0001  max mem: 10917
[15:05:27.987048] Test:  [240/345]  eta: 0:00:09  loss: 0.7354 (0.7337)  time: 0.0899  data: 0.0001  max mem: 10917
[15:05:28.891651] Test:  [250/345]  eta: 0:00:08  loss: 0.7368 (0.7340)  time: 0.0902  data: 0.0001  max mem: 10917
[15:05:29.800062] Test:  [260/345]  eta: 0:00:07  loss: 0.7415 (0.7342)  time: 0.0906  data: 0.0001  max mem: 10917
[15:05:30.713472] Test:  [270/345]  eta: 0:00:06  loss: 0.7345 (0.7344)  time: 0.0910  data: 0.0001  max mem: 10917
[15:05:31.629360] Test:  [280/345]  eta: 0:00:05  loss: 0.7345 (0.7345)  time: 0.0914  data: 0.0001  max mem: 10917
[15:05:32.548339] Test:  [290/345]  eta: 0:00:04  loss: 0.7292 (0.7344)  time: 0.0917  data: 0.0001  max mem: 10917
[15:05:33.470890] Test:  [300/345]  eta: 0:00:03  loss: 0.7292 (0.7345)  time: 0.0920  data: 0.0001  max mem: 10917
[15:05:34.395962] Test:  [310/345]  eta: 0:00:03  loss: 0.7299 (0.7343)  time: 0.0923  data: 0.0001  max mem: 10917
[15:05:35.325508] Test:  [320/345]  eta: 0:00:02  loss: 0.7299 (0.7342)  time: 0.0927  data: 0.0001  max mem: 10917
[15:05:36.258312] Test:  [330/345]  eta: 0:00:01  loss: 0.7311 (0.7341)  time: 0.0931  data: 0.0001  max mem: 10917
[15:05:37.194757] Test:  [340/345]  eta: 0:00:00  loss: 0.7287 (0.7339)  time: 0.0934  data: 0.0001  max mem: 10917
[15:05:37.570520] Test:  [344/345]  eta: 0:00:00  loss: 0.7288 (0.7339)  time: 0.0935  data: 0.0001  max mem: 10917
[15:05:37.628894] Test: Total time: 0:00:30 (0.0886 s / it)
[15:05:48.741521] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9240 (0.9240)  time: 0.2212  data: 0.1414  max mem: 10917
[15:05:49.555500] Test:  [10/57]  eta: 0:00:04  loss: 0.9240 (0.9256)  time: 0.0940  data: 0.0129  max mem: 10917
[15:05:50.371336] Test:  [20/57]  eta: 0:00:03  loss: 0.9124 (0.9056)  time: 0.0814  data: 0.0001  max mem: 10917
[15:05:51.192246] Test:  [30/57]  eta: 0:00:02  loss: 0.7974 (0.8616)  time: 0.0818  data: 0.0001  max mem: 10917
[15:05:52.017951] Test:  [40/57]  eta: 0:00:01  loss: 0.7670 (0.8386)  time: 0.0823  data: 0.0001  max mem: 10917
[15:05:52.845547] Test:  [50/57]  eta: 0:00:00  loss: 0.7679 (0.8296)  time: 0.0826  data: 0.0001  max mem: 10917
[15:05:53.295760] Test:  [56/57]  eta: 0:00:00  loss: 0.7893 (0.8336)  time: 0.0804  data: 0.0001  max mem: 10917
[15:05:53.337610] Test: Total time: 0:00:04 (0.0845 s / it)
[15:05:55.340097] Dice score of the network on the train images: 0.817408, val images: 0.816153
[15:05:55.340362] saving best_dice_model_0 @ epoch 31
[15:05:56.191016] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:05:56.594283] Epoch: [32]  [  0/345]  eta: 0:02:18  lr: 0.000082  loss: 0.7786 (0.7786)  time: 0.4021  data: 0.1489  max mem: 10917
[15:06:01.585838] Epoch: [32]  [ 20/345]  eta: 0:01:23  lr: 0.000081  loss: 0.7668 (0.7701)  time: 0.2495  data: 0.0001  max mem: 10917
[15:06:06.580939] Epoch: [32]  [ 40/345]  eta: 0:01:17  lr: 0.000081  loss: 0.7557 (0.7666)  time: 0.2497  data: 0.0001  max mem: 10917
[15:06:11.580978] Epoch: [32]  [ 60/345]  eta: 0:01:11  lr: 0.000081  loss: 0.7600 (0.7649)  time: 0.2500  data: 0.0001  max mem: 10917
[15:06:16.590163] Epoch: [32]  [ 80/345]  eta: 0:01:06  lr: 0.000080  loss: 0.7494 (0.7614)  time: 0.2504  data: 0.0000  max mem: 10917
[15:06:21.607478] Epoch: [32]  [100/345]  eta: 0:01:01  lr: 0.000080  loss: 0.7543 (0.7603)  time: 0.2508  data: 0.0000  max mem: 10917
[15:06:26.626084] Epoch: [32]  [120/345]  eta: 0:00:56  lr: 0.000080  loss: 0.7533 (0.7598)  time: 0.2509  data: 0.0000  max mem: 10917
[15:06:31.643616] Epoch: [32]  [140/345]  eta: 0:00:51  lr: 0.000079  loss: 0.7571 (0.7594)  time: 0.2508  data: 0.0000  max mem: 10917
[15:06:36.664436] Epoch: [32]  [160/345]  eta: 0:00:46  lr: 0.000079  loss: 0.7610 (0.7600)  time: 0.2510  data: 0.0001  max mem: 10917
[15:06:41.687943] Epoch: [32]  [180/345]  eta: 0:00:41  lr: 0.000079  loss: 0.7535 (0.7598)  time: 0.2511  data: 0.0001  max mem: 10917
[15:06:46.711451] Epoch: [32]  [200/345]  eta: 0:00:36  lr: 0.000078  loss: 0.7576 (0.7591)  time: 0.2511  data: 0.0001  max mem: 10917
[15:06:51.741514] Epoch: [32]  [220/345]  eta: 0:00:31  lr: 0.000078  loss: 0.7552 (0.7587)  time: 0.2515  data: 0.0001  max mem: 10917
[15:06:56.775949] Epoch: [32]  [240/345]  eta: 0:00:26  lr: 0.000077  loss: 0.7519 (0.7587)  time: 0.2517  data: 0.0000  max mem: 10917
[15:07:01.810357] Epoch: [32]  [260/345]  eta: 0:00:21  lr: 0.000077  loss: 0.7545 (0.7584)  time: 0.2517  data: 0.0000  max mem: 10917
[15:07:06.848442] Epoch: [32]  [280/345]  eta: 0:00:16  lr: 0.000077  loss: 0.7564 (0.7583)  time: 0.2519  data: 0.0001  max mem: 10917
[15:07:11.889323] Epoch: [32]  [300/345]  eta: 0:00:11  lr: 0.000076  loss: 0.7532 (0.7584)  time: 0.2520  data: 0.0001  max mem: 10917
[15:07:16.923959] Epoch: [32]  [320/345]  eta: 0:00:06  lr: 0.000076  loss: 0.7537 (0.7582)  time: 0.2517  data: 0.0001  max mem: 10917
[15:07:21.951466] Epoch: [32]  [340/345]  eta: 0:00:01  lr: 0.000076  loss: 0.7565 (0.7581)  time: 0.2513  data: 0.0001  max mem: 10917
[15:07:22.958753] Epoch: [32]  [344/345]  eta: 0:00:00  lr: 0.000076  loss: 0.7565 (0.7582)  time: 0.2514  data: 0.0001  max mem: 10917
[15:07:23.015856] Epoch: [32] Total time: 0:01:26 (0.2517 s / it)
[15:07:23.016286] Averaged stats: lr: 0.000076  loss: 0.7565 (0.7582)
[15:07:23.259139] Test:  [  0/345]  eta: 0:01:22  loss: 0.6961 (0.6961)  time: 0.2400  data: 0.1598  max mem: 10917
[15:07:24.085489] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7172 (0.7177)  time: 0.0969  data: 0.0152  max mem: 10917
[15:07:24.909799] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7172 (0.7183)  time: 0.0825  data: 0.0004  max mem: 10917
[15:07:25.736845] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7180 (0.7199)  time: 0.0825  data: 0.0001  max mem: 10917
[15:07:26.567897] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7180 (0.7207)  time: 0.0829  data: 0.0001  max mem: 10917
[15:07:27.402711] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7196 (0.7214)  time: 0.0832  data: 0.0001  max mem: 10917
[15:07:28.240506] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7176 (0.7207)  time: 0.0836  data: 0.0001  max mem: 10917
[15:07:29.082501] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7176 (0.7215)  time: 0.0839  data: 0.0001  max mem: 10917
[15:07:29.928530] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7224 (0.7215)  time: 0.0844  data: 0.0001  max mem: 10917
[15:07:30.778018] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7242 (0.7220)  time: 0.0847  data: 0.0001  max mem: 10917
[15:07:31.631194] Test:  [100/345]  eta: 0:00:20  loss: 0.7259 (0.7220)  time: 0.0851  data: 0.0001  max mem: 10917
[15:07:32.487867] Test:  [110/345]  eta: 0:00:20  loss: 0.7240 (0.7218)  time: 0.0854  data: 0.0001  max mem: 10917
[15:07:33.347706] Test:  [120/345]  eta: 0:00:19  loss: 0.7236 (0.7222)  time: 0.0858  data: 0.0001  max mem: 10917
[15:07:34.211119] Test:  [130/345]  eta: 0:00:18  loss: 0.7262 (0.7227)  time: 0.0861  data: 0.0001  max mem: 10917
[15:07:35.077385] Test:  [140/345]  eta: 0:00:17  loss: 0.7297 (0.7231)  time: 0.0864  data: 0.0001  max mem: 10917
[15:07:35.947636] Test:  [150/345]  eta: 0:00:16  loss: 0.7201 (0.7228)  time: 0.0868  data: 0.0001  max mem: 10917
[15:07:36.821489] Test:  [160/345]  eta: 0:00:15  loss: 0.7181 (0.7227)  time: 0.0872  data: 0.0001  max mem: 10917
[15:07:37.697729] Test:  [170/345]  eta: 0:00:15  loss: 0.7241 (0.7229)  time: 0.0875  data: 0.0001  max mem: 10917
[15:07:38.578146] Test:  [180/345]  eta: 0:00:14  loss: 0.7228 (0.7229)  time: 0.0878  data: 0.0001  max mem: 10917
[15:07:39.462473] Test:  [190/345]  eta: 0:00:13  loss: 0.7228 (0.7230)  time: 0.0882  data: 0.0001  max mem: 10917
[15:07:40.350498] Test:  [200/345]  eta: 0:00:12  loss: 0.7230 (0.7233)  time: 0.0886  data: 0.0001  max mem: 10917
[15:07:41.241446] Test:  [210/345]  eta: 0:00:11  loss: 0.7221 (0.7233)  time: 0.0889  data: 0.0001  max mem: 10917
[15:07:42.136192] Test:  [220/345]  eta: 0:00:10  loss: 0.7226 (0.7234)  time: 0.0892  data: 0.0001  max mem: 10917
[15:07:43.034673] Test:  [230/345]  eta: 0:00:09  loss: 0.7241 (0.7235)  time: 0.0896  data: 0.0001  max mem: 10917
[15:07:43.936604] Test:  [240/345]  eta: 0:00:09  loss: 0.7240 (0.7234)  time: 0.0900  data: 0.0001  max mem: 10917
[15:07:44.842358] Test:  [250/345]  eta: 0:00:08  loss: 0.7196 (0.7235)  time: 0.0903  data: 0.0001  max mem: 10917
[15:07:45.751635] Test:  [260/345]  eta: 0:00:07  loss: 0.7136 (0.7231)  time: 0.0907  data: 0.0001  max mem: 10917
[15:07:46.664026] Test:  [270/345]  eta: 0:00:06  loss: 0.7113 (0.7231)  time: 0.0910  data: 0.0001  max mem: 10917
[15:07:47.579411] Test:  [280/345]  eta: 0:00:05  loss: 0.7208 (0.7229)  time: 0.0913  data: 0.0001  max mem: 10917
[15:07:48.498613] Test:  [290/345]  eta: 0:00:04  loss: 0.7230 (0.7233)  time: 0.0917  data: 0.0001  max mem: 10917
[15:07:49.421092] Test:  [300/345]  eta: 0:00:03  loss: 0.7179 (0.7229)  time: 0.0920  data: 0.0001  max mem: 10917
[15:07:50.347050] Test:  [310/345]  eta: 0:00:03  loss: 0.7163 (0.7231)  time: 0.0924  data: 0.0001  max mem: 10917
[15:07:51.275642] Test:  [320/345]  eta: 0:00:02  loss: 0.7196 (0.7229)  time: 0.0927  data: 0.0001  max mem: 10917
[15:07:52.209501] Test:  [330/345]  eta: 0:00:01  loss: 0.7196 (0.7229)  time: 0.0931  data: 0.0001  max mem: 10917
[15:07:53.146334] Test:  [340/345]  eta: 0:00:00  loss: 0.7240 (0.7232)  time: 0.0935  data: 0.0001  max mem: 10917
[15:07:53.522600] Test:  [344/345]  eta: 0:00:00  loss: 0.7256 (0.7232)  time: 0.0936  data: 0.0001  max mem: 10917
[15:07:53.579940] Test: Total time: 0:00:30 (0.0886 s / it)
[15:08:04.714600] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9059 (0.9059)  time: 0.2158  data: 0.1359  max mem: 10917
[15:08:05.527755] Test:  [10/57]  eta: 0:00:04  loss: 0.9059 (0.9066)  time: 0.0935  data: 0.0124  max mem: 10917
[15:08:06.344075] Test:  [20/57]  eta: 0:00:03  loss: 0.8975 (0.8919)  time: 0.0814  data: 0.0001  max mem: 10917
[15:08:07.164739] Test:  [30/57]  eta: 0:00:02  loss: 0.7871 (0.8518)  time: 0.0818  data: 0.0001  max mem: 10917
[15:08:07.988900] Test:  [40/57]  eta: 0:00:01  loss: 0.7758 (0.8314)  time: 0.0822  data: 0.0001  max mem: 10917
[15:08:08.817134] Test:  [50/57]  eta: 0:00:00  loss: 0.7659 (0.8247)  time: 0.0826  data: 0.0001  max mem: 10917
[15:08:09.266921] Test:  [56/57]  eta: 0:00:00  loss: 0.8008 (0.8295)  time: 0.0804  data: 0.0001  max mem: 10917
[15:08:09.325576] Test: Total time: 0:00:04 (0.0847 s / it)
[15:08:11.293099] Dice score of the network on the train images: 0.819967, val images: 0.813492
[15:08:11.297552] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:08:11.699202] Epoch: [33]  [  0/345]  eta: 0:02:18  lr: 0.000075  loss: 0.7293 (0.7293)  time: 0.4007  data: 0.1488  max mem: 10917
[15:08:16.697389] Epoch: [33]  [ 20/345]  eta: 0:01:23  lr: 0.000075  loss: 0.7511 (0.7529)  time: 0.2499  data: 0.0000  max mem: 10917
[15:08:21.702188] Epoch: [33]  [ 40/345]  eta: 0:01:17  lr: 0.000075  loss: 0.7501 (0.7533)  time: 0.2502  data: 0.0000  max mem: 10917
[15:08:26.713829] Epoch: [33]  [ 60/345]  eta: 0:01:12  lr: 0.000074  loss: 0.7533 (0.7536)  time: 0.2505  data: 0.0000  max mem: 10917
[15:08:31.729186] Epoch: [33]  [ 80/345]  eta: 0:01:06  lr: 0.000074  loss: 0.7564 (0.7545)  time: 0.2507  data: 0.0000  max mem: 10917
[15:08:36.748898] Epoch: [33]  [100/345]  eta: 0:01:01  lr: 0.000074  loss: 0.7497 (0.7544)  time: 0.2509  data: 0.0000  max mem: 10917
[15:08:41.771118] Epoch: [33]  [120/345]  eta: 0:00:56  lr: 0.000073  loss: 0.7496 (0.7546)  time: 0.2511  data: 0.0000  max mem: 10917
[15:08:46.793106] Epoch: [33]  [140/345]  eta: 0:00:51  lr: 0.000073  loss: 0.7588 (0.7550)  time: 0.2511  data: 0.0001  max mem: 10917
[15:08:51.800937] Epoch: [33]  [160/345]  eta: 0:00:46  lr: 0.000073  loss: 0.7631 (0.7558)  time: 0.2503  data: 0.0001  max mem: 10917
[15:08:56.823905] Epoch: [33]  [180/345]  eta: 0:00:41  lr: 0.000072  loss: 0.7565 (0.7558)  time: 0.2511  data: 0.0001  max mem: 10917
[15:09:01.844264] Epoch: [33]  [200/345]  eta: 0:00:36  lr: 0.000072  loss: 0.7508 (0.7558)  time: 0.2510  data: 0.0001  max mem: 10917
[15:09:06.867204] Epoch: [33]  [220/345]  eta: 0:00:31  lr: 0.000071  loss: 0.7600 (0.7564)  time: 0.2511  data: 0.0001  max mem: 10917
[15:09:11.967149] Epoch: [33]  [240/345]  eta: 0:00:26  lr: 0.000071  loss: 0.7515 (0.7564)  time: 0.2550  data: 0.0001  max mem: 10917
[15:09:16.990082] Epoch: [33]  [260/345]  eta: 0:00:21  lr: 0.000071  loss: 0.7536 (0.7566)  time: 0.2511  data: 0.0000  max mem: 10917
[15:09:22.012625] Epoch: [33]  [280/345]  eta: 0:00:16  lr: 0.000070  loss: 0.7538 (0.7566)  time: 0.2511  data: 0.0001  max mem: 10917
[15:09:27.039984] Epoch: [33]  [300/345]  eta: 0:00:11  lr: 0.000070  loss: 0.7571 (0.7571)  time: 0.2513  data: 0.0001  max mem: 10917
[15:09:32.069405] Epoch: [33]  [320/345]  eta: 0:00:06  lr: 0.000070  loss: 0.7578 (0.7571)  time: 0.2514  data: 0.0001  max mem: 10917
[15:09:37.095934] Epoch: [33]  [340/345]  eta: 0:00:01  lr: 0.000069  loss: 0.7557 (0.7572)  time: 0.2513  data: 0.0001  max mem: 10917
[15:09:38.103761] Epoch: [33]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.7547 (0.7572)  time: 0.2513  data: 0.0001  max mem: 10917
[15:09:38.165258] Epoch: [33] Total time: 0:01:26 (0.2518 s / it)
[15:09:38.165695] Averaged stats: lr: 0.000069  loss: 0.7547 (0.7572)
[15:09:38.401961] Test:  [  0/345]  eta: 0:01:20  loss: 0.7280 (0.7280)  time: 0.2332  data: 0.1532  max mem: 10917
[15:09:39.231670] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7205 (0.7212)  time: 0.0965  data: 0.0148  max mem: 10917
[15:09:40.055433] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7167 (0.7194)  time: 0.0826  data: 0.0005  max mem: 10917
[15:09:40.884429] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7167 (0.7197)  time: 0.0826  data: 0.0001  max mem: 10917
[15:09:41.715206] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7232 (0.7209)  time: 0.0829  data: 0.0001  max mem: 10917
[15:09:42.549631] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7225 (0.7218)  time: 0.0832  data: 0.0001  max mem: 10917
[15:09:43.388444] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7201 (0.7221)  time: 0.0836  data: 0.0001  max mem: 10917
[15:09:44.230247] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7215 (0.7226)  time: 0.0840  data: 0.0001  max mem: 10917
[15:09:45.074966] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7238 (0.7229)  time: 0.0843  data: 0.0001  max mem: 10917
[15:09:45.923830] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7181 (0.7227)  time: 0.0846  data: 0.0001  max mem: 10917
[15:09:46.775191] Test:  [100/345]  eta: 0:00:20  loss: 0.7176 (0.7228)  time: 0.0850  data: 0.0001  max mem: 10917
[15:09:47.630746] Test:  [110/345]  eta: 0:00:20  loss: 0.7189 (0.7229)  time: 0.0853  data: 0.0001  max mem: 10917
[15:09:48.490780] Test:  [120/345]  eta: 0:00:19  loss: 0.7259 (0.7232)  time: 0.0857  data: 0.0001  max mem: 10917
[15:09:49.353990] Test:  [130/345]  eta: 0:00:18  loss: 0.7266 (0.7231)  time: 0.0861  data: 0.0001  max mem: 10917
[15:09:50.220164] Test:  [140/345]  eta: 0:00:17  loss: 0.7205 (0.7228)  time: 0.0864  data: 0.0001  max mem: 10917
[15:09:51.090116] Test:  [150/345]  eta: 0:00:16  loss: 0.7205 (0.7234)  time: 0.0868  data: 0.0001  max mem: 10917
[15:09:51.962853] Test:  [160/345]  eta: 0:00:15  loss: 0.7196 (0.7231)  time: 0.0871  data: 0.0001  max mem: 10917
[15:09:52.839516] Test:  [170/345]  eta: 0:00:15  loss: 0.7172 (0.7232)  time: 0.0874  data: 0.0001  max mem: 10917
[15:09:53.720466] Test:  [180/345]  eta: 0:00:14  loss: 0.7269 (0.7238)  time: 0.0878  data: 0.0001  max mem: 10917
[15:09:54.603964] Test:  [190/345]  eta: 0:00:13  loss: 0.7269 (0.7239)  time: 0.0882  data: 0.0001  max mem: 10917
[15:09:55.492083] Test:  [200/345]  eta: 0:00:12  loss: 0.7196 (0.7239)  time: 0.0885  data: 0.0001  max mem: 10917
[15:09:56.383728] Test:  [210/345]  eta: 0:00:11  loss: 0.7231 (0.7241)  time: 0.0889  data: 0.0001  max mem: 10917
[15:09:57.278247] Test:  [220/345]  eta: 0:00:10  loss: 0.7231 (0.7243)  time: 0.0893  data: 0.0001  max mem: 10917
[15:09:58.175331] Test:  [230/345]  eta: 0:00:09  loss: 0.7223 (0.7246)  time: 0.0895  data: 0.0001  max mem: 10917
[15:09:59.076385] Test:  [240/345]  eta: 0:00:09  loss: 0.7219 (0.7245)  time: 0.0899  data: 0.0001  max mem: 10917
[15:09:59.981538] Test:  [250/345]  eta: 0:00:08  loss: 0.7254 (0.7244)  time: 0.0903  data: 0.0001  max mem: 10917
[15:10:00.890551] Test:  [260/345]  eta: 0:00:07  loss: 0.7267 (0.7247)  time: 0.0907  data: 0.0001  max mem: 10917
[15:10:01.803108] Test:  [270/345]  eta: 0:00:06  loss: 0.7243 (0.7245)  time: 0.0910  data: 0.0001  max mem: 10917
[15:10:02.719769] Test:  [280/345]  eta: 0:00:05  loss: 0.7221 (0.7245)  time: 0.0914  data: 0.0001  max mem: 10917
[15:10:03.638476] Test:  [290/345]  eta: 0:00:04  loss: 0.7246 (0.7247)  time: 0.0917  data: 0.0001  max mem: 10917
[15:10:04.561119] Test:  [300/345]  eta: 0:00:03  loss: 0.7225 (0.7247)  time: 0.0920  data: 0.0001  max mem: 10917
[15:10:05.487434] Test:  [310/345]  eta: 0:00:03  loss: 0.7224 (0.7248)  time: 0.0924  data: 0.0001  max mem: 10917
[15:10:06.417056] Test:  [320/345]  eta: 0:00:02  loss: 0.7278 (0.7249)  time: 0.0927  data: 0.0001  max mem: 10917
[15:10:07.349628] Test:  [330/345]  eta: 0:00:01  loss: 0.7163 (0.7247)  time: 0.0930  data: 0.0001  max mem: 10917
[15:10:08.286304] Test:  [340/345]  eta: 0:00:00  loss: 0.7175 (0.7248)  time: 0.0934  data: 0.0001  max mem: 10917
[15:10:08.662886] Test:  [344/345]  eta: 0:00:00  loss: 0.7217 (0.7248)  time: 0.0936  data: 0.0001  max mem: 10917
[15:10:08.719446] Test: Total time: 0:00:30 (0.0886 s / it)
[15:10:19.849471] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9223 (0.9223)  time: 0.2251  data: 0.1451  max mem: 10917
[15:10:20.662126] Test:  [10/57]  eta: 0:00:04  loss: 0.9078 (0.9083)  time: 0.0943  data: 0.0133  max mem: 10917
[15:10:21.480004] Test:  [20/57]  eta: 0:00:03  loss: 0.9044 (0.8940)  time: 0.0815  data: 0.0001  max mem: 10917
[15:10:22.300831] Test:  [30/57]  eta: 0:00:02  loss: 0.7900 (0.8529)  time: 0.0819  data: 0.0001  max mem: 10917
[15:10:23.125886] Test:  [40/57]  eta: 0:00:01  loss: 0.7618 (0.8314)  time: 0.0822  data: 0.0001  max mem: 10917
[15:10:23.954213] Test:  [50/57]  eta: 0:00:00  loss: 0.7682 (0.8249)  time: 0.0826  data: 0.0001  max mem: 10917
[15:10:24.404702] Test:  [56/57]  eta: 0:00:00  loss: 0.8024 (0.8297)  time: 0.0804  data: 0.0001  max mem: 10917
[15:10:24.462176] Test: Total time: 0:00:04 (0.0849 s / it)
[15:10:26.399184] Dice score of the network on the train images: 0.813395, val images: 0.812688
[15:10:26.402775] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:10:26.799122] Epoch: [34]  [  0/345]  eta: 0:02:16  lr: 0.000069  loss: 0.7560 (0.7560)  time: 0.3955  data: 0.1427  max mem: 10917
[15:10:31.795382] Epoch: [34]  [ 20/345]  eta: 0:01:23  lr: 0.000069  loss: 0.7467 (0.7541)  time: 0.2498  data: 0.0000  max mem: 10917
[15:10:36.779528] Epoch: [34]  [ 40/345]  eta: 0:01:17  lr: 0.000068  loss: 0.7515 (0.7536)  time: 0.2492  data: 0.0001  max mem: 10917
[15:10:41.769910] Epoch: [34]  [ 60/345]  eta: 0:01:11  lr: 0.000068  loss: 0.7488 (0.7536)  time: 0.2495  data: 0.0000  max mem: 10917
[15:10:46.764870] Epoch: [34]  [ 80/345]  eta: 0:01:06  lr: 0.000068  loss: 0.7494 (0.7538)  time: 0.2497  data: 0.0000  max mem: 10917
[15:10:51.769309] Epoch: [34]  [100/345]  eta: 0:01:01  lr: 0.000067  loss: 0.7488 (0.7533)  time: 0.2502  data: 0.0001  max mem: 10917
[15:10:56.772736] Epoch: [34]  [120/345]  eta: 0:00:56  lr: 0.000067  loss: 0.7587 (0.7544)  time: 0.2501  data: 0.0000  max mem: 10917
[15:11:01.779207] Epoch: [34]  [140/345]  eta: 0:00:51  lr: 0.000066  loss: 0.7516 (0.7549)  time: 0.2503  data: 0.0001  max mem: 10917
[15:11:06.788776] Epoch: [34]  [160/345]  eta: 0:00:46  lr: 0.000066  loss: 0.7584 (0.7555)  time: 0.2504  data: 0.0001  max mem: 10917
[15:11:11.817598] Epoch: [34]  [180/345]  eta: 0:00:41  lr: 0.000066  loss: 0.7419 (0.7542)  time: 0.2514  data: 0.0001  max mem: 10917
[15:11:16.848309] Epoch: [34]  [200/345]  eta: 0:00:36  lr: 0.000065  loss: 0.7443 (0.7533)  time: 0.2515  data: 0.0000  max mem: 10917
[15:11:21.883923] Epoch: [34]  [220/345]  eta: 0:00:31  lr: 0.000065  loss: 0.7473 (0.7532)  time: 0.2517  data: 0.0001  max mem: 10917
[15:11:26.920246] Epoch: [34]  [240/345]  eta: 0:00:26  lr: 0.000064  loss: 0.7430 (0.7528)  time: 0.2518  data: 0.0001  max mem: 10917
[15:11:31.957759] Epoch: [34]  [260/345]  eta: 0:00:21  lr: 0.000064  loss: 0.7504 (0.7528)  time: 0.2518  data: 0.0001  max mem: 10917
[15:11:36.997561] Epoch: [34]  [280/345]  eta: 0:00:16  lr: 0.000064  loss: 0.7543 (0.7528)  time: 0.2520  data: 0.0001  max mem: 10917
[15:11:42.034907] Epoch: [34]  [300/345]  eta: 0:00:11  lr: 0.000063  loss: 0.7534 (0.7532)  time: 0.2518  data: 0.0001  max mem: 10917
[15:11:47.070237] Epoch: [34]  [320/345]  eta: 0:00:06  lr: 0.000063  loss: 0.7656 (0.7538)  time: 0.2517  data: 0.0001  max mem: 10917
[15:11:52.113171] Epoch: [34]  [340/345]  eta: 0:00:01  lr: 0.000063  loss: 0.7617 (0.7545)  time: 0.2521  data: 0.0000  max mem: 10917
[15:11:53.122297] Epoch: [34]  [344/345]  eta: 0:00:00  lr: 0.000063  loss: 0.7618 (0.7548)  time: 0.2521  data: 0.0001  max mem: 10917
[15:11:53.177990] Epoch: [34] Total time: 0:01:26 (0.2515 s / it)
[15:11:53.178414] Averaged stats: lr: 0.000063  loss: 0.7618 (0.7548)
[15:11:53.419845] Test:  [  0/345]  eta: 0:01:22  loss: 0.7119 (0.7119)  time: 0.2381  data: 0.1580  max mem: 10917
[15:11:54.241493] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7252 (0.7275)  time: 0.0963  data: 0.0145  max mem: 10917
[15:11:55.065513] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7310 (0.7297)  time: 0.0822  data: 0.0001  max mem: 10917
[15:11:55.894513] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7320 (0.7298)  time: 0.0826  data: 0.0001  max mem: 10917
[15:11:56.726327] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7241 (0.7287)  time: 0.0830  data: 0.0001  max mem: 10917
[15:11:57.561118] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7241 (0.7288)  time: 0.0833  data: 0.0001  max mem: 10917
[15:11:58.400291] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7268 (0.7287)  time: 0.0836  data: 0.0001  max mem: 10917
[15:11:59.242928] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7286 (0.7293)  time: 0.0840  data: 0.0001  max mem: 10917
[15:12:00.087968] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7275 (0.7288)  time: 0.0843  data: 0.0001  max mem: 10917
[15:12:00.937521] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7274 (0.7287)  time: 0.0847  data: 0.0001  max mem: 10917
[15:12:01.790782] Test:  [100/345]  eta: 0:00:20  loss: 0.7274 (0.7279)  time: 0.0851  data: 0.0001  max mem: 10917
[15:12:02.647150] Test:  [110/345]  eta: 0:00:20  loss: 0.7162 (0.7273)  time: 0.0854  data: 0.0001  max mem: 10917
[15:12:03.506885] Test:  [120/345]  eta: 0:00:19  loss: 0.7238 (0.7271)  time: 0.0858  data: 0.0001  max mem: 10917
[15:12:04.370188] Test:  [130/345]  eta: 0:00:18  loss: 0.7255 (0.7272)  time: 0.0861  data: 0.0001  max mem: 10917
[15:12:05.237076] Test:  [140/345]  eta: 0:00:17  loss: 0.7255 (0.7269)  time: 0.0865  data: 0.0001  max mem: 10917
[15:12:06.106842] Test:  [150/345]  eta: 0:00:16  loss: 0.7265 (0.7268)  time: 0.0868  data: 0.0001  max mem: 10917
[15:12:06.980573] Test:  [160/345]  eta: 0:00:15  loss: 0.7264 (0.7268)  time: 0.0871  data: 0.0001  max mem: 10917
[15:12:07.857359] Test:  [170/345]  eta: 0:00:15  loss: 0.7264 (0.7269)  time: 0.0875  data: 0.0001  max mem: 10917
[15:12:08.738132] Test:  [180/345]  eta: 0:00:14  loss: 0.7358 (0.7276)  time: 0.0878  data: 0.0001  max mem: 10917
[15:12:09.621412] Test:  [190/345]  eta: 0:00:13  loss: 0.7328 (0.7275)  time: 0.0882  data: 0.0001  max mem: 10917
[15:12:10.508619] Test:  [200/345]  eta: 0:00:12  loss: 0.7289 (0.7278)  time: 0.0885  data: 0.0001  max mem: 10917
[15:12:11.400318] Test:  [210/345]  eta: 0:00:11  loss: 0.7259 (0.7277)  time: 0.0889  data: 0.0001  max mem: 10917
[15:12:12.295231] Test:  [220/345]  eta: 0:00:10  loss: 0.7245 (0.7278)  time: 0.0893  data: 0.0001  max mem: 10917
[15:12:13.193271] Test:  [230/345]  eta: 0:00:09  loss: 0.7268 (0.7279)  time: 0.0896  data: 0.0001  max mem: 10917
[15:12:14.095418] Test:  [240/345]  eta: 0:00:09  loss: 0.7268 (0.7279)  time: 0.0900  data: 0.0001  max mem: 10917
[15:12:15.000724] Test:  [250/345]  eta: 0:00:08  loss: 0.7269 (0.7277)  time: 0.0903  data: 0.0001  max mem: 10917
[15:12:15.908359] Test:  [260/345]  eta: 0:00:07  loss: 0.7291 (0.7281)  time: 0.0906  data: 0.0001  max mem: 10917
[15:12:16.820962] Test:  [270/345]  eta: 0:00:06  loss: 0.7351 (0.7282)  time: 0.0910  data: 0.0001  max mem: 10917
[15:12:17.736317] Test:  [280/345]  eta: 0:00:05  loss: 0.7288 (0.7280)  time: 0.0914  data: 0.0001  max mem: 10917
[15:12:18.655511] Test:  [290/345]  eta: 0:00:04  loss: 0.7251 (0.7281)  time: 0.0917  data: 0.0001  max mem: 10917
[15:12:19.578071] Test:  [300/345]  eta: 0:00:03  loss: 0.7312 (0.7280)  time: 0.0920  data: 0.0001  max mem: 10917
[15:12:20.504455] Test:  [310/345]  eta: 0:00:03  loss: 0.7286 (0.7282)  time: 0.0924  data: 0.0001  max mem: 10917
[15:12:21.434797] Test:  [320/345]  eta: 0:00:02  loss: 0.7258 (0.7281)  time: 0.0928  data: 0.0001  max mem: 10917
[15:12:22.367421] Test:  [330/345]  eta: 0:00:01  loss: 0.7258 (0.7282)  time: 0.0931  data: 0.0001  max mem: 10917
[15:12:23.304624] Test:  [340/345]  eta: 0:00:00  loss: 0.7324 (0.7283)  time: 0.0934  data: 0.0001  max mem: 10917
[15:12:23.681014] Test:  [344/345]  eta: 0:00:00  loss: 0.7324 (0.7283)  time: 0.0936  data: 0.0001  max mem: 10917
[15:12:23.735610] Test: Total time: 0:00:30 (0.0886 s / it)
[15:12:34.794779] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9360 (0.9360)  time: 0.2211  data: 0.1412  max mem: 10917
[15:12:35.607738] Test:  [10/57]  eta: 0:00:04  loss: 0.9093 (0.9113)  time: 0.0939  data: 0.0129  max mem: 10917
[15:12:36.424113] Test:  [20/57]  eta: 0:00:03  loss: 0.8996 (0.8989)  time: 0.0814  data: 0.0001  max mem: 10917
[15:12:37.244362] Test:  [30/57]  eta: 0:00:02  loss: 0.7904 (0.8591)  time: 0.0818  data: 0.0001  max mem: 10917
[15:12:38.068322] Test:  [40/57]  eta: 0:00:01  loss: 0.7763 (0.8380)  time: 0.0822  data: 0.0001  max mem: 10917
[15:12:38.895111] Test:  [50/57]  eta: 0:00:00  loss: 0.7742 (0.8316)  time: 0.0825  data: 0.0001  max mem: 10917
[15:12:39.344650] Test:  [56/57]  eta: 0:00:00  loss: 0.7952 (0.8353)  time: 0.0803  data: 0.0001  max mem: 10917
[15:12:39.400136] Test: Total time: 0:00:04 (0.0847 s / it)
[15:12:41.325621] Dice score of the network on the train images: 0.808323, val images: 0.805631
[15:12:41.329960] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:12:41.727429] Epoch: [35]  [  0/345]  eta: 0:02:16  lr: 0.000063  loss: 0.7554 (0.7554)  time: 0.3964  data: 0.1446  max mem: 10917
[15:12:46.724611] Epoch: [35]  [ 20/345]  eta: 0:01:23  lr: 0.000062  loss: 0.7669 (0.7649)  time: 0.2498  data: 0.0000  max mem: 10917
[15:12:51.719009] Epoch: [35]  [ 40/345]  eta: 0:01:17  lr: 0.000062  loss: 0.7589 (0.7616)  time: 0.2497  data: 0.0001  max mem: 10917
[15:12:56.711172] Epoch: [35]  [ 60/345]  eta: 0:01:11  lr: 0.000061  loss: 0.7463 (0.7587)  time: 0.2496  data: 0.0000  max mem: 10917
[15:13:01.715996] Epoch: [35]  [ 80/345]  eta: 0:01:06  lr: 0.000061  loss: 0.7554 (0.7579)  time: 0.2502  data: 0.0000  max mem: 10917
[15:13:06.723096] Epoch: [35]  [100/345]  eta: 0:01:01  lr: 0.000061  loss: 0.7505 (0.7561)  time: 0.2503  data: 0.0000  max mem: 10917
[15:13:11.733976] Epoch: [35]  [120/345]  eta: 0:00:56  lr: 0.000060  loss: 0.7562 (0.7566)  time: 0.2505  data: 0.0001  max mem: 10917
[15:13:16.748047] Epoch: [35]  [140/345]  eta: 0:00:51  lr: 0.000060  loss: 0.7522 (0.7561)  time: 0.2507  data: 0.0000  max mem: 10917
[15:13:21.762868] Epoch: [35]  [160/345]  eta: 0:00:46  lr: 0.000059  loss: 0.7494 (0.7555)  time: 0.2507  data: 0.0000  max mem: 10917
[15:13:26.784030] Epoch: [35]  [180/345]  eta: 0:00:41  lr: 0.000059  loss: 0.7487 (0.7550)  time: 0.2510  data: 0.0001  max mem: 10917
[15:13:31.818913] Epoch: [35]  [200/345]  eta: 0:00:36  lr: 0.000059  loss: 0.7494 (0.7546)  time: 0.2517  data: 0.0000  max mem: 10917
[15:13:36.857706] Epoch: [35]  [220/345]  eta: 0:00:31  lr: 0.000058  loss: 0.7512 (0.7544)  time: 0.2519  data: 0.0000  max mem: 10917
[15:13:41.896001] Epoch: [35]  [240/345]  eta: 0:00:26  lr: 0.000058  loss: 0.7538 (0.7544)  time: 0.2519  data: 0.0000  max mem: 10917
[15:13:46.942257] Epoch: [35]  [260/345]  eta: 0:00:21  lr: 0.000058  loss: 0.7480 (0.7542)  time: 0.2523  data: 0.0000  max mem: 10917
[15:13:51.986539] Epoch: [35]  [280/345]  eta: 0:00:16  lr: 0.000057  loss: 0.7554 (0.7543)  time: 0.2522  data: 0.0000  max mem: 10917
[15:13:57.032060] Epoch: [35]  [300/345]  eta: 0:00:11  lr: 0.000057  loss: 0.7499 (0.7542)  time: 0.2522  data: 0.0000  max mem: 10917
[15:14:02.078136] Epoch: [35]  [320/345]  eta: 0:00:06  lr: 0.000056  loss: 0.7463 (0.7538)  time: 0.2523  data: 0.0000  max mem: 10917
[15:14:07.124271] Epoch: [35]  [340/345]  eta: 0:00:01  lr: 0.000056  loss: 0.7522 (0.7539)  time: 0.2523  data: 0.0000  max mem: 10917
[15:14:08.132389] Epoch: [35]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.7522 (0.7539)  time: 0.2522  data: 0.0001  max mem: 10917
[15:14:08.187500] Epoch: [35] Total time: 0:01:26 (0.2518 s / it)
[15:14:08.187976] Averaged stats: lr: 0.000056  loss: 0.7522 (0.7539)
[15:14:08.425829] Test:  [  0/345]  eta: 0:01:20  loss: 0.6920 (0.6920)  time: 0.2343  data: 0.1540  max mem: 10917
[15:14:09.247420] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7300 (0.7236)  time: 0.0959  data: 0.0141  max mem: 10917
[15:14:10.071619] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7247 (0.7238)  time: 0.0822  data: 0.0001  max mem: 10917
[15:14:10.899242] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7236 (0.7242)  time: 0.0825  data: 0.0001  max mem: 10917
[15:14:11.730334] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7265 (0.7251)  time: 0.0829  data: 0.0001  max mem: 10917
[15:14:12.564242] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7221 (0.7242)  time: 0.0832  data: 0.0001  max mem: 10917
[15:14:13.402864] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7221 (0.7239)  time: 0.0836  data: 0.0001  max mem: 10917
[15:14:14.244878] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7247 (0.7240)  time: 0.0840  data: 0.0001  max mem: 10917
[15:14:15.090032] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7257 (0.7243)  time: 0.0843  data: 0.0001  max mem: 10917
[15:14:15.938859] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7208 (0.7242)  time: 0.0847  data: 0.0001  max mem: 10917
[15:14:16.791134] Test:  [100/345]  eta: 0:00:20  loss: 0.7188 (0.7239)  time: 0.0850  data: 0.0001  max mem: 10917
[15:14:17.646631] Test:  [110/345]  eta: 0:00:20  loss: 0.7169 (0.7235)  time: 0.0853  data: 0.0001  max mem: 10917
[15:14:18.506573] Test:  [120/345]  eta: 0:00:19  loss: 0.7229 (0.7237)  time: 0.0857  data: 0.0001  max mem: 10917
[15:14:19.369041] Test:  [130/345]  eta: 0:00:18  loss: 0.7270 (0.7237)  time: 0.0861  data: 0.0001  max mem: 10917
[15:14:20.236038] Test:  [140/345]  eta: 0:00:17  loss: 0.7223 (0.7236)  time: 0.0864  data: 0.0001  max mem: 10917
[15:14:21.106411] Test:  [150/345]  eta: 0:00:16  loss: 0.7192 (0.7231)  time: 0.0868  data: 0.0001  max mem: 10917
[15:14:21.980708] Test:  [160/345]  eta: 0:00:15  loss: 0.7156 (0.7228)  time: 0.0872  data: 0.0001  max mem: 10917
[15:14:22.858154] Test:  [170/345]  eta: 0:00:15  loss: 0.7221 (0.7229)  time: 0.0875  data: 0.0001  max mem: 10917
[15:14:23.738807] Test:  [180/345]  eta: 0:00:14  loss: 0.7221 (0.7229)  time: 0.0878  data: 0.0001  max mem: 10917
[15:14:24.622920] Test:  [190/345]  eta: 0:00:13  loss: 0.7164 (0.7228)  time: 0.0882  data: 0.0001  max mem: 10917
[15:14:25.510623] Test:  [200/345]  eta: 0:00:12  loss: 0.7184 (0.7227)  time: 0.0885  data: 0.0001  max mem: 10917
[15:14:26.401788] Test:  [210/345]  eta: 0:00:11  loss: 0.7189 (0.7226)  time: 0.0889  data: 0.0001  max mem: 10917
[15:14:27.295279] Test:  [220/345]  eta: 0:00:10  loss: 0.7159 (0.7224)  time: 0.0892  data: 0.0001  max mem: 10917
[15:14:28.193312] Test:  [230/345]  eta: 0:00:09  loss: 0.7173 (0.7225)  time: 0.0895  data: 0.0001  max mem: 10917
[15:14:29.095294] Test:  [240/345]  eta: 0:00:09  loss: 0.7239 (0.7227)  time: 0.0900  data: 0.0001  max mem: 10917
[15:14:30.000427] Test:  [250/345]  eta: 0:00:08  loss: 0.7232 (0.7227)  time: 0.0903  data: 0.0001  max mem: 10917
[15:14:30.908839] Test:  [260/345]  eta: 0:00:07  loss: 0.7178 (0.7227)  time: 0.0906  data: 0.0001  max mem: 10917
[15:14:31.821346] Test:  [270/345]  eta: 0:00:06  loss: 0.7263 (0.7227)  time: 0.0910  data: 0.0001  max mem: 10917
[15:14:32.737389] Test:  [280/345]  eta: 0:00:05  loss: 0.7248 (0.7227)  time: 0.0914  data: 0.0001  max mem: 10917
[15:14:33.656724] Test:  [290/345]  eta: 0:00:04  loss: 0.7226 (0.7226)  time: 0.0917  data: 0.0001  max mem: 10917
[15:14:34.578677] Test:  [300/345]  eta: 0:00:03  loss: 0.7177 (0.7223)  time: 0.0920  data: 0.0001  max mem: 10917
[15:14:35.504792] Test:  [310/345]  eta: 0:00:03  loss: 0.7192 (0.7225)  time: 0.0924  data: 0.0001  max mem: 10917
[15:14:36.434199] Test:  [320/345]  eta: 0:00:02  loss: 0.7217 (0.7224)  time: 0.0927  data: 0.0001  max mem: 10917
[15:14:37.366985] Test:  [330/345]  eta: 0:00:01  loss: 0.7175 (0.7223)  time: 0.0931  data: 0.0001  max mem: 10917
[15:14:38.302729] Test:  [340/345]  eta: 0:00:00  loss: 0.7175 (0.7223)  time: 0.0934  data: 0.0001  max mem: 10917
[15:14:38.678659] Test:  [344/345]  eta: 0:00:00  loss: 0.7197 (0.7223)  time: 0.0935  data: 0.0001  max mem: 10917
[15:14:38.719138] Test: Total time: 0:00:30 (0.0885 s / it)
[15:14:49.726241] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9156 (0.9156)  time: 0.2195  data: 0.1394  max mem: 10917
[15:14:50.540555] Test:  [10/57]  eta: 0:00:04  loss: 0.9156 (0.9147)  time: 0.0939  data: 0.0127  max mem: 10917
[15:14:51.357193] Test:  [20/57]  eta: 0:00:03  loss: 0.8966 (0.9019)  time: 0.0815  data: 0.0001  max mem: 10917
[15:14:52.178099] Test:  [30/57]  eta: 0:00:02  loss: 0.7907 (0.8588)  time: 0.0818  data: 0.0001  max mem: 10917
[15:14:53.002135] Test:  [40/57]  eta: 0:00:01  loss: 0.7775 (0.8363)  time: 0.0822  data: 0.0001  max mem: 10917
[15:14:53.830441] Test:  [50/57]  eta: 0:00:00  loss: 0.7611 (0.8277)  time: 0.0826  data: 0.0001  max mem: 10917
[15:14:54.280488] Test:  [56/57]  eta: 0:00:00  loss: 0.7975 (0.8331)  time: 0.0804  data: 0.0001  max mem: 10917
[15:14:54.335644] Test: Total time: 0:00:04 (0.0847 s / it)
[15:14:56.282776] Dice score of the network on the train images: 0.821039, val images: 0.812637
[15:14:56.286615] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:14:56.684479] Epoch: [36]  [  0/345]  eta: 0:02:16  lr: 0.000056  loss: 0.7358 (0.7358)  time: 0.3968  data: 0.1447  max mem: 10917
[15:15:01.688127] Epoch: [36]  [ 20/345]  eta: 0:01:23  lr: 0.000056  loss: 0.7476 (0.7500)  time: 0.2501  data: 0.0000  max mem: 10917
[15:15:06.702506] Epoch: [36]  [ 40/345]  eta: 0:01:17  lr: 0.000055  loss: 0.7481 (0.7519)  time: 0.2507  data: 0.0001  max mem: 10917
[15:15:11.713436] Epoch: [36]  [ 60/345]  eta: 0:01:12  lr: 0.000055  loss: 0.7519 (0.7514)  time: 0.2505  data: 0.0000  max mem: 10917
[15:15:16.733652] Epoch: [36]  [ 80/345]  eta: 0:01:06  lr: 0.000054  loss: 0.7507 (0.7522)  time: 0.2510  data: 0.0000  max mem: 10917
[15:15:21.756150] Epoch: [36]  [100/345]  eta: 0:01:01  lr: 0.000054  loss: 0.7537 (0.7520)  time: 0.2511  data: 0.0000  max mem: 10917
[15:15:26.781294] Epoch: [36]  [120/345]  eta: 0:00:56  lr: 0.000054  loss: 0.7446 (0.7516)  time: 0.2512  data: 0.0000  max mem: 10917
[15:15:31.806204] Epoch: [36]  [140/345]  eta: 0:00:51  lr: 0.000053  loss: 0.7337 (0.7494)  time: 0.2512  data: 0.0000  max mem: 10917
[15:15:36.836684] Epoch: [36]  [160/345]  eta: 0:00:46  lr: 0.000053  loss: 0.7490 (0.7496)  time: 0.2515  data: 0.0000  max mem: 10917
[15:15:41.869230] Epoch: [36]  [180/345]  eta: 0:00:41  lr: 0.000053  loss: 0.7521 (0.7498)  time: 0.2516  data: 0.0001  max mem: 10917
[15:15:46.904751] Epoch: [36]  [200/345]  eta: 0:00:36  lr: 0.000052  loss: 0.7519 (0.7501)  time: 0.2517  data: 0.0000  max mem: 10917
[15:15:51.939460] Epoch: [36]  [220/345]  eta: 0:00:31  lr: 0.000052  loss: 0.7548 (0.7510)  time: 0.2517  data: 0.0000  max mem: 10917
[15:15:56.980645] Epoch: [36]  [240/345]  eta: 0:00:26  lr: 0.000051  loss: 0.7664 (0.7522)  time: 0.2520  data: 0.0000  max mem: 10917
[15:16:02.019054] Epoch: [36]  [260/345]  eta: 0:00:21  lr: 0.000051  loss: 0.7611 (0.7528)  time: 0.2519  data: 0.0001  max mem: 10917
[15:16:07.063902] Epoch: [36]  [280/345]  eta: 0:00:16  lr: 0.000051  loss: 0.7484 (0.7528)  time: 0.2522  data: 0.0000  max mem: 10917
[15:16:12.108996] Epoch: [36]  [300/345]  eta: 0:00:11  lr: 0.000050  loss: 0.7587 (0.7534)  time: 0.2522  data: 0.0000  max mem: 10917
[15:16:17.153403] Epoch: [36]  [320/345]  eta: 0:00:06  lr: 0.000050  loss: 0.7484 (0.7534)  time: 0.2522  data: 0.0001  max mem: 10917
[15:16:22.193947] Epoch: [36]  [340/345]  eta: 0:00:01  lr: 0.000050  loss: 0.7416 (0.7528)  time: 0.2520  data: 0.0001  max mem: 10917
[15:16:23.203701] Epoch: [36]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.7428 (0.7528)  time: 0.2520  data: 0.0001  max mem: 10917
[15:16:23.256930] Epoch: [36] Total time: 0:01:26 (0.2521 s / it)
[15:16:23.257048] Averaged stats: lr: 0.000050  loss: 0.7428 (0.7528)
[15:16:23.488758] Test:  [  0/345]  eta: 0:01:18  loss: 0.7096 (0.7096)  time: 0.2283  data: 0.1485  max mem: 10917
[15:16:24.325473] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7188 (0.7183)  time: 0.0967  data: 0.0150  max mem: 10917
[15:16:25.149453] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7188 (0.7180)  time: 0.0830  data: 0.0009  max mem: 10917
[15:16:25.976011] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7163 (0.7181)  time: 0.0825  data: 0.0001  max mem: 10917
[15:16:26.807265] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7208 (0.7193)  time: 0.0828  data: 0.0001  max mem: 10917
[15:16:27.640915] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7208 (0.7201)  time: 0.0832  data: 0.0001  max mem: 10917
[15:16:28.479453] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7145 (0.7195)  time: 0.0836  data: 0.0001  max mem: 10917
[15:16:29.321999] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7137 (0.7195)  time: 0.0840  data: 0.0001  max mem: 10917
[15:16:30.167168] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7212 (0.7197)  time: 0.0843  data: 0.0001  max mem: 10917
[15:16:31.016458] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7192 (0.7194)  time: 0.0847  data: 0.0001  max mem: 10917
[15:16:31.869195] Test:  [100/345]  eta: 0:00:20  loss: 0.7194 (0.7197)  time: 0.0851  data: 0.0001  max mem: 10917
[15:16:32.725567] Test:  [110/345]  eta: 0:00:20  loss: 0.7212 (0.7195)  time: 0.0854  data: 0.0001  max mem: 10917
[15:16:33.584908] Test:  [120/345]  eta: 0:00:19  loss: 0.7195 (0.7201)  time: 0.0857  data: 0.0001  max mem: 10917
[15:16:34.447889] Test:  [130/345]  eta: 0:00:18  loss: 0.7199 (0.7200)  time: 0.0861  data: 0.0001  max mem: 10917
[15:16:35.314075] Test:  [140/345]  eta: 0:00:17  loss: 0.7111 (0.7192)  time: 0.0864  data: 0.0001  max mem: 10917
[15:16:36.184373] Test:  [150/345]  eta: 0:00:16  loss: 0.7129 (0.7194)  time: 0.0868  data: 0.0001  max mem: 10917
[15:16:37.058417] Test:  [160/345]  eta: 0:00:15  loss: 0.7182 (0.7195)  time: 0.0872  data: 0.0001  max mem: 10917
[15:16:37.935578] Test:  [170/345]  eta: 0:00:15  loss: 0.7211 (0.7196)  time: 0.0875  data: 0.0001  max mem: 10917
[15:16:38.815574] Test:  [180/345]  eta: 0:00:14  loss: 0.7212 (0.7200)  time: 0.0878  data: 0.0001  max mem: 10917
[15:16:39.698789] Test:  [190/345]  eta: 0:00:13  loss: 0.7212 (0.7199)  time: 0.0881  data: 0.0001  max mem: 10917
[15:16:40.586489] Test:  [200/345]  eta: 0:00:12  loss: 0.7245 (0.7200)  time: 0.0885  data: 0.0001  max mem: 10917
[15:16:41.477738] Test:  [210/345]  eta: 0:00:11  loss: 0.7212 (0.7202)  time: 0.0889  data: 0.0001  max mem: 10917
[15:16:42.371288] Test:  [220/345]  eta: 0:00:10  loss: 0.7165 (0.7202)  time: 0.0892  data: 0.0001  max mem: 10917
[15:16:43.269337] Test:  [230/345]  eta: 0:00:09  loss: 0.7137 (0.7200)  time: 0.0895  data: 0.0001  max mem: 10917
[15:16:44.172146] Test:  [240/345]  eta: 0:00:09  loss: 0.7196 (0.7198)  time: 0.0900  data: 0.0001  max mem: 10917
[15:16:45.076424] Test:  [250/345]  eta: 0:00:08  loss: 0.7157 (0.7198)  time: 0.0903  data: 0.0001  max mem: 10917
[15:16:45.984496] Test:  [260/345]  eta: 0:00:07  loss: 0.7162 (0.7199)  time: 0.0906  data: 0.0001  max mem: 10917
[15:16:46.897021] Test:  [270/345]  eta: 0:00:06  loss: 0.7211 (0.7197)  time: 0.0910  data: 0.0001  max mem: 10917
[15:16:47.811925] Test:  [280/345]  eta: 0:00:05  loss: 0.7210 (0.7199)  time: 0.0913  data: 0.0001  max mem: 10917
[15:16:48.731263] Test:  [290/345]  eta: 0:00:04  loss: 0.7123 (0.7195)  time: 0.0917  data: 0.0001  max mem: 10917
[15:16:49.653587] Test:  [300/345]  eta: 0:00:03  loss: 0.7082 (0.7192)  time: 0.0920  data: 0.0001  max mem: 10917
[15:16:50.578859] Test:  [310/345]  eta: 0:00:03  loss: 0.7113 (0.7191)  time: 0.0923  data: 0.0001  max mem: 10917
[15:16:51.508378] Test:  [320/345]  eta: 0:00:02  loss: 0.7180 (0.7191)  time: 0.0927  data: 0.0001  max mem: 10917
[15:16:52.441033] Test:  [330/345]  eta: 0:00:01  loss: 0.7197 (0.7191)  time: 0.0931  data: 0.0001  max mem: 10917
[15:16:53.378876] Test:  [340/345]  eta: 0:00:00  loss: 0.7167 (0.7189)  time: 0.0935  data: 0.0001  max mem: 10917
[15:16:53.755383] Test:  [344/345]  eta: 0:00:00  loss: 0.7081 (0.7188)  time: 0.0937  data: 0.0001  max mem: 10917
[15:16:53.811065] Test: Total time: 0:00:30 (0.0886 s / it)
[15:17:04.969464] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9026 (0.9026)  time: 0.2174  data: 0.1378  max mem: 10917
[15:17:05.782795] Test:  [10/57]  eta: 0:00:04  loss: 0.9141 (0.9159)  time: 0.0936  data: 0.0126  max mem: 10917
[15:17:06.600648] Test:  [20/57]  eta: 0:00:03  loss: 0.9003 (0.8990)  time: 0.0815  data: 0.0001  max mem: 10917
[15:17:07.421923] Test:  [30/57]  eta: 0:00:02  loss: 0.7850 (0.8575)  time: 0.0819  data: 0.0001  max mem: 10917
[15:17:08.247118] Test:  [40/57]  eta: 0:00:01  loss: 0.7801 (0.8358)  time: 0.0823  data: 0.0001  max mem: 10917
[15:17:09.076034] Test:  [50/57]  eta: 0:00:00  loss: 0.7680 (0.8281)  time: 0.0827  data: 0.0001  max mem: 10917
[15:17:09.526629] Test:  [56/57]  eta: 0:00:00  loss: 0.8030 (0.8335)  time: 0.0804  data: 0.0001  max mem: 10917
[15:17:09.581604] Test: Total time: 0:00:04 (0.0847 s / it)
[15:17:11.528670] Dice score of the network on the train images: 0.820875, val images: 0.812048
[15:17:11.532281] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:17:11.929677] Epoch: [37]  [  0/345]  eta: 0:02:16  lr: 0.000050  loss: 0.7240 (0.7240)  time: 0.3965  data: 0.1435  max mem: 10917
[15:17:16.924836] Epoch: [37]  [ 20/345]  eta: 0:01:23  lr: 0.000049  loss: 0.7532 (0.7507)  time: 0.2497  data: 0.0001  max mem: 10917
[15:17:21.918184] Epoch: [37]  [ 40/345]  eta: 0:01:17  lr: 0.000049  loss: 0.7483 (0.7507)  time: 0.2496  data: 0.0001  max mem: 10917
[15:17:26.932917] Epoch: [37]  [ 60/345]  eta: 0:01:11  lr: 0.000048  loss: 0.7506 (0.7507)  time: 0.2507  data: 0.0001  max mem: 10917
[15:17:31.949201] Epoch: [37]  [ 80/345]  eta: 0:01:06  lr: 0.000048  loss: 0.7444 (0.7503)  time: 0.2508  data: 0.0000  max mem: 10917
[15:17:36.974557] Epoch: [37]  [100/345]  eta: 0:01:01  lr: 0.000048  loss: 0.7485 (0.7503)  time: 0.2512  data: 0.0000  max mem: 10917
[15:17:41.997565] Epoch: [37]  [120/345]  eta: 0:00:56  lr: 0.000047  loss: 0.7477 (0.7502)  time: 0.2511  data: 0.0000  max mem: 10917
[15:17:47.100518] Epoch: [37]  [140/345]  eta: 0:00:51  lr: 0.000047  loss: 0.7463 (0.7503)  time: 0.2551  data: 0.0001  max mem: 10917
[15:17:52.124887] Epoch: [37]  [160/345]  eta: 0:00:46  lr: 0.000047  loss: 0.7355 (0.7497)  time: 0.2512  data: 0.0000  max mem: 10917
[15:17:57.155910] Epoch: [37]  [180/345]  eta: 0:00:41  lr: 0.000046  loss: 0.7411 (0.7494)  time: 0.2515  data: 0.0000  max mem: 10917
[15:18:02.187595] Epoch: [37]  [200/345]  eta: 0:00:36  lr: 0.000046  loss: 0.7454 (0.7492)  time: 0.2515  data: 0.0000  max mem: 10917
[15:18:07.223939] Epoch: [37]  [220/345]  eta: 0:00:31  lr: 0.000045  loss: 0.7463 (0.7493)  time: 0.2518  data: 0.0000  max mem: 10917
[15:18:12.264304] Epoch: [37]  [240/345]  eta: 0:00:26  lr: 0.000045  loss: 0.7406 (0.7489)  time: 0.2520  data: 0.0000  max mem: 10917
[15:18:17.302419] Epoch: [37]  [260/345]  eta: 0:00:21  lr: 0.000045  loss: 0.7484 (0.7489)  time: 0.2519  data: 0.0000  max mem: 10917
[15:18:22.342108] Epoch: [37]  [280/345]  eta: 0:00:16  lr: 0.000044  loss: 0.7467 (0.7488)  time: 0.2519  data: 0.0000  max mem: 10917
[15:18:27.386271] Epoch: [37]  [300/345]  eta: 0:00:11  lr: 0.000044  loss: 0.7452 (0.7487)  time: 0.2522  data: 0.0000  max mem: 10917
[15:18:32.431797] Epoch: [37]  [320/345]  eta: 0:00:06  lr: 0.000044  loss: 0.7462 (0.7489)  time: 0.2522  data: 0.0000  max mem: 10917
[15:18:37.478901] Epoch: [37]  [340/345]  eta: 0:00:01  lr: 0.000043  loss: 0.7439 (0.7486)  time: 0.2523  data: 0.0000  max mem: 10917
[15:18:38.489066] Epoch: [37]  [344/345]  eta: 0:00:00  lr: 0.000043  loss: 0.7439 (0.7486)  time: 0.2524  data: 0.0001  max mem: 10917
[15:18:38.552401] Epoch: [37] Total time: 0:01:27 (0.2522 s / it)
[15:18:38.552910] Averaged stats: lr: 0.000043  loss: 0.7439 (0.7486)
[15:18:38.788786] Test:  [  0/345]  eta: 0:01:20  loss: 0.7175 (0.7175)  time: 0.2323  data: 0.1519  max mem: 10917
[15:18:39.613895] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7206 (0.7232)  time: 0.0961  data: 0.0143  max mem: 10917
[15:18:40.437827] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7206 (0.7183)  time: 0.0824  data: 0.0003  max mem: 10917
[15:18:41.266653] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7170 (0.7171)  time: 0.0826  data: 0.0001  max mem: 10917
[15:18:42.096957] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7151 (0.7164)  time: 0.0829  data: 0.0001  max mem: 10917
[15:18:42.932611] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7104 (0.7158)  time: 0.0832  data: 0.0001  max mem: 10917
[15:18:43.771736] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7172 (0.7163)  time: 0.0837  data: 0.0001  max mem: 10917
[15:18:44.612943] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7155 (0.7159)  time: 0.0840  data: 0.0001  max mem: 10917
[15:18:45.457612] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7155 (0.7169)  time: 0.0842  data: 0.0001  max mem: 10917
[15:18:46.307934] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7151 (0.7162)  time: 0.0847  data: 0.0001  max mem: 10917
[15:18:47.159783] Test:  [100/345]  eta: 0:00:20  loss: 0.7065 (0.7159)  time: 0.0851  data: 0.0001  max mem: 10917
[15:18:48.015899] Test:  [110/345]  eta: 0:00:20  loss: 0.7117 (0.7158)  time: 0.0854  data: 0.0001  max mem: 10917
[15:18:48.875745] Test:  [120/345]  eta: 0:00:19  loss: 0.7131 (0.7156)  time: 0.0858  data: 0.0001  max mem: 10917
[15:18:49.737975] Test:  [130/345]  eta: 0:00:18  loss: 0.7136 (0.7153)  time: 0.0861  data: 0.0001  max mem: 10917
[15:18:50.604675] Test:  [140/345]  eta: 0:00:17  loss: 0.7125 (0.7153)  time: 0.0864  data: 0.0001  max mem: 10917
[15:18:51.474633] Test:  [150/345]  eta: 0:00:16  loss: 0.7177 (0.7156)  time: 0.0868  data: 0.0001  max mem: 10917
[15:18:52.348330] Test:  [160/345]  eta: 0:00:15  loss: 0.7177 (0.7159)  time: 0.0871  data: 0.0001  max mem: 10917
[15:18:53.225239] Test:  [170/345]  eta: 0:00:15  loss: 0.7117 (0.7157)  time: 0.0875  data: 0.0001  max mem: 10917
[15:18:54.105860] Test:  [180/345]  eta: 0:00:14  loss: 0.7074 (0.7155)  time: 0.0878  data: 0.0001  max mem: 10917
[15:18:54.989131] Test:  [190/345]  eta: 0:00:13  loss: 0.7103 (0.7155)  time: 0.0881  data: 0.0001  max mem: 10917
[15:18:55.876698] Test:  [200/345]  eta: 0:00:12  loss: 0.7137 (0.7154)  time: 0.0885  data: 0.0001  max mem: 10917
[15:18:56.767949] Test:  [210/345]  eta: 0:00:11  loss: 0.7142 (0.7159)  time: 0.0889  data: 0.0001  max mem: 10917
[15:18:57.661559] Test:  [220/345]  eta: 0:00:10  loss: 0.7125 (0.7159)  time: 0.0892  data: 0.0001  max mem: 10917
[15:18:58.558754] Test:  [230/345]  eta: 0:00:09  loss: 0.7139 (0.7158)  time: 0.0895  data: 0.0001  max mem: 10917
[15:18:59.459111] Test:  [240/345]  eta: 0:00:09  loss: 0.7167 (0.7161)  time: 0.0898  data: 0.0001  max mem: 10917
[15:19:00.364506] Test:  [250/345]  eta: 0:00:08  loss: 0.7176 (0.7160)  time: 0.0902  data: 0.0001  max mem: 10917
[15:19:01.272540] Test:  [260/345]  eta: 0:00:07  loss: 0.7086 (0.7157)  time: 0.0906  data: 0.0001  max mem: 10917
[15:19:02.184293] Test:  [270/345]  eta: 0:00:06  loss: 0.7114 (0.7158)  time: 0.0909  data: 0.0001  max mem: 10917
[15:19:03.099219] Test:  [280/345]  eta: 0:00:05  loss: 0.7132 (0.7157)  time: 0.0913  data: 0.0001  max mem: 10917
[15:19:04.018097] Test:  [290/345]  eta: 0:00:04  loss: 0.7112 (0.7157)  time: 0.0916  data: 0.0001  max mem: 10917
[15:19:04.939475] Test:  [300/345]  eta: 0:00:03  loss: 0.7112 (0.7157)  time: 0.0920  data: 0.0001  max mem: 10917
[15:19:05.865295] Test:  [310/345]  eta: 0:00:03  loss: 0.7220 (0.7158)  time: 0.0923  data: 0.0001  max mem: 10917
[15:19:06.794756] Test:  [320/345]  eta: 0:00:02  loss: 0.7243 (0.7160)  time: 0.0927  data: 0.0001  max mem: 10917
[15:19:07.727194] Test:  [330/345]  eta: 0:00:01  loss: 0.7149 (0.7160)  time: 0.0930  data: 0.0001  max mem: 10917
[15:19:08.663332] Test:  [340/345]  eta: 0:00:00  loss: 0.7142 (0.7160)  time: 0.0934  data: 0.0001  max mem: 10917
[15:19:09.039648] Test:  [344/345]  eta: 0:00:00  loss: 0.7126 (0.7161)  time: 0.0935  data: 0.0001  max mem: 10917
[15:19:09.096683] Test: Total time: 0:00:30 (0.0885 s / it)
[15:19:20.226777] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9069 (0.9069)  time: 0.2197  data: 0.1398  max mem: 10917
[15:19:21.039257] Test:  [10/57]  eta: 0:00:04  loss: 0.9069 (0.9157)  time: 0.0938  data: 0.0128  max mem: 10917
[15:19:21.857163] Test:  [20/57]  eta: 0:00:03  loss: 0.8999 (0.9003)  time: 0.0814  data: 0.0001  max mem: 10917
[15:19:22.677787] Test:  [30/57]  eta: 0:00:02  loss: 0.7949 (0.8591)  time: 0.0819  data: 0.0001  max mem: 10917
[15:19:23.502178] Test:  [40/57]  eta: 0:00:01  loss: 0.7744 (0.8375)  time: 0.0822  data: 0.0001  max mem: 10917
[15:19:24.331128] Test:  [50/57]  eta: 0:00:00  loss: 0.7687 (0.8298)  time: 0.0826  data: 0.0001  max mem: 10917
[15:19:24.780638] Test:  [56/57]  eta: 0:00:00  loss: 0.8058 (0.8347)  time: 0.0803  data: 0.0001  max mem: 10917
[15:19:24.836056] Test: Total time: 0:00:04 (0.0847 s / it)
[15:19:26.848020] Dice score of the network on the train images: 0.822514, val images: 0.810342
[15:19:26.851696] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:19:27.248428] Epoch: [38]  [  0/345]  eta: 0:02:16  lr: 0.000043  loss: 0.7242 (0.7242)  time: 0.3959  data: 0.1438  max mem: 10917
[15:19:32.249701] Epoch: [38]  [ 20/345]  eta: 0:01:23  lr: 0.000043  loss: 0.7499 (0.7479)  time: 0.2500  data: 0.0001  max mem: 10917
[15:19:37.260264] Epoch: [38]  [ 40/345]  eta: 0:01:17  lr: 0.000042  loss: 0.7386 (0.7446)  time: 0.2505  data: 0.0000  max mem: 10917
[15:19:42.268689] Epoch: [38]  [ 60/345]  eta: 0:01:12  lr: 0.000042  loss: 0.7500 (0.7469)  time: 0.2504  data: 0.0001  max mem: 10917
[15:19:47.287679] Epoch: [38]  [ 80/345]  eta: 0:01:06  lr: 0.000042  loss: 0.7457 (0.7467)  time: 0.2509  data: 0.0000  max mem: 10917
[15:19:52.307444] Epoch: [38]  [100/345]  eta: 0:01:01  lr: 0.000041  loss: 0.7397 (0.7461)  time: 0.2509  data: 0.0000  max mem: 10917
[15:19:57.334778] Epoch: [38]  [120/345]  eta: 0:00:56  lr: 0.000041  loss: 0.7467 (0.7466)  time: 0.2513  data: 0.0000  max mem: 10917
[15:20:02.364418] Epoch: [38]  [140/345]  eta: 0:00:51  lr: 0.000041  loss: 0.7420 (0.7458)  time: 0.2514  data: 0.0001  max mem: 10917
[15:20:07.396620] Epoch: [38]  [160/345]  eta: 0:00:46  lr: 0.000040  loss: 0.7462 (0.7455)  time: 0.2516  data: 0.0001  max mem: 10917
[15:20:12.432179] Epoch: [38]  [180/345]  eta: 0:00:41  lr: 0.000040  loss: 0.7463 (0.7460)  time: 0.2517  data: 0.0001  max mem: 10917
[15:20:17.471599] Epoch: [38]  [200/345]  eta: 0:00:36  lr: 0.000040  loss: 0.7468 (0.7462)  time: 0.2519  data: 0.0001  max mem: 10917
[15:20:22.507009] Epoch: [38]  [220/345]  eta: 0:00:31  lr: 0.000039  loss: 0.7497 (0.7463)  time: 0.2517  data: 0.0001  max mem: 10917
[15:20:27.544901] Epoch: [38]  [240/345]  eta: 0:00:26  lr: 0.000039  loss: 0.7403 (0.7460)  time: 0.2518  data: 0.0001  max mem: 10917
[15:20:32.592744] Epoch: [38]  [260/345]  eta: 0:00:21  lr: 0.000039  loss: 0.7427 (0.7455)  time: 0.2523  data: 0.0001  max mem: 10917
[15:20:37.640287] Epoch: [38]  [280/345]  eta: 0:00:16  lr: 0.000038  loss: 0.7429 (0.7456)  time: 0.2523  data: 0.0001  max mem: 10917
[15:20:42.688671] Epoch: [38]  [300/345]  eta: 0:00:11  lr: 0.000038  loss: 0.7407 (0.7454)  time: 0.2524  data: 0.0001  max mem: 10917
[15:20:47.739883] Epoch: [38]  [320/345]  eta: 0:00:06  lr: 0.000038  loss: 0.7480 (0.7456)  time: 0.2525  data: 0.0001  max mem: 10917
[15:20:52.788391] Epoch: [38]  [340/345]  eta: 0:00:01  lr: 0.000037  loss: 0.7461 (0.7456)  time: 0.2524  data: 0.0001  max mem: 10917
[15:20:53.799349] Epoch: [38]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 0.7457 (0.7455)  time: 0.2525  data: 0.0001  max mem: 10917
[15:20:53.857452] Epoch: [38] Total time: 0:01:27 (0.2522 s / it)
[15:20:53.857959] Averaged stats: lr: 0.000037  loss: 0.7457 (0.7455)
[15:20:54.091625] Test:  [  0/345]  eta: 0:01:19  loss: 0.6906 (0.6906)  time: 0.2299  data: 0.1496  max mem: 10917
[15:20:54.926525] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7074 (0.7074)  time: 0.0967  data: 0.0150  max mem: 10917
[15:20:55.749722] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7089 (0.7102)  time: 0.0828  data: 0.0008  max mem: 10917
[15:20:56.577105] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7089 (0.7103)  time: 0.0825  data: 0.0001  max mem: 10917
[15:20:57.407455] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7059 (0.7113)  time: 0.0828  data: 0.0001  max mem: 10917
[15:20:58.242820] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7079 (0.7119)  time: 0.0832  data: 0.0001  max mem: 10917
[15:20:59.080414] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7227 (0.7136)  time: 0.0836  data: 0.0001  max mem: 10917
[15:20:59.921363] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7184 (0.7134)  time: 0.0839  data: 0.0001  max mem: 10917
[15:21:00.766137] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7064 (0.7127)  time: 0.0842  data: 0.0001  max mem: 10917
[15:21:01.614247] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7064 (0.7121)  time: 0.0846  data: 0.0001  max mem: 10917
[15:21:02.466430] Test:  [100/345]  eta: 0:00:20  loss: 0.7077 (0.7118)  time: 0.0850  data: 0.0001  max mem: 10917
[15:21:03.321584] Test:  [110/345]  eta: 0:00:20  loss: 0.7106 (0.7120)  time: 0.0853  data: 0.0001  max mem: 10917
[15:21:04.179919] Test:  [120/345]  eta: 0:00:19  loss: 0.7102 (0.7121)  time: 0.0856  data: 0.0001  max mem: 10917
[15:21:05.041351] Test:  [130/345]  eta: 0:00:18  loss: 0.7068 (0.7122)  time: 0.0859  data: 0.0001  max mem: 10917
[15:21:05.907243] Test:  [140/345]  eta: 0:00:17  loss: 0.7061 (0.7119)  time: 0.0863  data: 0.0001  max mem: 10917
[15:21:06.777387] Test:  [150/345]  eta: 0:00:16  loss: 0.7107 (0.7125)  time: 0.0867  data: 0.0001  max mem: 10917
[15:21:07.649716] Test:  [160/345]  eta: 0:00:15  loss: 0.7149 (0.7126)  time: 0.0870  data: 0.0001  max mem: 10917
[15:21:08.526291] Test:  [170/345]  eta: 0:00:14  loss: 0.7109 (0.7126)  time: 0.0874  data: 0.0001  max mem: 10917
[15:21:09.406215] Test:  [180/345]  eta: 0:00:14  loss: 0.7109 (0.7128)  time: 0.0878  data: 0.0001  max mem: 10917
[15:21:10.289514] Test:  [190/345]  eta: 0:00:13  loss: 0.7146 (0.7130)  time: 0.0881  data: 0.0001  max mem: 10917
[15:21:11.176195] Test:  [200/345]  eta: 0:00:12  loss: 0.7139 (0.7128)  time: 0.0885  data: 0.0001  max mem: 10917
[15:21:12.067219] Test:  [210/345]  eta: 0:00:11  loss: 0.7075 (0.7125)  time: 0.0888  data: 0.0001  max mem: 10917
[15:21:12.961121] Test:  [220/345]  eta: 0:00:10  loss: 0.7100 (0.7128)  time: 0.0892  data: 0.0001  max mem: 10917
[15:21:13.858459] Test:  [230/345]  eta: 0:00:09  loss: 0.7135 (0.7127)  time: 0.0895  data: 0.0001  max mem: 10917
[15:21:14.760164] Test:  [240/345]  eta: 0:00:09  loss: 0.7130 (0.7126)  time: 0.0899  data: 0.0001  max mem: 10917
[15:21:15.664849] Test:  [250/345]  eta: 0:00:08  loss: 0.7090 (0.7126)  time: 0.0903  data: 0.0001  max mem: 10917
[15:21:16.573319] Test:  [260/345]  eta: 0:00:07  loss: 0.7090 (0.7127)  time: 0.0906  data: 0.0001  max mem: 10917
[15:21:17.485705] Test:  [270/345]  eta: 0:00:06  loss: 0.7131 (0.7128)  time: 0.0910  data: 0.0001  max mem: 10917
[15:21:18.400644] Test:  [280/345]  eta: 0:00:05  loss: 0.7136 (0.7128)  time: 0.0913  data: 0.0001  max mem: 10917
[15:21:19.320198] Test:  [290/345]  eta: 0:00:04  loss: 0.7138 (0.7128)  time: 0.0916  data: 0.0001  max mem: 10917
[15:21:20.242099] Test:  [300/345]  eta: 0:00:03  loss: 0.7135 (0.7129)  time: 0.0920  data: 0.0001  max mem: 10917
[15:21:21.168131] Test:  [310/345]  eta: 0:00:03  loss: 0.7154 (0.7131)  time: 0.0923  data: 0.0001  max mem: 10917
[15:21:22.098843] Test:  [320/345]  eta: 0:00:02  loss: 0.7145 (0.7130)  time: 0.0928  data: 0.0001  max mem: 10917
[15:21:23.031370] Test:  [330/345]  eta: 0:00:01  loss: 0.7133 (0.7132)  time: 0.0931  data: 0.0001  max mem: 10917
[15:21:23.967649] Test:  [340/345]  eta: 0:00:00  loss: 0.7109 (0.7131)  time: 0.0934  data: 0.0001  max mem: 10917
[15:21:24.343964] Test:  [344/345]  eta: 0:00:00  loss: 0.7135 (0.7132)  time: 0.0936  data: 0.0001  max mem: 10917
[15:21:24.399278] Test: Total time: 0:00:30 (0.0885 s / it)
[15:21:35.391381] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9060 (0.9060)  time: 0.2243  data: 0.1443  max mem: 10917
[15:21:36.205616] Test:  [10/57]  eta: 0:00:04  loss: 0.9060 (0.9178)  time: 0.0943  data: 0.0132  max mem: 10917
[15:21:37.022366] Test:  [20/57]  eta: 0:00:03  loss: 0.9032 (0.9023)  time: 0.0815  data: 0.0001  max mem: 10917
[15:21:37.843296] Test:  [30/57]  eta: 0:00:02  loss: 0.7964 (0.8621)  time: 0.0818  data: 0.0001  max mem: 10917
[15:21:38.668120] Test:  [40/57]  eta: 0:00:01  loss: 0.7826 (0.8409)  time: 0.0822  data: 0.0001  max mem: 10917
[15:21:39.496106] Test:  [50/57]  eta: 0:00:00  loss: 0.7724 (0.8334)  time: 0.0826  data: 0.0001  max mem: 10917
[15:21:39.946052] Test:  [56/57]  eta: 0:00:00  loss: 0.8133 (0.8385)  time: 0.0804  data: 0.0001  max mem: 10917
[15:21:40.000049] Test: Total time: 0:00:04 (0.0848 s / it)
[15:21:41.960710] Dice score of the network on the train images: 0.827111, val images: 0.808907
[15:21:41.964155] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:21:42.362380] Epoch: [39]  [  0/345]  eta: 0:02:17  lr: 0.000037  loss: 0.7553 (0.7553)  time: 0.3971  data: 0.1439  max mem: 10917
[15:21:47.366802] Epoch: [39]  [ 20/345]  eta: 0:01:23  lr: 0.000037  loss: 0.7424 (0.7459)  time: 0.2502  data: 0.0001  max mem: 10917
[15:21:52.375094] Epoch: [39]  [ 40/345]  eta: 0:01:17  lr: 0.000036  loss: 0.7485 (0.7472)  time: 0.2504  data: 0.0001  max mem: 10917
[15:21:57.385751] Epoch: [39]  [ 60/345]  eta: 0:01:12  lr: 0.000036  loss: 0.7398 (0.7449)  time: 0.2505  data: 0.0001  max mem: 10917
[15:22:02.401798] Epoch: [39]  [ 80/345]  eta: 0:01:06  lr: 0.000036  loss: 0.7420 (0.7443)  time: 0.2508  data: 0.0001  max mem: 10917
[15:22:07.421147] Epoch: [39]  [100/345]  eta: 0:01:01  lr: 0.000035  loss: 0.7433 (0.7443)  time: 0.2509  data: 0.0001  max mem: 10917
[15:22:12.443370] Epoch: [39]  [120/345]  eta: 0:00:56  lr: 0.000035  loss: 0.7392 (0.7438)  time: 0.2511  data: 0.0001  max mem: 10917
[15:22:17.467920] Epoch: [39]  [140/345]  eta: 0:00:51  lr: 0.000035  loss: 0.7431 (0.7440)  time: 0.2512  data: 0.0001  max mem: 10917
[15:22:22.494800] Epoch: [39]  [160/345]  eta: 0:00:46  lr: 0.000034  loss: 0.7399 (0.7441)  time: 0.2513  data: 0.0001  max mem: 10917
[15:22:27.520610] Epoch: [39]  [180/345]  eta: 0:00:41  lr: 0.000034  loss: 0.7419 (0.7442)  time: 0.2513  data: 0.0001  max mem: 10917
[15:22:32.540269] Epoch: [39]  [200/345]  eta: 0:00:36  lr: 0.000034  loss: 0.7427 (0.7440)  time: 0.2509  data: 0.0001  max mem: 10917
[15:22:37.560848] Epoch: [39]  [220/345]  eta: 0:00:31  lr: 0.000033  loss: 0.7378 (0.7437)  time: 0.2510  data: 0.0000  max mem: 10917
[15:22:42.584240] Epoch: [39]  [240/345]  eta: 0:00:26  lr: 0.000033  loss: 0.7452 (0.7441)  time: 0.2511  data: 0.0001  max mem: 10917
[15:22:47.620788] Epoch: [39]  [260/345]  eta: 0:00:21  lr: 0.000033  loss: 0.7399 (0.7437)  time: 0.2518  data: 0.0001  max mem: 10917
[15:22:52.660549] Epoch: [39]  [280/345]  eta: 0:00:16  lr: 0.000032  loss: 0.7428 (0.7436)  time: 0.2519  data: 0.0001  max mem: 10917
[15:22:57.702647] Epoch: [39]  [300/345]  eta: 0:00:11  lr: 0.000032  loss: 0.7397 (0.7435)  time: 0.2521  data: 0.0001  max mem: 10917
[15:23:02.745763] Epoch: [39]  [320/345]  eta: 0:00:06  lr: 0.000032  loss: 0.7436 (0.7435)  time: 0.2521  data: 0.0001  max mem: 10917
[15:23:07.793175] Epoch: [39]  [340/345]  eta: 0:00:01  lr: 0.000031  loss: 0.7420 (0.7435)  time: 0.2523  data: 0.0000  max mem: 10917
[15:23:08.801333] Epoch: [39]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 0.7400 (0.7434)  time: 0.2523  data: 0.0001  max mem: 10917
[15:23:08.858910] Epoch: [39] Total time: 0:01:26 (0.2519 s / it)
[15:23:08.859297] Averaged stats: lr: 0.000031  loss: 0.7400 (0.7434)
[15:23:09.088612] Test:  [  0/345]  eta: 0:01:17  loss: 0.7251 (0.7251)  time: 0.2257  data: 0.1454  max mem: 10917
[15:23:09.909622] Test:  [ 10/345]  eta: 0:00:31  loss: 0.7242 (0.7195)  time: 0.0951  data: 0.0133  max mem: 10917
[15:23:10.733642] Test:  [ 20/345]  eta: 0:00:28  loss: 0.7166 (0.7206)  time: 0.0822  data: 0.0001  max mem: 10917
[15:23:11.560843] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7127 (0.7184)  time: 0.0825  data: 0.0001  max mem: 10917
[15:23:12.391398] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7082 (0.7167)  time: 0.0828  data: 0.0001  max mem: 10917
[15:23:13.227056] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7095 (0.7167)  time: 0.0833  data: 0.0001  max mem: 10917
[15:23:14.065543] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7126 (0.7159)  time: 0.0837  data: 0.0001  max mem: 10917
[15:23:14.906934] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7126 (0.7152)  time: 0.0839  data: 0.0001  max mem: 10917
[15:23:15.751857] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7150 (0.7156)  time: 0.0843  data: 0.0001  max mem: 10917
[15:23:16.600800] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7150 (0.7153)  time: 0.0846  data: 0.0001  max mem: 10917
[15:23:17.452968] Test:  [100/345]  eta: 0:00:20  loss: 0.7131 (0.7148)  time: 0.0850  data: 0.0001  max mem: 10917
[15:23:18.308864] Test:  [110/345]  eta: 0:00:19  loss: 0.7034 (0.7136)  time: 0.0854  data: 0.0001  max mem: 10917
[15:23:19.168458] Test:  [120/345]  eta: 0:00:19  loss: 0.7016 (0.7129)  time: 0.0857  data: 0.0001  max mem: 10917
[15:23:20.030679] Test:  [130/345]  eta: 0:00:18  loss: 0.7064 (0.7123)  time: 0.0860  data: 0.0001  max mem: 10917
[15:23:20.897129] Test:  [140/345]  eta: 0:00:17  loss: 0.7099 (0.7129)  time: 0.0864  data: 0.0001  max mem: 10917
[15:23:21.766550] Test:  [150/345]  eta: 0:00:16  loss: 0.7177 (0.7133)  time: 0.0867  data: 0.0001  max mem: 10917
[15:23:22.639840] Test:  [160/345]  eta: 0:00:15  loss: 0.7131 (0.7132)  time: 0.0871  data: 0.0001  max mem: 10917
[15:23:23.516772] Test:  [170/345]  eta: 0:00:14  loss: 0.7100 (0.7130)  time: 0.0874  data: 0.0001  max mem: 10917
[15:23:24.397781] Test:  [180/345]  eta: 0:00:14  loss: 0.7073 (0.7130)  time: 0.0878  data: 0.0001  max mem: 10917
[15:23:25.282142] Test:  [190/345]  eta: 0:00:13  loss: 0.7049 (0.7127)  time: 0.0882  data: 0.0001  max mem: 10917
[15:23:26.169563] Test:  [200/345]  eta: 0:00:12  loss: 0.7065 (0.7127)  time: 0.0885  data: 0.0001  max mem: 10917
[15:23:27.061958] Test:  [210/345]  eta: 0:00:11  loss: 0.7098 (0.7124)  time: 0.0889  data: 0.0001  max mem: 10917
[15:23:27.957068] Test:  [220/345]  eta: 0:00:10  loss: 0.7085 (0.7123)  time: 0.0893  data: 0.0001  max mem: 10917
[15:23:28.854945] Test:  [230/345]  eta: 0:00:09  loss: 0.7057 (0.7122)  time: 0.0896  data: 0.0001  max mem: 10917
[15:23:29.757176] Test:  [240/345]  eta: 0:00:09  loss: 0.7127 (0.7123)  time: 0.0900  data: 0.0001  max mem: 10917
[15:23:30.662411] Test:  [250/345]  eta: 0:00:08  loss: 0.7099 (0.7120)  time: 0.0903  data: 0.0001  max mem: 10917
[15:23:31.570935] Test:  [260/345]  eta: 0:00:07  loss: 0.7051 (0.7117)  time: 0.0906  data: 0.0001  max mem: 10917
[15:23:32.484316] Test:  [270/345]  eta: 0:00:06  loss: 0.7024 (0.7118)  time: 0.0910  data: 0.0001  max mem: 10917
[15:23:33.400324] Test:  [280/345]  eta: 0:00:05  loss: 0.7128 (0.7118)  time: 0.0914  data: 0.0001  max mem: 10917
[15:23:34.318680] Test:  [290/345]  eta: 0:00:04  loss: 0.7087 (0.7118)  time: 0.0917  data: 0.0001  max mem: 10917
[15:23:35.240723] Test:  [300/345]  eta: 0:00:03  loss: 0.7063 (0.7118)  time: 0.0920  data: 0.0001  max mem: 10917
[15:23:36.165935] Test:  [310/345]  eta: 0:00:03  loss: 0.7148 (0.7119)  time: 0.0923  data: 0.0001  max mem: 10917
[15:23:37.095544] Test:  [320/345]  eta: 0:00:02  loss: 0.7166 (0.7122)  time: 0.0927  data: 0.0001  max mem: 10917
[15:23:38.027975] Test:  [330/345]  eta: 0:00:01  loss: 0.7166 (0.7124)  time: 0.0931  data: 0.0001  max mem: 10917
[15:23:38.963890] Test:  [340/345]  eta: 0:00:00  loss: 0.7095 (0.7124)  time: 0.0934  data: 0.0001  max mem: 10917
[15:23:39.339750] Test:  [344/345]  eta: 0:00:00  loss: 0.7111 (0.7124)  time: 0.0935  data: 0.0001  max mem: 10917
[15:23:39.394597] Test: Total time: 0:00:30 (0.0885 s / it)
[15:23:50.556815] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9098 (0.9098)  time: 0.2210  data: 0.1414  max mem: 10917
[15:23:51.370264] Test:  [10/57]  eta: 0:00:04  loss: 0.9098 (0.9195)  time: 0.0940  data: 0.0129  max mem: 10917
[15:23:52.188020] Test:  [20/57]  eta: 0:00:03  loss: 0.8999 (0.9051)  time: 0.0815  data: 0.0001  max mem: 10917
[15:23:53.008872] Test:  [30/57]  eta: 0:00:02  loss: 0.7976 (0.8630)  time: 0.0819  data: 0.0001  max mem: 10917
[15:23:53.833306] Test:  [40/57]  eta: 0:00:01  loss: 0.7816 (0.8411)  time: 0.0822  data: 0.0001  max mem: 10917
[15:23:54.661904] Test:  [50/57]  eta: 0:00:00  loss: 0.7708 (0.8335)  time: 0.0826  data: 0.0001  max mem: 10917
[15:23:55.112333] Test:  [56/57]  eta: 0:00:00  loss: 0.8155 (0.8391)  time: 0.0804  data: 0.0001  max mem: 10917
[15:23:55.168084] Test: Total time: 0:00:04 (0.0848 s / it)
[15:23:57.120248] Dice score of the network on the train images: 0.827389, val images: 0.810228
[15:23:57.123850] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:23:57.519005] Epoch: [40]  [  0/345]  eta: 0:02:16  lr: 0.000031  loss: 0.7369 (0.7369)  time: 0.3943  data: 0.1421  max mem: 10917
[15:24:02.503559] Epoch: [40]  [ 20/345]  eta: 0:01:23  lr: 0.000031  loss: 0.7427 (0.7433)  time: 0.2492  data: 0.0000  max mem: 10917
[15:24:07.491455] Epoch: [40]  [ 40/345]  eta: 0:01:17  lr: 0.000031  loss: 0.7397 (0.7428)  time: 0.2494  data: 0.0000  max mem: 10917
[15:24:12.488152] Epoch: [40]  [ 60/345]  eta: 0:01:11  lr: 0.000030  loss: 0.7438 (0.7436)  time: 0.2498  data: 0.0000  max mem: 10917
[15:24:17.488474] Epoch: [40]  [ 80/345]  eta: 0:01:06  lr: 0.000030  loss: 0.7381 (0.7425)  time: 0.2500  data: 0.0000  max mem: 10917
[15:24:22.490438] Epoch: [40]  [100/345]  eta: 0:01:01  lr: 0.000030  loss: 0.7394 (0.7430)  time: 0.2501  data: 0.0000  max mem: 10917
[15:24:27.496055] Epoch: [40]  [120/345]  eta: 0:00:56  lr: 0.000029  loss: 0.7361 (0.7427)  time: 0.2502  data: 0.0000  max mem: 10917
[15:24:32.509202] Epoch: [40]  [140/345]  eta: 0:00:51  lr: 0.000029  loss: 0.7421 (0.7425)  time: 0.2506  data: 0.0000  max mem: 10917
[15:24:37.522984] Epoch: [40]  [160/345]  eta: 0:00:46  lr: 0.000029  loss: 0.7418 (0.7425)  time: 0.2507  data: 0.0000  max mem: 10917
[15:24:42.537588] Epoch: [40]  [180/345]  eta: 0:00:41  lr: 0.000028  loss: 0.7430 (0.7424)  time: 0.2507  data: 0.0000  max mem: 10917
[15:24:47.555523] Epoch: [40]  [200/345]  eta: 0:00:36  lr: 0.000028  loss: 0.7411 (0.7426)  time: 0.2509  data: 0.0000  max mem: 10917
[15:24:52.565202] Epoch: [40]  [220/345]  eta: 0:00:31  lr: 0.000028  loss: 0.7425 (0.7430)  time: 0.2504  data: 0.0000  max mem: 10917
[15:24:57.586547] Epoch: [40]  [240/345]  eta: 0:00:26  lr: 0.000027  loss: 0.7453 (0.7433)  time: 0.2510  data: 0.0001  max mem: 10917
[15:25:02.607794] Epoch: [40]  [260/345]  eta: 0:00:21  lr: 0.000027  loss: 0.7339 (0.7428)  time: 0.2510  data: 0.0000  max mem: 10917
[15:25:07.634369] Epoch: [40]  [280/345]  eta: 0:00:16  lr: 0.000027  loss: 0.7425 (0.7430)  time: 0.2513  data: 0.0000  max mem: 10917
[15:25:12.657915] Epoch: [40]  [300/345]  eta: 0:00:11  lr: 0.000026  loss: 0.7344 (0.7426)  time: 0.2511  data: 0.0000  max mem: 10917
[15:25:17.685552] Epoch: [40]  [320/345]  eta: 0:00:06  lr: 0.000026  loss: 0.7405 (0.7427)  time: 0.2513  data: 0.0000  max mem: 10917
[15:25:22.710977] Epoch: [40]  [340/345]  eta: 0:00:01  lr: 0.000026  loss: 0.7409 (0.7427)  time: 0.2512  data: 0.0000  max mem: 10917
[15:25:23.717624] Epoch: [40]  [344/345]  eta: 0:00:00  lr: 0.000026  loss: 0.7414 (0.7429)  time: 0.2513  data: 0.0001  max mem: 10917
[15:25:23.774816] Epoch: [40] Total time: 0:01:26 (0.2512 s / it)
[15:25:23.775265] Averaged stats: lr: 0.000026  loss: 0.7414 (0.7429)
[15:25:24.012758] Test:  [  0/345]  eta: 0:01:20  loss: 0.6982 (0.6982)  time: 0.2345  data: 0.1545  max mem: 10917
[15:25:24.834679] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7097 (0.7093)  time: 0.0960  data: 0.0141  max mem: 10917
[15:25:25.658599] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7097 (0.7098)  time: 0.0822  data: 0.0001  max mem: 10917
[15:25:26.486894] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7063 (0.7092)  time: 0.0826  data: 0.0001  max mem: 10917
[15:25:27.318699] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7113 (0.7100)  time: 0.0830  data: 0.0001  max mem: 10917
[15:25:28.152709] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7113 (0.7096)  time: 0.0832  data: 0.0001  max mem: 10917
[15:25:28.991790] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7113 (0.7100)  time: 0.0836  data: 0.0001  max mem: 10917
[15:25:29.833878] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7104 (0.7097)  time: 0.0840  data: 0.0001  max mem: 10917
[15:25:30.679114] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7068 (0.7094)  time: 0.0843  data: 0.0001  max mem: 10917
[15:25:31.527727] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7059 (0.7090)  time: 0.0846  data: 0.0001  max mem: 10917
[15:25:32.380047] Test:  [100/345]  eta: 0:00:20  loss: 0.7086 (0.7094)  time: 0.0850  data: 0.0001  max mem: 10917
[15:25:33.235434] Test:  [110/345]  eta: 0:00:20  loss: 0.7065 (0.7095)  time: 0.0853  data: 0.0001  max mem: 10917
[15:25:34.094964] Test:  [120/345]  eta: 0:00:19  loss: 0.7119 (0.7099)  time: 0.0857  data: 0.0001  max mem: 10917
[15:25:34.957760] Test:  [130/345]  eta: 0:00:18  loss: 0.7117 (0.7102)  time: 0.0861  data: 0.0001  max mem: 10917
[15:25:35.823884] Test:  [140/345]  eta: 0:00:17  loss: 0.7103 (0.7101)  time: 0.0864  data: 0.0001  max mem: 10917
[15:25:36.694422] Test:  [150/345]  eta: 0:00:16  loss: 0.7104 (0.7102)  time: 0.0868  data: 0.0001  max mem: 10917
[15:25:37.568226] Test:  [160/345]  eta: 0:00:15  loss: 0.7137 (0.7105)  time: 0.0872  data: 0.0001  max mem: 10917
[15:25:38.445246] Test:  [170/345]  eta: 0:00:15  loss: 0.7137 (0.7104)  time: 0.0875  data: 0.0001  max mem: 10917
[15:25:39.325990] Test:  [180/345]  eta: 0:00:14  loss: 0.7093 (0.7102)  time: 0.0878  data: 0.0001  max mem: 10917
[15:25:40.209432] Test:  [190/345]  eta: 0:00:13  loss: 0.7044 (0.7102)  time: 0.0882  data: 0.0001  max mem: 10917
[15:25:41.097375] Test:  [200/345]  eta: 0:00:12  loss: 0.7044 (0.7102)  time: 0.0885  data: 0.0001  max mem: 10917
[15:25:41.988251] Test:  [210/345]  eta: 0:00:11  loss: 0.7042 (0.7098)  time: 0.0889  data: 0.0001  max mem: 10917
[15:25:42.882725] Test:  [220/345]  eta: 0:00:10  loss: 0.7043 (0.7100)  time: 0.0892  data: 0.0001  max mem: 10917
[15:25:43.780491] Test:  [230/345]  eta: 0:00:09  loss: 0.7100 (0.7102)  time: 0.0896  data: 0.0001  max mem: 10917
[15:25:44.682931] Test:  [240/345]  eta: 0:00:09  loss: 0.7147 (0.7105)  time: 0.0900  data: 0.0001  max mem: 10917
[15:25:45.587615] Test:  [250/345]  eta: 0:00:08  loss: 0.7133 (0.7104)  time: 0.0903  data: 0.0001  max mem: 10917
[15:25:46.496231] Test:  [260/345]  eta: 0:00:07  loss: 0.7094 (0.7105)  time: 0.0906  data: 0.0001  max mem: 10917
[15:25:47.407830] Test:  [270/345]  eta: 0:00:06  loss: 0.7094 (0.7105)  time: 0.0910  data: 0.0001  max mem: 10917
[15:25:48.323184] Test:  [280/345]  eta: 0:00:05  loss: 0.7102 (0.7106)  time: 0.0913  data: 0.0001  max mem: 10917
[15:25:49.242953] Test:  [290/345]  eta: 0:00:04  loss: 0.7105 (0.7107)  time: 0.0917  data: 0.0001  max mem: 10917
[15:25:50.165172] Test:  [300/345]  eta: 0:00:03  loss: 0.7130 (0.7110)  time: 0.0921  data: 0.0001  max mem: 10917
[15:25:51.090971] Test:  [310/345]  eta: 0:00:03  loss: 0.7111 (0.7107)  time: 0.0924  data: 0.0001  max mem: 10917
[15:25:52.021070] Test:  [320/345]  eta: 0:00:02  loss: 0.7096 (0.7109)  time: 0.0927  data: 0.0001  max mem: 10917
[15:25:52.954029] Test:  [330/345]  eta: 0:00:01  loss: 0.7117 (0.7109)  time: 0.0931  data: 0.0001  max mem: 10917
[15:25:53.890355] Test:  [340/345]  eta: 0:00:00  loss: 0.7099 (0.7109)  time: 0.0934  data: 0.0001  max mem: 10917
[15:25:54.266831] Test:  [344/345]  eta: 0:00:00  loss: 0.7099 (0.7110)  time: 0.0936  data: 0.0001  max mem: 10917
[15:25:54.324473] Test: Total time: 0:00:30 (0.0885 s / it)
[15:26:05.493275] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9134 (0.9134)  time: 0.2229  data: 0.1432  max mem: 10917
[15:26:06.305905] Test:  [10/57]  eta: 0:00:04  loss: 0.9134 (0.9219)  time: 0.0941  data: 0.0131  max mem: 10917
[15:26:07.123484] Test:  [20/57]  eta: 0:00:03  loss: 0.9029 (0.9063)  time: 0.0814  data: 0.0001  max mem: 10917
[15:26:07.944539] Test:  [30/57]  eta: 0:00:02  loss: 0.7995 (0.8655)  time: 0.0819  data: 0.0001  max mem: 10917
[15:26:08.768453] Test:  [40/57]  eta: 0:00:01  loss: 0.7826 (0.8440)  time: 0.0822  data: 0.0001  max mem: 10917
[15:26:09.596521] Test:  [50/57]  eta: 0:00:00  loss: 0.7792 (0.8360)  time: 0.0825  data: 0.0001  max mem: 10917
[15:26:10.046595] Test:  [56/57]  eta: 0:00:00  loss: 0.8133 (0.8411)  time: 0.0803  data: 0.0001  max mem: 10917
[15:26:10.105506] Test: Total time: 0:00:04 (0.0848 s / it)
[15:26:12.111522] Dice score of the network on the train images: 0.830201, val images: 0.809700
[15:26:12.115172] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:26:12.512524] Epoch: [41]  [  0/345]  eta: 0:02:16  lr: 0.000026  loss: 0.7317 (0.7317)  time: 0.3965  data: 0.1447  max mem: 10917
[15:26:17.567240] Epoch: [41]  [ 20/345]  eta: 0:01:24  lr: 0.000025  loss: 0.7397 (0.7400)  time: 0.2527  data: 0.0000  max mem: 10917
[15:26:22.549352] Epoch: [41]  [ 40/345]  eta: 0:01:17  lr: 0.000025  loss: 0.7419 (0.7424)  time: 0.2491  data: 0.0000  max mem: 10917
[15:26:27.537348] Epoch: [41]  [ 60/345]  eta: 0:01:12  lr: 0.000025  loss: 0.7407 (0.7424)  time: 0.2494  data: 0.0001  max mem: 10917
[15:26:32.530177] Epoch: [41]  [ 80/345]  eta: 0:01:06  lr: 0.000025  loss: 0.7299 (0.7405)  time: 0.2496  data: 0.0000  max mem: 10917
[15:26:37.530179] Epoch: [41]  [100/345]  eta: 0:01:01  lr: 0.000024  loss: 0.7349 (0.7400)  time: 0.2500  data: 0.0000  max mem: 10917
[15:26:42.530583] Epoch: [41]  [120/345]  eta: 0:00:56  lr: 0.000024  loss: 0.7371 (0.7405)  time: 0.2500  data: 0.0000  max mem: 10917
[15:26:47.539942] Epoch: [41]  [140/345]  eta: 0:00:51  lr: 0.000024  loss: 0.7369 (0.7405)  time: 0.2504  data: 0.0000  max mem: 10917
[15:26:52.551674] Epoch: [41]  [160/345]  eta: 0:00:46  lr: 0.000023  loss: 0.7368 (0.7407)  time: 0.2506  data: 0.0000  max mem: 10917
[15:26:57.564768] Epoch: [41]  [180/345]  eta: 0:00:41  lr: 0.000023  loss: 0.7397 (0.7409)  time: 0.2506  data: 0.0000  max mem: 10917
[15:27:02.579704] Epoch: [41]  [200/345]  eta: 0:00:36  lr: 0.000023  loss: 0.7377 (0.7405)  time: 0.2507  data: 0.0000  max mem: 10917
[15:27:07.594189] Epoch: [41]  [220/345]  eta: 0:00:31  lr: 0.000022  loss: 0.7416 (0.7406)  time: 0.2507  data: 0.0001  max mem: 10917
[15:27:12.611888] Epoch: [41]  [240/345]  eta: 0:00:26  lr: 0.000022  loss: 0.7393 (0.7407)  time: 0.2508  data: 0.0000  max mem: 10917
[15:27:17.632271] Epoch: [41]  [260/345]  eta: 0:00:21  lr: 0.000022  loss: 0.7407 (0.7410)  time: 0.2510  data: 0.0000  max mem: 10917
[15:27:22.657586] Epoch: [41]  [280/345]  eta: 0:00:16  lr: 0.000022  loss: 0.7425 (0.7412)  time: 0.2512  data: 0.0001  max mem: 10917
[15:27:27.680997] Epoch: [41]  [300/345]  eta: 0:00:11  lr: 0.000021  loss: 0.7410 (0.7414)  time: 0.2511  data: 0.0000  max mem: 10917
[15:27:32.708190] Epoch: [41]  [320/345]  eta: 0:00:06  lr: 0.000021  loss: 0.7421 (0.7416)  time: 0.2513  data: 0.0000  max mem: 10917
[15:27:37.736341] Epoch: [41]  [340/345]  eta: 0:00:01  lr: 0.000021  loss: 0.7369 (0.7415)  time: 0.2514  data: 0.0000  max mem: 10917
[15:27:38.746036] Epoch: [41]  [344/345]  eta: 0:00:00  lr: 0.000021  loss: 0.7350 (0.7415)  time: 0.2516  data: 0.0001  max mem: 10917
[15:27:38.806946] Epoch: [41] Total time: 0:01:26 (0.2513 s / it)
[15:27:38.807261] Averaged stats: lr: 0.000021  loss: 0.7350 (0.7415)
[15:27:39.044270] Test:  [  0/345]  eta: 0:01:20  loss: 0.7230 (0.7230)  time: 0.2333  data: 0.1532  max mem: 10917
[15:27:39.904612] Test:  [ 10/345]  eta: 0:00:33  loss: 0.7139 (0.7126)  time: 0.0994  data: 0.0178  max mem: 10917
[15:27:40.748748] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7139 (0.7145)  time: 0.0852  data: 0.0032  max mem: 10917
[15:27:41.575500] Test:  [ 30/345]  eta: 0:00:28  loss: 0.7069 (0.7117)  time: 0.0835  data: 0.0011  max mem: 10917
[15:27:42.406729] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7069 (0.7109)  time: 0.0829  data: 0.0001  max mem: 10917
[15:27:43.241221] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7069 (0.7108)  time: 0.0832  data: 0.0001  max mem: 10917
[15:27:44.079506] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7118 (0.7113)  time: 0.0836  data: 0.0001  max mem: 10917
[15:27:44.921313] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7118 (0.7105)  time: 0.0840  data: 0.0001  max mem: 10917
[15:27:45.766687] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7121 (0.7117)  time: 0.0843  data: 0.0001  max mem: 10917
[15:27:46.615198] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7121 (0.7116)  time: 0.0846  data: 0.0001  max mem: 10917
[15:27:47.467523] Test:  [100/345]  eta: 0:00:20  loss: 0.7085 (0.7108)  time: 0.0850  data: 0.0001  max mem: 10917
[15:27:48.323031] Test:  [110/345]  eta: 0:00:20  loss: 0.7052 (0.7115)  time: 0.0853  data: 0.0001  max mem: 10917
[15:27:49.181949] Test:  [120/345]  eta: 0:00:19  loss: 0.7085 (0.7111)  time: 0.0857  data: 0.0001  max mem: 10917
[15:27:50.044042] Test:  [130/345]  eta: 0:00:18  loss: 0.7055 (0.7107)  time: 0.0860  data: 0.0001  max mem: 10917
[15:27:50.910281] Test:  [140/345]  eta: 0:00:17  loss: 0.7092 (0.7110)  time: 0.0864  data: 0.0001  max mem: 10917
[15:27:51.779982] Test:  [150/345]  eta: 0:00:16  loss: 0.7185 (0.7115)  time: 0.0868  data: 0.0001  max mem: 10917
[15:27:52.653562] Test:  [160/345]  eta: 0:00:15  loss: 0.7149 (0.7117)  time: 0.0871  data: 0.0001  max mem: 10917
[15:27:53.530354] Test:  [170/345]  eta: 0:00:15  loss: 0.7061 (0.7114)  time: 0.0875  data: 0.0001  max mem: 10917
[15:27:54.411197] Test:  [180/345]  eta: 0:00:14  loss: 0.7061 (0.7115)  time: 0.0878  data: 0.0001  max mem: 10917
[15:27:55.295088] Test:  [190/345]  eta: 0:00:13  loss: 0.7065 (0.7116)  time: 0.0882  data: 0.0001  max mem: 10917
[15:27:56.182317] Test:  [200/345]  eta: 0:00:12  loss: 0.7026 (0.7114)  time: 0.0885  data: 0.0001  max mem: 10917
[15:27:57.073282] Test:  [210/345]  eta: 0:00:11  loss: 0.7091 (0.7115)  time: 0.0889  data: 0.0001  max mem: 10917
[15:27:57.967820] Test:  [220/345]  eta: 0:00:10  loss: 0.7139 (0.7116)  time: 0.0892  data: 0.0001  max mem: 10917
[15:27:58.866058] Test:  [230/345]  eta: 0:00:09  loss: 0.7113 (0.7119)  time: 0.0896  data: 0.0001  max mem: 10917
[15:27:59.767642] Test:  [240/345]  eta: 0:00:09  loss: 0.7115 (0.7118)  time: 0.0899  data: 0.0001  max mem: 10917
[15:28:00.673395] Test:  [250/345]  eta: 0:00:08  loss: 0.7083 (0.7119)  time: 0.0903  data: 0.0001  max mem: 10917
[15:28:01.582235] Test:  [260/345]  eta: 0:00:07  loss: 0.7111 (0.7120)  time: 0.0907  data: 0.0001  max mem: 10917
[15:28:02.494743] Test:  [270/345]  eta: 0:00:06  loss: 0.7129 (0.7120)  time: 0.0910  data: 0.0001  max mem: 10917
[15:28:03.410685] Test:  [280/345]  eta: 0:00:05  loss: 0.7069 (0.7118)  time: 0.0914  data: 0.0001  max mem: 10917
[15:28:04.329790] Test:  [290/345]  eta: 0:00:04  loss: 0.7086 (0.7119)  time: 0.0917  data: 0.0001  max mem: 10917
[15:28:05.252351] Test:  [300/345]  eta: 0:00:03  loss: 0.7149 (0.7119)  time: 0.0920  data: 0.0001  max mem: 10917
[15:28:06.177932] Test:  [310/345]  eta: 0:00:03  loss: 0.7075 (0.7118)  time: 0.0924  data: 0.0001  max mem: 10917
[15:28:07.107954] Test:  [320/345]  eta: 0:00:02  loss: 0.7075 (0.7117)  time: 0.0927  data: 0.0001  max mem: 10917
[15:28:08.040484] Test:  [330/345]  eta: 0:00:01  loss: 0.7101 (0.7118)  time: 0.0931  data: 0.0001  max mem: 10917
[15:28:08.977161] Test:  [340/345]  eta: 0:00:00  loss: 0.7067 (0.7118)  time: 0.0934  data: 0.0001  max mem: 10917
[15:28:09.353170] Test:  [344/345]  eta: 0:00:00  loss: 0.7067 (0.7119)  time: 0.0936  data: 0.0001  max mem: 10917
[15:28:09.411034] Test: Total time: 0:00:30 (0.0887 s / it)
[15:28:20.559535] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9078 (0.9078)  time: 0.2188  data: 0.1389  max mem: 10917
[15:28:21.372509] Test:  [10/57]  eta: 0:00:04  loss: 0.9134 (0.9196)  time: 0.0937  data: 0.0127  max mem: 10917
[15:28:22.189517] Test:  [20/57]  eta: 0:00:03  loss: 0.9019 (0.9036)  time: 0.0814  data: 0.0001  max mem: 10917
[15:28:23.010730] Test:  [30/57]  eta: 0:00:02  loss: 0.7999 (0.8641)  time: 0.0819  data: 0.0001  max mem: 10917
[15:28:23.834687] Test:  [40/57]  eta: 0:00:01  loss: 0.7832 (0.8430)  time: 0.0822  data: 0.0001  max mem: 10917
[15:28:24.662329] Test:  [50/57]  eta: 0:00:00  loss: 0.7765 (0.8352)  time: 0.0825  data: 0.0001  max mem: 10917
[15:28:25.112555] Test:  [56/57]  eta: 0:00:00  loss: 0.8187 (0.8409)  time: 0.0803  data: 0.0001  max mem: 10917
[15:28:25.168994] Test: Total time: 0:00:04 (0.0847 s / it)
[15:28:27.151819] Dice score of the network on the train images: 0.828368, val images: 0.810715
[15:28:27.155315] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:28:27.550412] Epoch: [42]  [  0/345]  eta: 0:02:15  lr: 0.000021  loss: 0.7344 (0.7344)  time: 0.3940  data: 0.1415  max mem: 10917
[15:28:32.541368] Epoch: [42]  [ 20/345]  eta: 0:01:23  lr: 0.000020  loss: 0.7400 (0.7389)  time: 0.2495  data: 0.0001  max mem: 10917
[15:28:37.527730] Epoch: [42]  [ 40/345]  eta: 0:01:17  lr: 0.000020  loss: 0.7364 (0.7403)  time: 0.2493  data: 0.0000  max mem: 10917
[15:28:42.517394] Epoch: [42]  [ 60/345]  eta: 0:01:11  lr: 0.000020  loss: 0.7353 (0.7398)  time: 0.2494  data: 0.0000  max mem: 10917
[15:28:47.510019] Epoch: [42]  [ 80/345]  eta: 0:01:06  lr: 0.000020  loss: 0.7406 (0.7407)  time: 0.2496  data: 0.0000  max mem: 10917
[15:28:52.511348] Epoch: [42]  [100/345]  eta: 0:01:01  lr: 0.000019  loss: 0.7401 (0.7416)  time: 0.2500  data: 0.0000  max mem: 10917
[15:28:57.516985] Epoch: [42]  [120/345]  eta: 0:00:56  lr: 0.000019  loss: 0.7369 (0.7415)  time: 0.2502  data: 0.0000  max mem: 10917
[15:29:02.522292] Epoch: [42]  [140/345]  eta: 0:00:51  lr: 0.000019  loss: 0.7400 (0.7411)  time: 0.2502  data: 0.0000  max mem: 10917
[15:29:07.528899] Epoch: [42]  [160/345]  eta: 0:00:46  lr: 0.000018  loss: 0.7443 (0.7417)  time: 0.2503  data: 0.0000  max mem: 10917
[15:29:12.542502] Epoch: [42]  [180/345]  eta: 0:00:41  lr: 0.000018  loss: 0.7352 (0.7412)  time: 0.2506  data: 0.0000  max mem: 10917
[15:29:17.558603] Epoch: [42]  [200/345]  eta: 0:00:36  lr: 0.000018  loss: 0.7402 (0.7412)  time: 0.2508  data: 0.0000  max mem: 10917
[15:29:22.588643] Epoch: [42]  [220/345]  eta: 0:00:31  lr: 0.000018  loss: 0.7391 (0.7412)  time: 0.2515  data: 0.0001  max mem: 10917
[15:29:27.617834] Epoch: [42]  [240/345]  eta: 0:00:26  lr: 0.000017  loss: 0.7424 (0.7412)  time: 0.2514  data: 0.0001  max mem: 10917
[15:29:32.642826] Epoch: [42]  [260/345]  eta: 0:00:21  lr: 0.000017  loss: 0.7380 (0.7409)  time: 0.2512  data: 0.0000  max mem: 10917
[15:29:37.667774] Epoch: [42]  [280/345]  eta: 0:00:16  lr: 0.000017  loss: 0.7392 (0.7412)  time: 0.2512  data: 0.0001  max mem: 10917
[15:29:42.693998] Epoch: [42]  [300/345]  eta: 0:00:11  lr: 0.000017  loss: 0.7388 (0.7413)  time: 0.2513  data: 0.0000  max mem: 10917

[15:29:47.720701] Epoch: [42]  [320/345]  eta: 0:00:06  lr: 0.000016  loss: 0.7361 (0.7410)  time: 0.2513  data: 0.0001  max mem: 10917
[15:29:52.750075] Epoch: [42]  [340/345]  eta: 0:00:01  lr: 0.000016  loss: 0.7342 (0.7407)  time: 0.2514  data: 0.0000  max mem: 10917
[15:29:53.757983] Epoch: [42]  [344/345]  eta: 0:00:00  lr: 0.000016  loss: 0.7352 (0.7408)  time: 0.2516  data: 0.0001  max mem: 10917
[15:29:53.815658] Epoch: [42] Total time: 0:01:26 (0.2512 s / it)
[15:29:53.816135] Averaged stats: lr: 0.000016  loss: 0.7352 (0.7408)
[15:29:54.057885] Test:  [  0/345]  eta: 0:01:22  loss: 0.7337 (0.7337)  time: 0.2387  data: 0.1584  max mem: 10917
[15:29:54.881847] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7122 (0.7162)  time: 0.0965  data: 0.0148  max mem: 10917
[15:29:55.705696] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7101 (0.7124)  time: 0.0823  data: 0.0002  max mem: 10917
[15:29:56.532751] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7099 (0.7142)  time: 0.0825  data: 0.0001  max mem: 10917
[15:29:57.364189] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7108 (0.7145)  time: 0.0829  data: 0.0001  max mem: 10917
[15:29:58.198430] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7149 (0.7149)  time: 0.0832  data: 0.0001  max mem: 10917
[15:29:59.036860] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7149 (0.7144)  time: 0.0836  data: 0.0001  max mem: 10917
[15:29:59.878986] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7161 (0.7138)  time: 0.0840  data: 0.0001  max mem: 10917
[15:30:00.724431] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7128 (0.7132)  time: 0.0843  data: 0.0001  max mem: 10917
[15:30:01.573473] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7128 (0.7135)  time: 0.0847  data: 0.0001  max mem: 10917
[15:30:02.425057] Test:  [100/345]  eta: 0:00:20  loss: 0.7141 (0.7134)  time: 0.0850  data: 0.0001  max mem: 10917
[15:30:03.280753] Test:  [110/345]  eta: 0:00:20  loss: 0.7084 (0.7129)  time: 0.0853  data: 0.0001  max mem: 10917
[15:30:04.140935] Test:  [120/345]  eta: 0:00:19  loss: 0.7068 (0.7126)  time: 0.0857  data: 0.0001  max mem: 10917
[15:30:05.003723] Test:  [130/345]  eta: 0:00:18  loss: 0.7082 (0.7126)  time: 0.0861  data: 0.0001  max mem: 10917
[15:30:05.869861] Test:  [140/345]  eta: 0:00:17  loss: 0.7069 (0.7123)  time: 0.0864  data: 0.0001  max mem: 10917
[15:30:06.739633] Test:  [150/345]  eta: 0:00:16  loss: 0.7080 (0.7122)  time: 0.0867  data: 0.0001  max mem: 10917
[15:30:07.613185] Test:  [160/345]  eta: 0:00:15  loss: 0.7100 (0.7119)  time: 0.0871  data: 0.0001  max mem: 10917
[15:30:08.490136] Test:  [170/345]  eta: 0:00:15  loss: 0.7056 (0.7117)  time: 0.0875  data: 0.0001  max mem: 10917
[15:30:09.370776] Test:  [180/345]  eta: 0:00:14  loss: 0.7095 (0.7116)  time: 0.0878  data: 0.0001  max mem: 10917
[15:30:10.254630] Test:  [190/345]  eta: 0:00:13  loss: 0.7073 (0.7113)  time: 0.0882  data: 0.0001  max mem: 10917
[15:30:11.143803] Test:  [200/345]  eta: 0:00:12  loss: 0.7066 (0.7115)  time: 0.0886  data: 0.0001  max mem: 10917
[15:30:12.035242] Test:  [210/345]  eta: 0:00:11  loss: 0.7125 (0.7118)  time: 0.0890  data: 0.0001  max mem: 10917
[15:30:12.929240] Test:  [220/345]  eta: 0:00:10  loss: 0.7120 (0.7118)  time: 0.0892  data: 0.0001  max mem: 10917
[15:30:13.828072] Test:  [230/345]  eta: 0:00:09  loss: 0.7051 (0.7115)  time: 0.0896  data: 0.0001  max mem: 10917
[15:30:14.730221] Test:  [240/345]  eta: 0:00:09  loss: 0.7061 (0.7114)  time: 0.0900  data: 0.0001  max mem: 10917
[15:30:15.634906] Test:  [250/345]  eta: 0:00:08  loss: 0.7071 (0.7113)  time: 0.0903  data: 0.0001  max mem: 10917
[15:30:16.542856] Test:  [260/345]  eta: 0:00:07  loss: 0.7058 (0.7113)  time: 0.0906  data: 0.0001  max mem: 10917
[15:30:17.455481] Test:  [270/345]  eta: 0:00:06  loss: 0.7075 (0.7112)  time: 0.0910  data: 0.0001  max mem: 10917
[15:30:18.371934] Test:  [280/345]  eta: 0:00:05  loss: 0.7116 (0.7114)  time: 0.0914  data: 0.0001  max mem: 10917
[15:30:19.291075] Test:  [290/345]  eta: 0:00:04  loss: 0.7111 (0.7114)  time: 0.0917  data: 0.0001  max mem: 10917
[15:30:20.214106] Test:  [300/345]  eta: 0:00:03  loss: 0.7048 (0.7113)  time: 0.0921  data: 0.0001  max mem: 10917
[15:30:21.141498] Test:  [310/345]  eta: 0:00:03  loss: 0.7088 (0.7114)  time: 0.0925  data: 0.0001  max mem: 10917
[15:30:22.071731] Test:  [320/345]  eta: 0:00:02  loss: 0.7122 (0.7115)  time: 0.0928  data: 0.0001  max mem: 10917
[15:30:23.004554] Test:  [330/345]  eta: 0:00:01  loss: 0.7139 (0.7116)  time: 0.0931  data: 0.0001  max mem: 10917
[15:30:23.941092] Test:  [340/345]  eta: 0:00:00  loss: 0.7121 (0.7117)  time: 0.0934  data: 0.0001  max mem: 10917
[15:30:24.317235] Test:  [344/345]  eta: 0:00:00  loss: 0.7087 (0.7117)  time: 0.0936  data: 0.0001  max mem: 10917
[15:30:24.374371] Test: Total time: 0:00:30 (0.0886 s / it)
[15:30:35.581026] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9157 (0.9157)  time: 0.2238  data: 0.1440  max mem: 10917
[15:30:36.395012] Test:  [10/57]  eta: 0:00:04  loss: 0.9167 (0.9335)  time: 0.0943  data: 0.0131  max mem: 10917
[15:30:37.211703] Test:  [20/57]  eta: 0:00:03  loss: 0.9112 (0.9154)  time: 0.0815  data: 0.0001  max mem: 10917
[15:30:38.032529] Test:  [30/57]  eta: 0:00:02  loss: 0.7942 (0.8727)  time: 0.0818  data: 0.0001  max mem: 10917
[15:30:38.856848] Test:  [40/57]  eta: 0:00:01  loss: 0.7876 (0.8502)  time: 0.0822  data: 0.0001  max mem: 10917
[15:30:39.685949] Test:  [50/57]  eta: 0:00:00  loss: 0.7841 (0.8433)  time: 0.0826  data: 0.0001  max mem: 10917
[15:30:40.135936] Test:  [56/57]  eta: 0:00:00  loss: 0.8287 (0.8486)  time: 0.0804  data: 0.0001  max mem: 10917
[15:30:40.191989] Test: Total time: 0:00:04 (0.0848 s / it)
[15:30:42.173302] Dice score of the network on the train images: 0.831354, val images: 0.802214
[15:30:42.176803] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:30:42.575797] Epoch: [43]  [  0/345]  eta: 0:02:17  lr: 0.000016  loss: 0.7414 (0.7414)  time: 0.3979  data: 0.1457  max mem: 10917
[15:30:47.574687] Epoch: [43]  [ 20/345]  eta: 0:01:23  lr: 0.000016  loss: 0.7346 (0.7368)  time: 0.2499  data: 0.0001  max mem: 10917
[15:30:52.580281] Epoch: [43]  [ 40/345]  eta: 0:01:17  lr: 0.000016  loss: 0.7329 (0.7369)  time: 0.2502  data: 0.0001  max mem: 10917
[15:30:57.589973] Epoch: [43]  [ 60/345]  eta: 0:01:11  lr: 0.000015  loss: 0.7379 (0.7389)  time: 0.2504  data: 0.0001  max mem: 10917
[15:31:02.597356] Epoch: [43]  [ 80/345]  eta: 0:01:06  lr: 0.000015  loss: 0.7448 (0.7404)  time: 0.2503  data: 0.0001  max mem: 10917
[15:31:07.615215] Epoch: [43]  [100/345]  eta: 0:01:01  lr: 0.000015  loss: 0.7440 (0.7408)  time: 0.2508  data: 0.0000  max mem: 10917
[15:31:12.634480] Epoch: [43]  [120/345]  eta: 0:00:56  lr: 0.000015  loss: 0.7431 (0.7416)  time: 0.2509  data: 0.0000  max mem: 10917
[15:31:17.659822] Epoch: [43]  [140/345]  eta: 0:00:51  lr: 0.000014  loss: 0.7335 (0.7408)  time: 0.2512  data: 0.0001  max mem: 10917
[15:31:22.683109] Epoch: [43]  [160/345]  eta: 0:00:46  lr: 0.000014  loss: 0.7280 (0.7400)  time: 0.2511  data: 0.0000  max mem: 10917
[15:31:27.699078] Epoch: [43]  [180/345]  eta: 0:00:41  lr: 0.000014  loss: 0.7376 (0.7401)  time: 0.2508  data: 0.0001  max mem: 10917
[15:31:32.715707] Epoch: [43]  [200/345]  eta: 0:00:36  lr: 0.000014  loss: 0.7339 (0.7401)  time: 0.2508  data: 0.0000  max mem: 10917
[15:31:37.734401] Epoch: [43]  [220/345]  eta: 0:00:31  lr: 0.000013  loss: 0.7329 (0.7396)  time: 0.2509  data: 0.0000  max mem: 10917
[15:31:42.758506] Epoch: [43]  [240/345]  eta: 0:00:26  lr: 0.000013  loss: 0.7365 (0.7395)  time: 0.2512  data: 0.0000  max mem: 10917
[15:31:47.783096] Epoch: [43]  [260/345]  eta: 0:00:21  lr: 0.000013  loss: 0.7489 (0.7402)  time: 0.2512  data: 0.0000  max mem: 10917
[15:31:52.806443] Epoch: [43]  [280/345]  eta: 0:00:16  lr: 0.000013  loss: 0.7392 (0.7405)  time: 0.2511  data: 0.0000  max mem: 10917
[15:31:57.836125] Epoch: [43]  [300/345]  eta: 0:00:11  lr: 0.000012  loss: 0.7404 (0.7405)  time: 0.2514  data: 0.0000  max mem: 10917
[15:32:02.882696] Epoch: [43]  [320/345]  eta: 0:00:06  lr: 0.000012  loss: 0.7393 (0.7405)  time: 0.2523  data: 0.0000  max mem: 10917
[15:32:07.924740] Epoch: [43]  [340/345]  eta: 0:00:01  lr: 0.000012  loss: 0.7300 (0.7400)  time: 0.2521  data: 0.0000  max mem: 10917
[15:32:08.935064] Epoch: [43]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 0.7317 (0.7401)  time: 0.2521  data: 0.0001  max mem: 10917
[15:32:08.975170] Epoch: [43] Total time: 0:01:26 (0.2516 s / it)
[15:32:08.975433] Averaged stats: lr: 0.000012  loss: 0.7317 (0.7401)
[15:32:09.213495] Test:  [  0/345]  eta: 0:01:20  loss: 0.6981 (0.6981)  time: 0.2341  data: 0.1535  max mem: 10917
[15:32:10.045183] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7079 (0.7054)  time: 0.0968  data: 0.0150  max mem: 10917
[15:32:10.868096] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7076 (0.7043)  time: 0.0827  data: 0.0006  max mem: 10917
[15:32:11.695627] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7035 (0.7056)  time: 0.0825  data: 0.0001  max mem: 10917
[15:32:12.526221] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7123 (0.7067)  time: 0.0829  data: 0.0001  max mem: 10917
[15:32:13.360172] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7101 (0.7077)  time: 0.0832  data: 0.0001  max mem: 10917
[15:32:14.198937] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7104 (0.7087)  time: 0.0836  data: 0.0001  max mem: 10917
[15:32:15.041320] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7069 (0.7079)  time: 0.0840  data: 0.0001  max mem: 10917
[15:32:15.887008] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7060 (0.7084)  time: 0.0844  data: 0.0001  max mem: 10917
[15:32:16.735020] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7060 (0.7089)  time: 0.0846  data: 0.0001  max mem: 10917
[15:32:17.586990] Test:  [100/345]  eta: 0:00:20  loss: 0.7072 (0.7089)  time: 0.0850  data: 0.0001  max mem: 10917
[15:32:18.443405] Test:  [110/345]  eta: 0:00:20  loss: 0.7067 (0.7090)  time: 0.0854  data: 0.0001  max mem: 10917
[15:32:19.302043] Test:  [120/345]  eta: 0:00:19  loss: 0.7052 (0.7090)  time: 0.0857  data: 0.0001  max mem: 10917
[15:32:20.164149] Test:  [130/345]  eta: 0:00:18  loss: 0.7105 (0.7094)  time: 0.0860  data: 0.0001  max mem: 10917
[15:32:21.030509] Test:  [140/345]  eta: 0:00:17  loss: 0.7055 (0.7088)  time: 0.0864  data: 0.0001  max mem: 10917
[15:32:21.899763] Test:  [150/345]  eta: 0:00:16  loss: 0.7089 (0.7097)  time: 0.0867  data: 0.0001  max mem: 10917
[15:32:22.773054] Test:  [160/345]  eta: 0:00:15  loss: 0.7146 (0.7096)  time: 0.0871  data: 0.0001  max mem: 10917
[15:32:23.649934] Test:  [170/345]  eta: 0:00:15  loss: 0.7030 (0.7094)  time: 0.0875  data: 0.0001  max mem: 10917
[15:32:24.530405] Test:  [180/345]  eta: 0:00:14  loss: 0.7028 (0.7094)  time: 0.0878  data: 0.0001  max mem: 10917
[15:32:25.414302] Test:  [190/345]  eta: 0:00:13  loss: 0.7105 (0.7095)  time: 0.0882  data: 0.0001  max mem: 10917
[15:32:26.301044] Test:  [200/345]  eta: 0:00:12  loss: 0.7105 (0.7095)  time: 0.0885  data: 0.0001  max mem: 10917
[15:32:27.191861] Test:  [210/345]  eta: 0:00:11  loss: 0.7062 (0.7095)  time: 0.0888  data: 0.0001  max mem: 10917
[15:32:28.086838] Test:  [220/345]  eta: 0:00:10  loss: 0.7091 (0.7094)  time: 0.0892  data: 0.0001  max mem: 10917
[15:32:28.984441] Test:  [230/345]  eta: 0:00:09  loss: 0.7036 (0.7092)  time: 0.0896  data: 0.0001  max mem: 10917
[15:32:29.886528] Test:  [240/345]  eta: 0:00:09  loss: 0.7074 (0.7092)  time: 0.0899  data: 0.0001  max mem: 10917
[15:32:30.790517] Test:  [250/345]  eta: 0:00:08  loss: 0.7109 (0.7092)  time: 0.0903  data: 0.0001  max mem: 10917
[15:32:31.699179] Test:  [260/345]  eta: 0:00:07  loss: 0.7079 (0.7090)  time: 0.0906  data: 0.0001  max mem: 10917
[15:32:32.611339] Test:  [270/345]  eta: 0:00:06  loss: 0.7057 (0.7089)  time: 0.0910  data: 0.0001  max mem: 10917
[15:32:33.527420] Test:  [280/345]  eta: 0:00:05  loss: 0.7059 (0.7091)  time: 0.0914  data: 0.0001  max mem: 10917
[15:32:34.446414] Test:  [290/345]  eta: 0:00:04  loss: 0.7059 (0.7092)  time: 0.0917  data: 0.0001  max mem: 10917
[15:32:35.369000] Test:  [300/345]  eta: 0:00:03  loss: 0.7056 (0.7091)  time: 0.0920  data: 0.0001  max mem: 10917
[15:32:36.294768] Test:  [310/345]  eta: 0:00:03  loss: 0.7056 (0.7089)  time: 0.0924  data: 0.0001  max mem: 10917
[15:32:37.224952] Test:  [320/345]  eta: 0:00:02  loss: 0.7056 (0.7088)  time: 0.0928  data: 0.0001  max mem: 10917
[15:32:38.157165] Test:  [330/345]  eta: 0:00:01  loss: 0.7030 (0.7088)  time: 0.0931  data: 0.0001  max mem: 10917
[15:32:39.093262] Test:  [340/345]  eta: 0:00:00  loss: 0.7063 (0.7089)  time: 0.0934  data: 0.0001  max mem: 10917
[15:32:39.469039] Test:  [344/345]  eta: 0:00:00  loss: 0.7063 (0.7090)  time: 0.0935  data: 0.0001  max mem: 10917
[15:32:39.525403] Test: Total time: 0:00:30 (0.0885 s / it)
[15:32:50.645251] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9127 (0.9127)  time: 0.2223  data: 0.1427  max mem: 10917
[15:32:51.458925] Test:  [10/57]  eta: 0:00:04  loss: 0.9191 (0.9257)  time: 0.0941  data: 0.0130  max mem: 10917
[15:32:52.276126] Test:  [20/57]  eta: 0:00:03  loss: 0.9102 (0.9095)  time: 0.0815  data: 0.0001  max mem: 10917
[15:32:53.097627] Test:  [30/57]  eta: 0:00:02  loss: 0.7941 (0.8677)  time: 0.0819  data: 0.0001  max mem: 10917
[15:32:53.921807] Test:  [40/57]  eta: 0:00:01  loss: 0.7869 (0.8461)  time: 0.0822  data: 0.0001  max mem: 10917
[15:32:54.750653] Test:  [50/57]  eta: 0:00:00  loss: 0.7864 (0.8385)  time: 0.0826  data: 0.0001  max mem: 10917
[15:32:55.200512] Test:  [56/57]  eta: 0:00:00  loss: 0.8254 (0.8446)  time: 0.0804  data: 0.0001  max mem: 10917
[15:32:55.259325] Test: Total time: 0:00:04 (0.0849 s / it)
[15:32:57.206653] Dice score of the network on the train images: 0.830274, val images: 0.808521
[15:32:57.210258] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:32:57.607144] Epoch: [44]  [  0/345]  eta: 0:02:16  lr: 0.000012  loss: 0.7283 (0.7283)  time: 0.3960  data: 0.1439  max mem: 10917
[15:33:02.605124] Epoch: [44]  [ 20/345]  eta: 0:01:23  lr: 0.000012  loss: 0.7380 (0.7382)  time: 0.2499  data: 0.0001  max mem: 10917
[15:33:07.609495] Epoch: [44]  [ 40/345]  eta: 0:01:17  lr: 0.000011  loss: 0.7418 (0.7398)  time: 0.2502  data: 0.0001  max mem: 10917
[15:33:12.618115] Epoch: [44]  [ 60/345]  eta: 0:01:11  lr: 0.000011  loss: 0.7292 (0.7383)  time: 0.2504  data: 0.0001  max mem: 10917
[15:33:17.629977] Epoch: [44]  [ 80/345]  eta: 0:01:06  lr: 0.000011  loss: 0.7384 (0.7387)  time: 0.2506  data: 0.0000  max mem: 10917
[15:33:22.649078] Epoch: [44]  [100/345]  eta: 0:01:01  lr: 0.000011  loss: 0.7364 (0.7391)  time: 0.2509  data: 0.0000  max mem: 10917
[15:33:27.672712] Epoch: [44]  [120/345]  eta: 0:00:56  lr: 0.000011  loss: 0.7316 (0.7387)  time: 0.2511  data: 0.0000  max mem: 10917
[15:33:32.696454] Epoch: [44]  [140/345]  eta: 0:00:51  lr: 0.000010  loss: 0.7408 (0.7391)  time: 0.2511  data: 0.0001  max mem: 10917
[15:33:37.724139] Epoch: [44]  [160/345]  eta: 0:00:46  lr: 0.000010  loss: 0.7431 (0.7398)  time: 0.2513  data: 0.0000  max mem: 10917
[15:33:42.748251] Epoch: [44]  [180/345]  eta: 0:00:41  lr: 0.000010  loss: 0.7373 (0.7397)  time: 0.2512  data: 0.0000  max mem: 10917
[15:33:47.777859] Epoch: [44]  [200/345]  eta: 0:00:36  lr: 0.000010  loss: 0.7403 (0.7399)  time: 0.2514  data: 0.0000  max mem: 10917
[15:33:52.808697] Epoch: [44]  [220/345]  eta: 0:00:31  lr: 0.000010  loss: 0.7341 (0.7398)  time: 0.2515  data: 0.0000  max mem: 10917
[15:33:57.841756] Epoch: [44]  [240/345]  eta: 0:00:26  lr: 0.000009  loss: 0.7327 (0.7396)  time: 0.2516  data: 0.0000  max mem: 10917
[15:34:02.877879] Epoch: [44]  [260/345]  eta: 0:00:21  lr: 0.000009  loss: 0.7363 (0.7394)  time: 0.2518  data: 0.0000  max mem: 10917
[15:34:07.996807] Epoch: [44]  [280/345]  eta: 0:00:16  lr: 0.000009  loss: 0.7385 (0.7394)  time: 0.2559  data: 0.0000  max mem: 10917
[15:34:13.037733] Epoch: [44]  [300/345]  eta: 0:00:11  lr: 0.000009  loss: 0.7376 (0.7393)  time: 0.2520  data: 0.0000  max mem: 10917

[15:34:18.081580] Epoch: [44]  [320/345]  eta: 0:00:06  lr: 0.000009  loss: 0.7366 (0.7392)  time: 0.2522  data: 0.0000  max mem: 10917
[15:34:23.126849] Epoch: [44]  [340/345]  eta: 0:00:01  lr: 0.000008  loss: 0.7397 (0.7393)  time: 0.2522  data: 0.0000  max mem: 10917
[15:34:24.134103] Epoch: [44]  [344/345]  eta: 0:00:00  lr: 0.000008  loss: 0.7397 (0.7393)  time: 0.2521  data: 0.0001  max mem: 10917
[15:34:24.195956] Epoch: [44] Total time: 0:01:26 (0.2521 s / it)
[15:34:24.196294] Averaged stats: lr: 0.000008  loss: 0.7397 (0.7393)
[15:34:24.433865] Test:  [  0/345]  eta: 0:01:20  loss: 0.6902 (0.6902)  time: 0.2339  data: 0.1538  max mem: 10917
[15:34:25.254327] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7066 (0.7086)  time: 0.0958  data: 0.0140  max mem: 10917
[15:34:26.078129] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7094 (0.7095)  time: 0.0821  data: 0.0001  max mem: 10917
[15:34:26.904892] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7073 (0.7080)  time: 0.0825  data: 0.0001  max mem: 10917
[15:34:27.736923] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7049 (0.7083)  time: 0.0829  data: 0.0001  max mem: 10917
[15:34:28.571401] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7058 (0.7083)  time: 0.0833  data: 0.0001  max mem: 10917
[15:34:29.409515] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7043 (0.7083)  time: 0.0836  data: 0.0001  max mem: 10917
[15:34:30.250384] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7036 (0.7081)  time: 0.0839  data: 0.0001  max mem: 10917
[15:34:31.095505] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7006 (0.7074)  time: 0.0843  data: 0.0001  max mem: 10917
[15:34:31.944305] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7061 (0.7086)  time: 0.0847  data: 0.0001  max mem: 10917
[15:34:32.796717] Test:  [100/345]  eta: 0:00:20  loss: 0.7157 (0.7091)  time: 0.0850  data: 0.0001  max mem: 10917
[15:34:33.652256] Test:  [110/345]  eta: 0:00:19  loss: 0.7146 (0.7092)  time: 0.0854  data: 0.0001  max mem: 10917
[15:34:34.510770] Test:  [120/345]  eta: 0:00:19  loss: 0.7128 (0.7092)  time: 0.0857  data: 0.0001  max mem: 10917
[15:34:35.373663] Test:  [130/345]  eta: 0:00:18  loss: 0.6991 (0.7086)  time: 0.0860  data: 0.0001  max mem: 10917
[15:34:36.239972] Test:  [140/345]  eta: 0:00:17  loss: 0.6991 (0.7083)  time: 0.0864  data: 0.0001  max mem: 10917
[15:34:37.109180] Test:  [150/345]  eta: 0:00:16  loss: 0.7088 (0.7085)  time: 0.0867  data: 0.0001  max mem: 10917
[15:34:37.982516] Test:  [160/345]  eta: 0:00:15  loss: 0.7087 (0.7086)  time: 0.0871  data: 0.0001  max mem: 10917
[15:34:38.859058] Test:  [170/345]  eta: 0:00:14  loss: 0.7080 (0.7089)  time: 0.0874  data: 0.0001  max mem: 10917
[15:34:39.739254] Test:  [180/345]  eta: 0:00:14  loss: 0.7113 (0.7090)  time: 0.0878  data: 0.0001  max mem: 10917
[15:34:40.622857] Test:  [190/345]  eta: 0:00:13  loss: 0.7066 (0.7089)  time: 0.0881  data: 0.0001  max mem: 10917
[15:34:41.510203] Test:  [200/345]  eta: 0:00:12  loss: 0.7066 (0.7088)  time: 0.0885  data: 0.0001  max mem: 10917
[15:34:42.401509] Test:  [210/345]  eta: 0:00:11  loss: 0.7059 (0.7087)  time: 0.0889  data: 0.0001  max mem: 10917
[15:34:43.295762] Test:  [220/345]  eta: 0:00:10  loss: 0.7057 (0.7086)  time: 0.0892  data: 0.0001  max mem: 10917
[15:34:44.193517] Test:  [230/345]  eta: 0:00:09  loss: 0.7072 (0.7086)  time: 0.0896  data: 0.0001  max mem: 10917
[15:34:45.094567] Test:  [240/345]  eta: 0:00:09  loss: 0.7067 (0.7086)  time: 0.0899  data: 0.0001  max mem: 10917
[15:34:46.000796] Test:  [250/345]  eta: 0:00:08  loss: 0.7082 (0.7087)  time: 0.0903  data: 0.0001  max mem: 10917
[15:34:46.908889] Test:  [260/345]  eta: 0:00:07  loss: 0.7082 (0.7087)  time: 0.0907  data: 0.0001  max mem: 10917
[15:34:47.821100] Test:  [270/345]  eta: 0:00:06  loss: 0.7095 (0.7088)  time: 0.0910  data: 0.0001  max mem: 10917
[15:34:48.736391] Test:  [280/345]  eta: 0:00:05  loss: 0.7065 (0.7087)  time: 0.0913  data: 0.0001  max mem: 10917
[15:34:49.654961] Test:  [290/345]  eta: 0:00:04  loss: 0.7056 (0.7088)  time: 0.0916  data: 0.0001  max mem: 10917
[15:34:50.577354] Test:  [300/345]  eta: 0:00:03  loss: 0.7116 (0.7090)  time: 0.0920  data: 0.0001  max mem: 10917
[15:34:51.503730] Test:  [310/345]  eta: 0:00:03  loss: 0.7080 (0.7090)  time: 0.0924  data: 0.0001  max mem: 10917
[15:34:52.433181] Test:  [320/345]  eta: 0:00:02  loss: 0.7013 (0.7088)  time: 0.0927  data: 0.0001  max mem: 10917
[15:34:53.365868] Test:  [330/345]  eta: 0:00:01  loss: 0.7106 (0.7089)  time: 0.0931  data: 0.0001  max mem: 10917
[15:34:54.302570] Test:  [340/345]  eta: 0:00:00  loss: 0.7144 (0.7089)  time: 0.0934  data: 0.0001  max mem: 10917
[15:34:54.678166] Test:  [344/345]  eta: 0:00:00  loss: 0.7108 (0.7088)  time: 0.0936  data: 0.0001  max mem: 10917
[15:34:54.734974] Test: Total time: 0:00:30 (0.0885 s / it)
[15:35:05.855447] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9134 (0.9134)  time: 0.2233  data: 0.1436  max mem: 10917
[15:35:06.668466] Test:  [10/57]  eta: 0:00:04  loss: 0.9236 (0.9260)  time: 0.0942  data: 0.0131  max mem: 10917
[15:35:07.485415] Test:  [20/57]  eta: 0:00:03  loss: 0.9187 (0.9126)  time: 0.0814  data: 0.0001  max mem: 10917
[15:35:08.306724] Test:  [30/57]  eta: 0:00:02  loss: 0.8050 (0.8704)  time: 0.0819  data: 0.0001  max mem: 10917
[15:35:09.130510] Test:  [40/57]  eta: 0:00:01  loss: 0.7871 (0.8484)  time: 0.0822  data: 0.0001  max mem: 10917
[15:35:09.958542] Test:  [50/57]  eta: 0:00:00  loss: 0.7892 (0.8409)  time: 0.0825  data: 0.0001  max mem: 10917
[15:35:10.408067] Test:  [56/57]  eta: 0:00:00  loss: 0.8240 (0.8472)  time: 0.0803  data: 0.0001  max mem: 10917
[15:35:10.466425] Test: Total time: 0:00:04 (0.0848 s / it)
[15:35:12.491313] Dice score of the network on the train images: 0.832607, val images: 0.808945
[15:35:12.494984] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:35:12.893845] Epoch: [45]  [  0/345]  eta: 0:02:17  lr: 0.000008  loss: 0.7343 (0.7343)  time: 0.3977  data: 0.1454  max mem: 10917
[15:35:17.894378] Epoch: [45]  [ 20/345]  eta: 0:01:23  lr: 0.000008  loss: 0.7406 (0.7412)  time: 0.2500  data: 0.0001  max mem: 10917
[15:35:22.903686] Epoch: [45]  [ 40/345]  eta: 0:01:17  lr: 0.000008  loss: 0.7290 (0.7376)  time: 0.2504  data: 0.0000  max mem: 10917
[15:35:27.910913] Epoch: [45]  [ 60/345]  eta: 0:01:12  lr: 0.000008  loss: 0.7330 (0.7364)  time: 0.2503  data: 0.0000  max mem: 10917
[15:35:32.923036] Epoch: [45]  [ 80/345]  eta: 0:01:06  lr: 0.000008  loss: 0.7347 (0.7371)  time: 0.2506  data: 0.0000  max mem: 10917
[15:35:37.945392] Epoch: [45]  [100/345]  eta: 0:01:01  lr: 0.000007  loss: 0.7399 (0.7377)  time: 0.2511  data: 0.0001  max mem: 10917
[15:35:42.974459] Epoch: [45]  [120/345]  eta: 0:00:56  lr: 0.000007  loss: 0.7359 (0.7377)  time: 0.2514  data: 0.0001  max mem: 10917
[15:35:48.002271] Epoch: [45]  [140/345]  eta: 0:00:51  lr: 0.000007  loss: 0.7412 (0.7387)  time: 0.2513  data: 0.0000  max mem: 10917
[15:35:53.025094] Epoch: [45]  [160/345]  eta: 0:00:46  lr: 0.000007  loss: 0.7294 (0.7380)  time: 0.2511  data: 0.0000  max mem: 10917
[15:35:58.050968] Epoch: [45]  [180/345]  eta: 0:00:41  lr: 0.000007  loss: 0.7328 (0.7377)  time: 0.2512  data: 0.0000  max mem: 10917
[15:36:03.081231] Epoch: [45]  [200/345]  eta: 0:00:36  lr: 0.000007  loss: 0.7395 (0.7381)  time: 0.2515  data: 0.0000  max mem: 10917
[15:36:08.114878] Epoch: [45]  [220/345]  eta: 0:00:31  lr: 0.000006  loss: 0.7329 (0.7379)  time: 0.2516  data: 0.0000  max mem: 10917
[15:36:13.148800] Epoch: [45]  [240/345]  eta: 0:00:26  lr: 0.000006  loss: 0.7394 (0.7380)  time: 0.2516  data: 0.0000  max mem: 10917
[15:36:18.188450] Epoch: [45]  [260/345]  eta: 0:00:21  lr: 0.000006  loss: 0.7321 (0.7384)  time: 0.2519  data: 0.0000  max mem: 10917
[15:36:23.228772] Epoch: [45]  [280/345]  eta: 0:00:16  lr: 0.000006  loss: 0.7316 (0.7384)  time: 0.2520  data: 0.0000  max mem: 10917

[15:36:28.273120] Epoch: [45]  [300/345]  eta: 0:00:11  lr: 0.000006  loss: 0.7376 (0.7386)  time: 0.2522  data: 0.0001  max mem: 10917
[15:36:33.318833] Epoch: [45]  [320/345]  eta: 0:00:06  lr: 0.000006  loss: 0.7411 (0.7385)  time: 0.2522  data: 0.0000  max mem: 10917
[15:36:38.361949] Epoch: [45]  [340/345]  eta: 0:00:01  lr: 0.000005  loss: 0.7351 (0.7385)  time: 0.2521  data: 0.0001  max mem: 10917
[15:36:39.372258] Epoch: [45]  [344/345]  eta: 0:00:00  lr: 0.000005  loss: 0.7413 (0.7384)  time: 0.2522  data: 0.0001  max mem: 10917
[15:36:39.430403] Epoch: [45] Total time: 0:01:26 (0.2520 s / it)
[15:36:39.430720] Averaged stats: lr: 0.000005  loss: 0.7413 (0.7384)
[15:36:39.669362] Test:  [  0/345]  eta: 0:01:21  loss: 0.6929 (0.6929)  time: 0.2351  data: 0.1552  max mem: 10917
[15:36:40.532180] Test:  [ 10/345]  eta: 0:00:33  loss: 0.6985 (0.7021)  time: 0.0997  data: 0.0182  max mem: 10917
[15:36:41.356763] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7000 (0.7033)  time: 0.0843  data: 0.0023  max mem: 10917
[15:36:42.183639] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7027 (0.7039)  time: 0.0825  data: 0.0001  max mem: 10917
[15:36:43.015205] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7009 (0.7030)  time: 0.0829  data: 0.0001  max mem: 10917
[15:36:43.849319] Test:  [ 50/345]  eta: 0:00:25  loss: 0.6975 (0.7033)  time: 0.0832  data: 0.0001  max mem: 10917
[15:36:44.687507] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7047 (0.7048)  time: 0.0836  data: 0.0001  max mem: 10917
[15:36:45.529278] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7116 (0.7055)  time: 0.0840  data: 0.0001  max mem: 10917
[15:36:46.374831] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7054 (0.7063)  time: 0.0843  data: 0.0001  max mem: 10917
[15:36:47.222993] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7040 (0.7060)  time: 0.0846  data: 0.0001  max mem: 10917
[15:36:48.075701] Test:  [100/345]  eta: 0:00:20  loss: 0.7040 (0.7061)  time: 0.0850  data: 0.0001  max mem: 10917
[15:36:48.931403] Test:  [110/345]  eta: 0:00:20  loss: 0.7060 (0.7065)  time: 0.0854  data: 0.0001  max mem: 10917
[15:36:49.790446] Test:  [120/345]  eta: 0:00:19  loss: 0.7083 (0.7066)  time: 0.0857  data: 0.0001  max mem: 10917
[15:36:50.653770] Test:  [130/345]  eta: 0:00:18  loss: 0.7026 (0.7064)  time: 0.0861  data: 0.0001  max mem: 10917
[15:36:51.520569] Test:  [140/345]  eta: 0:00:17  loss: 0.7102 (0.7070)  time: 0.0864  data: 0.0001  max mem: 10917
[15:36:52.390963] Test:  [150/345]  eta: 0:00:16  loss: 0.7095 (0.7074)  time: 0.0868  data: 0.0001  max mem: 10917
[15:36:53.263993] Test:  [160/345]  eta: 0:00:15  loss: 0.7037 (0.7068)  time: 0.0871  data: 0.0001  max mem: 10917
[15:36:54.141192] Test:  [170/345]  eta: 0:00:15  loss: 0.7019 (0.7066)  time: 0.0875  data: 0.0001  max mem: 10917
[15:36:55.022154] Test:  [180/345]  eta: 0:00:14  loss: 0.7051 (0.7068)  time: 0.0879  data: 0.0001  max mem: 10917
[15:36:55.905302] Test:  [190/345]  eta: 0:00:13  loss: 0.7092 (0.7070)  time: 0.0882  data: 0.0001  max mem: 10917
[15:36:56.792603] Test:  [200/345]  eta: 0:00:12  loss: 0.7084 (0.7072)  time: 0.0885  data: 0.0001  max mem: 10917
[15:36:57.683330] Test:  [210/345]  eta: 0:00:11  loss: 0.7131 (0.7076)  time: 0.0889  data: 0.0001  max mem: 10917
[15:36:58.577710] Test:  [220/345]  eta: 0:00:10  loss: 0.7156 (0.7078)  time: 0.0892  data: 0.0001  max mem: 10917
[15:36:59.475450] Test:  [230/345]  eta: 0:00:09  loss: 0.7014 (0.7076)  time: 0.0896  data: 0.0001  max mem: 10917
[15:37:00.377768] Test:  [240/345]  eta: 0:00:09  loss: 0.7014 (0.7076)  time: 0.0900  data: 0.0001  max mem: 10917
[15:37:01.282899] Test:  [250/345]  eta: 0:00:08  loss: 0.7084 (0.7077)  time: 0.0903  data: 0.0001  max mem: 10917
[15:37:02.191772] Test:  [260/345]  eta: 0:00:07  loss: 0.7109 (0.7079)  time: 0.0907  data: 0.0001  max mem: 10917
[15:37:03.103815] Test:  [270/345]  eta: 0:00:06  loss: 0.7091 (0.7078)  time: 0.0910  data: 0.0001  max mem: 10917
[15:37:04.020369] Test:  [280/345]  eta: 0:00:05  loss: 0.7049 (0.7078)  time: 0.0914  data: 0.0001  max mem: 10917
[15:37:04.939127] Test:  [290/345]  eta: 0:00:04  loss: 0.7101 (0.7080)  time: 0.0917  data: 0.0001  max mem: 10917
[15:37:05.861195] Test:  [300/345]  eta: 0:00:03  loss: 0.7117 (0.7080)  time: 0.0920  data: 0.0001  max mem: 10917
[15:37:06.786447] Test:  [310/345]  eta: 0:00:03  loss: 0.7056 (0.7080)  time: 0.0923  data: 0.0001  max mem: 10917
[15:37:07.716139] Test:  [320/345]  eta: 0:00:02  loss: 0.7085 (0.7080)  time: 0.0927  data: 0.0001  max mem: 10917
[15:37:08.648638] Test:  [330/345]  eta: 0:00:01  loss: 0.7074 (0.7080)  time: 0.0931  data: 0.0001  max mem: 10917
[15:37:09.586050] Test:  [340/345]  eta: 0:00:00  loss: 0.7053 (0.7080)  time: 0.0934  data: 0.0001  max mem: 10917
[15:37:09.962055] Test:  [344/345]  eta: 0:00:00  loss: 0.7053 (0.7080)  time: 0.0936  data: 0.0001  max mem: 10917
[15:37:10.018257] Test: Total time: 0:00:30 (0.0887 s / it)
[15:37:21.083695] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9159 (0.9159)  time: 0.2209  data: 0.1412  max mem: 10917
[15:37:21.896129] Test:  [10/57]  eta: 0:00:04  loss: 0.9227 (0.9255)  time: 0.0939  data: 0.0129  max mem: 10917
[15:37:22.712858] Test:  [20/57]  eta: 0:00:03  loss: 0.9217 (0.9115)  time: 0.0814  data: 0.0001  max mem: 10917
[15:37:23.533685] Test:  [30/57]  eta: 0:00:02  loss: 0.8027 (0.8696)  time: 0.0818  data: 0.0001  max mem: 10917
[15:37:24.358828] Test:  [40/57]  eta: 0:00:01  loss: 0.7846 (0.8475)  time: 0.0823  data: 0.0001  max mem: 10917
[15:37:25.187389] Test:  [50/57]  eta: 0:00:00  loss: 0.7859 (0.8399)  time: 0.0826  data: 0.0001  max mem: 10917
[15:37:25.637788] Test:  [56/57]  eta: 0:00:00  loss: 0.8241 (0.8464)  time: 0.0804  data: 0.0001  max mem: 10917
[15:37:25.694790] Test: Total time: 0:00:04 (0.0848 s / it)
[15:37:27.678249] Dice score of the network on the train images: 0.832880, val images: 0.810015
[15:37:27.682718] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:37:28.083701] Epoch: [46]  [  0/345]  eta: 0:02:17  lr: 0.000005  loss: 0.7501 (0.7501)  time: 0.3999  data: 0.1479  max mem: 10917
[15:37:33.084587] Epoch: [46]  [ 20/345]  eta: 0:01:23  lr: 0.000005  loss: 0.7373 (0.7375)  time: 0.2500  data: 0.0000  max mem: 10917
[15:37:38.086839] Epoch: [46]  [ 40/345]  eta: 0:01:17  lr: 0.000005  loss: 0.7365 (0.7380)  time: 0.2501  data: 0.0001  max mem: 10917
[15:37:43.089771] Epoch: [46]  [ 60/345]  eta: 0:01:11  lr: 0.000005  loss: 0.7440 (0.7406)  time: 0.2501  data: 0.0000  max mem: 10917
[15:37:48.100276] Epoch: [46]  [ 80/345]  eta: 0:01:06  lr: 0.000005  loss: 0.7351 (0.7392)  time: 0.2505  data: 0.0000  max mem: 10917
[15:37:53.117953] Epoch: [46]  [100/345]  eta: 0:01:01  lr: 0.000005  loss: 0.7336 (0.7383)  time: 0.2508  data: 0.0000  max mem: 10917
[15:37:58.138018] Epoch: [46]  [120/345]  eta: 0:00:56  lr: 0.000005  loss: 0.7329 (0.7378)  time: 0.2510  data: 0.0001  max mem: 10917
[15:38:03.163217] Epoch: [46]  [140/345]  eta: 0:00:51  lr: 0.000004  loss: 0.7353 (0.7378)  time: 0.2512  data: 0.0000  max mem: 10917
[15:38:08.191768] Epoch: [46]  [160/345]  eta: 0:00:46  lr: 0.000004  loss: 0.7411 (0.7382)  time: 0.2514  data: 0.0000  max mem: 10917
[15:38:13.222935] Epoch: [46]  [180/345]  eta: 0:00:41  lr: 0.000004  loss: 0.7392 (0.7384)  time: 0.2515  data: 0.0000  max mem: 10917
[15:38:18.257913] Epoch: [46]  [200/345]  eta: 0:00:36  lr: 0.000004  loss: 0.7307 (0.7379)  time: 0.2517  data: 0.0000  max mem: 10917
[15:38:23.293037] Epoch: [46]  [220/345]  eta: 0:00:31  lr: 0.000004  loss: 0.7323 (0.7379)  time: 0.2517  data: 0.0000  max mem: 10917
[15:38:28.330243] Epoch: [46]  [240/345]  eta: 0:00:26  lr: 0.000004  loss: 0.7405 (0.7383)  time: 0.2518  data: 0.0000  max mem: 10917
[15:38:33.372237] Epoch: [46]  [260/345]  eta: 0:00:21  lr: 0.000004  loss: 0.7328 (0.7380)  time: 0.2521  data: 0.0000  max mem: 10917
[15:38:38.419491] Epoch: [46]  [280/345]  eta: 0:00:16  lr: 0.000003  loss: 0.7359 (0.7379)  time: 0.2523  data: 0.0000  max mem: 10917
[15:38:43.464662] Epoch: [46]  [300/345]  eta: 0:00:11  lr: 0.000003  loss: 0.7329 (0.7375)  time: 0.2522  data: 0.0000  max mem: 10917
[15:38:48.511336] Epoch: [46]  [320/345]  eta: 0:00:06  lr: 0.000003  loss: 0.7327 (0.7376)  time: 0.2523  data: 0.0000  max mem: 10917
[15:38:53.560331] Epoch: [46]  [340/345]  eta: 0:00:01  lr: 0.000003  loss: 0.7368 (0.7378)  time: 0.2524  data: 0.0000  max mem: 10917
[15:38:54.571744] Epoch: [46]  [344/345]  eta: 0:00:00  lr: 0.000003  loss: 0.7387 (0.7378)  time: 0.2525  data: 0.0001  max mem: 10917
[15:38:54.627944] Epoch: [46] Total time: 0:01:26 (0.2520 s / it)
[15:38:54.628287] Averaged stats: lr: 0.000003  loss: 0.7387 (0.7378)
[15:38:54.868041] Test:  [  0/345]  eta: 0:01:21  loss: 0.7015 (0.7015)  time: 0.2362  data: 0.1564  max mem: 10917
[15:38:55.703821] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7040 (0.7051)  time: 0.0974  data: 0.0158  max mem: 10917
[15:38:56.526469] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7040 (0.7038)  time: 0.0829  data: 0.0009  max mem: 10917
[15:38:57.353963] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7027 (0.7042)  time: 0.0825  data: 0.0001  max mem: 10917
[15:38:58.184541] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7027 (0.7048)  time: 0.0829  data: 0.0001  max mem: 10917
[15:38:59.018402] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7000 (0.7042)  time: 0.0832  data: 0.0001  max mem: 10917
[15:38:59.855688] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7083 (0.7055)  time: 0.0835  data: 0.0001  max mem: 10917
[15:39:00.696418] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7094 (0.7059)  time: 0.0839  data: 0.0001  max mem: 10917
[15:39:01.539947] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7073 (0.7065)  time: 0.0842  data: 0.0001  max mem: 10917
[15:39:02.387970] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7062 (0.7066)  time: 0.0845  data: 0.0001  max mem: 10917
[15:39:03.239674] Test:  [100/345]  eta: 0:00:20  loss: 0.7027 (0.7065)  time: 0.0849  data: 0.0001  max mem: 10917
[15:39:04.094974] Test:  [110/345]  eta: 0:00:20  loss: 0.7036 (0.7072)  time: 0.0853  data: 0.0001  max mem: 10917
[15:39:04.952965] Test:  [120/345]  eta: 0:00:19  loss: 0.7085 (0.7074)  time: 0.0856  data: 0.0001  max mem: 10917
[15:39:05.814987] Test:  [130/345]  eta: 0:00:18  loss: 0.7067 (0.7074)  time: 0.0860  data: 0.0001  max mem: 10917
[15:39:06.679396] Test:  [140/345]  eta: 0:00:17  loss: 0.7091 (0.7079)  time: 0.0863  data: 0.0001  max mem: 10917
[15:39:07.548543] Test:  [150/345]  eta: 0:00:16  loss: 0.7107 (0.7078)  time: 0.0866  data: 0.0001  max mem: 10917
[15:39:08.421644] Test:  [160/345]  eta: 0:00:15  loss: 0.7107 (0.7081)  time: 0.0871  data: 0.0001  max mem: 10917
[15:39:09.297555] Test:  [170/345]  eta: 0:00:15  loss: 0.7124 (0.7084)  time: 0.0874  data: 0.0001  max mem: 10917
[15:39:10.177740] Test:  [180/345]  eta: 0:00:14  loss: 0.7075 (0.7081)  time: 0.0878  data: 0.0001  max mem: 10917
[15:39:11.060074] Test:  [190/345]  eta: 0:00:13  loss: 0.7077 (0.7083)  time: 0.0881  data: 0.0001  max mem: 10917
[15:39:11.947481] Test:  [200/345]  eta: 0:00:12  loss: 0.7101 (0.7084)  time: 0.0884  data: 0.0001  max mem: 10917
[15:39:12.838621] Test:  [210/345]  eta: 0:00:11  loss: 0.7121 (0.7085)  time: 0.0889  data: 0.0001  max mem: 10917
[15:39:13.732023] Test:  [220/345]  eta: 0:00:10  loss: 0.7145 (0.7085)  time: 0.0892  data: 0.0001  max mem: 10917
[15:39:14.629915] Test:  [230/345]  eta: 0:00:09  loss: 0.7087 (0.7086)  time: 0.0895  data: 0.0001  max mem: 10917
[15:39:15.531864] Test:  [240/345]  eta: 0:00:09  loss: 0.7055 (0.7084)  time: 0.0899  data: 0.0001  max mem: 10917
[15:39:16.437033] Test:  [250/345]  eta: 0:00:08  loss: 0.7020 (0.7080)  time: 0.0903  data: 0.0001  max mem: 10917
[15:39:17.344942] Test:  [260/345]  eta: 0:00:07  loss: 0.6998 (0.7080)  time: 0.0906  data: 0.0001  max mem: 10917
[15:39:18.257164] Test:  [270/345]  eta: 0:00:06  loss: 0.7039 (0.7080)  time: 0.0910  data: 0.0001  max mem: 10917
[15:39:19.172580] Test:  [280/345]  eta: 0:00:05  loss: 0.7050 (0.7078)  time: 0.0913  data: 0.0001  max mem: 10917
[15:39:20.091534] Test:  [290/345]  eta: 0:00:04  loss: 0.7038 (0.7077)  time: 0.0917  data: 0.0001  max mem: 10917
[15:39:21.013959] Test:  [300/345]  eta: 0:00:03  loss: 0.7055 (0.7078)  time: 0.0920  data: 0.0001  max mem: 10917
[15:39:21.939912] Test:  [310/345]  eta: 0:00:03  loss: 0.7036 (0.7077)  time: 0.0924  data: 0.0001  max mem: 10917
[15:39:22.870407] Test:  [320/345]  eta: 0:00:02  loss: 0.7032 (0.7076)  time: 0.0928  data: 0.0001  max mem: 10917
[15:39:23.803638] Test:  [330/345]  eta: 0:00:01  loss: 0.7057 (0.7076)  time: 0.0931  data: 0.0001  max mem: 10917
[15:39:24.739412] Test:  [340/345]  eta: 0:00:00  loss: 0.7116 (0.7078)  time: 0.0934  data: 0.0001  max mem: 10917
[15:39:25.115664] Test:  [344/345]  eta: 0:00:00  loss: 0.7164 (0.7080)  time: 0.0936  data: 0.0001  max mem: 10917
[15:39:25.174038] Test: Total time: 0:00:30 (0.0885 s / it)
[15:39:36.310561] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9166 (0.9166)  time: 0.2207  data: 0.1411  max mem: 10917
[15:39:37.130524] Test:  [10/57]  eta: 0:00:04  loss: 0.9241 (0.9279)  time: 0.0945  data: 0.0136  max mem: 10917
[15:39:37.948024] Test:  [20/57]  eta: 0:00:03  loss: 0.9229 (0.9139)  time: 0.0818  data: 0.0004  max mem: 10917
[15:39:38.769046] Test:  [30/57]  eta: 0:00:02  loss: 0.8044 (0.8720)  time: 0.0819  data: 0.0001  max mem: 10917
[15:39:39.593147] Test:  [40/57]  eta: 0:00:01  loss: 0.7858 (0.8497)  time: 0.0822  data: 0.0001  max mem: 10917
[15:39:40.422587] Test:  [50/57]  eta: 0:00:00  loss: 0.7891 (0.8420)  time: 0.0826  data: 0.0001  max mem: 10917
[15:39:40.872538] Test:  [56/57]  eta: 0:00:00  loss: 0.8268 (0.8487)  time: 0.0804  data: 0.0001  max mem: 10917
[15:39:40.930540] Test: Total time: 0:00:04 (0.0849 s / it)
[15:39:42.922666] Dice score of the network on the train images: 0.832675, val images: 0.809242
[15:39:42.926041] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:39:43.325231] Epoch: [47]  [  0/345]  eta: 0:02:17  lr: 0.000003  loss: 0.7350 (0.7350)  time: 0.3982  data: 0.1470  max mem: 10917
[15:39:48.316313] Epoch: [47]  [ 20/345]  eta: 0:01:23  lr: 0.000003  loss: 0.7347 (0.7367)  time: 0.2495  data: 0.0001  max mem: 10917
[15:39:53.302743] Epoch: [47]  [ 40/345]  eta: 0:01:17  lr: 0.000003  loss: 0.7375 (0.7383)  time: 0.2493  data: 0.0001  max mem: 10917
[15:39:58.296831] Epoch: [47]  [ 60/345]  eta: 0:01:11  lr: 0.000003  loss: 0.7336 (0.7393)  time: 0.2497  data: 0.0001  max mem: 10917
[15:40:03.310238] Epoch: [47]  [ 80/345]  eta: 0:01:06  lr: 0.000003  loss: 0.7388 (0.7392)  time: 0.2506  data: 0.0001  max mem: 10917
[15:40:08.329731] Epoch: [47]  [100/345]  eta: 0:01:01  lr: 0.000003  loss: 0.7357 (0.7389)  time: 0.2509  data: 0.0001  max mem: 10917
[15:40:13.353398] Epoch: [47]  [120/345]  eta: 0:00:56  lr: 0.000002  loss: 0.7320 (0.7378)  time: 0.2511  data: 0.0001  max mem: 10917
[15:40:18.378757] Epoch: [47]  [140/345]  eta: 0:00:51  lr: 0.000002  loss: 0.7345 (0.7373)  time: 0.2512  data: 0.0001  max mem: 10917
[15:40:23.405146] Epoch: [47]  [160/345]  eta: 0:00:46  lr: 0.000002  loss: 0.7366 (0.7374)  time: 0.2513  data: 0.0000  max mem: 10917
[15:40:28.433937] Epoch: [47]  [180/345]  eta: 0:00:41  lr: 0.000002  loss: 0.7371 (0.7375)  time: 0.2514  data: 0.0001  max mem: 10917
[15:40:33.465989] Epoch: [47]  [200/345]  eta: 0:00:36  lr: 0.000002  loss: 0.7358 (0.7376)  time: 0.2516  data: 0.0001  max mem: 10917
[15:40:38.504159] Epoch: [47]  [220/345]  eta: 0:00:31  lr: 0.000002  loss: 0.7360 (0.7374)  time: 0.2519  data: 0.0001  max mem: 10917
[15:40:43.542945] Epoch: [47]  [240/345]  eta: 0:00:26  lr: 0.000002  loss: 0.7408 (0.7376)  time: 0.2519  data: 0.0001  max mem: 10917
[15:40:48.587158] Epoch: [47]  [260/345]  eta: 0:00:21  lr: 0.000002  loss: 0.7367 (0.7377)  time: 0.2522  data: 0.0001  max mem: 10917
[15:40:53.632261] Epoch: [47]  [280/345]  eta: 0:00:16  lr: 0.000002  loss: 0.7336 (0.7376)  time: 0.2522  data: 0.0001  max mem: 10917
[15:40:58.677329] Epoch: [47]  [300/345]  eta: 0:00:11  lr: 0.000002  loss: 0.7441 (0.7381)  time: 0.2522  data: 0.0000  max mem: 10917
[15:41:03.720418] Epoch: [47]  [320/345]  eta: 0:00:06  lr: 0.000001  loss: 0.7319 (0.7378)  time: 0.2521  data: 0.0001  max mem: 10917
[15:41:08.763827] Epoch: [47]  [340/345]  eta: 0:00:01  lr: 0.000001  loss: 0.7344 (0.7377)  time: 0.2521  data: 0.0000  max mem: 10917
[15:41:09.773199] Epoch: [47]  [344/345]  eta: 0:00:00  lr: 0.000001  loss: 0.7423 (0.7378)  time: 0.2521  data: 0.0001  max mem: 10917
[15:41:09.830668] Epoch: [47] Total time: 0:01:26 (0.2519 s / it)
[15:41:09.831195] Averaged stats: lr: 0.000001  loss: 0.7423 (0.7378)
[15:41:10.073820] Test:  [  0/345]  eta: 0:01:22  loss: 0.6950 (0.6950)  time: 0.2388  data: 0.1585  max mem: 10917
[15:41:10.912476] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7113 (0.7120)  time: 0.0979  data: 0.0162  max mem: 10917
[15:41:11.760856] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7057 (0.7078)  time: 0.0843  data: 0.0023  max mem: 10917
[15:41:12.587972] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7001 (0.7069)  time: 0.0837  data: 0.0013  max mem: 10917
[15:41:13.417817] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7055 (0.7087)  time: 0.0828  data: 0.0001  max mem: 10917
[15:41:14.251692] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7064 (0.7082)  time: 0.0831  data: 0.0001  max mem: 10917
[15:41:15.089863] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7059 (0.7081)  time: 0.0836  data: 0.0001  max mem: 10917
[15:41:15.931828] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7071 (0.7083)  time: 0.0840  data: 0.0001  max mem: 10917
[15:41:16.776876] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7071 (0.7079)  time: 0.0843  data: 0.0001  max mem: 10917
[15:41:17.625681] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7030 (0.7072)  time: 0.0846  data: 0.0001  max mem: 10917
[15:41:18.477170] Test:  [100/345]  eta: 0:00:20  loss: 0.7020 (0.7068)  time: 0.0850  data: 0.0001  max mem: 10917
[15:41:19.332613] Test:  [110/345]  eta: 0:00:20  loss: 0.7043 (0.7070)  time: 0.0853  data: 0.0001  max mem: 10917
[15:41:20.192304] Test:  [120/345]  eta: 0:00:19  loss: 0.7098 (0.7075)  time: 0.0857  data: 0.0001  max mem: 10917
[15:41:21.054923] Test:  [130/345]  eta: 0:00:18  loss: 0.7074 (0.7073)  time: 0.0861  data: 0.0001  max mem: 10917
[15:41:21.920973] Test:  [140/345]  eta: 0:00:17  loss: 0.7017 (0.7071)  time: 0.0864  data: 0.0001  max mem: 10917
[15:41:22.790539] Test:  [150/345]  eta: 0:00:16  loss: 0.7000 (0.7069)  time: 0.0867  data: 0.0001  max mem: 10917
[15:41:23.663280] Test:  [160/345]  eta: 0:00:15  loss: 0.7064 (0.7071)  time: 0.0871  data: 0.0001  max mem: 10917
[15:41:24.539145] Test:  [170/345]  eta: 0:00:15  loss: 0.7076 (0.7073)  time: 0.0874  data: 0.0001  max mem: 10917
[15:41:25.419061] Test:  [180/345]  eta: 0:00:14  loss: 0.7084 (0.7073)  time: 0.0877  data: 0.0001  max mem: 10917
[15:41:26.301893] Test:  [190/345]  eta: 0:00:13  loss: 0.7047 (0.7071)  time: 0.0881  data: 0.0001  max mem: 10917
[15:41:27.189552] Test:  [200/345]  eta: 0:00:12  loss: 0.7042 (0.7071)  time: 0.0885  data: 0.0001  max mem: 10917
[15:41:28.081000] Test:  [210/345]  eta: 0:00:11  loss: 0.7077 (0.7071)  time: 0.0889  data: 0.0001  max mem: 10917
[15:41:28.975576] Test:  [220/345]  eta: 0:00:10  loss: 0.7056 (0.7072)  time: 0.0893  data: 0.0001  max mem: 10917
[15:41:29.873496] Test:  [230/345]  eta: 0:00:09  loss: 0.7005 (0.7071)  time: 0.0896  data: 0.0001  max mem: 10917
[15:41:30.774861] Test:  [240/345]  eta: 0:00:09  loss: 0.7089 (0.7076)  time: 0.0899  data: 0.0001  max mem: 10917
[15:41:31.680273] Test:  [250/345]  eta: 0:00:08  loss: 0.7089 (0.7076)  time: 0.0903  data: 0.0001  max mem: 10917
[15:41:32.587999] Test:  [260/345]  eta: 0:00:07  loss: 0.7091 (0.7077)  time: 0.0906  data: 0.0001  max mem: 10917
[15:41:33.499824] Test:  [270/345]  eta: 0:00:06  loss: 0.7091 (0.7077)  time: 0.0909  data: 0.0001  max mem: 10917
[15:41:34.415124] Test:  [280/345]  eta: 0:00:05  loss: 0.7083 (0.7076)  time: 0.0913  data: 0.0001  max mem: 10917
[15:41:35.334355] Test:  [290/345]  eta: 0:00:04  loss: 0.7115 (0.7077)  time: 0.0917  data: 0.0001  max mem: 10917
[15:41:36.256191] Test:  [300/345]  eta: 0:00:03  loss: 0.7112 (0.7078)  time: 0.0920  data: 0.0001  max mem: 10917
[15:41:37.181839] Test:  [310/345]  eta: 0:00:03  loss: 0.7094 (0.7078)  time: 0.0923  data: 0.0001  max mem: 10917
[15:41:38.110488] Test:  [320/345]  eta: 0:00:02  loss: 0.7094 (0.7078)  time: 0.0927  data: 0.0001  max mem: 10917
[15:41:39.043250] Test:  [330/345]  eta: 0:00:01  loss: 0.7051 (0.7076)  time: 0.0930  data: 0.0001  max mem: 10917
[15:41:39.979306] Test:  [340/345]  eta: 0:00:00  loss: 0.7051 (0.7077)  time: 0.0934  data: 0.0001  max mem: 10917
[15:41:40.355358] Test:  [344/345]  eta: 0:00:00  loss: 0.7051 (0.7077)  time: 0.0935  data: 0.0001  max mem: 10917
[15:41:40.411244] Test: Total time: 0:00:30 (0.0886 s / it)
[15:41:51.476453] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9163 (0.9163)  time: 0.2231  data: 0.1432  max mem: 10917
[15:41:52.289407] Test:  [10/57]  eta: 0:00:04  loss: 0.9233 (0.9266)  time: 0.0941  data: 0.0131  max mem: 10917
[15:41:53.106914] Test:  [20/57]  eta: 0:00:03  loss: 0.9195 (0.9126)  time: 0.0815  data: 0.0001  max mem: 10917
[15:41:53.928520] Test:  [30/57]  eta: 0:00:02  loss: 0.8026 (0.8706)  time: 0.0819  data: 0.0001  max mem: 10917
[15:41:54.753016] Test:  [40/57]  eta: 0:00:01  loss: 0.7843 (0.8484)  time: 0.0823  data: 0.0001  max mem: 10917
[15:41:55.581373] Test:  [50/57]  eta: 0:00:00  loss: 0.7874 (0.8408)  time: 0.0826  data: 0.0001  max mem: 10917
[15:41:56.031641] Test:  [56/57]  eta: 0:00:00  loss: 0.8252 (0.8475)  time: 0.0804  data: 0.0001  max mem: 10917
[15:41:56.073755] Test: Total time: 0:00:04 (0.0846 s / it)
[15:41:58.071471] Dice score of the network on the train images: 0.831849, val images: 0.809808
[15:41:58.074993] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:41:58.472666] Epoch: [48]  [  0/345]  eta: 0:02:16  lr: 0.000001  loss: 0.7397 (0.7397)  time: 0.3966  data: 0.1453  max mem: 10917
[15:42:03.460976] Epoch: [48]  [ 20/345]  eta: 0:01:23  lr: 0.000001  loss: 0.7393 (0.7387)  time: 0.2494  data: 0.0001  max mem: 10917
[15:42:08.453269] Epoch: [48]  [ 40/345]  eta: 0:01:17  lr: 0.000001  loss: 0.7406 (0.7386)  time: 0.2496  data: 0.0001  max mem: 10917
[15:42:13.445305] Epoch: [48]  [ 60/345]  eta: 0:01:11  lr: 0.000001  loss: 0.7359 (0.7392)  time: 0.2496  data: 0.0001  max mem: 10917
[15:42:18.442437] Epoch: [48]  [ 80/345]  eta: 0:01:06  lr: 0.000001  loss: 0.7360 (0.7382)  time: 0.2498  data: 0.0001  max mem: 10917
[15:42:23.451390] Epoch: [48]  [100/345]  eta: 0:01:01  lr: 0.000001  loss: 0.7425 (0.7395)  time: 0.2504  data: 0.0000  max mem: 10917
[15:42:28.466285] Epoch: [48]  [120/345]  eta: 0:00:56  lr: 0.000001  loss: 0.7332 (0.7395)  time: 0.2507  data: 0.0001  max mem: 10917
[15:42:33.492999] Epoch: [48]  [140/345]  eta: 0:00:51  lr: 0.000001  loss: 0.7391 (0.7394)  time: 0.2513  data: 0.0000  max mem: 10917
[15:42:38.516470] Epoch: [48]  [160/345]  eta: 0:00:46  lr: 0.000001  loss: 0.7387 (0.7392)  time: 0.2511  data: 0.0000  max mem: 10917
[15:42:43.549315] Epoch: [48]  [180/345]  eta: 0:00:41  lr: 0.000001  loss: 0.7408 (0.7395)  time: 0.2516  data: 0.0001  max mem: 10917
[15:42:48.664317] Epoch: [48]  [200/345]  eta: 0:00:36  lr: 0.000001  loss: 0.7317 (0.7389)  time: 0.2557  data: 0.0001  max mem: 10917
[15:42:53.699020] Epoch: [48]  [220/345]  eta: 0:00:31  lr: 0.000001  loss: 0.7332 (0.7387)  time: 0.2517  data: 0.0000  max mem: 10917
[15:42:58.734113] Epoch: [48]  [240/345]  eta: 0:00:26  lr: 0.000001  loss: 0.7287 (0.7383)  time: 0.2517  data: 0.0000  max mem: 10917
[15:43:03.772907] Epoch: [48]  [260/345]  eta: 0:00:21  lr: 0.000001  loss: 0.7361 (0.7382)  time: 0.2519  data: 0.0001  max mem: 10917

[15:43:08.813674] Epoch: [48]  [280/345]  eta: 0:00:16  lr: 0.000000  loss: 0.7285 (0.7377)  time: 0.2520  data: 0.0000  max mem: 10917
[15:43:13.861420] Epoch: [48]  [300/345]  eta: 0:00:11  lr: 0.000000  loss: 0.7333 (0.7376)  time: 0.2523  data: 0.0000  max mem: 10917
[15:43:18.905567] Epoch: [48]  [320/345]  eta: 0:00:06  lr: 0.000000  loss: 0.7327 (0.7373)  time: 0.2522  data: 0.0000  max mem: 10917
[15:43:23.948453] Epoch: [48]  [340/345]  eta: 0:00:01  lr: 0.000000  loss: 0.7337 (0.7372)  time: 0.2521  data: 0.0001  max mem: 10917
[15:43:24.958604] Epoch: [48]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.7368 (0.7373)  time: 0.2521  data: 0.0001  max mem: 10917
[15:43:25.022436] Epoch: [48] Total time: 0:01:26 (0.2520 s / it)
[15:43:25.022848] Averaged stats: lr: 0.000000  loss: 0.7368 (0.7373)
[15:43:25.262255] Test:  [  0/345]  eta: 0:01:21  loss: 0.7084 (0.7084)  time: 0.2356  data: 0.1556  max mem: 10917
[15:43:26.102887] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7058 (0.7044)  time: 0.0978  data: 0.0160  max mem: 10917
[15:43:26.926386] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7046 (0.7071)  time: 0.0831  data: 0.0011  max mem: 10917
[15:43:27.753950] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7046 (0.7069)  time: 0.0825  data: 0.0001  max mem: 10917
[15:43:28.585518] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7035 (0.7061)  time: 0.0829  data: 0.0001  max mem: 10917
[15:43:29.419848] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7101 (0.7081)  time: 0.0832  data: 0.0001  max mem: 10917
[15:43:30.258180] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7112 (0.7084)  time: 0.0836  data: 0.0001  max mem: 10917
[15:43:31.100116] Test:  [ 70/345]  eta: 0:00:23  loss: 0.6990 (0.7076)  time: 0.0840  data: 0.0001  max mem: 10917
[15:43:31.946053] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7006 (0.7074)  time: 0.0843  data: 0.0001  max mem: 10917
[15:43:32.794452] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7006 (0.7068)  time: 0.0847  data: 0.0001  max mem: 10917
[15:43:33.647296] Test:  [100/345]  eta: 0:00:20  loss: 0.7047 (0.7071)  time: 0.0850  data: 0.0001  max mem: 10917
[15:43:34.502139] Test:  [110/345]  eta: 0:00:20  loss: 0.7047 (0.7067)  time: 0.0853  data: 0.0001  max mem: 10917
[15:43:35.361273] Test:  [120/345]  eta: 0:00:19  loss: 0.7039 (0.7074)  time: 0.0856  data: 0.0001  max mem: 10917
[15:43:36.224912] Test:  [130/345]  eta: 0:00:18  loss: 0.7106 (0.7079)  time: 0.0861  data: 0.0001  max mem: 10917
[15:43:37.091597] Test:  [140/345]  eta: 0:00:17  loss: 0.7107 (0.7082)  time: 0.0865  data: 0.0001  max mem: 10917
[15:43:37.961802] Test:  [150/345]  eta: 0:00:16  loss: 0.7068 (0.7079)  time: 0.0868  data: 0.0001  max mem: 10917
[15:43:38.834822] Test:  [160/345]  eta: 0:00:15  loss: 0.7002 (0.7077)  time: 0.0871  data: 0.0001  max mem: 10917
[15:43:39.712424] Test:  [170/345]  eta: 0:00:15  loss: 0.7034 (0.7075)  time: 0.0875  data: 0.0001  max mem: 10917
[15:43:40.592899] Test:  [180/345]  eta: 0:00:14  loss: 0.7043 (0.7077)  time: 0.0879  data: 0.0001  max mem: 10917
[15:43:41.476493] Test:  [190/345]  eta: 0:00:13  loss: 0.7043 (0.7077)  time: 0.0882  data: 0.0001  max mem: 10917
[15:43:42.363746] Test:  [200/345]  eta: 0:00:12  loss: 0.7052 (0.7079)  time: 0.0885  data: 0.0001  max mem: 10917
[15:43:43.255057] Test:  [210/345]  eta: 0:00:11  loss: 0.7052 (0.7077)  time: 0.0889  data: 0.0001  max mem: 10917
[15:43:44.150105] Test:  [220/345]  eta: 0:00:10  loss: 0.7076 (0.7078)  time: 0.0893  data: 0.0001  max mem: 10917
[15:43:45.047505] Test:  [230/345]  eta: 0:00:09  loss: 0.7102 (0.7079)  time: 0.0896  data: 0.0001  max mem: 10917
[15:43:45.949204] Test:  [240/345]  eta: 0:00:09  loss: 0.7019 (0.7076)  time: 0.0899  data: 0.0001  max mem: 10917
[15:43:46.853928] Test:  [250/345]  eta: 0:00:08  loss: 0.7054 (0.7077)  time: 0.0903  data: 0.0001  max mem: 10917
[15:43:47.763005] Test:  [260/345]  eta: 0:00:07  loss: 0.7093 (0.7078)  time: 0.0906  data: 0.0001  max mem: 10917
[15:43:48.675310] Test:  [270/345]  eta: 0:00:06  loss: 0.7108 (0.7078)  time: 0.0910  data: 0.0001  max mem: 10917
[15:43:49.591600] Test:  [280/345]  eta: 0:00:05  loss: 0.7096 (0.7080)  time: 0.0914  data: 0.0001  max mem: 10917
[15:43:50.510376] Test:  [290/345]  eta: 0:00:04  loss: 0.7091 (0.7080)  time: 0.0917  data: 0.0001  max mem: 10917
[15:43:51.433327] Test:  [300/345]  eta: 0:00:03  loss: 0.7059 (0.7079)  time: 0.0920  data: 0.0001  max mem: 10917
[15:43:52.358807] Test:  [310/345]  eta: 0:00:03  loss: 0.7063 (0.7079)  time: 0.0924  data: 0.0001  max mem: 10917
[15:43:53.287897] Test:  [320/345]  eta: 0:00:02  loss: 0.7025 (0.7078)  time: 0.0927  data: 0.0001  max mem: 10917
[15:43:54.220204] Test:  [330/345]  eta: 0:00:01  loss: 0.7011 (0.7077)  time: 0.0930  data: 0.0001  max mem: 10917
[15:43:55.156357] Test:  [340/345]  eta: 0:00:00  loss: 0.7041 (0.7076)  time: 0.0934  data: 0.0001  max mem: 10917
[15:43:55.532623] Test:  [344/345]  eta: 0:00:00  loss: 0.7041 (0.7076)  time: 0.0935  data: 0.0001  max mem: 10917
[15:43:55.587563] Test: Total time: 0:00:30 (0.0886 s / it)
[15:44:06.819123] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9160 (0.9160)  time: 0.2204  data: 0.1406  max mem: 10917
[15:44:07.632964] Test:  [10/57]  eta: 0:00:04  loss: 0.9243 (0.9273)  time: 0.0939  data: 0.0128  max mem: 10917
[15:44:08.449741] Test:  [20/57]  eta: 0:00:03  loss: 0.9209 (0.9134)  time: 0.0814  data: 0.0001  max mem: 10917
[15:44:09.270541] Test:  [30/57]  eta: 0:00:02  loss: 0.8048 (0.8714)  time: 0.0818  data: 0.0001  max mem: 10917
[15:44:10.094858] Test:  [40/57]  eta: 0:00:01  loss: 0.7861 (0.8493)  time: 0.0822  data: 0.0001  max mem: 10917
[15:44:10.923018] Test:  [50/57]  eta: 0:00:00  loss: 0.7886 (0.8417)  time: 0.0826  data: 0.0001  max mem: 10917
[15:44:11.373120] Test:  [56/57]  eta: 0:00:00  loss: 0.8259 (0.8483)  time: 0.0804  data: 0.0001  max mem: 10917
[15:44:11.431692] Test: Total time: 0:00:04 (0.0848 s / it)
[15:44:13.384555] Dice score of the network on the train images: 0.833944, val images: 0.809465
[15:44:13.389104] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:44:13.790612] Epoch: [49]  [  0/345]  eta: 0:02:18  lr: 0.000000  loss: 0.7490 (0.7490)  time: 0.4005  data: 0.1484  max mem: 10917
[15:44:18.793835] Epoch: [49]  [ 20/345]  eta: 0:01:23  lr: 0.000000  loss: 0.7381 (0.7379)  time: 0.2501  data: 0.0001  max mem: 10917
[15:44:23.797441] Epoch: [49]  [ 40/345]  eta: 0:01:17  lr: 0.000000  loss: 0.7444 (0.7399)  time: 0.2501  data: 0.0001  max mem: 10917
[15:44:28.813291] Epoch: [49]  [ 60/345]  eta: 0:01:12  lr: 0.000000  loss: 0.7319 (0.7381)  time: 0.2507  data: 0.0000  max mem: 10917
[15:44:33.825245] Epoch: [49]  [ 80/345]  eta: 0:01:06  lr: 0.000000  loss: 0.7332 (0.7364)  time: 0.2505  data: 0.0001  max mem: 10917
[15:44:38.846165] Epoch: [49]  [100/345]  eta: 0:01:01  lr: 0.000000  loss: 0.7356 (0.7362)  time: 0.2510  data: 0.0000  max mem: 10917
[15:44:43.872704] Epoch: [49]  [120/345]  eta: 0:00:56  lr: 0.000000  loss: 0.7393 (0.7368)  time: 0.2513  data: 0.0001  max mem: 10917
[15:44:48.900175] Epoch: [49]  [140/345]  eta: 0:00:51  lr: 0.000000  loss: 0.7363 (0.7370)  time: 0.2513  data: 0.0000  max mem: 10917
[15:44:53.929196] Epoch: [49]  [160/345]  eta: 0:00:46  lr: 0.000000  loss: 0.7411 (0.7371)  time: 0.2514  data: 0.0000  max mem: 10917

[15:44:58.964083] Epoch: [49]  [180/345]  eta: 0:00:41  lr: 0.000000  loss: 0.7296 (0.7368)  time: 0.2517  data: 0.0000  max mem: 10917
[15:45:03.998607] Epoch: [49]  [200/345]  eta: 0:00:36  lr: 0.000000  loss: 0.7420 (0.7378)  time: 0.2517  data: 0.0001  max mem: 10917
[15:45:09.035811] Epoch: [49]  [220/345]  eta: 0:00:31  lr: 0.000000  loss: 0.7283 (0.7374)  time: 0.2518  data: 0.0000  max mem: 10917
[15:45:14.076019] Epoch: [49]  [240/345]  eta: 0:00:26  lr: 0.000000  loss: 0.7425 (0.7377)  time: 0.2520  data: 0.0000  max mem: 10917
[15:45:19.120443] Epoch: [49]  [260/345]  eta: 0:00:21  lr: 0.000000  loss: 0.7305 (0.7379)  time: 0.2522  data: 0.0000  max mem: 10917
[15:45:24.166280] Epoch: [49]  [280/345]  eta: 0:00:16  lr: 0.000000  loss: 0.7342 (0.7378)  time: 0.2522  data: 0.0001  max mem: 10917
[15:45:29.212093] Epoch: [49]  [300/345]  eta: 0:00:11  lr: 0.000000  loss: 0.7349 (0.7376)  time: 0.2522  data: 0.0000  max mem: 10917
[15:45:34.260988] Epoch: [49]  [320/345]  eta: 0:00:06  lr: 0.000000  loss: 0.7386 (0.7378)  time: 0.2524  data: 0.0000  max mem: 10917
[15:45:39.310695] Epoch: [49]  [340/345]  eta: 0:00:01  lr: 0.000000  loss: 0.7273 (0.7374)  time: 0.2524  data: 0.0001  max mem: 10917
[15:45:40.319829] Epoch: [49]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.7324 (0.7374)  time: 0.2524  data: 0.0001  max mem: 10917
[15:45:40.377718] Epoch: [49] Total time: 0:01:26 (0.2521 s / it)
[15:45:40.378185] Averaged stats: lr: 0.000000  loss: 0.7324 (0.7374)
[15:45:40.621466] Test:  [  0/345]  eta: 0:01:22  loss: 0.7211 (0.7211)  time: 0.2395  data: 0.1590  max mem: 10917
[15:45:41.441560] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7038 (0.7071)  time: 0.0963  data: 0.0145  max mem: 10917
[15:45:42.265538] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7060 (0.7091)  time: 0.0821  data: 0.0001  max mem: 10917
[15:45:43.092642] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7090 (0.7091)  time: 0.0825  data: 0.0001  max mem: 10917
[15:45:43.924489] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7025 (0.7082)  time: 0.0829  data: 0.0001  max mem: 10917
[15:45:44.758953] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7065 (0.7085)  time: 0.0833  data: 0.0001  max mem: 10917
[15:45:45.597642] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7000 (0.7075)  time: 0.0836  data: 0.0001  max mem: 10917
[15:45:46.439840] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7073 (0.7087)  time: 0.0840  data: 0.0001  max mem: 10917
[15:45:47.285392] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7090 (0.7085)  time: 0.0843  data: 0.0001  max mem: 10917
[15:45:48.133568] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7067 (0.7083)  time: 0.0846  data: 0.0001  max mem: 10917
[15:45:48.985575] Test:  [100/345]  eta: 0:00:20  loss: 0.7067 (0.7085)  time: 0.0850  data: 0.0001  max mem: 10917
[15:45:49.841484] Test:  [110/345]  eta: 0:00:20  loss: 0.7065 (0.7081)  time: 0.0853  data: 0.0001  max mem: 10917
[15:45:50.700583] Test:  [120/345]  eta: 0:00:19  loss: 0.7105 (0.7085)  time: 0.0857  data: 0.0001  max mem: 10917
[15:45:51.562793] Test:  [130/345]  eta: 0:00:18  loss: 0.7096 (0.7086)  time: 0.0860  data: 0.0001  max mem: 10917
[15:45:52.428969] Test:  [140/345]  eta: 0:00:17  loss: 0.7086 (0.7089)  time: 0.0864  data: 0.0001  max mem: 10917
[15:45:53.299308] Test:  [150/345]  eta: 0:00:16  loss: 0.7064 (0.7085)  time: 0.0868  data: 0.0001  max mem: 10917
[15:45:54.172482] Test:  [160/345]  eta: 0:00:15  loss: 0.7072 (0.7087)  time: 0.0871  data: 0.0001  max mem: 10917
[15:45:55.050405] Test:  [170/345]  eta: 0:00:15  loss: 0.7131 (0.7090)  time: 0.0875  data: 0.0001  max mem: 10917
[15:45:55.931336] Test:  [180/345]  eta: 0:00:14  loss: 0.7079 (0.7088)  time: 0.0879  data: 0.0001  max mem: 10917
[15:45:56.814917] Test:  [190/345]  eta: 0:00:13  loss: 0.7104 (0.7090)  time: 0.0882  data: 0.0001  max mem: 10917
[15:45:57.702885] Test:  [200/345]  eta: 0:00:12  loss: 0.7070 (0.7089)  time: 0.0885  data: 0.0001  max mem: 10917
[15:45:58.594127] Test:  [210/345]  eta: 0:00:11  loss: 0.7033 (0.7087)  time: 0.0889  data: 0.0001  max mem: 10917
[15:45:59.487872] Test:  [220/345]  eta: 0:00:10  loss: 0.7034 (0.7085)  time: 0.0892  data: 0.0001  max mem: 10917
[15:46:00.385149] Test:  [230/345]  eta: 0:00:09  loss: 0.7063 (0.7084)  time: 0.0895  data: 0.0001  max mem: 10917
[15:46:01.286693] Test:  [240/345]  eta: 0:00:09  loss: 0.7103 (0.7085)  time: 0.0899  data: 0.0001  max mem: 10917
[15:46:02.191900] Test:  [250/345]  eta: 0:00:08  loss: 0.7016 (0.7081)  time: 0.0903  data: 0.0001  max mem: 10917
[15:46:03.100569] Test:  [260/345]  eta: 0:00:07  loss: 0.6996 (0.7081)  time: 0.0906  data: 0.0001  max mem: 10917
[15:46:04.013564] Test:  [270/345]  eta: 0:00:06  loss: 0.7029 (0.7080)  time: 0.0910  data: 0.0001  max mem: 10917
[15:46:04.928390] Test:  [280/345]  eta: 0:00:05  loss: 0.7066 (0.7081)  time: 0.0913  data: 0.0001  max mem: 10917
[15:46:05.847973] Test:  [290/345]  eta: 0:00:04  loss: 0.7023 (0.7079)  time: 0.0917  data: 0.0001  max mem: 10917
[15:46:06.770300] Test:  [300/345]  eta: 0:00:03  loss: 0.7023 (0.7079)  time: 0.0921  data: 0.0001  max mem: 10917
[15:46:07.696309] Test:  [310/345]  eta: 0:00:03  loss: 0.7066 (0.7078)  time: 0.0924  data: 0.0001  max mem: 10917
[15:46:08.626309] Test:  [320/345]  eta: 0:00:02  loss: 0.7065 (0.7079)  time: 0.0928  data: 0.0001  max mem: 10917
[15:46:09.559163] Test:  [330/345]  eta: 0:00:01  loss: 0.7065 (0.7078)  time: 0.0931  data: 0.0001  max mem: 10917
[15:46:10.495129] Test:  [340/345]  eta: 0:00:00  loss: 0.7085 (0.7079)  time: 0.0934  data: 0.0001  max mem: 10917
[15:46:10.871442] Test:  [344/345]  eta: 0:00:00  loss: 0.7085 (0.7079)  time: 0.0936  data: 0.0001  max mem: 10917
[15:46:10.928720] Test: Total time: 0:00:30 (0.0885 s / it)
[15:46:21.950161] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9153 (0.9153)  time: 0.2261  data: 0.1463  max mem: 10917
[15:46:22.762354] Test:  [10/57]  eta: 0:00:04  loss: 0.9226 (0.9257)  time: 0.0943  data: 0.0134  max mem: 10917
[15:46:23.578515] Test:  [20/57]  eta: 0:00:03  loss: 0.9184 (0.9118)  time: 0.0814  data: 0.0001  max mem: 10917
[15:46:24.399505] Test:  [30/57]  eta: 0:00:02  loss: 0.8020 (0.8699)  time: 0.0818  data: 0.0001  max mem: 10917
[15:46:25.223660] Test:  [40/57]  eta: 0:00:01  loss: 0.7840 (0.8478)  time: 0.0822  data: 0.0001  max mem: 10917
[15:46:26.051898] Test:  [50/57]  eta: 0:00:00  loss: 0.7869 (0.8402)  time: 0.0826  data: 0.0001  max mem: 10917
[15:46:26.501867] Test:  [56/57]  eta: 0:00:00  loss: 0.8252 (0.8470)  time: 0.0804  data: 0.0001  max mem: 10917
[15:46:26.559161] Test: Total time: 0:00:04 (0.0848 s / it)
[15:46:28.489120] Dice score of the network on the train images: 0.831238, val images: 0.810188
[15:46:28.490576] Training time 1:52:50
[15:46:29.925722] Load pre-trained checkpoint from: /root/seg_framework/MS-Mamba/output_dir/mslesseg/checkpoints_0/checkpoint-best_dice_model_0.pth
[15:46:29.941794] <All keys matched successfully>
[15:46:30.384214] Test:  [  0/246]  eta: 0:01:33    time: 0.3801  data: 0.1738  max mem: 10917
[15:46:31.797514] Test:  [ 10/246]  eta: 0:00:38    time: 0.1630  data: 0.0159  max mem: 10917
[15:46:36.619723] ---------------------------------
[15:46:36.619953] Patient 1:
[15:46:36.620039]       precision: 0.5757299065589905
[15:46:36.620108]       recall: 0.41540488600730896
[15:46:36.620167]       dice_score: 0.4826003909111023
[15:46:36.623931] Test:  [ 20/246]  eta: 0:01:11    time: 0.3119  data: 0.0001  max mem: 10917
[15:46:38.031856] Test:  [ 30/246]  eta: 0:00:55    time: 0.3117  data: 0.0001  max mem: 10917
[15:46:42.794185] ---------------------------------
[15:46:42.794409] Patient 2:
[15:46:42.794489]       precision: 0.6966666579246521
[15:46:42.794554]       recall: 0.42200908064842224
[15:46:42.794616]       dice_score: 0.5256208777427673
[15:46:42.795138] Test:  [ 40/246]  eta: 0:01:04    time: 0.3085  data: 0.0001  max mem: 10917
[15:46:44.199731] Test:  [ 50/246]  eta: 0:00:54    time: 0.3083  data: 0.0001  max mem: 10917
[15:46:45.747159] Test:  [ 60/246]  eta: 0:00:47    time: 0.1476  data: 0.0001  max mem: 10917
[15:46:49.140752] ---------------------------------
[15:46:49.140986] Patient 3:
[15:46:49.141067]       precision: 0.4215189814567566
[15:46:49.141134]       recall: 0.36533185839653015
[15:46:49.141196]       dice_score: 0.39141932129859924
[15:46:50.394402] Test:  [ 70/246]  eta: 0:00:50    time: 0.3097  data: 0.0001  max mem: 10917
[15:46:51.942508] Test:  [ 80/246]  eta: 0:00:44    time: 0.3097  data: 0.0001  max mem: 10917
[15:46:55.331270] ---------------------------------
[15:46:55.331506] Patient 4:
[15:46:55.331589]       precision: 0.6975772976875305
[15:46:55.331656]       recall: 0.42150428891181946
[15:46:55.331717]       dice_score: 0.5254877209663391
[15:46:56.580763] Test:  [ 90/246]  eta: 0:00:45    time: 0.3093  data: 0.0001  max mem: 10917
[15:46:58.124893] Test:  [100/246]  eta: 0:00:40    time: 0.3091  data: 0.0001  max mem: 10917
[15:47:01.654121] ---------------------------------
[15:47:01.654378] Patient 5:
[15:47:01.654464]       precision: 0.4215189814567566
[15:47:01.654532]       recall: 0.36533185839653015
[15:47:01.654594]       dice_score: 0.39141932129859924
[15:47:02.752901] Test:  [110/246]  eta: 0:00:40    time: 0.3086  data: 0.0001  max mem: 10917
[15:47:04.298340] Test:  [120/246]  eta: 0:00:35    time: 0.3086  data: 0.0001  max mem: 10917
[15:47:07.843802] ---------------------------------
[15:47:07.844039] Patient 6:
[15:47:07.844126]       precision: 0.4123774468898773
[15:47:07.844193]       recall: 0.36917170882225037
[15:47:07.844265]       dice_score: 0.38958030939102173
[15:47:08.940715] Test:  [130/246]  eta: 0:00:34    time: 0.3093  data: 0.0001  max mem: 10917
[15:47:10.485251] Test:  [140/246]  eta: 0:00:30    time: 0.3093  data: 0.0001  max mem: 10917
[15:47:14.240687] ---------------------------------
[15:47:14.240924] Patient 7:
[15:47:14.241006]       precision: 0.8028650283813477
[15:47:14.241071]       recall: 0.7372676730155945
[15:47:14.241130]       dice_score: 0.7686693668365479
[15:47:15.183290] Test:  [150/246]  eta: 0:00:28    time: 0.3121  data: 0.0001  max mem: 10917
[15:47:16.724492] Test:  [160/246]  eta: 0:00:24    time: 0.3119  data: 0.0001  max mem: 10917
[15:47:20.431540] ---------------------------------
[15:47:20.431759] Patient 8:
[15:47:20.431838]       precision: 0.9109878540039062
[15:47:20.431902]       recall: 0.5047715306282043
[15:47:20.458689]       dice_score: 0.6496029496192932
[15:47:21.397895] Test:  [170/246]  eta: 0:00:22    time: 0.3107  data: 0.0001  max mem: 10917
[15:47:22.938114] Test:  [180/246]  eta: 0:00:19    time: 0.3106  data: 0.0001  max mem: 10917
[15:47:26.665493] ---------------------------------
[15:47:26.665708] Patient 9:
[15:47:26.665787]       precision: 0.7381160259246826
[15:47:26.665850]       recall: 0.7702021598815918
[15:47:26.665909]       dice_score: 0.7538177967071533
[15:47:27.605328] Test:  [190/246]  eta: 0:00:16    time: 0.3103  data: 0.0001  max mem: 10917

[15:47:29.146744] Test:  [200/246]  eta: 0:00:13    time: 0.3104  data: 0.0001  max mem: 10917
[15:47:32.972508] ---------------------------------
[15:47:32.972731] Patient 10:
[15:47:32.972816]       precision: 0.7403227686882019
[15:47:32.972885]       recall: 0.7686843276023865
[15:47:32.972946]       dice_score: 0.7542370557785034
[15:47:33.757376] Test:  [210/246]  eta: 0:00:10    time: 0.3076  data: 0.0001  max mem: 10917
[15:47:35.298351] Test:  [220/246]  eta: 0:00:07    time: 0.3075  data: 0.0001  max mem: 10917
[15:47:39.162655] ---------------------------------
[15:47:39.162927] Patient 11:
[15:47:39.163010]       precision: 0.9008983373641968
[15:47:39.163074]       recall: 0.7157066464424133
[15:47:39.163131]       dice_score: 0.7976951003074646
[15:47:39.947542] Test:  [230/246]  eta: 0:00:04    time: 0.3095  data: 0.0001  max mem: 10917
[15:47:41.487178] Test:  [240/246]  eta: 0:00:01    time: 0.3094  data: 0.0001  max mem: 10917
[15:47:45.395843] ---------------------------------
[15:47:45.396079] Patient 12:
[15:47:45.396164]       precision: 0.690330982208252
[15:47:45.396241]       recall: 0.7146077752113342
[15:47:45.396302]       dice_score: 0.7022596597671509
[15:47:45.400098] Test:  [245/246]  eta: 0:00:00    time: 0.3108  data: 0.0001  max mem: 10917
[15:47:45.469390] Test: Total time: 0:01:15 (0.3068 s / it)
[15:47:45.469796] ================================
[15:47:45.469906] Averaged over all patients:
[15:47:45.470117]       precision: 0.6674 ± 0.1681
[15:47:45.470267]       recall: 0.5475 ± 0.1683
[15:47:45.470397]       dice_score: 0.5944 ± 0.1538
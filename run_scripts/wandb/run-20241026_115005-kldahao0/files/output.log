Not using distributed mode
[11:50:08.011995] job dir: /root/seg_framework/MS-Mamba/run_scripts
[11:50:08.012137] Namespace(accum_iter=1,
model='SegFormer3D',
in_channels=1,
lr=None,
blr=0.001,
min_lr=0,
dist_on_itp=False,
warmup_epochs=20,
device='cuda:0',
seed=42,
layer_decay=0.75,
clip_grad=None,
num_workers=1,
pin_mem=True,
resume='',
mask_mode='concatenate to image',
world_size=1,
embed_dim=1,
local_rank=-1,
dist_url='env://',
nb_classes=2,
data_dir='/root/MSLesSeg24/data',
datalist=None,
preprocess=False,
dim=2,
loss='mask tp1 tp2',
distributed=False)
[11:50:08.012258] device  cuda:0
[11:50:08.012908] Random seed set as 42
[11:50:08.013269] Starting for fold 0
[11:50:08.202998] Elements in data_dir_paths: 11052
[11:50:08.237098] Elements in data_dir_paths: 1803
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[11:50:10.111046] number of params: 47335447
[11:50:10.111292] model: Vivim2D(
  (encoder): mamba_block(
    (downsample_layers): SegformerEncoder(
      (patch_embeddings): ModuleList(
        (0): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(2, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (1): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (2): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (3): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (block): ModuleList(
        (0): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): Identity()
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.003703703870996833)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.007407407741993666)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.011111111380159855)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.014814815483987331)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.018518518656492233)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.02222222276031971)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (2): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.025925926864147186)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.029629630967974663)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03333333507180214)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03703703731298447)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04074074327945709)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04444444552063942)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.048148151487112045)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.051851850003004074)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0555555559694767)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.05925925821065903)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06296296417713165)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06666667014360428)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07037036865949631)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07407407462596893)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07777778059244156)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08148147910833359)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08518518507480621)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08888889104127884)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (3): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.09259259700775146)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0962962955236435)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.10000000149011612)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (layer_norm): ModuleList(
        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): SegformerDecodeHead(
    (linear_c): ModuleList(
      (0): SegformerMLP(
        (proj): Linear(in_features=64, out_features=768, bias=True)
      )
      (1): SegformerMLP(
        (proj): Linear(in_features=128, out_features=768, bias=True)
      )
      (2): SegformerMLP(
        (proj): Linear(in_features=320, out_features=768, bias=True)
      )
      (3): SegformerMLP(
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
    )
    (linear_fuse): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (batch_norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): ReLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Conv2d(768, 150, kernel_size=(1, 1), stride=(1, 1))
  )
  (out): Conv2d(768, 1, kernel_size=(1, 1), stride=(1, 1))
)
[11:50:10.113769] base lr: 1.00e-03
[11:50:10.113827] actual lr: 1.25e-04
[11:50:10.113877] accumulate grad iterations: 1
[11:50:10.113924] effective batch size: 32
[11:50:10.115191] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.000125
    maximize: False
    weight_decay: 0.01
)
[11:50:10.117223] Start training for 50 epochs
[11:50:10.118740] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:50:11.206970] Epoch: [0]  [  0/345]  eta: 0:06:15  lr: 0.000000  loss: 1.6960 (1.6960)  time: 1.0872  data: 0.2051  max mem: 10551
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
[11:50:16.057582] Epoch: [0]  [ 20/345]  eta: 0:01:31  lr: 0.000000  loss: 1.6900 (1.6908)  time: 0.2425  data: 0.0001  max mem: 10917
[11:50:20.916272] Epoch: [0]  [ 40/345]  eta: 0:01:20  lr: 0.000001  loss: 1.6888 (1.6902)  time: 0.2429  data: 0.0001  max mem: 10917
[11:50:25.770690] Epoch: [0]  [ 60/345]  eta: 0:01:13  lr: 0.000001  loss: 1.6859 (1.6889)  time: 0.2427  data: 0.0001  max mem: 10917
[11:50:30.620967] Epoch: [0]  [ 80/345]  eta: 0:01:07  lr: 0.000001  loss: 1.6809 (1.6870)  time: 0.2425  data: 0.0001  max mem: 10917
[11:50:35.478429] Epoch: [0]  [100/345]  eta: 0:01:01  lr: 0.000002  loss: 1.6779 (1.6852)  time: 0.2428  data: 0.0001  max mem: 10917
[11:50:40.347660] Epoch: [0]  [120/345]  eta: 0:00:56  lr: 0.000002  loss: 1.6719 (1.6830)  time: 0.2434  data: 0.0000  max mem: 10917
[11:50:45.232470] Epoch: [0]  [140/345]  eta: 0:00:51  lr: 0.000003  loss: 1.6633 (1.6804)  time: 0.2442  data: 0.0001  max mem: 10917
[11:50:50.127164] Epoch: [0]  [160/345]  eta: 0:00:45  lr: 0.000003  loss: 1.6554 (1.6773)  time: 0.2447  data: 0.0001  max mem: 10917
[11:50:55.035587] Epoch: [0]  [180/345]  eta: 0:00:40  lr: 0.000003  loss: 1.6422 (1.6736)  time: 0.2454  data: 0.0001  max mem: 10917
[11:50:59.953613] Epoch: [0]  [200/345]  eta: 0:00:35  lr: 0.000004  loss: 1.6268 (1.6690)  time: 0.2459  data: 0.0001  max mem: 10917
[11:51:04.879624] Epoch: [0]  [220/345]  eta: 0:00:30  lr: 0.000004  loss: 1.6131 (1.6640)  time: 0.2463  data: 0.0001  max mem: 10917
[11:51:09.816749] Epoch: [0]  [240/345]  eta: 0:00:26  lr: 0.000004  loss: 1.5986 (1.6588)  time: 0.2468  data: 0.0001  max mem: 10917
[11:51:14.756242] Epoch: [0]  [260/345]  eta: 0:00:21  lr: 0.000005  loss: 1.5842 (1.6531)  time: 0.2469  data: 0.0001  max mem: 10917
[11:51:19.701269] Epoch: [0]  [280/345]  eta: 0:00:16  lr: 0.000005  loss: 1.5702 (1.6472)  time: 0.2472  data: 0.0001  max mem: 10917
[11:51:24.651047] Epoch: [0]  [300/345]  eta: 0:00:11  lr: 0.000005  loss: 1.5530 (1.6409)  time: 0.2474  data: 0.0001  max mem: 10917
[11:51:29.613272] Epoch: [0]  [320/345]  eta: 0:00:06  lr: 0.000006  loss: 1.5361 (1.6344)  time: 0.2481  data: 0.0001  max mem: 10917
[11:51:34.578299] Epoch: [0]  [340/345]  eta: 0:00:01  lr: 0.000006  loss: 1.5210 (1.6278)  time: 0.2482  data: 0.0001  max mem: 10917
[11:51:35.572986] Epoch: [0]  [344/345]  eta: 0:00:00  lr: 0.000006  loss: 1.5196 (1.6265)  time: 0.2483  data: 0.0001  max mem: 10917
[11:51:35.629190] Epoch: [0] Total time: 0:01:25 (0.2479 s / it)
[11:51:35.629704] Averaged stats: lr: 0.000006  loss: 1.5196 (1.6265)
[11:51:35.876427] Test:  [  0/345]  eta: 0:01:24  loss: 1.5056 (1.5056)  time: 0.2442  data: 0.1649  max mem: 10917
[11:51:36.689022] Test:  [ 10/345]  eta: 0:00:32  loss: 1.5062 (1.5065)  time: 0.0960  data: 0.0151  max mem: 10917
[11:51:37.505950] Test:  [ 20/345]  eta: 0:00:28  loss: 1.5062 (1.5065)  time: 0.0814  data: 0.0001  max mem: 10917
[11:51:38.325664] Test:  [ 30/345]  eta: 0:00:27  loss: 1.5065 (1.5066)  time: 0.0818  data: 0.0001  max mem: 10917
[11:51:39.148648] Test:  [ 40/345]  eta: 0:00:26  loss: 1.5064 (1.5065)  time: 0.0821  data: 0.0001  max mem: 10917
[11:51:39.975075] Test:  [ 50/345]  eta: 0:00:25  loss: 1.5070 (1.5067)  time: 0.0824  data: 0.0001  max mem: 10917
[11:51:40.806636] Test:  [ 60/345]  eta: 0:00:24  loss: 1.5067 (1.5066)  time: 0.0829  data: 0.0001  max mem: 10917
[11:51:41.641274] Test:  [ 70/345]  eta: 0:00:23  loss: 1.5055 (1.5064)  time: 0.0833  data: 0.0001  max mem: 10917
[11:51:42.478867] Test:  [ 80/345]  eta: 0:00:22  loss: 1.5048 (1.5064)  time: 0.0836  data: 0.0001  max mem: 10917
[11:51:43.320680] Test:  [ 90/345]  eta: 0:00:21  loss: 1.5062 (1.5064)  time: 0.0839  data: 0.0001  max mem: 10917
[11:51:44.165662] Test:  [100/345]  eta: 0:00:20  loss: 1.5066 (1.5064)  time: 0.0843  data: 0.0001  max mem: 10917
[11:51:45.014962] Test:  [110/345]  eta: 0:00:19  loss: 1.5057 (1.5064)  time: 0.0847  data: 0.0001  max mem: 10917
[11:51:45.867455] Test:  [120/345]  eta: 0:00:19  loss: 1.5058 (1.5064)  time: 0.0850  data: 0.0001  max mem: 10917
[11:51:46.723498] Test:  [130/345]  eta: 0:00:18  loss: 1.5059 (1.5063)  time: 0.0854  data: 0.0001  max mem: 10917
[11:51:47.583036] Test:  [140/345]  eta: 0:00:17  loss: 1.5059 (1.5063)  time: 0.0857  data: 0.0001  max mem: 10917
[11:51:48.446342] Test:  [150/345]  eta: 0:00:16  loss: 1.5058 (1.5063)  time: 0.0861  data: 0.0001  max mem: 10917
[11:51:49.313129] Test:  [160/345]  eta: 0:00:15  loss: 1.5061 (1.5063)  time: 0.0865  data: 0.0001  max mem: 10917
[11:51:50.184367] Test:  [170/345]  eta: 0:00:14  loss: 1.5067 (1.5064)  time: 0.0869  data: 0.0001  max mem: 10917
[11:51:51.057812] Test:  [180/345]  eta: 0:00:14  loss: 1.5062 (1.5063)  time: 0.0872  data: 0.0001  max mem: 10917
[11:51:51.936035] Test:  [190/345]  eta: 0:00:13  loss: 1.5061 (1.5064)  time: 0.0875  data: 0.0001  max mem: 10917
[11:51:52.817314] Test:  [200/345]  eta: 0:00:12  loss: 1.5061 (1.5063)  time: 0.0879  data: 0.0001  max mem: 10917
[11:51:54.037968] Test:  [210/345]  eta: 0:00:11  loss: 1.5056 (1.5063)  time: 0.1050  data: 0.0001  max mem: 10917
[11:51:54.959416] Test:  [220/345]  eta: 0:00:10  loss: 1.5056 (1.5062)  time: 0.1071  data: 0.0001  max mem: 10917
[11:51:56.013476] Test:  [230/345]  eta: 0:00:10  loss: 1.5070 (1.5063)  time: 0.0987  data: 0.0001  max mem: 10917
[11:51:56.937337] Test:  [240/345]  eta: 0:00:09  loss: 1.5075 (1.5063)  time: 0.0988  data: 0.0001  max mem: 10917
[11:51:58.080896] Test:  [250/345]  eta: 0:00:08  loss: 1.5057 (1.5063)  time: 0.1033  data: 0.0001  max mem: 10917
[11:51:59.228189] Test:  [260/345]  eta: 0:00:07  loss: 1.5057 (1.5063)  time: 0.1145  data: 0.0001  max mem: 10917
[11:52:00.162417] Test:  [270/345]  eta: 0:00:06  loss: 1.5058 (1.5063)  time: 0.1040  data: 0.0001  max mem: 10917
[11:52:01.369664] Test:  [280/345]  eta: 0:00:05  loss: 1.5051 (1.5063)  time: 0.1070  data: 0.0001  max mem: 10917
[11:52:02.554242] Test:  [290/345]  eta: 0:00:05  loss: 1.5071 (1.5063)  time: 0.1195  data: 0.0001  max mem: 10917
[11:52:03.799611] Test:  [300/345]  eta: 0:00:04  loss: 1.5060 (1.5063)  time: 0.1214  data: 0.0001  max mem: 10917
[11:52:05.002083] Test:  [310/345]  eta: 0:00:03  loss: 1.5059 (1.5063)  time: 0.1223  data: 0.0001  max mem: 10917
[11:52:06.087731] Test:  [320/345]  eta: 0:00:02  loss: 1.5060 (1.5062)  time: 0.1144  data: 0.0001  max mem: 10917
[11:52:07.206401] Test:  [330/345]  eta: 0:00:01  loss: 1.5051 (1.5062)  time: 0.1102  data: 0.0001  max mem: 10917
[11:52:08.569948] Test:  [340/345]  eta: 0:00:00  loss: 1.5057 (1.5062)  time: 0.1241  data: 0.0001  max mem: 10917
[11:52:09.173253] Test:  [344/345]  eta: 0:00:00  loss: 1.5061 (1.5062)  time: 0.1279  data: 0.0001  max mem: 10917
[11:52:09.231960] Test: Total time: 0:00:33 (0.0974 s / it)
[11:52:20.509492] Test:  [ 0/57]  eta: 0:00:13  loss: 1.5115 (1.5115)  time: 0.2282  data: 0.1483  max mem: 10917
[11:52:21.353491] Test:  [10/57]  eta: 0:00:04  loss: 1.5087 (1.5089)  time: 0.0974  data: 0.0170  max mem: 10917
[11:52:22.166308] Test:  [20/57]  eta: 0:00:03  loss: 1.5093 (1.5080)  time: 0.0828  data: 0.0020  max mem: 10917
[11:52:22.981246] Test:  [30/57]  eta: 0:00:02  loss: 1.5080 (1.5048)  time: 0.0813  data: 0.0001  max mem: 10917
[11:52:23.799782] Test:  [40/57]  eta: 0:00:01  loss: 1.4966 (1.5025)  time: 0.0816  data: 0.0001  max mem: 10917
[11:52:24.622146] Test:  [50/57]  eta: 0:00:00  loss: 1.4966 (1.5016)  time: 0.0820  data: 0.0001  max mem: 10917
[11:52:25.096545] Test:  [56/57]  eta: 0:00:00  loss: 1.4989 (1.5016)  time: 0.0812  data: 0.0001  max mem: 10917
[11:52:25.153238] Test: Total time: 0:00:04 (0.0855 s / it)
[11:52:27.076407] Dice score of the network on the train images: 0.000000, val images: 0.000000
[11:52:27.076665] saving best_dice_model_0 @ epoch 0
[11:52:27.766214] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:52:28.169440] Epoch: [1]  [  0/345]  eta: 0:02:18  lr: 0.000006  loss: 1.5158 (1.5158)  time: 0.4021  data: 0.1524  max mem: 10917
[11:52:33.126122] Epoch: [1]  [ 20/345]  eta: 0:01:22  lr: 0.000007  loss: 1.5031 (1.5047)  time: 0.2478  data: 0.0001  max mem: 10917
[11:52:38.094016] Epoch: [1]  [ 40/345]  eta: 0:01:16  lr: 0.000007  loss: 1.4936 (1.4991)  time: 0.2484  data: 0.0001  max mem: 10917
[11:52:43.070269] Epoch: [1]  [ 60/345]  eta: 0:01:11  lr: 0.000007  loss: 1.4792 (1.4928)  time: 0.2488  data: 0.0001  max mem: 10917

[11:52:48.049301] Epoch: [1]  [ 80/345]  eta: 0:01:06  lr: 0.000008  loss: 1.4671 (1.4868)  time: 0.2489  data: 0.0001  max mem: 10917
[11:52:53.030825] Epoch: [1]  [100/345]  eta: 0:01:01  lr: 0.000008  loss: 1.4561 (1.4809)  time: 0.2490  data: 0.0001  max mem: 10917
[11:52:58.023199] Epoch: [1]  [120/345]  eta: 0:00:56  lr: 0.000008  loss: 1.4482 (1.4756)  time: 0.2496  data: 0.0001  max mem: 10917
[11:53:03.011347] Epoch: [1]  [140/345]  eta: 0:00:51  lr: 0.000009  loss: 1.4378 (1.4702)  time: 0.2494  data: 0.0001  max mem: 10917
[11:53:08.015725] Epoch: [1]  [160/345]  eta: 0:00:46  lr: 0.000009  loss: 1.4295 (1.4651)  time: 0.2502  data: 0.0001  max mem: 10917
[11:53:13.028506] Epoch: [1]  [180/345]  eta: 0:00:41  lr: 0.000010  loss: 1.4227 (1.4604)  time: 0.2506  data: 0.0001  max mem: 10917
[11:53:18.045355] Epoch: [1]  [200/345]  eta: 0:00:36  lr: 0.000010  loss: 1.4116 (1.4556)  time: 0.2508  data: 0.0000  max mem: 10917
[11:53:23.063250] Epoch: [1]  [220/345]  eta: 0:00:31  lr: 0.000010  loss: 1.4049 (1.4510)  time: 0.2509  data: 0.0000  max mem: 10917
[11:53:28.084162] Epoch: [1]  [240/345]  eta: 0:00:26  lr: 0.000011  loss: 1.3984 (1.4467)  time: 0.2510  data: 0.0001  max mem: 10917
[11:53:33.105138] Epoch: [1]  [260/345]  eta: 0:00:21  lr: 0.000011  loss: 1.3905 (1.4424)  time: 0.2510  data: 0.0000  max mem: 10917
[11:53:38.125747] Epoch: [1]  [280/345]  eta: 0:00:16  lr: 0.000011  loss: 1.3855 (1.4384)  time: 0.2510  data: 0.0001  max mem: 10917
[11:53:43.150997] Epoch: [1]  [300/345]  eta: 0:00:11  lr: 0.000012  loss: 1.3785 (1.4345)  time: 0.2512  data: 0.0000  max mem: 10917
[11:53:48.176163] Epoch: [1]  [320/345]  eta: 0:00:06  lr: 0.000012  loss: 1.3730 (1.4307)  time: 0.2512  data: 0.0000  max mem: 10917
[11:53:53.205064] Epoch: [1]  [340/345]  eta: 0:00:01  lr: 0.000012  loss: 1.3677 (1.4270)  time: 0.2514  data: 0.0000  max mem: 10917
[11:53:54.211740] Epoch: [1]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 1.3673 (1.4263)  time: 0.2515  data: 0.0001  max mem: 10917
[11:53:54.269833] Epoch: [1] Total time: 0:01:26 (0.2507 s / it)
[11:53:54.270117] Averaged stats: lr: 0.000012  loss: 1.3673 (1.4263)
[11:53:54.514860] Test:  [  0/345]  eta: 0:01:23  loss: 1.3687 (1.3687)  time: 0.2414  data: 0.1616  max mem: 10917
[11:53:55.377144] Test:  [ 10/345]  eta: 0:00:33  loss: 1.3653 (1.3652)  time: 0.1003  data: 0.0188  max mem: 10917
[11:53:56.200835] Test:  [ 20/345]  eta: 0:00:29  loss: 1.3652 (1.3654)  time: 0.0842  data: 0.0023  max mem: 10917
[11:53:57.028492] Test:  [ 30/345]  eta: 0:00:27  loss: 1.3652 (1.3652)  time: 0.0825  data: 0.0001  max mem: 10917
[11:53:57.860480] Test:  [ 40/345]  eta: 0:00:26  loss: 1.3648 (1.3651)  time: 0.0829  data: 0.0001  max mem: 10917
[11:53:58.694821] Test:  [ 50/345]  eta: 0:00:25  loss: 1.3648 (1.3649)  time: 0.0833  data: 0.0001  max mem: 10917
[11:53:59.532273] Test:  [ 60/345]  eta: 0:00:24  loss: 1.3645 (1.3649)  time: 0.0835  data: 0.0001  max mem: 10917
[11:54:00.373896] Test:  [ 70/345]  eta: 0:00:23  loss: 1.3645 (1.3649)  time: 0.0839  data: 0.0001  max mem: 10917
[11:54:01.219336] Test:  [ 80/345]  eta: 0:00:22  loss: 1.3641 (1.3647)  time: 0.0843  data: 0.0001  max mem: 10917
[11:54:02.068323] Test:  [ 90/345]  eta: 0:00:21  loss: 1.3639 (1.3648)  time: 0.0847  data: 0.0001  max mem: 10917
[11:54:02.921452] Test:  [100/345]  eta: 0:00:20  loss: 1.3647 (1.3648)  time: 0.0851  data: 0.0001  max mem: 10917
[11:54:03.777669] Test:  [110/345]  eta: 0:00:20  loss: 1.3640 (1.3648)  time: 0.0854  data: 0.0001  max mem: 10917
[11:54:04.636927] Test:  [120/345]  eta: 0:00:19  loss: 1.3640 (1.3648)  time: 0.0857  data: 0.0001  max mem: 10917
[11:54:05.500860] Test:  [130/345]  eta: 0:00:18  loss: 1.3647 (1.3648)  time: 0.0861  data: 0.0001  max mem: 10917
[11:54:06.366538] Test:  [140/345]  eta: 0:00:17  loss: 1.3648 (1.3648)  time: 0.0864  data: 0.0001  max mem: 10917
[11:54:07.236405] Test:  [150/345]  eta: 0:00:16  loss: 1.3648 (1.3648)  time: 0.0867  data: 0.0001  max mem: 10917
[11:54:08.109723] Test:  [160/345]  eta: 0:00:15  loss: 1.3650 (1.3648)  time: 0.0871  data: 0.0001  max mem: 10917
[11:54:08.987174] Test:  [170/345]  eta: 0:00:15  loss: 1.3644 (1.3647)  time: 0.0875  data: 0.0001  max mem: 10917
[11:54:09.867406] Test:  [180/345]  eta: 0:00:14  loss: 1.3636 (1.3646)  time: 0.0878  data: 0.0001  max mem: 10917
[11:54:10.751228] Test:  [190/345]  eta: 0:00:13  loss: 1.3638 (1.3646)  time: 0.0882  data: 0.0001  max mem: 10917
[11:54:11.639155] Test:  [200/345]  eta: 0:00:12  loss: 1.3652 (1.3647)  time: 0.0885  data: 0.0001  max mem: 10917
[11:54:12.530552] Test:  [210/345]  eta: 0:00:11  loss: 1.3656 (1.3647)  time: 0.0889  data: 0.0001  max mem: 10917
[11:54:13.424797] Test:  [220/345]  eta: 0:00:10  loss: 1.3653 (1.3647)  time: 0.0892  data: 0.0001  max mem: 10917
[11:54:14.322712] Test:  [230/345]  eta: 0:00:09  loss: 1.3647 (1.3647)  time: 0.0896  data: 0.0001  max mem: 10917
[11:54:15.224811] Test:  [240/345]  eta: 0:00:09  loss: 1.3646 (1.3647)  time: 0.0900  data: 0.0001  max mem: 10917
[11:54:16.131313] Test:  [250/345]  eta: 0:00:08  loss: 1.3650 (1.3647)  time: 0.0904  data: 0.0001  max mem: 10917
[11:54:17.040338] Test:  [260/345]  eta: 0:00:07  loss: 1.3652 (1.3647)  time: 0.0907  data: 0.0001  max mem: 10917
[11:54:17.951934] Test:  [270/345]  eta: 0:00:06  loss: 1.3648 (1.3647)  time: 0.0910  data: 0.0001  max mem: 10917
[11:54:18.867844] Test:  [280/345]  eta: 0:00:05  loss: 1.3643 (1.3647)  time: 0.0913  data: 0.0001  max mem: 10917
[11:54:19.786964] Test:  [290/345]  eta: 0:00:04  loss: 1.3647 (1.3647)  time: 0.0917  data: 0.0001  max mem: 10917
[11:54:20.709297] Test:  [300/345]  eta: 0:00:03  loss: 1.3646 (1.3647)  time: 0.0920  data: 0.0001  max mem: 10917
[11:54:21.634942] Test:  [310/345]  eta: 0:00:03  loss: 1.3640 (1.3647)  time: 0.0923  data: 0.0001  max mem: 10917
[11:54:22.564182] Test:  [320/345]  eta: 0:00:02  loss: 1.3634 (1.3647)  time: 0.0927  data: 0.0001  max mem: 10917
[11:54:23.496646] Test:  [330/345]  eta: 0:00:01  loss: 1.3638 (1.3647)  time: 0.0930  data: 0.0001  max mem: 10917
[11:54:24.432178] Test:  [340/345]  eta: 0:00:00  loss: 1.3640 (1.3646)  time: 0.0934  data: 0.0001  max mem: 10917
[11:54:24.807802] Test:  [344/345]  eta: 0:00:00  loss: 1.3640 (1.3646)  time: 0.0935  data: 0.0001  max mem: 10917
[11:54:24.864400] Test: Total time: 0:00:30 (0.0887 s / it)
[11:54:36.048728] Test:  [ 0/57]  eta: 0:00:12  loss: 1.3699 (1.3699)  time: 0.2238  data: 0.1435  max mem: 10917
[11:54:36.860632] Test:  [10/57]  eta: 0:00:04  loss: 1.3685 (1.3671)  time: 0.0941  data: 0.0131  max mem: 10917
[11:54:37.675588] Test:  [20/57]  eta: 0:00:03  loss: 1.3685 (1.3664)  time: 0.0813  data: 0.0001  max mem: 10917
[11:54:38.495020] Test:  [30/57]  eta: 0:00:02  loss: 1.3640 (1.3637)  time: 0.0817  data: 0.0001  max mem: 10917
[11:54:39.318100] Test:  [40/57]  eta: 0:00:01  loss: 1.3588 (1.3618)  time: 0.0821  data: 0.0001  max mem: 10917
[11:54:40.145068] Test:  [50/57]  eta: 0:00:00  loss: 1.3585 (1.3608)  time: 0.0825  data: 0.0001  max mem: 10917
[11:54:40.595152] Test:  [56/57]  eta: 0:00:00  loss: 1.3585 (1.3606)  time: 0.0802  data: 0.0001  max mem: 10917
[11:54:40.653449] Test: Total time: 0:00:04 (0.0847 s / it)
[11:54:42.560516] Dice score of the network on the train images: 0.000000, val images: 0.000000
[11:54:42.564388] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:54:42.961413] Epoch: [2]  [  0/345]  eta: 0:02:16  lr: 0.000013  loss: 1.3689 (1.3689)  time: 0.3959  data: 0.1452  max mem: 10917
[11:54:47.944499] Epoch: [2]  [ 20/345]  eta: 0:01:23  lr: 0.000013  loss: 1.3616 (1.3635)  time: 0.2491  data: 0.0001  max mem: 10917
[11:54:52.932445] Epoch: [2]  [ 40/345]  eta: 0:01:17  lr: 0.000013  loss: 1.3551 (1.3600)  time: 0.2493  data: 0.0001  max mem: 10917
[11:54:57.918467] Epoch: [2]  [ 60/345]  eta: 0:01:11  lr: 0.000014  loss: 1.3535 (1.3578)  time: 0.2493  data: 0.0000  max mem: 10917
[11:55:02.932829] Epoch: [2]  [ 80/345]  eta: 0:01:06  lr: 0.000014  loss: 1.3473 (1.3552)  time: 0.2507  data: 0.0001  max mem: 10917
[11:55:07.949133] Epoch: [2]  [100/345]  eta: 0:01:01  lr: 0.000014  loss: 1.3437 (1.3529)  time: 0.2508  data: 0.0001  max mem: 10917
[11:55:12.969249] Epoch: [2]  [120/345]  eta: 0:00:56  lr: 0.000015  loss: 1.3398 (1.3508)  time: 0.2510  data: 0.0000  max mem: 10917
[11:55:17.997663] Epoch: [2]  [140/345]  eta: 0:00:51  lr: 0.000015  loss: 1.3362 (1.3487)  time: 0.2514  data: 0.0001  max mem: 10917
[11:55:23.025832] Epoch: [2]  [160/345]  eta: 0:00:46  lr: 0.000015  loss: 1.3335 (1.3469)  time: 0.2514  data: 0.0001  max mem: 10917
[11:55:28.059149] Epoch: [2]  [180/345]  eta: 0:00:41  lr: 0.000016  loss: 1.3299 (1.3450)  time: 0.2516  data: 0.0000  max mem: 10917
[11:55:33.092871] Epoch: [2]  [200/345]  eta: 0:00:36  lr: 0.000016  loss: 1.3257 (1.3431)  time: 0.2516  data: 0.0000  max mem: 10917
[11:55:38.131848] Epoch: [2]  [220/345]  eta: 0:00:31  lr: 0.000016  loss: 1.3236 (1.3414)  time: 0.2519  data: 0.0000  max mem: 10917
[11:55:43.172553] Epoch: [2]  [240/345]  eta: 0:00:26  lr: 0.000017  loss: 1.3210 (1.3397)  time: 0.2520  data: 0.0000  max mem: 10917
[11:55:48.213034] Epoch: [2]  [260/345]  eta: 0:00:21  lr: 0.000017  loss: 1.3170 (1.3380)  time: 0.2520  data: 0.0001  max mem: 10917
[11:55:53.259451] Epoch: [2]  [280/345]  eta: 0:00:16  lr: 0.000018  loss: 1.3160 (1.3364)  time: 0.2523  data: 0.0000  max mem: 10917
[11:55:58.307477] Epoch: [2]  [300/345]  eta: 0:00:11  lr: 0.000018  loss: 1.3120 (1.3348)  time: 0.2524  data: 0.0001  max mem: 10917
[11:56:03.351930] Epoch: [2]  [320/345]  eta: 0:00:06  lr: 0.000018  loss: 1.3092 (1.3332)  time: 0.2522  data: 0.0000  max mem: 10917
[11:56:08.394677] Epoch: [2]  [340/345]  eta: 0:00:01  lr: 0.000019  loss: 1.3071 (1.3317)  time: 0.2521  data: 0.0000  max mem: 10917
[11:56:09.404015] Epoch: [2]  [344/345]  eta: 0:00:00  lr: 0.000019  loss: 1.3062 (1.3314)  time: 0.2521  data: 0.0001  max mem: 10917
[11:56:09.461656] Epoch: [2] Total time: 0:01:26 (0.2519 s / it)
[11:56:09.462123] Averaged stats: lr: 0.000019  loss: 1.3062 (1.3314)
[11:56:09.697739] Test:  [  0/345]  eta: 0:01:19  loss: 1.3039 (1.3039)  time: 0.2318  data: 0.1517  max mem: 10917
[11:56:10.517737] Test:  [ 10/345]  eta: 0:00:32  loss: 1.3029 (1.3018)  time: 0.0955  data: 0.0138  max mem: 10917
[11:56:11.340257] Test:  [ 20/345]  eta: 0:00:28  loss: 1.3012 (1.3006)  time: 0.0821  data: 0.0001  max mem: 10917
[11:56:12.166604] Test:  [ 30/345]  eta: 0:00:27  loss: 1.2996 (1.3005)  time: 0.0824  data: 0.0001  max mem: 10917
[11:56:12.996918] Test:  [ 40/345]  eta: 0:00:26  loss: 1.2997 (1.3004)  time: 0.0828  data: 0.0001  max mem: 10917
[11:56:13.830597] Test:  [ 50/345]  eta: 0:00:25  loss: 1.2997 (1.3003)  time: 0.0831  data: 0.0001  max mem: 10917
[11:56:14.666341] Test:  [ 60/345]  eta: 0:00:24  loss: 1.3004 (1.3004)  time: 0.0834  data: 0.0001  max mem: 10917
[11:56:15.506580] Test:  [ 70/345]  eta: 0:00:23  loss: 1.2992 (1.3001)  time: 0.0837  data: 0.0001  max mem: 10917
[11:56:16.350734] Test:  [ 80/345]  eta: 0:00:22  loss: 1.2986 (1.3000)  time: 0.0842  data: 0.0001  max mem: 10917
[11:56:17.197802] Test:  [ 90/345]  eta: 0:00:21  loss: 1.2995 (1.3001)  time: 0.0845  data: 0.0001  max mem: 10917
[11:56:18.048017] Test:  [100/345]  eta: 0:00:20  loss: 1.2997 (1.3000)  time: 0.0848  data: 0.0001  max mem: 10917
[11:56:18.901611] Test:  [110/345]  eta: 0:00:19  loss: 1.2996 (1.3001)  time: 0.0851  data: 0.0001  max mem: 10917
[11:56:19.759606] Test:  [120/345]  eta: 0:00:19  loss: 1.3003 (1.3002)  time: 0.0855  data: 0.0001  max mem: 10917
[11:56:20.620589] Test:  [130/345]  eta: 0:00:18  loss: 1.3013 (1.3003)  time: 0.0859  data: 0.0001  max mem: 10917
[11:56:21.485841] Test:  [140/345]  eta: 0:00:17  loss: 1.3011 (1.3003)  time: 0.0863  data: 0.0001  max mem: 10917
[11:56:22.355094] Test:  [150/345]  eta: 0:00:16  loss: 1.3010 (1.3004)  time: 0.0867  data: 0.0001  max mem: 10917
[11:56:23.226756] Test:  [160/345]  eta: 0:00:15  loss: 1.3012 (1.3004)  time: 0.0870  data: 0.0001  max mem: 10917
[11:56:24.102193] Test:  [170/345]  eta: 0:00:14  loss: 1.3012 (1.3004)  time: 0.0873  data: 0.0001  max mem: 10917
[11:56:24.980848] Test:  [180/345]  eta: 0:00:14  loss: 1.3012 (1.3005)  time: 0.0876  data: 0.0001  max mem: 10917
[11:56:25.862891] Test:  [190/345]  eta: 0:00:13  loss: 1.3015 (1.3005)  time: 0.0880  data: 0.0001  max mem: 10917
[11:56:26.748235] Test:  [200/345]  eta: 0:00:12  loss: 1.3017 (1.3005)  time: 0.0883  data: 0.0001  max mem: 10917
[11:56:27.637355] Test:  [210/345]  eta: 0:00:11  loss: 1.3008 (1.3005)  time: 0.0887  data: 0.0001  max mem: 10917
[11:56:28.529292] Test:  [220/345]  eta: 0:00:10  loss: 1.3008 (1.3006)  time: 0.0890  data: 0.0001  max mem: 10917
[11:56:29.425015] Test:  [230/345]  eta: 0:00:09  loss: 1.3019 (1.3006)  time: 0.0893  data: 0.0001  max mem: 10917
[11:56:30.324694] Test:  [240/345]  eta: 0:00:09  loss: 1.3010 (1.3007)  time: 0.0897  data: 0.0001  max mem: 10917
[11:56:31.227675] Test:  [250/345]  eta: 0:00:08  loss: 1.3005 (1.3007)  time: 0.0901  data: 0.0001  max mem: 10917
[11:56:32.133669] Test:  [260/345]  eta: 0:00:07  loss: 1.2996 (1.3006)  time: 0.0904  data: 0.0001  max mem: 10917
[11:56:33.044173] Test:  [270/345]  eta: 0:00:06  loss: 1.2995 (1.3006)  time: 0.0908  data: 0.0001  max mem: 10917
[11:56:33.957427] Test:  [280/345]  eta: 0:00:05  loss: 1.3012 (1.3007)  time: 0.0911  data: 0.0001  max mem: 10917
[11:56:34.874601] Test:  [290/345]  eta: 0:00:04  loss: 1.3003 (1.3006)  time: 0.0915  data: 0.0001  max mem: 10917
[11:56:35.795543] Test:  [300/345]  eta: 0:00:03  loss: 1.2998 (1.3006)  time: 0.0919  data: 0.0001  max mem: 10917
[11:56:36.719898] Test:  [310/345]  eta: 0:00:03  loss: 1.2998 (1.3006)  time: 0.0922  data: 0.0001  max mem: 10917
[11:56:37.647277] Test:  [320/345]  eta: 0:00:02  loss: 1.3015 (1.3006)  time: 0.0925  data: 0.0001  max mem: 10917
[11:56:38.578732] Test:  [330/345]  eta: 0:00:01  loss: 1.3011 (1.3007)  time: 0.0929  data: 0.0001  max mem: 10917
[11:56:39.513079] Test:  [340/345]  eta: 0:00:00  loss: 1.3010 (1.3007)  time: 0.0932  data: 0.0001  max mem: 10917
[11:56:39.888303] Test:  [344/345]  eta: 0:00:00  loss: 1.3006 (1.3007)  time: 0.0934  data: 0.0001  max mem: 10917
[11:56:39.946493] Test: Total time: 0:00:30 (0.0884 s / it)
[11:56:51.154968] Test:  [ 0/57]  eta: 0:00:12  loss: 1.3069 (1.3069)  time: 0.2256  data: 0.1459  max mem: 10917
[11:56:51.967428] Test:  [10/57]  eta: 0:00:04  loss: 1.3044 (1.3037)  time: 0.0943  data: 0.0133  max mem: 10917
[11:56:52.784188] Test:  [20/57]  eta: 0:00:03  loss: 1.3048 (1.3035)  time: 0.0814  data: 0.0001  max mem: 10917
[11:56:53.604662] Test:  [30/57]  eta: 0:00:02  loss: 1.2963 (1.2995)  time: 0.0818  data: 0.0001  max mem: 10917
[11:56:54.428170] Test:  [40/57]  eta: 0:00:01  loss: 1.2907 (1.2969)  time: 0.0821  data: 0.0001  max mem: 10917
[11:56:55.255927] Test:  [50/57]  eta: 0:00:00  loss: 1.2901 (1.2957)  time: 0.0825  data: 0.0001  max mem: 10917
[11:56:55.705838] Test:  [56/57]  eta: 0:00:00  loss: 1.2933 (1.2955)  time: 0.0803  data: 0.0001  max mem: 10917
[11:56:55.759842] Test: Total time: 0:00:04 (0.0848 s / it)
[11:56:57.660342] Dice score of the network on the train images: 0.000000, val images: 0.000000
[11:56:57.664176] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:56:58.058341] Epoch: [3]  [  0/345]  eta: 0:02:15  lr: 0.000019  loss: 1.3071 (1.3071)  time: 0.3932  data: 0.1415  max mem: 10917
[11:57:03.057697] Epoch: [3]  [ 20/345]  eta: 0:01:23  lr: 0.000019  loss: 1.3039 (1.3047)  time: 0.2499  data: 0.0001  max mem: 10917
[11:57:08.057933] Epoch: [3]  [ 40/345]  eta: 0:01:17  lr: 0.000019  loss: 1.3022 (1.3035)  time: 0.2500  data: 0.0001  max mem: 10917
[11:57:13.058904] Epoch: [3]  [ 60/345]  eta: 0:01:11  lr: 0.000020  loss: 1.3002 (1.3024)  time: 0.2500  data: 0.0000  max mem: 10917
[11:57:18.060929] Epoch: [3]  [ 80/345]  eta: 0:01:06  lr: 0.000020  loss: 1.2985 (1.3011)  time: 0.2501  data: 0.0001  max mem: 10917
[11:57:23.069889] Epoch: [3]  [100/345]  eta: 0:01:01  lr: 0.000021  loss: 1.2964 (1.3002)  time: 0.2504  data: 0.0001  max mem: 10917
[11:57:28.084270] Epoch: [3]  [120/345]  eta: 0:00:56  lr: 0.000021  loss: 1.2953 (1.2993)  time: 0.2507  data: 0.0000  max mem: 10917
[11:57:33.099789] Epoch: [3]  [140/345]  eta: 0:00:51  lr: 0.000021  loss: 1.2902 (1.2980)  time: 0.2507  data: 0.0000  max mem: 10917
[11:57:38.119669] Epoch: [3]  [160/345]  eta: 0:00:46  lr: 0.000022  loss: 1.2891 (1.2970)  time: 0.2509  data: 0.0001  max mem: 10917
[11:57:43.141468] Epoch: [3]  [180/345]  eta: 0:00:41  lr: 0.000022  loss: 1.2877 (1.2960)  time: 0.2510  data: 0.0001  max mem: 10917
[11:57:48.167561] Epoch: [3]  [200/345]  eta: 0:00:36  lr: 0.000022  loss: 1.2856 (1.2950)  time: 0.2513  data: 0.0000  max mem: 10917
[11:57:53.194639] Epoch: [3]  [220/345]  eta: 0:00:31  lr: 0.000023  loss: 1.2823 (1.2939)  time: 0.2513  data: 0.0000  max mem: 10917
[11:57:58.223411] Epoch: [3]  [240/345]  eta: 0:00:26  lr: 0.000023  loss: 1.2810 (1.2928)  time: 0.2514  data: 0.0000  max mem: 10917
[11:58:03.255641] Epoch: [3]  [260/345]  eta: 0:00:21  lr: 0.000023  loss: 1.2747 (1.2915)  time: 0.2516  data: 0.0001  max mem: 10917
[11:58:08.289981] Epoch: [3]  [280/345]  eta: 0:00:16  lr: 0.000024  loss: 1.2729 (1.2902)  time: 0.2517  data: 0.0000  max mem: 10917
[11:58:13.329719] Epoch: [3]  [300/345]  eta: 0:00:11  lr: 0.000024  loss: 1.2640 (1.2886)  time: 0.2519  data: 0.0000  max mem: 10917
[11:58:18.367748] Epoch: [3]  [320/345]  eta: 0:00:06  lr: 0.000025  loss: 1.2621 (1.2869)  time: 0.2519  data: 0.0000  max mem: 10917
[11:58:23.406349] Epoch: [3]  [340/345]  eta: 0:00:01  lr: 0.000025  loss: 1.2587 (1.2852)  time: 0.2519  data: 0.0000  max mem: 10917
[11:58:24.415278] Epoch: [3]  [344/345]  eta: 0:00:00  lr: 0.000025  loss: 1.2556 (1.2849)  time: 0.2519  data: 0.0001  max mem: 10917
[11:58:24.473648] Epoch: [3] Total time: 0:01:26 (0.2516 s / it)
[11:58:24.473967] Averaged stats: lr: 0.000025  loss: 1.2556 (1.2849)
[11:58:24.715713] Test:  [  0/345]  eta: 0:01:22  loss: 1.2440 (1.2440)  time: 0.2379  data: 0.1576  max mem: 10917
[11:58:25.537769] Test:  [ 10/345]  eta: 0:00:32  loss: 1.2384 (1.2378)  time: 0.0963  data: 0.0145  max mem: 10917
[11:58:26.361294] Test:  [ 20/345]  eta: 0:00:29  loss: 1.2384 (1.2405)  time: 0.0822  data: 0.0001  max mem: 10917
[11:58:27.188808] Test:  [ 30/345]  eta: 0:00:27  loss: 1.2444 (1.2406)  time: 0.0825  data: 0.0001  max mem: 10917
[11:58:28.018943] Test:  [ 40/345]  eta: 0:00:26  loss: 1.2366 (1.2398)  time: 0.0828  data: 0.0001  max mem: 10917
[11:58:28.853066] Test:  [ 50/345]  eta: 0:00:25  loss: 1.2382 (1.2406)  time: 0.0832  data: 0.0001  max mem: 10917
[11:58:29.690684] Test:  [ 60/345]  eta: 0:00:24  loss: 1.2462 (1.2417)  time: 0.0835  data: 0.0001  max mem: 10917
[11:58:30.531778] Test:  [ 70/345]  eta: 0:00:23  loss: 1.2446 (1.2418)  time: 0.0839  data: 0.0001  max mem: 10917
[11:58:31.376414] Test:  [ 80/345]  eta: 0:00:22  loss: 1.2416 (1.2415)  time: 0.0842  data: 0.0001  max mem: 10917
[11:58:32.224942] Test:  [ 90/345]  eta: 0:00:21  loss: 1.2387 (1.2411)  time: 0.0846  data: 0.0001  max mem: 10917
[11:58:33.076444] Test:  [100/345]  eta: 0:00:20  loss: 1.2416 (1.2415)  time: 0.0849  data: 0.0001  max mem: 10917
[11:58:33.931514] Test:  [110/345]  eta: 0:00:20  loss: 1.2438 (1.2418)  time: 0.0853  data: 0.0001  max mem: 10917
[11:58:34.790477] Test:  [120/345]  eta: 0:00:19  loss: 1.2392 (1.2415)  time: 0.0857  data: 0.0001  max mem: 10917
[11:58:35.652737] Test:  [130/345]  eta: 0:00:18  loss: 1.2383 (1.2413)  time: 0.0860  data: 0.0001  max mem: 10917
[11:58:36.518335] Test:  [140/345]  eta: 0:00:17  loss: 1.2417 (1.2413)  time: 0.0863  data: 0.0001  max mem: 10917
[11:58:37.388921] Test:  [150/345]  eta: 0:00:16  loss: 1.2407 (1.2413)  time: 0.0868  data: 0.0001  max mem: 10917
[11:58:38.261138] Test:  [160/345]  eta: 0:00:15  loss: 1.2386 (1.2412)  time: 0.0871  data: 0.0001  max mem: 10917
[11:58:39.137737] Test:  [170/345]  eta: 0:00:14  loss: 1.2377 (1.2410)  time: 0.0874  data: 0.0001  max mem: 10917
[11:58:40.017985] Test:  [180/345]  eta: 0:00:14  loss: 1.2377 (1.2409)  time: 0.0878  data: 0.0001  max mem: 10917
[11:58:40.902291] Test:  [190/345]  eta: 0:00:13  loss: 1.2374 (1.2408)  time: 0.0882  data: 0.0001  max mem: 10917
[11:58:41.789580] Test:  [200/345]  eta: 0:00:12  loss: 1.2376 (1.2407)  time: 0.0885  data: 0.0001  max mem: 10917
[11:58:42.679415] Test:  [210/345]  eta: 0:00:11  loss: 1.2390 (1.2408)  time: 0.0888  data: 0.0001  max mem: 10917
[11:58:43.572802] Test:  [220/345]  eta: 0:00:10  loss: 1.2398 (1.2407)  time: 0.0891  data: 0.0001  max mem: 10917
[11:58:44.470110] Test:  [230/345]  eta: 0:00:09  loss: 1.2355 (1.2406)  time: 0.0895  data: 0.0001  max mem: 10917
[11:58:45.370514] Test:  [240/345]  eta: 0:00:09  loss: 1.2389 (1.2406)  time: 0.0898  data: 0.0001  max mem: 10917
[11:58:46.274008] Test:  [250/345]  eta: 0:00:08  loss: 1.2403 (1.2408)  time: 0.0901  data: 0.0001  max mem: 10917
[11:58:47.181515] Test:  [260/345]  eta: 0:00:07  loss: 1.2429 (1.2407)  time: 0.0905  data: 0.0001  max mem: 10917
[11:58:48.092974] Test:  [270/345]  eta: 0:00:06  loss: 1.2439 (1.2408)  time: 0.0909  data: 0.0001  max mem: 10917
[11:58:49.007598] Test:  [280/345]  eta: 0:00:05  loss: 1.2448 (1.2409)  time: 0.0913  data: 0.0001  max mem: 10917
[11:58:49.925764] Test:  [290/345]  eta: 0:00:04  loss: 1.2377 (1.2408)  time: 0.0916  data: 0.0001  max mem: 10917
[11:58:50.847092] Test:  [300/345]  eta: 0:00:03  loss: 1.2378 (1.2408)  time: 0.0919  data: 0.0001  max mem: 10917
[11:58:51.773582] Test:  [310/345]  eta: 0:00:03  loss: 1.2392 (1.2408)  time: 0.0923  data: 0.0001  max mem: 10917
[11:58:52.702009] Test:  [320/345]  eta: 0:00:02  loss: 1.2418 (1.2408)  time: 0.0927  data: 0.0001  max mem: 10917
[11:58:53.634485] Test:  [330/345]  eta: 0:00:01  loss: 1.2429 (1.2409)  time: 0.0930  data: 0.0001  max mem: 10917
[11:58:54.570835] Test:  [340/345]  eta: 0:00:00  loss: 1.2414 (1.2408)  time: 0.0934  data: 0.0001  max mem: 10917
[11:58:54.946307] Test:  [344/345]  eta: 0:00:00  loss: 1.2382 (1.2408)  time: 0.0935  data: 0.0001  max mem: 10917
[11:58:55.003371] Test: Total time: 0:00:30 (0.0885 s / it)
[11:59:06.116818] Test:  [ 0/57]  eta: 0:00:12  loss: 1.2613 (1.2613)  time: 0.2240  data: 0.1443  max mem: 10917
[11:59:06.930024] Test:  [10/57]  eta: 0:00:04  loss: 1.2597 (1.2549)  time: 0.0942  data: 0.0132  max mem: 10917
[11:59:07.746996] Test:  [20/57]  eta: 0:00:03  loss: 1.2599 (1.2535)  time: 0.0814  data: 0.0001  max mem: 10917
[11:59:08.568836] Test:  [30/57]  eta: 0:00:02  loss: 1.2242 (1.2365)  time: 0.0819  data: 0.0001  max mem: 10917
[11:59:09.393366] Test:  [40/57]  eta: 0:00:01  loss: 1.1916 (1.2255)  time: 0.0823  data: 0.0001  max mem: 10917
[11:59:10.221559] Test:  [50/57]  eta: 0:00:00  loss: 1.2009 (1.2216)  time: 0.0826  data: 0.0001  max mem: 10917
[11:59:10.671459] Test:  [56/57]  eta: 0:00:00  loss: 1.2166 (1.2219)  time: 0.0804  data: 0.0001  max mem: 10917
[11:59:10.730853] Test: Total time: 0:00:04 (0.0849 s / it)
[11:59:12.662471] Dice score of the network on the train images: 0.113530, val images: 0.112544
[11:59:12.662709] saving best_prec_model_0 @ epoch 3
[11:59:13.347980] saving best_rec_model_0 @ epoch 3
[11:59:13.909247] saving best_dice_model_0 @ epoch 3
[11:59:14.791497] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:59:15.189745] Epoch: [4]  [  0/345]  eta: 0:02:17  lr: 0.000025  loss: 1.2608 (1.2608)  time: 0.3971  data: 0.1459  max mem: 10917
[11:59:20.186360] Epoch: [4]  [ 20/345]  eta: 0:01:23  lr: 0.000025  loss: 1.2530 (1.2518)  time: 0.2498  data: 0.0001  max mem: 10917
[11:59:25.182637] Epoch: [4]  [ 40/345]  eta: 0:01:17  lr: 0.000026  loss: 1.2373 (1.2448)  time: 0.2498  data: 0.0001  max mem: 10917
[11:59:30.172263] Epoch: [4]  [ 60/345]  eta: 0:01:11  lr: 0.000026  loss: 1.2332 (1.2418)  time: 0.2494  data: 0.0001  max mem: 10917
[11:59:35.166419] Epoch: [4]  [ 80/345]  eta: 0:01:06  lr: 0.000026  loss: 1.2295 (1.2384)  time: 0.2497  data: 0.0001  max mem: 10917
[11:59:40.162756] Epoch: [4]  [100/345]  eta: 0:01:01  lr: 0.000027  loss: 1.2181 (1.2342)  time: 0.2498  data: 0.0001  max mem: 10917
[11:59:45.180704] Epoch: [4]  [120/345]  eta: 0:00:56  lr: 0.000027  loss: 1.2097 (1.2300)  time: 0.2509  data: 0.0001  max mem: 10917
[11:59:50.190249] Epoch: [4]  [140/345]  eta: 0:00:51  lr: 0.000028  loss: 1.1992 (1.2262)  time: 0.2504  data: 0.0001  max mem: 10917
[11:59:55.199333] Epoch: [4]  [160/345]  eta: 0:00:46  lr: 0.000028  loss: 1.2001 (1.2227)  time: 0.2504  data: 0.0001  max mem: 10917
[12:00:00.218353] Epoch: [4]  [180/345]  eta: 0:00:41  lr: 0.000028  loss: 1.1942 (1.2194)  time: 0.2509  data: 0.0001  max mem: 10917
[12:00:05.252017] Epoch: [4]  [200/345]  eta: 0:00:36  lr: 0.000029  loss: 1.1852 (1.2159)  time: 0.2516  data: 0.0000  max mem: 10917
[12:00:10.286327] Epoch: [4]  [220/345]  eta: 0:00:31  lr: 0.000029  loss: 1.1761 (1.2124)  time: 0.2517  data: 0.0000  max mem: 10917
[12:00:15.310792] Epoch: [4]  [240/345]  eta: 0:00:26  lr: 0.000029  loss: 1.1759 (1.2096)  time: 0.2511  data: 0.0000  max mem: 10917
[12:00:20.338121] Epoch: [4]  [260/345]  eta: 0:00:21  lr: 0.000030  loss: 1.1679 (1.2064)  time: 0.2513  data: 0.0001  max mem: 10917
[12:00:25.365698] Epoch: [4]  [280/345]  eta: 0:00:16  lr: 0.000030  loss: 1.1555 (1.2031)  time: 0.2513  data: 0.0000  max mem: 10917
[12:00:30.393804] Epoch: [4]  [300/345]  eta: 0:00:11  lr: 0.000030  loss: 1.1572 (1.2000)  time: 0.2514  data: 0.0001  max mem: 10917
[12:00:35.424601] Epoch: [4]  [320/345]  eta: 0:00:06  lr: 0.000031  loss: 1.1413 (1.1967)  time: 0.2515  data: 0.0000  max mem: 10917
[12:00:40.456334] Epoch: [4]  [340/345]  eta: 0:00:01  lr: 0.000031  loss: 1.1321 (1.1932)  time: 0.2515  data: 0.0000  max mem: 10917
[12:00:41.462683] Epoch: [4]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 1.1321 (1.1924)  time: 0.2516  data: 0.0001  max mem: 10917
[12:00:41.521585] Epoch: [4] Total time: 0:01:26 (0.2514 s / it)
[12:00:41.522071] Averaged stats: lr: 0.000031  loss: 1.1321 (1.1924)
[12:00:41.764341] Test:  [  0/345]  eta: 0:01:22  loss: 1.1237 (1.1237)  time: 0.2394  data: 0.1592  max mem: 10917
[12:00:42.682802] Test:  [ 10/345]  eta: 0:00:35  loss: 1.1190 (1.1223)  time: 0.1052  data: 0.0238  max mem: 10917
[12:00:43.550497] Test:  [ 20/345]  eta: 0:00:31  loss: 1.1244 (1.1243)  time: 0.0892  data: 0.0074  max mem: 10917
[12:00:44.389500] Test:  [ 30/345]  eta: 0:00:29  loss: 1.1279 (1.1233)  time: 0.0853  data: 0.0029  max mem: 10917
[12:00:45.222500] Test:  [ 40/345]  eta: 0:00:27  loss: 1.1193 (1.1203)  time: 0.0836  data: 0.0006  max mem: 10917
[12:00:46.058354] Test:  [ 50/345]  eta: 0:00:26  loss: 1.1193 (1.1208)  time: 0.0834  data: 0.0001  max mem: 10917
[12:00:46.898191] Test:  [ 60/345]  eta: 0:00:25  loss: 1.1214 (1.1219)  time: 0.0837  data: 0.0001  max mem: 10917
[12:00:47.741729] Test:  [ 70/345]  eta: 0:00:24  loss: 1.1214 (1.1220)  time: 0.0841  data: 0.0001  max mem: 10917
[12:00:48.588127] Test:  [ 80/345]  eta: 0:00:23  loss: 1.1143 (1.1213)  time: 0.0844  data: 0.0001  max mem: 10917
[12:00:49.437488] Test:  [ 90/345]  eta: 0:00:22  loss: 1.1168 (1.1224)  time: 0.0847  data: 0.0001  max mem: 10917
[12:00:50.292007] Test:  [100/345]  eta: 0:00:21  loss: 1.1208 (1.1216)  time: 0.0851  data: 0.0001  max mem: 10917
[12:00:51.150054] Test:  [110/345]  eta: 0:00:20  loss: 1.1187 (1.1216)  time: 0.0856  data: 0.0001  max mem: 10917
[12:00:52.011035] Test:  [120/345]  eta: 0:00:19  loss: 1.1228 (1.1215)  time: 0.0859  data: 0.0001  max mem: 10917
[12:00:52.874974] Test:  [130/345]  eta: 0:00:18  loss: 1.1158 (1.1215)  time: 0.0862  data: 0.0001  max mem: 10917
[12:00:53.743703] Test:  [140/345]  eta: 0:00:17  loss: 1.1179 (1.1219)  time: 0.0866  data: 0.0001  max mem: 10917
[12:00:54.614763] Test:  [150/345]  eta: 0:00:16  loss: 1.1197 (1.1219)  time: 0.0869  data: 0.0001  max mem: 10917
[12:00:55.489977] Test:  [160/345]  eta: 0:00:16  loss: 1.1179 (1.1215)  time: 0.0873  data: 0.0001  max mem: 10917
[12:00:56.368574] Test:  [170/345]  eta: 0:00:15  loss: 1.1179 (1.1216)  time: 0.0876  data: 0.0001  max mem: 10917
[12:00:57.250317] Test:  [180/345]  eta: 0:00:14  loss: 1.1223 (1.1217)  time: 0.0880  data: 0.0001  max mem: 10917
[12:00:58.135737] Test:  [190/345]  eta: 0:00:13  loss: 1.1145 (1.1212)  time: 0.0883  data: 0.0001  max mem: 10917
[12:00:59.024241] Test:  [200/345]  eta: 0:00:12  loss: 1.1190 (1.1213)  time: 0.0886  data: 0.0001  max mem: 10917
[12:00:59.916753] Test:  [210/345]  eta: 0:00:11  loss: 1.1230 (1.1216)  time: 0.0890  data: 0.0001  max mem: 10917
[12:01:00.813060] Test:  [220/345]  eta: 0:00:10  loss: 1.1231 (1.1216)  time: 0.0894  data: 0.0001  max mem: 10917
[12:01:01.713109] Test:  [230/345]  eta: 0:00:10  loss: 1.1231 (1.1217)  time: 0.0898  data: 0.0001  max mem: 10917
[12:01:02.616276] Test:  [240/345]  eta: 0:00:09  loss: 1.1180 (1.1217)  time: 0.0901  data: 0.0001  max mem: 10917
[12:01:03.522537] Test:  [250/345]  eta: 0:00:08  loss: 1.1308 (1.1222)  time: 0.0904  data: 0.0001  max mem: 10917
[12:01:04.432542] Test:  [260/345]  eta: 0:00:07  loss: 1.1308 (1.1222)  time: 0.0908  data: 0.0001  max mem: 10917
[12:01:05.345797] Test:  [270/345]  eta: 0:00:06  loss: 1.1192 (1.1220)  time: 0.0911  data: 0.0001  max mem: 10917
[12:01:06.262541] Test:  [280/345]  eta: 0:00:05  loss: 1.1192 (1.1218)  time: 0.0915  data: 0.0001  max mem: 10917
[12:01:07.183681] Test:  [290/345]  eta: 0:00:04  loss: 1.1223 (1.1217)  time: 0.0918  data: 0.0001  max mem: 10917
[12:01:08.107792] Test:  [300/345]  eta: 0:00:03  loss: 1.1303 (1.1218)  time: 0.0922  data: 0.0001  max mem: 10917
[12:01:09.035057] Test:  [310/345]  eta: 0:00:03  loss: 1.1322 (1.1220)  time: 0.0925  data: 0.0001  max mem: 10917
[12:01:09.966115] Test:  [320/345]  eta: 0:00:02  loss: 1.1237 (1.1218)  time: 0.0929  data: 0.0001  max mem: 10917
[12:01:10.899736] Test:  [330/345]  eta: 0:00:01  loss: 1.1204 (1.1219)  time: 0.0932  data: 0.0001  max mem: 10917
[12:01:11.836576] Test:  [340/345]  eta: 0:00:00  loss: 1.1195 (1.1219)  time: 0.0935  data: 0.0001  max mem: 10917
[12:01:12.213073] Test:  [344/345]  eta: 0:00:00  loss: 1.1127 (1.1219)  time: 0.0937  data: 0.0001  max mem: 10917
[12:01:12.271113] Test: Total time: 0:00:30 (0.0891 s / it)
[12:01:23.268987] Test:  [ 0/57]  eta: 0:00:13  loss: 1.1867 (1.1867)  time: 0.2305  data: 0.1505  max mem: 10917
[12:01:24.089821] Test:  [10/57]  eta: 0:00:04  loss: 1.1844 (1.1617)  time: 0.0955  data: 0.0144  max mem: 10917
[12:01:24.906908] Test:  [20/57]  eta: 0:00:03  loss: 1.1787 (1.1602)  time: 0.0818  data: 0.0004  max mem: 10917
[12:01:25.728270] Test:  [30/57]  eta: 0:00:02  loss: 1.1010 (1.1213)  time: 0.0819  data: 0.0001  max mem: 10917
[12:01:26.552867] Test:  [40/57]  eta: 0:00:01  loss: 1.0152 (1.0960)  time: 0.0822  data: 0.0001  max mem: 10917
[12:01:27.381844] Test:  [50/57]  eta: 0:00:00  loss: 1.0272 (1.0873)  time: 0.0826  data: 0.0001  max mem: 10917
[12:01:27.831624] Test:  [56/57]  eta: 0:00:00  loss: 1.0605 (1.0899)  time: 0.0804  data: 0.0001  max mem: 10917
[12:01:27.889487] Test: Total time: 0:00:04 (0.0851 s / it)
[12:01:29.750678] Dice score of the network on the train images: 0.618188, val images: 0.679115
[12:01:29.750915] saving best_rec_model_0 @ epoch 4
[12:01:30.595281] saving best_dice_model_0 @ epoch 4
[12:01:31.444471] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:01:31.849069] Epoch: [5]  [  0/345]  eta: 0:02:19  lr: 0.000031  loss: 1.1239 (1.1239)  time: 0.4034  data: 0.1523  max mem: 10917
[12:01:36.847479] Epoch: [5]  [ 20/345]  eta: 0:01:23  lr: 0.000032  loss: 1.1284 (1.1335)  time: 0.2499  data: 0.0001  max mem: 10917
[12:01:41.852718] Epoch: [5]  [ 40/345]  eta: 0:01:17  lr: 0.000032  loss: 1.1289 (1.1291)  time: 0.2502  data: 0.0001  max mem: 10917
[12:01:46.855365] Epoch: [5]  [ 60/345]  eta: 0:01:11  lr: 0.000032  loss: 1.1182 (1.1262)  time: 0.2501  data: 0.0000  max mem: 10917
[12:01:51.863742] Epoch: [5]  [ 80/345]  eta: 0:01:06  lr: 0.000033  loss: 1.1181 (1.1239)  time: 0.2504  data: 0.0001  max mem: 10917
[12:01:56.869900] Epoch: [5]  [100/345]  eta: 0:01:01  lr: 0.000033  loss: 1.0946 (1.1183)  time: 0.2503  data: 0.0001  max mem: 10917
[12:02:01.870405] Epoch: [5]  [120/345]  eta: 0:00:56  lr: 0.000033  loss: 1.1091 (1.1159)  time: 0.2500  data: 0.0001  max mem: 10917
[12:02:06.881112] Epoch: [5]  [140/345]  eta: 0:00:51  lr: 0.000034  loss: 1.0902 (1.1130)  time: 0.2505  data: 0.0001  max mem: 10917
[12:02:11.883015] Epoch: [5]  [160/345]  eta: 0:00:46  lr: 0.000034  loss: 1.0966 (1.1112)  time: 0.2501  data: 0.0001  max mem: 10917
[12:02:16.895877] Epoch: [5]  [180/345]  eta: 0:00:41  lr: 0.000035  loss: 1.0752 (1.1073)  time: 0.2506  data: 0.0001  max mem: 10917
[12:02:21.911106] Epoch: [5]  [200/345]  eta: 0:00:36  lr: 0.000035  loss: 1.0717 (1.1040)  time: 0.2507  data: 0.0000  max mem: 10917
[12:02:26.930143] Epoch: [5]  [220/345]  eta: 0:00:31  lr: 0.000035  loss: 1.0843 (1.1018)  time: 0.2509  data: 0.0001  max mem: 10917
[12:02:31.951364] Epoch: [5]  [240/345]  eta: 0:00:26  lr: 0.000036  loss: 1.0585 (1.0986)  time: 0.2510  data: 0.0001  max mem: 10917
[12:02:36.977395] Epoch: [5]  [260/345]  eta: 0:00:21  lr: 0.000036  loss: 1.0511 (1.0948)  time: 0.2513  data: 0.0001  max mem: 10917
[12:02:42.007928] Epoch: [5]  [280/345]  eta: 0:00:16  lr: 0.000036  loss: 1.0352 (1.0904)  time: 0.2515  data: 0.0001  max mem: 10917
[12:02:47.041787] Epoch: [5]  [300/345]  eta: 0:00:11  lr: 0.000037  loss: 1.0286 (1.0867)  time: 0.2516  data: 0.0001  max mem: 10917
[12:02:52.077410] Epoch: [5]  [320/345]  eta: 0:00:06  lr: 0.000037  loss: 1.0290 (1.0832)  time: 0.2517  data: 0.0001  max mem: 10917
[12:02:57.109892] Epoch: [5]  [340/345]  eta: 0:00:01  lr: 0.000037  loss: 1.0267 (1.0800)  time: 0.2516  data: 0.0001  max mem: 10917
[12:02:58.117578] Epoch: [5]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 1.0278 (1.0794)  time: 0.2517  data: 0.0001  max mem: 10917
[12:02:58.175046] Epoch: [5] Total time: 0:01:26 (0.2514 s / it)
[12:02:58.175489] Averaged stats: lr: 0.000037  loss: 1.0278 (1.0794)
[12:02:58.413195] Test:  [  0/345]  eta: 0:01:21  loss: 1.0189 (1.0189)  time: 0.2349  data: 0.1550  max mem: 10917
[12:02:59.235348] Test:  [ 10/345]  eta: 0:00:32  loss: 1.0087 (1.0110)  time: 0.0960  data: 0.0141  max mem: 10917
[12:03:00.060240] Test:  [ 20/345]  eta: 0:00:29  loss: 1.0137 (1.0154)  time: 0.0823  data: 0.0001  max mem: 10917
[12:03:00.888911] Test:  [ 30/345]  eta: 0:00:27  loss: 1.0137 (1.0163)  time: 0.0826  data: 0.0001  max mem: 10917
[12:03:01.722608] Test:  [ 40/345]  eta: 0:00:26  loss: 1.0063 (1.0137)  time: 0.0831  data: 0.0001  max mem: 10917
[12:03:02.559781] Test:  [ 50/345]  eta: 0:00:25  loss: 1.0123 (1.0158)  time: 0.0835  data: 0.0001  max mem: 10917
[12:03:03.398809] Test:  [ 60/345]  eta: 0:00:24  loss: 1.0259 (1.0146)  time: 0.0838  data: 0.0001  max mem: 10917
[12:03:04.242381] Test:  [ 70/345]  eta: 0:00:23  loss: 1.0163 (1.0140)  time: 0.0841  data: 0.0001  max mem: 10917
[12:03:05.088720] Test:  [ 80/345]  eta: 0:00:22  loss: 1.0071 (1.0132)  time: 0.0844  data: 0.0001  max mem: 10917
[12:03:05.938939] Test:  [ 90/345]  eta: 0:00:21  loss: 1.0142 (1.0131)  time: 0.0848  data: 0.0001  max mem: 10917
[12:03:06.792478] Test:  [100/345]  eta: 0:00:20  loss: 1.0142 (1.0135)  time: 0.0851  data: 0.0001  max mem: 10917
[12:03:07.649532] Test:  [110/345]  eta: 0:00:20  loss: 1.0090 (1.0137)  time: 0.0855  data: 0.0001  max mem: 10917
[12:03:08.511088] Test:  [120/345]  eta: 0:00:19  loss: 1.0096 (1.0134)  time: 0.0859  data: 0.0001  max mem: 10917
[12:03:09.375567] Test:  [130/345]  eta: 0:00:18  loss: 1.0056 (1.0119)  time: 0.0863  data: 0.0001  max mem: 10917
[12:03:10.244195] Test:  [140/345]  eta: 0:00:17  loss: 0.9932 (1.0101)  time: 0.0866  data: 0.0001  max mem: 10917
[12:03:11.115550] Test:  [150/345]  eta: 0:00:16  loss: 1.0065 (1.0110)  time: 0.0870  data: 0.0001  max mem: 10917
[12:03:11.989850] Test:  [160/345]  eta: 0:00:15  loss: 1.0079 (1.0108)  time: 0.0872  data: 0.0001  max mem: 10917
[12:03:12.868069] Test:  [170/345]  eta: 0:00:15  loss: 1.0018 (1.0104)  time: 0.0876  data: 0.0001  max mem: 10917
[12:03:13.749279] Test:  [180/345]  eta: 0:00:14  loss: 1.0035 (1.0107)  time: 0.0879  data: 0.0001  max mem: 10917
[12:03:14.634442] Test:  [190/345]  eta: 0:00:13  loss: 1.0038 (1.0104)  time: 0.0883  data: 0.0001  max mem: 10917
[12:03:15.523406] Test:  [200/345]  eta: 0:00:12  loss: 1.0066 (1.0103)  time: 0.0887  data: 0.0001  max mem: 10917
[12:03:16.415528] Test:  [210/345]  eta: 0:00:11  loss: 1.0066 (1.0100)  time: 0.0890  data: 0.0001  max mem: 10917
[12:03:17.311568] Test:  [220/345]  eta: 0:00:10  loss: 1.0046 (1.0100)  time: 0.0894  data: 0.0001  max mem: 10917
[12:03:18.210362] Test:  [230/345]  eta: 0:00:09  loss: 1.0039 (1.0094)  time: 0.0897  data: 0.0001  max mem: 10917
[12:03:19.112534] Test:  [240/345]  eta: 0:00:09  loss: 1.0072 (1.0095)  time: 0.0900  data: 0.0001  max mem: 10917
[12:03:20.018533] Test:  [250/345]  eta: 0:00:08  loss: 1.0110 (1.0099)  time: 0.0904  data: 0.0001  max mem: 10917
[12:03:20.928379] Test:  [260/345]  eta: 0:00:07  loss: 0.9992 (1.0093)  time: 0.0907  data: 0.0001  max mem: 10917
[12:03:21.841450] Test:  [270/345]  eta: 0:00:06  loss: 1.0042 (1.0095)  time: 0.0911  data: 0.0001  max mem: 10917
[12:03:22.757800] Test:  [280/345]  eta: 0:00:05  loss: 1.0147 (1.0098)  time: 0.0914  data: 0.0001  max mem: 10917
[12:03:23.678850] Test:  [290/345]  eta: 0:00:04  loss: 1.0175 (1.0094)  time: 0.0918  data: 0.0001  max mem: 10917
[12:03:24.602430] Test:  [300/345]  eta: 0:00:03  loss: 0.9888 (1.0087)  time: 0.0922  data: 0.0001  max mem: 10917
[12:03:25.528376] Test:  [310/345]  eta: 0:00:03  loss: 1.0023 (1.0089)  time: 0.0924  data: 0.0001  max mem: 10917
[12:03:26.459207] Test:  [320/345]  eta: 0:00:02  loss: 1.0096 (1.0084)  time: 0.0928  data: 0.0001  max mem: 10917
[12:03:27.393130] Test:  [330/345]  eta: 0:00:01  loss: 0.9976 (1.0084)  time: 0.0932  data: 0.0001  max mem: 10917
[12:03:28.329850] Test:  [340/345]  eta: 0:00:00  loss: 1.0120 (1.0085)  time: 0.0935  data: 0.0001  max mem: 10917
[12:03:28.706232] Test:  [344/345]  eta: 0:00:00  loss: 1.0113 (1.0084)  time: 0.0937  data: 0.0001  max mem: 10917
[12:03:28.765081] Test: Total time: 0:00:30 (0.0887 s / it)
[12:03:39.711270] Test:  [ 0/57]  eta: 0:00:12  loss: 1.0775 (1.0775)  time: 0.2249  data: 0.1450  max mem: 10917
[12:03:40.524894] Test:  [10/57]  eta: 0:00:04  loss: 1.0706 (1.0521)  time: 0.0943  data: 0.0132  max mem: 10917
[12:03:41.341959] Test:  [20/57]  eta: 0:00:03  loss: 1.0557 (1.0514)  time: 0.0815  data: 0.0001  max mem: 10917
[12:03:42.162464] Test:  [30/57]  eta: 0:00:02  loss: 0.9926 (1.0073)  time: 0.0818  data: 0.0001  max mem: 10917
[12:03:42.986780] Test:  [40/57]  eta: 0:00:01  loss: 0.8951 (0.9792)  time: 0.0822  data: 0.0001  max mem: 10917
[12:03:43.814616] Test:  [50/57]  eta: 0:00:00  loss: 0.9140 (0.9690)  time: 0.0826  data: 0.0001  max mem: 10917
[12:03:44.264820] Test:  [56/57]  eta: 0:00:00  loss: 0.9332 (0.9716)  time: 0.0804  data: 0.0001  max mem: 10917
[12:03:44.323410] Test: Total time: 0:00:04 (0.0849 s / it)
[12:03:46.185707] Dice score of the network on the train images: 0.663798, val images: 0.733101
[12:03:46.185950] saving best_rec_model_0 @ epoch 5
[12:03:47.148327] saving best_dice_model_0 @ epoch 5
[12:03:47.972087] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:03:48.372150] Epoch: [6]  [  0/345]  eta: 0:02:17  lr: 0.000038  loss: 1.0134 (1.0134)  time: 0.3989  data: 0.1462  max mem: 10917
[12:03:53.376710] Epoch: [6]  [ 20/345]  eta: 0:01:23  lr: 0.000038  loss: 1.0198 (1.0164)  time: 0.2502  data: 0.0001  max mem: 10917
[12:03:58.374803] Epoch: [6]  [ 40/345]  eta: 0:01:17  lr: 0.000038  loss: 1.0111 (1.0140)  time: 0.2499  data: 0.0001  max mem: 10917
[12:04:03.377725] Epoch: [6]  [ 60/345]  eta: 0:01:11  lr: 0.000039  loss: 1.0026 (1.0128)  time: 0.2501  data: 0.0000  max mem: 10917
[12:04:08.389541] Epoch: [6]  [ 80/345]  eta: 0:01:06  lr: 0.000039  loss: 0.9907 (1.0076)  time: 0.2505  data: 0.0000  max mem: 10917

[12:04:13.407175] Epoch: [6]  [100/345]  eta: 0:01:01  lr: 0.000039  loss: 0.9885 (1.0042)  time: 0.2508  data: 0.0001  max mem: 10917
[12:04:18.427922] Epoch: [6]  [120/345]  eta: 0:00:56  lr: 0.000040  loss: 0.9820 (1.0016)  time: 0.2510  data: 0.0000  max mem: 10917

[12:04:23.447283] Epoch: [6]  [140/345]  eta: 0:00:51  lr: 0.000040  loss: 0.9794 (0.9987)  time: 0.2509  data: 0.0000  max mem: 10917
[12:04:28.469701] Epoch: [6]  [160/345]  eta: 0:00:46  lr: 0.000040  loss: 0.9766 (0.9966)  time: 0.2511  data: 0.0000  max mem: 10917
[12:04:33.501957] Epoch: [6]  [180/345]  eta: 0:00:41  lr: 0.000041  loss: 0.9711 (0.9944)  time: 0.2516  data: 0.0000  max mem: 10917
[12:04:38.528817] Epoch: [6]  [200/345]  eta: 0:00:36  lr: 0.000041  loss: 0.9597 (0.9913)  time: 0.2513  data: 0.0000  max mem: 10917
[12:04:43.562464] Epoch: [6]  [220/345]  eta: 0:00:31  lr: 0.000041  loss: 0.9578 (0.9887)  time: 0.2516  data: 0.0000  max mem: 10917
[12:04:48.599265] Epoch: [6]  [240/345]  eta: 0:00:26  lr: 0.000042  loss: 0.9441 (0.9851)  time: 0.2518  data: 0.0000  max mem: 10917
[12:04:53.638708] Epoch: [6]  [260/345]  eta: 0:00:21  lr: 0.000042  loss: 0.9586 (0.9829)  time: 0.2519  data: 0.0000  max mem: 10917
[12:04:58.683551] Epoch: [6]  [280/345]  eta: 0:00:16  lr: 0.000043  loss: 0.9468 (0.9804)  time: 0.2522  data: 0.0001  max mem: 10917
[12:05:03.736514] Epoch: [6]  [300/345]  eta: 0:00:11  lr: 0.000043  loss: 0.9477 (0.9781)  time: 0.2526  data: 0.0001  max mem: 10917
[12:05:08.808517] Epoch: [6]  [320/345]  eta: 0:00:06  lr: 0.000043  loss: 0.9373 (0.9753)  time: 0.2536  data: 0.0001  max mem: 10917
[12:05:13.868832] Epoch: [6]  [340/345]  eta: 0:00:01  lr: 0.000044  loss: 0.9211 (0.9726)  time: 0.2530  data: 0.0001  max mem: 10917
[12:05:14.878631] Epoch: [6]  [344/345]  eta: 0:00:00  lr: 0.000044  loss: 0.9186 (0.9722)  time: 0.2528  data: 0.0001  max mem: 10917
[12:05:14.936864] Epoch: [6] Total time: 0:01:26 (0.2521 s / it)
[12:05:14.937320] Averaged stats: lr: 0.000044  loss: 0.9186 (0.9722)
[12:05:15.181158] Test:  [  0/345]  eta: 0:01:22  loss: 0.9173 (0.9173)  time: 0.2404  data: 0.1600  max mem: 10917
[12:05:16.003603] Test:  [ 10/345]  eta: 0:00:32  loss: 0.9091 (0.9087)  time: 0.0966  data: 0.0146  max mem: 10917
[12:05:16.830217] Test:  [ 20/345]  eta: 0:00:29  loss: 0.9048 (0.9050)  time: 0.0824  data: 0.0001  max mem: 10917
[12:05:17.660071] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8983 (0.9048)  time: 0.0828  data: 0.0001  max mem: 10917
[12:05:18.493848] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8969 (0.9040)  time: 0.0831  data: 0.0001  max mem: 10917
[12:05:19.329782] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8969 (0.9062)  time: 0.0834  data: 0.0001  max mem: 10917
[12:05:20.170299] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8985 (0.9067)  time: 0.0838  data: 0.0001  max mem: 10917
[12:05:21.013282] Test:  [ 70/345]  eta: 0:00:23  loss: 0.9012 (0.9057)  time: 0.0841  data: 0.0001  max mem: 10917
[12:05:21.859951] Test:  [ 80/345]  eta: 0:00:22  loss: 0.9041 (0.9060)  time: 0.0844  data: 0.0001  max mem: 10917
[12:05:22.711232] Test:  [ 90/345]  eta: 0:00:21  loss: 0.9148 (0.9085)  time: 0.0848  data: 0.0001  max mem: 10917
[12:05:23.564188] Test:  [100/345]  eta: 0:00:20  loss: 0.9148 (0.9085)  time: 0.0852  data: 0.0001  max mem: 10917
[12:05:24.422143] Test:  [110/345]  eta: 0:00:20  loss: 0.9059 (0.9084)  time: 0.0855  data: 0.0001  max mem: 10917
[12:05:25.282952] Test:  [120/345]  eta: 0:00:19  loss: 0.9090 (0.9087)  time: 0.0859  data: 0.0001  max mem: 10917
[12:05:26.147231] Test:  [130/345]  eta: 0:00:18  loss: 0.9068 (0.9088)  time: 0.0862  data: 0.0001  max mem: 10917
[12:05:27.016249] Test:  [140/345]  eta: 0:00:17  loss: 0.9033 (0.9078)  time: 0.0866  data: 0.0001  max mem: 10917
[12:05:27.886975] Test:  [150/345]  eta: 0:00:16  loss: 0.9134 (0.9096)  time: 0.0869  data: 0.0001  max mem: 10917
[12:05:28.761696] Test:  [160/345]  eta: 0:00:15  loss: 0.9164 (0.9093)  time: 0.0872  data: 0.0001  max mem: 10917
[12:05:29.640195] Test:  [170/345]  eta: 0:00:15  loss: 0.9081 (0.9094)  time: 0.0876  data: 0.0001  max mem: 10917
[12:05:30.522215] Test:  [180/345]  eta: 0:00:14  loss: 0.9142 (0.9099)  time: 0.0880  data: 0.0001  max mem: 10917
[12:05:31.407239] Test:  [190/345]  eta: 0:00:13  loss: 0.9142 (0.9101)  time: 0.0883  data: 0.0001  max mem: 10917
[12:05:32.296247] Test:  [200/345]  eta: 0:00:12  loss: 0.9130 (0.9101)  time: 0.0887  data: 0.0001  max mem: 10917
[12:05:33.188147] Test:  [210/345]  eta: 0:00:11  loss: 0.9071 (0.9097)  time: 0.0890  data: 0.0001  max mem: 10917
[12:05:34.083943] Test:  [220/345]  eta: 0:00:10  loss: 0.8994 (0.9096)  time: 0.0893  data: 0.0001  max mem: 10917
[12:05:34.983402] Test:  [230/345]  eta: 0:00:09  loss: 0.9054 (0.9096)  time: 0.0897  data: 0.0001  max mem: 10917
[12:05:35.885883] Test:  [240/345]  eta: 0:00:09  loss: 0.9121 (0.9097)  time: 0.0900  data: 0.0001  max mem: 10917
[12:05:36.791335] Test:  [250/345]  eta: 0:00:08  loss: 0.9082 (0.9095)  time: 0.0903  data: 0.0001  max mem: 10917
[12:05:37.701531] Test:  [260/345]  eta: 0:00:07  loss: 0.9082 (0.9098)  time: 0.0907  data: 0.0001  max mem: 10917
[12:05:38.614467] Test:  [270/345]  eta: 0:00:06  loss: 0.9177 (0.9099)  time: 0.0911  data: 0.0001  max mem: 10917
[12:05:39.530524] Test:  [280/345]  eta: 0:00:05  loss: 0.9042 (0.9099)  time: 0.0914  data: 0.0001  max mem: 10917
[12:05:40.450823] Test:  [290/345]  eta: 0:00:04  loss: 0.8968 (0.9099)  time: 0.0918  data: 0.0001  max mem: 10917
[12:05:41.373552] Test:  [300/345]  eta: 0:00:03  loss: 0.8975 (0.9097)  time: 0.0921  data: 0.0001  max mem: 10917
[12:05:42.300472] Test:  [310/345]  eta: 0:00:03  loss: 0.9096 (0.9097)  time: 0.0924  data: 0.0001  max mem: 10917
[12:05:43.230831] Test:  [320/345]  eta: 0:00:02  loss: 0.9096 (0.9098)  time: 0.0928  data: 0.0001  max mem: 10917
[12:05:44.165099] Test:  [330/345]  eta: 0:00:01  loss: 0.8994 (0.9098)  time: 0.0932  data: 0.0001  max mem: 10917
[12:05:45.102413] Test:  [340/345]  eta: 0:00:00  loss: 0.9041 (0.9098)  time: 0.0935  data: 0.0001  max mem: 10917
[12:05:45.478893] Test:  [344/345]  eta: 0:00:00  loss: 0.9041 (0.9098)  time: 0.0937  data: 0.0001  max mem: 10917
[12:05:45.543126] Test: Total time: 0:00:30 (0.0887 s / it)
[12:05:56.549918] Test:  [ 0/57]  eta: 0:00:13  loss: 0.9747 (0.9747)  time: 0.2312  data: 0.1512  max mem: 10917
[12:05:57.367216] Test:  [10/57]  eta: 0:00:04  loss: 0.9588 (0.9615)  time: 0.0952  data: 0.0142  max mem: 10917
[12:05:58.185116] Test:  [20/57]  eta: 0:00:03  loss: 0.9517 (0.9593)  time: 0.0817  data: 0.0003  max mem: 10917
[12:05:59.006704] Test:  [30/57]  eta: 0:00:02  loss: 0.8946 (0.9243)  time: 0.0819  data: 0.0001  max mem: 10917
[12:05:59.830571] Test:  [40/57]  eta: 0:00:01  loss: 0.8424 (0.9033)  time: 0.0822  data: 0.0001  max mem: 10917
[12:06:00.659869] Test:  [50/57]  eta: 0:00:00  loss: 0.8462 (0.8961)  time: 0.0826  data: 0.0001  max mem: 10917
[12:06:01.110444] Test:  [56/57]  eta: 0:00:00  loss: 0.8717 (0.8993)  time: 0.0804  data: 0.0001  max mem: 10917
[12:06:01.167628] Test: Total time: 0:00:04 (0.0851 s / it)
[12:06:03.070091] Dice score of the network on the train images: 0.722357, val images: 0.729275
[12:06:03.073677] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:06:03.475010] Epoch: [7]  [  0/345]  eta: 0:02:18  lr: 0.000044  loss: 0.8884 (0.8884)  time: 0.4003  data: 0.1475  max mem: 10917
[12:06:08.483341] Epoch: [7]  [ 20/345]  eta: 0:01:23  lr: 0.000044  loss: 0.9379 (0.9343)  time: 0.2504  data: 0.0001  max mem: 10917
[12:06:13.487650] Epoch: [7]  [ 40/345]  eta: 0:01:17  lr: 0.000044  loss: 0.9302 (0.9345)  time: 0.2502  data: 0.0001  max mem: 10917
[12:06:18.498786] Epoch: [7]  [ 60/345]  eta: 0:01:12  lr: 0.000045  loss: 0.9223 (0.9331)  time: 0.2505  data: 0.0001  max mem: 10917
[12:06:23.509609] Epoch: [7]  [ 80/345]  eta: 0:01:06  lr: 0.000045  loss: 0.9149 (0.9294)  time: 0.2505  data: 0.0001  max mem: 10917
[12:06:28.527388] Epoch: [7]  [100/345]  eta: 0:01:01  lr: 0.000046  loss: 0.9063 (0.9255)  time: 0.2508  data: 0.0001  max mem: 10917
[12:06:33.550434] Epoch: [7]  [120/345]  eta: 0:00:56  lr: 0.000046  loss: 0.9039 (0.9226)  time: 0.2511  data: 0.0001  max mem: 10917
[12:06:38.575471] Epoch: [7]  [140/345]  eta: 0:00:51  lr: 0.000046  loss: 0.9126 (0.9214)  time: 0.2512  data: 0.0000  max mem: 10917

[12:06:43.603253] Epoch: [7]  [160/345]  eta: 0:00:46  lr: 0.000047  loss: 0.9107 (0.9203)  time: 0.2513  data: 0.0001  max mem: 10917
[12:06:48.637061] Epoch: [7]  [180/345]  eta: 0:00:41  lr: 0.000047  loss: 0.9085 (0.9200)  time: 0.2516  data: 0.0001  max mem: 10917
[12:06:53.673958] Epoch: [7]  [200/345]  eta: 0:00:36  lr: 0.000047  loss: 0.9117 (0.9191)  time: 0.2518  data: 0.0001  max mem: 10917
[12:06:58.717282] Epoch: [7]  [220/345]  eta: 0:00:31  lr: 0.000048  loss: 0.9122 (0.9186)  time: 0.2521  data: 0.0001  max mem: 10917
[12:07:03.757153] Epoch: [7]  [240/345]  eta: 0:00:26  lr: 0.000048  loss: 0.8988 (0.9173)  time: 0.2519  data: 0.0000  max mem: 10917
[12:07:08.798966] Epoch: [7]  [260/345]  eta: 0:00:21  lr: 0.000048  loss: 0.8961 (0.9160)  time: 0.2520  data: 0.0000  max mem: 10917
[12:07:13.849072] Epoch: [7]  [280/345]  eta: 0:00:16  lr: 0.000049  loss: 0.8821 (0.9140)  time: 0.2525  data: 0.0001  max mem: 10917
[12:07:18.893166] Epoch: [7]  [300/345]  eta: 0:00:11  lr: 0.000049  loss: 0.9032 (0.9132)  time: 0.2522  data: 0.0001  max mem: 10917
[12:07:23.938265] Epoch: [7]  [320/345]  eta: 0:00:06  lr: 0.000050  loss: 0.9010 (0.9122)  time: 0.2522  data: 0.0001  max mem: 10917
[12:07:28.984692] Epoch: [7]  [340/345]  eta: 0:00:01  lr: 0.000050  loss: 0.8966 (0.9112)  time: 0.2523  data: 0.0001  max mem: 10917
[12:07:29.994895] Epoch: [7]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.8966 (0.9109)  time: 0.2523  data: 0.0001  max mem: 10917
[12:07:30.053663] Epoch: [7] Total time: 0:01:26 (0.2521 s / it)
[12:07:30.054034] Averaged stats: lr: 0.000050  loss: 0.8966 (0.9109)
[12:07:30.300604] Test:  [  0/345]  eta: 0:01:23  loss: 0.8553 (0.8553)  time: 0.2431  data: 0.1633  max mem: 10917
[12:07:31.232978] Test:  [ 10/345]  eta: 0:00:35  loss: 0.8579 (0.8606)  time: 0.1068  data: 0.0257  max mem: 10917
[12:07:32.056085] Test:  [ 20/345]  eta: 0:00:30  loss: 0.8612 (0.8575)  time: 0.0877  data: 0.0060  max mem: 10917
[12:07:32.909277] Test:  [ 30/345]  eta: 0:00:28  loss: 0.8536 (0.8578)  time: 0.0838  data: 0.0015  max mem: 10917
[12:07:33.738851] Test:  [ 40/345]  eta: 0:00:27  loss: 0.8525 (0.8610)  time: 0.0841  data: 0.0015  max mem: 10917
[12:07:34.573193] Test:  [ 50/345]  eta: 0:00:26  loss: 0.8531 (0.8590)  time: 0.0831  data: 0.0001  max mem: 10917
[12:07:35.411040] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8622 (0.8606)  time: 0.0836  data: 0.0001  max mem: 10917
[12:07:36.252021] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8661 (0.8617)  time: 0.0839  data: 0.0001  max mem: 10917
[12:07:37.095653] Test:  [ 80/345]  eta: 0:00:23  loss: 0.8544 (0.8617)  time: 0.0842  data: 0.0001  max mem: 10917
[12:07:37.943942] Test:  [ 90/345]  eta: 0:00:22  loss: 0.8649 (0.8632)  time: 0.0845  data: 0.0001  max mem: 10917
[12:07:38.795261] Test:  [100/345]  eta: 0:00:21  loss: 0.8688 (0.8636)  time: 0.0849  data: 0.0001  max mem: 10917
[12:07:39.649589] Test:  [110/345]  eta: 0:00:20  loss: 0.8664 (0.8641)  time: 0.0852  data: 0.0001  max mem: 10917
[12:07:40.507732] Test:  [120/345]  eta: 0:00:19  loss: 0.8673 (0.8639)  time: 0.0856  data: 0.0001  max mem: 10917
[12:07:41.369740] Test:  [130/345]  eta: 0:00:18  loss: 0.8711 (0.8645)  time: 0.0860  data: 0.0001  max mem: 10917
[12:07:42.234768] Test:  [140/345]  eta: 0:00:17  loss: 0.8643 (0.8649)  time: 0.0863  data: 0.0001  max mem: 10917
[12:07:43.103589] Test:  [150/345]  eta: 0:00:16  loss: 0.8641 (0.8651)  time: 0.0866  data: 0.0001  max mem: 10917
[12:07:43.975983] Test:  [160/345]  eta: 0:00:15  loss: 0.8566 (0.8645)  time: 0.0870  data: 0.0001  max mem: 10917
[12:07:44.853167] Test:  [170/345]  eta: 0:00:15  loss: 0.8624 (0.8647)  time: 0.0874  data: 0.0001  max mem: 10917
[12:07:45.732691] Test:  [180/345]  eta: 0:00:14  loss: 0.8607 (0.8646)  time: 0.0878  data: 0.0001  max mem: 10917
[12:07:46.615523] Test:  [190/345]  eta: 0:00:13  loss: 0.8642 (0.8649)  time: 0.0881  data: 0.0001  max mem: 10917
[12:07:47.501334] Test:  [200/345]  eta: 0:00:12  loss: 0.8707 (0.8650)  time: 0.0884  data: 0.0001  max mem: 10917
[12:07:48.391809] Test:  [210/345]  eta: 0:00:11  loss: 0.8643 (0.8643)  time: 0.0888  data: 0.0001  max mem: 10917
[12:07:49.284388] Test:  [220/345]  eta: 0:00:10  loss: 0.8552 (0.8646)  time: 0.0891  data: 0.0001  max mem: 10917
[12:07:50.181091] Test:  [230/345]  eta: 0:00:10  loss: 0.8704 (0.8650)  time: 0.0894  data: 0.0001  max mem: 10917
[12:07:51.081783] Test:  [240/345]  eta: 0:00:09  loss: 0.8606 (0.8647)  time: 0.0898  data: 0.0001  max mem: 10917
[12:07:51.984794] Test:  [250/345]  eta: 0:00:08  loss: 0.8671 (0.8653)  time: 0.0901  data: 0.0001  max mem: 10917
[12:07:52.892322] Test:  [260/345]  eta: 0:00:07  loss: 0.8775 (0.8656)  time: 0.0905  data: 0.0001  max mem: 10917
[12:07:53.803206] Test:  [270/345]  eta: 0:00:06  loss: 0.8776 (0.8658)  time: 0.0909  data: 0.0001  max mem: 10917
[12:07:54.718073] Test:  [280/345]  eta: 0:00:05  loss: 0.8625 (0.8653)  time: 0.0912  data: 0.0001  max mem: 10917
[12:07:55.636767] Test:  [290/345]  eta: 0:00:04  loss: 0.8576 (0.8651)  time: 0.0916  data: 0.0001  max mem: 10917
[12:07:56.558407] Test:  [300/345]  eta: 0:00:03  loss: 0.8601 (0.8653)  time: 0.0920  data: 0.0001  max mem: 10917
[12:07:57.482949] Test:  [310/345]  eta: 0:00:03  loss: 0.8734 (0.8656)  time: 0.0923  data: 0.0001  max mem: 10917
[12:07:58.411569] Test:  [320/345]  eta: 0:00:02  loss: 0.8797 (0.8661)  time: 0.0926  data: 0.0001  max mem: 10917
[12:07:59.343806] Test:  [330/345]  eta: 0:00:01  loss: 0.8611 (0.8655)  time: 0.0930  data: 0.0001  max mem: 10917
[12:08:00.278945] Test:  [340/345]  eta: 0:00:00  loss: 0.8611 (0.8660)  time: 0.0933  data: 0.0001  max mem: 10917
[12:08:00.654516] Test:  [344/345]  eta: 0:00:00  loss: 0.8611 (0.8661)  time: 0.0935  data: 0.0001  max mem: 10917
[12:08:00.713392] Test: Total time: 0:00:30 (0.0889 s / it)
[12:08:11.656707] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9299 (0.9299)  time: 0.2234  data: 0.1436  max mem: 10917
[12:08:12.471121] Test:  [10/57]  eta: 0:00:04  loss: 0.9024 (0.9212)  time: 0.0943  data: 0.0132  max mem: 10917
[12:08:13.288995] Test:  [20/57]  eta: 0:00:03  loss: 0.9089 (0.9173)  time: 0.0815  data: 0.0001  max mem: 10917
[12:08:14.111118] Test:  [30/57]  eta: 0:00:02  loss: 0.8403 (0.8785)  time: 0.0819  data: 0.0001  max mem: 10917
[12:08:14.937047] Test:  [40/57]  eta: 0:00:01  loss: 0.7890 (0.8540)  time: 0.0824  data: 0.0001  max mem: 10917
[12:08:15.765872] Test:  [50/57]  eta: 0:00:00  loss: 0.7890 (0.8460)  time: 0.0827  data: 0.0001  max mem: 10917
[12:08:16.216338] Test:  [56/57]  eta: 0:00:00  loss: 0.8302 (0.8499)  time: 0.0805  data: 0.0001  max mem: 10917
[12:08:16.272549] Test: Total time: 0:00:04 (0.0849 s / it)
[12:08:18.180528] Dice score of the network on the train images: 0.720730, val images: 0.795249
[12:08:18.180760] saving best_rec_model_0 @ epoch 7
[12:08:18.994753] saving best_dice_model_0 @ epoch 7
[12:08:19.792144] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:08:20.192910] Epoch: [8]  [  0/345]  eta: 0:02:17  lr: 0.000050  loss: 0.8759 (0.8759)  time: 0.3996  data: 0.1469  max mem: 10917
[12:08:25.197965] Epoch: [8]  [ 20/345]  eta: 0:01:23  lr: 0.000050  loss: 0.8816 (0.8839)  time: 0.2502  data: 0.0001  max mem: 10917
[12:08:30.207957] Epoch: [8]  [ 40/345]  eta: 0:01:17  lr: 0.000051  loss: 0.8936 (0.8891)  time: 0.2505  data: 0.0001  max mem: 10917
[12:08:35.227248] Epoch: [8]  [ 60/345]  eta: 0:01:12  lr: 0.000051  loss: 0.9017 (0.8903)  time: 0.2509  data: 0.0001  max mem: 10917
[12:08:40.250837] Epoch: [8]  [ 80/345]  eta: 0:01:06  lr: 0.000051  loss: 0.8782 (0.8895)  time: 0.2511  data: 0.0001  max mem: 10917
[12:08:45.269769] Epoch: [8]  [100/345]  eta: 0:01:01  lr: 0.000052  loss: 0.8815 (0.8883)  time: 0.2509  data: 0.0001  max mem: 10917
[12:08:50.373238] Epoch: [8]  [120/345]  eta: 0:00:56  lr: 0.000052  loss: 0.8848 (0.8879)  time: 0.2551  data: 0.0001  max mem: 10917
[12:08:55.409953] Epoch: [8]  [140/345]  eta: 0:00:51  lr: 0.000053  loss: 0.8751 (0.8870)  time: 0.2518  data: 0.0001  max mem: 10917
[12:09:00.425364] Epoch: [8]  [160/345]  eta: 0:00:46  lr: 0.000053  loss: 0.8907 (0.8867)  time: 0.2507  data: 0.0001  max mem: 10917
[12:09:05.436496] Epoch: [8]  [180/345]  eta: 0:00:41  lr: 0.000053  loss: 0.8673 (0.8850)  time: 0.2505  data: 0.0000  max mem: 10917
[12:09:10.455183] Epoch: [8]  [200/345]  eta: 0:00:36  lr: 0.000054  loss: 0.8778 (0.8846)  time: 0.2509  data: 0.0001  max mem: 10917
[12:09:15.473499] Epoch: [8]  [220/345]  eta: 0:00:31  lr: 0.000054  loss: 0.8958 (0.8853)  time: 0.2509  data: 0.0000  max mem: 10917
[12:09:20.495776] Epoch: [8]  [240/345]  eta: 0:00:26  lr: 0.000054  loss: 0.8684 (0.8839)  time: 0.2511  data: 0.0000  max mem: 10917
[12:09:25.523492] Epoch: [8]  [260/345]  eta: 0:00:21  lr: 0.000055  loss: 0.8719 (0.8832)  time: 0.2514  data: 0.0000  max mem: 10917
[12:09:30.552387] Epoch: [8]  [280/345]  eta: 0:00:16  lr: 0.000055  loss: 0.8644 (0.8823)  time: 0.2514  data: 0.0001  max mem: 10917
[12:09:35.579218] Epoch: [8]  [300/345]  eta: 0:00:11  lr: 0.000055  loss: 0.8641 (0.8818)  time: 0.2513  data: 0.0000  max mem: 10917
[12:09:40.621403] Epoch: [8]  [320/345]  eta: 0:00:06  lr: 0.000056  loss: 0.8845 (0.8816)  time: 0.2521  data: 0.0000  max mem: 10917
[12:09:45.668582] Epoch: [8]  [340/345]  eta: 0:00:01  lr: 0.000056  loss: 0.8678 (0.8808)  time: 0.2523  data: 0.0001  max mem: 10917
[12:09:46.679324] Epoch: [8]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.8691 (0.8808)  time: 0.2524  data: 0.0001  max mem: 10917
[12:09:46.743363] Epoch: [8] Total time: 0:01:26 (0.2520 s / it)
[12:09:46.743687] Averaged stats: lr: 0.000056  loss: 0.8691 (0.8808)
[12:09:46.993207] Test:  [  0/345]  eta: 0:01:24  loss: 0.8958 (0.8958)  time: 0.2461  data: 0.1657  max mem: 10917
[12:09:47.816159] Test:  [ 10/345]  eta: 0:00:32  loss: 0.8413 (0.8429)  time: 0.0971  data: 0.0151  max mem: 10917
[12:09:48.641236] Test:  [ 20/345]  eta: 0:00:29  loss: 0.8354 (0.8398)  time: 0.0823  data: 0.0001  max mem: 10917
[12:09:49.470447] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8289 (0.8369)  time: 0.0827  data: 0.0001  max mem: 10917
[12:09:50.304809] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8267 (0.8373)  time: 0.0831  data: 0.0001  max mem: 10917
[12:09:51.141682] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8296 (0.8371)  time: 0.0835  data: 0.0001  max mem: 10917
[12:09:51.980783] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8263 (0.8354)  time: 0.0837  data: 0.0001  max mem: 10917
[12:09:52.824565] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8295 (0.8358)  time: 0.0841  data: 0.0001  max mem: 10917
[12:09:53.671274] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8299 (0.8370)  time: 0.0845  data: 0.0001  max mem: 10917
[12:09:54.521024] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8331 (0.8374)  time: 0.0848  data: 0.0001  max mem: 10917
[12:09:55.374129] Test:  [100/345]  eta: 0:00:20  loss: 0.8388 (0.8385)  time: 0.0851  data: 0.0001  max mem: 10917
[12:09:56.230849] Test:  [110/345]  eta: 0:00:20  loss: 0.8485 (0.8393)  time: 0.0854  data: 0.0001  max mem: 10917
[12:09:57.091534] Test:  [120/345]  eta: 0:00:19  loss: 0.8511 (0.8401)  time: 0.0858  data: 0.0001  max mem: 10917
[12:09:57.955949] Test:  [130/345]  eta: 0:00:18  loss: 0.8495 (0.8403)  time: 0.0862  data: 0.0001  max mem: 10917
[12:09:58.824714] Test:  [140/345]  eta: 0:00:17  loss: 0.8456 (0.8410)  time: 0.0866  data: 0.0001  max mem: 10917
[12:09:59.696102] Test:  [150/345]  eta: 0:00:16  loss: 0.8456 (0.8412)  time: 0.0870  data: 0.0001  max mem: 10917
[12:10:00.570197] Test:  [160/345]  eta: 0:00:15  loss: 0.8310 (0.8401)  time: 0.0872  data: 0.0001  max mem: 10917
[12:10:01.448479] Test:  [170/345]  eta: 0:00:15  loss: 0.8278 (0.8404)  time: 0.0876  data: 0.0001  max mem: 10917
[12:10:02.329485] Test:  [180/345]  eta: 0:00:14  loss: 0.8423 (0.8405)  time: 0.0879  data: 0.0001  max mem: 10917
[12:10:03.214143] Test:  [190/345]  eta: 0:00:13  loss: 0.8371 (0.8402)  time: 0.0882  data: 0.0001  max mem: 10917
[12:10:04.102762] Test:  [200/345]  eta: 0:00:12  loss: 0.8378 (0.8404)  time: 0.0886  data: 0.0001  max mem: 10917
[12:10:04.994366] Test:  [210/345]  eta: 0:00:11  loss: 0.8378 (0.8404)  time: 0.0890  data: 0.0001  max mem: 10917
[12:10:05.890578] Test:  [220/345]  eta: 0:00:10  loss: 0.8353 (0.8402)  time: 0.0893  data: 0.0001  max mem: 10917
[12:10:06.788990] Test:  [230/345]  eta: 0:00:09  loss: 0.8354 (0.8401)  time: 0.0897  data: 0.0001  max mem: 10917
[12:10:07.690792] Test:  [240/345]  eta: 0:00:09  loss: 0.8414 (0.8402)  time: 0.0900  data: 0.0001  max mem: 10917
[12:10:08.596838] Test:  [250/345]  eta: 0:00:08  loss: 0.8414 (0.8405)  time: 0.0903  data: 0.0001  max mem: 10917
[12:10:09.506623] Test:  [260/345]  eta: 0:00:07  loss: 0.8461 (0.8407)  time: 0.0907  data: 0.0001  max mem: 10917
[12:10:10.419800] Test:  [270/345]  eta: 0:00:06  loss: 0.8483 (0.8411)  time: 0.0911  data: 0.0001  max mem: 10917
[12:10:11.336127] Test:  [280/345]  eta: 0:00:05  loss: 0.8403 (0.8409)  time: 0.0914  data: 0.0001  max mem: 10917
[12:10:12.256061] Test:  [290/345]  eta: 0:00:04  loss: 0.8367 (0.8408)  time: 0.0918  data: 0.0001  max mem: 10917
[12:10:13.179445] Test:  [300/345]  eta: 0:00:03  loss: 0.8386 (0.8407)  time: 0.0921  data: 0.0001  max mem: 10917
[12:10:14.107054] Test:  [310/345]  eta: 0:00:03  loss: 0.8428 (0.8407)  time: 0.0925  data: 0.0001  max mem: 10917
[12:10:15.037104] Test:  [320/345]  eta: 0:00:02  loss: 0.8454 (0.8409)  time: 0.0928  data: 0.0001  max mem: 10917
[12:10:15.970704] Test:  [330/345]  eta: 0:00:01  loss: 0.8388 (0.8405)  time: 0.0931  data: 0.0001  max mem: 10917
[12:10:16.908476] Test:  [340/345]  eta: 0:00:00  loss: 0.8289 (0.8405)  time: 0.0935  data: 0.0001  max mem: 10917
[12:10:17.284956] Test:  [344/345]  eta: 0:00:00  loss: 0.8347 (0.8407)  time: 0.0937  data: 0.0001  max mem: 10917
[12:10:17.339022] Test: Total time: 0:00:30 (0.0887 s / it)
[12:10:28.296640] Test:  [ 0/57]  eta: 0:00:13  loss: 0.9273 (0.9273)  time: 0.2308  data: 0.1509  max mem: 10917
[12:10:29.111143] Test:  [10/57]  eta: 0:00:04  loss: 0.9023 (0.9128)  time: 0.0950  data: 0.0138  max mem: 10917
[12:10:29.928596] Test:  [20/57]  eta: 0:00:03  loss: 0.9059 (0.9098)  time: 0.0815  data: 0.0001  max mem: 10917
[12:10:30.749516] Test:  [30/57]  eta: 0:00:02  loss: 0.8150 (0.8697)  time: 0.0819  data: 0.0001  max mem: 10917
[12:10:31.574094] Test:  [40/57]  eta: 0:00:01  loss: 0.7831 (0.8456)  time: 0.0822  data: 0.0001  max mem: 10917
[12:10:32.402901] Test:  [50/57]  eta: 0:00:00  loss: 0.7845 (0.8378)  time: 0.0826  data: 0.0001  max mem: 10917
[12:10:32.853063] Test:  [56/57]  eta: 0:00:00  loss: 0.8115 (0.8411)  time: 0.0804  data: 0.0001  max mem: 10917
[12:10:32.911877] Test: Total time: 0:00:04 (0.0850 s / it)
[12:10:34.782587] Dice score of the network on the train images: 0.744541, val images: 0.800417
[12:10:34.782826] saving best_dice_model_0 @ epoch 8
[12:10:35.634370] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:10:36.033894] Epoch: [9]  [  0/345]  eta: 0:02:17  lr: 0.000056  loss: 0.8411 (0.8411)  time: 0.3983  data: 0.1448  max mem: 10917
[12:10:41.040182] Epoch: [9]  [ 20/345]  eta: 0:01:23  lr: 0.000057  loss: 0.8706 (0.8667)  time: 0.2503  data: 0.0001  max mem: 10917
[12:10:46.037800] Epoch: [9]  [ 40/345]  eta: 0:01:17  lr: 0.000057  loss: 0.8745 (0.8731)  time: 0.2498  data: 0.0001  max mem: 10917
[12:10:51.045037] Epoch: [9]  [ 60/345]  eta: 0:01:11  lr: 0.000057  loss: 0.8642 (0.8737)  time: 0.2503  data: 0.0001  max mem: 10917
[12:10:56.060713] Epoch: [9]  [ 80/345]  eta: 0:01:06  lr: 0.000058  loss: 0.8698 (0.8723)  time: 0.2507  data: 0.0001  max mem: 10917
[12:11:01.079891] Epoch: [9]  [100/345]  eta: 0:01:01  lr: 0.000058  loss: 0.8617 (0.8703)  time: 0.2509  data: 0.0000  max mem: 10917
[12:11:06.101507] Epoch: [9]  [120/345]  eta: 0:00:56  lr: 0.000058  loss: 0.8543 (0.8686)  time: 0.2510  data: 0.0000  max mem: 10917
[12:11:11.121276] Epoch: [9]  [140/345]  eta: 0:00:51  lr: 0.000059  loss: 0.8534 (0.8664)  time: 0.2509  data: 0.0001  max mem: 10917
[12:11:16.147877] Epoch: [9]  [160/345]  eta: 0:00:46  lr: 0.000059  loss: 0.8654 (0.8673)  time: 0.2513  data: 0.0000  max mem: 10917
[12:11:21.170139] Epoch: [9]  [180/345]  eta: 0:00:41  lr: 0.000060  loss: 0.8588 (0.8667)  time: 0.2511  data: 0.0001  max mem: 10917
[12:11:26.198894] Epoch: [9]  [200/345]  eta: 0:00:36  lr: 0.000060  loss: 0.8462 (0.8648)  time: 0.2514  data: 0.0000  max mem: 10917
[12:11:31.232081] Epoch: [9]  [220/345]  eta: 0:00:31  lr: 0.000060  loss: 0.8496 (0.8634)  time: 0.2516  data: 0.0000  max mem: 10917
[12:11:36.265714] Epoch: [9]  [240/345]  eta: 0:00:26  lr: 0.000061  loss: 0.8497 (0.8629)  time: 0.2516  data: 0.0000  max mem: 10917
[12:11:41.304857] Epoch: [9]  [260/345]  eta: 0:00:21  lr: 0.000061  loss: 0.8766 (0.8640)  time: 0.2519  data: 0.0000  max mem: 10917
[12:11:46.343405] Epoch: [9]  [280/345]  eta: 0:00:16  lr: 0.000061  loss: 0.8593 (0.8636)  time: 0.2519  data: 0.0001  max mem: 10917
[12:11:51.378008] Epoch: [9]  [300/345]  eta: 0:00:11  lr: 0.000062  loss: 0.8543 (0.8633)  time: 0.2517  data: 0.0001  max mem: 10917
[12:11:56.408164] Epoch: [9]  [320/345]  eta: 0:00:06  lr: 0.000062  loss: 0.8431 (0.8631)  time: 0.2515  data: 0.0001  max mem: 10917
[12:12:01.437452] Epoch: [9]  [340/345]  eta: 0:00:01  lr: 0.000062  loss: 0.8510 (0.8625)  time: 0.2514  data: 0.0001  max mem: 10917
[12:12:02.444582] Epoch: [9]  [344/345]  eta: 0:00:00  lr: 0.000062  loss: 0.8508 (0.8624)  time: 0.2515  data: 0.0001  max mem: 10917
[12:12:02.502727] Epoch: [9] Total time: 0:01:26 (0.2518 s / it)
[12:12:02.503144] Averaged stats: lr: 0.000062  loss: 0.8508 (0.8624)
[12:12:02.746983] Test:  [  0/345]  eta: 0:01:22  loss: 0.8326 (0.8326)  time: 0.2403  data: 0.1600  max mem: 10917
[12:12:03.583593] Test:  [ 10/345]  eta: 0:00:32  loss: 0.8190 (0.8184)  time: 0.0978  data: 0.0160  max mem: 10917
[12:12:04.407996] Test:  [ 20/345]  eta: 0:00:29  loss: 0.8221 (0.8236)  time: 0.0830  data: 0.0008  max mem: 10917
[12:12:05.237003] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8274 (0.8229)  time: 0.0826  data: 0.0001  max mem: 10917
[12:12:06.069280] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8274 (0.8246)  time: 0.0830  data: 0.0001  max mem: 10917
[12:12:06.905573] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8270 (0.8241)  time: 0.0834  data: 0.0001  max mem: 10917
[12:12:07.745386] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8124 (0.8216)  time: 0.0838  data: 0.0001  max mem: 10917
[12:12:08.588156] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8039 (0.8212)  time: 0.0841  data: 0.0001  max mem: 10917
[12:12:09.434414] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8185 (0.8215)  time: 0.0844  data: 0.0001  max mem: 10917
[12:12:10.284561] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8319 (0.8224)  time: 0.0848  data: 0.0001  max mem: 10917
[12:12:11.137688] Test:  [100/345]  eta: 0:00:20  loss: 0.8292 (0.8223)  time: 0.0851  data: 0.0001  max mem: 10917
[12:12:11.994558] Test:  [110/345]  eta: 0:00:20  loss: 0.8293 (0.8236)  time: 0.0855  data: 0.0001  max mem: 10917
[12:12:12.855222] Test:  [120/345]  eta: 0:00:19  loss: 0.8189 (0.8227)  time: 0.0858  data: 0.0001  max mem: 10917
[12:12:13.719683] Test:  [130/345]  eta: 0:00:18  loss: 0.8127 (0.8222)  time: 0.0862  data: 0.0001  max mem: 10917
[12:12:14.589056] Test:  [140/345]  eta: 0:00:17  loss: 0.8188 (0.8224)  time: 0.0866  data: 0.0001  max mem: 10917
[12:12:15.460463] Test:  [150/345]  eta: 0:00:16  loss: 0.8271 (0.8227)  time: 0.0870  data: 0.0001  max mem: 10917
[12:12:16.335327] Test:  [160/345]  eta: 0:00:15  loss: 0.8341 (0.8238)  time: 0.0873  data: 0.0001  max mem: 10917
[12:12:17.213258] Test:  [170/345]  eta: 0:00:15  loss: 0.8351 (0.8239)  time: 0.0876  data: 0.0001  max mem: 10917
[12:12:18.095339] Test:  [180/345]  eta: 0:00:14  loss: 0.8219 (0.8237)  time: 0.0880  data: 0.0001  max mem: 10917
[12:12:18.980717] Test:  [190/345]  eta: 0:00:13  loss: 0.8226 (0.8239)  time: 0.0883  data: 0.0001  max mem: 10917
[12:12:19.869015] Test:  [200/345]  eta: 0:00:12  loss: 0.8361 (0.8247)  time: 0.0886  data: 0.0001  max mem: 10917
[12:12:20.761514] Test:  [210/345]  eta: 0:00:11  loss: 0.8147 (0.8236)  time: 0.0890  data: 0.0001  max mem: 10917
[12:12:21.657130] Test:  [220/345]  eta: 0:00:10  loss: 0.8043 (0.8230)  time: 0.0894  data: 0.0001  max mem: 10917
[12:12:22.557123] Test:  [230/345]  eta: 0:00:09  loss: 0.8029 (0.8225)  time: 0.0897  data: 0.0001  max mem: 10917
[12:12:23.459689] Test:  [240/345]  eta: 0:00:09  loss: 0.8094 (0.8226)  time: 0.0901  data: 0.0001  max mem: 10917
[12:12:24.365719] Test:  [250/345]  eta: 0:00:08  loss: 0.8212 (0.8228)  time: 0.0904  data: 0.0001  max mem: 10917
[12:12:25.274574] Test:  [260/345]  eta: 0:00:07  loss: 0.8191 (0.8227)  time: 0.0907  data: 0.0001  max mem: 10917
[12:12:26.187106] Test:  [270/345]  eta: 0:00:06  loss: 0.8221 (0.8228)  time: 0.0910  data: 0.0001  max mem: 10917
[12:12:27.103164] Test:  [280/345]  eta: 0:00:05  loss: 0.8206 (0.8228)  time: 0.0914  data: 0.0001  max mem: 10917
[12:12:28.023825] Test:  [290/345]  eta: 0:00:04  loss: 0.8160 (0.8229)  time: 0.0918  data: 0.0001  max mem: 10917
[12:12:28.947041] Test:  [300/345]  eta: 0:00:03  loss: 0.8330 (0.8234)  time: 0.0921  data: 0.0001  max mem: 10917
[12:12:29.873662] Test:  [310/345]  eta: 0:00:03  loss: 0.8325 (0.8232)  time: 0.0924  data: 0.0001  max mem: 10917
[12:12:30.805195] Test:  [320/345]  eta: 0:00:02  loss: 0.8074 (0.8229)  time: 0.0929  data: 0.0001  max mem: 10917
[12:12:31.738157] Test:  [330/345]  eta: 0:00:01  loss: 0.8208 (0.8231)  time: 0.0932  data: 0.0001  max mem: 10917
[12:12:32.675559] Test:  [340/345]  eta: 0:00:00  loss: 0.8213 (0.8230)  time: 0.0935  data: 0.0001  max mem: 10917
[12:12:33.051607] Test:  [344/345]  eta: 0:00:00  loss: 0.8213 (0.8230)  time: 0.0936  data: 0.0001  max mem: 10917
[12:12:33.110246] Test: Total time: 0:00:30 (0.0887 s / it)
[12:12:44.015727] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9119 (0.9119)  time: 0.2280  data: 0.1480  max mem: 10917
[12:12:44.829349] Test:  [10/57]  eta: 0:00:04  loss: 0.9041 (0.9105)  time: 0.0946  data: 0.0135  max mem: 10917
[12:12:45.646940] Test:  [20/57]  eta: 0:00:03  loss: 0.9041 (0.9033)  time: 0.0815  data: 0.0001  max mem: 10917
[12:12:46.468238] Test:  [30/57]  eta: 0:00:02  loss: 0.8006 (0.8631)  time: 0.0819  data: 0.0001  max mem: 10917
[12:12:47.293442] Test:  [40/57]  eta: 0:00:01  loss: 0.7800 (0.8392)  time: 0.0823  data: 0.0001  max mem: 10917
[12:12:48.121891] Test:  [50/57]  eta: 0:00:00  loss: 0.7751 (0.8313)  time: 0.0826  data: 0.0001  max mem: 10917
[12:12:48.571616] Test:  [56/57]  eta: 0:00:00  loss: 0.8041 (0.8344)  time: 0.0804  data: 0.0001  max mem: 10917
[12:12:48.626510] Test: Total time: 0:00:04 (0.0849 s / it)
[12:12:50.502588] Dice score of the network on the train images: 0.762299, val images: 0.802868
[12:12:50.502824] saving best_dice_model_0 @ epoch 9
[12:12:51.333957] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:12:51.735962] Epoch: [10]  [  0/345]  eta: 0:02:18  lr: 0.000063  loss: 0.7944 (0.7944)  time: 0.4008  data: 0.1482  max mem: 10917
[12:12:56.726892] Epoch: [10]  [ 20/345]  eta: 0:01:23  lr: 0.000063  loss: 0.8537 (0.8461)  time: 0.2495  data: 0.0001  max mem: 10917
[12:13:01.713218] Epoch: [10]  [ 40/345]  eta: 0:01:17  lr: 0.000063  loss: 0.8556 (0.8507)  time: 0.2493  data: 0.0001  max mem: 10917
[12:13:06.706544] Epoch: [10]  [ 60/345]  eta: 0:01:11  lr: 0.000064  loss: 0.8493 (0.8503)  time: 0.2496  data: 0.0001  max mem: 10917
[12:13:11.704960] Epoch: [10]  [ 80/345]  eta: 0:01:06  lr: 0.000064  loss: 0.8555 (0.8512)  time: 0.2499  data: 0.0001  max mem: 10917
[12:13:16.704133] Epoch: [10]  [100/345]  eta: 0:01:01  lr: 0.000064  loss: 0.8453 (0.8508)  time: 0.2499  data: 0.0001  max mem: 10917
[12:13:21.710577] Epoch: [10]  [120/345]  eta: 0:00:56  lr: 0.000065  loss: 0.8437 (0.8514)  time: 0.2503  data: 0.0001  max mem: 10917
[12:13:26.719799] Epoch: [10]  [140/345]  eta: 0:00:51  lr: 0.000065  loss: 0.8346 (0.8504)  time: 0.2504  data: 0.0001  max mem: 10917
[12:13:31.728648] Epoch: [10]  [160/345]  eta: 0:00:46  lr: 0.000065  loss: 0.8489 (0.8498)  time: 0.2504  data: 0.0001  max mem: 10917
[12:13:36.736463] Epoch: [10]  [180/345]  eta: 0:00:41  lr: 0.000066  loss: 0.8502 (0.8495)  time: 0.2504  data: 0.0001  max mem: 10917
[12:13:41.748965] Epoch: [10]  [200/345]  eta: 0:00:36  lr: 0.000066  loss: 0.8548 (0.8501)  time: 0.2506  data: 0.0001  max mem: 10917
[12:13:46.766908] Epoch: [10]  [220/345]  eta: 0:00:31  lr: 0.000066  loss: 0.8491 (0.8498)  time: 0.2509  data: 0.0001  max mem: 10917
[12:13:51.793094] Epoch: [10]  [240/345]  eta: 0:00:26  lr: 0.000067  loss: 0.8435 (0.8498)  time: 0.2513  data: 0.0001  max mem: 10917
[12:13:56.819230] Epoch: [10]  [260/345]  eta: 0:00:21  lr: 0.000067  loss: 0.8567 (0.8507)  time: 0.2513  data: 0.0001  max mem: 10917
[12:14:01.849528] Epoch: [10]  [280/345]  eta: 0:00:16  lr: 0.000068  loss: 0.8537 (0.8510)  time: 0.2515  data: 0.0001  max mem: 10917
[12:14:06.884297] Epoch: [10]  [300/345]  eta: 0:00:11  lr: 0.000068  loss: 0.8517 (0.8511)  time: 0.2517  data: 0.0001  max mem: 10917
[12:14:11.994849] Epoch: [10]  [320/345]  eta: 0:00:06  lr: 0.000068  loss: 0.8546 (0.8513)  time: 0.2555  data: 0.0001  max mem: 10917
[12:14:17.024233] Epoch: [10]  [340/345]  eta: 0:00:01  lr: 0.000069  loss: 0.8448 (0.8513)  time: 0.2514  data: 0.0001  max mem: 10917
[12:14:18.031177] Epoch: [10]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.8354 (0.8510)  time: 0.2515  data: 0.0001  max mem: 10917
[12:14:18.093553] Epoch: [10] Total time: 0:01:26 (0.2515 s / it)
[12:14:18.093990] Averaged stats: lr: 0.000069  loss: 0.8354 (0.8510)
[12:14:18.330564] Test:  [  0/345]  eta: 0:01:20  loss: 0.8115 (0.8115)  time: 0.2336  data: 0.1535  max mem: 10917
[12:14:19.164195] Test:  [ 10/345]  eta: 0:00:32  loss: 0.8109 (0.8179)  time: 0.0969  data: 0.0151  max mem: 10917
[12:14:19.989176] Test:  [ 20/345]  eta: 0:00:29  loss: 0.8109 (0.8180)  time: 0.0829  data: 0.0007  max mem: 10917
[12:14:20.819144] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8170 (0.8176)  time: 0.0827  data: 0.0001  max mem: 10917
[12:14:21.651610] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8108 (0.8164)  time: 0.0831  data: 0.0001  max mem: 10917
[12:14:22.487288] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8122 (0.8193)  time: 0.0834  data: 0.0001  max mem: 10917
[12:14:23.327886] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8245 (0.8204)  time: 0.0838  data: 0.0001  max mem: 10917
[12:14:24.171061] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8181 (0.8197)  time: 0.0841  data: 0.0001  max mem: 10917
[12:14:25.017833] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8144 (0.8189)  time: 0.0844  data: 0.0001  max mem: 10917
[12:14:25.867709] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8156 (0.8192)  time: 0.0848  data: 0.0001  max mem: 10917
[12:14:26.721395] Test:  [100/345]  eta: 0:00:20  loss: 0.8202 (0.8201)  time: 0.0851  data: 0.0001  max mem: 10917
[12:14:27.577971] Test:  [110/345]  eta: 0:00:20  loss: 0.8202 (0.8194)  time: 0.0855  data: 0.0001  max mem: 10917
[12:14:28.438868] Test:  [120/345]  eta: 0:00:19  loss: 0.8146 (0.8185)  time: 0.0858  data: 0.0001  max mem: 10917
[12:14:29.302458] Test:  [130/345]  eta: 0:00:18  loss: 0.8164 (0.8190)  time: 0.0862  data: 0.0001  max mem: 10917
[12:14:30.169584] Test:  [140/345]  eta: 0:00:17  loss: 0.8156 (0.8181)  time: 0.0865  data: 0.0001  max mem: 10917
[12:14:31.040940] Test:  [150/345]  eta: 0:00:16  loss: 0.8073 (0.8179)  time: 0.0869  data: 0.0001  max mem: 10917
[12:14:31.915060] Test:  [160/345]  eta: 0:00:15  loss: 0.8078 (0.8181)  time: 0.0872  data: 0.0001  max mem: 10917
[12:14:32.792106] Test:  [170/345]  eta: 0:00:15  loss: 0.8130 (0.8179)  time: 0.0875  data: 0.0001  max mem: 10917
[12:14:33.674138] Test:  [180/345]  eta: 0:00:14  loss: 0.8130 (0.8176)  time: 0.0879  data: 0.0001  max mem: 10917
[12:14:34.559248] Test:  [190/345]  eta: 0:00:13  loss: 0.8112 (0.8174)  time: 0.0883  data: 0.0001  max mem: 10917
[12:14:35.447544] Test:  [200/345]  eta: 0:00:12  loss: 0.8172 (0.8177)  time: 0.0886  data: 0.0001  max mem: 10917
[12:14:36.340002] Test:  [210/345]  eta: 0:00:11  loss: 0.8128 (0.8176)  time: 0.0890  data: 0.0001  max mem: 10917
[12:14:37.236060] Test:  [220/345]  eta: 0:00:10  loss: 0.8076 (0.8176)  time: 0.0894  data: 0.0001  max mem: 10917
[12:14:38.136026] Test:  [230/345]  eta: 0:00:09  loss: 0.8022 (0.8167)  time: 0.0898  data: 0.0001  max mem: 10917
[12:14:39.038967] Test:  [240/345]  eta: 0:00:09  loss: 0.8081 (0.8169)  time: 0.0901  data: 0.0001  max mem: 10917
[12:14:39.944563] Test:  [250/345]  eta: 0:00:08  loss: 0.8252 (0.8173)  time: 0.0904  data: 0.0001  max mem: 10917
[12:14:40.854066] Test:  [260/345]  eta: 0:00:07  loss: 0.8191 (0.8174)  time: 0.0907  data: 0.0001  max mem: 10917
[12:14:41.766423] Test:  [270/345]  eta: 0:00:06  loss: 0.8147 (0.8172)  time: 0.0910  data: 0.0001  max mem: 10917
[12:14:42.682801] Test:  [280/345]  eta: 0:00:05  loss: 0.8045 (0.8169)  time: 0.0914  data: 0.0001  max mem: 10917
[12:14:43.603373] Test:  [290/345]  eta: 0:00:04  loss: 0.8080 (0.8170)  time: 0.0918  data: 0.0001  max mem: 10917
[12:14:44.526405] Test:  [300/345]  eta: 0:00:03  loss: 0.8125 (0.8172)  time: 0.0921  data: 0.0001  max mem: 10917
[12:14:45.453712] Test:  [310/345]  eta: 0:00:03  loss: 0.8145 (0.8174)  time: 0.0925  data: 0.0001  max mem: 10917
[12:14:46.383744] Test:  [320/345]  eta: 0:00:02  loss: 0.8276 (0.8177)  time: 0.0928  data: 0.0001  max mem: 10917
[12:14:47.318117] Test:  [330/345]  eta: 0:00:01  loss: 0.8214 (0.8176)  time: 0.0932  data: 0.0001  max mem: 10917
[12:14:48.255676] Test:  [340/345]  eta: 0:00:00  loss: 0.8157 (0.8176)  time: 0.0935  data: 0.0001  max mem: 10917
[12:14:48.632403] Test:  [344/345]  eta: 0:00:00  loss: 0.8189 (0.8179)  time: 0.0937  data: 0.0001  max mem: 10917
[12:14:48.689914] Test: Total time: 0:00:30 (0.0887 s / it)
[12:14:59.594308] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9320 (0.9320)  time: 0.2242  data: 0.1445  max mem: 10917
[12:15:00.407436] Test:  [10/57]  eta: 0:00:04  loss: 0.9320 (0.9310)  time: 0.0942  data: 0.0132  max mem: 10917
[12:15:01.226561] Test:  [20/57]  eta: 0:00:03  loss: 0.9127 (0.9167)  time: 0.0815  data: 0.0001  max mem: 10917
[12:15:02.047370] Test:  [30/57]  eta: 0:00:02  loss: 0.8055 (0.8756)  time: 0.0819  data: 0.0001  max mem: 10917
[12:15:02.871715] Test:  [40/57]  eta: 0:00:01  loss: 0.7864 (0.8516)  time: 0.0822  data: 0.0001  max mem: 10917
[12:15:03.700276] Test:  [50/57]  eta: 0:00:00  loss: 0.7837 (0.8448)  time: 0.0826  data: 0.0001  max mem: 10917
[12:15:04.150872] Test:  [56/57]  eta: 0:00:00  loss: 0.8082 (0.8472)  time: 0.0804  data: 0.0001  max mem: 10917
[12:15:04.207444] Test: Total time: 0:00:04 (0.0849 s / it)
[12:15:06.067363] Dice score of the network on the train images: 0.775658, val images: 0.788975
[12:15:06.070463] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:15:06.469236] Epoch: [11]  [  0/345]  eta: 0:02:17  lr: 0.000069  loss: 0.8480 (0.8480)  time: 0.3981  data: 0.1462  max mem: 10917
[12:15:11.456756] Epoch: [11]  [ 20/345]  eta: 0:01:23  lr: 0.000069  loss: 0.8346 (0.8318)  time: 0.2493  data: 0.0001  max mem: 10917
[12:15:16.445533] Epoch: [11]  [ 40/345]  eta: 0:01:17  lr: 0.000069  loss: 0.8412 (0.8383)  time: 0.2494  data: 0.0001  max mem: 10917
[12:15:21.446880] Epoch: [11]  [ 60/345]  eta: 0:01:11  lr: 0.000070  loss: 0.8315 (0.8394)  time: 0.2500  data: 0.0000  max mem: 10917
[12:15:26.457120] Epoch: [11]  [ 80/345]  eta: 0:01:06  lr: 0.000070  loss: 0.8387 (0.8397)  time: 0.2505  data: 0.0001  max mem: 10917
[12:15:31.476675] Epoch: [11]  [100/345]  eta: 0:01:01  lr: 0.000071  loss: 0.8392 (0.8397)  time: 0.2509  data: 0.0000  max mem: 10917
[12:15:36.499474] Epoch: [11]  [120/345]  eta: 0:00:56  lr: 0.000071  loss: 0.8432 (0.8399)  time: 0.2511  data: 0.0000  max mem: 10917
[12:15:41.525822] Epoch: [11]  [140/345]  eta: 0:00:51  lr: 0.000071  loss: 0.8435 (0.8408)  time: 0.2513  data: 0.0001  max mem: 10917
[12:15:46.556819] Epoch: [11]  [160/345]  eta: 0:00:46  lr: 0.000072  loss: 0.8430 (0.8418)  time: 0.2515  data: 0.0000  max mem: 10917
[12:15:51.583794] Epoch: [11]  [180/345]  eta: 0:00:41  lr: 0.000072  loss: 0.8352 (0.8416)  time: 0.2513  data: 0.0000  max mem: 10917
[12:15:56.612296] Epoch: [11]  [200/345]  eta: 0:00:36  lr: 0.000072  loss: 0.8310 (0.8413)  time: 0.2514  data: 0.0000  max mem: 10917
[12:16:01.640814] Epoch: [11]  [220/345]  eta: 0:00:31  lr: 0.000073  loss: 0.8401 (0.8416)  time: 0.2514  data: 0.0000  max mem: 10917
[12:16:06.674268] Epoch: [11]  [240/345]  eta: 0:00:26  lr: 0.000073  loss: 0.8280 (0.8411)  time: 0.2516  data: 0.0000  max mem: 10917
[12:16:11.713181] Epoch: [11]  [260/345]  eta: 0:00:21  lr: 0.000073  loss: 0.8375 (0.8410)  time: 0.2519  data: 0.0000  max mem: 10917
[12:16:16.754428] Epoch: [11]  [280/345]  eta: 0:00:16  lr: 0.000074  loss: 0.8324 (0.8408)  time: 0.2520  data: 0.0001  max mem: 10917
[12:16:21.790500] Epoch: [11]  [300/345]  eta: 0:00:11  lr: 0.000074  loss: 0.8282 (0.8405)  time: 0.2518  data: 0.0000  max mem: 10917
[12:16:26.831740] Epoch: [11]  [320/345]  eta: 0:00:06  lr: 0.000075  loss: 0.8428 (0.8403)  time: 0.2520  data: 0.0000  max mem: 10917
[12:16:31.873795] Epoch: [11]  [340/345]  eta: 0:00:01  lr: 0.000075  loss: 0.8373 (0.8403)  time: 0.2521  data: 0.0000  max mem: 10917
[12:16:32.881062] Epoch: [11]  [344/345]  eta: 0:00:00  lr: 0.000075  loss: 0.8273 (0.8400)  time: 0.2520  data: 0.0001  max mem: 10917
[12:16:32.940506] Epoch: [11] Total time: 0:01:26 (0.2518 s / it)
[12:16:32.941005] Averaged stats: lr: 0.000075  loss: 0.8273 (0.8400)
[12:16:33.182009] Test:  [  0/345]  eta: 0:01:21  loss: 0.8117 (0.8117)  time: 0.2374  data: 0.1568  max mem: 10917
[12:16:34.001413] Test:  [ 10/345]  eta: 0:00:32  loss: 0.8199 (0.8137)  time: 0.0960  data: 0.0143  max mem: 10917
[12:16:34.823368] Test:  [ 20/345]  eta: 0:00:29  loss: 0.8099 (0.8092)  time: 0.0820  data: 0.0001  max mem: 10917
[12:16:35.650249] Test:  [ 30/345]  eta: 0:00:27  loss: 0.8099 (0.8088)  time: 0.0824  data: 0.0001  max mem: 10917
[12:16:36.480598] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8141 (0.8083)  time: 0.0828  data: 0.0001  max mem: 10917
[12:16:37.314086] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7953 (0.8056)  time: 0.0831  data: 0.0001  max mem: 10917
[12:16:38.150766] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7953 (0.8044)  time: 0.0835  data: 0.0001  max mem: 10917
[12:16:38.992008] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7979 (0.8027)  time: 0.0838  data: 0.0001  max mem: 10917
[12:16:39.835933] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7960 (0.8024)  time: 0.0842  data: 0.0001  max mem: 10917
[12:16:40.683820] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7964 (0.8026)  time: 0.0845  data: 0.0001  max mem: 10917
[12:16:41.534894] Test:  [100/345]  eta: 0:00:20  loss: 0.7964 (0.8023)  time: 0.0849  data: 0.0001  max mem: 10917
[12:16:42.389243] Test:  [110/345]  eta: 0:00:19  loss: 0.8067 (0.8034)  time: 0.0852  data: 0.0001  max mem: 10917
[12:16:43.247995] Test:  [120/345]  eta: 0:00:19  loss: 0.8067 (0.8034)  time: 0.0856  data: 0.0001  max mem: 10917
[12:16:44.109895] Test:  [130/345]  eta: 0:00:18  loss: 0.8028 (0.8035)  time: 0.0860  data: 0.0001  max mem: 10917
[12:16:44.975693] Test:  [140/345]  eta: 0:00:17  loss: 0.8038 (0.8036)  time: 0.0863  data: 0.0001  max mem: 10917
[12:16:45.844419] Test:  [150/345]  eta: 0:00:16  loss: 0.7913 (0.8027)  time: 0.0867  data: 0.0001  max mem: 10917
[12:16:46.717597] Test:  [160/345]  eta: 0:00:15  loss: 0.7959 (0.8027)  time: 0.0870  data: 0.0001  max mem: 10917
[12:16:47.593467] Test:  [170/345]  eta: 0:00:14  loss: 0.8007 (0.8032)  time: 0.0874  data: 0.0001  max mem: 10917
[12:16:48.473150] Test:  [180/345]  eta: 0:00:14  loss: 0.8056 (0.8031)  time: 0.0877  data: 0.0001  max mem: 10917
[12:16:49.356899] Test:  [190/345]  eta: 0:00:13  loss: 0.8056 (0.8035)  time: 0.0881  data: 0.0001  max mem: 10917
[12:16:50.242857] Test:  [200/345]  eta: 0:00:12  loss: 0.8058 (0.8034)  time: 0.0884  data: 0.0001  max mem: 10917
[12:16:51.133500] Test:  [210/345]  eta: 0:00:11  loss: 0.8002 (0.8035)  time: 0.0888  data: 0.0001  max mem: 10917
[12:16:52.026923] Test:  [220/345]  eta: 0:00:10  loss: 0.7984 (0.8032)  time: 0.0892  data: 0.0001  max mem: 10917
[12:16:52.923800] Test:  [230/345]  eta: 0:00:09  loss: 0.8035 (0.8038)  time: 0.0895  data: 0.0001  max mem: 10917
[12:16:53.825061] Test:  [240/345]  eta: 0:00:09  loss: 0.8027 (0.8031)  time: 0.0899  data: 0.0001  max mem: 10917
[12:16:54.728805] Test:  [250/345]  eta: 0:00:08  loss: 0.7954 (0.8032)  time: 0.0902  data: 0.0001  max mem: 10917
[12:16:55.636469] Test:  [260/345]  eta: 0:00:07  loss: 0.8040 (0.8031)  time: 0.0905  data: 0.0001  max mem: 10917
[12:16:56.547853] Test:  [270/345]  eta: 0:00:06  loss: 0.8065 (0.8031)  time: 0.0909  data: 0.0001  max mem: 10917
[12:16:57.461904] Test:  [280/345]  eta: 0:00:05  loss: 0.8078 (0.8032)  time: 0.0912  data: 0.0001  max mem: 10917
[12:16:58.379429] Test:  [290/345]  eta: 0:00:04  loss: 0.8036 (0.8031)  time: 0.0915  data: 0.0001  max mem: 10917
[12:16:59.301393] Test:  [300/345]  eta: 0:00:03  loss: 0.8007 (0.8030)  time: 0.0919  data: 0.0001  max mem: 10917
[12:17:00.226232] Test:  [310/345]  eta: 0:00:03  loss: 0.8007 (0.8030)  time: 0.0923  data: 0.0001  max mem: 10917
[12:17:01.154593] Test:  [320/345]  eta: 0:00:02  loss: 0.8028 (0.8030)  time: 0.0926  data: 0.0001  max mem: 10917
[12:17:02.086687] Test:  [330/345]  eta: 0:00:01  loss: 0.8042 (0.8032)  time: 0.0930  data: 0.0001  max mem: 10917
[12:17:03.021953] Test:  [340/345]  eta: 0:00:00  loss: 0.8046 (0.8032)  time: 0.0933  data: 0.0001  max mem: 10917
[12:17:03.397542] Test:  [344/345]  eta: 0:00:00  loss: 0.8046 (0.8031)  time: 0.0935  data: 0.0001  max mem: 10917
[12:17:03.456465] Test: Total time: 0:00:30 (0.0884 s / it)
[12:17:14.381275] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8893 (0.8893)  time: 0.2239  data: 0.1440  max mem: 10917
[12:17:15.194898] Test:  [10/57]  eta: 0:00:04  loss: 0.8910 (0.9053)  time: 0.0943  data: 0.0131  max mem: 10917
[12:17:16.011534] Test:  [20/57]  eta: 0:00:03  loss: 0.8936 (0.8972)  time: 0.0815  data: 0.0001  max mem: 10917
[12:17:16.831564] Test:  [30/57]  eta: 0:00:02  loss: 0.7849 (0.8558)  time: 0.0818  data: 0.0001  max mem: 10917
[12:17:17.655702] Test:  [40/57]  eta: 0:00:01  loss: 0.7745 (0.8320)  time: 0.0822  data: 0.0001  max mem: 10917
[12:17:18.483663] Test:  [50/57]  eta: 0:00:00  loss: 0.7709 (0.8243)  time: 0.0826  data: 0.0001  max mem: 10917
[12:17:18.933519] Test:  [56/57]  eta: 0:00:00  loss: 0.7915 (0.8283)  time: 0.0803  data: 0.0001  max mem: 10917
[12:17:18.988546] Test: Total time: 0:00:04 (0.0848 s / it)
[12:17:20.848019] Dice score of the network on the train images: 0.768881, val images: 0.810531
[12:17:20.848256] saving best_dice_model_0 @ epoch 11
[12:17:21.712677] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:17:22.115799] Epoch: [12]  [  0/345]  eta: 0:02:18  lr: 0.000075  loss: 0.8019 (0.8019)  time: 0.4022  data: 0.1506  max mem: 10917
[12:17:27.112949] Epoch: [12]  [ 20/345]  eta: 0:01:23  lr: 0.000075  loss: 0.8198 (0.8303)  time: 0.2498  data: 0.0001  max mem: 10917
[12:17:32.111573] Epoch: [12]  [ 40/345]  eta: 0:01:17  lr: 0.000076  loss: 0.8407 (0.8343)  time: 0.2499  data: 0.0000  max mem: 10917
[12:17:37.112152] Epoch: [12]  [ 60/345]  eta: 0:01:11  lr: 0.000076  loss: 0.8482 (0.8373)  time: 0.2500  data: 0.0000  max mem: 10917
[12:17:42.131458] Epoch: [12]  [ 80/345]  eta: 0:01:06  lr: 0.000076  loss: 0.8349 (0.8364)  time: 0.2509  data: 0.0001  max mem: 10917
[12:17:47.151310] Epoch: [12]  [100/345]  eta: 0:01:01  lr: 0.000077  loss: 0.8296 (0.8356)  time: 0.2510  data: 0.0000  max mem: 10917
[12:17:52.170879] Epoch: [12]  [120/345]  eta: 0:00:56  lr: 0.000077  loss: 0.8385 (0.8356)  time: 0.2509  data: 0.0000  max mem: 10917
[12:17:57.193774] Epoch: [12]  [140/345]  eta: 0:00:51  lr: 0.000078  loss: 0.8384 (0.8364)  time: 0.2511  data: 0.0000  max mem: 10917
[12:18:02.218848] Epoch: [12]  [160/345]  eta: 0:00:46  lr: 0.000078  loss: 0.8379 (0.8362)  time: 0.2512  data: 0.0000  max mem: 10917
[12:18:07.247842] Epoch: [12]  [180/345]  eta: 0:00:41  lr: 0.000078  loss: 0.8246 (0.8354)  time: 0.2514  data: 0.0000  max mem: 10917
[12:18:12.274716] Epoch: [12]  [200/345]  eta: 0:00:36  lr: 0.000079  loss: 0.8220 (0.8346)  time: 0.2513  data: 0.0001  max mem: 10917
[12:18:17.305988] Epoch: [12]  [220/345]  eta: 0:00:31  lr: 0.000079  loss: 0.8435 (0.8347)  time: 0.2515  data: 0.0000  max mem: 10917
[12:18:22.340008] Epoch: [12]  [240/345]  eta: 0:00:26  lr: 0.000079  loss: 0.8333 (0.8349)  time: 0.2517  data: 0.0000  max mem: 10917
[12:18:27.375733] Epoch: [12]  [260/345]  eta: 0:00:21  lr: 0.000080  loss: 0.8465 (0.8357)  time: 0.2517  data: 0.0000  max mem: 10917
[12:18:32.410425] Epoch: [12]  [280/345]  eta: 0:00:16  lr: 0.000080  loss: 0.8179 (0.8350)  time: 0.2517  data: 0.0000  max mem: 10917
[12:18:37.447562] Epoch: [12]  [300/345]  eta: 0:00:11  lr: 0.000080  loss: 0.8227 (0.8343)  time: 0.2518  data: 0.0001  max mem: 10917
[12:18:42.490391] Epoch: [12]  [320/345]  eta: 0:00:06  lr: 0.000081  loss: 0.8426 (0.8346)  time: 0.2521  data: 0.0001  max mem: 10917
[12:18:47.532318] Epoch: [12]  [340/345]  eta: 0:00:01  lr: 0.000081  loss: 0.8349 (0.8349)  time: 0.2521  data: 0.0000  max mem: 10917
[12:18:48.539818] Epoch: [12]  [344/345]  eta: 0:00:00  lr: 0.000081  loss: 0.8342 (0.8349)  time: 0.2520  data: 0.0001  max mem: 10917
[12:18:48.600059] Epoch: [12] Total time: 0:01:26 (0.2518 s / it)
[12:18:48.600565] Averaged stats: lr: 0.000081  loss: 0.8342 (0.8349)
[12:18:48.839665] Test:  [  0/345]  eta: 0:01:21  loss: 0.7662 (0.7662)  time: 0.2354  data: 0.1553  max mem: 10917
[12:18:49.676836] Test:  [ 10/345]  eta: 0:00:32  loss: 0.8154 (0.8107)  time: 0.0974  data: 0.0158  max mem: 10917
[12:18:50.500273] Test:  [ 20/345]  eta: 0:00:29  loss: 0.8074 (0.8042)  time: 0.0830  data: 0.0010  max mem: 10917
[12:18:51.327704] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7955 (0.8044)  time: 0.0825  data: 0.0001  max mem: 10917
[12:18:52.157308] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8068 (0.8044)  time: 0.0828  data: 0.0001  max mem: 10917
[12:18:52.991601] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8077 (0.8053)  time: 0.0831  data: 0.0001  max mem: 10917
[12:18:53.829531] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8032 (0.8047)  time: 0.0836  data: 0.0001  max mem: 10917
[12:18:54.670557] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7965 (0.8050)  time: 0.0839  data: 0.0001  max mem: 10917
[12:18:55.514356] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7953 (0.8041)  time: 0.0842  data: 0.0001  max mem: 10917
[12:18:56.363106] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8015 (0.8052)  time: 0.0846  data: 0.0001  max mem: 10917
[12:18:57.214391] Test:  [100/345]  eta: 0:00:20  loss: 0.8154 (0.8063)  time: 0.0850  data: 0.0001  max mem: 10917
[12:18:58.069377] Test:  [110/345]  eta: 0:00:20  loss: 0.8057 (0.8062)  time: 0.0853  data: 0.0001  max mem: 10917
[12:18:58.928733] Test:  [120/345]  eta: 0:00:19  loss: 0.8037 (0.8063)  time: 0.0857  data: 0.0001  max mem: 10917
[12:18:59.790903] Test:  [130/345]  eta: 0:00:18  loss: 0.8066 (0.8063)  time: 0.0860  data: 0.0001  max mem: 10917
[12:19:00.656966] Test:  [140/345]  eta: 0:00:17  loss: 0.7984 (0.8062)  time: 0.0864  data: 0.0001  max mem: 10917
[12:19:01.526876] Test:  [150/345]  eta: 0:00:16  loss: 0.7984 (0.8065)  time: 0.0868  data: 0.0001  max mem: 10917
[12:19:02.399511] Test:  [160/345]  eta: 0:00:15  loss: 0.7996 (0.8064)  time: 0.0871  data: 0.0001  max mem: 10917
[12:19:03.276792] Test:  [170/345]  eta: 0:00:15  loss: 0.7996 (0.8066)  time: 0.0874  data: 0.0001  max mem: 10917
[12:19:04.156157] Test:  [180/345]  eta: 0:00:14  loss: 0.8105 (0.8071)  time: 0.0878  data: 0.0001  max mem: 10917
[12:19:05.039044] Test:  [190/345]  eta: 0:00:13  loss: 0.8027 (0.8069)  time: 0.0881  data: 0.0001  max mem: 10917
[12:19:05.926378] Test:  [200/345]  eta: 0:00:12  loss: 0.7968 (0.8066)  time: 0.0885  data: 0.0001  max mem: 10917
[12:19:06.816617] Test:  [210/345]  eta: 0:00:11  loss: 0.7998 (0.8066)  time: 0.0888  data: 0.0001  max mem: 10917
[12:19:07.709648] Test:  [220/345]  eta: 0:00:10  loss: 0.8066 (0.8071)  time: 0.0891  data: 0.0001  max mem: 10917
[12:19:08.607579] Test:  [230/345]  eta: 0:00:09  loss: 0.8085 (0.8073)  time: 0.0895  data: 0.0001  max mem: 10917
[12:19:09.509028] Test:  [240/345]  eta: 0:00:09  loss: 0.8065 (0.8073)  time: 0.0899  data: 0.0001  max mem: 10917
[12:19:10.413593] Test:  [250/345]  eta: 0:00:08  loss: 0.8001 (0.8070)  time: 0.0903  data: 0.0001  max mem: 10917
[12:19:11.321610] Test:  [260/345]  eta: 0:00:07  loss: 0.7943 (0.8067)  time: 0.0906  data: 0.0001  max mem: 10917
[12:19:12.232916] Test:  [270/345]  eta: 0:00:06  loss: 0.8123 (0.8071)  time: 0.0909  data: 0.0001  max mem: 10917
[12:19:13.147120] Test:  [280/345]  eta: 0:00:05  loss: 0.8151 (0.8073)  time: 0.0912  data: 0.0001  max mem: 10917
[12:19:14.064761] Test:  [290/345]  eta: 0:00:04  loss: 0.8159 (0.8075)  time: 0.0915  data: 0.0001  max mem: 10917
[12:19:14.986969] Test:  [300/345]  eta: 0:00:03  loss: 0.8121 (0.8077)  time: 0.0919  data: 0.0001  max mem: 10917
[12:19:15.912110] Test:  [310/345]  eta: 0:00:03  loss: 0.8117 (0.8076)  time: 0.0923  data: 0.0001  max mem: 10917
[12:19:16.839995] Test:  [320/345]  eta: 0:00:02  loss: 0.8018 (0.8076)  time: 0.0926  data: 0.0001  max mem: 10917
[12:19:17.772665] Test:  [330/345]  eta: 0:00:01  loss: 0.8020 (0.8075)  time: 0.0930  data: 0.0001  max mem: 10917
[12:19:18.707699] Test:  [340/345]  eta: 0:00:00  loss: 0.8044 (0.8076)  time: 0.0933  data: 0.0001  max mem: 10917
[12:19:19.083324] Test:  [344/345]  eta: 0:00:00  loss: 0.8044 (0.8075)  time: 0.0935  data: 0.0001  max mem: 10917
[12:19:19.136007] Test: Total time: 0:00:30 (0.0885 s / it)
[12:19:30.058535] Test:  [ 0/57]  eta: 0:00:12  loss: 0.9398 (0.9398)  time: 0.2238  data: 0.1439  max mem: 10917
[12:19:30.870683] Test:  [10/57]  eta: 0:00:04  loss: 0.9398 (0.9235)  time: 0.0941  data: 0.0131  max mem: 10917
[12:19:31.686115] Test:  [20/57]  eta: 0:00:03  loss: 0.9250 (0.9082)  time: 0.0813  data: 0.0001  max mem: 10917
[12:19:32.506205] Test:  [30/57]  eta: 0:00:02  loss: 0.7996 (0.8658)  time: 0.0817  data: 0.0001  max mem: 10917
[12:19:33.329445] Test:  [40/57]  eta: 0:00:01  loss: 0.7804 (0.8427)  time: 0.0821  data: 0.0001  max mem: 10917
[12:19:34.157092] Test:  [50/57]  eta: 0:00:00  loss: 0.7723 (0.8342)  time: 0.0825  data: 0.0001  max mem: 10917
[12:19:34.606463] Test:  [56/57]  eta: 0:00:00  loss: 0.7908 (0.8362)  time: 0.0803  data: 0.0001  max mem: 10917
[12:19:34.665257] Test: Total time: 0:00:04 (0.0848 s / it)
[12:19:36.573369] Dice score of the network on the train images: 0.765347, val images: 0.802287
[12:19:36.577047] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:19:36.981498] Epoch: [13]  [  0/345]  eta: 0:02:19  lr: 0.000081  loss: 0.8513 (0.8513)  time: 0.4034  data: 0.1513  max mem: 10917
[12:19:41.985963] Epoch: [13]  [ 20/345]  eta: 0:01:23  lr: 0.000082  loss: 0.8594 (0.8602)  time: 0.2502  data: 0.0001  max mem: 10917
[12:19:47.001252] Epoch: [13]  [ 40/345]  eta: 0:01:17  lr: 0.000082  loss: 0.8338 (0.8489)  time: 0.2507  data: 0.0001  max mem: 10917
[12:19:52.014695] Epoch: [13]  [ 60/345]  eta: 0:01:12  lr: 0.000082  loss: 0.8369 (0.8461)  time: 0.2506  data: 0.0001  max mem: 10917
[12:19:57.034666] Epoch: [13]  [ 80/345]  eta: 0:01:06  lr: 0.000083  loss: 0.8296 (0.8430)  time: 0.2510  data: 0.0001  max mem: 10917
[12:20:02.061907] Epoch: [13]  [100/345]  eta: 0:01:01  lr: 0.000083  loss: 0.8318 (0.8412)  time: 0.2513  data: 0.0001  max mem: 10917
[12:20:07.090595] Epoch: [13]  [120/345]  eta: 0:00:56  lr: 0.000083  loss: 0.8285 (0.8402)  time: 0.2514  data: 0.0001  max mem: 10917
[12:20:12.118197] Epoch: [13]  [140/345]  eta: 0:00:51  lr: 0.000084  loss: 0.8314 (0.8388)  time: 0.2513  data: 0.0000  max mem: 10917
[12:20:17.151304] Epoch: [13]  [160/345]  eta: 0:00:46  lr: 0.000084  loss: 0.8226 (0.8373)  time: 0.2516  data: 0.0001  max mem: 10917
[12:20:22.183596] Epoch: [13]  [180/345]  eta: 0:00:41  lr: 0.000085  loss: 0.8272 (0.8361)  time: 0.2516  data: 0.0001  max mem: 10917
[12:20:27.211866] Epoch: [13]  [200/345]  eta: 0:00:36  lr: 0.000085  loss: 0.8247 (0.8348)  time: 0.2514  data: 0.0000  max mem: 10917
[12:20:32.245375] Epoch: [13]  [220/345]  eta: 0:00:31  lr: 0.000085  loss: 0.8238 (0.8337)  time: 0.2516  data: 0.0001  max mem: 10917
[12:20:37.282982] Epoch: [13]  [240/345]  eta: 0:00:26  lr: 0.000086  loss: 0.8275 (0.8332)  time: 0.2518  data: 0.0000  max mem: 10917
[12:20:42.326024] Epoch: [13]  [260/345]  eta: 0:00:21  lr: 0.000086  loss: 0.8377 (0.8336)  time: 0.2521  data: 0.0001  max mem: 10917
[12:20:47.372501] Epoch: [13]  [280/345]  eta: 0:00:16  lr: 0.000086  loss: 0.8331 (0.8336)  time: 0.2523  data: 0.0001  max mem: 10917
[12:20:52.420728] Epoch: [13]  [300/345]  eta: 0:00:11  lr: 0.000087  loss: 0.8423 (0.8340)  time: 0.2524  data: 0.0001  max mem: 10917
[12:20:57.469190] Epoch: [13]  [320/345]  eta: 0:00:06  lr: 0.000087  loss: 0.8346 (0.8342)  time: 0.2524  data: 0.0001  max mem: 10917
[12:21:02.597419] Epoch: [13]  [340/345]  eta: 0:00:01  lr: 0.000087  loss: 0.8285 (0.8337)  time: 0.2564  data: 0.0001  max mem: 10917
[12:21:03.606385] Epoch: [13]  [344/345]  eta: 0:00:00  lr: 0.000087  loss: 0.8277 (0.8334)  time: 0.2563  data: 0.0001  max mem: 10917
[12:21:03.669778] Epoch: [13] Total time: 0:01:27 (0.2524 s / it)
[12:21:03.670185] Averaged stats: lr: 0.000087  loss: 0.8277 (0.8334)
[12:21:03.910731] Test:  [  0/345]  eta: 0:01:21  loss: 0.7833 (0.7833)  time: 0.2370  data: 0.1567  max mem: 10917
[12:21:04.738637] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7867 (0.7918)  time: 0.0967  data: 0.0149  max mem: 10917
[12:21:05.561401] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7867 (0.7917)  time: 0.0824  data: 0.0004  max mem: 10917
[12:21:06.387840] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7981 (0.7957)  time: 0.0824  data: 0.0001  max mem: 10917
[12:21:07.218309] Test:  [ 40/345]  eta: 0:00:26  loss: 0.8016 (0.7955)  time: 0.0828  data: 0.0001  max mem: 10917
[12:21:08.051269] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7945 (0.7950)  time: 0.0831  data: 0.0001  max mem: 10917
[12:21:08.888826] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8021 (0.7981)  time: 0.0835  data: 0.0001  max mem: 10917
[12:21:09.729850] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8075 (0.7983)  time: 0.0839  data: 0.0001  max mem: 10917
[12:21:10.573938] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7989 (0.7984)  time: 0.0842  data: 0.0001  max mem: 10917
[12:21:11.422196] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7846 (0.7974)  time: 0.0846  data: 0.0001  max mem: 10917
[12:21:12.273820] Test:  [100/345]  eta: 0:00:20  loss: 0.7824 (0.7970)  time: 0.0849  data: 0.0001  max mem: 10917
[12:21:13.129059] Test:  [110/345]  eta: 0:00:20  loss: 0.8065 (0.7979)  time: 0.0853  data: 0.0001  max mem: 10917
[12:21:13.987873] Test:  [120/345]  eta: 0:00:19  loss: 0.7960 (0.7964)  time: 0.0857  data: 0.0001  max mem: 10917
[12:21:14.849195] Test:  [130/345]  eta: 0:00:18  loss: 0.7846 (0.7961)  time: 0.0860  data: 0.0001  max mem: 10917
[12:21:15.713878] Test:  [140/345]  eta: 0:00:17  loss: 0.7871 (0.7956)  time: 0.0863  data: 0.0001  max mem: 10917
[12:21:16.583083] Test:  [150/345]  eta: 0:00:16  loss: 0.7861 (0.7955)  time: 0.0866  data: 0.0001  max mem: 10917
[12:21:17.454829] Test:  [160/345]  eta: 0:00:15  loss: 0.7838 (0.7946)  time: 0.0870  data: 0.0001  max mem: 10917
[12:21:18.330682] Test:  [170/345]  eta: 0:00:14  loss: 0.7880 (0.7948)  time: 0.0873  data: 0.0001  max mem: 10917
[12:21:19.210998] Test:  [180/345]  eta: 0:00:14  loss: 0.7954 (0.7949)  time: 0.0878  data: 0.0001  max mem: 10917
[12:21:20.094447] Test:  [190/345]  eta: 0:00:13  loss: 0.7891 (0.7942)  time: 0.0881  data: 0.0001  max mem: 10917
[12:21:20.980214] Test:  [200/345]  eta: 0:00:12  loss: 0.7764 (0.7937)  time: 0.0884  data: 0.0001  max mem: 10917
[12:21:21.869933] Test:  [210/345]  eta: 0:00:11  loss: 0.7783 (0.7932)  time: 0.0887  data: 0.0001  max mem: 10917
[12:21:22.763118] Test:  [220/345]  eta: 0:00:10  loss: 0.7783 (0.7927)  time: 0.0891  data: 0.0001  max mem: 10917
[12:21:23.659939] Test:  [230/345]  eta: 0:00:09  loss: 0.7847 (0.7925)  time: 0.0895  data: 0.0001  max mem: 10917
[12:21:24.559842] Test:  [240/345]  eta: 0:00:09  loss: 0.7910 (0.7925)  time: 0.0898  data: 0.0001  max mem: 10917
[12:21:25.463088] Test:  [250/345]  eta: 0:00:08  loss: 0.7942 (0.7928)  time: 0.0901  data: 0.0001  max mem: 10917
[12:21:26.370119] Test:  [260/345]  eta: 0:00:07  loss: 0.7907 (0.7925)  time: 0.0905  data: 0.0001  max mem: 10917
[12:21:27.281051] Test:  [270/345]  eta: 0:00:06  loss: 0.7865 (0.7924)  time: 0.0909  data: 0.0001  max mem: 10917
[12:21:28.194717] Test:  [280/345]  eta: 0:00:05  loss: 0.7920 (0.7926)  time: 0.0912  data: 0.0001  max mem: 10917
[12:21:29.112284] Test:  [290/345]  eta: 0:00:04  loss: 0.7902 (0.7923)  time: 0.0915  data: 0.0001  max mem: 10917
[12:21:30.034449] Test:  [300/345]  eta: 0:00:03  loss: 0.7774 (0.7921)  time: 0.0919  data: 0.0001  max mem: 10917
[12:21:30.958549] Test:  [310/345]  eta: 0:00:03  loss: 0.7804 (0.7919)  time: 0.0923  data: 0.0001  max mem: 10917
[12:21:31.886772] Test:  [320/345]  eta: 0:00:02  loss: 0.7996 (0.7922)  time: 0.0926  data: 0.0001  max mem: 10917
[12:21:32.818716] Test:  [330/345]  eta: 0:00:01  loss: 0.7981 (0.7919)  time: 0.0930  data: 0.0001  max mem: 10917
[12:21:33.754131] Test:  [340/345]  eta: 0:00:00  loss: 0.7889 (0.7919)  time: 0.0933  data: 0.0001  max mem: 10917
[12:21:34.130029] Test:  [344/345]  eta: 0:00:00  loss: 0.7805 (0.7917)  time: 0.0935  data: 0.0001  max mem: 10917
[12:21:34.187264] Test: Total time: 0:00:30 (0.0884 s / it)
[12:21:44.955237] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8847 (0.8847)  time: 0.2234  data: 0.1434  max mem: 10917
[12:21:45.769633] Test:  [10/57]  eta: 0:00:04  loss: 0.8847 (0.8968)  time: 0.0943  data: 0.0131  max mem: 10917
[12:21:46.585743] Test:  [20/57]  eta: 0:00:03  loss: 0.8862 (0.8864)  time: 0.0815  data: 0.0001  max mem: 10917
[12:21:47.406837] Test:  [30/57]  eta: 0:00:02  loss: 0.7781 (0.8493)  time: 0.0818  data: 0.0001  max mem: 10917
[12:21:48.231341] Test:  [40/57]  eta: 0:00:01  loss: 0.7702 (0.8264)  time: 0.0822  data: 0.0001  max mem: 10917
[12:21:49.059048] Test:  [50/57]  eta: 0:00:00  loss: 0.7516 (0.8172)  time: 0.0826  data: 0.0001  max mem: 10917
[12:21:49.508929] Test:  [56/57]  eta: 0:00:00  loss: 0.7797 (0.8211)  time: 0.0804  data: 0.0001  max mem: 10917
[12:21:49.565822] Test: Total time: 0:00:04 (0.0848 s / it)
[12:21:51.403139] Dice score of the network on the train images: 0.766934, val images: 0.809289
[12:21:51.406855] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:21:51.814561] Epoch: [14]  [  0/345]  eta: 0:02:20  lr: 0.000087  loss: 0.7903 (0.7903)  time: 0.4067  data: 0.1540  max mem: 10917
[12:21:56.818853] Epoch: [14]  [ 20/345]  eta: 0:01:23  lr: 0.000088  loss: 0.8187 (0.8167)  time: 0.2502  data: 0.0001  max mem: 10917
[12:22:01.824964] Epoch: [14]  [ 40/345]  eta: 0:01:17  lr: 0.000088  loss: 0.8233 (0.8226)  time: 0.2503  data: 0.0001  max mem: 10917
[12:22:06.828438] Epoch: [14]  [ 60/345]  eta: 0:01:12  lr: 0.000089  loss: 0.8154 (0.8214)  time: 0.2501  data: 0.0001  max mem: 10917
[12:22:11.829077] Epoch: [14]  [ 80/345]  eta: 0:01:06  lr: 0.000089  loss: 0.8143 (0.8197)  time: 0.2500  data: 0.0001  max mem: 10917
[12:22:16.835268] Epoch: [14]  [100/345]  eta: 0:01:01  lr: 0.000089  loss: 0.8163 (0.8204)  time: 0.2503  data: 0.0001  max mem: 10917
[12:22:21.854023] Epoch: [14]  [120/345]  eta: 0:00:56  lr: 0.000090  loss: 0.8185 (0.8206)  time: 0.2509  data: 0.0001  max mem: 10917

[12:22:26.871643] Epoch: [14]  [140/345]  eta: 0:00:51  lr: 0.000090  loss: 0.8129 (0.8195)  time: 0.2508  data: 0.0001  max mem: 10917
[12:22:31.894750] Epoch: [14]  [160/345]  eta: 0:00:46  lr: 0.000090  loss: 0.8243 (0.8200)  time: 0.2511  data: 0.0000  max mem: 10917
[12:22:36.914627] Epoch: [14]  [180/345]  eta: 0:00:41  lr: 0.000091  loss: 0.8349 (0.8221)  time: 0.2509  data: 0.0001  max mem: 10917
[12:22:41.938593] Epoch: [14]  [200/345]  eta: 0:00:36  lr: 0.000091  loss: 0.8298 (0.8226)  time: 0.2512  data: 0.0001  max mem: 10917
[12:22:46.970183] Epoch: [14]  [220/345]  eta: 0:00:31  lr: 0.000091  loss: 0.8449 (0.8251)  time: 0.2515  data: 0.0000  max mem: 10917
[12:22:52.004808] Epoch: [14]  [240/345]  eta: 0:00:26  lr: 0.000092  loss: 0.8364 (0.8258)  time: 0.2517  data: 0.0000  max mem: 10917
[12:22:57.040322] Epoch: [14]  [260/345]  eta: 0:00:21  lr: 0.000092  loss: 0.8256 (0.8259)  time: 0.2517  data: 0.0000  max mem: 10917
[12:23:02.077898] Epoch: [14]  [280/345]  eta: 0:00:16  lr: 0.000093  loss: 0.8250 (0.8259)  time: 0.2518  data: 0.0000  max mem: 10917
[12:23:07.112142] Epoch: [14]  [300/345]  eta: 0:00:11  lr: 0.000093  loss: 0.8295 (0.8264)  time: 0.2517  data: 0.0000  max mem: 10917
[12:23:12.163525] Epoch: [14]  [320/345]  eta: 0:00:06  lr: 0.000093  loss: 0.8274 (0.8263)  time: 0.2525  data: 0.0001  max mem: 10917
[12:23:17.205259] Epoch: [14]  [340/345]  eta: 0:00:01  lr: 0.000094  loss: 0.8122 (0.8258)  time: 0.2520  data: 0.0001  max mem: 10917
[12:23:18.213083] Epoch: [14]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.8122 (0.8259)  time: 0.2519  data: 0.0001  max mem: 10917
[12:23:18.271802] Epoch: [14] Total time: 0:01:26 (0.2518 s / it)
[12:23:18.272181] Averaged stats: lr: 0.000094  loss: 0.8122 (0.8259)
[12:23:18.518343] Test:  [  0/345]  eta: 0:01:23  loss: 0.7663 (0.7663)  time: 0.2424  data: 0.1624  max mem: 10917
[12:23:19.356569] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7833 (0.7883)  time: 0.0982  data: 0.0165  max mem: 10917
[12:23:20.180391] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7863 (0.7878)  time: 0.0830  data: 0.0010  max mem: 10917
[12:23:21.007061] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7830 (0.7843)  time: 0.0825  data: 0.0001  max mem: 10917
[12:23:21.837141] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7741 (0.7843)  time: 0.0828  data: 0.0001  max mem: 10917
[12:23:22.669965] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7823 (0.7850)  time: 0.0831  data: 0.0001  max mem: 10917
[12:23:23.507942] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7889 (0.7866)  time: 0.0835  data: 0.0001  max mem: 10917
[12:23:24.348652] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7843 (0.7857)  time: 0.0839  data: 0.0001  max mem: 10917
[12:23:25.193062] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7842 (0.7869)  time: 0.0842  data: 0.0001  max mem: 10917
[12:23:26.042015] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7807 (0.7862)  time: 0.0846  data: 0.0001  max mem: 10917
[12:23:26.892766] Test:  [100/345]  eta: 0:00:20  loss: 0.7828 (0.7865)  time: 0.0849  data: 0.0001  max mem: 10917
[12:23:27.747746] Test:  [110/345]  eta: 0:00:20  loss: 0.7878 (0.7873)  time: 0.0852  data: 0.0001  max mem: 10917
[12:23:28.606425] Test:  [120/345]  eta: 0:00:19  loss: 0.7926 (0.7881)  time: 0.0856  data: 0.0001  max mem: 10917
[12:23:29.468726] Test:  [130/345]  eta: 0:00:18  loss: 0.7965 (0.7888)  time: 0.0860  data: 0.0001  max mem: 10917
[12:23:30.334055] Test:  [140/345]  eta: 0:00:17  loss: 0.7837 (0.7882)  time: 0.0863  data: 0.0001  max mem: 10917
[12:23:31.203345] Test:  [150/345]  eta: 0:00:16  loss: 0.7827 (0.7888)  time: 0.0867  data: 0.0001  max mem: 10917
[12:23:32.074840] Test:  [160/345]  eta: 0:00:15  loss: 0.7885 (0.7885)  time: 0.0870  data: 0.0001  max mem: 10917
[12:23:32.950566] Test:  [170/345]  eta: 0:00:15  loss: 0.7844 (0.7883)  time: 0.0873  data: 0.0001  max mem: 10917
[12:23:33.830180] Test:  [180/345]  eta: 0:00:14  loss: 0.7898 (0.7884)  time: 0.0877  data: 0.0001  max mem: 10917
[12:23:34.712820] Test:  [190/345]  eta: 0:00:13  loss: 0.7819 (0.7881)  time: 0.0881  data: 0.0001  max mem: 10917
[12:23:35.599269] Test:  [200/345]  eta: 0:00:12  loss: 0.7819 (0.7879)  time: 0.0884  data: 0.0001  max mem: 10917
[12:23:36.488803] Test:  [210/345]  eta: 0:00:11  loss: 0.7876 (0.7879)  time: 0.0888  data: 0.0001  max mem: 10917
[12:23:37.382157] Test:  [220/345]  eta: 0:00:10  loss: 0.7787 (0.7880)  time: 0.0891  data: 0.0001  max mem: 10917
[12:23:38.279427] Test:  [230/345]  eta: 0:00:09  loss: 0.7787 (0.7880)  time: 0.0895  data: 0.0001  max mem: 10917
[12:23:39.181022] Test:  [240/345]  eta: 0:00:09  loss: 0.7911 (0.7887)  time: 0.0899  data: 0.0001  max mem: 10917
[12:23:40.085390] Test:  [250/345]  eta: 0:00:08  loss: 0.7947 (0.7889)  time: 0.0902  data: 0.0001  max mem: 10917
[12:23:40.992603] Test:  [260/345]  eta: 0:00:07  loss: 0.7930 (0.7890)  time: 0.0905  data: 0.0001  max mem: 10917
[12:23:41.905051] Test:  [270/345]  eta: 0:00:06  loss: 0.7902 (0.7891)  time: 0.0909  data: 0.0001  max mem: 10917
[12:23:42.819057] Test:  [280/345]  eta: 0:00:05  loss: 0.7867 (0.7890)  time: 0.0913  data: 0.0001  max mem: 10917
[12:23:43.737010] Test:  [290/345]  eta: 0:00:04  loss: 0.7790 (0.7886)  time: 0.0916  data: 0.0001  max mem: 10917
[12:23:44.658358] Test:  [300/345]  eta: 0:00:03  loss: 0.7823 (0.7889)  time: 0.0919  data: 0.0001  max mem: 10917
[12:23:45.583273] Test:  [310/345]  eta: 0:00:03  loss: 0.7943 (0.7887)  time: 0.0923  data: 0.0001  max mem: 10917
[12:23:46.511326] Test:  [320/345]  eta: 0:00:02  loss: 0.7816 (0.7885)  time: 0.0926  data: 0.0001  max mem: 10917
[12:23:47.444003] Test:  [330/345]  eta: 0:00:01  loss: 0.7849 (0.7886)  time: 0.0930  data: 0.0001  max mem: 10917
[12:23:48.379599] Test:  [340/345]  eta: 0:00:00  loss: 0.7859 (0.7885)  time: 0.0934  data: 0.0001  max mem: 10917
[12:23:48.755312] Test:  [344/345]  eta: 0:00:00  loss: 0.7916 (0.7887)  time: 0.0935  data: 0.0001  max mem: 10917
[12:23:48.813240] Test: Total time: 0:00:30 (0.0885 s / it)
[12:23:59.705358] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8696 (0.8696)  time: 0.2237  data: 0.1437  max mem: 10917
[12:24:00.518837] Test:  [10/57]  eta: 0:00:04  loss: 0.8804 (0.8926)  time: 0.0942  data: 0.0132  max mem: 10917
[12:24:01.335553] Test:  [20/57]  eta: 0:00:03  loss: 0.8860 (0.8847)  time: 0.0814  data: 0.0001  max mem: 10917
[12:24:02.156459] Test:  [30/57]  eta: 0:00:02  loss: 0.7794 (0.8471)  time: 0.0818  data: 0.0001  max mem: 10917
[12:24:02.981229] Test:  [40/57]  eta: 0:00:01  loss: 0.7659 (0.8257)  time: 0.0822  data: 0.0001  max mem: 10917
[12:24:03.809332] Test:  [50/57]  eta: 0:00:00  loss: 0.7556 (0.8172)  time: 0.0826  data: 0.0001  max mem: 10917
[12:24:04.259768] Test:  [56/57]  eta: 0:00:00  loss: 0.7851 (0.8221)  time: 0.0804  data: 0.0001  max mem: 10917
[12:24:04.315740] Test: Total time: 0:00:04 (0.0848 s / it)
[12:24:06.194995] Dice score of the network on the train images: 0.771461, val images: 0.812618
[12:24:06.195204] saving best_dice_model_0 @ epoch 14
[12:24:07.051423] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:24:07.452855] Epoch: [15]  [  0/345]  eta: 0:02:18  lr: 0.000094  loss: 0.7866 (0.7866)  time: 0.4003  data: 0.1492  max mem: 10917
[12:24:12.435829] Epoch: [15]  [ 20/345]  eta: 0:01:23  lr: 0.000094  loss: 0.8191 (0.8181)  time: 0.2491  data: 0.0001  max mem: 10917
[12:24:17.426530] Epoch: [15]  [ 40/345]  eta: 0:01:17  lr: 0.000094  loss: 0.8157 (0.8166)  time: 0.2495  data: 0.0001  max mem: 10917
[12:24:22.415612] Epoch: [15]  [ 60/345]  eta: 0:01:11  lr: 0.000095  loss: 0.8000 (0.8125)  time: 0.2494  data: 0.0001  max mem: 10917
[12:24:27.420059] Epoch: [15]  [ 80/345]  eta: 0:01:06  lr: 0.000095  loss: 0.8104 (0.8132)  time: 0.2502  data: 0.0000  max mem: 10917
[12:24:32.434135] Epoch: [15]  [100/345]  eta: 0:01:01  lr: 0.000096  loss: 0.8315 (0.8172)  time: 0.2507  data: 0.0000  max mem: 10917
[12:24:37.454487] Epoch: [15]  [120/345]  eta: 0:00:56  lr: 0.000096  loss: 0.8281 (0.8189)  time: 0.2510  data: 0.0000  max mem: 10917
[12:24:42.475972] Epoch: [15]  [140/345]  eta: 0:00:51  lr: 0.000096  loss: 0.8279 (0.8202)  time: 0.2510  data: 0.0000  max mem: 10917
[12:24:47.499324] Epoch: [15]  [160/345]  eta: 0:00:46  lr: 0.000097  loss: 0.8105 (0.8194)  time: 0.2511  data: 0.0001  max mem: 10917
[12:24:52.521069] Epoch: [15]  [180/345]  eta: 0:00:41  lr: 0.000097  loss: 0.8087 (0.8182)  time: 0.2510  data: 0.0000  max mem: 10917
[12:24:57.551736] Epoch: [15]  [200/345]  eta: 0:00:36  lr: 0.000097  loss: 0.8187 (0.8181)  time: 0.2515  data: 0.0000  max mem: 10917
[12:25:02.583522] Epoch: [15]  [220/345]  eta: 0:00:31  lr: 0.000098  loss: 0.8159 (0.8183)  time: 0.2516  data: 0.0001  max mem: 10917
[12:25:07.613247] Epoch: [15]  [240/345]  eta: 0:00:26  lr: 0.000098  loss: 0.8107 (0.8178)  time: 0.2514  data: 0.0000  max mem: 10917
[12:25:12.647524] Epoch: [15]  [260/345]  eta: 0:00:21  lr: 0.000098  loss: 0.7997 (0.8168)  time: 0.2517  data: 0.0000  max mem: 10917
[12:25:17.680834] Epoch: [15]  [280/345]  eta: 0:00:16  lr: 0.000099  loss: 0.8092 (0.8162)  time: 0.2516  data: 0.0000  max mem: 10917
[12:25:22.720458] Epoch: [15]  [300/345]  eta: 0:00:11  lr: 0.000099  loss: 0.8238 (0.8166)  time: 0.2519  data: 0.0000  max mem: 10917
[12:25:27.759031] Epoch: [15]  [320/345]  eta: 0:00:06  lr: 0.000100  loss: 0.8213 (0.8169)  time: 0.2519  data: 0.0000  max mem: 10917
[12:25:32.799244] Epoch: [15]  [340/345]  eta: 0:00:01  lr: 0.000100  loss: 0.8164 (0.8165)  time: 0.2520  data: 0.0000  max mem: 10917
[12:25:33.807791] Epoch: [15]  [344/345]  eta: 0:00:00  lr: 0.000100  loss: 0.8164 (0.8165)  time: 0.2520  data: 0.0001  max mem: 10917
[12:25:33.866225] Epoch: [15] Total time: 0:01:26 (0.2516 s / it)
[12:25:33.866683] Averaged stats: lr: 0.000100  loss: 0.8164 (0.8165)
[12:25:34.113528] Test:  [  0/345]  eta: 0:01:23  loss: 0.7630 (0.7630)  time: 0.2429  data: 0.1628  max mem: 10917
[12:25:34.937941] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7674 (0.7716)  time: 0.0969  data: 0.0152  max mem: 10917
[12:25:35.760914] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7719 (0.7757)  time: 0.0823  data: 0.0002  max mem: 10917
[12:25:36.587746] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7837 (0.7773)  time: 0.0824  data: 0.0001  max mem: 10917
[12:25:37.418716] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7701 (0.7738)  time: 0.0828  data: 0.0001  max mem: 10917
[12:25:38.252511] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7701 (0.7744)  time: 0.0832  data: 0.0001  max mem: 10917
[12:25:39.089591] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7729 (0.7742)  time: 0.0835  data: 0.0001  max mem: 10917
[12:25:39.930471] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7707 (0.7737)  time: 0.0839  data: 0.0001  max mem: 10917
[12:25:40.775479] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7692 (0.7734)  time: 0.0842  data: 0.0001  max mem: 10917
[12:25:41.623076] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7692 (0.7734)  time: 0.0846  data: 0.0001  max mem: 10917
[12:25:42.475507] Test:  [100/345]  eta: 0:00:20  loss: 0.7727 (0.7732)  time: 0.0850  data: 0.0001  max mem: 10917
[12:25:43.329681] Test:  [110/345]  eta: 0:00:20  loss: 0.7795 (0.7752)  time: 0.0853  data: 0.0001  max mem: 10917
[12:25:44.188781] Test:  [120/345]  eta: 0:00:19  loss: 0.7773 (0.7746)  time: 0.0856  data: 0.0001  max mem: 10917
[12:25:45.051612] Test:  [130/345]  eta: 0:00:18  loss: 0.7629 (0.7742)  time: 0.0860  data: 0.0001  max mem: 10917
[12:25:45.917395] Test:  [140/345]  eta: 0:00:17  loss: 0.7737 (0.7747)  time: 0.0864  data: 0.0001  max mem: 10917
[12:25:46.786008] Test:  [150/345]  eta: 0:00:16  loss: 0.7872 (0.7760)  time: 0.0867  data: 0.0001  max mem: 10917
[12:25:47.658635] Test:  [160/345]  eta: 0:00:15  loss: 0.7810 (0.7758)  time: 0.0870  data: 0.0001  max mem: 10917
[12:25:48.535158] Test:  [170/345]  eta: 0:00:14  loss: 0.7750 (0.7756)  time: 0.0874  data: 0.0001  max mem: 10917
[12:25:49.415226] Test:  [180/345]  eta: 0:00:14  loss: 0.7768 (0.7753)  time: 0.0878  data: 0.0001  max mem: 10917
[12:25:50.297622] Test:  [190/345]  eta: 0:00:13  loss: 0.7821 (0.7757)  time: 0.0881  data: 0.0001  max mem: 10917
[12:25:51.184156] Test:  [200/345]  eta: 0:00:12  loss: 0.7771 (0.7760)  time: 0.0884  data: 0.0001  max mem: 10917
[12:25:52.074984] Test:  [210/345]  eta: 0:00:11  loss: 0.7766 (0.7763)  time: 0.0888  data: 0.0001  max mem: 10917
[12:25:52.968596] Test:  [220/345]  eta: 0:00:10  loss: 0.7787 (0.7767)  time: 0.0892  data: 0.0001  max mem: 10917
[12:25:53.865482] Test:  [230/345]  eta: 0:00:09  loss: 0.7825 (0.7769)  time: 0.0895  data: 0.0001  max mem: 10917
[12:25:54.767324] Test:  [240/345]  eta: 0:00:09  loss: 0.7808 (0.7769)  time: 0.0899  data: 0.0001  max mem: 10917
[12:25:55.670592] Test:  [250/345]  eta: 0:00:08  loss: 0.7753 (0.7767)  time: 0.0902  data: 0.0001  max mem: 10917
[12:25:56.578656] Test:  [260/345]  eta: 0:00:07  loss: 0.7773 (0.7768)  time: 0.0905  data: 0.0001  max mem: 10917
[12:25:57.489476] Test:  [270/345]  eta: 0:00:06  loss: 0.7773 (0.7767)  time: 0.0909  data: 0.0001  max mem: 10917
[12:25:58.403555] Test:  [280/345]  eta: 0:00:05  loss: 0.7778 (0.7768)  time: 0.0912  data: 0.0001  max mem: 10917
[12:25:59.321256] Test:  [290/345]  eta: 0:00:04  loss: 0.7875 (0.7773)  time: 0.0915  data: 0.0001  max mem: 10917
[12:26:00.244025] Test:  [300/345]  eta: 0:00:03  loss: 0.7785 (0.7771)  time: 0.0920  data: 0.0001  max mem: 10917
[12:26:01.168916] Test:  [310/345]  eta: 0:00:03  loss: 0.7718 (0.7772)  time: 0.0923  data: 0.0001  max mem: 10917
[12:26:02.099434] Test:  [320/345]  eta: 0:00:02  loss: 0.7689 (0.7768)  time: 0.0926  data: 0.0001  max mem: 10917
[12:26:03.031227] Test:  [330/345]  eta: 0:00:01  loss: 0.7689 (0.7771)  time: 0.0930  data: 0.0001  max mem: 10917
[12:26:03.967220] Test:  [340/345]  eta: 0:00:00  loss: 0.7693 (0.7768)  time: 0.0933  data: 0.0001  max mem: 10917
[12:26:04.343137] Test:  [344/345]  eta: 0:00:00  loss: 0.7693 (0.7767)  time: 0.0935  data: 0.0001  max mem: 10917
[12:26:04.403006] Test: Total time: 0:00:30 (0.0885 s / it)
[12:26:15.289433] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8923 (0.8923)  time: 0.2194  data: 0.1397  max mem: 10917
[12:26:16.103635] Test:  [10/57]  eta: 0:00:04  loss: 0.8923 (0.8923)  time: 0.0939  data: 0.0128  max mem: 10917
[12:26:16.920996] Test:  [20/57]  eta: 0:00:03  loss: 0.8924 (0.8874)  time: 0.0815  data: 0.0001  max mem: 10917
[12:26:17.741308] Test:  [30/57]  eta: 0:00:02  loss: 0.7803 (0.8479)  time: 0.0818  data: 0.0001  max mem: 10917
[12:26:18.565818] Test:  [40/57]  eta: 0:00:01  loss: 0.7683 (0.8264)  time: 0.0822  data: 0.0001  max mem: 10917
[12:26:19.394653] Test:  [50/57]  eta: 0:00:00  loss: 0.7540 (0.8175)  time: 0.0826  data: 0.0001  max mem: 10917
[12:26:19.845048] Test:  [56/57]  eta: 0:00:00  loss: 0.7802 (0.8226)  time: 0.0804  data: 0.0001  max mem: 10917
[12:26:19.901379] Test: Total time: 0:00:04 (0.0848 s / it)
[12:26:21.751074] Dice score of the network on the train images: 0.782461, val images: 0.806337
[12:26:21.754179] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:26:22.148676] Epoch: [16]  [  0/345]  eta: 0:02:15  lr: 0.000100  loss: 0.8180 (0.8180)  time: 0.3936  data: 0.1412  max mem: 10917
[12:26:27.148174] Epoch: [16]  [ 20/345]  eta: 0:01:23  lr: 0.000100  loss: 0.8298 (0.8307)  time: 0.2499  data: 0.0000  max mem: 10917
[12:26:32.151463] Epoch: [16]  [ 40/345]  eta: 0:01:17  lr: 0.000101  loss: 0.8251 (0.8263)  time: 0.2501  data: 0.0000  max mem: 10917
[12:26:37.146816] Epoch: [16]  [ 60/345]  eta: 0:01:11  lr: 0.000101  loss: 0.8223 (0.8247)  time: 0.2497  data: 0.0000  max mem: 10917
[12:26:42.151086] Epoch: [16]  [ 80/345]  eta: 0:01:06  lr: 0.000101  loss: 0.8084 (0.8209)  time: 0.2502  data: 0.0000  max mem: 10917
[12:26:47.157080] Epoch: [16]  [100/345]  eta: 0:01:01  lr: 0.000102  loss: 0.8149 (0.8201)  time: 0.2503  data: 0.0000  max mem: 10917
[12:26:52.164311] Epoch: [16]  [120/345]  eta: 0:00:56  lr: 0.000102  loss: 0.8026 (0.8185)  time: 0.2503  data: 0.0001  max mem: 10917
[12:26:57.165468] Epoch: [16]  [140/345]  eta: 0:00:51  lr: 0.000103  loss: 0.8107 (0.8175)  time: 0.2500  data: 0.0001  max mem: 10917
[12:27:02.169902] Epoch: [16]  [160/345]  eta: 0:00:46  lr: 0.000103  loss: 0.8118 (0.8164)  time: 0.2502  data: 0.0000  max mem: 10917
[12:27:07.177371] Epoch: [16]  [180/345]  eta: 0:00:41  lr: 0.000103  loss: 0.8107 (0.8157)  time: 0.2503  data: 0.0000  max mem: 10917
[12:27:12.201470] Epoch: [16]  [200/345]  eta: 0:00:36  lr: 0.000104  loss: 0.8090 (0.8156)  time: 0.2512  data: 0.0000  max mem: 10917
[12:27:17.226179] Epoch: [16]  [220/345]  eta: 0:00:31  lr: 0.000104  loss: 0.8056 (0.8152)  time: 0.2512  data: 0.0000  max mem: 10917
[12:27:22.259116] Epoch: [16]  [240/345]  eta: 0:00:26  lr: 0.000104  loss: 0.8094 (0.8148)  time: 0.2516  data: 0.0000  max mem: 10917
[12:27:27.291230] Epoch: [16]  [260/345]  eta: 0:00:21  lr: 0.000105  loss: 0.7986 (0.8142)  time: 0.2516  data: 0.0000  max mem: 10917
[12:27:32.329409] Epoch: [16]  [280/345]  eta: 0:00:16  lr: 0.000105  loss: 0.8008 (0.8134)  time: 0.2519  data: 0.0000  max mem: 10917
[12:27:37.368069] Epoch: [16]  [300/345]  eta: 0:00:11  lr: 0.000105  loss: 0.7997 (0.8125)  time: 0.2519  data: 0.0001  max mem: 10917
[12:27:42.407844] Epoch: [16]  [320/345]  eta: 0:00:06  lr: 0.000106  loss: 0.8060 (0.8123)  time: 0.2520  data: 0.0001  max mem: 10917
[12:27:47.448965] Epoch: [16]  [340/345]  eta: 0:00:01  lr: 0.000106  loss: 0.8132 (0.8125)  time: 0.2520  data: 0.0000  max mem: 10917
[12:27:48.458551] Epoch: [16]  [344/345]  eta: 0:00:00  lr: 0.000106  loss: 0.8239 (0.8127)  time: 0.2521  data: 0.0001  max mem: 10917
[12:27:48.511999] Epoch: [16] Total time: 0:01:26 (0.2515 s / it)
[12:27:48.512471] Averaged stats: lr: 0.000106  loss: 0.8239 (0.8127)
[12:27:48.742982] Test:  [  0/345]  eta: 0:01:18  loss: 0.7631 (0.7631)  time: 0.2271  data: 0.1470  max mem: 10917
[12:27:49.579596] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7791 (0.7796)  time: 0.0966  data: 0.0149  max mem: 10917
[12:27:50.403885] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7826 (0.7841)  time: 0.0830  data: 0.0009  max mem: 10917
[12:27:51.231539] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7800 (0.7818)  time: 0.0825  data: 0.0001  max mem: 10917
[12:27:52.062192] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7789 (0.7817)  time: 0.0829  data: 0.0001  max mem: 10917
[12:27:52.896827] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7777 (0.7822)  time: 0.0832  data: 0.0001  max mem: 10917
[12:27:53.735029] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7860 (0.7829)  time: 0.0836  data: 0.0001  max mem: 10917
[12:27:54.576287] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7820 (0.7825)  time: 0.0839  data: 0.0001  max mem: 10917
[12:27:55.421328] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7860 (0.7827)  time: 0.0843  data: 0.0001  max mem: 10917
[12:27:56.270058] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7848 (0.7831)  time: 0.0846  data: 0.0001  max mem: 10917
[12:27:57.121827] Test:  [100/345]  eta: 0:00:20  loss: 0.7847 (0.7830)  time: 0.0850  data: 0.0001  max mem: 10917
[12:27:57.977165] Test:  [110/345]  eta: 0:00:20  loss: 0.7814 (0.7831)  time: 0.0853  data: 0.0001  max mem: 10917
[12:27:58.835980] Test:  [120/345]  eta: 0:00:19  loss: 0.7814 (0.7830)  time: 0.0857  data: 0.0001  max mem: 10917
[12:27:59.698009] Test:  [130/345]  eta: 0:00:18  loss: 0.7849 (0.7841)  time: 0.0860  data: 0.0001  max mem: 10917
[12:28:00.564193] Test:  [140/345]  eta: 0:00:17  loss: 0.7879 (0.7844)  time: 0.0864  data: 0.0001  max mem: 10917
[12:28:01.433174] Test:  [150/345]  eta: 0:00:16  loss: 0.7830 (0.7845)  time: 0.0867  data: 0.0001  max mem: 10917
[12:28:02.305315] Test:  [160/345]  eta: 0:00:15  loss: 0.7830 (0.7847)  time: 0.0870  data: 0.0001  max mem: 10917
[12:28:03.181682] Test:  [170/345]  eta: 0:00:14  loss: 0.7748 (0.7843)  time: 0.0873  data: 0.0001  max mem: 10917
[12:28:04.061703] Test:  [180/345]  eta: 0:00:14  loss: 0.7743 (0.7842)  time: 0.0877  data: 0.0001  max mem: 10917
[12:28:04.944521] Test:  [190/345]  eta: 0:00:13  loss: 0.7756 (0.7838)  time: 0.0881  data: 0.0001  max mem: 10917
[12:28:05.830959] Test:  [200/345]  eta: 0:00:12  loss: 0.7740 (0.7834)  time: 0.0884  data: 0.0001  max mem: 10917
[12:28:06.720866] Test:  [210/345]  eta: 0:00:11  loss: 0.7784 (0.7837)  time: 0.0888  data: 0.0001  max mem: 10917
[12:28:07.613928] Test:  [220/345]  eta: 0:00:10  loss: 0.7832 (0.7837)  time: 0.0891  data: 0.0001  max mem: 10917
[12:28:08.510345] Test:  [230/345]  eta: 0:00:09  loss: 0.7823 (0.7835)  time: 0.0894  data: 0.0001  max mem: 10917
[12:28:09.411153] Test:  [240/345]  eta: 0:00:09  loss: 0.7802 (0.7832)  time: 0.0898  data: 0.0001  max mem: 10917
[12:28:10.314816] Test:  [250/345]  eta: 0:00:08  loss: 0.7833 (0.7836)  time: 0.0902  data: 0.0001  max mem: 10917
[12:28:11.221141] Test:  [260/345]  eta: 0:00:07  loss: 0.7955 (0.7844)  time: 0.0905  data: 0.0001  max mem: 10917
[12:28:12.132474] Test:  [270/345]  eta: 0:00:06  loss: 0.7906 (0.7844)  time: 0.0908  data: 0.0001  max mem: 10917
[12:28:13.045974] Test:  [280/345]  eta: 0:00:05  loss: 0.7879 (0.7847)  time: 0.0912  data: 0.0001  max mem: 10917
[12:28:13.963406] Test:  [290/345]  eta: 0:00:04  loss: 0.7755 (0.7842)  time: 0.0915  data: 0.0001  max mem: 10917
[12:28:14.884547] Test:  [300/345]  eta: 0:00:03  loss: 0.7755 (0.7842)  time: 0.0919  data: 0.0001  max mem: 10917
[12:28:15.808356] Test:  [310/345]  eta: 0:00:03  loss: 0.7887 (0.7843)  time: 0.0922  data: 0.0001  max mem: 10917
[12:28:16.736117] Test:  [320/345]  eta: 0:00:02  loss: 0.7745 (0.7840)  time: 0.0925  data: 0.0001  max mem: 10917
[12:28:17.667824] Test:  [330/345]  eta: 0:00:01  loss: 0.7717 (0.7838)  time: 0.0929  data: 0.0001  max mem: 10917
[12:28:18.602041] Test:  [340/345]  eta: 0:00:00  loss: 0.7720 (0.7837)  time: 0.0932  data: 0.0001  max mem: 10917
[12:28:18.978266] Test:  [344/345]  eta: 0:00:00  loss: 0.7752 (0.7837)  time: 0.0934  data: 0.0001  max mem: 10917
[12:28:19.036377] Test: Total time: 0:00:30 (0.0885 s / it)
[12:28:29.731493] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8809 (0.8809)  time: 0.2216  data: 0.1420  max mem: 10917
[12:28:30.545770] Test:  [10/57]  eta: 0:00:04  loss: 0.9366 (0.9242)  time: 0.0941  data: 0.0130  max mem: 10917
[12:28:31.362632] Test:  [20/57]  eta: 0:00:03  loss: 0.9446 (0.9226)  time: 0.0815  data: 0.0001  max mem: 10917
[12:28:32.184008] Test:  [30/57]  eta: 0:00:02  loss: 0.8089 (0.8767)  time: 0.0819  data: 0.0001  max mem: 10917
[12:28:33.008191] Test:  [40/57]  eta: 0:00:01  loss: 0.7853 (0.8501)  time: 0.0822  data: 0.0001  max mem: 10917
[12:28:33.836488] Test:  [50/57]  eta: 0:00:00  loss: 0.7742 (0.8393)  time: 0.0826  data: 0.0001  max mem: 10917
[12:28:34.286568] Test:  [56/57]  eta: 0:00:00  loss: 0.7982 (0.8440)  time: 0.0804  data: 0.0001  max mem: 10917
[12:28:34.343358] Test: Total time: 0:00:04 (0.0848 s / it)
[12:28:36.195530] Dice score of the network on the train images: 0.776118, val images: 0.804053
[12:28:36.199205] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:28:36.599280] Epoch: [17]  [  0/345]  eta: 0:02:17  lr: 0.000106  loss: 0.8268 (0.8268)  time: 0.3991  data: 0.1472  max mem: 10917
[12:28:41.602825] Epoch: [17]  [ 20/345]  eta: 0:01:23  lr: 0.000107  loss: 0.8087 (0.8089)  time: 0.2501  data: 0.0001  max mem: 10917
[12:28:46.606144] Epoch: [17]  [ 40/345]  eta: 0:01:17  lr: 0.000107  loss: 0.8353 (0.8189)  time: 0.2501  data: 0.0000  max mem: 10917
[12:28:51.618537] Epoch: [17]  [ 60/345]  eta: 0:01:12  lr: 0.000107  loss: 0.8105 (0.8171)  time: 0.2506  data: 0.0000  max mem: 10917
[12:28:56.633255] Epoch: [17]  [ 80/345]  eta: 0:01:06  lr: 0.000108  loss: 0.8118 (0.8163)  time: 0.2507  data: 0.0001  max mem: 10917
[12:29:01.729144] Epoch: [17]  [100/345]  eta: 0:01:01  lr: 0.000108  loss: 0.8022 (0.8152)  time: 0.2548  data: 0.0001  max mem: 10917
[12:29:06.747150] Epoch: [17]  [120/345]  eta: 0:00:56  lr: 0.000108  loss: 0.8274 (0.8175)  time: 0.2509  data: 0.0000  max mem: 10917
[12:29:11.768639] Epoch: [17]  [140/345]  eta: 0:00:51  lr: 0.000109  loss: 0.8149 (0.8166)  time: 0.2510  data: 0.0000  max mem: 10917
[12:29:16.791839] Epoch: [17]  [160/345]  eta: 0:00:46  lr: 0.000109  loss: 0.8279 (0.8172)  time: 0.2511  data: 0.0000  max mem: 10917
[12:29:21.813517] Epoch: [17]  [180/345]  eta: 0:00:41  lr: 0.000110  loss: 0.8187 (0.8180)  time: 0.2510  data: 0.0001  max mem: 10917
[12:29:26.826644] Epoch: [17]  [200/345]  eta: 0:00:36  lr: 0.000110  loss: 0.8194 (0.8185)  time: 0.2506  data: 0.0001  max mem: 10917
[12:29:31.841177] Epoch: [17]  [220/345]  eta: 0:00:31  lr: 0.000110  loss: 0.8192 (0.8187)  time: 0.2507  data: 0.0001  max mem: 10917
[12:29:36.869253] Epoch: [17]  [240/345]  eta: 0:00:26  lr: 0.000111  loss: 0.8118 (0.8183)  time: 0.2514  data: 0.0000  max mem: 10917
[12:29:41.902534] Epoch: [17]  [260/345]  eta: 0:00:21  lr: 0.000111  loss: 0.8017 (0.8173)  time: 0.2516  data: 0.0000  max mem: 10917
[12:29:46.936840] Epoch: [17]  [280/345]  eta: 0:00:16  lr: 0.000111  loss: 0.8039 (0.8170)  time: 0.2517  data: 0.0000  max mem: 10917
[12:29:51.970824] Epoch: [17]  [300/345]  eta: 0:00:11  lr: 0.000112  loss: 0.8015 (0.8161)  time: 0.2517  data: 0.0000  max mem: 10917
[12:29:57.008978] Epoch: [17]  [320/345]  eta: 0:00:06  lr: 0.000112  loss: 0.8213 (0.8167)  time: 0.2519  data: 0.0000  max mem: 10917
[12:30:02.048752] Epoch: [17]  [340/345]  eta: 0:00:01  lr: 0.000112  loss: 0.8129 (0.8165)  time: 0.2519  data: 0.0000  max mem: 10917
[12:30:03.057724] Epoch: [17]  [344/345]  eta: 0:00:00  lr: 0.000112  loss: 0.8144 (0.8165)  time: 0.2519  data: 0.0001  max mem: 10917
[12:30:03.123247] Epoch: [17] Total time: 0:01:26 (0.2520 s / it)
[12:30:03.123643] Averaged stats: lr: 0.000112  loss: 0.8144 (0.8165)
[12:30:03.357236] Test:  [  0/345]  eta: 0:01:19  loss: 0.8059 (0.8059)  time: 0.2299  data: 0.1497  max mem: 10917
[12:30:04.176906] Test:  [ 10/345]  eta: 0:00:31  loss: 0.7839 (0.7825)  time: 0.0953  data: 0.0137  max mem: 10917
[12:30:04.999386] Test:  [ 20/345]  eta: 0:00:28  loss: 0.7755 (0.7764)  time: 0.0820  data: 0.0001  max mem: 10917
[12:30:05.825421] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7798 (0.7780)  time: 0.0824  data: 0.0001  max mem: 10917
[12:30:06.654983] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7847 (0.7781)  time: 0.0827  data: 0.0001  max mem: 10917
[12:30:07.488108] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7657 (0.7772)  time: 0.0831  data: 0.0001  max mem: 10917
[12:30:08.324974] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7624 (0.7748)  time: 0.0835  data: 0.0001  max mem: 10917
[12:30:09.165176] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7653 (0.7754)  time: 0.0838  data: 0.0001  max mem: 10917
[12:30:10.009496] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7804 (0.7755)  time: 0.0842  data: 0.0001  max mem: 10917
[12:30:10.856409] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7801 (0.7754)  time: 0.0845  data: 0.0001  max mem: 10917
[12:30:11.707846] Test:  [100/345]  eta: 0:00:20  loss: 0.7769 (0.7753)  time: 0.0849  data: 0.0001  max mem: 10917
[12:30:12.561884] Test:  [110/345]  eta: 0:00:19  loss: 0.7730 (0.7750)  time: 0.0852  data: 0.0001  max mem: 10917
[12:30:13.419221] Test:  [120/345]  eta: 0:00:19  loss: 0.7685 (0.7745)  time: 0.0855  data: 0.0001  max mem: 10917
[12:30:14.280433] Test:  [130/345]  eta: 0:00:18  loss: 0.7721 (0.7745)  time: 0.0859  data: 0.0001  max mem: 10917
[12:30:15.145055] Test:  [140/345]  eta: 0:00:17  loss: 0.7796 (0.7754)  time: 0.0862  data: 0.0001  max mem: 10917
[12:30:16.013661] Test:  [150/345]  eta: 0:00:16  loss: 0.7848 (0.7758)  time: 0.0866  data: 0.0001  max mem: 10917
[12:30:16.885770] Test:  [160/345]  eta: 0:00:15  loss: 0.7828 (0.7762)  time: 0.0870  data: 0.0001  max mem: 10917
[12:30:17.760300] Test:  [170/345]  eta: 0:00:14  loss: 0.7699 (0.7763)  time: 0.0873  data: 0.0001  max mem: 10917
[12:30:18.639283] Test:  [180/345]  eta: 0:00:14  loss: 0.7677 (0.7764)  time: 0.0876  data: 0.0001  max mem: 10917
[12:30:19.521689] Test:  [190/345]  eta: 0:00:13  loss: 0.7663 (0.7763)  time: 0.0880  data: 0.0001  max mem: 10917
[12:30:20.407945] Test:  [200/345]  eta: 0:00:12  loss: 0.7688 (0.7760)  time: 0.0884  data: 0.0001  max mem: 10917
[12:30:21.297539] Test:  [210/345]  eta: 0:00:11  loss: 0.7689 (0.7761)  time: 0.0887  data: 0.0001  max mem: 10917
[12:30:22.190674] Test:  [220/345]  eta: 0:00:10  loss: 0.7724 (0.7759)  time: 0.0891  data: 0.0001  max mem: 10917
[12:30:23.087180] Test:  [230/345]  eta: 0:00:09  loss: 0.7724 (0.7757)  time: 0.0894  data: 0.0001  max mem: 10917
[12:30:23.987883] Test:  [240/345]  eta: 0:00:09  loss: 0.7749 (0.7760)  time: 0.0898  data: 0.0001  max mem: 10917
[12:30:24.891193] Test:  [250/345]  eta: 0:00:08  loss: 0.7786 (0.7759)  time: 0.0902  data: 0.0001  max mem: 10917
[12:30:25.797923] Test:  [260/345]  eta: 0:00:07  loss: 0.7735 (0.7756)  time: 0.0905  data: 0.0001  max mem: 10917
[12:30:26.709189] Test:  [270/345]  eta: 0:00:06  loss: 0.7596 (0.7752)  time: 0.0909  data: 0.0001  max mem: 10917
[12:30:27.623688] Test:  [280/345]  eta: 0:00:05  loss: 0.7666 (0.7750)  time: 0.0912  data: 0.0001  max mem: 10917
[12:30:28.540930] Test:  [290/345]  eta: 0:00:04  loss: 0.7717 (0.7749)  time: 0.0915  data: 0.0001  max mem: 10917
[12:30:29.462970] Test:  [300/345]  eta: 0:00:03  loss: 0.7733 (0.7750)  time: 0.0919  data: 0.0001  max mem: 10917
[12:30:30.387604] Test:  [310/345]  eta: 0:00:03  loss: 0.7733 (0.7748)  time: 0.0923  data: 0.0001  max mem: 10917
[12:30:31.316172] Test:  [320/345]  eta: 0:00:02  loss: 0.7639 (0.7745)  time: 0.0926  data: 0.0001  max mem: 10917
[12:30:32.247492] Test:  [330/345]  eta: 0:00:01  loss: 0.7706 (0.7746)  time: 0.0929  data: 0.0001  max mem: 10917
[12:30:33.181522] Test:  [340/345]  eta: 0:00:00  loss: 0.7735 (0.7745)  time: 0.0932  data: 0.0001  max mem: 10917
[12:30:33.556936] Test:  [344/345]  eta: 0:00:00  loss: 0.7735 (0.7745)  time: 0.0934  data: 0.0001  max mem: 10917
[12:30:33.614895] Test: Total time: 0:00:30 (0.0884 s / it)
[12:30:44.338205] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8655 (0.8655)  time: 0.2209  data: 0.1410  max mem: 10917
[12:30:45.151728] Test:  [10/57]  eta: 0:00:04  loss: 0.8732 (0.8987)  time: 0.0940  data: 0.0129  max mem: 10917
[12:30:45.968407] Test:  [20/57]  eta: 0:00:03  loss: 0.8869 (0.8924)  time: 0.0814  data: 0.0001  max mem: 10917
[12:30:46.789088] Test:  [30/57]  eta: 0:00:02  loss: 0.7944 (0.8564)  time: 0.0818  data: 0.0001  max mem: 10917
[12:30:47.613833] Test:  [40/57]  eta: 0:00:01  loss: 0.7847 (0.8367)  time: 0.0822  data: 0.0001  max mem: 10917
[12:30:48.440504] Test:  [50/57]  eta: 0:00:00  loss: 0.7805 (0.8310)  time: 0.0825  data: 0.0001  max mem: 10917
[12:30:48.890662] Test:  [56/57]  eta: 0:00:00  loss: 0.7920 (0.8347)  time: 0.0803  data: 0.0001  max mem: 10917
[12:30:48.944852] Test: Total time: 0:00:04 (0.0847 s / it)
[12:30:50.823578] Dice score of the network on the train images: 0.779145, val images: 0.790776
[12:30:50.827015] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:30:51.219484] Epoch: [18]  [  0/345]  eta: 0:02:15  lr: 0.000113  loss: 0.7915 (0.7915)  time: 0.3914  data: 0.1392  max mem: 10917
[12:30:56.213336] Epoch: [18]  [ 20/345]  eta: 0:01:23  lr: 0.000113  loss: 0.8061 (0.8054)  time: 0.2496  data: 0.0001  max mem: 10917
[12:31:01.199921] Epoch: [18]  [ 40/345]  eta: 0:01:17  lr: 0.000113  loss: 0.8201 (0.8105)  time: 0.2493  data: 0.0001  max mem: 10917
[12:31:06.190928] Epoch: [18]  [ 60/345]  eta: 0:01:11  lr: 0.000114  loss: 0.8180 (0.8151)  time: 0.2495  data: 0.0000  max mem: 10917
[12:31:11.187343] Epoch: [18]  [ 80/345]  eta: 0:01:06  lr: 0.000114  loss: 0.8185 (0.8167)  time: 0.2498  data: 0.0001  max mem: 10917
[12:31:16.185980] Epoch: [18]  [100/345]  eta: 0:01:01  lr: 0.000114  loss: 0.8121 (0.8153)  time: 0.2499  data: 0.0001  max mem: 10917
[12:31:21.186166] Epoch: [18]  [120/345]  eta: 0:00:56  lr: 0.000115  loss: 0.7981 (0.8130)  time: 0.2500  data: 0.0000  max mem: 10917
[12:31:26.188773] Epoch: [18]  [140/345]  eta: 0:00:51  lr: 0.000115  loss: 0.8024 (0.8121)  time: 0.2501  data: 0.0000  max mem: 10917
[12:31:31.192472] Epoch: [18]  [160/345]  eta: 0:00:46  lr: 0.000115  loss: 0.8010 (0.8113)  time: 0.2501  data: 0.0000  max mem: 10917
[12:31:36.200908] Epoch: [18]  [180/345]  eta: 0:00:41  lr: 0.000116  loss: 0.8051 (0.8104)  time: 0.2504  data: 0.0000  max mem: 10917
[12:31:41.207578] Epoch: [18]  [200/345]  eta: 0:00:36  lr: 0.000116  loss: 0.8063 (0.8108)  time: 0.2503  data: 0.0000  max mem: 10917
[12:31:46.223485] Epoch: [18]  [220/345]  eta: 0:00:31  lr: 0.000116  loss: 0.8176 (0.8119)  time: 0.2508  data: 0.0000  max mem: 10917
[12:31:51.240853] Epoch: [18]  [240/345]  eta: 0:00:26  lr: 0.000117  loss: 0.8049 (0.8114)  time: 0.2508  data: 0.0000  max mem: 10917
[12:31:56.260458] Epoch: [18]  [260/345]  eta: 0:00:21  lr: 0.000117  loss: 0.8042 (0.8111)  time: 0.2509  data: 0.0000  max mem: 10917
[12:32:01.281235] Epoch: [18]  [280/345]  eta: 0:00:16  lr: 0.000118  loss: 0.8198 (0.8115)  time: 0.2510  data: 0.0000  max mem: 10917
[12:32:06.303429] Epoch: [18]  [300/345]  eta: 0:00:11  lr: 0.000118  loss: 0.8033 (0.8107)  time: 0.2511  data: 0.0000  max mem: 10917
[12:32:11.323891] Epoch: [18]  [320/345]  eta: 0:00:06  lr: 0.000118  loss: 0.8096 (0.8107)  time: 0.2510  data: 0.0000  max mem: 10917
[12:32:16.346306] Epoch: [18]  [340/345]  eta: 0:00:01  lr: 0.000119  loss: 0.8028 (0.8102)  time: 0.2511  data: 0.0001  max mem: 10917
[12:32:17.351739] Epoch: [18]  [344/345]  eta: 0:00:00  lr: 0.000119  loss: 0.8047 (0.8101)  time: 0.2511  data: 0.0001  max mem: 10917
[12:32:17.407593] Epoch: [18] Total time: 0:01:26 (0.2510 s / it)
[12:32:17.408106] Averaged stats: lr: 0.000119  loss: 0.8047 (0.8101)
[12:32:17.641226] Test:  [  0/345]  eta: 0:01:19  loss: 0.7700 (0.7700)  time: 0.2301  data: 0.1504  max mem: 10917
[12:32:18.462057] Test:  [ 10/345]  eta: 0:00:31  loss: 0.7677 (0.7654)  time: 0.0955  data: 0.0137  max mem: 10917
[12:32:19.285422] Test:  [ 20/345]  eta: 0:00:28  loss: 0.7675 (0.7638)  time: 0.0822  data: 0.0001  max mem: 10917
[12:32:20.111471] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7675 (0.7656)  time: 0.0824  data: 0.0001  max mem: 10917
[12:32:20.942146] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7660 (0.7654)  time: 0.0828  data: 0.0001  max mem: 10917
[12:32:21.775295] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7660 (0.7659)  time: 0.0831  data: 0.0001  max mem: 10917
[12:32:22.612036] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7704 (0.7679)  time: 0.0834  data: 0.0001  max mem: 10917
[12:32:23.453656] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7683 (0.7670)  time: 0.0839  data: 0.0001  max mem: 10917
[12:32:24.297282] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7613 (0.7667)  time: 0.0842  data: 0.0001  max mem: 10917
[12:32:25.145119] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7706 (0.7674)  time: 0.0845  data: 0.0001  max mem: 10917
[12:32:25.996754] Test:  [100/345]  eta: 0:00:20  loss: 0.7754 (0.7683)  time: 0.0849  data: 0.0001  max mem: 10917
[12:32:26.851739] Test:  [110/345]  eta: 0:00:19  loss: 0.7714 (0.7682)  time: 0.0853  data: 0.0001  max mem: 10917
[12:32:27.710474] Test:  [120/345]  eta: 0:00:19  loss: 0.7691 (0.7693)  time: 0.0856  data: 0.0001  max mem: 10917
[12:32:28.571678] Test:  [130/345]  eta: 0:00:18  loss: 0.7683 (0.7690)  time: 0.0859  data: 0.0001  max mem: 10917
[12:32:29.436444] Test:  [140/345]  eta: 0:00:17  loss: 0.7648 (0.7686)  time: 0.0862  data: 0.0001  max mem: 10917
[12:32:30.305400] Test:  [150/345]  eta: 0:00:16  loss: 0.7635 (0.7689)  time: 0.0866  data: 0.0001  max mem: 10917
[12:32:31.177771] Test:  [160/345]  eta: 0:00:15  loss: 0.7692 (0.7687)  time: 0.0870  data: 0.0001  max mem: 10917
[12:32:32.053214] Test:  [170/345]  eta: 0:00:14  loss: 0.7652 (0.7682)  time: 0.0873  data: 0.0001  max mem: 10917
[12:32:32.932495] Test:  [180/345]  eta: 0:00:14  loss: 0.7653 (0.7685)  time: 0.0877  data: 0.0001  max mem: 10917
[12:32:33.815322] Test:  [190/345]  eta: 0:00:13  loss: 0.7671 (0.7687)  time: 0.0881  data: 0.0001  max mem: 10917
[12:32:34.701966] Test:  [200/345]  eta: 0:00:12  loss: 0.7695 (0.7691)  time: 0.0884  data: 0.0001  max mem: 10917
[12:32:35.591928] Test:  [210/345]  eta: 0:00:11  loss: 0.7756 (0.7693)  time: 0.0888  data: 0.0001  max mem: 10917
[12:32:36.484200] Test:  [220/345]  eta: 0:00:10  loss: 0.7651 (0.7693)  time: 0.0891  data: 0.0001  max mem: 10917
[12:32:37.381673] Test:  [230/345]  eta: 0:00:09  loss: 0.7651 (0.7693)  time: 0.0894  data: 0.0001  max mem: 10917
[12:32:38.282926] Test:  [240/345]  eta: 0:00:09  loss: 0.7689 (0.7697)  time: 0.0899  data: 0.0001  max mem: 10917
[12:32:39.187147] Test:  [250/345]  eta: 0:00:08  loss: 0.7760 (0.7702)  time: 0.0902  data: 0.0001  max mem: 10917
[12:32:40.094230] Test:  [260/345]  eta: 0:00:07  loss: 0.7760 (0.7704)  time: 0.0905  data: 0.0001  max mem: 10917
[12:32:41.005390] Test:  [270/345]  eta: 0:00:06  loss: 0.7710 (0.7702)  time: 0.0909  data: 0.0001  max mem: 10917
[12:32:41.919237] Test:  [280/345]  eta: 0:00:05  loss: 0.7656 (0.7700)  time: 0.0912  data: 0.0001  max mem: 10917
[12:32:42.837120] Test:  [290/345]  eta: 0:00:04  loss: 0.7657 (0.7701)  time: 0.0915  data: 0.0001  max mem: 10917
[12:32:43.758403] Test:  [300/345]  eta: 0:00:03  loss: 0.7737 (0.7704)  time: 0.0919  data: 0.0001  max mem: 10917
[12:32:44.682635] Test:  [310/345]  eta: 0:00:03  loss: 0.7835 (0.7708)  time: 0.0922  data: 0.0001  max mem: 10917
[12:32:45.610382] Test:  [320/345]  eta: 0:00:02  loss: 0.7719 (0.7705)  time: 0.0926  data: 0.0001  max mem: 10917
[12:32:46.542717] Test:  [330/345]  eta: 0:00:01  loss: 0.7639 (0.7709)  time: 0.0930  data: 0.0001  max mem: 10917
[12:32:47.478061] Test:  [340/345]  eta: 0:00:00  loss: 0.7753 (0.7709)  time: 0.0933  data: 0.0001  max mem: 10917
[12:32:47.852970] Test:  [344/345]  eta: 0:00:00  loss: 0.7746 (0.7708)  time: 0.0934  data: 0.0001  max mem: 10917
[12:32:47.910998] Test: Total time: 0:00:30 (0.0884 s / it)
[12:32:58.669390] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8779 (0.8779)  time: 0.2212  data: 0.1412  max mem: 10917
[12:32:59.482615] Test:  [10/57]  eta: 0:00:04  loss: 0.8987 (0.8997)  time: 0.0940  data: 0.0129  max mem: 10917
[12:33:00.299512] Test:  [20/57]  eta: 0:00:03  loss: 0.8987 (0.8860)  time: 0.0814  data: 0.0001  max mem: 10917
[12:33:01.121202] Test:  [30/57]  eta: 0:00:02  loss: 0.7856 (0.8490)  time: 0.0819  data: 0.0001  max mem: 10917
[12:33:01.946598] Test:  [40/57]  eta: 0:00:01  loss: 0.7777 (0.8288)  time: 0.0823  data: 0.0001  max mem: 10917
[12:33:02.775774] Test:  [50/57]  eta: 0:00:00  loss: 0.7549 (0.8211)  time: 0.0827  data: 0.0001  max mem: 10917
[12:33:03.226324] Test:  [56/57]  eta: 0:00:00  loss: 0.7915 (0.8261)  time: 0.0804  data: 0.0001  max mem: 10917
[12:33:03.281783] Test: Total time: 0:00:04 (0.0848 s / it)
[12:33:05.137549] Dice score of the network on the train images: 0.772747, val images: 0.806677
[12:33:05.141042] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:33:05.536568] Epoch: [19]  [  0/345]  eta: 0:02:16  lr: 0.000119  loss: 0.8143 (0.8143)  time: 0.3945  data: 0.1422  max mem: 10917
[12:33:10.535902] Epoch: [19]  [ 20/345]  eta: 0:01:23  lr: 0.000119  loss: 0.7918 (0.8010)  time: 0.2499  data: 0.0001  max mem: 10917
[12:33:15.533833] Epoch: [19]  [ 40/345]  eta: 0:01:17  lr: 0.000119  loss: 0.8113 (0.8063)  time: 0.2498  data: 0.0001  max mem: 10917
[12:33:20.538679] Epoch: [19]  [ 60/345]  eta: 0:01:11  lr: 0.000120  loss: 0.8012 (0.8057)  time: 0.2502  data: 0.0000  max mem: 10917
[12:33:25.545562] Epoch: [19]  [ 80/345]  eta: 0:01:06  lr: 0.000120  loss: 0.8021 (0.8049)  time: 0.2503  data: 0.0000  max mem: 10917
[12:33:30.557340] Epoch: [19]  [100/345]  eta: 0:01:01  lr: 0.000121  loss: 0.8253 (0.8106)  time: 0.2505  data: 0.0000  max mem: 10917
[12:33:35.573750] Epoch: [19]  [120/345]  eta: 0:00:56  lr: 0.000121  loss: 0.8086 (0.8102)  time: 0.2508  data: 0.0000  max mem: 10917
[12:33:40.594486] Epoch: [19]  [140/345]  eta: 0:00:51  lr: 0.000121  loss: 0.8136 (0.8106)  time: 0.2510  data: 0.0000  max mem: 10917
[12:33:45.616984] Epoch: [19]  [160/345]  eta: 0:00:46  lr: 0.000122  loss: 0.8092 (0.8111)  time: 0.2511  data: 0.0001  max mem: 10917
[12:33:50.645183] Epoch: [19]  [180/345]  eta: 0:00:41  lr: 0.000122  loss: 0.8101 (0.8111)  time: 0.2514  data: 0.0001  max mem: 10917
[12:33:55.667342] Epoch: [19]  [200/345]  eta: 0:00:36  lr: 0.000122  loss: 0.7989 (0.8102)  time: 0.2511  data: 0.0000  max mem: 10917
[12:34:00.693013] Epoch: [19]  [220/345]  eta: 0:00:31  lr: 0.000123  loss: 0.8028 (0.8093)  time: 0.2512  data: 0.0000  max mem: 10917
[12:34:05.723365] Epoch: [19]  [240/345]  eta: 0:00:26  lr: 0.000123  loss: 0.8013 (0.8089)  time: 0.2515  data: 0.0000  max mem: 10917
[12:34:10.754981] Epoch: [19]  [260/345]  eta: 0:00:21  lr: 0.000123  loss: 0.7963 (0.8084)  time: 0.2515  data: 0.0000  max mem: 10917
[12:34:15.782102] Epoch: [19]  [280/345]  eta: 0:00:16  lr: 0.000124  loss: 0.8027 (0.8079)  time: 0.2513  data: 0.0000  max mem: 10917
[12:34:20.815735] Epoch: [19]  [300/345]  eta: 0:00:11  lr: 0.000124  loss: 0.7869 (0.8071)  time: 0.2516  data: 0.0000  max mem: 10917
[12:34:25.850263] Epoch: [19]  [320/345]  eta: 0:00:06  lr: 0.000125  loss: 0.7946 (0.8065)  time: 0.2517  data: 0.0000  max mem: 10917
[12:34:30.887136] Epoch: [19]  [340/345]  eta: 0:00:01  lr: 0.000125  loss: 0.8055 (0.8066)  time: 0.2518  data: 0.0000  max mem: 10917
[12:34:31.895653] Epoch: [19]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.8055 (0.8064)  time: 0.2519  data: 0.0001  max mem: 10917
[12:34:31.951009] Epoch: [19] Total time: 0:01:26 (0.2516 s / it)
[12:34:31.951356] Averaged stats: lr: 0.000125  loss: 0.8055 (0.8064)
[12:34:32.185824] Test:  [  0/345]  eta: 0:01:19  loss: 0.7597 (0.7597)  time: 0.2307  data: 0.1505  max mem: 10917
[12:34:33.022779] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7665 (0.7665)  time: 0.0970  data: 0.0154  max mem: 10917
[12:34:33.845819] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7665 (0.7686)  time: 0.0829  data: 0.0010  max mem: 10917
[12:34:34.673341] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7622 (0.7664)  time: 0.0825  data: 0.0001  max mem: 10917
[12:34:35.504472] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7683 (0.7678)  time: 0.0829  data: 0.0001  max mem: 10917
[12:34:36.338590] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7703 (0.7686)  time: 0.0832  data: 0.0001  max mem: 10917
[12:34:37.174950] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7594 (0.7669)  time: 0.0835  data: 0.0001  max mem: 10917
[12:34:38.015844] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7593 (0.7665)  time: 0.0838  data: 0.0001  max mem: 10917
[12:34:38.860926] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7554 (0.7650)  time: 0.0843  data: 0.0001  max mem: 10917
[12:34:39.707549] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7559 (0.7648)  time: 0.0845  data: 0.0001  max mem: 10917
[12:34:40.559693] Test:  [100/345]  eta: 0:00:20  loss: 0.7580 (0.7646)  time: 0.0849  data: 0.0001  max mem: 10917
[12:34:41.413785] Test:  [110/345]  eta: 0:00:20  loss: 0.7556 (0.7642)  time: 0.0853  data: 0.0001  max mem: 10917
[12:34:42.272180] Test:  [120/345]  eta: 0:00:19  loss: 0.7622 (0.7649)  time: 0.0856  data: 0.0001  max mem: 10917
[12:34:43.134708] Test:  [130/345]  eta: 0:00:18  loss: 0.7611 (0.7646)  time: 0.0860  data: 0.0001  max mem: 10917
[12:34:43.999892] Test:  [140/345]  eta: 0:00:17  loss: 0.7571 (0.7642)  time: 0.0863  data: 0.0001  max mem: 10917
[12:34:44.868196] Test:  [150/345]  eta: 0:00:16  loss: 0.7597 (0.7639)  time: 0.0866  data: 0.0001  max mem: 10917
[12:34:45.740723] Test:  [160/345]  eta: 0:00:15  loss: 0.7545 (0.7631)  time: 0.0870  data: 0.0001  max mem: 10917
[12:34:46.615745] Test:  [170/345]  eta: 0:00:14  loss: 0.7564 (0.7630)  time: 0.0873  data: 0.0001  max mem: 10917
[12:34:47.495606] Test:  [180/345]  eta: 0:00:14  loss: 0.7570 (0.7626)  time: 0.0877  data: 0.0001  max mem: 10917
[12:34:48.378661] Test:  [190/345]  eta: 0:00:13  loss: 0.7620 (0.7631)  time: 0.0881  data: 0.0001  max mem: 10917
[12:34:49.265731] Test:  [200/345]  eta: 0:00:12  loss: 0.7638 (0.7630)  time: 0.0885  data: 0.0001  max mem: 10917
[12:34:50.155380] Test:  [210/345]  eta: 0:00:11  loss: 0.7580 (0.7626)  time: 0.0888  data: 0.0001  max mem: 10917
[12:34:51.048453] Test:  [220/345]  eta: 0:00:10  loss: 0.7604 (0.7627)  time: 0.0891  data: 0.0001  max mem: 10917
[12:34:51.945579] Test:  [230/345]  eta: 0:00:09  loss: 0.7566 (0.7625)  time: 0.0895  data: 0.0001  max mem: 10917
[12:34:52.846632] Test:  [240/345]  eta: 0:00:09  loss: 0.7566 (0.7629)  time: 0.0899  data: 0.0001  max mem: 10917
[12:34:53.750395] Test:  [250/345]  eta: 0:00:08  loss: 0.7703 (0.7632)  time: 0.0902  data: 0.0001  max mem: 10917
[12:34:54.657596] Test:  [260/345]  eta: 0:00:07  loss: 0.7697 (0.7633)  time: 0.0905  data: 0.0001  max mem: 10917
[12:34:55.569827] Test:  [270/345]  eta: 0:00:06  loss: 0.7697 (0.7636)  time: 0.0909  data: 0.0001  max mem: 10917
[12:34:56.484981] Test:  [280/345]  eta: 0:00:05  loss: 0.7742 (0.7638)  time: 0.0913  data: 0.0001  max mem: 10917
[12:34:57.403266] Test:  [290/345]  eta: 0:00:04  loss: 0.7677 (0.7637)  time: 0.0916  data: 0.0001  max mem: 10917
[12:34:58.325288] Test:  [300/345]  eta: 0:00:03  loss: 0.7571 (0.7637)  time: 0.0920  data: 0.0001  max mem: 10917
[12:34:59.250375] Test:  [310/345]  eta: 0:00:03  loss: 0.7551 (0.7636)  time: 0.0923  data: 0.0001  max mem: 10917
[12:35:00.179346] Test:  [320/345]  eta: 0:00:02  loss: 0.7613 (0.7636)  time: 0.0927  data: 0.0001  max mem: 10917
[12:35:01.111482] Test:  [330/345]  eta: 0:00:01  loss: 0.7613 (0.7636)  time: 0.0930  data: 0.0001  max mem: 10917
[12:35:02.046815] Test:  [340/345]  eta: 0:00:00  loss: 0.7586 (0.7636)  time: 0.0933  data: 0.0001  max mem: 10917
[12:35:02.422658] Test:  [344/345]  eta: 0:00:00  loss: 0.7586 (0.7635)  time: 0.0935  data: 0.0001  max mem: 10917
[12:35:02.478722] Test: Total time: 0:00:30 (0.0885 s / it)
[12:35:13.139812] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8804 (0.8804)  time: 0.2142  data: 0.1345  max mem: 10917
[12:35:13.952827] Test:  [10/57]  eta: 0:00:04  loss: 0.8827 (0.8942)  time: 0.0933  data: 0.0123  max mem: 10917
[12:35:14.769874] Test:  [20/57]  eta: 0:00:03  loss: 0.8855 (0.8886)  time: 0.0814  data: 0.0001  max mem: 10917
[12:35:15.590283] Test:  [30/57]  eta: 0:00:02  loss: 0.7862 (0.8509)  time: 0.0818  data: 0.0001  max mem: 10917
[12:35:16.413809] Test:  [40/57]  eta: 0:00:01  loss: 0.7805 (0.8314)  time: 0.0821  data: 0.0001  max mem: 10917
[12:35:17.241762] Test:  [50/57]  eta: 0:00:00  loss: 0.7615 (0.8226)  time: 0.0825  data: 0.0001  max mem: 10917
[12:35:17.691325] Test:  [56/57]  eta: 0:00:00  loss: 0.7856 (0.8260)  time: 0.0803  data: 0.0001  max mem: 10917
[12:35:17.746878] Test: Total time: 0:00:04 (0.0846 s / it)
[12:35:19.590521] Dice score of the network on the train images: 0.791013, val images: 0.811250
[12:35:19.594220] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:35:19.990872] Epoch: [20]  [  0/345]  eta: 0:02:16  lr: 0.000125  loss: 0.7765 (0.7765)  time: 0.3956  data: 0.1431  max mem: 10917
[12:35:24.992079] Epoch: [20]  [ 20/345]  eta: 0:01:23  lr: 0.000125  loss: 0.7990 (0.7979)  time: 0.2500  data: 0.0000  max mem: 10917
[12:35:29.999801] Epoch: [20]  [ 40/345]  eta: 0:01:17  lr: 0.000125  loss: 0.8050 (0.8010)  time: 0.2503  data: 0.0000  max mem: 10917
[12:35:35.013570] Epoch: [20]  [ 60/345]  eta: 0:01:12  lr: 0.000125  loss: 0.8036 (0.8040)  time: 0.2506  data: 0.0001  max mem: 10917
[12:35:40.032838] Epoch: [20]  [ 80/345]  eta: 0:01:06  lr: 0.000125  loss: 0.8132 (0.8068)  time: 0.2509  data: 0.0001  max mem: 10917
[12:35:45.050326] Epoch: [20]  [100/345]  eta: 0:01:01  lr: 0.000125  loss: 0.8047 (0.8065)  time: 0.2508  data: 0.0000  max mem: 10917
[12:35:50.072554] Epoch: [20]  [120/345]  eta: 0:00:56  lr: 0.000125  loss: 0.8001 (0.8057)  time: 0.2511  data: 0.0000  max mem: 10917
[12:35:55.093432] Epoch: [20]  [140/345]  eta: 0:00:51  lr: 0.000125  loss: 0.8126 (0.8066)  time: 0.2510  data: 0.0001  max mem: 10917
[12:36:00.107147] Epoch: [20]  [160/345]  eta: 0:00:46  lr: 0.000125  loss: 0.8200 (0.8082)  time: 0.2506  data: 0.0000  max mem: 10917
[12:36:05.128447] Epoch: [20]  [180/345]  eta: 0:00:41  lr: 0.000125  loss: 0.8033 (0.8079)  time: 0.2510  data: 0.0001  max mem: 10917
[12:36:10.137307] Epoch: [20]  [200/345]  eta: 0:00:36  lr: 0.000125  loss: 0.8070 (0.8081)  time: 0.2504  data: 0.0001  max mem: 10917
[12:36:15.145976] Epoch: [20]  [220/345]  eta: 0:00:31  lr: 0.000125  loss: 0.7947 (0.8076)  time: 0.2504  data: 0.0001  max mem: 10917
[12:36:20.163140] Epoch: [20]  [240/345]  eta: 0:00:26  lr: 0.000125  loss: 0.8018 (0.8070)  time: 0.2508  data: 0.0000  max mem: 10917
[12:36:25.183560] Epoch: [20]  [260/345]  eta: 0:00:21  lr: 0.000125  loss: 0.7969 (0.8059)  time: 0.2510  data: 0.0000  max mem: 10917
[12:36:30.204694] Epoch: [20]  [280/345]  eta: 0:00:16  lr: 0.000125  loss: 0.7951 (0.8054)  time: 0.2510  data: 0.0000  max mem: 10917
[12:36:35.226555] Epoch: [20]  [300/345]  eta: 0:00:11  lr: 0.000125  loss: 0.7953 (0.8049)  time: 0.2510  data: 0.0000  max mem: 10917
[12:36:40.249310] Epoch: [20]  [320/345]  eta: 0:00:06  lr: 0.000125  loss: 0.7880 (0.8042)  time: 0.2511  data: 0.0001  max mem: 10917
[12:36:45.275772] Epoch: [20]  [340/345]  eta: 0:00:01  lr: 0.000125  loss: 0.7979 (0.8041)  time: 0.2513  data: 0.0001  max mem: 10917
[12:36:46.282412] Epoch: [20]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.8146 (0.8044)  time: 0.2513  data: 0.0001  max mem: 10917
[12:36:46.338744] Epoch: [20] Total time: 0:01:26 (0.2514 s / it)
[12:36:46.339135] Averaged stats: lr: 0.000125  loss: 0.8146 (0.8044)
[12:36:46.575461] Test:  [  0/345]  eta: 0:01:20  loss: 0.7679 (0.7679)  time: 0.2335  data: 0.1533  max mem: 10917
[12:36:47.402087] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7669 (0.7676)  time: 0.0963  data: 0.0147  max mem: 10917
[12:36:48.223968] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7647 (0.7681)  time: 0.0824  data: 0.0005  max mem: 10917
[12:36:49.050116] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7748 (0.7731)  time: 0.0823  data: 0.0001  max mem: 10917
[12:36:49.879585] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7810 (0.7745)  time: 0.0827  data: 0.0001  max mem: 10917
[12:36:50.712425] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7749 (0.7743)  time: 0.0831  data: 0.0001  max mem: 10917
[12:36:51.548816] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7734 (0.7735)  time: 0.0834  data: 0.0001  max mem: 10917
[12:36:52.388935] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7734 (0.7732)  time: 0.0838  data: 0.0001  max mem: 10917
[12:36:53.233131] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7734 (0.7731)  time: 0.0842  data: 0.0001  max mem: 10917
[12:36:54.079407] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7720 (0.7737)  time: 0.0845  data: 0.0001  max mem: 10917
[12:36:54.929594] Test:  [100/345]  eta: 0:00:20  loss: 0.7720 (0.7737)  time: 0.0848  data: 0.0001  max mem: 10917
[12:36:55.783072] Test:  [110/345]  eta: 0:00:19  loss: 0.7705 (0.7739)  time: 0.0851  data: 0.0001  max mem: 10917
[12:36:56.640412] Test:  [120/345]  eta: 0:00:19  loss: 0.7696 (0.7738)  time: 0.0855  data: 0.0001  max mem: 10917
[12:36:57.501536] Test:  [130/345]  eta: 0:00:18  loss: 0.7704 (0.7737)  time: 0.0859  data: 0.0001  max mem: 10917
[12:36:58.366036] Test:  [140/345]  eta: 0:00:17  loss: 0.7767 (0.7742)  time: 0.0862  data: 0.0001  max mem: 10917
[12:36:59.234653] Test:  [150/345]  eta: 0:00:16  loss: 0.7777 (0.7743)  time: 0.0866  data: 0.0001  max mem: 10917
[12:37:00.106251] Test:  [160/345]  eta: 0:00:15  loss: 0.7775 (0.7741)  time: 0.0870  data: 0.0001  max mem: 10917
[12:37:00.981379] Test:  [170/345]  eta: 0:00:14  loss: 0.7808 (0.7745)  time: 0.0873  data: 0.0001  max mem: 10917
[12:37:01.859640] Test:  [180/345]  eta: 0:00:14  loss: 0.7725 (0.7742)  time: 0.0876  data: 0.0001  max mem: 10917
[12:37:02.741782] Test:  [190/345]  eta: 0:00:13  loss: 0.7661 (0.7740)  time: 0.0880  data: 0.0001  max mem: 10917
[12:37:03.627596] Test:  [200/345]  eta: 0:00:12  loss: 0.7671 (0.7739)  time: 0.0884  data: 0.0001  max mem: 10917
[12:37:04.516984] Test:  [210/345]  eta: 0:00:11  loss: 0.7695 (0.7738)  time: 0.0887  data: 0.0001  max mem: 10917
[12:37:05.409629] Test:  [220/345]  eta: 0:00:10  loss: 0.7667 (0.7736)  time: 0.0891  data: 0.0001  max mem: 10917
[12:37:06.306472] Test:  [230/345]  eta: 0:00:09  loss: 0.7696 (0.7738)  time: 0.0894  data: 0.0001  max mem: 10917
[12:37:07.206488] Test:  [240/345]  eta: 0:00:09  loss: 0.7691 (0.7734)  time: 0.0898  data: 0.0001  max mem: 10917
[12:37:08.108973] Test:  [250/345]  eta: 0:00:08  loss: 0.7661 (0.7732)  time: 0.0901  data: 0.0001  max mem: 10917
[12:37:09.015290] Test:  [260/345]  eta: 0:00:07  loss: 0.7740 (0.7733)  time: 0.0904  data: 0.0001  max mem: 10917
[12:37:09.925785] Test:  [270/345]  eta: 0:00:06  loss: 0.7770 (0.7731)  time: 0.0908  data: 0.0001  max mem: 10917
[12:37:10.840148] Test:  [280/345]  eta: 0:00:05  loss: 0.7691 (0.7729)  time: 0.0912  data: 0.0001  max mem: 10917
[12:37:11.757513] Test:  [290/345]  eta: 0:00:04  loss: 0.7695 (0.7728)  time: 0.0915  data: 0.0001  max mem: 10917
[12:37:12.678580] Test:  [300/345]  eta: 0:00:03  loss: 0.7693 (0.7727)  time: 0.0919  data: 0.0001  max mem: 10917
[12:37:13.602553] Test:  [310/345]  eta: 0:00:03  loss: 0.7752 (0.7732)  time: 0.0922  data: 0.0001  max mem: 10917
[12:37:14.530002] Test:  [320/345]  eta: 0:00:02  loss: 0.7745 (0.7731)  time: 0.0925  data: 0.0001  max mem: 10917
[12:37:15.461665] Test:  [330/345]  eta: 0:00:01  loss: 0.7678 (0.7730)  time: 0.0929  data: 0.0001  max mem: 10917
[12:37:16.396312] Test:  [340/345]  eta: 0:00:00  loss: 0.7563 (0.7726)  time: 0.0933  data: 0.0001  max mem: 10917
[12:37:16.771346] Test:  [344/345]  eta: 0:00:00  loss: 0.7532 (0.7725)  time: 0.0934  data: 0.0001  max mem: 10917
[12:37:16.827741] Test: Total time: 0:00:30 (0.0884 s / it)
[12:37:27.569081] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8850 (0.8850)  time: 0.2185  data: 0.1384  max mem: 10917
[12:37:28.384923] Test:  [10/57]  eta: 0:00:04  loss: 0.9217 (0.9181)  time: 0.0939  data: 0.0128  max mem: 10917
[12:37:29.202774] Test:  [20/57]  eta: 0:00:03  loss: 0.8913 (0.8939)  time: 0.0816  data: 0.0001  max mem: 10917
[12:37:30.023148] Test:  [30/57]  eta: 0:00:02  loss: 0.7827 (0.8540)  time: 0.0819  data: 0.0001  max mem: 10917
[12:37:30.847026] Test:  [40/57]  eta: 0:00:01  loss: 0.7804 (0.8335)  time: 0.0822  data: 0.0001  max mem: 10917
[12:37:31.674920] Test:  [50/57]  eta: 0:00:00  loss: 0.7637 (0.8254)  time: 0.0825  data: 0.0001  max mem: 10917
[12:37:32.124521] Test:  [56/57]  eta: 0:00:00  loss: 0.7895 (0.8280)  time: 0.0803  data: 0.0001  max mem: 10917
[12:37:32.181421] Test: Total time: 0:00:04 (0.0848 s / it)
[12:37:34.052845] Dice score of the network on the train images: 0.782602, val images: 0.804183
[12:37:34.056563] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:37:34.451493] Epoch: [21]  [  0/345]  eta: 0:02:15  lr: 0.000125  loss: 0.8505 (0.8505)  time: 0.3939  data: 0.1417  max mem: 10917
[12:37:39.529423] Epoch: [21]  [ 20/345]  eta: 0:01:24  lr: 0.000125  loss: 0.7960 (0.8030)  time: 0.2538  data: 0.0001  max mem: 10917
[12:37:44.529196] Epoch: [21]  [ 40/345]  eta: 0:01:17  lr: 0.000125  loss: 0.7964 (0.8056)  time: 0.2499  data: 0.0000  max mem: 10917
[12:37:49.537889] Epoch: [21]  [ 60/345]  eta: 0:01:12  lr: 0.000125  loss: 0.8098 (0.8084)  time: 0.2504  data: 0.0001  max mem: 10917
[12:37:54.547811] Epoch: [21]  [ 80/345]  eta: 0:01:07  lr: 0.000124  loss: 0.7955 (0.8054)  time: 0.2505  data: 0.0000  max mem: 10917
[12:37:59.558926] Epoch: [21]  [100/345]  eta: 0:01:01  lr: 0.000124  loss: 0.8010 (0.8044)  time: 0.2505  data: 0.0001  max mem: 10917
[12:38:04.574570] Epoch: [21]  [120/345]  eta: 0:00:56  lr: 0.000124  loss: 0.8061 (0.8043)  time: 0.2507  data: 0.0001  max mem: 10917
[12:38:09.591266] Epoch: [21]  [140/345]  eta: 0:00:51  lr: 0.000124  loss: 0.7993 (0.8045)  time: 0.2508  data: 0.0000  max mem: 10917
[12:38:14.613893] Epoch: [21]  [160/345]  eta: 0:00:46  lr: 0.000124  loss: 0.7982 (0.8033)  time: 0.2511  data: 0.0001  max mem: 10917
[12:38:19.633662] Epoch: [21]  [180/345]  eta: 0:00:41  lr: 0.000124  loss: 0.8064 (0.8042)  time: 0.2509  data: 0.0000  max mem: 10917
[12:38:24.658563] Epoch: [21]  [200/345]  eta: 0:00:36  lr: 0.000124  loss: 0.8167 (0.8057)  time: 0.2512  data: 0.0001  max mem: 10917
[12:38:29.686007] Epoch: [21]  [220/345]  eta: 0:00:31  lr: 0.000124  loss: 0.8138 (0.8064)  time: 0.2513  data: 0.0000  max mem: 10917
[12:38:34.706323] Epoch: [21]  [240/345]  eta: 0:00:26  lr: 0.000124  loss: 0.7979 (0.8062)  time: 0.2510  data: 0.0001  max mem: 10917
[12:38:39.740870] Epoch: [21]  [260/345]  eta: 0:00:21  lr: 0.000124  loss: 0.8044 (0.8059)  time: 0.2517  data: 0.0001  max mem: 10917
[12:38:44.769669] Epoch: [21]  [280/345]  eta: 0:00:16  lr: 0.000124  loss: 0.7924 (0.8051)  time: 0.2514  data: 0.0001  max mem: 10917
[12:38:49.793969] Epoch: [21]  [300/345]  eta: 0:00:11  lr: 0.000124  loss: 0.8022 (0.8049)  time: 0.2512  data: 0.0001  max mem: 10917
[12:38:54.829136] Epoch: [21]  [320/345]  eta: 0:00:06  lr: 0.000124  loss: 0.7917 (0.8041)  time: 0.2517  data: 0.0000  max mem: 10917
[12:38:59.865337] Epoch: [21]  [340/345]  eta: 0:00:01  lr: 0.000124  loss: 0.7980 (0.8039)  time: 0.2518  data: 0.0000  max mem: 10917
[12:39:00.872360] Epoch: [21]  [344/345]  eta: 0:00:00  lr: 0.000124  loss: 0.7974 (0.8037)  time: 0.2518  data: 0.0001  max mem: 10917
[12:39:00.934875] Epoch: [21] Total time: 0:01:26 (0.2518 s / it)
[12:39:00.935379] Averaged stats: lr: 0.000124  loss: 0.7974 (0.8037)
[12:39:01.173393] Test:  [  0/345]  eta: 0:01:20  loss: 0.8000 (0.8000)  time: 0.2342  data: 0.1540  max mem: 10917
[12:39:01.994050] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7523 (0.7623)  time: 0.0958  data: 0.0141  max mem: 10917
[12:39:02.816679] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7609 (0.7634)  time: 0.0821  data: 0.0001  max mem: 10917
[12:39:03.642934] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7668 (0.7628)  time: 0.0824  data: 0.0001  max mem: 10917
[12:39:04.472979] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7607 (0.7627)  time: 0.0828  data: 0.0001  max mem: 10917
[12:39:05.305971] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7606 (0.7630)  time: 0.0831  data: 0.0001  max mem: 10917
[12:39:06.143465] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7556 (0.7621)  time: 0.0835  data: 0.0001  max mem: 10917
[12:39:06.984546] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7547 (0.7625)  time: 0.0839  data: 0.0001  max mem: 10917
[12:39:07.828808] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7547 (0.7616)  time: 0.0842  data: 0.0001  max mem: 10917
[12:39:08.676906] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7600 (0.7615)  time: 0.0846  data: 0.0001  max mem: 10917
[12:39:09.528389] Test:  [100/345]  eta: 0:00:20  loss: 0.7627 (0.7618)  time: 0.0849  data: 0.0001  max mem: 10917
[12:39:10.382241] Test:  [110/345]  eta: 0:00:19  loss: 0.7512 (0.7608)  time: 0.0852  data: 0.0001  max mem: 10917
[12:39:11.240870] Test:  [120/345]  eta: 0:00:19  loss: 0.7514 (0.7613)  time: 0.0856  data: 0.0001  max mem: 10917
[12:39:12.103475] Test:  [130/345]  eta: 0:00:18  loss: 0.7569 (0.7610)  time: 0.0860  data: 0.0001  max mem: 10917
[12:39:12.969277] Test:  [140/345]  eta: 0:00:17  loss: 0.7604 (0.7611)  time: 0.0864  data: 0.0001  max mem: 10917
[12:39:13.838821] Test:  [150/345]  eta: 0:00:16  loss: 0.7606 (0.7609)  time: 0.0867  data: 0.0001  max mem: 10917
[12:39:14.711717] Test:  [160/345]  eta: 0:00:15  loss: 0.7649 (0.7611)  time: 0.0871  data: 0.0001  max mem: 10917
[12:39:15.587647] Test:  [170/345]  eta: 0:00:14  loss: 0.7621 (0.7609)  time: 0.0874  data: 0.0001  max mem: 10917
[12:39:16.466949] Test:  [180/345]  eta: 0:00:14  loss: 0.7621 (0.7612)  time: 0.0877  data: 0.0001  max mem: 10917
[12:39:17.349419] Test:  [190/345]  eta: 0:00:13  loss: 0.7710 (0.7617)  time: 0.0880  data: 0.0001  max mem: 10917
[12:39:18.235662] Test:  [200/345]  eta: 0:00:12  loss: 0.7688 (0.7623)  time: 0.0884  data: 0.0001  max mem: 10917
[12:39:19.125106] Test:  [210/345]  eta: 0:00:11  loss: 0.7623 (0.7620)  time: 0.0887  data: 0.0001  max mem: 10917
[12:39:20.017872] Test:  [220/345]  eta: 0:00:10  loss: 0.7542 (0.7616)  time: 0.0891  data: 0.0001  max mem: 10917
[12:39:20.913947] Test:  [230/345]  eta: 0:00:09  loss: 0.7565 (0.7615)  time: 0.0894  data: 0.0001  max mem: 10917
[12:39:21.814491] Test:  [240/345]  eta: 0:00:09  loss: 0.7630 (0.7617)  time: 0.0898  data: 0.0001  max mem: 10917
[12:39:22.717766] Test:  [250/345]  eta: 0:00:08  loss: 0.7593 (0.7614)  time: 0.0901  data: 0.0001  max mem: 10917
[12:39:23.625393] Test:  [260/345]  eta: 0:00:07  loss: 0.7547 (0.7614)  time: 0.0905  data: 0.0001  max mem: 10917
[12:39:24.536659] Test:  [270/345]  eta: 0:00:06  loss: 0.7568 (0.7613)  time: 0.0909  data: 0.0001  max mem: 10917
[12:39:25.449922] Test:  [280/345]  eta: 0:00:05  loss: 0.7597 (0.7613)  time: 0.0912  data: 0.0001  max mem: 10917
[12:39:26.367437] Test:  [290/345]  eta: 0:00:04  loss: 0.7638 (0.7615)  time: 0.0915  data: 0.0001  max mem: 10917
[12:39:27.288679] Test:  [300/345]  eta: 0:00:03  loss: 0.7638 (0.7616)  time: 0.0919  data: 0.0001  max mem: 10917
[12:39:28.212716] Test:  [310/345]  eta: 0:00:03  loss: 0.7642 (0.7621)  time: 0.0922  data: 0.0001  max mem: 10917
[12:39:29.140377] Test:  [320/345]  eta: 0:00:02  loss: 0.7702 (0.7622)  time: 0.0925  data: 0.0001  max mem: 10917
[12:39:30.072429] Test:  [330/345]  eta: 0:00:01  loss: 0.7618 (0.7620)  time: 0.0929  data: 0.0001  max mem: 10917
[12:39:31.007078] Test:  [340/345]  eta: 0:00:00  loss: 0.7572 (0.7620)  time: 0.0933  data: 0.0001  max mem: 10917
[12:39:31.382447] Test:  [344/345]  eta: 0:00:00  loss: 0.7572 (0.7620)  time: 0.0934  data: 0.0001  max mem: 10917
[12:39:31.441522] Test: Total time: 0:00:30 (0.0884 s / it)
[12:39:42.239578] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8626 (0.8626)  time: 0.2269  data: 0.1470  max mem: 10917
[12:39:43.052504] Test:  [10/57]  eta: 0:00:04  loss: 0.8677 (0.8866)  time: 0.0944  data: 0.0134  max mem: 10917
[12:39:43.870301] Test:  [20/57]  eta: 0:00:03  loss: 0.8684 (0.8756)  time: 0.0815  data: 0.0001  max mem: 10917
[12:39:44.690930] Test:  [30/57]  eta: 0:00:02  loss: 0.7741 (0.8391)  time: 0.0819  data: 0.0001  max mem: 10917
[12:39:45.515159] Test:  [40/57]  eta: 0:00:01  loss: 0.7713 (0.8187)  time: 0.0822  data: 0.0001  max mem: 10917
[12:39:46.342572] Test:  [50/57]  eta: 0:00:00  loss: 0.7603 (0.8126)  time: 0.0825  data: 0.0001  max mem: 10917
[12:39:46.792716] Test:  [56/57]  eta: 0:00:00  loss: 0.7877 (0.8171)  time: 0.0803  data: 0.0001  max mem: 10917
[12:39:46.849459] Test: Total time: 0:00:04 (0.0849 s / it)
[12:39:48.711757] Dice score of the network on the train images: 0.774486, val images: 0.805389
[12:39:48.715480] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:39:49.112331] Epoch: [22]  [  0/345]  eta: 0:02:16  lr: 0.000124  loss: 0.7770 (0.7770)  time: 0.3958  data: 0.1442  max mem: 10917
[12:39:54.103203] Epoch: [22]  [ 20/345]  eta: 0:01:23  lr: 0.000124  loss: 0.7918 (0.7933)  time: 0.2495  data: 0.0001  max mem: 10917
[12:39:59.107266] Epoch: [22]  [ 40/345]  eta: 0:01:17  lr: 0.000123  loss: 0.7849 (0.7916)  time: 0.2502  data: 0.0000  max mem: 10917
[12:40:04.116875] Epoch: [22]  [ 60/345]  eta: 0:01:11  lr: 0.000123  loss: 0.7882 (0.7907)  time: 0.2504  data: 0.0000  max mem: 10917
[12:40:09.129887] Epoch: [22]  [ 80/345]  eta: 0:01:06  lr: 0.000123  loss: 0.8074 (0.7938)  time: 0.2506  data: 0.0000  max mem: 10917
[12:40:14.145537] Epoch: [22]  [100/345]  eta: 0:01:01  lr: 0.000123  loss: 0.7954 (0.7946)  time: 0.2507  data: 0.0000  max mem: 10917
[12:40:19.165085] Epoch: [22]  [120/345]  eta: 0:00:56  lr: 0.000123  loss: 0.7881 (0.7941)  time: 0.2509  data: 0.0000  max mem: 10917
[12:40:24.186308] Epoch: [22]  [140/345]  eta: 0:00:51  lr: 0.000123  loss: 0.7961 (0.7947)  time: 0.2510  data: 0.0000  max mem: 10917
[12:40:29.207620] Epoch: [22]  [160/345]  eta: 0:00:46  lr: 0.000123  loss: 0.8020 (0.7951)  time: 0.2510  data: 0.0000  max mem: 10917
[12:40:34.233425] Epoch: [22]  [180/345]  eta: 0:00:41  lr: 0.000123  loss: 0.8047 (0.7963)  time: 0.2512  data: 0.0001  max mem: 10917
[12:40:39.260432] Epoch: [22]  [200/345]  eta: 0:00:36  lr: 0.000123  loss: 0.7939 (0.7966)  time: 0.2513  data: 0.0000  max mem: 10917
[12:40:44.290827] Epoch: [22]  [220/345]  eta: 0:00:31  lr: 0.000123  loss: 0.7864 (0.7958)  time: 0.2515  data: 0.0000  max mem: 10917
[12:40:49.322172] Epoch: [22]  [240/345]  eta: 0:00:26  lr: 0.000123  loss: 0.7952 (0.7956)  time: 0.2515  data: 0.0001  max mem: 10917
[12:40:54.351558] Epoch: [22]  [260/345]  eta: 0:00:21  lr: 0.000122  loss: 0.7943 (0.7954)  time: 0.2514  data: 0.0000  max mem: 10917
[12:40:59.375017] Epoch: [22]  [280/345]  eta: 0:00:16  lr: 0.000122  loss: 0.7831 (0.7949)  time: 0.2511  data: 0.0001  max mem: 10917
[12:41:04.402386] Epoch: [22]  [300/345]  eta: 0:00:11  lr: 0.000122  loss: 0.7881 (0.7945)  time: 0.2513  data: 0.0001  max mem: 10917
[12:41:09.427315] Epoch: [22]  [320/345]  eta: 0:00:06  lr: 0.000122  loss: 0.7848 (0.7938)  time: 0.2512  data: 0.0001  max mem: 10917
[12:41:14.450531] Epoch: [22]  [340/345]  eta: 0:00:01  lr: 0.000122  loss: 0.7800 (0.7932)  time: 0.2511  data: 0.0001  max mem: 10917
[12:41:15.457471] Epoch: [22]  [344/345]  eta: 0:00:00  lr: 0.000122  loss: 0.7870 (0.7932)  time: 0.2512  data: 0.0001  max mem: 10917
[12:41:15.515861] Epoch: [22] Total time: 0:01:26 (0.2516 s / it)
[12:41:15.516363] Averaged stats: lr: 0.000122  loss: 0.7870 (0.7932)
[12:41:15.747224] Test:  [  0/345]  eta: 0:01:18  loss: 0.7380 (0.7380)  time: 0.2282  data: 0.1478  max mem: 10917
[12:41:16.568432] Test:  [ 10/345]  eta: 0:00:31  loss: 0.7471 (0.7505)  time: 0.0953  data: 0.0135  max mem: 10917
[12:41:17.391383] Test:  [ 20/345]  eta: 0:00:28  loss: 0.7541 (0.7565)  time: 0.0821  data: 0.0001  max mem: 10917
[12:41:18.218040] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7540 (0.7549)  time: 0.0824  data: 0.0001  max mem: 10917
[12:41:19.048519] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7520 (0.7548)  time: 0.0828  data: 0.0001  max mem: 10917
[12:41:19.881593] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7510 (0.7565)  time: 0.0831  data: 0.0001  max mem: 10917
[12:41:20.718835] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7579 (0.7570)  time: 0.0835  data: 0.0001  max mem: 10917
[12:41:21.559924] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7550 (0.7566)  time: 0.0839  data: 0.0001  max mem: 10917
[12:41:22.403522] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7565 (0.7577)  time: 0.0842  data: 0.0001  max mem: 10917
[12:41:23.251938] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7570 (0.7565)  time: 0.0846  data: 0.0001  max mem: 10917
[12:41:24.103076] Test:  [100/345]  eta: 0:00:20  loss: 0.7573 (0.7570)  time: 0.0849  data: 0.0001  max mem: 10917
[12:41:24.958142] Test:  [110/345]  eta: 0:00:19  loss: 0.7573 (0.7569)  time: 0.0853  data: 0.0001  max mem: 10917
[12:41:25.817525] Test:  [120/345]  eta: 0:00:19  loss: 0.7477 (0.7562)  time: 0.0857  data: 0.0001  max mem: 10917
[12:41:26.680077] Test:  [130/345]  eta: 0:00:18  loss: 0.7451 (0.7560)  time: 0.0860  data: 0.0001  max mem: 10917
[12:41:27.545517] Test:  [140/345]  eta: 0:00:17  loss: 0.7500 (0.7559)  time: 0.0863  data: 0.0001  max mem: 10917
[12:41:28.414014] Test:  [150/345]  eta: 0:00:16  loss: 0.7538 (0.7562)  time: 0.0866  data: 0.0001  max mem: 10917
[12:41:29.287092] Test:  [160/345]  eta: 0:00:15  loss: 0.7510 (0.7561)  time: 0.0870  data: 0.0001  max mem: 10917
[12:41:30.163646] Test:  [170/345]  eta: 0:00:14  loss: 0.7437 (0.7555)  time: 0.0874  data: 0.0001  max mem: 10917
[12:41:31.044835] Test:  [180/345]  eta: 0:00:14  loss: 0.7466 (0.7554)  time: 0.0878  data: 0.0001  max mem: 10917
[12:41:31.927969] Test:  [190/345]  eta: 0:00:13  loss: 0.7525 (0.7553)  time: 0.0881  data: 0.0001  max mem: 10917
[12:41:32.814905] Test:  [200/345]  eta: 0:00:12  loss: 0.7575 (0.7555)  time: 0.0885  data: 0.0001  max mem: 10917
[12:41:33.705147] Test:  [210/345]  eta: 0:00:11  loss: 0.7496 (0.7549)  time: 0.0888  data: 0.0001  max mem: 10917
[12:41:34.597870] Test:  [220/345]  eta: 0:00:10  loss: 0.7489 (0.7551)  time: 0.0891  data: 0.0001  max mem: 10917
[12:41:35.496017] Test:  [230/345]  eta: 0:00:09  loss: 0.7564 (0.7554)  time: 0.0895  data: 0.0001  max mem: 10917
[12:41:36.398144] Test:  [240/345]  eta: 0:00:09  loss: 0.7561 (0.7551)  time: 0.0900  data: 0.0001  max mem: 10917
[12:41:37.302426] Test:  [250/345]  eta: 0:00:08  loss: 0.7544 (0.7555)  time: 0.0903  data: 0.0001  max mem: 10917
[12:41:38.211326] Test:  [260/345]  eta: 0:00:07  loss: 0.7521 (0.7554)  time: 0.0906  data: 0.0001  max mem: 10917
[12:41:39.123137] Test:  [270/345]  eta: 0:00:06  loss: 0.7491 (0.7554)  time: 0.0910  data: 0.0001  max mem: 10917
[12:41:40.038242] Test:  [280/345]  eta: 0:00:05  loss: 0.7475 (0.7552)  time: 0.0913  data: 0.0001  max mem: 10917
[12:41:40.956296] Test:  [290/345]  eta: 0:00:04  loss: 0.7481 (0.7549)  time: 0.0916  data: 0.0001  max mem: 10917
[12:41:41.877788] Test:  [300/345]  eta: 0:00:03  loss: 0.7481 (0.7547)  time: 0.0919  data: 0.0001  max mem: 10917
[12:41:42.802510] Test:  [310/345]  eta: 0:00:03  loss: 0.7468 (0.7550)  time: 0.0923  data: 0.0001  max mem: 10917
[12:41:43.731827] Test:  [320/345]  eta: 0:00:02  loss: 0.7563 (0.7552)  time: 0.0927  data: 0.0001  max mem: 10917
[12:41:44.663854] Test:  [330/345]  eta: 0:00:01  loss: 0.7563 (0.7552)  time: 0.0930  data: 0.0001  max mem: 10917
[12:41:45.599346] Test:  [340/345]  eta: 0:00:00  loss: 0.7593 (0.7553)  time: 0.0933  data: 0.0001  max mem: 10917
[12:41:45.975070] Test:  [344/345]  eta: 0:00:00  loss: 0.7611 (0.7555)  time: 0.0935  data: 0.0001  max mem: 10917
[12:41:46.033793] Test: Total time: 0:00:30 (0.0885 s / it)
[12:41:56.782366] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8686 (0.8686)  time: 0.2190  data: 0.1389  max mem: 10917
[12:41:57.596478] Test:  [10/57]  eta: 0:00:04  loss: 0.8704 (0.8932)  time: 0.0938  data: 0.0127  max mem: 10917
[12:41:58.415160] Test:  [20/57]  eta: 0:00:03  loss: 0.8704 (0.8862)  time: 0.0816  data: 0.0001  max mem: 10917
[12:41:59.236145] Test:  [30/57]  eta: 0:00:02  loss: 0.7784 (0.8466)  time: 0.0819  data: 0.0001  max mem: 10917
[12:42:00.060205] Test:  [40/57]  eta: 0:00:01  loss: 0.7658 (0.8247)  time: 0.0822  data: 0.0001  max mem: 10917
[12:42:00.889271] Test:  [50/57]  eta: 0:00:00  loss: 0.7577 (0.8169)  time: 0.0826  data: 0.0001  max mem: 10917
[12:42:01.338775] Test:  [56/57]  eta: 0:00:00  loss: 0.7873 (0.8213)  time: 0.0804  data: 0.0001  max mem: 10917
[12:42:01.395971] Test: Total time: 0:00:04 (0.0848 s / it)
[12:42:03.238572] Dice score of the network on the train images: 0.794694, val images: 0.811303
[12:42:03.242060] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:42:03.634640] Epoch: [23]  [  0/345]  eta: 0:02:15  lr: 0.000122  loss: 0.7795 (0.7795)  time: 0.3916  data: 0.1400  max mem: 10917
[12:42:08.618074] Epoch: [23]  [ 20/345]  eta: 0:01:23  lr: 0.000122  loss: 0.7773 (0.7817)  time: 0.2491  data: 0.0001  max mem: 10917
[12:42:13.603679] Epoch: [23]  [ 40/345]  eta: 0:01:17  lr: 0.000122  loss: 0.7802 (0.7833)  time: 0.2492  data: 0.0001  max mem: 10917
[12:42:18.599137] Epoch: [23]  [ 60/345]  eta: 0:01:11  lr: 0.000122  loss: 0.7762 (0.7823)  time: 0.2497  data: 0.0001  max mem: 10917
[12:42:23.598625] Epoch: [23]  [ 80/345]  eta: 0:01:06  lr: 0.000121  loss: 0.7759 (0.7822)  time: 0.2499  data: 0.0001  max mem: 10917
[12:42:28.600043] Epoch: [23]  [100/345]  eta: 0:01:01  lr: 0.000121  loss: 0.7915 (0.7849)  time: 0.2500  data: 0.0001  max mem: 10917
[12:42:33.617134] Epoch: [23]  [120/345]  eta: 0:00:56  lr: 0.000121  loss: 0.7876 (0.7851)  time: 0.2508  data: 0.0001  max mem: 10917
[12:42:38.637736] Epoch: [23]  [140/345]  eta: 0:00:51  lr: 0.000121  loss: 0.7834 (0.7853)  time: 0.2510  data: 0.0000  max mem: 10917
[12:42:43.659582] Epoch: [23]  [160/345]  eta: 0:00:46  lr: 0.000121  loss: 0.7865 (0.7855)  time: 0.2510  data: 0.0000  max mem: 10917
[12:42:48.682376] Epoch: [23]  [180/345]  eta: 0:00:41  lr: 0.000121  loss: 0.7770 (0.7848)  time: 0.2511  data: 0.0000  max mem: 10917
[12:42:53.705722] Epoch: [23]  [200/345]  eta: 0:00:36  lr: 0.000121  loss: 0.7966 (0.7860)  time: 0.2511  data: 0.0000  max mem: 10917
[12:42:58.730374] Epoch: [23]  [220/345]  eta: 0:00:31  lr: 0.000121  loss: 0.7925 (0.7868)  time: 0.2512  data: 0.0000  max mem: 10917
[12:43:03.751572] Epoch: [23]  [240/345]  eta: 0:00:26  lr: 0.000120  loss: 0.7946 (0.7874)  time: 0.2510  data: 0.0001  max mem: 10917
[12:43:08.772692] Epoch: [23]  [260/345]  eta: 0:00:21  lr: 0.000120  loss: 0.7910 (0.7881)  time: 0.2510  data: 0.0000  max mem: 10917
[12:43:13.792050] Epoch: [23]  [280/345]  eta: 0:00:16  lr: 0.000120  loss: 0.8038 (0.7891)  time: 0.2509  data: 0.0001  max mem: 10917
[12:43:18.814329] Epoch: [23]  [300/345]  eta: 0:00:11  lr: 0.000120  loss: 0.7908 (0.7895)  time: 0.2511  data: 0.0001  max mem: 10917
[12:43:23.832541] Epoch: [23]  [320/345]  eta: 0:00:06  lr: 0.000120  loss: 0.8152 (0.7916)  time: 0.2509  data: 0.0001  max mem: 10917
[12:43:28.855883] Epoch: [23]  [340/345]  eta: 0:00:01  lr: 0.000120  loss: 0.8176 (0.7932)  time: 0.2511  data: 0.0000  max mem: 10917
[12:43:29.861812] Epoch: [23]  [344/345]  eta: 0:00:00  lr: 0.000120  loss: 0.8132 (0.7932)  time: 0.2511  data: 0.0001  max mem: 10917
[12:43:29.927045] Epoch: [23] Total time: 0:01:26 (0.2513 s / it)
[12:43:29.927413] Averaged stats: lr: 0.000120  loss: 0.8132 (0.7932)
[12:43:30.162935] Test:  [  0/345]  eta: 0:01:20  loss: 0.7536 (0.7536)  time: 0.2329  data: 0.1529  max mem: 10917
[12:43:31.033242] Test:  [ 10/345]  eta: 0:00:33  loss: 0.7721 (0.7819)  time: 0.1002  data: 0.0189  max mem: 10917
[12:43:31.856060] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7721 (0.7814)  time: 0.0846  data: 0.0028  max mem: 10917
[12:43:32.683514] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7693 (0.7790)  time: 0.0825  data: 0.0001  max mem: 10917
[12:43:33.512434] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7764 (0.7776)  time: 0.0828  data: 0.0001  max mem: 10917
[12:43:34.346054] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7742 (0.7771)  time: 0.0831  data: 0.0001  max mem: 10917
[12:43:35.181826] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7742 (0.7774)  time: 0.0834  data: 0.0001  max mem: 10917
[12:43:36.021488] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7760 (0.7770)  time: 0.0837  data: 0.0001  max mem: 10917
[12:43:36.864992] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7728 (0.7759)  time: 0.0841  data: 0.0001  max mem: 10917
[12:43:37.712570] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7742 (0.7764)  time: 0.0845  data: 0.0001  max mem: 10917
[12:43:38.563417] Test:  [100/345]  eta: 0:00:20  loss: 0.7751 (0.7758)  time: 0.0849  data: 0.0001  max mem: 10917
[12:43:39.417596] Test:  [110/345]  eta: 0:00:20  loss: 0.7669 (0.7758)  time: 0.0852  data: 0.0001  max mem: 10917
[12:43:40.274967] Test:  [120/345]  eta: 0:00:19  loss: 0.7732 (0.7769)  time: 0.0855  data: 0.0001  max mem: 10917
[12:43:41.135903] Test:  [130/345]  eta: 0:00:18  loss: 0.7708 (0.7765)  time: 0.0859  data: 0.0001  max mem: 10917
[12:43:42.000316] Test:  [140/345]  eta: 0:00:17  loss: 0.7728 (0.7771)  time: 0.0862  data: 0.0001  max mem: 10917
[12:43:42.868830] Test:  [150/345]  eta: 0:00:16  loss: 0.7802 (0.7774)  time: 0.0866  data: 0.0001  max mem: 10917
[12:43:43.742225] Test:  [160/345]  eta: 0:00:15  loss: 0.7653 (0.7762)  time: 0.0870  data: 0.0001  max mem: 10917
[12:43:44.616976] Test:  [170/345]  eta: 0:00:15  loss: 0.7652 (0.7759)  time: 0.0874  data: 0.0001  max mem: 10917
[12:43:45.495980] Test:  [180/345]  eta: 0:00:14  loss: 0.7771 (0.7758)  time: 0.0876  data: 0.0001  max mem: 10917
[12:43:46.378393] Test:  [190/345]  eta: 0:00:13  loss: 0.7672 (0.7749)  time: 0.0880  data: 0.0001  max mem: 10917
[12:43:47.265450] Test:  [200/345]  eta: 0:00:12  loss: 0.7660 (0.7747)  time: 0.0884  data: 0.0001  max mem: 10917
[12:43:48.155170] Test:  [210/345]  eta: 0:00:11  loss: 0.7699 (0.7749)  time: 0.0888  data: 0.0001  max mem: 10917
[12:43:49.048544] Test:  [220/345]  eta: 0:00:10  loss: 0.7745 (0.7750)  time: 0.0891  data: 0.0001  max mem: 10917
[12:43:49.944690] Test:  [230/345]  eta: 0:00:09  loss: 0.7720 (0.7748)  time: 0.0894  data: 0.0001  max mem: 10917
[12:43:50.844436] Test:  [240/345]  eta: 0:00:09  loss: 0.7687 (0.7750)  time: 0.0897  data: 0.0001  max mem: 10917
[12:43:51.746804] Test:  [250/345]  eta: 0:00:08  loss: 0.7654 (0.7748)  time: 0.0901  data: 0.0001  max mem: 10917
[12:43:52.652678] Test:  [260/345]  eta: 0:00:07  loss: 0.7650 (0.7747)  time: 0.0904  data: 0.0001  max mem: 10917
[12:43:53.562471] Test:  [270/345]  eta: 0:00:06  loss: 0.7764 (0.7747)  time: 0.0907  data: 0.0001  max mem: 10917
[12:43:54.476703] Test:  [280/345]  eta: 0:00:05  loss: 0.7721 (0.7745)  time: 0.0912  data: 0.0001  max mem: 10917
[12:43:55.393885] Test:  [290/345]  eta: 0:00:04  loss: 0.7672 (0.7745)  time: 0.0915  data: 0.0001  max mem: 10917
[12:43:56.314790] Test:  [300/345]  eta: 0:00:03  loss: 0.7794 (0.7747)  time: 0.0919  data: 0.0001  max mem: 10917
[12:43:57.238476] Test:  [310/345]  eta: 0:00:03  loss: 0.7799 (0.7747)  time: 0.0922  data: 0.0001  max mem: 10917
[12:43:58.165972] Test:  [320/345]  eta: 0:00:02  loss: 0.7750 (0.7745)  time: 0.0925  data: 0.0001  max mem: 10917
[12:43:59.097298] Test:  [330/345]  eta: 0:00:01  loss: 0.7709 (0.7749)  time: 0.0929  data: 0.0001  max mem: 10917
[12:44:00.031657] Test:  [340/345]  eta: 0:00:00  loss: 0.7802 (0.7750)  time: 0.0932  data: 0.0001  max mem: 10917
[12:44:00.406319] Test:  [344/345]  eta: 0:00:00  loss: 0.7777 (0.7749)  time: 0.0934  data: 0.0001  max mem: 10917
[12:44:00.463010] Test: Total time: 0:00:30 (0.0885 s / it)
[12:44:11.197785] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8829 (0.8829)  time: 0.2212  data: 0.1415  max mem: 10917
[12:44:12.011735] Test:  [10/57]  eta: 0:00:04  loss: 0.8829 (0.8927)  time: 0.0940  data: 0.0129  max mem: 10917
[12:44:12.829897] Test:  [20/57]  eta: 0:00:03  loss: 0.8789 (0.8900)  time: 0.0815  data: 0.0001  max mem: 10917
[12:44:13.650114] Test:  [30/57]  eta: 0:00:02  loss: 0.7750 (0.8482)  time: 0.0818  data: 0.0001  max mem: 10917
[12:44:14.474159] Test:  [40/57]  eta: 0:00:01  loss: 0.7653 (0.8249)  time: 0.0822  data: 0.0001  max mem: 10917
[12:44:15.302586] Test:  [50/57]  eta: 0:00:00  loss: 0.7553 (0.8174)  time: 0.0826  data: 0.0001  max mem: 10917
[12:44:15.752460] Test:  [56/57]  eta: 0:00:00  loss: 0.7858 (0.8229)  time: 0.0804  data: 0.0001  max mem: 10917
[12:44:15.807939] Test: Total time: 0:00:04 (0.0848 s / it)
[12:44:17.639558] Dice score of the network on the train images: 0.768692, val images: 0.800414
[12:44:17.643249] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:44:18.040773] Epoch: [24]  [  0/345]  eta: 0:02:16  lr: 0.000120  loss: 0.8282 (0.8282)  time: 0.3965  data: 0.1450  max mem: 10917
[12:44:23.021016] Epoch: [24]  [ 20/345]  eta: 0:01:23  lr: 0.000119  loss: 0.7988 (0.8043)  time: 0.2490  data: 0.0001  max mem: 10917
[12:44:28.003256] Epoch: [24]  [ 40/345]  eta: 0:01:17  lr: 0.000119  loss: 0.7976 (0.8020)  time: 0.2491  data: 0.0000  max mem: 10917
[12:44:32.998850] Epoch: [24]  [ 60/345]  eta: 0:01:11  lr: 0.000119  loss: 0.7801 (0.7962)  time: 0.2497  data: 0.0001  max mem: 10917
[12:44:37.997374] Epoch: [24]  [ 80/345]  eta: 0:01:06  lr: 0.000119  loss: 0.7833 (0.7942)  time: 0.2499  data: 0.0000  max mem: 10917
[12:44:42.999382] Epoch: [24]  [100/345]  eta: 0:01:01  lr: 0.000119  loss: 0.7860 (0.7933)  time: 0.2501  data: 0.0001  max mem: 10917
[12:44:48.002871] Epoch: [24]  [120/345]  eta: 0:00:56  lr: 0.000119  loss: 0.7799 (0.7913)  time: 0.2501  data: 0.0000  max mem: 10917
[12:44:53.008189] Epoch: [24]  [140/345]  eta: 0:00:51  lr: 0.000118  loss: 0.7788 (0.7902)  time: 0.2502  data: 0.0001  max mem: 10917
[12:44:58.026451] Epoch: [24]  [160/345]  eta: 0:00:46  lr: 0.000118  loss: 0.7846 (0.7892)  time: 0.2509  data: 0.0001  max mem: 10917
[12:45:03.053532] Epoch: [24]  [180/345]  eta: 0:00:41  lr: 0.000118  loss: 0.7842 (0.7888)  time: 0.2513  data: 0.0000  max mem: 10917
[12:45:08.079828] Epoch: [24]  [200/345]  eta: 0:00:36  lr: 0.000118  loss: 0.7888 (0.7890)  time: 0.2513  data: 0.0001  max mem: 10917
[12:45:13.106190] Epoch: [24]  [220/345]  eta: 0:00:31  lr: 0.000118  loss: 0.7805 (0.7885)  time: 0.2513  data: 0.0001  max mem: 10917
[12:45:18.137287] Epoch: [24]  [240/345]  eta: 0:00:26  lr: 0.000118  loss: 0.7821 (0.7880)  time: 0.2515  data: 0.0001  max mem: 10917
[12:45:23.170553] Epoch: [24]  [260/345]  eta: 0:00:21  lr: 0.000117  loss: 0.7891 (0.7885)  time: 0.2516  data: 0.0000  max mem: 10917
[12:45:28.282008] Epoch: [24]  [280/345]  eta: 0:00:16  lr: 0.000117  loss: 0.7868 (0.7885)  time: 0.2555  data: 0.0001  max mem: 10917
[12:45:33.317474] Epoch: [24]  [300/345]  eta: 0:00:11  lr: 0.000117  loss: 0.7829 (0.7884)  time: 0.2517  data: 0.0000  max mem: 10917
[12:45:38.350286] Epoch: [24]  [320/345]  eta: 0:00:06  lr: 0.000117  loss: 0.7833 (0.7881)  time: 0.2516  data: 0.0000  max mem: 10917
[12:45:43.386434] Epoch: [24]  [340/345]  eta: 0:00:01  lr: 0.000117  loss: 0.7900 (0.7885)  time: 0.2518  data: 0.0000  max mem: 10917
[12:45:44.393751] Epoch: [24]  [344/345]  eta: 0:00:00  lr: 0.000117  loss: 0.7914 (0.7885)  time: 0.2518  data: 0.0001  max mem: 10917
[12:45:44.457891] Epoch: [24] Total time: 0:01:26 (0.2516 s / it)
[12:45:44.458270] Averaged stats: lr: 0.000117  loss: 0.7914 (0.7885)
[12:45:44.699103] Test:  [  0/345]  eta: 0:01:21  loss: 0.7535 (0.7535)  time: 0.2374  data: 0.1576  max mem: 10917
[12:45:45.528614] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7535 (0.7593)  time: 0.0969  data: 0.0154  max mem: 10917
[12:45:46.352544] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7535 (0.7593)  time: 0.0826  data: 0.0006  max mem: 10917
[12:45:47.179707] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7483 (0.7562)  time: 0.0825  data: 0.0001  max mem: 10917
[12:45:48.009332] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7446 (0.7543)  time: 0.0828  data: 0.0001  max mem: 10917
[12:45:48.844243] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7479 (0.7536)  time: 0.0832  data: 0.0001  max mem: 10917
[12:45:49.681773] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7479 (0.7538)  time: 0.0836  data: 0.0001  max mem: 10917
[12:45:50.522280] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7501 (0.7545)  time: 0.0839  data: 0.0001  max mem: 10917
[12:45:51.366900] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7480 (0.7537)  time: 0.0842  data: 0.0001  max mem: 10917
[12:45:52.214690] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7450 (0.7528)  time: 0.0846  data: 0.0001  max mem: 10917
[12:45:53.065915] Test:  [100/345]  eta: 0:00:20  loss: 0.7460 (0.7525)  time: 0.0849  data: 0.0001  max mem: 10917
[12:45:53.921244] Test:  [110/345]  eta: 0:00:20  loss: 0.7400 (0.7513)  time: 0.0853  data: 0.0001  max mem: 10917
[12:45:54.779763] Test:  [120/345]  eta: 0:00:19  loss: 0.7375 (0.7507)  time: 0.0856  data: 0.0001  max mem: 10917
[12:45:55.642407] Test:  [130/345]  eta: 0:00:18  loss: 0.7529 (0.7510)  time: 0.0860  data: 0.0001  max mem: 10917
[12:45:56.506675] Test:  [140/345]  eta: 0:00:17  loss: 0.7548 (0.7512)  time: 0.0863  data: 0.0001  max mem: 10917
[12:45:57.374979] Test:  [150/345]  eta: 0:00:16  loss: 0.7553 (0.7518)  time: 0.0866  data: 0.0001  max mem: 10917
[12:45:58.246946] Test:  [160/345]  eta: 0:00:15  loss: 0.7561 (0.7515)  time: 0.0870  data: 0.0001  max mem: 10917
[12:45:59.122739] Test:  [170/345]  eta: 0:00:14  loss: 0.7545 (0.7518)  time: 0.0873  data: 0.0001  max mem: 10917
[12:46:00.001873] Test:  [180/345]  eta: 0:00:14  loss: 0.7545 (0.7517)  time: 0.0877  data: 0.0001  max mem: 10917
[12:46:00.884270] Test:  [190/345]  eta: 0:00:13  loss: 0.7494 (0.7520)  time: 0.0880  data: 0.0001  max mem: 10917
[12:46:01.770565] Test:  [200/345]  eta: 0:00:12  loss: 0.7494 (0.7518)  time: 0.0884  data: 0.0001  max mem: 10917
[12:46:02.661133] Test:  [210/345]  eta: 0:00:11  loss: 0.7427 (0.7513)  time: 0.0888  data: 0.0001  max mem: 10917
[12:46:03.554138] Test:  [220/345]  eta: 0:00:10  loss: 0.7427 (0.7513)  time: 0.0891  data: 0.0001  max mem: 10917
[12:46:04.451029] Test:  [230/345]  eta: 0:00:09  loss: 0.7464 (0.7512)  time: 0.0894  data: 0.0001  max mem: 10917
[12:46:05.352023] Test:  [240/345]  eta: 0:00:09  loss: 0.7508 (0.7514)  time: 0.0898  data: 0.0001  max mem: 10917
[12:46:06.255216] Test:  [250/345]  eta: 0:00:08  loss: 0.7536 (0.7515)  time: 0.0902  data: 0.0001  max mem: 10917
[12:46:07.162631] Test:  [260/345]  eta: 0:00:07  loss: 0.7551 (0.7518)  time: 0.0905  data: 0.0001  max mem: 10917
[12:46:08.073198] Test:  [270/345]  eta: 0:00:06  loss: 0.7509 (0.7517)  time: 0.0909  data: 0.0001  max mem: 10917
[12:46:08.986552] Test:  [280/345]  eta: 0:00:05  loss: 0.7518 (0.7518)  time: 0.0911  data: 0.0001  max mem: 10917
[12:46:09.905163] Test:  [290/345]  eta: 0:00:04  loss: 0.7518 (0.7516)  time: 0.0916  data: 0.0001  max mem: 10917
[12:46:10.826667] Test:  [300/345]  eta: 0:00:03  loss: 0.7478 (0.7518)  time: 0.0920  data: 0.0001  max mem: 10917
[12:46:11.751403] Test:  [310/345]  eta: 0:00:03  loss: 0.7473 (0.7519)  time: 0.0923  data: 0.0001  max mem: 10917
[12:46:12.679604] Test:  [320/345]  eta: 0:00:02  loss: 0.7572 (0.7524)  time: 0.0926  data: 0.0001  max mem: 10917
[12:46:13.612018] Test:  [330/345]  eta: 0:00:01  loss: 0.7536 (0.7524)  time: 0.0930  data: 0.0001  max mem: 10917
[12:46:14.547394] Test:  [340/345]  eta: 0:00:00  loss: 0.7465 (0.7523)  time: 0.0933  data: 0.0001  max mem: 10917
[12:46:14.922627] Test:  [344/345]  eta: 0:00:00  loss: 0.7465 (0.7523)  time: 0.0935  data: 0.0001  max mem: 10917
[12:46:14.980225] Test: Total time: 0:00:30 (0.0885 s / it)
[12:46:25.699247] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8736 (0.8736)  time: 0.2263  data: 0.1465  max mem: 10917
[12:46:26.516187] Test:  [10/57]  eta: 0:00:04  loss: 0.8694 (0.8926)  time: 0.0948  data: 0.0138  max mem: 10917
[12:46:27.333554] Test:  [20/57]  eta: 0:00:03  loss: 0.8694 (0.8811)  time: 0.0816  data: 0.0003  max mem: 10917
[12:46:28.154179] Test:  [30/57]  eta: 0:00:02  loss: 0.7791 (0.8439)  time: 0.0818  data: 0.0001  max mem: 10917
[12:46:28.977718] Test:  [40/57]  eta: 0:00:01  loss: 0.7725 (0.8228)  time: 0.0822  data: 0.0001  max mem: 10917
[12:46:29.806376] Test:  [50/57]  eta: 0:00:00  loss: 0.7573 (0.8148)  time: 0.0826  data: 0.0001  max mem: 10917
[12:46:30.256070] Test:  [56/57]  eta: 0:00:00  loss: 0.7863 (0.8192)  time: 0.0803  data: 0.0001  max mem: 10917
[12:46:30.312448] Test: Total time: 0:00:04 (0.0849 s / it)
[12:46:32.155497] Dice score of the network on the train images: 0.790702, val images: 0.808565
[12:46:32.159072] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:46:32.558265] Epoch: [25]  [  0/345]  eta: 0:02:17  lr: 0.000117  loss: 0.7674 (0.7674)  time: 0.3981  data: 0.1460  max mem: 10917
[12:46:37.558804] Epoch: [25]  [ 20/345]  eta: 0:01:23  lr: 0.000116  loss: 0.7864 (0.7847)  time: 0.2500  data: 0.0001  max mem: 10917
[12:46:42.548527] Epoch: [25]  [ 40/345]  eta: 0:01:17  lr: 0.000116  loss: 0.7746 (0.7816)  time: 0.2494  data: 0.0001  max mem: 10917
[12:46:47.543459] Epoch: [25]  [ 60/345]  eta: 0:01:11  lr: 0.000116  loss: 0.7804 (0.7807)  time: 0.2497  data: 0.0001  max mem: 10917
[12:46:52.541953] Epoch: [25]  [ 80/345]  eta: 0:01:06  lr: 0.000116  loss: 0.7845 (0.7817)  time: 0.2499  data: 0.0001  max mem: 10917
[12:46:57.543111] Epoch: [25]  [100/345]  eta: 0:01:01  lr: 0.000116  loss: 0.8234 (0.7903)  time: 0.2500  data: 0.0001  max mem: 10917
[12:47:02.548616] Epoch: [25]  [120/345]  eta: 0:00:56  lr: 0.000115  loss: 0.8234 (0.7958)  time: 0.2502  data: 0.0001  max mem: 10917
[12:47:07.556926] Epoch: [25]  [140/345]  eta: 0:00:51  lr: 0.000115  loss: 0.8025 (0.7974)  time: 0.2504  data: 0.0001  max mem: 10917
[12:47:12.564293] Epoch: [25]  [160/345]  eta: 0:00:46  lr: 0.000115  loss: 0.7813 (0.7957)  time: 0.2503  data: 0.0001  max mem: 10917
[12:47:17.575318] Epoch: [25]  [180/345]  eta: 0:00:41  lr: 0.000115  loss: 0.7818 (0.7946)  time: 0.2505  data: 0.0001  max mem: 10917
[12:47:22.584424] Epoch: [25]  [200/345]  eta: 0:00:36  lr: 0.000115  loss: 0.7807 (0.7933)  time: 0.2504  data: 0.0001  max mem: 10917
[12:47:27.605395] Epoch: [25]  [220/345]  eta: 0:00:31  lr: 0.000114  loss: 0.7837 (0.7930)  time: 0.2510  data: 0.0001  max mem: 10917
[12:47:32.649382] Epoch: [25]  [240/345]  eta: 0:00:26  lr: 0.000114  loss: 0.7956 (0.7934)  time: 0.2522  data: 0.0001  max mem: 10917
[12:47:37.673888] Epoch: [25]  [260/345]  eta: 0:00:21  lr: 0.000114  loss: 0.7914 (0.7935)  time: 0.2512  data: 0.0001  max mem: 10917
[12:47:42.695346] Epoch: [25]  [280/345]  eta: 0:00:16  lr: 0.000114  loss: 0.7793 (0.7928)  time: 0.2510  data: 0.0001  max mem: 10917
[12:47:47.725217] Epoch: [25]  [300/345]  eta: 0:00:11  lr: 0.000114  loss: 0.7867 (0.7923)  time: 0.2514  data: 0.0000  max mem: 10917
[12:47:52.751977] Epoch: [25]  [320/345]  eta: 0:00:06  lr: 0.000113  loss: 0.7799 (0.7917)  time: 0.2513  data: 0.0001  max mem: 10917
[12:47:57.776367] Epoch: [25]  [340/345]  eta: 0:00:01  lr: 0.000113  loss: 0.7839 (0.7915)  time: 0.2512  data: 0.0000  max mem: 10917
[12:47:58.782085] Epoch: [25]  [344/345]  eta: 0:00:00  lr: 0.000113  loss: 0.7839 (0.7914)  time: 0.2512  data: 0.0001  max mem: 10917
[12:47:58.841109] Epoch: [25] Total time: 0:01:26 (0.2513 s / it)
[12:47:58.841498] Averaged stats: lr: 0.000113  loss: 0.7839 (0.7914)
[12:47:59.079339] Test:  [  0/345]  eta: 0:01:21  loss: 0.7528 (0.7528)  time: 0.2353  data: 0.1553  max mem: 10917
[12:47:59.938772] Test:  [ 10/345]  eta: 0:00:33  loss: 0.7422 (0.7420)  time: 0.0994  data: 0.0179  max mem: 10917
[12:48:00.762290] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7484 (0.7449)  time: 0.0841  data: 0.0021  max mem: 10917
[12:48:01.588109] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7531 (0.7478)  time: 0.0824  data: 0.0001  max mem: 10917
[12:48:02.419537] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7423 (0.7485)  time: 0.0828  data: 0.0001  max mem: 10917
[12:48:03.252620] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7396 (0.7465)  time: 0.0832  data: 0.0001  max mem: 10917
[12:48:04.090389] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7385 (0.7470)  time: 0.0835  data: 0.0001  max mem: 10917
[12:48:04.931344] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7519 (0.7476)  time: 0.0839  data: 0.0001  max mem: 10917
[12:48:05.775723] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7519 (0.7475)  time: 0.0842  data: 0.0001  max mem: 10917
[12:48:06.623639] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7423 (0.7473)  time: 0.0846  data: 0.0001  max mem: 10917
[12:48:07.474369] Test:  [100/345]  eta: 0:00:20  loss: 0.7436 (0.7470)  time: 0.0849  data: 0.0001  max mem: 10917
[12:48:08.328888] Test:  [110/345]  eta: 0:00:20  loss: 0.7426 (0.7470)  time: 0.0852  data: 0.0001  max mem: 10917
[12:48:09.187510] Test:  [120/345]  eta: 0:00:19  loss: 0.7446 (0.7477)  time: 0.0856  data: 0.0001  max mem: 10917
[12:48:10.049012] Test:  [130/345]  eta: 0:00:18  loss: 0.7532 (0.7483)  time: 0.0860  data: 0.0001  max mem: 10917
[12:48:10.915372] Test:  [140/345]  eta: 0:00:17  loss: 0.7532 (0.7481)  time: 0.0863  data: 0.0001  max mem: 10917
[12:48:11.784521] Test:  [150/345]  eta: 0:00:16  loss: 0.7386 (0.7477)  time: 0.0867  data: 0.0001  max mem: 10917
[12:48:12.657920] Test:  [160/345]  eta: 0:00:15  loss: 0.7369 (0.7474)  time: 0.0871  data: 0.0001  max mem: 10917
[12:48:13.533461] Test:  [170/345]  eta: 0:00:15  loss: 0.7432 (0.7476)  time: 0.0874  data: 0.0001  max mem: 10917
[12:48:14.413231] Test:  [180/345]  eta: 0:00:14  loss: 0.7460 (0.7475)  time: 0.0877  data: 0.0001  max mem: 10917
[12:48:15.295487] Test:  [190/345]  eta: 0:00:13  loss: 0.7460 (0.7475)  time: 0.0881  data: 0.0001  max mem: 10917
[12:48:16.182127] Test:  [200/345]  eta: 0:00:12  loss: 0.7502 (0.7476)  time: 0.0884  data: 0.0001  max mem: 10917
[12:48:17.072930] Test:  [210/345]  eta: 0:00:11  loss: 0.7555 (0.7482)  time: 0.0888  data: 0.0001  max mem: 10917
[12:48:17.966338] Test:  [220/345]  eta: 0:00:10  loss: 0.7562 (0.7484)  time: 0.0892  data: 0.0001  max mem: 10917
[12:48:18.863179] Test:  [230/345]  eta: 0:00:09  loss: 0.7429 (0.7482)  time: 0.0895  data: 0.0001  max mem: 10917
[12:48:19.764372] Test:  [240/345]  eta: 0:00:09  loss: 0.7443 (0.7487)  time: 0.0899  data: 0.0001  max mem: 10917
[12:48:20.667428] Test:  [250/345]  eta: 0:00:08  loss: 0.7583 (0.7486)  time: 0.0902  data: 0.0001  max mem: 10917
[12:48:21.575148] Test:  [260/345]  eta: 0:00:07  loss: 0.7518 (0.7486)  time: 0.0905  data: 0.0001  max mem: 10917
[12:48:22.485669] Test:  [270/345]  eta: 0:00:06  loss: 0.7503 (0.7488)  time: 0.0909  data: 0.0001  max mem: 10917
[12:48:23.399468] Test:  [280/345]  eta: 0:00:05  loss: 0.7495 (0.7489)  time: 0.0912  data: 0.0001  max mem: 10917
[12:48:24.318075] Test:  [290/345]  eta: 0:00:04  loss: 0.7469 (0.7488)  time: 0.0916  data: 0.0001  max mem: 10917
[12:48:25.239820] Test:  [300/345]  eta: 0:00:03  loss: 0.7469 (0.7489)  time: 0.0920  data: 0.0001  max mem: 10917
[12:48:26.164482] Test:  [310/345]  eta: 0:00:03  loss: 0.7499 (0.7490)  time: 0.0923  data: 0.0001  max mem: 10917
[12:48:27.092545] Test:  [320/345]  eta: 0:00:02  loss: 0.7458 (0.7490)  time: 0.0926  data: 0.0001  max mem: 10917
[12:48:28.024423] Test:  [330/345]  eta: 0:00:01  loss: 0.7451 (0.7489)  time: 0.0929  data: 0.0001  max mem: 10917
[12:48:28.959466] Test:  [340/345]  eta: 0:00:00  loss: 0.7462 (0.7490)  time: 0.0933  data: 0.0001  max mem: 10917
[12:48:29.334700] Test:  [344/345]  eta: 0:00:00  loss: 0.7465 (0.7491)  time: 0.0934  data: 0.0001  max mem: 10917
[12:48:29.392695] Test: Total time: 0:00:30 (0.0885 s / it)
[12:48:40.148054] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8804 (0.8804)  time: 0.2204  data: 0.1401  max mem: 10917
[12:48:40.966820] Test:  [10/57]  eta: 0:00:04  loss: 0.9042 (0.9061)  time: 0.0944  data: 0.0132  max mem: 10917
[12:48:41.784804] Test:  [20/57]  eta: 0:00:03  loss: 0.9010 (0.8926)  time: 0.0818  data: 0.0003  max mem: 10917
[12:48:42.605850] Test:  [30/57]  eta: 0:00:02  loss: 0.7859 (0.8536)  time: 0.0819  data: 0.0001  max mem: 10917
[12:48:43.429895] Test:  [40/57]  eta: 0:00:01  loss: 0.7758 (0.8324)  time: 0.0822  data: 0.0001  max mem: 10917
[12:48:44.258515] Test:  [50/57]  eta: 0:00:00  loss: 0.7744 (0.8247)  time: 0.0826  data: 0.0001  max mem: 10917
[12:48:44.708360] Test:  [56/57]  eta: 0:00:00  loss: 0.7862 (0.8288)  time: 0.0804  data: 0.0001  max mem: 10917
[12:48:44.764652] Test: Total time: 0:00:04 (0.0849 s / it)
[12:48:46.621135] Dice score of the network on the train images: 0.794251, val images: 0.800009
[12:48:46.624522] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:48:47.022428] Epoch: [26]  [  0/345]  eta: 0:02:16  lr: 0.000113  loss: 0.7961 (0.7961)  time: 0.3969  data: 0.1450  max mem: 10917
[12:48:52.032136] Epoch: [26]  [ 20/345]  eta: 0:01:23  lr: 0.000113  loss: 0.7833 (0.7838)  time: 0.2504  data: 0.0001  max mem: 10917
[12:48:57.032063] Epoch: [26]  [ 40/345]  eta: 0:01:17  lr: 0.000113  loss: 0.7847 (0.7845)  time: 0.2500  data: 0.0001  max mem: 10917
[12:49:02.022931] Epoch: [26]  [ 60/345]  eta: 0:01:11  lr: 0.000112  loss: 0.7821 (0.7844)  time: 0.2495  data: 0.0000  max mem: 10917
[12:49:07.018983] Epoch: [26]  [ 80/345]  eta: 0:01:06  lr: 0.000112  loss: 0.7771 (0.7831)  time: 0.2498  data: 0.0001  max mem: 10917
[12:49:12.021696] Epoch: [26]  [100/345]  eta: 0:01:01  lr: 0.000112  loss: 0.7818 (0.7830)  time: 0.2501  data: 0.0001  max mem: 10917

[12:49:17.027315] Epoch: [26]  [120/345]  eta: 0:00:56  lr: 0.000112  loss: 0.7764 (0.7824)  time: 0.2502  data: 0.0000  max mem: 10917
[12:49:22.033069] Epoch: [26]  [140/345]  eta: 0:00:51  lr: 0.000111  loss: 0.7821 (0.7824)  time: 0.2502  data: 0.0001  max mem: 10917
[12:49:27.051479] Epoch: [26]  [160/345]  eta: 0:00:46  lr: 0.000111  loss: 0.7737 (0.7811)  time: 0.2509  data: 0.0001  max mem: 10917
[12:49:32.064845] Epoch: [26]  [180/345]  eta: 0:00:41  lr: 0.000111  loss: 0.7750 (0.7808)  time: 0.2506  data: 0.0000  max mem: 10917
[12:49:37.082344] Epoch: [26]  [200/345]  eta: 0:00:36  lr: 0.000111  loss: 0.7809 (0.7808)  time: 0.2508  data: 0.0001  max mem: 10917
[12:49:42.100697] Epoch: [26]  [220/345]  eta: 0:00:31  lr: 0.000110  loss: 0.7771 (0.7804)  time: 0.2509  data: 0.0001  max mem: 10917
[12:49:47.119872] Epoch: [26]  [240/345]  eta: 0:00:26  lr: 0.000110  loss: 0.7720 (0.7800)  time: 0.2509  data: 0.0000  max mem: 10917
[12:49:52.143050] Epoch: [26]  [260/345]  eta: 0:00:21  lr: 0.000110  loss: 0.7759 (0.7796)  time: 0.2511  data: 0.0001  max mem: 10917
[12:49:57.165802] Epoch: [26]  [280/345]  eta: 0:00:16  lr: 0.000110  loss: 0.7716 (0.7791)  time: 0.2511  data: 0.0001  max mem: 10917
[12:50:02.185931] Epoch: [26]  [300/345]  eta: 0:00:11  lr: 0.000110  loss: 0.7753 (0.7787)  time: 0.2510  data: 0.0000  max mem: 10917
[12:50:07.211083] Epoch: [26]  [320/345]  eta: 0:00:06  lr: 0.000109  loss: 0.7613 (0.7779)  time: 0.2512  data: 0.0000  max mem: 10917
[12:50:12.235698] Epoch: [26]  [340/345]  eta: 0:00:01  lr: 0.000109  loss: 0.7708 (0.7778)  time: 0.2512  data: 0.0000  max mem: 10917
[12:50:13.243618] Epoch: [26]  [344/345]  eta: 0:00:00  lr: 0.000109  loss: 0.7762 (0.7780)  time: 0.2514  data: 0.0001  max mem: 10917
[12:50:13.302454] Epoch: [26] Total time: 0:01:26 (0.2512 s / it)
[12:50:13.302692] Averaged stats: lr: 0.000109  loss: 0.7762 (0.7780)
[12:50:13.544147] Test:  [  0/345]  eta: 0:01:22  loss: 0.7385 (0.7385)  time: 0.2385  data: 0.1580  max mem: 10917
[12:50:14.373121] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7356 (0.7387)  time: 0.0969  data: 0.0152  max mem: 10917
[12:50:15.195868] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7356 (0.7374)  time: 0.0825  data: 0.0005  max mem: 10917
[12:50:16.022089] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7393 (0.7404)  time: 0.0824  data: 0.0001  max mem: 10917
[12:50:16.852817] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7448 (0.7416)  time: 0.0828  data: 0.0001  max mem: 10917
[12:50:17.686840] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7432 (0.7418)  time: 0.0832  data: 0.0001  max mem: 10917
[12:50:18.524608] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7424 (0.7426)  time: 0.0835  data: 0.0001  max mem: 10917
[12:50:19.366113] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7487 (0.7438)  time: 0.0839  data: 0.0001  max mem: 10917
[12:50:20.209736] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7500 (0.7443)  time: 0.0842  data: 0.0001  max mem: 10917
[12:50:21.058310] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7425 (0.7433)  time: 0.0846  data: 0.0001  max mem: 10917
[12:50:21.909525] Test:  [100/345]  eta: 0:00:20  loss: 0.7390 (0.7434)  time: 0.0849  data: 0.0001  max mem: 10917
[12:50:22.764263] Test:  [110/345]  eta: 0:00:20  loss: 0.7414 (0.7443)  time: 0.0853  data: 0.0001  max mem: 10917
[12:50:23.622929] Test:  [120/345]  eta: 0:00:19  loss: 0.7471 (0.7445)  time: 0.0856  data: 0.0001  max mem: 10917
[12:50:24.485265] Test:  [130/345]  eta: 0:00:18  loss: 0.7448 (0.7444)  time: 0.0860  data: 0.0001  max mem: 10917
[12:50:25.351057] Test:  [140/345]  eta: 0:00:17  loss: 0.7435 (0.7447)  time: 0.0864  data: 0.0001  max mem: 10917
[12:50:26.220994] Test:  [150/345]  eta: 0:00:16  loss: 0.7439 (0.7444)  time: 0.0867  data: 0.0001  max mem: 10917
[12:50:27.093565] Test:  [160/345]  eta: 0:00:15  loss: 0.7410 (0.7445)  time: 0.0871  data: 0.0001  max mem: 10917
[12:50:27.970811] Test:  [170/345]  eta: 0:00:14  loss: 0.7414 (0.7444)  time: 0.0874  data: 0.0001  max mem: 10917
[12:50:28.850349] Test:  [180/345]  eta: 0:00:14  loss: 0.7471 (0.7449)  time: 0.0878  data: 0.0001  max mem: 10917
[12:50:29.733441] Test:  [190/345]  eta: 0:00:13  loss: 0.7473 (0.7452)  time: 0.0881  data: 0.0001  max mem: 10917
[12:50:30.620197] Test:  [200/345]  eta: 0:00:12  loss: 0.7461 (0.7454)  time: 0.0884  data: 0.0001  max mem: 10917
[12:50:31.511334] Test:  [210/345]  eta: 0:00:11  loss: 0.7437 (0.7454)  time: 0.0888  data: 0.0001  max mem: 10917
[12:50:32.404321] Test:  [220/345]  eta: 0:00:10  loss: 0.7412 (0.7456)  time: 0.0892  data: 0.0001  max mem: 10917
[12:50:33.300859] Test:  [230/345]  eta: 0:00:09  loss: 0.7440 (0.7458)  time: 0.0894  data: 0.0001  max mem: 10917
[12:50:34.201530] Test:  [240/345]  eta: 0:00:09  loss: 0.7395 (0.7456)  time: 0.0898  data: 0.0001  max mem: 10917
[12:50:35.105309] Test:  [250/345]  eta: 0:00:08  loss: 0.7395 (0.7455)  time: 0.0902  data: 0.0001  max mem: 10917
[12:50:36.012617] Test:  [260/345]  eta: 0:00:07  loss: 0.7423 (0.7457)  time: 0.0905  data: 0.0001  max mem: 10917
[12:50:36.924889] Test:  [270/345]  eta: 0:00:06  loss: 0.7453 (0.7457)  time: 0.0909  data: 0.0001  max mem: 10917
[12:50:37.839278] Test:  [280/345]  eta: 0:00:05  loss: 0.7497 (0.7458)  time: 0.0913  data: 0.0001  max mem: 10917
[12:50:38.757854] Test:  [290/345]  eta: 0:00:04  loss: 0.7501 (0.7459)  time: 0.0916  data: 0.0001  max mem: 10917
[12:50:39.679309] Test:  [300/345]  eta: 0:00:03  loss: 0.7532 (0.7460)  time: 0.0920  data: 0.0001  max mem: 10917
[12:50:40.604306] Test:  [310/345]  eta: 0:00:03  loss: 0.7520 (0.7461)  time: 0.0923  data: 0.0001  max mem: 10917
[12:50:41.533159] Test:  [320/345]  eta: 0:00:02  loss: 0.7435 (0.7460)  time: 0.0926  data: 0.0001  max mem: 10917
[12:50:42.465505] Test:  [330/345]  eta: 0:00:01  loss: 0.7407 (0.7461)  time: 0.0930  data: 0.0001  max mem: 10917
[12:50:43.401470] Test:  [340/345]  eta: 0:00:00  loss: 0.7431 (0.7461)  time: 0.0934  data: 0.0001  max mem: 10917
[12:50:43.777220] Test:  [344/345]  eta: 0:00:00  loss: 0.7460 (0.7462)  time: 0.0935  data: 0.0001  max mem: 10917
[12:50:43.834775] Test: Total time: 0:00:30 (0.0885 s / it)
[12:50:54.519119] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8768 (0.8768)  time: 0.2230  data: 0.1434  max mem: 10917
[12:50:55.332333] Test:  [10/57]  eta: 0:00:04  loss: 0.8850 (0.9043)  time: 0.0941  data: 0.0131  max mem: 10917
[12:50:56.148991] Test:  [20/57]  eta: 0:00:03  loss: 0.8850 (0.8851)  time: 0.0814  data: 0.0001  max mem: 10917
[12:50:56.970498] Test:  [30/57]  eta: 0:00:02  loss: 0.7740 (0.8456)  time: 0.0819  data: 0.0001  max mem: 10917
[12:50:57.794581] Test:  [40/57]  eta: 0:00:01  loss: 0.7703 (0.8247)  time: 0.0822  data: 0.0001  max mem: 10917
[12:50:58.622711] Test:  [50/57]  eta: 0:00:00  loss: 0.7508 (0.8158)  time: 0.0826  data: 0.0001  max mem: 10917
[12:50:59.073055] Test:  [56/57]  eta: 0:00:00  loss: 0.7825 (0.8200)  time: 0.0804  data: 0.0001  max mem: 10917
[12:50:59.130363] Test: Total time: 0:00:04 (0.0848 s / it)
[12:51:00.961592] Dice score of the network on the train images: 0.795570, val images: 0.804560
[12:51:00.965268] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:51:01.363815] Epoch: [27]  [  0/345]  eta: 0:02:17  lr: 0.000109  loss: 0.7923 (0.7923)  time: 0.3975  data: 0.1461  max mem: 10917
[12:51:06.362197] Epoch: [27]  [ 20/345]  eta: 0:01:23  lr: 0.000109  loss: 0.7811 (0.7786)  time: 0.2499  data: 0.0001  max mem: 10917
[12:51:11.376815] Epoch: [27]  [ 40/345]  eta: 0:01:17  lr: 0.000108  loss: 0.7681 (0.7757)  time: 0.2507  data: 0.0001  max mem: 10917
[12:51:16.393873] Epoch: [27]  [ 60/345]  eta: 0:01:12  lr: 0.000108  loss: 0.7746 (0.7775)  time: 0.2508  data: 0.0001  max mem: 10917
[12:51:21.397729] Epoch: [27]  [ 80/345]  eta: 0:01:06  lr: 0.000108  loss: 0.7779 (0.7785)  time: 0.2501  data: 0.0001  max mem: 10917
[12:51:26.405223] Epoch: [27]  [100/345]  eta: 0:01:01  lr: 0.000108  loss: 0.7807 (0.7792)  time: 0.2503  data: 0.0001  max mem: 10917
[12:51:31.413885] Epoch: [27]  [120/345]  eta: 0:00:56  lr: 0.000107  loss: 0.7777 (0.7798)  time: 0.2504  data: 0.0000  max mem: 10917
[12:51:36.424958] Epoch: [27]  [140/345]  eta: 0:00:51  lr: 0.000107  loss: 0.7700 (0.7789)  time: 0.2505  data: 0.0000  max mem: 10917
[12:51:41.439166] Epoch: [27]  [160/345]  eta: 0:00:46  lr: 0.000107  loss: 0.7833 (0.7796)  time: 0.2507  data: 0.0001  max mem: 10917
[12:51:46.450770] Epoch: [27]  [180/345]  eta: 0:00:41  lr: 0.000107  loss: 0.7754 (0.7791)  time: 0.2505  data: 0.0001  max mem: 10917
[12:51:51.469391] Epoch: [27]  [200/345]  eta: 0:00:36  lr: 0.000106  loss: 0.7754 (0.7800)  time: 0.2509  data: 0.0001  max mem: 10917
[12:51:56.483876] Epoch: [27]  [220/345]  eta: 0:00:31  lr: 0.000106  loss: 0.7831 (0.7806)  time: 0.2507  data: 0.0001  max mem: 10917
[12:52:01.503589] Epoch: [27]  [240/345]  eta: 0:00:26  lr: 0.000106  loss: 0.7802 (0.7805)  time: 0.2509  data: 0.0001  max mem: 10917
[12:52:06.535653] Epoch: [27]  [260/345]  eta: 0:00:21  lr: 0.000106  loss: 0.7755 (0.7801)  time: 0.2516  data: 0.0001  max mem: 10917
[12:52:11.570161] Epoch: [27]  [280/345]  eta: 0:00:16  lr: 0.000105  loss: 0.7668 (0.7797)  time: 0.2517  data: 0.0001  max mem: 10917
[12:52:16.607871] Epoch: [27]  [300/345]  eta: 0:00:11  lr: 0.000105  loss: 0.7801 (0.7799)  time: 0.2518  data: 0.0001  max mem: 10917
[12:52:21.643548] Epoch: [27]  [320/345]  eta: 0:00:06  lr: 0.000105  loss: 0.7740 (0.7798)  time: 0.2517  data: 0.0001  max mem: 10917
[12:52:26.683741] Epoch: [27]  [340/345]  eta: 0:00:01  lr: 0.000104  loss: 0.7768 (0.7796)  time: 0.2520  data: 0.0001  max mem: 10917
[12:52:27.691989] Epoch: [27]  [344/345]  eta: 0:00:00  lr: 0.000104  loss: 0.7768 (0.7796)  time: 0.2519  data: 0.0001  max mem: 10917
[12:52:27.749521] Epoch: [27] Total time: 0:01:26 (0.2515 s / it)
[12:52:27.749849] Averaged stats: lr: 0.000104  loss: 0.7768 (0.7796)
[12:52:27.990324] Test:  [  0/345]  eta: 0:01:21  loss: 0.7073 (0.7073)  time: 0.2370  data: 0.1569  max mem: 10917
[12:52:28.829735] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7435 (0.7460)  time: 0.0978  data: 0.0161  max mem: 10917
[12:52:29.658614] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7521 (0.7495)  time: 0.0833  data: 0.0014  max mem: 10917
[12:52:30.486538] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7412 (0.7469)  time: 0.0828  data: 0.0004  max mem: 10917
[12:52:31.317197] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7392 (0.7454)  time: 0.0829  data: 0.0001  max mem: 10917
[12:52:32.151600] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7415 (0.7447)  time: 0.0832  data: 0.0001  max mem: 10917
[12:52:32.988823] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7408 (0.7444)  time: 0.0835  data: 0.0001  max mem: 10917
[12:52:33.829705] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7387 (0.7440)  time: 0.0839  data: 0.0001  max mem: 10917
[12:52:34.673735] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7549 (0.7456)  time: 0.0842  data: 0.0001  max mem: 10917
[12:52:35.521246] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7514 (0.7448)  time: 0.0845  data: 0.0001  max mem: 10917
[12:52:36.372729] Test:  [100/345]  eta: 0:00:20  loss: 0.7400 (0.7438)  time: 0.0849  data: 0.0001  max mem: 10917
[12:52:37.227650] Test:  [110/345]  eta: 0:00:20  loss: 0.7381 (0.7441)  time: 0.0853  data: 0.0001  max mem: 10917
[12:52:38.085989] Test:  [120/345]  eta: 0:00:19  loss: 0.7380 (0.7440)  time: 0.0856  data: 0.0001  max mem: 10917
[12:52:38.947572] Test:  [130/345]  eta: 0:00:18  loss: 0.7414 (0.7439)  time: 0.0859  data: 0.0001  max mem: 10917
[12:52:39.813248] Test:  [140/345]  eta: 0:00:17  loss: 0.7414 (0.7443)  time: 0.0863  data: 0.0001  max mem: 10917
[12:52:40.682174] Test:  [150/345]  eta: 0:00:16  loss: 0.7405 (0.7439)  time: 0.0867  data: 0.0001  max mem: 10917
[12:52:41.554748] Test:  [160/345]  eta: 0:00:15  loss: 0.7385 (0.7440)  time: 0.0870  data: 0.0001  max mem: 10917
[12:52:42.431552] Test:  [170/345]  eta: 0:00:15  loss: 0.7390 (0.7443)  time: 0.0874  data: 0.0001  max mem: 10917
[12:52:43.311386] Test:  [180/345]  eta: 0:00:14  loss: 0.7458 (0.7445)  time: 0.0878  data: 0.0001  max mem: 10917
[12:52:44.194755] Test:  [190/345]  eta: 0:00:13  loss: 0.7468 (0.7446)  time: 0.0881  data: 0.0001  max mem: 10917
[12:52:45.081114] Test:  [200/345]  eta: 0:00:12  loss: 0.7464 (0.7444)  time: 0.0884  data: 0.0001  max mem: 10917
[12:52:45.970539] Test:  [210/345]  eta: 0:00:11  loss: 0.7434 (0.7445)  time: 0.0887  data: 0.0001  max mem: 10917
[12:52:46.862919] Test:  [220/345]  eta: 0:00:10  loss: 0.7453 (0.7446)  time: 0.0890  data: 0.0001  max mem: 10917
[12:52:47.760347] Test:  [230/345]  eta: 0:00:09  loss: 0.7427 (0.7445)  time: 0.0894  data: 0.0001  max mem: 10917
[12:52:48.661341] Test:  [240/345]  eta: 0:00:09  loss: 0.7394 (0.7444)  time: 0.0899  data: 0.0001  max mem: 10917
[12:52:49.565242] Test:  [250/345]  eta: 0:00:08  loss: 0.7389 (0.7445)  time: 0.0902  data: 0.0001  max mem: 10917
[12:52:50.473183] Test:  [260/345]  eta: 0:00:07  loss: 0.7389 (0.7445)  time: 0.0905  data: 0.0001  max mem: 10917
[12:52:51.385230] Test:  [270/345]  eta: 0:00:06  loss: 0.7433 (0.7447)  time: 0.0909  data: 0.0001  max mem: 10917
[12:52:52.299888] Test:  [280/345]  eta: 0:00:05  loss: 0.7460 (0.7445)  time: 0.0913  data: 0.0001  max mem: 10917
[12:52:53.218779] Test:  [290/345]  eta: 0:00:04  loss: 0.7410 (0.7445)  time: 0.0916  data: 0.0001  max mem: 10917
[12:52:54.140014] Test:  [300/345]  eta: 0:00:03  loss: 0.7429 (0.7446)  time: 0.0920  data: 0.0001  max mem: 10917
[12:52:55.064753] Test:  [310/345]  eta: 0:00:03  loss: 0.7429 (0.7445)  time: 0.0923  data: 0.0001  max mem: 10917
[12:52:55.993088] Test:  [320/345]  eta: 0:00:02  loss: 0.7363 (0.7441)  time: 0.0926  data: 0.0001  max mem: 10917
[12:52:56.925327] Test:  [330/345]  eta: 0:00:01  loss: 0.7351 (0.7438)  time: 0.0930  data: 0.0001  max mem: 10917
[12:52:57.860733] Test:  [340/345]  eta: 0:00:00  loss: 0.7356 (0.7438)  time: 0.0933  data: 0.0001  max mem: 10917
[12:52:58.236774] Test:  [344/345]  eta: 0:00:00  loss: 0.7401 (0.7438)  time: 0.0935  data: 0.0001  max mem: 10917
[12:52:58.295014] Test: Total time: 0:00:30 (0.0885 s / it)
[12:53:09.063126] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8684 (0.8684)  time: 0.2229  data: 0.1431  max mem: 10917
[12:53:09.878002] Test:  [10/57]  eta: 0:00:04  loss: 0.8733 (0.8896)  time: 0.0942  data: 0.0131  max mem: 10917
[12:53:10.695025] Test:  [20/57]  eta: 0:00:03  loss: 0.8733 (0.8734)  time: 0.0815  data: 0.0001  max mem: 10917
[12:53:11.515107] Test:  [30/57]  eta: 0:00:02  loss: 0.7790 (0.8371)  time: 0.0818  data: 0.0001  max mem: 10917
[12:53:12.339588] Test:  [40/57]  eta: 0:00:01  loss: 0.7620 (0.8167)  time: 0.0822  data: 0.0001  max mem: 10917
[12:53:13.167563] Test:  [50/57]  eta: 0:00:00  loss: 0.7533 (0.8098)  time: 0.0826  data: 0.0001  max mem: 10917
[12:53:13.617689] Test:  [56/57]  eta: 0:00:00  loss: 0.7831 (0.8141)  time: 0.0804  data: 0.0001  max mem: 10917
[12:53:13.672380] Test: Total time: 0:00:04 (0.0848 s / it)
[12:53:15.492222] Dice score of the network on the train images: 0.792024, val images: 0.814544
[12:53:15.492453] saving best_dice_model_0 @ epoch 27
[12:53:16.366358] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:53:16.841650] Epoch: [28]  [  0/345]  eta: 0:02:43  lr: 0.000104  loss: 0.7659 (0.7659)  time: 0.4743  data: 0.1444  max mem: 10917
[12:53:21.836942] Epoch: [28]  [ 20/345]  eta: 0:01:24  lr: 0.000104  loss: 0.7710 (0.7696)  time: 0.2497  data: 0.0001  max mem: 10917
[12:53:26.836228] Epoch: [28]  [ 40/345]  eta: 0:01:17  lr: 0.000104  loss: 0.7690 (0.7694)  time: 0.2499  data: 0.0001  max mem: 10917
[12:53:31.838661] Epoch: [28]  [ 60/345]  eta: 0:01:12  lr: 0.000103  loss: 0.7684 (0.7702)  time: 0.2501  data: 0.0001  max mem: 10917
[12:53:36.845710] Epoch: [28]  [ 80/345]  eta: 0:01:06  lr: 0.000103  loss: 0.7681 (0.7704)  time: 0.2503  data: 0.0001  max mem: 10917
[12:53:41.855775] Epoch: [28]  [100/345]  eta: 0:01:01  lr: 0.000103  loss: 0.7635 (0.7697)  time: 0.2505  data: 0.0001  max mem: 10917
[12:53:46.875068] Epoch: [28]  [120/345]  eta: 0:00:56  lr: 0.000103  loss: 0.7706 (0.7699)  time: 0.2509  data: 0.0001  max mem: 10917
[12:53:51.896308] Epoch: [28]  [140/345]  eta: 0:00:51  lr: 0.000102  loss: 0.7738 (0.7704)  time: 0.2510  data: 0.0001  max mem: 10917
[12:53:56.918609] Epoch: [28]  [160/345]  eta: 0:00:46  lr: 0.000102  loss: 0.7671 (0.7704)  time: 0.2511  data: 0.0001  max mem: 10917
[12:54:01.940997] Epoch: [28]  [180/345]  eta: 0:00:41  lr: 0.000102  loss: 0.7631 (0.7698)  time: 0.2511  data: 0.0001  max mem: 10917
[12:54:06.966147] Epoch: [28]  [200/345]  eta: 0:00:36  lr: 0.000101  loss: 0.7789 (0.7707)  time: 0.2512  data: 0.0001  max mem: 10917
[12:54:11.997941] Epoch: [28]  [220/345]  eta: 0:00:31  lr: 0.000101  loss: 0.7676 (0.7705)  time: 0.2515  data: 0.0001  max mem: 10917
[12:54:17.035129] Epoch: [28]  [240/345]  eta: 0:00:26  lr: 0.000101  loss: 0.7722 (0.7708)  time: 0.2518  data: 0.0001  max mem: 10917
[12:54:22.073671] Epoch: [28]  [260/345]  eta: 0:00:21  lr: 0.000101  loss: 0.7880 (0.7720)  time: 0.2519  data: 0.0001  max mem: 10917
[12:54:27.113994] Epoch: [28]  [280/345]  eta: 0:00:16  lr: 0.000100  loss: 0.7824 (0.7732)  time: 0.2520  data: 0.0001  max mem: 10917
[12:54:32.141667] Epoch: [28]  [300/345]  eta: 0:00:11  lr: 0.000100  loss: 0.7760 (0.7735)  time: 0.2513  data: 0.0000  max mem: 10917
[12:54:37.166029] Epoch: [28]  [320/345]  eta: 0:00:06  lr: 0.000100  loss: 0.7660 (0.7733)  time: 0.2512  data: 0.0000  max mem: 10917
[12:54:42.190029] Epoch: [28]  [340/345]  eta: 0:00:01  lr: 0.000099  loss: 0.7729 (0.7735)  time: 0.2512  data: 0.0000  max mem: 10917
[12:54:43.197615] Epoch: [28]  [344/345]  eta: 0:00:00  lr: 0.000099  loss: 0.7740 (0.7735)  time: 0.2513  data: 0.0001  max mem: 10917
[12:54:43.259117] Epoch: [28] Total time: 0:01:26 (0.2519 s / it)
[12:54:43.259591] Averaged stats: lr: 0.000099  loss: 0.7740 (0.7735)
[12:54:43.507620] Test:  [  0/345]  eta: 0:01:24  loss: 0.7457 (0.7457)  time: 0.2453  data: 0.1653  max mem: 10917
[12:54:44.329183] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7416 (0.7407)  time: 0.0969  data: 0.0151  max mem: 10917
[12:54:45.152949] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7400 (0.7387)  time: 0.0822  data: 0.0001  max mem: 10917
[12:54:45.980105] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7401 (0.7387)  time: 0.0825  data: 0.0001  max mem: 10917
[12:54:46.811468] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7401 (0.7396)  time: 0.0829  data: 0.0001  max mem: 10917
[12:54:47.645575] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7356 (0.7392)  time: 0.0832  data: 0.0001  max mem: 10917
[12:54:48.483375] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7356 (0.7401)  time: 0.0835  data: 0.0001  max mem: 10917
[12:54:49.324663] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7391 (0.7412)  time: 0.0839  data: 0.0001  max mem: 10917
[12:54:50.169455] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7367 (0.7397)  time: 0.0843  data: 0.0001  max mem: 10917
[12:54:51.017360] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7348 (0.7395)  time: 0.0846  data: 0.0001  max mem: 10917
[12:54:51.869558] Test:  [100/345]  eta: 0:00:20  loss: 0.7389 (0.7395)  time: 0.0850  data: 0.0001  max mem: 10917
[12:54:52.725882] Test:  [110/345]  eta: 0:00:20  loss: 0.7394 (0.7395)  time: 0.0854  data: 0.0001  max mem: 10917
[12:54:53.585806] Test:  [120/345]  eta: 0:00:19  loss: 0.7426 (0.7395)  time: 0.0858  data: 0.0001  max mem: 10917
[12:54:54.448754] Test:  [130/345]  eta: 0:00:18  loss: 0.7436 (0.7404)  time: 0.0861  data: 0.0001  max mem: 10917
[12:54:55.314331] Test:  [140/345]  eta: 0:00:17  loss: 0.7401 (0.7402)  time: 0.0864  data: 0.0001  max mem: 10917
[12:54:56.183634] Test:  [150/345]  eta: 0:00:16  loss: 0.7340 (0.7401)  time: 0.0867  data: 0.0001  max mem: 10917
[12:54:57.056258] Test:  [160/345]  eta: 0:00:15  loss: 0.7381 (0.7401)  time: 0.0870  data: 0.0001  max mem: 10917
[12:54:57.932311] Test:  [170/345]  eta: 0:00:15  loss: 0.7381 (0.7402)  time: 0.0874  data: 0.0001  max mem: 10917
[12:54:58.811737] Test:  [180/345]  eta: 0:00:14  loss: 0.7322 (0.7400)  time: 0.0877  data: 0.0001  max mem: 10917
[12:54:59.695058] Test:  [190/345]  eta: 0:00:13  loss: 0.7322 (0.7400)  time: 0.0881  data: 0.0001  max mem: 10917
[12:55:00.581994] Test:  [200/345]  eta: 0:00:12  loss: 0.7336 (0.7395)  time: 0.0885  data: 0.0001  max mem: 10917
[12:55:01.472278] Test:  [210/345]  eta: 0:00:11  loss: 0.7336 (0.7394)  time: 0.0888  data: 0.0001  max mem: 10917
[12:55:02.365547] Test:  [220/345]  eta: 0:00:10  loss: 0.7404 (0.7396)  time: 0.0891  data: 0.0001  max mem: 10917
[12:55:03.263536] Test:  [230/345]  eta: 0:00:09  loss: 0.7399 (0.7392)  time: 0.0895  data: 0.0001  max mem: 10917
[12:55:04.165520] Test:  [240/345]  eta: 0:00:09  loss: 0.7399 (0.7395)  time: 0.0900  data: 0.0001  max mem: 10917
[12:55:05.069772] Test:  [250/345]  eta: 0:00:08  loss: 0.7355 (0.7398)  time: 0.0903  data: 0.0001  max mem: 10917
[12:55:05.977931] Test:  [260/345]  eta: 0:00:07  loss: 0.7414 (0.7400)  time: 0.0906  data: 0.0001  max mem: 10917
[12:55:06.888994] Test:  [270/345]  eta: 0:00:06  loss: 0.7451 (0.7401)  time: 0.0909  data: 0.0001  max mem: 10917
[12:55:07.803284] Test:  [280/345]  eta: 0:00:05  loss: 0.7417 (0.7401)  time: 0.0912  data: 0.0001  max mem: 10917
[12:55:08.721673] Test:  [290/345]  eta: 0:00:04  loss: 0.7365 (0.7398)  time: 0.0916  data: 0.0001  max mem: 10917
[12:55:09.643681] Test:  [300/345]  eta: 0:00:03  loss: 0.7358 (0.7397)  time: 0.0920  data: 0.0001  max mem: 10917
[12:55:10.569017] Test:  [310/345]  eta: 0:00:03  loss: 0.7307 (0.7394)  time: 0.0923  data: 0.0001  max mem: 10917
[12:55:11.498141] Test:  [320/345]  eta: 0:00:02  loss: 0.7334 (0.7396)  time: 0.0927  data: 0.0001  max mem: 10917
[12:55:12.430599] Test:  [330/345]  eta: 0:00:01  loss: 0.7402 (0.7395)  time: 0.0930  data: 0.0001  max mem: 10917
[12:55:13.366018] Test:  [340/345]  eta: 0:00:00  loss: 0.7327 (0.7395)  time: 0.0933  data: 0.0001  max mem: 10917
[12:55:13.741988] Test:  [344/345]  eta: 0:00:00  loss: 0.7361 (0.7395)  time: 0.0935  data: 0.0001  max mem: 10917
[12:55:13.797712] Test: Total time: 0:00:30 (0.0885 s / it)
[12:55:24.597329] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8897 (0.8897)  time: 0.2243  data: 0.1445  max mem: 10917
[12:55:25.411115] Test:  [10/57]  eta: 0:00:04  loss: 0.9091 (0.9072)  time: 0.0943  data: 0.0132  max mem: 10917
[12:55:26.227685] Test:  [20/57]  eta: 0:00:03  loss: 0.9091 (0.8954)  time: 0.0814  data: 0.0001  max mem: 10917
[12:55:27.047797] Test:  [30/57]  eta: 0:00:02  loss: 0.7907 (0.8552)  time: 0.0818  data: 0.0001  max mem: 10917
[12:55:27.871778] Test:  [40/57]  eta: 0:00:01  loss: 0.7750 (0.8332)  time: 0.0822  data: 0.0001  max mem: 10917
[12:55:28.698735] Test:  [50/57]  eta: 0:00:00  loss: 0.7753 (0.8248)  time: 0.0825  data: 0.0001  max mem: 10917
[12:55:29.149129] Test:  [56/57]  eta: 0:00:00  loss: 0.7949 (0.8291)  time: 0.0803  data: 0.0001  max mem: 10917
[12:55:29.203222] Test: Total time: 0:00:04 (0.0847 s / it)
[12:55:31.061292] Dice score of the network on the train images: 0.797927, val images: 0.804839
[12:55:31.064795] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:55:31.462686] Epoch: [29]  [  0/345]  eta: 0:02:16  lr: 0.000099  loss: 0.7528 (0.7528)  time: 0.3971  data: 0.1457  max mem: 10917
[12:55:36.462981] Epoch: [29]  [ 20/345]  eta: 0:01:23  lr: 0.000099  loss: 0.7631 (0.7631)  time: 0.2500  data: 0.0001  max mem: 10917
[12:55:41.464558] Epoch: [29]  [ 40/345]  eta: 0:01:17  lr: 0.000099  loss: 0.8018 (0.7815)  time: 0.2500  data: 0.0001  max mem: 10917
[12:55:46.469799] Epoch: [29]  [ 60/345]  eta: 0:01:11  lr: 0.000098  loss: 0.7899 (0.7844)  time: 0.2502  data: 0.0001  max mem: 10917
[12:55:51.483029] Epoch: [29]  [ 80/345]  eta: 0:01:06  lr: 0.000098  loss: 0.7666 (0.7821)  time: 0.2506  data: 0.0001  max mem: 10917
[12:55:56.497312] Epoch: [29]  [100/345]  eta: 0:01:01  lr: 0.000098  loss: 0.7776 (0.7810)  time: 0.2507  data: 0.0001  max mem: 10917
[12:56:01.515202] Epoch: [29]  [120/345]  eta: 0:00:56  lr: 0.000097  loss: 0.7842 (0.7810)  time: 0.2508  data: 0.0001  max mem: 10917
[12:56:06.534707] Epoch: [29]  [140/345]  eta: 0:00:51  lr: 0.000097  loss: 0.7776 (0.7815)  time: 0.2509  data: 0.0001  max mem: 10917

[12:56:11.558848] Epoch: [29]  [160/345]  eta: 0:00:46  lr: 0.000097  loss: 0.7789 (0.7812)  time: 0.2512  data: 0.0001  max mem: 10917
[12:56:16.584470] Epoch: [29]  [180/345]  eta: 0:00:41  lr: 0.000096  loss: 0.7738 (0.7807)  time: 0.2512  data: 0.0001  max mem: 10917
[12:56:21.611775] Epoch: [29]  [200/345]  eta: 0:00:36  lr: 0.000096  loss: 0.7791 (0.7805)  time: 0.2513  data: 0.0001  max mem: 10917
[12:56:26.627827] Epoch: [29]  [220/345]  eta: 0:00:31  lr: 0.000096  loss: 0.7799 (0.7805)  time: 0.2508  data: 0.0000  max mem: 10917
[12:56:31.644393] Epoch: [29]  [240/345]  eta: 0:00:26  lr: 0.000095  loss: 0.7825 (0.7807)  time: 0.2508  data: 0.0000  max mem: 10917
[12:56:36.667191] Epoch: [29]  [260/345]  eta: 0:00:21  lr: 0.000095  loss: 0.7695 (0.7799)  time: 0.2511  data: 0.0000  max mem: 10917
[12:56:41.705746] Epoch: [29]  [280/345]  eta: 0:00:16  lr: 0.000095  loss: 0.7746 (0.7793)  time: 0.2519  data: 0.0001  max mem: 10917
[12:56:46.742493] Epoch: [29]  [300/345]  eta: 0:00:11  lr: 0.000094  loss: 0.7683 (0.7787)  time: 0.2518  data: 0.0001  max mem: 10917
[12:56:51.778009] Epoch: [29]  [320/345]  eta: 0:00:06  lr: 0.000094  loss: 0.7746 (0.7786)  time: 0.2517  data: 0.0001  max mem: 10917
[12:56:56.809414] Epoch: [29]  [340/345]  eta: 0:00:01  lr: 0.000094  loss: 0.7735 (0.7783)  time: 0.2515  data: 0.0001  max mem: 10917
[12:56:57.815417] Epoch: [29]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.7735 (0.7782)  time: 0.2515  data: 0.0001  max mem: 10917
[12:56:57.874679] Epoch: [29] Total time: 0:01:26 (0.2516 s / it)
[12:56:57.874983] Averaged stats: lr: 0.000094  loss: 0.7735 (0.7782)
[12:56:58.109802] Test:  [  0/345]  eta: 0:01:19  loss: 0.7299 (0.7299)  time: 0.2317  data: 0.1513  max mem: 10917
[12:56:58.947888] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7419 (0.7410)  time: 0.0972  data: 0.0155  max mem: 10917
[12:56:59.770500] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7349 (0.7335)  time: 0.0830  data: 0.0010  max mem: 10917
[12:57:00.597857] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7297 (0.7361)  time: 0.0824  data: 0.0001  max mem: 10917
[12:57:01.427634] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7396 (0.7370)  time: 0.0828  data: 0.0001  max mem: 10917
[12:57:02.261753] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7396 (0.7370)  time: 0.0831  data: 0.0001  max mem: 10917
[12:57:03.098472] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7376 (0.7370)  time: 0.0835  data: 0.0001  max mem: 10917
[12:57:03.939559] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7347 (0.7367)  time: 0.0838  data: 0.0001  max mem: 10917
[12:57:04.784495] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7308 (0.7370)  time: 0.0843  data: 0.0001  max mem: 10917
[12:57:05.632218] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7271 (0.7371)  time: 0.0846  data: 0.0001  max mem: 10917
[12:57:06.483807] Test:  [100/345]  eta: 0:00:20  loss: 0.7351 (0.7371)  time: 0.0849  data: 0.0001  max mem: 10917
[12:57:07.338618] Test:  [110/345]  eta: 0:00:20  loss: 0.7418 (0.7377)  time: 0.0853  data: 0.0001  max mem: 10917
[12:57:08.197630] Test:  [120/345]  eta: 0:00:19  loss: 0.7415 (0.7372)  time: 0.0856  data: 0.0001  max mem: 10917
[12:57:09.059706] Test:  [130/345]  eta: 0:00:18  loss: 0.7315 (0.7375)  time: 0.0860  data: 0.0001  max mem: 10917
[12:57:09.925216] Test:  [140/345]  eta: 0:00:17  loss: 0.7399 (0.7377)  time: 0.0863  data: 0.0001  max mem: 10917
[12:57:10.794984] Test:  [150/345]  eta: 0:00:16  loss: 0.7397 (0.7378)  time: 0.0867  data: 0.0001  max mem: 10917
[12:57:11.667816] Test:  [160/345]  eta: 0:00:15  loss: 0.7427 (0.7381)  time: 0.0871  data: 0.0001  max mem: 10917
[12:57:12.543728] Test:  [170/345]  eta: 0:00:14  loss: 0.7403 (0.7384)  time: 0.0874  data: 0.0001  max mem: 10917
[12:57:13.423431] Test:  [180/345]  eta: 0:00:14  loss: 0.7381 (0.7383)  time: 0.0877  data: 0.0001  max mem: 10917
[12:57:14.306583] Test:  [190/345]  eta: 0:00:13  loss: 0.7381 (0.7385)  time: 0.0881  data: 0.0001  max mem: 10917
[12:57:15.193057] Test:  [200/345]  eta: 0:00:12  loss: 0.7352 (0.7384)  time: 0.0884  data: 0.0001  max mem: 10917
[12:57:16.084497] Test:  [210/345]  eta: 0:00:11  loss: 0.7342 (0.7382)  time: 0.0888  data: 0.0001  max mem: 10917
[12:57:16.977479] Test:  [220/345]  eta: 0:00:10  loss: 0.7325 (0.7379)  time: 0.0892  data: 0.0001  max mem: 10917
[12:57:17.874712] Test:  [230/345]  eta: 0:00:09  loss: 0.7267 (0.7380)  time: 0.0895  data: 0.0001  max mem: 10917
[12:57:18.775429] Test:  [240/345]  eta: 0:00:09  loss: 0.7403 (0.7383)  time: 0.0899  data: 0.0001  max mem: 10917
[12:57:19.679460] Test:  [250/345]  eta: 0:00:08  loss: 0.7373 (0.7383)  time: 0.0902  data: 0.0001  max mem: 10917
[12:57:20.587290] Test:  [260/345]  eta: 0:00:07  loss: 0.7351 (0.7384)  time: 0.0905  data: 0.0001  max mem: 10917
[12:57:21.497840] Test:  [270/345]  eta: 0:00:06  loss: 0.7376 (0.7384)  time: 0.0909  data: 0.0001  max mem: 10917
[12:57:22.413024] Test:  [280/345]  eta: 0:00:05  loss: 0.7369 (0.7384)  time: 0.0912  data: 0.0001  max mem: 10917
[12:57:23.331507] Test:  [290/345]  eta: 0:00:04  loss: 0.7432 (0.7387)  time: 0.0916  data: 0.0001  max mem: 10917
[12:57:24.253193] Test:  [300/345]  eta: 0:00:03  loss: 0.7404 (0.7385)  time: 0.0920  data: 0.0001  max mem: 10917
[12:57:25.178231] Test:  [310/345]  eta: 0:00:03  loss: 0.7327 (0.7385)  time: 0.0923  data: 0.0001  max mem: 10917
[12:57:26.107082] Test:  [320/345]  eta: 0:00:02  loss: 0.7341 (0.7385)  time: 0.0926  data: 0.0001  max mem: 10917
[12:57:27.038482] Test:  [330/345]  eta: 0:00:01  loss: 0.7348 (0.7386)  time: 0.0930  data: 0.0001  max mem: 10917
[12:57:27.973528] Test:  [340/345]  eta: 0:00:00  loss: 0.7325 (0.7384)  time: 0.0933  data: 0.0001  max mem: 10917
[12:57:28.349389] Test:  [344/345]  eta: 0:00:00  loss: 0.7322 (0.7384)  time: 0.0934  data: 0.0001  max mem: 10917
[12:57:28.407741] Test: Total time: 0:00:30 (0.0885 s / it)
[12:57:39.125326] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8946 (0.8946)  time: 0.2211  data: 0.1411  max mem: 10917
[12:57:39.938351] Test:  [10/57]  eta: 0:00:04  loss: 0.8946 (0.9091)  time: 0.0939  data: 0.0129  max mem: 10917
[12:57:40.755463] Test:  [20/57]  eta: 0:00:03  loss: 0.9030 (0.8982)  time: 0.0814  data: 0.0001  max mem: 10917
[12:57:41.576447] Test:  [30/57]  eta: 0:00:02  loss: 0.7831 (0.8564)  time: 0.0818  data: 0.0001  max mem: 10917
[12:57:42.399970] Test:  [40/57]  eta: 0:00:01  loss: 0.7799 (0.8329)  time: 0.0822  data: 0.0001  max mem: 10917
[12:57:43.228659] Test:  [50/57]  eta: 0:00:00  loss: 0.7627 (0.8233)  time: 0.0826  data: 0.0001  max mem: 10917
[12:57:43.679113] Test:  [56/57]  eta: 0:00:00  loss: 0.7841 (0.8284)  time: 0.0804  data: 0.0001  max mem: 10917
[12:57:43.733767] Test: Total time: 0:00:04 (0.0847 s / it)
[12:57:45.546526] Dice score of the network on the train images: 0.806734, val images: 0.812738
[12:57:45.550145] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:57:45.952197] Epoch: [30]  [  0/345]  eta: 0:02:18  lr: 0.000094  loss: 0.7950 (0.7950)  time: 0.4013  data: 0.1501  max mem: 10917
[12:57:50.935749] Epoch: [30]  [ 20/345]  eta: 0:01:23  lr: 0.000093  loss: 0.7651 (0.7694)  time: 0.2491  data: 0.0000  max mem: 10917
[12:57:55.929537] Epoch: [30]  [ 40/345]  eta: 0:01:17  lr: 0.000093  loss: 0.7725 (0.7687)  time: 0.2497  data: 0.0001  max mem: 10917
[12:58:00.928013] Epoch: [30]  [ 60/345]  eta: 0:01:11  lr: 0.000093  loss: 0.7735 (0.7704)  time: 0.2499  data: 0.0000  max mem: 10917
[12:58:05.925898] Epoch: [30]  [ 80/345]  eta: 0:01:06  lr: 0.000092  loss: 0.7712 (0.7708)  time: 0.2499  data: 0.0000  max mem: 10917
[12:58:10.924765] Epoch: [30]  [100/345]  eta: 0:01:01  lr: 0.000092  loss: 0.7647 (0.7706)  time: 0.2499  data: 0.0000  max mem: 10917
[12:58:15.930606] Epoch: [30]  [120/345]  eta: 0:00:56  lr: 0.000092  loss: 0.7663 (0.7702)  time: 0.2503  data: 0.0000  max mem: 10917
[12:58:20.940654] Epoch: [30]  [140/345]  eta: 0:00:51  lr: 0.000091  loss: 0.7783 (0.7718)  time: 0.2505  data: 0.0000  max mem: 10917
[12:58:25.951084] Epoch: [30]  [160/345]  eta: 0:00:46  lr: 0.000091  loss: 0.7639 (0.7715)  time: 0.2505  data: 0.0000  max mem: 10917
[12:58:30.961433] Epoch: [30]  [180/345]  eta: 0:00:41  lr: 0.000091  loss: 0.7601 (0.7708)  time: 0.2505  data: 0.0000  max mem: 10917
[12:58:35.980498] Epoch: [30]  [200/345]  eta: 0:00:36  lr: 0.000090  loss: 0.7634 (0.7705)  time: 0.2509  data: 0.0001  max mem: 10917
[12:58:41.039437] Epoch: [30]  [220/345]  eta: 0:00:31  lr: 0.000090  loss: 0.7660 (0.7704)  time: 0.2529  data: 0.0001  max mem: 10917
[12:58:46.099759] Epoch: [30]  [240/345]  eta: 0:00:26  lr: 0.000090  loss: 0.7652 (0.7706)  time: 0.2530  data: 0.0001  max mem: 10917
[12:58:51.131787] Epoch: [30]  [260/345]  eta: 0:00:21  lr: 0.000089  loss: 0.7786 (0.7714)  time: 0.2516  data: 0.0000  max mem: 10917
[12:58:56.169198] Epoch: [30]  [280/345]  eta: 0:00:16  lr: 0.000089  loss: 0.7813 (0.7723)  time: 0.2518  data: 0.0000  max mem: 10917
[12:59:01.208008] Epoch: [30]  [300/345]  eta: 0:00:11  lr: 0.000089  loss: 0.7711 (0.7725)  time: 0.2519  data: 0.0000  max mem: 10917
[12:59:06.247360] Epoch: [30]  [320/345]  eta: 0:00:06  lr: 0.000088  loss: 0.7668 (0.7724)  time: 0.2519  data: 0.0000  max mem: 10917
[12:59:11.287766] Epoch: [30]  [340/345]  eta: 0:00:01  lr: 0.000088  loss: 0.7718 (0.7722)  time: 0.2520  data: 0.0000  max mem: 10917
[12:59:12.297079] Epoch: [30]  [344/345]  eta: 0:00:00  lr: 0.000088  loss: 0.7659 (0.7720)  time: 0.2521  data: 0.0001  max mem: 10917
[12:59:12.355932] Epoch: [30] Total time: 0:01:26 (0.2516 s / it)
[12:59:12.356421] Averaged stats: lr: 0.000088  loss: 0.7659 (0.7720)
[12:59:12.600398] Test:  [  0/345]  eta: 0:01:22  loss: 0.7285 (0.7285)  time: 0.2404  data: 0.1601  max mem: 10917
[12:59:13.441086] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7285 (0.7342)  time: 0.0982  data: 0.0165  max mem: 10917
[12:59:14.264624] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7363 (0.7350)  time: 0.0831  data: 0.0011  max mem: 10917
[12:59:15.092042] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7363 (0.7365)  time: 0.0825  data: 0.0001  max mem: 10917
[12:59:15.923727] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7314 (0.7348)  time: 0.0829  data: 0.0001  max mem: 10917
[12:59:16.757629] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7314 (0.7350)  time: 0.0832  data: 0.0001  max mem: 10917
[12:59:17.595378] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7305 (0.7349)  time: 0.0835  data: 0.0001  max mem: 10917
[12:59:18.436719] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7325 (0.7360)  time: 0.0839  data: 0.0001  max mem: 10917
[12:59:19.281539] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7318 (0.7356)  time: 0.0843  data: 0.0001  max mem: 10917
[12:59:20.129792] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7315 (0.7357)  time: 0.0846  data: 0.0001  max mem: 10917
[12:59:20.982613] Test:  [100/345]  eta: 0:00:20  loss: 0.7317 (0.7351)  time: 0.0850  data: 0.0001  max mem: 10917
[12:59:21.838254] Test:  [110/345]  eta: 0:00:20  loss: 0.7283 (0.7347)  time: 0.0854  data: 0.0001  max mem: 10917
[12:59:22.697224] Test:  [120/345]  eta: 0:00:19  loss: 0.7284 (0.7344)  time: 0.0857  data: 0.0001  max mem: 10917
[12:59:23.559657] Test:  [130/345]  eta: 0:00:18  loss: 0.7308 (0.7346)  time: 0.0860  data: 0.0001  max mem: 10917
[12:59:24.425432] Test:  [140/345]  eta: 0:00:17  loss: 0.7365 (0.7348)  time: 0.0864  data: 0.0001  max mem: 10917
[12:59:25.294993] Test:  [150/345]  eta: 0:00:16  loss: 0.7336 (0.7349)  time: 0.0867  data: 0.0001  max mem: 10917
[12:59:26.167843] Test:  [160/345]  eta: 0:00:15  loss: 0.7297 (0.7343)  time: 0.0871  data: 0.0001  max mem: 10917
[12:59:27.044747] Test:  [170/345]  eta: 0:00:15  loss: 0.7287 (0.7342)  time: 0.0874  data: 0.0001  max mem: 10917
[12:59:27.925121] Test:  [180/345]  eta: 0:00:14  loss: 0.7321 (0.7341)  time: 0.0878  data: 0.0001  max mem: 10917
[12:59:28.808237] Test:  [190/345]  eta: 0:00:13  loss: 0.7329 (0.7344)  time: 0.0881  data: 0.0001  max mem: 10917
[12:59:29.695053] Test:  [200/345]  eta: 0:00:12  loss: 0.7327 (0.7341)  time: 0.0885  data: 0.0001  max mem: 10917
[12:59:30.585431] Test:  [210/345]  eta: 0:00:11  loss: 0.7323 (0.7342)  time: 0.0888  data: 0.0001  max mem: 10917
[12:59:31.478732] Test:  [220/345]  eta: 0:00:10  loss: 0.7367 (0.7346)  time: 0.0891  data: 0.0001  max mem: 10917
[12:59:32.376386] Test:  [230/345]  eta: 0:00:09  loss: 0.7367 (0.7346)  time: 0.0895  data: 0.0001  max mem: 10917
[12:59:33.277533] Test:  [240/345]  eta: 0:00:09  loss: 0.7329 (0.7349)  time: 0.0899  data: 0.0001  max mem: 10917
[12:59:34.181892] Test:  [250/345]  eta: 0:00:08  loss: 0.7339 (0.7346)  time: 0.0902  data: 0.0001  max mem: 10917
[12:59:35.089565] Test:  [260/345]  eta: 0:00:07  loss: 0.7307 (0.7346)  time: 0.0906  data: 0.0001  max mem: 10917
[12:59:36.001888] Test:  [270/345]  eta: 0:00:06  loss: 0.7312 (0.7346)  time: 0.0909  data: 0.0001  max mem: 10917
[12:59:36.916547] Test:  [280/345]  eta: 0:00:05  loss: 0.7355 (0.7345)  time: 0.0913  data: 0.0001  max mem: 10917
[12:59:37.835511] Test:  [290/345]  eta: 0:00:04  loss: 0.7355 (0.7348)  time: 0.0916  data: 0.0001  max mem: 10917
[12:59:38.756966] Test:  [300/345]  eta: 0:00:03  loss: 0.7390 (0.7349)  time: 0.0920  data: 0.0001  max mem: 10917
[12:59:39.682301] Test:  [310/345]  eta: 0:00:03  loss: 0.7353 (0.7350)  time: 0.0923  data: 0.0001  max mem: 10917
[12:59:40.611644] Test:  [320/345]  eta: 0:00:02  loss: 0.7330 (0.7349)  time: 0.0927  data: 0.0001  max mem: 10917
[12:59:41.544661] Test:  [330/345]  eta: 0:00:01  loss: 0.7286 (0.7348)  time: 0.0931  data: 0.0001  max mem: 10917
[12:59:42.480294] Test:  [340/345]  eta: 0:00:00  loss: 0.7286 (0.7348)  time: 0.0934  data: 0.0001  max mem: 10917
[12:59:42.855973] Test:  [344/345]  eta: 0:00:00  loss: 0.7295 (0.7348)  time: 0.0935  data: 0.0001  max mem: 10917
[12:59:42.914856] Test: Total time: 0:00:30 (0.0886 s / it)
[12:59:53.731780] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8901 (0.8901)  time: 0.2251  data: 0.1451  max mem: 10917
[12:59:54.545391] Test:  [10/57]  eta: 0:00:04  loss: 0.8977 (0.9122)  time: 0.0944  data: 0.0132  max mem: 10917
[12:59:55.361438] Test:  [20/57]  eta: 0:00:03  loss: 0.8977 (0.8951)  time: 0.0814  data: 0.0001  max mem: 10917
[12:59:56.182084] Test:  [30/57]  eta: 0:00:02  loss: 0.7842 (0.8520)  time: 0.0818  data: 0.0001  max mem: 10917
[12:59:57.007006] Test:  [40/57]  eta: 0:00:01  loss: 0.7669 (0.8283)  time: 0.0822  data: 0.0001  max mem: 10917
[12:59:57.835526] Test:  [50/57]  eta: 0:00:00  loss: 0.7510 (0.8198)  time: 0.0826  data: 0.0001  max mem: 10917
[12:59:58.285683] Test:  [56/57]  eta: 0:00:00  loss: 0.7869 (0.8244)  time: 0.0804  data: 0.0001  max mem: 10917
[12:59:58.343786] Test: Total time: 0:00:04 (0.0849 s / it)
[13:00:00.186850] Dice score of the network on the train images: 0.799688, val images: 0.810402
[13:00:00.190520] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:00:00.585281] Epoch: [31]  [  0/345]  eta: 0:02:15  lr: 0.000088  loss: 0.7851 (0.7851)  time: 0.3939  data: 0.1418  max mem: 10917
[13:00:05.581691] Epoch: [31]  [ 20/345]  eta: 0:01:23  lr: 0.000088  loss: 0.7665 (0.7657)  time: 0.2498  data: 0.0001  max mem: 10917
[13:00:10.579626] Epoch: [31]  [ 40/345]  eta: 0:01:17  lr: 0.000087  loss: 0.7643 (0.7659)  time: 0.2499  data: 0.0000  max mem: 10917
[13:00:15.580002] Epoch: [31]  [ 60/345]  eta: 0:01:11  lr: 0.000087  loss: 0.7561 (0.7629)  time: 0.2500  data: 0.0000  max mem: 10917
[13:00:20.596164] Epoch: [31]  [ 80/345]  eta: 0:01:06  lr: 0.000087  loss: 0.7615 (0.7626)  time: 0.2508  data: 0.0001  max mem: 10917
[13:00:25.611772] Epoch: [31]  [100/345]  eta: 0:01:01  lr: 0.000086  loss: 0.7653 (0.7633)  time: 0.2507  data: 0.0000  max mem: 10917
[13:00:30.628696] Epoch: [31]  [120/345]  eta: 0:00:56  lr: 0.000086  loss: 0.7606 (0.7629)  time: 0.2508  data: 0.0000  max mem: 10917
[13:00:35.650412] Epoch: [31]  [140/345]  eta: 0:00:51  lr: 0.000085  loss: 0.7586 (0.7627)  time: 0.2511  data: 0.0000  max mem: 10917
[13:00:40.670504] Epoch: [31]  [160/345]  eta: 0:00:46  lr: 0.000085  loss: 0.7597 (0.7629)  time: 0.2510  data: 0.0000  max mem: 10917
[13:00:45.693246] Epoch: [31]  [180/345]  eta: 0:00:41  lr: 0.000085  loss: 0.7603 (0.7625)  time: 0.2511  data: 0.0000  max mem: 10917
[13:00:50.725463] Epoch: [31]  [200/345]  eta: 0:00:36  lr: 0.000084  loss: 0.7605 (0.7628)  time: 0.2516  data: 0.0001  max mem: 10917
[13:00:55.759936] Epoch: [31]  [220/345]  eta: 0:00:31  lr: 0.000084  loss: 0.7590 (0.7626)  time: 0.2517  data: 0.0001  max mem: 10917
[13:01:00.793399] Epoch: [31]  [240/345]  eta: 0:00:26  lr: 0.000084  loss: 0.7574 (0.7622)  time: 0.2516  data: 0.0001  max mem: 10917
[13:01:05.822498] Epoch: [31]  [260/345]  eta: 0:00:21  lr: 0.000083  loss: 0.7587 (0.7621)  time: 0.2514  data: 0.0000  max mem: 10917
[13:01:10.937776] Epoch: [31]  [280/345]  eta: 0:00:16  lr: 0.000083  loss: 0.7621 (0.7621)  time: 0.2557  data: 0.0000  max mem: 10917
[13:01:15.971979] Epoch: [31]  [300/345]  eta: 0:00:11  lr: 0.000083  loss: 0.7656 (0.7624)  time: 0.2517  data: 0.0000  max mem: 10917
[13:01:21.011618] Epoch: [31]  [320/345]  eta: 0:00:06  lr: 0.000082  loss: 0.7828 (0.7635)  time: 0.2519  data: 0.0000  max mem: 10917
[13:01:26.050005] Epoch: [31]  [340/345]  eta: 0:00:01  lr: 0.000082  loss: 0.7610 (0.7635)  time: 0.2519  data: 0.0000  max mem: 10917
[13:01:27.057567] Epoch: [31]  [344/345]  eta: 0:00:00  lr: 0.000082  loss: 0.7610 (0.7634)  time: 0.2519  data: 0.0001  max mem: 10917
[13:01:27.120725] Epoch: [31] Total time: 0:01:26 (0.2520 s / it)
[13:01:27.121063] Averaged stats: lr: 0.000082  loss: 0.7610 (0.7634)
[13:01:27.358326] Test:  [  0/345]  eta: 0:01:20  loss: 0.7226 (0.7226)  time: 0.2339  data: 0.1537  max mem: 10917
[13:01:28.179032] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7264 (0.7298)  time: 0.0958  data: 0.0140  max mem: 10917
[13:01:29.002938] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7264 (0.7290)  time: 0.0822  data: 0.0001  max mem: 10917
[13:01:29.830177] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7279 (0.7304)  time: 0.0825  data: 0.0001  max mem: 10917
[13:01:30.660852] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7243 (0.7291)  time: 0.0828  data: 0.0001  max mem: 10917
[13:01:31.494826] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7307 (0.7317)  time: 0.0832  data: 0.0001  max mem: 10917
[13:01:32.331838] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7265 (0.7292)  time: 0.0835  data: 0.0001  max mem: 10917
[13:01:33.172750] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7189 (0.7305)  time: 0.0838  data: 0.0001  max mem: 10917
[13:01:34.017712] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7255 (0.7302)  time: 0.0842  data: 0.0001  max mem: 10917
[13:01:34.866518] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7255 (0.7308)  time: 0.0846  data: 0.0001  max mem: 10917
[13:01:35.718974] Test:  [100/345]  eta: 0:00:20  loss: 0.7266 (0.7304)  time: 0.0850  data: 0.0001  max mem: 10917
[13:01:36.574099] Test:  [110/345]  eta: 0:00:19  loss: 0.7305 (0.7313)  time: 0.0853  data: 0.0001  max mem: 10917
[13:01:37.432983] Test:  [120/345]  eta: 0:00:19  loss: 0.7356 (0.7316)  time: 0.0857  data: 0.0001  max mem: 10917
[13:01:38.295982] Test:  [130/345]  eta: 0:00:18  loss: 0.7382 (0.7324)  time: 0.0860  data: 0.0001  max mem: 10917
[13:01:39.161434] Test:  [140/345]  eta: 0:00:17  loss: 0.7340 (0.7320)  time: 0.0864  data: 0.0001  max mem: 10917
[13:01:40.030251] Test:  [150/345]  eta: 0:00:16  loss: 0.7295 (0.7317)  time: 0.0867  data: 0.0001  max mem: 10917
[13:01:40.902691] Test:  [160/345]  eta: 0:00:15  loss: 0.7324 (0.7321)  time: 0.0870  data: 0.0001  max mem: 10917
[13:01:41.779592] Test:  [170/345]  eta: 0:00:14  loss: 0.7324 (0.7323)  time: 0.0874  data: 0.0001  max mem: 10917
[13:01:42.659545] Test:  [180/345]  eta: 0:00:14  loss: 0.7347 (0.7324)  time: 0.0878  data: 0.0001  max mem: 10917
[13:01:43.542636] Test:  [190/345]  eta: 0:00:13  loss: 0.7341 (0.7322)  time: 0.0881  data: 0.0001  max mem: 10917
[13:01:44.430382] Test:  [200/345]  eta: 0:00:12  loss: 0.7250 (0.7320)  time: 0.0885  data: 0.0001  max mem: 10917
[13:01:45.321702] Test:  [210/345]  eta: 0:00:11  loss: 0.7296 (0.7319)  time: 0.0889  data: 0.0001  max mem: 10917
[13:01:46.215201] Test:  [220/345]  eta: 0:00:10  loss: 0.7325 (0.7322)  time: 0.0892  data: 0.0001  max mem: 10917
[13:01:47.112448] Test:  [230/345]  eta: 0:00:09  loss: 0.7349 (0.7325)  time: 0.0895  data: 0.0001  max mem: 10917
[13:01:48.013792] Test:  [240/345]  eta: 0:00:09  loss: 0.7331 (0.7326)  time: 0.0899  data: 0.0001  max mem: 10917
[13:01:48.917339] Test:  [250/345]  eta: 0:00:08  loss: 0.7367 (0.7329)  time: 0.0902  data: 0.0001  max mem: 10917
[13:01:49.824760] Test:  [260/345]  eta: 0:00:07  loss: 0.7419 (0.7331)  time: 0.0905  data: 0.0001  max mem: 10917
[13:01:50.737229] Test:  [270/345]  eta: 0:00:06  loss: 0.7325 (0.7333)  time: 0.0909  data: 0.0001  max mem: 10917
[13:01:51.651878] Test:  [280/345]  eta: 0:00:05  loss: 0.7311 (0.7333)  time: 0.0913  data: 0.0001  max mem: 10917
[13:01:52.570674] Test:  [290/345]  eta: 0:00:04  loss: 0.7317 (0.7333)  time: 0.0916  data: 0.0001  max mem: 10917
[13:01:53.493303] Test:  [300/345]  eta: 0:00:03  loss: 0.7380 (0.7335)  time: 0.0920  data: 0.0001  max mem: 10917
[13:01:54.418915] Test:  [310/345]  eta: 0:00:03  loss: 0.7370 (0.7333)  time: 0.0924  data: 0.0001  max mem: 10917
[13:01:55.348250] Test:  [320/345]  eta: 0:00:02  loss: 0.7312 (0.7332)  time: 0.0927  data: 0.0001  max mem: 10917
[13:01:56.280874] Test:  [330/345]  eta: 0:00:01  loss: 0.7297 (0.7331)  time: 0.0931  data: 0.0001  max mem: 10917
[13:01:57.217372] Test:  [340/345]  eta: 0:00:00  loss: 0.7272 (0.7328)  time: 0.0934  data: 0.0001  max mem: 10917
[13:01:57.593166] Test:  [344/345]  eta: 0:00:00  loss: 0.7272 (0.7328)  time: 0.0935  data: 0.0001  max mem: 10917
[13:01:57.651693] Test: Total time: 0:00:30 (0.0885 s / it)
[13:02:08.238990] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8809 (0.8809)  time: 0.2231  data: 0.1436  max mem: 10917
[13:02:09.050909] Test:  [10/57]  eta: 0:00:04  loss: 0.8967 (0.9039)  time: 0.0940  data: 0.0131  max mem: 10917
[13:02:09.868827] Test:  [20/57]  eta: 0:00:03  loss: 0.9082 (0.8929)  time: 0.0814  data: 0.0001  max mem: 10917
[13:02:10.690525] Test:  [30/57]  eta: 0:00:02  loss: 0.7887 (0.8529)  time: 0.0819  data: 0.0001  max mem: 10917
[13:02:11.515704] Test:  [40/57]  eta: 0:00:01  loss: 0.7733 (0.8312)  time: 0.0823  data: 0.0001  max mem: 10917
[13:02:12.344824] Test:  [50/57]  eta: 0:00:00  loss: 0.7638 (0.8228)  time: 0.0827  data: 0.0001  max mem: 10917
[13:02:12.795221] Test:  [56/57]  eta: 0:00:00  loss: 0.7932 (0.8275)  time: 0.0804  data: 0.0001  max mem: 10917
[13:02:12.853784] Test: Total time: 0:00:04 (0.0849 s / it)
[13:02:14.699264] Dice score of the network on the train images: 0.810325, val images: 0.807113
[13:02:14.702812] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:02:15.100128] Epoch: [32]  [  0/345]  eta: 0:02:16  lr: 0.000082  loss: 0.7761 (0.7761)  time: 0.3966  data: 0.1449  max mem: 10917
[13:02:20.099957] Epoch: [32]  [ 20/345]  eta: 0:01:23  lr: 0.000081  loss: 0.7615 (0.7682)  time: 0.2499  data: 0.0001  max mem: 10917
[13:02:25.102794] Epoch: [32]  [ 40/345]  eta: 0:01:17  lr: 0.000081  loss: 0.7575 (0.7663)  time: 0.2501  data: 0.0000  max mem: 10917
[13:02:30.106790] Epoch: [32]  [ 60/345]  eta: 0:01:11  lr: 0.000081  loss: 0.7667 (0.7679)  time: 0.2502  data: 0.0000  max mem: 10917
[13:02:35.122537] Epoch: [32]  [ 80/345]  eta: 0:01:06  lr: 0.000080  loss: 0.7534 (0.7650)  time: 0.2508  data: 0.0000  max mem: 10917
[13:02:40.142601] Epoch: [32]  [100/345]  eta: 0:01:01  lr: 0.000080  loss: 0.7662 (0.7647)  time: 0.2510  data: 0.0000  max mem: 10917
[13:02:45.158110] Epoch: [32]  [120/345]  eta: 0:00:56  lr: 0.000080  loss: 0.7586 (0.7643)  time: 0.2507  data: 0.0000  max mem: 10917
[13:02:50.177018] Epoch: [32]  [140/345]  eta: 0:00:51  lr: 0.000079  loss: 0.7597 (0.7640)  time: 0.2509  data: 0.0000  max mem: 10917
[13:02:55.187762] Epoch: [32]  [160/345]  eta: 0:00:46  lr: 0.000079  loss: 0.7710 (0.7649)  time: 0.2505  data: 0.0001  max mem: 10917
[13:03:00.202351] Epoch: [32]  [180/345]  eta: 0:00:41  lr: 0.000079  loss: 0.7608 (0.7646)  time: 0.2507  data: 0.0001  max mem: 10917
[13:03:05.226756] Epoch: [32]  [200/345]  eta: 0:00:36  lr: 0.000078  loss: 0.7590 (0.7640)  time: 0.2512  data: 0.0000  max mem: 10917
[13:03:10.264448] Epoch: [32]  [220/345]  eta: 0:00:31  lr: 0.000078  loss: 0.7633 (0.7638)  time: 0.2518  data: 0.0000  max mem: 10917
[13:03:15.296472] Epoch: [32]  [240/345]  eta: 0:00:26  lr: 0.000077  loss: 0.7573 (0.7636)  time: 0.2516  data: 0.0000  max mem: 10917
[13:03:20.326533] Epoch: [32]  [260/345]  eta: 0:00:21  lr: 0.000077  loss: 0.7513 (0.7629)  time: 0.2515  data: 0.0000  max mem: 10917
[13:03:25.365439] Epoch: [32]  [280/345]  eta: 0:00:16  lr: 0.000077  loss: 0.7558 (0.7628)  time: 0.2519  data: 0.0001  max mem: 10917
[13:03:30.405298] Epoch: [32]  [300/345]  eta: 0:00:11  lr: 0.000076  loss: 0.7591 (0.7628)  time: 0.2520  data: 0.0000  max mem: 10917
[13:03:35.443176] Epoch: [32]  [320/345]  eta: 0:00:06  lr: 0.000076  loss: 0.7590 (0.7624)  time: 0.2519  data: 0.0000  max mem: 10917
[13:03:40.474158] Epoch: [32]  [340/345]  eta: 0:00:01  lr: 0.000076  loss: 0.7590 (0.7622)  time: 0.2515  data: 0.0000  max mem: 10917
[13:03:41.479137] Epoch: [32]  [344/345]  eta: 0:00:00  lr: 0.000076  loss: 0.7590 (0.7622)  time: 0.2513  data: 0.0001  max mem: 10917
[13:03:41.537093] Epoch: [32] Total time: 0:01:26 (0.2517 s / it)
[13:03:41.537603] Averaged stats: lr: 0.000076  loss: 0.7590 (0.7622)
[13:03:41.780200] Test:  [  0/345]  eta: 0:01:22  loss: 0.6904 (0.6904)  time: 0.2387  data: 0.1584  max mem: 10917
[13:03:42.625419] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7219 (0.7189)  time: 0.0985  data: 0.0169  max mem: 10917
[13:03:43.450182] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7219 (0.7196)  time: 0.0834  data: 0.0014  max mem: 10917
[13:03:44.277694] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7178 (0.7195)  time: 0.0826  data: 0.0001  max mem: 10917
[13:03:45.109675] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7189 (0.7209)  time: 0.0829  data: 0.0001  max mem: 10917
[13:03:45.943664] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7241 (0.7222)  time: 0.0833  data: 0.0001  max mem: 10917
[13:03:46.781086] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7172 (0.7214)  time: 0.0835  data: 0.0001  max mem: 10917
[13:03:47.622380] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7161 (0.7215)  time: 0.0839  data: 0.0001  max mem: 10917
[13:03:48.466817] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7198 (0.7222)  time: 0.0842  data: 0.0001  max mem: 10917
[13:03:49.315232] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7282 (0.7224)  time: 0.0846  data: 0.0001  max mem: 10917
[13:03:50.167339] Test:  [100/345]  eta: 0:00:20  loss: 0.7282 (0.7227)  time: 0.0850  data: 0.0001  max mem: 10917
[13:03:51.022875] Test:  [110/345]  eta: 0:00:20  loss: 0.7259 (0.7226)  time: 0.0853  data: 0.0001  max mem: 10917
[13:03:51.882890] Test:  [120/345]  eta: 0:00:19  loss: 0.7278 (0.7232)  time: 0.0857  data: 0.0001  max mem: 10917
[13:03:52.745526] Test:  [130/345]  eta: 0:00:18  loss: 0.7294 (0.7238)  time: 0.0861  data: 0.0001  max mem: 10917
[13:03:53.613057] Test:  [140/345]  eta: 0:00:17  loss: 0.7312 (0.7243)  time: 0.0864  data: 0.0001  max mem: 10917
[13:03:54.482997] Test:  [150/345]  eta: 0:00:16  loss: 0.7295 (0.7241)  time: 0.0868  data: 0.0001  max mem: 10917
[13:03:55.356506] Test:  [160/345]  eta: 0:00:15  loss: 0.7225 (0.7241)  time: 0.0871  data: 0.0001  max mem: 10917
[13:03:56.232596] Test:  [170/345]  eta: 0:00:15  loss: 0.7274 (0.7242)  time: 0.0874  data: 0.0001  max mem: 10917
[13:03:57.112341] Test:  [180/345]  eta: 0:00:14  loss: 0.7238 (0.7242)  time: 0.0877  data: 0.0001  max mem: 10917
[13:03:57.995280] Test:  [190/345]  eta: 0:00:13  loss: 0.7270 (0.7243)  time: 0.0881  data: 0.0001  max mem: 10917
[13:03:58.882139] Test:  [200/345]  eta: 0:00:12  loss: 0.7288 (0.7244)  time: 0.0884  data: 0.0001  max mem: 10917
[13:03:59.773613] Test:  [210/345]  eta: 0:00:11  loss: 0.7278 (0.7247)  time: 0.0889  data: 0.0001  max mem: 10917
[13:04:00.666338] Test:  [220/345]  eta: 0:00:10  loss: 0.7278 (0.7248)  time: 0.0892  data: 0.0001  max mem: 10917
[13:04:01.563300] Test:  [230/345]  eta: 0:00:09  loss: 0.7304 (0.7251)  time: 0.0894  data: 0.0001  max mem: 10917
[13:04:02.464914] Test:  [240/345]  eta: 0:00:09  loss: 0.7271 (0.7250)  time: 0.0899  data: 0.0001  max mem: 10917
[13:04:03.369438] Test:  [250/345]  eta: 0:00:08  loss: 0.7229 (0.7250)  time: 0.0903  data: 0.0001  max mem: 10917
[13:04:04.278097] Test:  [260/345]  eta: 0:00:07  loss: 0.7182 (0.7247)  time: 0.0906  data: 0.0001  max mem: 10917
[13:04:05.189631] Test:  [270/345]  eta: 0:00:06  loss: 0.7155 (0.7247)  time: 0.0910  data: 0.0001  max mem: 10917
[13:04:06.105450] Test:  [280/345]  eta: 0:00:05  loss: 0.7173 (0.7245)  time: 0.0913  data: 0.0001  max mem: 10917
[13:04:07.024784] Test:  [290/345]  eta: 0:00:04  loss: 0.7237 (0.7247)  time: 0.0917  data: 0.0001  max mem: 10917
[13:04:07.947066] Test:  [300/345]  eta: 0:00:03  loss: 0.7183 (0.7244)  time: 0.0920  data: 0.0001  max mem: 10917
[13:04:08.873015] Test:  [310/345]  eta: 0:00:03  loss: 0.7183 (0.7246)  time: 0.0924  data: 0.0001  max mem: 10917
[13:04:09.802550] Test:  [320/345]  eta: 0:00:02  loss: 0.7217 (0.7245)  time: 0.0927  data: 0.0001  max mem: 10917
[13:04:10.735554] Test:  [330/345]  eta: 0:00:01  loss: 0.7217 (0.7246)  time: 0.0931  data: 0.0001  max mem: 10917
[13:04:11.672300] Test:  [340/345]  eta: 0:00:00  loss: 0.7247 (0.7247)  time: 0.0934  data: 0.0001  max mem: 10917
[13:04:12.048271] Test:  [344/345]  eta: 0:00:00  loss: 0.7247 (0.7248)  time: 0.0936  data: 0.0001  max mem: 10917
[13:04:12.106058] Test: Total time: 0:00:30 (0.0886 s / it)
[13:04:22.776427] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8679 (0.8679)  time: 0.2232  data: 0.1436  max mem: 10917
[13:04:23.588076] Test:  [10/57]  eta: 0:00:04  loss: 0.8955 (0.9039)  time: 0.0940  data: 0.0131  max mem: 10917
[13:04:24.404611] Test:  [20/57]  eta: 0:00:03  loss: 0.8956 (0.8894)  time: 0.0813  data: 0.0001  max mem: 10917
[13:04:25.224692] Test:  [30/57]  eta: 0:00:02  loss: 0.7821 (0.8501)  time: 0.0818  data: 0.0001  max mem: 10917
[13:04:26.047494] Test:  [40/57]  eta: 0:00:01  loss: 0.7741 (0.8285)  time: 0.0821  data: 0.0001  max mem: 10917
[13:04:26.874559] Test:  [50/57]  eta: 0:00:00  loss: 0.7634 (0.8206)  time: 0.0824  data: 0.0001  max mem: 10917
[13:04:27.324290] Test:  [56/57]  eta: 0:00:00  loss: 0.7910 (0.8255)  time: 0.0802  data: 0.0001  max mem: 10917
[13:04:27.382019] Test: Total time: 0:00:04 (0.0847 s / it)
[13:04:29.207447] Dice score of the network on the train images: 0.813794, val images: 0.809737
[13:04:29.211056] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:04:29.611339] Epoch: [33]  [  0/345]  eta: 0:02:17  lr: 0.000075  loss: 0.7332 (0.7332)  time: 0.3995  data: 0.1482  max mem: 10917
[13:04:34.596338] Epoch: [33]  [ 20/345]  eta: 0:01:23  lr: 0.000075  loss: 0.7535 (0.7569)  time: 0.2492  data: 0.0001  max mem: 10917
[13:04:39.580852] Epoch: [33]  [ 40/345]  eta: 0:01:17  lr: 0.000075  loss: 0.7512 (0.7563)  time: 0.2492  data: 0.0001  max mem: 10917
[13:04:44.567935] Epoch: [33]  [ 60/345]  eta: 0:01:11  lr: 0.000074  loss: 0.7563 (0.7564)  time: 0.2493  data: 0.0001  max mem: 10917
[13:04:49.565118] Epoch: [33]  [ 80/345]  eta: 0:01:06  lr: 0.000074  loss: 0.7587 (0.7573)  time: 0.2498  data: 0.0000  max mem: 10917
[13:04:54.568099] Epoch: [33]  [100/345]  eta: 0:01:01  lr: 0.000074  loss: 0.7588 (0.7579)  time: 0.2501  data: 0.0001  max mem: 10917
[13:04:59.577886] Epoch: [33]  [120/345]  eta: 0:00:56  lr: 0.000073  loss: 0.7621 (0.7589)  time: 0.2505  data: 0.0000  max mem: 10917
[13:05:04.589192] Epoch: [33]  [140/345]  eta: 0:00:51  lr: 0.000073  loss: 0.7645 (0.7599)  time: 0.2505  data: 0.0001  max mem: 10917
[13:05:09.600936] Epoch: [33]  [160/345]  eta: 0:00:46  lr: 0.000073  loss: 0.7716 (0.7609)  time: 0.2506  data: 0.0000  max mem: 10917
[13:05:14.615944] Epoch: [33]  [180/345]  eta: 0:00:41  lr: 0.000072  loss: 0.7601 (0.7607)  time: 0.2507  data: 0.0001  max mem: 10917
[13:05:19.634158] Epoch: [33]  [200/345]  eta: 0:00:36  lr: 0.000072  loss: 0.7499 (0.7600)  time: 0.2509  data: 0.0000  max mem: 10917
[13:05:24.651918] Epoch: [33]  [220/345]  eta: 0:00:31  lr: 0.000071  loss: 0.7582 (0.7599)  time: 0.2509  data: 0.0000  max mem: 10917
[13:05:29.674390] Epoch: [33]  [240/345]  eta: 0:00:26  lr: 0.000071  loss: 0.7509 (0.7595)  time: 0.2511  data: 0.0000  max mem: 10917
[13:05:34.715498] Epoch: [33]  [260/345]  eta: 0:00:21  lr: 0.000071  loss: 0.7538 (0.7594)  time: 0.2520  data: 0.0001  max mem: 10917
[13:05:39.738931] Epoch: [33]  [280/345]  eta: 0:00:16  lr: 0.000070  loss: 0.7522 (0.7589)  time: 0.2511  data: 0.0001  max mem: 10917
[13:05:44.766462] Epoch: [33]  [300/345]  eta: 0:00:11  lr: 0.000070  loss: 0.7574 (0.7591)  time: 0.2513  data: 0.0001  max mem: 10917
[13:05:49.795614] Epoch: [33]  [320/345]  eta: 0:00:06  lr: 0.000070  loss: 0.7487 (0.7584)  time: 0.2514  data: 0.0001  max mem: 10917
[13:05:54.822581] Epoch: [33]  [340/345]  eta: 0:00:01  lr: 0.000069  loss: 0.7580 (0.7586)  time: 0.2513  data: 0.0000  max mem: 10917
[13:05:55.828813] Epoch: [33]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.7569 (0.7585)  time: 0.2513  data: 0.0001  max mem: 10917
[13:05:55.888277] Epoch: [33] Total time: 0:01:26 (0.2512 s / it)
[13:05:55.888765] Averaged stats: lr: 0.000069  loss: 0.7569 (0.7585)
[13:05:56.131258] Test:  [  0/345]  eta: 0:01:22  loss: 0.7369 (0.7369)  time: 0.2392  data: 0.1591  max mem: 10917
[13:05:56.974414] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7173 (0.7178)  time: 0.0983  data: 0.0166  max mem: 10917
[13:05:57.798372] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7097 (0.7167)  time: 0.0833  data: 0.0012  max mem: 10917
[13:05:58.625843] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7158 (0.7176)  time: 0.0825  data: 0.0001  max mem: 10917
[13:05:59.456932] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7203 (0.7183)  time: 0.0829  data: 0.0001  max mem: 10917
[13:06:00.291739] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7264 (0.7196)  time: 0.0832  data: 0.0001  max mem: 10917
[13:06:01.130894] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7262 (0.7205)  time: 0.0836  data: 0.0001  max mem: 10917
[13:06:01.972025] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7182 (0.7209)  time: 0.0840  data: 0.0001  max mem: 10917
[13:06:02.816941] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7172 (0.7213)  time: 0.0843  data: 0.0001  max mem: 10917
[13:06:03.665920] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7154 (0.7209)  time: 0.0846  data: 0.0001  max mem: 10917
[13:06:04.517817] Test:  [100/345]  eta: 0:00:20  loss: 0.7157 (0.7209)  time: 0.0850  data: 0.0001  max mem: 10917
[13:06:05.373966] Test:  [110/345]  eta: 0:00:20  loss: 0.7169 (0.7207)  time: 0.0854  data: 0.0001  max mem: 10917
[13:06:06.233753] Test:  [120/345]  eta: 0:00:19  loss: 0.7247 (0.7213)  time: 0.0857  data: 0.0001  max mem: 10917
[13:06:07.096286] Test:  [130/345]  eta: 0:00:18  loss: 0.7262 (0.7214)  time: 0.0861  data: 0.0001  max mem: 10917
[13:06:07.961926] Test:  [140/345]  eta: 0:00:17  loss: 0.7191 (0.7211)  time: 0.0864  data: 0.0001  max mem: 10917
[13:06:08.831625] Test:  [150/345]  eta: 0:00:16  loss: 0.7159 (0.7217)  time: 0.0867  data: 0.0001  max mem: 10917
[13:06:09.703814] Test:  [160/345]  eta: 0:00:15  loss: 0.7159 (0.7215)  time: 0.0870  data: 0.0001  max mem: 10917
[13:06:10.579703] Test:  [170/345]  eta: 0:00:15  loss: 0.7207 (0.7217)  time: 0.0874  data: 0.0001  max mem: 10917
[13:06:11.460515] Test:  [180/345]  eta: 0:00:14  loss: 0.7239 (0.7223)  time: 0.0878  data: 0.0001  max mem: 10917
[13:06:12.344434] Test:  [190/345]  eta: 0:00:13  loss: 0.7205 (0.7222)  time: 0.0882  data: 0.0001  max mem: 10917
[13:06:13.232165] Test:  [200/345]  eta: 0:00:12  loss: 0.7162 (0.7222)  time: 0.0885  data: 0.0001  max mem: 10917
[13:06:14.122742] Test:  [210/345]  eta: 0:00:11  loss: 0.7200 (0.7223)  time: 0.0889  data: 0.0001  max mem: 10917
[13:06:15.015850] Test:  [220/345]  eta: 0:00:10  loss: 0.7194 (0.7224)  time: 0.0891  data: 0.0001  max mem: 10917
[13:06:15.913280] Test:  [230/345]  eta: 0:00:09  loss: 0.7205 (0.7228)  time: 0.0895  data: 0.0001  max mem: 10917
[13:06:16.814017] Test:  [240/345]  eta: 0:00:09  loss: 0.7240 (0.7228)  time: 0.0899  data: 0.0001  max mem: 10917
[13:06:17.717995] Test:  [250/345]  eta: 0:00:08  loss: 0.7204 (0.7227)  time: 0.0902  data: 0.0001  max mem: 10917
[13:06:18.625992] Test:  [260/345]  eta: 0:00:07  loss: 0.7218 (0.7228)  time: 0.0906  data: 0.0001  max mem: 10917
[13:06:19.538169] Test:  [270/345]  eta: 0:00:06  loss: 0.7214 (0.7227)  time: 0.0910  data: 0.0001  max mem: 10917
[13:06:20.452673] Test:  [280/345]  eta: 0:00:05  loss: 0.7214 (0.7229)  time: 0.0913  data: 0.0001  max mem: 10917
[13:06:21.371246] Test:  [290/345]  eta: 0:00:04  loss: 0.7219 (0.7232)  time: 0.0916  data: 0.0001  max mem: 10917
[13:06:22.293699] Test:  [300/345]  eta: 0:00:03  loss: 0.7211 (0.7232)  time: 0.0920  data: 0.0001  max mem: 10917
[13:06:23.219579] Test:  [310/345]  eta: 0:00:03  loss: 0.7244 (0.7234)  time: 0.0924  data: 0.0001  max mem: 10917
[13:06:24.148914] Test:  [320/345]  eta: 0:00:02  loss: 0.7297 (0.7235)  time: 0.0927  data: 0.0001  max mem: 10917
[13:06:25.081830] Test:  [330/345]  eta: 0:00:01  loss: 0.7161 (0.7232)  time: 0.0931  data: 0.0001  max mem: 10917
[13:06:26.017658] Test:  [340/345]  eta: 0:00:00  loss: 0.7161 (0.7232)  time: 0.0934  data: 0.0001  max mem: 10917
[13:06:26.393617] Test:  [344/345]  eta: 0:00:00  loss: 0.7161 (0.7232)  time: 0.0936  data: 0.0001  max mem: 10917
[13:06:26.450699] Test: Total time: 0:00:30 (0.0886 s / it)
[13:06:37.164003] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8679 (0.8679)  time: 0.2239  data: 0.1439  max mem: 10917
[13:06:37.989617] Test:  [10/57]  eta: 0:00:04  loss: 0.8732 (0.9034)  time: 0.0953  data: 0.0142  max mem: 10917
[13:06:38.807115] Test:  [20/57]  eta: 0:00:03  loss: 0.8865 (0.8905)  time: 0.0821  data: 0.0007  max mem: 10917
[13:06:39.628372] Test:  [30/57]  eta: 0:00:02  loss: 0.7847 (0.8496)  time: 0.0819  data: 0.0001  max mem: 10917
[13:06:40.453568] Test:  [40/57]  eta: 0:00:01  loss: 0.7701 (0.8279)  time: 0.0823  data: 0.0001  max mem: 10917
[13:06:41.282072] Test:  [50/57]  eta: 0:00:00  loss: 0.7573 (0.8196)  time: 0.0826  data: 0.0001  max mem: 10917
[13:06:41.732306] Test:  [56/57]  eta: 0:00:00  loss: 0.7895 (0.8255)  time: 0.0804  data: 0.0001  max mem: 10917
[13:06:41.787697] Test: Total time: 0:00:04 (0.0851 s / it)
[13:06:43.587907] Dice score of the network on the train images: 0.813910, val images: 0.813366
[13:06:43.591532] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:06:43.989799] Epoch: [34]  [  0/345]  eta: 0:02:17  lr: 0.000069  loss: 0.7524 (0.7524)  time: 0.3974  data: 0.1451  max mem: 10917
[13:06:48.983316] Epoch: [34]  [ 20/345]  eta: 0:01:23  lr: 0.000069  loss: 0.7607 (0.7588)  time: 0.2496  data: 0.0001  max mem: 10917
[13:06:53.973128] Epoch: [34]  [ 40/345]  eta: 0:01:17  lr: 0.000068  loss: 0.7605 (0.7596)  time: 0.2495  data: 0.0000  max mem: 10917
[13:06:58.963156] Epoch: [34]  [ 60/345]  eta: 0:01:11  lr: 0.000068  loss: 0.7520 (0.7579)  time: 0.2495  data: 0.0000  max mem: 10917
[13:07:03.962599] Epoch: [34]  [ 80/345]  eta: 0:01:06  lr: 0.000068  loss: 0.7558 (0.7574)  time: 0.2499  data: 0.0001  max mem: 10917
[13:07:08.968637] Epoch: [34]  [100/345]  eta: 0:01:01  lr: 0.000067  loss: 0.7531 (0.7566)  time: 0.2503  data: 0.0000  max mem: 10917
[13:07:13.976074] Epoch: [34]  [120/345]  eta: 0:00:56  lr: 0.000067  loss: 0.7591 (0.7578)  time: 0.2503  data: 0.0001  max mem: 10917
[13:07:18.989400] Epoch: [34]  [140/345]  eta: 0:00:51  lr: 0.000066  loss: 0.7526 (0.7579)  time: 0.2506  data: 0.0000  max mem: 10917
[13:07:24.002442] Epoch: [34]  [160/345]  eta: 0:00:46  lr: 0.000066  loss: 0.7627 (0.7586)  time: 0.2506  data: 0.0000  max mem: 10917
[13:07:29.016985] Epoch: [34]  [180/345]  eta: 0:00:41  lr: 0.000066  loss: 0.7506 (0.7574)  time: 0.2507  data: 0.0001  max mem: 10917
[13:07:34.036013] Epoch: [34]  [200/345]  eta: 0:00:36  lr: 0.000065  loss: 0.7434 (0.7563)  time: 0.2509  data: 0.0001  max mem: 10917
[13:07:39.057558] Epoch: [34]  [220/345]  eta: 0:00:31  lr: 0.000065  loss: 0.7542 (0.7563)  time: 0.2510  data: 0.0001  max mem: 10917
[13:07:44.079777] Epoch: [34]  [240/345]  eta: 0:00:26  lr: 0.000064  loss: 0.7479 (0.7560)  time: 0.2511  data: 0.0000  max mem: 10917
[13:07:49.104252] Epoch: [34]  [260/345]  eta: 0:00:21  lr: 0.000064  loss: 0.7522 (0.7559)  time: 0.2512  data: 0.0001  max mem: 10917
[13:07:54.130155] Epoch: [34]  [280/345]  eta: 0:00:16  lr: 0.000064  loss: 0.7615 (0.7561)  time: 0.2513  data: 0.0001  max mem: 10917
[13:07:59.158587] Epoch: [34]  [300/345]  eta: 0:00:11  lr: 0.000063  loss: 0.7554 (0.7565)  time: 0.2514  data: 0.0000  max mem: 10917
[13:08:04.185732] Epoch: [34]  [320/345]  eta: 0:00:06  lr: 0.000063  loss: 0.7558 (0.7565)  time: 0.2513  data: 0.0000  max mem: 10917
[13:08:09.216866] Epoch: [34]  [340/345]  eta: 0:00:01  lr: 0.000063  loss: 0.7524 (0.7565)  time: 0.2515  data: 0.0001  max mem: 10917
[13:08:10.222750] Epoch: [34]  [344/345]  eta: 0:00:00  lr: 0.000063  loss: 0.7547 (0.7566)  time: 0.2515  data: 0.0001  max mem: 10917
[13:08:10.276886] Epoch: [34] Total time: 0:01:26 (0.2513 s / it)
[13:08:10.277379] Averaged stats: lr: 0.000063  loss: 0.7547 (0.7566)
[13:08:10.514523] Test:  [  0/345]  eta: 0:01:20  loss: 0.6963 (0.6963)  time: 0.2343  data: 0.1539  max mem: 10917
[13:08:11.362172] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7165 (0.7192)  time: 0.0983  data: 0.0166  max mem: 10917
[13:08:12.185966] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7200 (0.7219)  time: 0.0835  data: 0.0015  max mem: 10917
[13:08:13.013286] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7239 (0.7228)  time: 0.0825  data: 0.0001  max mem: 10917
[13:08:13.844091] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7201 (0.7221)  time: 0.0829  data: 0.0001  max mem: 10917
[13:08:14.677903] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7170 (0.7224)  time: 0.0832  data: 0.0001  max mem: 10917
[13:08:15.515651] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7256 (0.7227)  time: 0.0835  data: 0.0001  max mem: 10917
[13:08:16.356378] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7241 (0.7228)  time: 0.0839  data: 0.0001  max mem: 10917
[13:08:17.201538] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7194 (0.7223)  time: 0.0842  data: 0.0001  max mem: 10917
[13:08:18.050215] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7194 (0.7222)  time: 0.0846  data: 0.0001  max mem: 10917
[13:08:18.902477] Test:  [100/345]  eta: 0:00:20  loss: 0.7147 (0.7215)  time: 0.0850  data: 0.0001  max mem: 10917
[13:08:19.757502] Test:  [110/345]  eta: 0:00:20  loss: 0.7141 (0.7215)  time: 0.0853  data: 0.0001  max mem: 10917
[13:08:20.616915] Test:  [120/345]  eta: 0:00:19  loss: 0.7168 (0.7211)  time: 0.0857  data: 0.0001  max mem: 10917
[13:08:21.479336] Test:  [130/345]  eta: 0:00:18  loss: 0.7168 (0.7213)  time: 0.0860  data: 0.0001  max mem: 10917
[13:08:22.345312] Test:  [140/345]  eta: 0:00:17  loss: 0.7161 (0.7209)  time: 0.0864  data: 0.0001  max mem: 10917
[13:08:23.214849] Test:  [150/345]  eta: 0:00:16  loss: 0.7167 (0.7209)  time: 0.0867  data: 0.0001  max mem: 10917
[13:08:24.088482] Test:  [160/345]  eta: 0:00:15  loss: 0.7195 (0.7210)  time: 0.0871  data: 0.0001  max mem: 10917
[13:08:24.965286] Test:  [170/345]  eta: 0:00:15  loss: 0.7195 (0.7210)  time: 0.0875  data: 0.0001  max mem: 10917
[13:08:25.845740] Test:  [180/345]  eta: 0:00:14  loss: 0.7294 (0.7216)  time: 0.0878  data: 0.0001  max mem: 10917
[13:08:26.729478] Test:  [190/345]  eta: 0:00:13  loss: 0.7282 (0.7217)  time: 0.0882  data: 0.0001  max mem: 10917
[13:08:27.615876] Test:  [200/345]  eta: 0:00:12  loss: 0.7251 (0.7222)  time: 0.0885  data: 0.0001  max mem: 10917
[13:08:28.506425] Test:  [210/345]  eta: 0:00:11  loss: 0.7264 (0.7222)  time: 0.0888  data: 0.0001  max mem: 10917
[13:08:29.399398] Test:  [220/345]  eta: 0:00:10  loss: 0.7216 (0.7224)  time: 0.0891  data: 0.0001  max mem: 10917
[13:08:30.296300] Test:  [230/345]  eta: 0:00:09  loss: 0.7254 (0.7226)  time: 0.0894  data: 0.0001  max mem: 10917
[13:08:31.197366] Test:  [240/345]  eta: 0:00:09  loss: 0.7231 (0.7225)  time: 0.0899  data: 0.0001  max mem: 10917
[13:08:32.101871] Test:  [250/345]  eta: 0:00:08  loss: 0.7124 (0.7223)  time: 0.0902  data: 0.0001  max mem: 10917
[13:08:33.010090] Test:  [260/345]  eta: 0:00:07  loss: 0.7192 (0.7226)  time: 0.0906  data: 0.0001  max mem: 10917
[13:08:33.921507] Test:  [270/345]  eta: 0:00:06  loss: 0.7247 (0.7228)  time: 0.0909  data: 0.0001  max mem: 10917
[13:08:34.836525] Test:  [280/345]  eta: 0:00:05  loss: 0.7226 (0.7226)  time: 0.0913  data: 0.0001  max mem: 10917
[13:08:35.754845] Test:  [290/345]  eta: 0:00:04  loss: 0.7219 (0.7226)  time: 0.0916  data: 0.0001  max mem: 10917
[13:08:36.676927] Test:  [300/345]  eta: 0:00:03  loss: 0.7236 (0.7225)  time: 0.0920  data: 0.0001  max mem: 10917
[13:08:37.602650] Test:  [310/345]  eta: 0:00:03  loss: 0.7231 (0.7226)  time: 0.0923  data: 0.0001  max mem: 10917
[13:08:38.532434] Test:  [320/345]  eta: 0:00:02  loss: 0.7178 (0.7226)  time: 0.0927  data: 0.0001  max mem: 10917
[13:08:39.464462] Test:  [330/345]  eta: 0:00:01  loss: 0.7168 (0.7226)  time: 0.0930  data: 0.0001  max mem: 10917
[13:08:40.400044] Test:  [340/345]  eta: 0:00:00  loss: 0.7242 (0.7226)  time: 0.0933  data: 0.0001  max mem: 10917
[13:08:40.775558] Test:  [344/345]  eta: 0:00:00  loss: 0.7247 (0.7225)  time: 0.0935  data: 0.0001  max mem: 10917
[13:08:40.832522] Test: Total time: 0:00:30 (0.0886 s / it)
[13:08:51.433676] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8914 (0.8914)  time: 0.2226  data: 0.1427  max mem: 10917
[13:08:52.254237] Test:  [10/57]  eta: 0:00:04  loss: 0.8914 (0.9133)  time: 0.0947  data: 0.0136  max mem: 10917
[13:08:53.072470] Test:  [20/57]  eta: 0:00:03  loss: 0.8982 (0.8984)  time: 0.0818  data: 0.0004  max mem: 10917
[13:08:53.893510] Test:  [30/57]  eta: 0:00:02  loss: 0.7885 (0.8573)  time: 0.0819  data: 0.0001  max mem: 10917
[13:08:54.717237] Test:  [40/57]  eta: 0:00:01  loss: 0.7789 (0.8350)  time: 0.0822  data: 0.0001  max mem: 10917
[13:08:55.545521] Test:  [50/57]  eta: 0:00:00  loss: 0.7702 (0.8264)  time: 0.0826  data: 0.0001  max mem: 10917
[13:08:55.995060] Test:  [56/57]  eta: 0:00:00  loss: 0.7950 (0.8316)  time: 0.0803  data: 0.0001  max mem: 10917
[13:08:56.053132] Test: Total time: 0:00:04 (0.0850 s / it)
[13:08:57.877834] Dice score of the network on the train images: 0.821054, val images: 0.809360
[13:08:57.882193] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:08:58.280204] Epoch: [35]  [  0/345]  eta: 0:02:16  lr: 0.000063  loss: 0.7465 (0.7465)  time: 0.3969  data: 0.1442  max mem: 10917
[13:09:03.269711] Epoch: [35]  [ 20/345]  eta: 0:01:23  lr: 0.000062  loss: 0.7535 (0.7570)  time: 0.2494  data: 0.0000  max mem: 10917
[13:09:08.259758] Epoch: [35]  [ 40/345]  eta: 0:01:17  lr: 0.000062  loss: 0.7569 (0.7558)  time: 0.2495  data: 0.0000  max mem: 10917
[13:09:13.256468] Epoch: [35]  [ 60/345]  eta: 0:01:11  lr: 0.000061  loss: 0.7486 (0.7542)  time: 0.2498  data: 0.0001  max mem: 10917
[13:09:18.256285] Epoch: [35]  [ 80/345]  eta: 0:01:06  lr: 0.000061  loss: 0.7481 (0.7536)  time: 0.2499  data: 0.0000  max mem: 10917
[13:09:23.259333] Epoch: [35]  [100/345]  eta: 0:01:01  lr: 0.000061  loss: 0.7477 (0.7523)  time: 0.2501  data: 0.0000  max mem: 10917
[13:09:28.268776] Epoch: [35]  [120/345]  eta: 0:00:56  lr: 0.000060  loss: 0.7592 (0.7534)  time: 0.2504  data: 0.0000  max mem: 10917
[13:09:33.276704] Epoch: [35]  [140/345]  eta: 0:00:51  lr: 0.000060  loss: 0.7455 (0.7527)  time: 0.2504  data: 0.0000  max mem: 10917
[13:09:38.287229] Epoch: [35]  [160/345]  eta: 0:00:46  lr: 0.000059  loss: 0.7508 (0.7526)  time: 0.2505  data: 0.0000  max mem: 10917
[13:09:43.374859] Epoch: [35]  [180/345]  eta: 0:00:41  lr: 0.000059  loss: 0.7484 (0.7521)  time: 0.2543  data: 0.0001  max mem: 10917
[13:09:48.392243] Epoch: [35]  [200/345]  eta: 0:00:36  lr: 0.000059  loss: 0.7513 (0.7520)  time: 0.2508  data: 0.0000  max mem: 10917
[13:09:53.406503] Epoch: [35]  [220/345]  eta: 0:00:31  lr: 0.000058  loss: 0.7428 (0.7517)  time: 0.2507  data: 0.0000  max mem: 10917
[13:09:58.426766] Epoch: [35]  [240/345]  eta: 0:00:26  lr: 0.000058  loss: 0.7473 (0.7517)  time: 0.2510  data: 0.0000  max mem: 10917
[13:10:03.450601] Epoch: [35]  [260/345]  eta: 0:00:21  lr: 0.000058  loss: 0.7476 (0.7516)  time: 0.2511  data: 0.0001  max mem: 10917
[13:10:08.477158] Epoch: [35]  [280/345]  eta: 0:00:16  lr: 0.000057  loss: 0.7539 (0.7517)  time: 0.2513  data: 0.0000  max mem: 10917
[13:10:13.502876] Epoch: [35]  [300/345]  eta: 0:00:11  lr: 0.000057  loss: 0.7506 (0.7517)  time: 0.2512  data: 0.0000  max mem: 10917
[13:10:18.530924] Epoch: [35]  [320/345]  eta: 0:00:06  lr: 0.000056  loss: 0.7441 (0.7513)  time: 0.2514  data: 0.0000  max mem: 10917
[13:10:23.560781] Epoch: [35]  [340/345]  eta: 0:00:01  lr: 0.000056  loss: 0.7517 (0.7515)  time: 0.2514  data: 0.0000  max mem: 10917
[13:10:24.566664] Epoch: [35]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.7517 (0.7515)  time: 0.2514  data: 0.0001  max mem: 10917
[13:10:24.627392] Epoch: [35] Total time: 0:01:26 (0.2514 s / it)
[13:10:24.627594] Averaged stats: lr: 0.000056  loss: 0.7517 (0.7515)
[13:10:24.866397] Test:  [  0/345]  eta: 0:01:21  loss: 0.6908 (0.6908)  time: 0.2358  data: 0.1557  max mem: 10917
[13:10:25.689545] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7271 (0.7228)  time: 0.0962  data: 0.0145  max mem: 10917
[13:10:26.513333] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7231 (0.7228)  time: 0.0823  data: 0.0002  max mem: 10917
[13:10:27.340496] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7212 (0.7217)  time: 0.0825  data: 0.0001  max mem: 10917
[13:10:28.170727] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7174 (0.7211)  time: 0.0828  data: 0.0001  max mem: 10917
[13:10:29.004734] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7180 (0.7208)  time: 0.0832  data: 0.0001  max mem: 10917
[13:10:29.842945] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7189 (0.7209)  time: 0.0836  data: 0.0001  max mem: 10917
[13:10:30.683796] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7192 (0.7210)  time: 0.0839  data: 0.0001  max mem: 10917
[13:10:31.527546] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7194 (0.7213)  time: 0.0842  data: 0.0001  max mem: 10917
[13:10:32.376719] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7203 (0.7215)  time: 0.0846  data: 0.0001  max mem: 10917
[13:10:33.227955] Test:  [100/345]  eta: 0:00:20  loss: 0.7200 (0.7217)  time: 0.0850  data: 0.0001  max mem: 10917
[13:10:34.082579] Test:  [110/345]  eta: 0:00:19  loss: 0.7200 (0.7215)  time: 0.0852  data: 0.0001  max mem: 10917
[13:10:34.940377] Test:  [120/345]  eta: 0:00:19  loss: 0.7226 (0.7216)  time: 0.0856  data: 0.0001  max mem: 10917
[13:10:35.801820] Test:  [130/345]  eta: 0:00:18  loss: 0.7224 (0.7214)  time: 0.0859  data: 0.0001  max mem: 10917
[13:10:36.666563] Test:  [140/345]  eta: 0:00:17  loss: 0.7212 (0.7213)  time: 0.0863  data: 0.0001  max mem: 10917
[13:10:37.535194] Test:  [150/345]  eta: 0:00:16  loss: 0.7181 (0.7211)  time: 0.0866  data: 0.0001  max mem: 10917
[13:10:38.407734] Test:  [160/345]  eta: 0:00:15  loss: 0.7177 (0.7209)  time: 0.0870  data: 0.0001  max mem: 10917
[13:10:39.284096] Test:  [170/345]  eta: 0:00:14  loss: 0.7164 (0.7209)  time: 0.0874  data: 0.0001  max mem: 10917
[13:10:40.163478] Test:  [180/345]  eta: 0:00:14  loss: 0.7190 (0.7210)  time: 0.0877  data: 0.0001  max mem: 10917
[13:10:41.045866] Test:  [190/345]  eta: 0:00:13  loss: 0.7190 (0.7208)  time: 0.0880  data: 0.0001  max mem: 10917
[13:10:41.932729] Test:  [200/345]  eta: 0:00:12  loss: 0.7192 (0.7208)  time: 0.0884  data: 0.0001  max mem: 10917
[13:10:42.823138] Test:  [210/345]  eta: 0:00:11  loss: 0.7193 (0.7206)  time: 0.0888  data: 0.0001  max mem: 10917
[13:10:43.716395] Test:  [220/345]  eta: 0:00:10  loss: 0.7145 (0.7203)  time: 0.0891  data: 0.0001  max mem: 10917
[13:10:44.612802] Test:  [230/345]  eta: 0:00:09  loss: 0.7151 (0.7203)  time: 0.0894  data: 0.0001  max mem: 10917
[13:10:45.513470] Test:  [240/345]  eta: 0:00:09  loss: 0.7229 (0.7206)  time: 0.0898  data: 0.0001  max mem: 10917
[13:10:46.416451] Test:  [250/345]  eta: 0:00:08  loss: 0.7216 (0.7207)  time: 0.0901  data: 0.0001  max mem: 10917
[13:10:47.324324] Test:  [260/345]  eta: 0:00:07  loss: 0.7150 (0.7205)  time: 0.0905  data: 0.0001  max mem: 10917
[13:10:48.235806] Test:  [270/345]  eta: 0:00:06  loss: 0.7166 (0.7205)  time: 0.0909  data: 0.0001  max mem: 10917
[13:10:49.150347] Test:  [280/345]  eta: 0:00:05  loss: 0.7200 (0.7205)  time: 0.0913  data: 0.0001  max mem: 10917
[13:10:50.068540] Test:  [290/345]  eta: 0:00:04  loss: 0.7200 (0.7204)  time: 0.0916  data: 0.0001  max mem: 10917
[13:10:50.990341] Test:  [300/345]  eta: 0:00:03  loss: 0.7169 (0.7201)  time: 0.0920  data: 0.0001  max mem: 10917
[13:10:51.915464] Test:  [310/345]  eta: 0:00:03  loss: 0.7159 (0.7202)  time: 0.0923  data: 0.0001  max mem: 10917
[13:10:52.843387] Test:  [320/345]  eta: 0:00:02  loss: 0.7159 (0.7201)  time: 0.0926  data: 0.0001  max mem: 10917
[13:10:53.774533] Test:  [330/345]  eta: 0:00:01  loss: 0.7116 (0.7200)  time: 0.0929  data: 0.0001  max mem: 10917
[13:10:54.710336] Test:  [340/345]  eta: 0:00:00  loss: 0.7132 (0.7199)  time: 0.0933  data: 0.0001  max mem: 10917
[13:10:55.086002] Test:  [344/345]  eta: 0:00:00  loss: 0.7137 (0.7199)  time: 0.0935  data: 0.0001  max mem: 10917
[13:10:55.144876] Test: Total time: 0:00:30 (0.0884 s / it)
[13:11:05.739840] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8736 (0.8736)  time: 0.2234  data: 0.1438  max mem: 10917
[13:11:06.553975] Test:  [10/57]  eta: 0:00:04  loss: 0.8963 (0.9095)  time: 0.0942  data: 0.0131  max mem: 10917
[13:11:07.370833] Test:  [20/57]  eta: 0:00:03  loss: 0.8963 (0.8949)  time: 0.0815  data: 0.0001  max mem: 10917
[13:11:08.191739] Test:  [30/57]  eta: 0:00:02  loss: 0.7912 (0.8543)  time: 0.0818  data: 0.0001  max mem: 10917
[13:11:09.015761] Test:  [40/57]  eta: 0:00:01  loss: 0.7740 (0.8324)  time: 0.0822  data: 0.0001  max mem: 10917
[13:11:09.844583] Test:  [50/57]  eta: 0:00:00  loss: 0.7639 (0.8245)  time: 0.0826  data: 0.0001  max mem: 10917
[13:11:10.294436] Test:  [56/57]  eta: 0:00:00  loss: 0.7959 (0.8302)  time: 0.0804  data: 0.0001  max mem: 10917
[13:11:10.334652] Test: Total time: 0:00:04 (0.0845 s / it)
[13:11:12.170215] Dice score of the network on the train images: 0.821661, val images: 0.811226
[13:11:12.174435] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:11:12.571636] Epoch: [36]  [  0/345]  eta: 0:02:16  lr: 0.000056  loss: 0.7340 (0.7340)  time: 0.3962  data: 0.1437  max mem: 10917
[13:11:17.576290] Epoch: [36]  [ 20/345]  eta: 0:01:23  lr: 0.000056  loss: 0.7458 (0.7488)  time: 0.2502  data: 0.0001  max mem: 10917
[13:11:22.579672] Epoch: [36]  [ 40/345]  eta: 0:01:17  lr: 0.000055  loss: 0.7446 (0.7497)  time: 0.2501  data: 0.0001  max mem: 10917
[13:11:27.571351] Epoch: [36]  [ 60/345]  eta: 0:01:11  lr: 0.000055  loss: 0.7509 (0.7501)  time: 0.2495  data: 0.0001  max mem: 10917
[13:11:32.566267] Epoch: [36]  [ 80/345]  eta: 0:01:06  lr: 0.000054  loss: 0.7527 (0.7506)  time: 0.2497  data: 0.0001  max mem: 10917
[13:11:37.570689] Epoch: [36]  [100/345]  eta: 0:01:01  lr: 0.000054  loss: 0.7495 (0.7501)  time: 0.2502  data: 0.0001  max mem: 10917
[13:11:42.571334] Epoch: [36]  [120/345]  eta: 0:00:56  lr: 0.000054  loss: 0.7480 (0.7501)  time: 0.2500  data: 0.0000  max mem: 10917
[13:11:47.578228] Epoch: [36]  [140/345]  eta: 0:00:51  lr: 0.000053  loss: 0.7354 (0.7481)  time: 0.2503  data: 0.0001  max mem: 10917
[13:11:52.587453] Epoch: [36]  [160/345]  eta: 0:00:46  lr: 0.000053  loss: 0.7424 (0.7479)  time: 0.2504  data: 0.0001  max mem: 10917
[13:11:57.595005] Epoch: [36]  [180/345]  eta: 0:00:41  lr: 0.000053  loss: 0.7421 (0.7473)  time: 0.2503  data: 0.0001  max mem: 10917
[13:12:02.609052] Epoch: [36]  [200/345]  eta: 0:00:36  lr: 0.000052  loss: 0.7456 (0.7474)  time: 0.2507  data: 0.0000  max mem: 10917
[13:12:07.626424] Epoch: [36]  [220/345]  eta: 0:00:31  lr: 0.000052  loss: 0.7489 (0.7477)  time: 0.2508  data: 0.0000  max mem: 10917
[13:12:12.640334] Epoch: [36]  [240/345]  eta: 0:00:26  lr: 0.000051  loss: 0.7552 (0.7486)  time: 0.2507  data: 0.0000  max mem: 10917
[13:12:17.661361] Epoch: [36]  [260/345]  eta: 0:00:21  lr: 0.000051  loss: 0.7563 (0.7490)  time: 0.2510  data: 0.0000  max mem: 10917
[13:12:22.685055] Epoch: [36]  [280/345]  eta: 0:00:16  lr: 0.000051  loss: 0.7443 (0.7490)  time: 0.2511  data: 0.0000  max mem: 10917
[13:12:27.710721] Epoch: [36]  [300/345]  eta: 0:00:11  lr: 0.000050  loss: 0.7533 (0.7497)  time: 0.2512  data: 0.0001  max mem: 10917
[13:12:32.736299] Epoch: [36]  [320/345]  eta: 0:00:06  lr: 0.000050  loss: 0.7503 (0.7500)  time: 0.2512  data: 0.0000  max mem: 10917
[13:12:37.763248] Epoch: [36]  [340/345]  eta: 0:00:01  lr: 0.000050  loss: 0.7411 (0.7496)  time: 0.2513  data: 0.0000  max mem: 10917
[13:12:38.769878] Epoch: [36]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.7418 (0.7496)  time: 0.2514  data: 0.0001  max mem: 10917
[13:12:38.828831] Epoch: [36] Total time: 0:01:26 (0.2512 s / it)
[13:12:38.829233] Averaged stats: lr: 0.000050  loss: 0.7418 (0.7496)
[13:12:39.064404] Test:  [  0/345]  eta: 0:01:20  loss: 0.7173 (0.7173)  time: 0.2325  data: 0.1520  max mem: 10917
[13:12:39.886294] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7132 (0.7158)  time: 0.0958  data: 0.0140  max mem: 10917
[13:12:40.709472] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7132 (0.7171)  time: 0.0822  data: 0.0001  max mem: 10917
[13:12:41.536480] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7140 (0.7161)  time: 0.0825  data: 0.0001  max mem: 10917
[13:12:42.366010] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7144 (0.7174)  time: 0.0828  data: 0.0001  max mem: 10917
[13:12:43.200246] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7149 (0.7181)  time: 0.0831  data: 0.0001  max mem: 10917
[13:12:44.038162] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7147 (0.7177)  time: 0.0836  data: 0.0001  max mem: 10917
[13:12:44.879463] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7147 (0.7175)  time: 0.0839  data: 0.0001  max mem: 10917
[13:12:45.723879] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7213 (0.7178)  time: 0.0842  data: 0.0001  max mem: 10917
[13:12:46.572896] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7216 (0.7178)  time: 0.0846  data: 0.0001  max mem: 10917
[13:12:47.424618] Test:  [100/345]  eta: 0:00:20  loss: 0.7222 (0.7180)  time: 0.0850  data: 0.0001  max mem: 10917
[13:12:48.279805] Test:  [110/345]  eta: 0:00:19  loss: 0.7219 (0.7178)  time: 0.0853  data: 0.0001  max mem: 10917
[13:12:49.139035] Test:  [120/345]  eta: 0:00:19  loss: 0.7203 (0.7184)  time: 0.0857  data: 0.0001  max mem: 10917
[13:12:50.001180] Test:  [130/345]  eta: 0:00:18  loss: 0.7203 (0.7185)  time: 0.0860  data: 0.0001  max mem: 10917
[13:12:50.866487] Test:  [140/345]  eta: 0:00:17  loss: 0.7131 (0.7179)  time: 0.0863  data: 0.0001  max mem: 10917
[13:12:51.735755] Test:  [150/345]  eta: 0:00:16  loss: 0.7131 (0.7180)  time: 0.0867  data: 0.0001  max mem: 10917
[13:12:52.607880] Test:  [160/345]  eta: 0:00:15  loss: 0.7184 (0.7182)  time: 0.0870  data: 0.0001  max mem: 10917
[13:12:53.485442] Test:  [170/345]  eta: 0:00:14  loss: 0.7155 (0.7181)  time: 0.0874  data: 0.0001  max mem: 10917
[13:12:54.364969] Test:  [180/345]  eta: 0:00:14  loss: 0.7149 (0.7185)  time: 0.0878  data: 0.0001  max mem: 10917
[13:12:55.248444] Test:  [190/345]  eta: 0:00:13  loss: 0.7201 (0.7184)  time: 0.0881  data: 0.0001  max mem: 10917
[13:12:56.135287] Test:  [200/345]  eta: 0:00:12  loss: 0.7160 (0.7184)  time: 0.0885  data: 0.0001  max mem: 10917
[13:12:57.026639] Test:  [210/345]  eta: 0:00:11  loss: 0.7197 (0.7186)  time: 0.0889  data: 0.0001  max mem: 10917
[13:12:57.920246] Test:  [220/345]  eta: 0:00:10  loss: 0.7187 (0.7184)  time: 0.0892  data: 0.0001  max mem: 10917
[13:12:58.818260] Test:  [230/345]  eta: 0:00:09  loss: 0.7105 (0.7184)  time: 0.0895  data: 0.0001  max mem: 10917
[13:12:59.720097] Test:  [240/345]  eta: 0:00:09  loss: 0.7154 (0.7183)  time: 0.0899  data: 0.0001  max mem: 10917
[13:13:00.624598] Test:  [250/345]  eta: 0:00:08  loss: 0.7154 (0.7183)  time: 0.0903  data: 0.0001  max mem: 10917
[13:13:01.532827] Test:  [260/345]  eta: 0:00:07  loss: 0.7157 (0.7183)  time: 0.0906  data: 0.0001  max mem: 10917
[13:13:02.445229] Test:  [270/345]  eta: 0:00:06  loss: 0.7161 (0.7180)  time: 0.0910  data: 0.0001  max mem: 10917
[13:13:03.360586] Test:  [280/345]  eta: 0:00:05  loss: 0.7178 (0.7182)  time: 0.0913  data: 0.0001  max mem: 10917
[13:13:04.279446] Test:  [290/345]  eta: 0:00:04  loss: 0.7091 (0.7178)  time: 0.0917  data: 0.0001  max mem: 10917
[13:13:05.200760] Test:  [300/345]  eta: 0:00:03  loss: 0.7060 (0.7175)  time: 0.0920  data: 0.0001  max mem: 10917
[13:13:06.126417] Test:  [310/345]  eta: 0:00:03  loss: 0.7113 (0.7175)  time: 0.0923  data: 0.0001  max mem: 10917
[13:13:07.055358] Test:  [320/345]  eta: 0:00:02  loss: 0.7177 (0.7176)  time: 0.0927  data: 0.0001  max mem: 10917
[13:13:07.987948] Test:  [330/345]  eta: 0:00:01  loss: 0.7209 (0.7177)  time: 0.0930  data: 0.0001  max mem: 10917
[13:13:08.923694] Test:  [340/345]  eta: 0:00:00  loss: 0.7125 (0.7174)  time: 0.0934  data: 0.0001  max mem: 10917
[13:13:09.299486] Test:  [344/345]  eta: 0:00:00  loss: 0.7062 (0.7174)  time: 0.0935  data: 0.0001  max mem: 10917
[13:13:09.358456] Test: Total time: 0:00:30 (0.0885 s / it)
[13:13:19.981955] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8874 (0.8874)  time: 0.2222  data: 0.1424  max mem: 10917
[13:13:20.794245] Test:  [10/57]  eta: 0:00:04  loss: 0.8913 (0.9154)  time: 0.0940  data: 0.0130  max mem: 10917
[13:13:21.610956] Test:  [20/57]  eta: 0:00:03  loss: 0.9184 (0.9033)  time: 0.0814  data: 0.0001  max mem: 10917
[13:13:22.432068] Test:  [30/57]  eta: 0:00:02  loss: 0.7892 (0.8609)  time: 0.0818  data: 0.0001  max mem: 10917
[13:13:23.256725] Test:  [40/57]  eta: 0:00:01  loss: 0.7831 (0.8383)  time: 0.0822  data: 0.0001  max mem: 10917
[13:13:24.085730] Test:  [50/57]  eta: 0:00:00  loss: 0.7660 (0.8307)  time: 0.0826  data: 0.0001  max mem: 10917
[13:13:24.535510] Test:  [56/57]  eta: 0:00:00  loss: 0.7981 (0.8362)  time: 0.0804  data: 0.0001  max mem: 10917
[13:13:24.595620] Test: Total time: 0:00:04 (0.0848 s / it)
[13:13:26.442988] Dice score of the network on the train images: 0.823229, val images: 0.806497
[13:13:26.446846] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft

[13:13:26.844426] Epoch: [37]  [  0/345]  eta: 0:02:16  lr: 0.000050  loss: 0.7237 (0.7237)  time: 0.3966  data: 0.1456  max mem: 10917
[13:13:31.844479] Epoch: [37]  [ 20/345]  eta: 0:01:23  lr: 0.000049  loss: 0.7484 (0.7502)  time: 0.2500  data: 0.0001  max mem: 10917

[13:13:36.854278] Epoch: [37]  [ 40/345]  eta: 0:01:17  lr: 0.000049  loss: 0.7527 (0.7506)  time: 0.2504  data: 0.0001  max mem: 10917
[13:13:41.861810] Epoch: [37]  [ 60/345]  eta: 0:01:12  lr: 0.000048  loss: 0.7551 (0.7519)  time: 0.2503  data: 0.0000  max mem: 10917

[13:13:46.869621] Epoch: [37]  [ 80/345]  eta: 0:01:06  lr: 0.000048  loss: 0.7462 (0.7515)  time: 0.2503  data: 0.0000  max mem: 10917
[13:13:51.888235] Epoch: [37]  [100/345]  eta: 0:01:01  lr: 0.000048  loss: 0.7506 (0.7509)  time: 0.2509  data: 0.0001  max mem: 10917
[13:13:56.910302] Epoch: [37]  [120/345]  eta: 0:00:56  lr: 0.000047  loss: 0.7476 (0.7509)  time: 0.2511  data: 0.0001  max mem: 10917
[13:14:01.934463] Epoch: [37]  [140/345]  eta: 0:00:51  lr: 0.000047  loss: 0.7456 (0.7506)  time: 0.2512  data: 0.0001  max mem: 10917
[13:14:06.955846] Epoch: [37]  [160/345]  eta: 0:00:46  lr: 0.000047  loss: 0.7403 (0.7504)  time: 0.2510  data: 0.0001  max mem: 10917
[13:14:11.977549] Epoch: [37]  [180/345]  eta: 0:00:41  lr: 0.000046  loss: 0.7428 (0.7499)  time: 0.2510  data: 0.0001  max mem: 10917
[13:14:16.991730] Epoch: [37]  [200/345]  eta: 0:00:36  lr: 0.000046  loss: 0.7407 (0.7494)  time: 0.2507  data: 0.0001  max mem: 10917
[13:14:22.018525] Epoch: [37]  [220/345]  eta: 0:00:31  lr: 0.000045  loss: 0.7456 (0.7493)  time: 0.2513  data: 0.0001  max mem: 10917
[13:14:27.055756] Epoch: [37]  [240/345]  eta: 0:00:26  lr: 0.000045  loss: 0.7429 (0.7492)  time: 0.2518  data: 0.0000  max mem: 10917
[13:14:32.095946] Epoch: [37]  [260/345]  eta: 0:00:21  lr: 0.000045  loss: 0.7494 (0.7490)  time: 0.2520  data: 0.0000  max mem: 10917
[13:14:37.141266] Epoch: [37]  [280/345]  eta: 0:00:16  lr: 0.000044  loss: 0.7475 (0.7489)  time: 0.2522  data: 0.0000  max mem: 10917
[13:14:42.180771] Epoch: [37]  [300/345]  eta: 0:00:11  lr: 0.000044  loss: 0.7463 (0.7488)  time: 0.2519  data: 0.0000  max mem: 10917
[13:14:47.222014] Epoch: [37]  [320/345]  eta: 0:00:06  lr: 0.000044  loss: 0.7472 (0.7488)  time: 0.2520  data: 0.0000  max mem: 10917
[13:14:52.265924] Epoch: [37]  [340/345]  eta: 0:00:01  lr: 0.000043  loss: 0.7483 (0.7487)  time: 0.2521  data: 0.0000  max mem: 10917
[13:14:53.274713] Epoch: [37]  [344/345]  eta: 0:00:00  lr: 0.000043  loss: 0.7477 (0.7488)  time: 0.2521  data: 0.0001  max mem: 10917
[13:14:53.333795] Epoch: [37] Total time: 0:01:26 (0.2518 s / it)
[13:14:53.334089] Averaged stats: lr: 0.000043  loss: 0.7477 (0.7488)
[13:14:53.575239] Test:  [  0/345]  eta: 0:01:22  loss: 0.7185 (0.7185)  time: 0.2378  data: 0.1577  max mem: 10917
[13:14:54.399079] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7215 (0.7244)  time: 0.0964  data: 0.0146  max mem: 10917
[13:14:55.222816] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7189 (0.7186)  time: 0.0823  data: 0.0002  max mem: 10917
[13:14:56.050169] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7106 (0.7178)  time: 0.0825  data: 0.0001  max mem: 10917
[13:14:56.880643] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7135 (0.7171)  time: 0.0828  data: 0.0001  max mem: 10917
[13:14:57.714993] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7115 (0.7170)  time: 0.0832  data: 0.0001  max mem: 10917
[13:14:58.553006] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7174 (0.7173)  time: 0.0836  data: 0.0001  max mem: 10917
[13:14:59.393924] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7174 (0.7169)  time: 0.0839  data: 0.0001  max mem: 10917
[13:15:00.238686] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7163 (0.7177)  time: 0.0842  data: 0.0001  max mem: 10917
[13:15:01.086703] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7136 (0.7168)  time: 0.0846  data: 0.0001  max mem: 10917
[13:15:01.938614] Test:  [100/345]  eta: 0:00:20  loss: 0.7103 (0.7161)  time: 0.0849  data: 0.0001  max mem: 10917
[13:15:02.794668] Test:  [110/345]  eta: 0:00:20  loss: 0.7126 (0.7159)  time: 0.0854  data: 0.0001  max mem: 10917
[13:15:03.652780] Test:  [120/345]  eta: 0:00:19  loss: 0.7137 (0.7157)  time: 0.0857  data: 0.0001  max mem: 10917
[13:15:04.514891] Test:  [130/345]  eta: 0:00:18  loss: 0.7110 (0.7156)  time: 0.0860  data: 0.0001  max mem: 10917
[13:15:05.381615] Test:  [140/345]  eta: 0:00:17  loss: 0.7105 (0.7155)  time: 0.0864  data: 0.0001  max mem: 10917
[13:15:06.251433] Test:  [150/345]  eta: 0:00:16  loss: 0.7129 (0.7157)  time: 0.0867  data: 0.0001  max mem: 10917
[13:15:07.124578] Test:  [160/345]  eta: 0:00:15  loss: 0.7174 (0.7161)  time: 0.0871  data: 0.0001  max mem: 10917
[13:15:08.002240] Test:  [170/345]  eta: 0:00:14  loss: 0.7138 (0.7160)  time: 0.0875  data: 0.0001  max mem: 10917
[13:15:08.883320] Test:  [180/345]  eta: 0:00:14  loss: 0.7099 (0.7158)  time: 0.0879  data: 0.0001  max mem: 10917
[13:15:09.766275] Test:  [190/345]  eta: 0:00:13  loss: 0.7099 (0.7158)  time: 0.0882  data: 0.0001  max mem: 10917
[13:15:10.652850] Test:  [200/345]  eta: 0:00:12  loss: 0.7140 (0.7157)  time: 0.0884  data: 0.0001  max mem: 10917
[13:15:11.543313] Test:  [210/345]  eta: 0:00:11  loss: 0.7140 (0.7161)  time: 0.0888  data: 0.0001  max mem: 10917
[13:15:12.437045] Test:  [220/345]  eta: 0:00:10  loss: 0.7123 (0.7160)  time: 0.0892  data: 0.0001  max mem: 10917
[13:15:13.334854] Test:  [230/345]  eta: 0:00:09  loss: 0.7130 (0.7160)  time: 0.0895  data: 0.0001  max mem: 10917
[13:15:14.236717] Test:  [240/345]  eta: 0:00:09  loss: 0.7191 (0.7162)  time: 0.0899  data: 0.0001  max mem: 10917
[13:15:15.141508] Test:  [250/345]  eta: 0:00:08  loss: 0.7170 (0.7159)  time: 0.0903  data: 0.0001  max mem: 10917
[13:15:16.049549] Test:  [260/345]  eta: 0:00:07  loss: 0.7097 (0.7158)  time: 0.0906  data: 0.0001  max mem: 10917
[13:15:16.961906] Test:  [270/345]  eta: 0:00:06  loss: 0.7150 (0.7160)  time: 0.0910  data: 0.0001  max mem: 10917
[13:15:17.877290] Test:  [280/345]  eta: 0:00:05  loss: 0.7185 (0.7159)  time: 0.0913  data: 0.0001  max mem: 10917
[13:15:18.796109] Test:  [290/345]  eta: 0:00:04  loss: 0.7098 (0.7159)  time: 0.0917  data: 0.0001  max mem: 10917
[13:15:19.718645] Test:  [300/345]  eta: 0:00:03  loss: 0.7098 (0.7159)  time: 0.0920  data: 0.0001  max mem: 10917
[13:15:20.644458] Test:  [310/345]  eta: 0:00:03  loss: 0.7211 (0.7161)  time: 0.0924  data: 0.0001  max mem: 10917
[13:15:21.573478] Test:  [320/345]  eta: 0:00:02  loss: 0.7213 (0.7163)  time: 0.0927  data: 0.0001  max mem: 10917
[13:15:22.506297] Test:  [330/345]  eta: 0:00:01  loss: 0.7151 (0.7162)  time: 0.0930  data: 0.0001  max mem: 10917
[13:15:23.442840] Test:  [340/345]  eta: 0:00:00  loss: 0.7118 (0.7163)  time: 0.0934  data: 0.0001  max mem: 10917
[13:15:23.818728] Test:  [344/345]  eta: 0:00:00  loss: 0.7118 (0.7163)  time: 0.0936  data: 0.0001  max mem: 10917
[13:15:23.877886] Test: Total time: 0:00:30 (0.0885 s / it)
[13:15:34.592181] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8784 (0.8784)  time: 0.2225  data: 0.1428  max mem: 10917
[13:15:35.406186] Test:  [10/57]  eta: 0:00:04  loss: 0.8970 (0.9100)  time: 0.0941  data: 0.0131  max mem: 10917
[13:15:36.223479] Test:  [20/57]  eta: 0:00:03  loss: 0.8983 (0.8983)  time: 0.0815  data: 0.0001  max mem: 10917
[13:15:37.044536] Test:  [30/57]  eta: 0:00:02  loss: 0.7924 (0.8566)  time: 0.0819  data: 0.0001  max mem: 10917
[13:15:37.868048] Test:  [40/57]  eta: 0:00:01  loss: 0.7733 (0.8340)  time: 0.0822  data: 0.0001  max mem: 10917
[13:15:38.696005] Test:  [50/57]  eta: 0:00:00  loss: 0.7625 (0.8259)  time: 0.0825  data: 0.0001  max mem: 10917
[13:15:39.145957] Test:  [56/57]  eta: 0:00:00  loss: 0.7996 (0.8325)  time: 0.0803  data: 0.0001  max mem: 10917
[13:15:39.200868] Test: Total time: 0:00:04 (0.0848 s / it)
[13:15:41.076601] Dice score of the network on the train images: 0.821771, val images: 0.814465
[13:15:41.080088] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:15:41.479841] Epoch: [38]  [  0/345]  eta: 0:02:17  lr: 0.000043  loss: 0.7400 (0.7400)  time: 0.3987  data: 0.1458  max mem: 10917
[13:15:46.491896] Epoch: [38]  [ 20/345]  eta: 0:01:23  lr: 0.000043  loss: 0.7510 (0.7503)  time: 0.2505  data: 0.0001  max mem: 10917
[13:15:51.506085] Epoch: [38]  [ 40/345]  eta: 0:01:17  lr: 0.000042  loss: 0.7387 (0.7458)  time: 0.2507  data: 0.0001  max mem: 10917
[13:15:56.529120] Epoch: [38]  [ 60/345]  eta: 0:01:12  lr: 0.000042  loss: 0.7427 (0.7470)  time: 0.2511  data: 0.0001  max mem: 10917
[13:16:01.559617] Epoch: [38]  [ 80/345]  eta: 0:01:06  lr: 0.000042  loss: 0.7444 (0.7463)  time: 0.2515  data: 0.0001  max mem: 10917
[13:16:06.578800] Epoch: [38]  [100/345]  eta: 0:01:01  lr: 0.000041  loss: 0.7408 (0.7460)  time: 0.2509  data: 0.0001  max mem: 10917
[13:16:11.601487] Epoch: [38]  [120/345]  eta: 0:00:56  lr: 0.000041  loss: 0.7479 (0.7465)  time: 0.2511  data: 0.0001  max mem: 10917
[13:16:16.626602] Epoch: [38]  [140/345]  eta: 0:00:51  lr: 0.000041  loss: 0.7383 (0.7456)  time: 0.2512  data: 0.0001  max mem: 10917
[13:16:21.647725] Epoch: [38]  [160/345]  eta: 0:00:46  lr: 0.000040  loss: 0.7460 (0.7458)  time: 0.2510  data: 0.0001  max mem: 10917
[13:16:26.672159] Epoch: [38]  [180/345]  eta: 0:00:41  lr: 0.000040  loss: 0.7524 (0.7473)  time: 0.2512  data: 0.0001  max mem: 10917
[13:16:31.708867] Epoch: [38]  [200/345]  eta: 0:00:36  lr: 0.000040  loss: 0.7566 (0.7481)  time: 0.2518  data: 0.0001  max mem: 10917
[13:16:36.745305] Epoch: [38]  [220/345]  eta: 0:00:31  lr: 0.000039  loss: 0.7483 (0.7482)  time: 0.2518  data: 0.0001  max mem: 10917
[13:16:41.780156] Epoch: [38]  [240/345]  eta: 0:00:26  lr: 0.000039  loss: 0.7465 (0.7482)  time: 0.2517  data: 0.0001  max mem: 10917
[13:16:46.817613] Epoch: [38]  [260/345]  eta: 0:00:21  lr: 0.000039  loss: 0.7411 (0.7478)  time: 0.2518  data: 0.0000  max mem: 10917
[13:16:51.856853] Epoch: [38]  [280/345]  eta: 0:00:16  lr: 0.000038  loss: 0.7515 (0.7480)  time: 0.2519  data: 0.0001  max mem: 10917
[13:16:56.896316] Epoch: [38]  [300/345]  eta: 0:00:11  lr: 0.000038  loss: 0.7447 (0.7480)  time: 0.2519  data: 0.0001  max mem: 10917
[13:17:01.937453] Epoch: [38]  [320/345]  eta: 0:00:06  lr: 0.000038  loss: 0.7542 (0.7484)  time: 0.2520  data: 0.0001  max mem: 10917
[13:17:06.963942] Epoch: [38]  [340/345]  eta: 0:00:01  lr: 0.000037  loss: 0.7442 (0.7482)  time: 0.2513  data: 0.0001  max mem: 10917
[13:17:07.971383] Epoch: [38]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 0.7455 (0.7482)  time: 0.2513  data: 0.0001  max mem: 10917
[13:17:08.029931] Epoch: [38] Total time: 0:01:26 (0.2520 s / it)
[13:17:08.030273] Averaged stats: lr: 0.000037  loss: 0.7455 (0.7482)
[13:17:08.276692] Test:  [  0/345]  eta: 0:01:23  loss: 0.6934 (0.6934)  time: 0.2428  data: 0.1625  max mem: 10917
[13:17:09.109583] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7147 (0.7108)  time: 0.0977  data: 0.0160  max mem: 10917
[13:17:09.932403] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7124 (0.7138)  time: 0.0827  data: 0.0007  max mem: 10917
[13:17:10.759224] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7124 (0.7141)  time: 0.0824  data: 0.0001  max mem: 10917
[13:17:11.590524] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7125 (0.7150)  time: 0.0829  data: 0.0001  max mem: 10917
[13:17:12.424276] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7077 (0.7147)  time: 0.0832  data: 0.0001  max mem: 10917
[13:17:13.263050] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7211 (0.7164)  time: 0.0836  data: 0.0001  max mem: 10917
[13:17:14.104097] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7138 (0.7157)  time: 0.0839  data: 0.0001  max mem: 10917
[13:17:14.949038] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7080 (0.7150)  time: 0.0843  data: 0.0001  max mem: 10917
[13:17:15.797457] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7072 (0.7145)  time: 0.0846  data: 0.0001  max mem: 10917
[13:17:16.650332] Test:  [100/345]  eta: 0:00:20  loss: 0.7086 (0.7141)  time: 0.0850  data: 0.0001  max mem: 10917
[13:17:17.505151] Test:  [110/345]  eta: 0:00:20  loss: 0.7118 (0.7140)  time: 0.0853  data: 0.0001  max mem: 10917
[13:17:18.364126] Test:  [120/345]  eta: 0:00:19  loss: 0.7129 (0.7144)  time: 0.0856  data: 0.0001  max mem: 10917
[13:17:19.226621] Test:  [130/345]  eta: 0:00:18  loss: 0.7142 (0.7145)  time: 0.0860  data: 0.0001  max mem: 10917
[13:17:20.092689] Test:  [140/345]  eta: 0:00:17  loss: 0.7091 (0.7142)  time: 0.0864  data: 0.0001  max mem: 10917
[13:17:20.962451] Test:  [150/345]  eta: 0:00:16  loss: 0.7104 (0.7148)  time: 0.0867  data: 0.0001  max mem: 10917
[13:17:21.835863] Test:  [160/345]  eta: 0:00:15  loss: 0.7198 (0.7150)  time: 0.0871  data: 0.0001  max mem: 10917
[13:17:22.712775] Test:  [170/345]  eta: 0:00:15  loss: 0.7121 (0.7148)  time: 0.0874  data: 0.0001  max mem: 10917
[13:17:23.592939] Test:  [180/345]  eta: 0:00:14  loss: 0.7116 (0.7149)  time: 0.0878  data: 0.0001  max mem: 10917
[13:17:24.476073] Test:  [190/345]  eta: 0:00:13  loss: 0.7183 (0.7151)  time: 0.0881  data: 0.0001  max mem: 10917
[13:17:25.363534] Test:  [200/345]  eta: 0:00:12  loss: 0.7165 (0.7150)  time: 0.0885  data: 0.0001  max mem: 10917
[13:17:26.254162] Test:  [210/345]  eta: 0:00:11  loss: 0.7104 (0.7148)  time: 0.0889  data: 0.0001  max mem: 10917
[13:17:27.148131] Test:  [220/345]  eta: 0:00:10  loss: 0.7135 (0.7150)  time: 0.0892  data: 0.0001  max mem: 10917
[13:17:28.046097] Test:  [230/345]  eta: 0:00:09  loss: 0.7192 (0.7150)  time: 0.0896  data: 0.0001  max mem: 10917
[13:17:28.948389] Test:  [240/345]  eta: 0:00:09  loss: 0.7188 (0.7151)  time: 0.0900  data: 0.0001  max mem: 10917
[13:17:29.853229] Test:  [250/345]  eta: 0:00:08  loss: 0.7188 (0.7149)  time: 0.0903  data: 0.0001  max mem: 10917
[13:17:30.761413] Test:  [260/345]  eta: 0:00:07  loss: 0.7142 (0.7151)  time: 0.0906  data: 0.0001  max mem: 10917
[13:17:31.673539] Test:  [270/345]  eta: 0:00:06  loss: 0.7174 (0.7151)  time: 0.0910  data: 0.0001  max mem: 10917
[13:17:32.588692] Test:  [280/345]  eta: 0:00:05  loss: 0.7149 (0.7150)  time: 0.0913  data: 0.0001  max mem: 10917
[13:17:33.506499] Test:  [290/345]  eta: 0:00:04  loss: 0.7149 (0.7151)  time: 0.0916  data: 0.0001  max mem: 10917
[13:17:34.428579] Test:  [300/345]  eta: 0:00:03  loss: 0.7146 (0.7151)  time: 0.0919  data: 0.0001  max mem: 10917
[13:17:35.354701] Test:  [310/345]  eta: 0:00:03  loss: 0.7146 (0.7152)  time: 0.0924  data: 0.0001  max mem: 10917
[13:17:36.282868] Test:  [320/345]  eta: 0:00:02  loss: 0.7136 (0.7151)  time: 0.0927  data: 0.0001  max mem: 10917
[13:17:37.215454] Test:  [330/345]  eta: 0:00:01  loss: 0.7146 (0.7153)  time: 0.0930  data: 0.0001  max mem: 10917
[13:17:38.151397] Test:  [340/345]  eta: 0:00:00  loss: 0.7145 (0.7153)  time: 0.0934  data: 0.0001  max mem: 10917
[13:17:38.527451] Test:  [344/345]  eta: 0:00:00  loss: 0.7146 (0.7153)  time: 0.0935  data: 0.0001  max mem: 10917
[13:17:38.583951] Test: Total time: 0:00:30 (0.0886 s / it)
[13:17:49.315128] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8727 (0.8727)  time: 0.2252  data: 0.1454  max mem: 10917
[13:17:50.126808] Test:  [10/57]  eta: 0:00:04  loss: 0.8972 (0.9144)  time: 0.0942  data: 0.0133  max mem: 10917
[13:17:50.943623] Test:  [20/57]  eta: 0:00:03  loss: 0.9031 (0.9032)  time: 0.0814  data: 0.0001  max mem: 10917
[13:17:51.763945] Test:  [30/57]  eta: 0:00:02  loss: 0.7912 (0.8608)  time: 0.0818  data: 0.0001  max mem: 10917
[13:17:52.587540] Test:  [40/57]  eta: 0:00:01  loss: 0.7785 (0.8381)  time: 0.0821  data: 0.0001  max mem: 10917
[13:17:53.415331] Test:  [50/57]  eta: 0:00:00  loss: 0.7651 (0.8298)  time: 0.0825  data: 0.0001  max mem: 10917
[13:17:53.864791] Test:  [56/57]  eta: 0:00:00  loss: 0.8030 (0.8369)  time: 0.0803  data: 0.0001  max mem: 10917
[13:17:53.921149] Test: Total time: 0:00:04 (0.0848 s / it)
[13:17:55.729720] Dice score of the network on the train images: 0.825278, val images: 0.810390
[13:17:55.733493] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:17:56.129647] Epoch: [39]  [  0/345]  eta: 0:02:16  lr: 0.000037  loss: 0.7567 (0.7567)  time: 0.3952  data: 0.1422  max mem: 10917
[13:18:01.111380] Epoch: [39]  [ 20/345]  eta: 0:01:23  lr: 0.000037  loss: 0.7465 (0.7503)  time: 0.2490  data: 0.0000  max mem: 10917
[13:18:06.095307] Epoch: [39]  [ 40/345]  eta: 0:01:17  lr: 0.000036  loss: 0.7420 (0.7473)  time: 0.2492  data: 0.0001  max mem: 10917
[13:18:11.085207] Epoch: [39]  [ 60/345]  eta: 0:01:11  lr: 0.000036  loss: 0.7430 (0.7460)  time: 0.2495  data: 0.0000  max mem: 10917
[13:18:16.157414] Epoch: [39]  [ 80/345]  eta: 0:01:06  lr: 0.000036  loss: 0.7448 (0.7457)  time: 0.2536  data: 0.0000  max mem: 10917
[13:18:21.170555] Epoch: [39]  [100/345]  eta: 0:01:01  lr: 0.000035  loss: 0.7547 (0.7484)  time: 0.2506  data: 0.0001  max mem: 10917
[13:18:26.190444] Epoch: [39]  [120/345]  eta: 0:00:56  lr: 0.000035  loss: 0.7515 (0.7493)  time: 0.2510  data: 0.0001  max mem: 10917
[13:18:31.216366] Epoch: [39]  [140/345]  eta: 0:00:51  lr: 0.000035  loss: 0.7472 (0.7493)  time: 0.2513  data: 0.0000  max mem: 10917
[13:18:36.242778] Epoch: [39]  [160/345]  eta: 0:00:46  lr: 0.000034  loss: 0.7478 (0.7494)  time: 0.2513  data: 0.0000  max mem: 10917

[13:18:41.270371] Epoch: [39]  [180/345]  eta: 0:00:41  lr: 0.000034  loss: 0.7491 (0.7495)  time: 0.2513  data: 0.0000  max mem: 10917
[13:18:46.295641] Epoch: [39]  [200/345]  eta: 0:00:36  lr: 0.000034  loss: 0.7514 (0.7495)  time: 0.2512  data: 0.0000  max mem: 10917
[13:18:51.324429] Epoch: [39]  [220/345]  eta: 0:00:31  lr: 0.000033  loss: 0.7432 (0.7492)  time: 0.2514  data: 0.0000  max mem: 10917
[13:18:56.357188] Epoch: [39]  [240/345]  eta: 0:00:26  lr: 0.000033  loss: 0.7497 (0.7494)  time: 0.2516  data: 0.0000  max mem: 10917
[13:19:01.388705] Epoch: [39]  [260/345]  eta: 0:00:21  lr: 0.000033  loss: 0.7449 (0.7489)  time: 0.2515  data: 0.0000  max mem: 10917
[13:19:06.420084] Epoch: [39]  [280/345]  eta: 0:00:16  lr: 0.000032  loss: 0.7468 (0.7486)  time: 0.2515  data: 0.0000  max mem: 10917
[13:19:11.444290] Epoch: [39]  [300/345]  eta: 0:00:11  lr: 0.000032  loss: 0.7434 (0.7485)  time: 0.2512  data: 0.0001  max mem: 10917
[13:19:16.465532] Epoch: [39]  [320/345]  eta: 0:00:06  lr: 0.000032  loss: 0.7463 (0.7484)  time: 0.2510  data: 0.0001  max mem: 10917
[13:19:21.491911] Epoch: [39]  [340/345]  eta: 0:00:01  lr: 0.000031  loss: 0.7502 (0.7484)  time: 0.2513  data: 0.0001  max mem: 10917
[13:19:22.499364] Epoch: [39]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 0.7461 (0.7483)  time: 0.2514  data: 0.0001  max mem: 10917
[13:19:22.560901] Epoch: [39] Total time: 0:01:26 (0.2517 s / it)
[13:19:22.561395] Averaged stats: lr: 0.000031  loss: 0.7461 (0.7483)
[13:19:22.801663] Test:  [  0/345]  eta: 0:01:21  loss: 0.7303 (0.7303)  time: 0.2374  data: 0.1576  max mem: 10917
[13:19:23.686466] Test:  [ 10/345]  eta: 0:00:34  loss: 0.7280 (0.7248)  time: 0.1019  data: 0.0204  max mem: 10917
[13:19:24.536842] Test:  [ 20/345]  eta: 0:00:30  loss: 0.7216 (0.7227)  time: 0.0867  data: 0.0048  max mem: 10917
[13:19:25.363935] Test:  [ 30/345]  eta: 0:00:28  loss: 0.7115 (0.7209)  time: 0.0838  data: 0.0015  max mem: 10917
[13:19:26.194774] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7097 (0.7193)  time: 0.0828  data: 0.0001  max mem: 10917
[13:19:27.029021] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7136 (0.7186)  time: 0.0832  data: 0.0001  max mem: 10917
[13:19:27.866899] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7114 (0.7183)  time: 0.0836  data: 0.0001  max mem: 10917
[13:19:28.707946] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7108 (0.7179)  time: 0.0839  data: 0.0001  max mem: 10917
[13:19:29.552567] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7167 (0.7181)  time: 0.0842  data: 0.0001  max mem: 10917
[13:19:30.400920] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7186 (0.7181)  time: 0.0846  data: 0.0001  max mem: 10917
[13:19:31.253461] Test:  [100/345]  eta: 0:00:21  loss: 0.7157 (0.7177)  time: 0.0850  data: 0.0001  max mem: 10917
[13:19:32.108722] Test:  [110/345]  eta: 0:00:20  loss: 0.7049 (0.7166)  time: 0.0853  data: 0.0001  max mem: 10917
[13:19:32.968868] Test:  [120/345]  eta: 0:00:19  loss: 0.7048 (0.7159)  time: 0.0857  data: 0.0001  max mem: 10917
[13:19:33.832271] Test:  [130/345]  eta: 0:00:18  loss: 0.7082 (0.7154)  time: 0.0861  data: 0.0001  max mem: 10917
[13:19:34.697815] Test:  [140/345]  eta: 0:00:17  loss: 0.7112 (0.7156)  time: 0.0864  data: 0.0001  max mem: 10917
[13:19:35.567594] Test:  [150/345]  eta: 0:00:16  loss: 0.7206 (0.7159)  time: 0.0867  data: 0.0001  max mem: 10917
[13:19:36.440222] Test:  [160/345]  eta: 0:00:15  loss: 0.7153 (0.7158)  time: 0.0871  data: 0.0001  max mem: 10917
[13:19:37.316573] Test:  [170/345]  eta: 0:00:15  loss: 0.7115 (0.7155)  time: 0.0874  data: 0.0001  max mem: 10917
[13:19:38.197527] Test:  [180/345]  eta: 0:00:14  loss: 0.7150 (0.7157)  time: 0.0878  data: 0.0001  max mem: 10917
[13:19:39.080587] Test:  [190/345]  eta: 0:00:13  loss: 0.7128 (0.7154)  time: 0.0882  data: 0.0001  max mem: 10917
[13:19:39.966970] Test:  [200/345]  eta: 0:00:12  loss: 0.7106 (0.7153)  time: 0.0884  data: 0.0001  max mem: 10917
[13:19:40.857318] Test:  [210/345]  eta: 0:00:11  loss: 0.7117 (0.7150)  time: 0.0888  data: 0.0001  max mem: 10917
[13:19:41.750914] Test:  [220/345]  eta: 0:00:10  loss: 0.7117 (0.7149)  time: 0.0891  data: 0.0001  max mem: 10917
[13:19:42.648740] Test:  [230/345]  eta: 0:00:09  loss: 0.7133 (0.7147)  time: 0.0895  data: 0.0001  max mem: 10917
[13:19:43.549700] Test:  [240/345]  eta: 0:00:09  loss: 0.7156 (0.7149)  time: 0.0899  data: 0.0001  max mem: 10917
[13:19:44.453565] Test:  [250/345]  eta: 0:00:08  loss: 0.7153 (0.7146)  time: 0.0902  data: 0.0001  max mem: 10917
[13:19:45.361656] Test:  [260/345]  eta: 0:00:07  loss: 0.7059 (0.7143)  time: 0.0906  data: 0.0001  max mem: 10917
[13:19:46.274108] Test:  [270/345]  eta: 0:00:06  loss: 0.7107 (0.7143)  time: 0.0910  data: 0.0001  max mem: 10917
[13:19:47.188988] Test:  [280/345]  eta: 0:00:05  loss: 0.7136 (0.7143)  time: 0.0913  data: 0.0001  max mem: 10917
[13:19:48.108418] Test:  [290/345]  eta: 0:00:04  loss: 0.7136 (0.7143)  time: 0.0917  data: 0.0001  max mem: 10917
[13:19:49.030552] Test:  [300/345]  eta: 0:00:03  loss: 0.7134 (0.7143)  time: 0.0920  data: 0.0001  max mem: 10917
[13:19:49.956470] Test:  [310/345]  eta: 0:00:03  loss: 0.7150 (0.7143)  time: 0.0924  data: 0.0001  max mem: 10917
[13:19:50.886074] Test:  [320/345]  eta: 0:00:02  loss: 0.7180 (0.7146)  time: 0.0927  data: 0.0001  max mem: 10917
[13:19:51.818738] Test:  [330/345]  eta: 0:00:01  loss: 0.7174 (0.7148)  time: 0.0931  data: 0.0001  max mem: 10917
[13:19:52.755521] Test:  [340/345]  eta: 0:00:00  loss: 0.7152 (0.7147)  time: 0.0934  data: 0.0001  max mem: 10917
[13:19:53.131809] Test:  [344/345]  eta: 0:00:00  loss: 0.7131 (0.7147)  time: 0.0936  data: 0.0001  max mem: 10917
[13:19:53.190828] Test: Total time: 0:00:30 (0.0888 s / it)
[13:20:03.829746] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8817 (0.8817)  time: 0.2244  data: 0.1446  max mem: 10917
[13:20:04.643400] Test:  [10/57]  eta: 0:00:04  loss: 0.9026 (0.9163)  time: 0.0943  data: 0.0132  max mem: 10917
[13:20:05.460592] Test:  [20/57]  eta: 0:00:03  loss: 0.9034 (0.8990)  time: 0.0815  data: 0.0001  max mem: 10917
[13:20:06.281937] Test:  [30/57]  eta: 0:00:02  loss: 0.7898 (0.8570)  time: 0.0819  data: 0.0001  max mem: 10917
[13:20:07.107572] Test:  [40/57]  eta: 0:00:01  loss: 0.7753 (0.8346)  time: 0.0823  data: 0.0001  max mem: 10917
[13:20:07.935621] Test:  [50/57]  eta: 0:00:00  loss: 0.7634 (0.8264)  time: 0.0826  data: 0.0001  max mem: 10917
[13:20:08.386238] Test:  [56/57]  eta: 0:00:00  loss: 0.7978 (0.8327)  time: 0.0804  data: 0.0001  max mem: 10917
[13:20:08.442320] Test: Total time: 0:00:04 (0.0849 s / it)
[13:20:10.294869] Dice score of the network on the train images: 0.822590, val images: 0.814436
[13:20:10.298317] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:20:10.695704] Epoch: [40]  [  0/345]  eta: 0:02:16  lr: 0.000031  loss: 0.7390 (0.7390)  time: 0.3964  data: 0.1449  max mem: 10917
[13:20:15.695090] Epoch: [40]  [ 20/345]  eta: 0:01:23  lr: 0.000031  loss: 0.7420 (0.7435)  time: 0.2499  data: 0.0001  max mem: 10917
[13:20:20.696225] Epoch: [40]  [ 40/345]  eta: 0:01:17  lr: 0.000031  loss: 0.7429 (0.7432)  time: 0.2500  data: 0.0000  max mem: 10917
[13:20:25.702948] Epoch: [40]  [ 60/345]  eta: 0:01:11  lr: 0.000030  loss: 0.7414 (0.7429)  time: 0.2503  data: 0.0001  max mem: 10917
[13:20:30.713735] Epoch: [40]  [ 80/345]  eta: 0:01:06  lr: 0.000030  loss: 0.7397 (0.7428)  time: 0.2505  data: 0.0001  max mem: 10917
[13:20:35.730329] Epoch: [40]  [100/345]  eta: 0:01:01  lr: 0.000030  loss: 0.7414 (0.7436)  time: 0.2508  data: 0.0001  max mem: 10917
[13:20:40.751777] Epoch: [40]  [120/345]  eta: 0:00:56  lr: 0.000029  loss: 0.7380 (0.7432)  time: 0.2510  data: 0.0001  max mem: 10917
[13:20:45.772870] Epoch: [40]  [140/345]  eta: 0:00:51  lr: 0.000029  loss: 0.7406 (0.7432)  time: 0.2510  data: 0.0001  max mem: 10917
[13:20:50.804954] Epoch: [40]  [160/345]  eta: 0:00:46  lr: 0.000029  loss: 0.7394 (0.7434)  time: 0.2516  data: 0.0001  max mem: 10917
[13:20:55.821009] Epoch: [40]  [180/345]  eta: 0:00:41  lr: 0.000028  loss: 0.7407 (0.7431)  time: 0.2508  data: 0.0001  max mem: 10917
[13:21:00.834663] Epoch: [40]  [200/345]  eta: 0:00:36  lr: 0.000028  loss: 0.7427 (0.7434)  time: 0.2506  data: 0.0001  max mem: 10917
[13:21:05.851631] Epoch: [40]  [220/345]  eta: 0:00:31  lr: 0.000028  loss: 0.7406 (0.7438)  time: 0.2508  data: 0.0001  max mem: 10917
[13:21:10.869417] Epoch: [40]  [240/345]  eta: 0:00:26  lr: 0.000027  loss: 0.7449 (0.7441)  time: 0.2509  data: 0.0001  max mem: 10917
[13:21:15.889900] Epoch: [40]  [260/345]  eta: 0:00:21  lr: 0.000027  loss: 0.7358 (0.7438)  time: 0.2510  data: 0.0001  max mem: 10917
[13:21:20.909698] Epoch: [40]  [280/345]  eta: 0:00:16  lr: 0.000027  loss: 0.7479 (0.7440)  time: 0.2510  data: 0.0001  max mem: 10917
[13:21:25.941917] Epoch: [40]  [300/345]  eta: 0:00:11  lr: 0.000026  loss: 0.7409 (0.7438)  time: 0.2516  data: 0.0001  max mem: 10917
[13:21:30.983542] Epoch: [40]  [320/345]  eta: 0:00:06  lr: 0.000026  loss: 0.7477 (0.7440)  time: 0.2520  data: 0.0001  max mem: 10917
[13:21:36.026945] Epoch: [40]  [340/345]  eta: 0:00:01  lr: 0.000026  loss: 0.7414 (0.7438)  time: 0.2521  data: 0.0001  max mem: 10917
[13:21:37.036694] Epoch: [40]  [344/345]  eta: 0:00:00  lr: 0.000026  loss: 0.7436 (0.7441)  time: 0.2521  data: 0.0001  max mem: 10917
[13:21:37.094924] Epoch: [40] Total time: 0:01:26 (0.2516 s / it)
[13:21:37.095177] Averaged stats: lr: 0.000026  loss: 0.7436 (0.7441)
[13:21:37.335958] Test:  [  0/345]  eta: 0:01:21  loss: 0.6991 (0.6991)  time: 0.2372  data: 0.1574  max mem: 10917
[13:21:38.200363] Test:  [ 10/345]  eta: 0:00:33  loss: 0.7105 (0.7109)  time: 0.1001  data: 0.0184  max mem: 10917
[13:21:39.024434] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7113 (0.7114)  time: 0.0843  data: 0.0023  max mem: 10917
[13:21:39.851628] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7098 (0.7096)  time: 0.0825  data: 0.0001  max mem: 10917
[13:21:40.682444] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7108 (0.7112)  time: 0.0829  data: 0.0001  max mem: 10917
[13:21:41.516761] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7122 (0.7108)  time: 0.0832  data: 0.0001  max mem: 10917
[13:21:42.354791] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7117 (0.7113)  time: 0.0836  data: 0.0001  max mem: 10917
[13:21:43.196816] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7065 (0.7101)  time: 0.0840  data: 0.0001  max mem: 10917
[13:21:44.042178] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7046 (0.7102)  time: 0.0843  data: 0.0001  max mem: 10917
[13:21:44.891476] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7069 (0.7102)  time: 0.0847  data: 0.0001  max mem: 10917
[13:21:45.744279] Test:  [100/345]  eta: 0:00:20  loss: 0.7108 (0.7106)  time: 0.0851  data: 0.0001  max mem: 10917
[13:21:46.599732] Test:  [110/345]  eta: 0:00:20  loss: 0.7093 (0.7106)  time: 0.0854  data: 0.0001  max mem: 10917
[13:21:47.459036] Test:  [120/345]  eta: 0:00:19  loss: 0.7095 (0.7109)  time: 0.0857  data: 0.0001  max mem: 10917
[13:21:48.320911] Test:  [130/345]  eta: 0:00:18  loss: 0.7103 (0.7111)  time: 0.0860  data: 0.0001  max mem: 10917
[13:21:49.186945] Test:  [140/345]  eta: 0:00:17  loss: 0.7094 (0.7110)  time: 0.0863  data: 0.0001  max mem: 10917
[13:21:50.056697] Test:  [150/345]  eta: 0:00:16  loss: 0.7094 (0.7112)  time: 0.0867  data: 0.0001  max mem: 10917
[13:21:50.930589] Test:  [160/345]  eta: 0:00:15  loss: 0.7155 (0.7116)  time: 0.0871  data: 0.0001  max mem: 10917
[13:21:51.807537] Test:  [170/345]  eta: 0:00:15  loss: 0.7156 (0.7115)  time: 0.0875  data: 0.0001  max mem: 10917
[13:21:52.687741] Test:  [180/345]  eta: 0:00:14  loss: 0.7100 (0.7114)  time: 0.0878  data: 0.0001  max mem: 10917
[13:21:53.570983] Test:  [190/345]  eta: 0:00:13  loss: 0.7103 (0.7115)  time: 0.0881  data: 0.0001  max mem: 10917
[13:21:54.458942] Test:  [200/345]  eta: 0:00:12  loss: 0.7104 (0.7115)  time: 0.0885  data: 0.0001  max mem: 10917
[13:21:55.349764] Test:  [210/345]  eta: 0:00:11  loss: 0.7042 (0.7110)  time: 0.0889  data: 0.0001  max mem: 10917
[13:21:56.244166] Test:  [220/345]  eta: 0:00:10  loss: 0.7097 (0.7115)  time: 0.0892  data: 0.0001  max mem: 10917
[13:21:57.142595] Test:  [230/345]  eta: 0:00:09  loss: 0.7146 (0.7116)  time: 0.0896  data: 0.0001  max mem: 10917
[13:21:58.045251] Test:  [240/345]  eta: 0:00:09  loss: 0.7126 (0.7118)  time: 0.0900  data: 0.0001  max mem: 10917
[13:21:58.950057] Test:  [250/345]  eta: 0:00:08  loss: 0.7090 (0.7117)  time: 0.0903  data: 0.0001  max mem: 10917
[13:21:59.858055] Test:  [260/345]  eta: 0:00:07  loss: 0.7116 (0.7118)  time: 0.0906  data: 0.0001  max mem: 10917
[13:22:00.770241] Test:  [270/345]  eta: 0:00:06  loss: 0.7094 (0.7118)  time: 0.0910  data: 0.0001  max mem: 10917
[13:22:01.686046] Test:  [280/345]  eta: 0:00:05  loss: 0.7098 (0.7117)  time: 0.0914  data: 0.0001  max mem: 10917
[13:22:02.604572] Test:  [290/345]  eta: 0:00:04  loss: 0.7117 (0.7119)  time: 0.0917  data: 0.0001  max mem: 10917
[13:22:03.526661] Test:  [300/345]  eta: 0:00:03  loss: 0.7124 (0.7121)  time: 0.0920  data: 0.0001  max mem: 10917
[13:22:04.451799] Test:  [310/345]  eta: 0:00:03  loss: 0.7108 (0.7118)  time: 0.0923  data: 0.0001  max mem: 10917
[13:22:05.380473] Test:  [320/345]  eta: 0:00:02  loss: 0.7108 (0.7119)  time: 0.0926  data: 0.0001  max mem: 10917
[13:22:06.313185] Test:  [330/345]  eta: 0:00:01  loss: 0.7116 (0.7119)  time: 0.0930  data: 0.0001  max mem: 10917
[13:22:07.249038] Test:  [340/345]  eta: 0:00:00  loss: 0.7116 (0.7120)  time: 0.0934  data: 0.0001  max mem: 10917
[13:22:07.624450] Test:  [344/345]  eta: 0:00:00  loss: 0.7116 (0.7121)  time: 0.0935  data: 0.0001  max mem: 10917
[13:22:07.682456] Test: Total time: 0:00:30 (0.0887 s / it)
[13:22:18.391448] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8824 (0.8824)  time: 0.2224  data: 0.1425  max mem: 10917
[13:22:19.206392] Test:  [10/57]  eta: 0:00:04  loss: 0.9087 (0.9216)  time: 0.0942  data: 0.0130  max mem: 10917
[13:22:20.023173] Test:  [20/57]  eta: 0:00:03  loss: 0.9113 (0.9081)  time: 0.0815  data: 0.0001  max mem: 10917
[13:22:20.844686] Test:  [30/57]  eta: 0:00:02  loss: 0.7962 (0.8647)  time: 0.0819  data: 0.0001  max mem: 10917
[13:22:21.669133] Test:  [40/57]  eta: 0:00:01  loss: 0.7833 (0.8420)  time: 0.0822  data: 0.0001  max mem: 10917
[13:22:22.497076] Test:  [50/57]  eta: 0:00:00  loss: 0.7693 (0.8344)  time: 0.0826  data: 0.0001  max mem: 10917
[13:22:22.947202] Test:  [56/57]  eta: 0:00:00  loss: 0.8024 (0.8410)  time: 0.0804  data: 0.0001  max mem: 10917
[13:22:23.003380] Test: Total time: 0:00:04 (0.0848 s / it)
[13:22:24.826865] Dice score of the network on the train images: 0.828840, val images: 0.808153
[13:22:24.830473] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:22:25.229960] Epoch: [41]  [  0/345]  eta: 0:02:17  lr: 0.000026  loss: 0.7344 (0.7344)  time: 0.3988  data: 0.1483  max mem: 10917
[13:22:30.216306] Epoch: [41]  [ 20/345]  eta: 0:01:23  lr: 0.000025  loss: 0.7444 (0.7417)  time: 0.2493  data: 0.0001  max mem: 10917
[13:22:35.203283] Epoch: [41]  [ 40/345]  eta: 0:01:17  lr: 0.000025  loss: 0.7470 (0.7450)  time: 0.2493  data: 0.0000  max mem: 10917
[13:22:40.194794] Epoch: [41]  [ 60/345]  eta: 0:01:11  lr: 0.000025  loss: 0.7399 (0.7445)  time: 0.2495  data: 0.0000  max mem: 10917
[13:22:45.185660] Epoch: [41]  [ 80/345]  eta: 0:01:06  lr: 0.000025  loss: 0.7320 (0.7423)  time: 0.2495  data: 0.0000  max mem: 10917
[13:22:50.185034] Epoch: [41]  [100/345]  eta: 0:01:01  lr: 0.000024  loss: 0.7373 (0.7417)  time: 0.2499  data: 0.0000  max mem: 10917
[13:22:55.191393] Epoch: [41]  [120/345]  eta: 0:00:56  lr: 0.000024  loss: 0.7383 (0.7420)  time: 0.2503  data: 0.0001  max mem: 10917
[13:23:00.201558] Epoch: [41]  [140/345]  eta: 0:00:51  lr: 0.000024  loss: 0.7421 (0.7421)  time: 0.2505  data: 0.0000  max mem: 10917
[13:23:05.210578] Epoch: [41]  [160/345]  eta: 0:00:46  lr: 0.000023  loss: 0.7416 (0.7425)  time: 0.2504  data: 0.0001  max mem: 10917
[13:23:10.219946] Epoch: [41]  [180/345]  eta: 0:00:41  lr: 0.000023  loss: 0.7419 (0.7427)  time: 0.2504  data: 0.0001  max mem: 10917
[13:23:15.230999] Epoch: [41]  [200/345]  eta: 0:00:36  lr: 0.000023  loss: 0.7387 (0.7423)  time: 0.2505  data: 0.0001  max mem: 10917
[13:23:20.249176] Epoch: [41]  [220/345]  eta: 0:00:31  lr: 0.000022  loss: 0.7408 (0.7423)  time: 0.2509  data: 0.0001  max mem: 10917
[13:23:25.265865] Epoch: [41]  [240/345]  eta: 0:00:26  lr: 0.000022  loss: 0.7389 (0.7421)  time: 0.2508  data: 0.0001  max mem: 10917
[13:23:30.285338] Epoch: [41]  [260/345]  eta: 0:00:21  lr: 0.000022  loss: 0.7383 (0.7421)  time: 0.2509  data: 0.0000  max mem: 10917
[13:23:35.306899] Epoch: [41]  [280/345]  eta: 0:00:16  lr: 0.000022  loss: 0.7476 (0.7423)  time: 0.2510  data: 0.0000  max mem: 10917
[13:23:40.324167] Epoch: [41]  [300/345]  eta: 0:00:11  lr: 0.000021  loss: 0.7473 (0.7426)  time: 0.2508  data: 0.0001  max mem: 10917
[13:23:45.350459] Epoch: [41]  [320/345]  eta: 0:00:06  lr: 0.000021  loss: 0.7446 (0.7428)  time: 0.2513  data: 0.0001  max mem: 10917
[13:23:50.374969] Epoch: [41]  [340/345]  eta: 0:00:01  lr: 0.000021  loss: 0.7416 (0.7428)  time: 0.2512  data: 0.0000  max mem: 10917
[13:23:51.381753] Epoch: [41]  [344/345]  eta: 0:00:00  lr: 0.000021  loss: 0.7416 (0.7427)  time: 0.2512  data: 0.0001  max mem: 10917
[13:23:51.440940] Epoch: [41] Total time: 0:01:26 (0.2510 s / it)
[13:23:51.441434] Averaged stats: lr: 0.000021  loss: 0.7416 (0.7427)
[13:23:51.688765] Test:  [  0/345]  eta: 0:01:24  loss: 0.7248 (0.7248)  time: 0.2443  data: 0.1641  max mem: 10917
[13:23:52.529238] Test:  [ 10/345]  eta: 0:00:33  loss: 0.7193 (0.7144)  time: 0.0985  data: 0.0167  max mem: 10917
[13:23:53.353354] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7173 (0.7152)  time: 0.0831  data: 0.0010  max mem: 10917
[13:23:54.181706] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7127 (0.7126)  time: 0.0826  data: 0.0001  max mem: 10917
[13:23:55.013065] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7080 (0.7114)  time: 0.0829  data: 0.0001  max mem: 10917
[13:23:55.847776] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7063 (0.7109)  time: 0.0833  data: 0.0001  max mem: 10917
[13:23:56.686371] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7115 (0.7113)  time: 0.0836  data: 0.0001  max mem: 10917
[13:23:57.527878] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7119 (0.7106)  time: 0.0840  data: 0.0001  max mem: 10917
[13:23:58.373595] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7137 (0.7120)  time: 0.0843  data: 0.0001  max mem: 10917
[13:23:59.222537] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7154 (0.7119)  time: 0.0847  data: 0.0001  max mem: 10917
[13:24:00.074535] Test:  [100/345]  eta: 0:00:20  loss: 0.7033 (0.7110)  time: 0.0850  data: 0.0001  max mem: 10917
[13:24:00.930318] Test:  [110/345]  eta: 0:00:20  loss: 0.7044 (0.7118)  time: 0.0853  data: 0.0001  max mem: 10917
[13:24:01.789378] Test:  [120/345]  eta: 0:00:19  loss: 0.7109 (0.7115)  time: 0.0857  data: 0.0001  max mem: 10917
[13:24:02.651571] Test:  [130/345]  eta: 0:00:18  loss: 0.7068 (0.7113)  time: 0.0860  data: 0.0001  max mem: 10917
[13:24:03.519587] Test:  [140/345]  eta: 0:00:17  loss: 0.7056 (0.7112)  time: 0.0865  data: 0.0001  max mem: 10917
[13:24:04.389290] Test:  [150/345]  eta: 0:00:16  loss: 0.7113 (0.7115)  time: 0.0868  data: 0.0001  max mem: 10917
[13:24:05.262609] Test:  [160/345]  eta: 0:00:15  loss: 0.7138 (0.7117)  time: 0.0871  data: 0.0001  max mem: 10917
[13:24:06.139011] Test:  [170/345]  eta: 0:00:15  loss: 0.7088 (0.7115)  time: 0.0874  data: 0.0001  max mem: 10917
[13:24:07.019684] Test:  [180/345]  eta: 0:00:14  loss: 0.7088 (0.7116)  time: 0.0878  data: 0.0001  max mem: 10917
[13:24:07.902737] Test:  [190/345]  eta: 0:00:13  loss: 0.7085 (0.7117)  time: 0.0881  data: 0.0001  max mem: 10917
[13:24:08.790280] Test:  [200/345]  eta: 0:00:12  loss: 0.7014 (0.7114)  time: 0.0885  data: 0.0001  max mem: 10917
[13:24:09.681960] Test:  [210/345]  eta: 0:00:11  loss: 0.7015 (0.7115)  time: 0.0889  data: 0.0001  max mem: 10917
[13:24:10.576878] Test:  [220/345]  eta: 0:00:10  loss: 0.7083 (0.7112)  time: 0.0893  data: 0.0001  max mem: 10917
[13:24:11.474544] Test:  [230/345]  eta: 0:00:09  loss: 0.7083 (0.7113)  time: 0.0896  data: 0.0001  max mem: 10917
[13:24:12.375650] Test:  [240/345]  eta: 0:00:09  loss: 0.7113 (0.7114)  time: 0.0899  data: 0.0001  max mem: 10917
[13:24:13.279858] Test:  [250/345]  eta: 0:00:08  loss: 0.7070 (0.7114)  time: 0.0902  data: 0.0001  max mem: 10917
[13:24:14.188022] Test:  [260/345]  eta: 0:00:07  loss: 0.7129 (0.7115)  time: 0.0906  data: 0.0001  max mem: 10917
[13:24:15.100160] Test:  [270/345]  eta: 0:00:06  loss: 0.7129 (0.7116)  time: 0.0910  data: 0.0001  max mem: 10917
[13:24:16.015606] Test:  [280/345]  eta: 0:00:05  loss: 0.7082 (0.7113)  time: 0.0913  data: 0.0001  max mem: 10917
[13:24:16.934847] Test:  [290/345]  eta: 0:00:04  loss: 0.7082 (0.7115)  time: 0.0917  data: 0.0001  max mem: 10917
[13:24:17.857433] Test:  [300/345]  eta: 0:00:03  loss: 0.7156 (0.7114)  time: 0.0920  data: 0.0001  max mem: 10917
[13:24:18.783239] Test:  [310/345]  eta: 0:00:03  loss: 0.7063 (0.7114)  time: 0.0924  data: 0.0001  max mem: 10917
[13:24:19.712274] Test:  [320/345]  eta: 0:00:02  loss: 0.7062 (0.7112)  time: 0.0927  data: 0.0001  max mem: 10917
[13:24:20.644621] Test:  [330/345]  eta: 0:00:01  loss: 0.7074 (0.7113)  time: 0.0930  data: 0.0001  max mem: 10917
[13:24:21.581530] Test:  [340/345]  eta: 0:00:00  loss: 0.7053 (0.7114)  time: 0.0934  data: 0.0001  max mem: 10917
[13:24:21.957487] Test:  [344/345]  eta: 0:00:00  loss: 0.7044 (0.7114)  time: 0.0936  data: 0.0001  max mem: 10917
[13:24:22.014720] Test: Total time: 0:00:30 (0.0886 s / it)
[13:24:32.734848] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8803 (0.8803)  time: 0.2226  data: 0.1425  max mem: 10917
[13:24:33.549443] Test:  [10/57]  eta: 0:00:04  loss: 0.9043 (0.9233)  time: 0.0942  data: 0.0130  max mem: 10917
[13:24:34.366240] Test:  [20/57]  eta: 0:00:03  loss: 0.9137 (0.9066)  time: 0.0815  data: 0.0001  max mem: 10917
[13:24:35.186513] Test:  [30/57]  eta: 0:00:02  loss: 0.7996 (0.8644)  time: 0.0818  data: 0.0001  max mem: 10917
[13:24:36.010684] Test:  [40/57]  eta: 0:00:01  loss: 0.7785 (0.8420)  time: 0.0822  data: 0.0001  max mem: 10917
[13:24:36.839377] Test:  [50/57]  eta: 0:00:00  loss: 0.7702 (0.8341)  time: 0.0826  data: 0.0001  max mem: 10917
[13:24:37.289576] Test:  [56/57]  eta: 0:00:00  loss: 0.8036 (0.8403)  time: 0.0804  data: 0.0001  max mem: 10917
[13:24:37.348148] Test: Total time: 0:00:04 (0.0848 s / it)
[13:24:39.129856] Dice score of the network on the train images: 0.831364, val images: 0.808824
[13:24:39.133714] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:24:39.536958] Epoch: [42]  [  0/345]  eta: 0:02:18  lr: 0.000021  loss: 0.7306 (0.7306)  time: 0.4022  data: 0.1495  max mem: 10917
[13:24:44.535598] Epoch: [42]  [ 20/345]  eta: 0:01:23  lr: 0.000020  loss: 0.7403 (0.7392)  time: 0.2499  data: 0.0001  max mem: 10917
[13:24:49.540205] Epoch: [42]  [ 40/345]  eta: 0:01:17  lr: 0.000020  loss: 0.7377 (0.7400)  time: 0.2502  data: 0.0001  max mem: 10917
[13:24:54.549026] Epoch: [42]  [ 60/345]  eta: 0:01:12  lr: 0.000020  loss: 0.7366 (0.7398)  time: 0.2504  data: 0.0001  max mem: 10917
[13:24:59.543219] Epoch: [42]  [ 80/345]  eta: 0:01:06  lr: 0.000020  loss: 0.7428 (0.7408)  time: 0.2497  data: 0.0000  max mem: 10917
[13:25:04.543481] Epoch: [42]  [100/345]  eta: 0:01:01  lr: 0.000019  loss: 0.7417 (0.7413)  time: 0.2500  data: 0.0000  max mem: 10917
[13:25:09.550871] Epoch: [42]  [120/345]  eta: 0:00:56  lr: 0.000019  loss: 0.7347 (0.7412)  time: 0.2503  data: 0.0001  max mem: 10917
[13:25:14.557637] Epoch: [42]  [140/345]  eta: 0:00:51  lr: 0.000019  loss: 0.7396 (0.7409)  time: 0.2503  data: 0.0001  max mem: 10917
[13:25:19.566742] Epoch: [42]  [160/345]  eta: 0:00:46  lr: 0.000018  loss: 0.7438 (0.7415)  time: 0.2504  data: 0.0000  max mem: 10917
[13:25:24.577382] Epoch: [42]  [180/345]  eta: 0:00:41  lr: 0.000018  loss: 0.7346 (0.7410)  time: 0.2505  data: 0.0000  max mem: 10917
[13:25:29.589564] Epoch: [42]  [200/345]  eta: 0:00:36  lr: 0.000018  loss: 0.7369 (0.7409)  time: 0.2506  data: 0.0000  max mem: 10917
[13:25:34.606137] Epoch: [42]  [220/345]  eta: 0:00:31  lr: 0.000018  loss: 0.7411 (0.7411)  time: 0.2508  data: 0.0000  max mem: 10917
[13:25:39.623289] Epoch: [42]  [240/345]  eta: 0:00:26  lr: 0.000017  loss: 0.7430 (0.7414)  time: 0.2508  data: 0.0000  max mem: 10917
[13:25:44.641024] Epoch: [42]  [260/345]  eta: 0:00:21  lr: 0.000017  loss: 0.7412 (0.7412)  time: 0.2509  data: 0.0000  max mem: 10917
[13:25:49.661731] Epoch: [42]  [280/345]  eta: 0:00:16  lr: 0.000017  loss: 0.7443 (0.7416)  time: 0.2510  data: 0.0000  max mem: 10917
[13:25:54.687460] Epoch: [42]  [300/345]  eta: 0:00:11  lr: 0.000017  loss: 0.7408 (0.7417)  time: 0.2513  data: 0.0000  max mem: 10917
[13:25:59.789550] Epoch: [42]  [320/345]  eta: 0:00:06  lr: 0.000016  loss: 0.7353 (0.7414)  time: 0.2551  data: 0.0000  max mem: 10917
[13:26:04.812753] Epoch: [42]  [340/345]  eta: 0:00:01  lr: 0.000016  loss: 0.7357 (0.7412)  time: 0.2511  data: 0.0000  max mem: 10917
[13:26:05.819623] Epoch: [42]  [344/345]  eta: 0:00:00  lr: 0.000016  loss: 0.7363 (0.7413)  time: 0.2512  data: 0.0001  max mem: 10917
[13:26:05.883253] Epoch: [42] Total time: 0:01:26 (0.2514 s / it)
[13:26:05.883717] Averaged stats: lr: 0.000016  loss: 0.7363 (0.7413)
[13:26:06.127096] Test:  [  0/345]  eta: 0:01:23  loss: 0.7257 (0.7257)  time: 0.2407  data: 0.1604  max mem: 10917
[13:26:06.995158] Test:  [ 10/345]  eta: 0:00:33  loss: 0.7093 (0.7122)  time: 0.1007  data: 0.0189  max mem: 10917
[13:26:07.819483] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7060 (0.7081)  time: 0.0845  data: 0.0024  max mem: 10917
[13:26:08.646505] Test:  [ 30/345]  eta: 0:00:28  loss: 0.7047 (0.7094)  time: 0.0825  data: 0.0001  max mem: 10917
[13:26:09.478066] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7126 (0.7111)  time: 0.0829  data: 0.0001  max mem: 10917
[13:26:10.312299] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7127 (0.7116)  time: 0.0832  data: 0.0001  max mem: 10917
[13:26:11.149855] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7128 (0.7117)  time: 0.0835  data: 0.0001  max mem: 10917
[13:26:11.991561] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7162 (0.7116)  time: 0.0839  data: 0.0001  max mem: 10917
[13:26:12.836688] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7097 (0.7110)  time: 0.0843  data: 0.0001  max mem: 10917
[13:26:13.685187] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7097 (0.7111)  time: 0.0846  data: 0.0001  max mem: 10917
[13:26:14.536812] Test:  [100/345]  eta: 0:00:20  loss: 0.7123 (0.7108)  time: 0.0850  data: 0.0001  max mem: 10917
[13:26:15.392613] Test:  [110/345]  eta: 0:00:20  loss: 0.7061 (0.7105)  time: 0.0853  data: 0.0001  max mem: 10917
[13:26:16.251998] Test:  [120/345]  eta: 0:00:19  loss: 0.7061 (0.7103)  time: 0.0857  data: 0.0001  max mem: 10917
[13:26:17.114865] Test:  [130/345]  eta: 0:00:18  loss: 0.7107 (0.7105)  time: 0.0861  data: 0.0001  max mem: 10917
[13:26:17.980864] Test:  [140/345]  eta: 0:00:17  loss: 0.7107 (0.7102)  time: 0.0864  data: 0.0001  max mem: 10917
[13:26:18.850379] Test:  [150/345]  eta: 0:00:16  loss: 0.7073 (0.7102)  time: 0.0867  data: 0.0001  max mem: 10917
[13:26:19.723643] Test:  [160/345]  eta: 0:00:15  loss: 0.7062 (0.7098)  time: 0.0871  data: 0.0001  max mem: 10917
[13:26:20.600517] Test:  [170/345]  eta: 0:00:15  loss: 0.7050 (0.7098)  time: 0.0875  data: 0.0001  max mem: 10917
[13:26:21.481114] Test:  [180/345]  eta: 0:00:14  loss: 0.7105 (0.7097)  time: 0.0878  data: 0.0001  max mem: 10917
[13:26:22.365055] Test:  [190/345]  eta: 0:00:13  loss: 0.7032 (0.7095)  time: 0.0882  data: 0.0001  max mem: 10917
[13:26:23.252392] Test:  [200/345]  eta: 0:00:12  loss: 0.7054 (0.7097)  time: 0.0885  data: 0.0001  max mem: 10917
[13:26:24.144531] Test:  [210/345]  eta: 0:00:11  loss: 0.7107 (0.7101)  time: 0.0889  data: 0.0001  max mem: 10917
[13:26:25.038655] Test:  [220/345]  eta: 0:00:10  loss: 0.7107 (0.7100)  time: 0.0893  data: 0.0001  max mem: 10917
[13:26:25.936524] Test:  [230/345]  eta: 0:00:09  loss: 0.7042 (0.7098)  time: 0.0896  data: 0.0001  max mem: 10917
[13:26:26.839283] Test:  [240/345]  eta: 0:00:09  loss: 0.7069 (0.7098)  time: 0.0900  data: 0.0001  max mem: 10917
[13:26:27.743158] Test:  [250/345]  eta: 0:00:08  loss: 0.7075 (0.7097)  time: 0.0903  data: 0.0001  max mem: 10917
[13:26:28.650857] Test:  [260/345]  eta: 0:00:07  loss: 0.7047 (0.7097)  time: 0.0905  data: 0.0001  max mem: 10917
[13:26:29.563366] Test:  [270/345]  eta: 0:00:06  loss: 0.7053 (0.7096)  time: 0.0910  data: 0.0001  max mem: 10917
[13:26:30.478934] Test:  [280/345]  eta: 0:00:05  loss: 0.7122 (0.7098)  time: 0.0914  data: 0.0001  max mem: 10917
[13:26:31.398289] Test:  [290/345]  eta: 0:00:04  loss: 0.7134 (0.7099)  time: 0.0917  data: 0.0001  max mem: 10917
[13:26:32.320483] Test:  [300/345]  eta: 0:00:03  loss: 0.7072 (0.7098)  time: 0.0920  data: 0.0001  max mem: 10917
[13:26:33.245701] Test:  [310/345]  eta: 0:00:03  loss: 0.7038 (0.7099)  time: 0.0923  data: 0.0001  max mem: 10917
[13:26:34.175930] Test:  [320/345]  eta: 0:00:02  loss: 0.7105 (0.7100)  time: 0.0927  data: 0.0001  max mem: 10917
[13:26:35.108903] Test:  [330/345]  eta: 0:00:01  loss: 0.7105 (0.7100)  time: 0.0931  data: 0.0001  max mem: 10917
[13:26:36.044911] Test:  [340/345]  eta: 0:00:00  loss: 0.7068 (0.7101)  time: 0.0934  data: 0.0001  max mem: 10917
[13:26:36.421346] Test:  [344/345]  eta: 0:00:00  loss: 0.7068 (0.7102)  time: 0.0936  data: 0.0001  max mem: 10917
[13:26:36.480472] Test: Total time: 0:00:30 (0.0887 s / it)
[13:26:47.312298] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8829 (0.8829)  time: 0.2267  data: 0.1465  max mem: 10917
[13:26:48.143185] Test:  [10/57]  eta: 0:00:04  loss: 0.9061 (0.9165)  time: 0.0960  data: 0.0149  max mem: 10917
[13:26:48.960527] Test:  [20/57]  eta: 0:00:03  loss: 0.9061 (0.9017)  time: 0.0823  data: 0.0009  max mem: 10917
[13:26:49.781655] Test:  [30/57]  eta: 0:00:02  loss: 0.7915 (0.8599)  time: 0.0819  data: 0.0001  max mem: 10917
[13:26:50.606178] Test:  [40/57]  eta: 0:00:01  loss: 0.7799 (0.8376)  time: 0.0822  data: 0.0001  max mem: 10917
[13:26:51.433996] Test:  [50/57]  eta: 0:00:00  loss: 0.7680 (0.8304)  time: 0.0826  data: 0.0001  max mem: 10917
[13:26:51.883836] Test:  [56/57]  eta: 0:00:00  loss: 0.8038 (0.8373)  time: 0.0804  data: 0.0001  max mem: 10917
[13:26:51.940794] Test: Total time: 0:00:04 (0.0852 s / it)
[13:26:53.714738] Dice score of the network on the train images: 0.828290, val images: 0.810510
[13:26:53.718294] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:26:54.116600] Epoch: [43]  [  0/345]  eta: 0:02:17  lr: 0.000016  loss: 0.7384 (0.7384)  time: 0.3976  data: 0.1461  max mem: 10917
[13:26:59.098365] Epoch: [43]  [ 20/345]  eta: 0:01:23  lr: 0.000016  loss: 0.7300 (0.7368)  time: 0.2490  data: 0.0001  max mem: 10917
[13:27:04.085300] Epoch: [43]  [ 40/345]  eta: 0:01:17  lr: 0.000016  loss: 0.7424 (0.7380)  time: 0.2493  data: 0.0000  max mem: 10917
[13:27:09.072156] Epoch: [43]  [ 60/345]  eta: 0:01:11  lr: 0.000015  loss: 0.7383 (0.7384)  time: 0.2493  data: 0.0000  max mem: 10917
[13:27:14.072056] Epoch: [43]  [ 80/345]  eta: 0:01:06  lr: 0.000015  loss: 0.7423 (0.7399)  time: 0.2500  data: 0.0000  max mem: 10917
[13:27:19.074920] Epoch: [43]  [100/345]  eta: 0:01:01  lr: 0.000015  loss: 0.7416 (0.7400)  time: 0.2501  data: 0.0000  max mem: 10917
[13:27:24.081546] Epoch: [43]  [120/345]  eta: 0:00:56  lr: 0.000015  loss: 0.7404 (0.7410)  time: 0.2503  data: 0.0000  max mem: 10917
[13:27:29.087023] Epoch: [43]  [140/345]  eta: 0:00:51  lr: 0.000014  loss: 0.7390 (0.7404)  time: 0.2502  data: 0.0000  max mem: 10917
[13:27:34.094559] Epoch: [43]  [160/345]  eta: 0:00:46  lr: 0.000014  loss: 0.7292 (0.7398)  time: 0.2503  data: 0.0000  max mem: 10917
[13:27:39.106657] Epoch: [43]  [180/345]  eta: 0:00:41  lr: 0.000014  loss: 0.7354 (0.7397)  time: 0.2506  data: 0.0000  max mem: 10917
[13:27:44.122282] Epoch: [43]  [200/345]  eta: 0:00:36  lr: 0.000014  loss: 0.7366 (0.7398)  time: 0.2507  data: 0.0000  max mem: 10917
[13:27:49.140088] Epoch: [43]  [220/345]  eta: 0:00:31  lr: 0.000013  loss: 0.7354 (0.7393)  time: 0.2509  data: 0.0000  max mem: 10917
[13:27:54.158758] Epoch: [43]  [240/345]  eta: 0:00:26  lr: 0.000013  loss: 0.7368 (0.7394)  time: 0.2509  data: 0.0000  max mem: 10917
[13:27:59.178198] Epoch: [43]  [260/345]  eta: 0:00:21  lr: 0.000013  loss: 0.7473 (0.7401)  time: 0.2509  data: 0.0000  max mem: 10917
[13:28:04.198105] Epoch: [43]  [280/345]  eta: 0:00:16  lr: 0.000013  loss: 0.7405 (0.7402)  time: 0.2510  data: 0.0000  max mem: 10917
[13:28:09.223475] Epoch: [43]  [300/345]  eta: 0:00:11  lr: 0.000012  loss: 0.7409 (0.7403)  time: 0.2512  data: 0.0000  max mem: 10917
[13:28:14.258489] Epoch: [43]  [320/345]  eta: 0:00:06  lr: 0.000012  loss: 0.7432 (0.7405)  time: 0.2517  data: 0.0001  max mem: 10917
[13:28:19.280993] Epoch: [43]  [340/345]  eta: 0:00:01  lr: 0.000012  loss: 0.7310 (0.7401)  time: 0.2511  data: 0.0000  max mem: 10917
[13:28:20.285383] Epoch: [43]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 0.7331 (0.7402)  time: 0.2510  data: 0.0001  max mem: 10917
[13:28:20.342391] Epoch: [43] Total time: 0:01:26 (0.2511 s / it)
[13:28:20.342753] Averaged stats: lr: 0.000012  loss: 0.7331 (0.7402)
[13:28:20.587465] Test:  [  0/345]  eta: 0:01:23  loss: 0.7061 (0.7061)  time: 0.2421  data: 0.1622  max mem: 10917
[13:28:21.448342] Test:  [ 10/345]  eta: 0:00:33  loss: 0.7095 (0.7103)  time: 0.1002  data: 0.0187  max mem: 10917
[13:28:22.272011] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7072 (0.7072)  time: 0.0841  data: 0.0022  max mem: 10917
[13:28:23.098937] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7046 (0.7072)  time: 0.0825  data: 0.0001  max mem: 10917
[13:28:23.930091] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7082 (0.7079)  time: 0.0829  data: 0.0001  max mem: 10917
[13:28:24.764740] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7044 (0.7082)  time: 0.0832  data: 0.0001  max mem: 10917
[13:28:25.603322] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7067 (0.7089)  time: 0.0836  data: 0.0001  max mem: 10917
[13:28:26.445320] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7079 (0.7082)  time: 0.0840  data: 0.0001  max mem: 10917
[13:28:27.289930] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7079 (0.7088)  time: 0.0843  data: 0.0001  max mem: 10917
[13:28:28.139192] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7086 (0.7092)  time: 0.0846  data: 0.0001  max mem: 10917
[13:28:28.990956] Test:  [100/345]  eta: 0:00:20  loss: 0.7044 (0.7091)  time: 0.0850  data: 0.0001  max mem: 10917
[13:28:29.846357] Test:  [110/345]  eta: 0:00:20  loss: 0.7032 (0.7089)  time: 0.0853  data: 0.0001  max mem: 10917
[13:28:30.705122] Test:  [120/345]  eta: 0:00:19  loss: 0.7034 (0.7086)  time: 0.0857  data: 0.0001  max mem: 10917
[13:28:31.568457] Test:  [130/345]  eta: 0:00:18  loss: 0.7092 (0.7094)  time: 0.0861  data: 0.0001  max mem: 10917
[13:28:32.435296] Test:  [140/345]  eta: 0:00:17  loss: 0.7106 (0.7091)  time: 0.0865  data: 0.0001  max mem: 10917
[13:28:33.304129] Test:  [150/345]  eta: 0:00:16  loss: 0.7133 (0.7100)  time: 0.0867  data: 0.0001  max mem: 10917
[13:28:34.177638] Test:  [160/345]  eta: 0:00:15  loss: 0.7165 (0.7099)  time: 0.0871  data: 0.0001  max mem: 10917
[13:28:35.054905] Test:  [170/345]  eta: 0:00:15  loss: 0.7030 (0.7099)  time: 0.0875  data: 0.0001  max mem: 10917
[13:28:35.936595] Test:  [180/345]  eta: 0:00:14  loss: 0.7041 (0.7099)  time: 0.0879  data: 0.0001  max mem: 10917
[13:28:36.819688] Test:  [190/345]  eta: 0:00:13  loss: 0.7112 (0.7099)  time: 0.0882  data: 0.0001  max mem: 10917
[13:28:37.707113] Test:  [200/345]  eta: 0:00:12  loss: 0.7106 (0.7099)  time: 0.0885  data: 0.0001  max mem: 10917
[13:28:38.599554] Test:  [210/345]  eta: 0:00:11  loss: 0.7061 (0.7100)  time: 0.0889  data: 0.0001  max mem: 10917
[13:28:39.492876] Test:  [220/345]  eta: 0:00:10  loss: 0.7058 (0.7098)  time: 0.0892  data: 0.0001  max mem: 10917
[13:28:40.390928] Test:  [230/345]  eta: 0:00:09  loss: 0.7033 (0.7096)  time: 0.0895  data: 0.0001  max mem: 10917
[13:28:41.292924] Test:  [240/345]  eta: 0:00:09  loss: 0.7082 (0.7097)  time: 0.0900  data: 0.0001  max mem: 10917
[13:28:42.198059] Test:  [250/345]  eta: 0:00:08  loss: 0.7100 (0.7095)  time: 0.0903  data: 0.0001  max mem: 10917
[13:28:43.106407] Test:  [260/345]  eta: 0:00:07  loss: 0.7064 (0.7093)  time: 0.0906  data: 0.0001  max mem: 10917
[13:28:44.018411] Test:  [270/345]  eta: 0:00:06  loss: 0.7039 (0.7092)  time: 0.0910  data: 0.0001  max mem: 10917
[13:28:44.933294] Test:  [280/345]  eta: 0:00:05  loss: 0.7096 (0.7093)  time: 0.0913  data: 0.0001  max mem: 10917
[13:28:45.851759] Test:  [290/345]  eta: 0:00:04  loss: 0.7062 (0.7093)  time: 0.0916  data: 0.0001  max mem: 10917
[13:28:46.774230] Test:  [300/345]  eta: 0:00:03  loss: 0.7034 (0.7092)  time: 0.0920  data: 0.0001  max mem: 10917
[13:28:47.699672] Test:  [310/345]  eta: 0:00:03  loss: 0.7028 (0.7091)  time: 0.0923  data: 0.0001  max mem: 10917
[13:28:48.628939] Test:  [320/345]  eta: 0:00:02  loss: 0.7005 (0.7089)  time: 0.0927  data: 0.0001  max mem: 10917
[13:28:49.561706] Test:  [330/345]  eta: 0:00:01  loss: 0.7005 (0.7088)  time: 0.0931  data: 0.0001  max mem: 10917
[13:28:50.498486] Test:  [340/345]  eta: 0:00:00  loss: 0.7059 (0.7089)  time: 0.0934  data: 0.0001  max mem: 10917
[13:28:50.874638] Test:  [344/345]  eta: 0:00:00  loss: 0.7065 (0.7090)  time: 0.0936  data: 0.0001  max mem: 10917
[13:28:50.932149] Test: Total time: 0:00:30 (0.0887 s / it)
[13:29:01.692672] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8843 (0.8843)  time: 0.2246  data: 0.1448  max mem: 10917
[13:29:02.506619] Test:  [10/57]  eta: 0:00:04  loss: 0.9110 (0.9232)  time: 0.0943  data: 0.0132  max mem: 10917
[13:29:03.323579] Test:  [20/57]  eta: 0:00:03  loss: 0.9110 (0.9078)  time: 0.0815  data: 0.0001  max mem: 10917
[13:29:04.144701] Test:  [30/57]  eta: 0:00:02  loss: 0.7944 (0.8647)  time: 0.0819  data: 0.0001  max mem: 10917
[13:29:04.968854] Test:  [40/57]  eta: 0:00:01  loss: 0.7781 (0.8418)  time: 0.0822  data: 0.0001  max mem: 10917
[13:29:05.797933] Test:  [50/57]  eta: 0:00:00  loss: 0.7704 (0.8344)  time: 0.0826  data: 0.0001  max mem: 10917
[13:29:06.247548] Test:  [56/57]  eta: 0:00:00  loss: 0.8048 (0.8416)  time: 0.0804  data: 0.0001  max mem: 10917
[13:29:06.301067] Test: Total time: 0:00:04 (0.0848 s / it)
[13:29:08.125118] Dice score of the network on the train images: 0.829981, val images: 0.809737
[13:29:08.128568] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:29:08.525465] Epoch: [44]  [  0/345]  eta: 0:02:16  lr: 0.000012  loss: 0.7286 (0.7286)  time: 0.3961  data: 0.1452  max mem: 10917
[13:29:13.509581] Epoch: [44]  [ 20/345]  eta: 0:01:23  lr: 0.000012  loss: 0.7391 (0.7393)  time: 0.2492  data: 0.0001  max mem: 10917
[13:29:18.491474] Epoch: [44]  [ 40/345]  eta: 0:01:17  lr: 0.000011  loss: 0.7426 (0.7412)  time: 0.2491  data: 0.0001  max mem: 10917
[13:29:23.493609] Epoch: [44]  [ 60/345]  eta: 0:01:11  lr: 0.000011  loss: 0.7348 (0.7394)  time: 0.2501  data: 0.0001  max mem: 10917
[13:29:28.505606] Epoch: [44]  [ 80/345]  eta: 0:01:06  lr: 0.000011  loss: 0.7411 (0.7399)  time: 0.2506  data: 0.0001  max mem: 10917
[13:29:33.508608] Epoch: [44]  [100/345]  eta: 0:01:01  lr: 0.000011  loss: 0.7329 (0.7399)  time: 0.2501  data: 0.0000  max mem: 10917
[13:29:38.512012] Epoch: [44]  [120/345]  eta: 0:00:56  lr: 0.000011  loss: 0.7326 (0.7393)  time: 0.2501  data: 0.0000  max mem: 10917
[13:29:43.522093] Epoch: [44]  [140/345]  eta: 0:00:51  lr: 0.000010  loss: 0.7373 (0.7395)  time: 0.2505  data: 0.0000  max mem: 10917
[13:29:48.530513] Epoch: [44]  [160/345]  eta: 0:00:46  lr: 0.000010  loss: 0.7432 (0.7405)  time: 0.2504  data: 0.0000  max mem: 10917
[13:29:53.541973] Epoch: [44]  [180/345]  eta: 0:00:41  lr: 0.000010  loss: 0.7407 (0.7401)  time: 0.2505  data: 0.0000  max mem: 10917
[13:29:58.552907] Epoch: [44]  [200/345]  eta: 0:00:36  lr: 0.000010  loss: 0.7410 (0.7402)  time: 0.2505  data: 0.0000  max mem: 10917
[13:30:03.576052] Epoch: [44]  [220/345]  eta: 0:00:31  lr: 0.000010  loss: 0.7343 (0.7400)  time: 0.2511  data: 0.0000  max mem: 10917
[13:30:08.596201] Epoch: [44]  [240/345]  eta: 0:00:26  lr: 0.000009  loss: 0.7346 (0.7398)  time: 0.2510  data: 0.0000  max mem: 10917
[13:30:13.620345] Epoch: [44]  [260/345]  eta: 0:00:21  lr: 0.000009  loss: 0.7366 (0.7396)  time: 0.2512  data: 0.0000  max mem: 10917

[13:30:18.645021] Epoch: [44]  [280/345]  eta: 0:00:16  lr: 0.000009  loss: 0.7382 (0.7396)  time: 0.2512  data: 0.0000  max mem: 10917
[13:30:23.671857] Epoch: [44]  [300/345]  eta: 0:00:11  lr: 0.000009  loss: 0.7373 (0.7395)  time: 0.2513  data: 0.0000  max mem: 10917
[13:30:28.696281] Epoch: [44]  [320/345]  eta: 0:00:06  lr: 0.000009  loss: 0.7367 (0.7394)  time: 0.2512  data: 0.0000  max mem: 10917
[13:30:33.729576] Epoch: [44]  [340/345]  eta: 0:00:01  lr: 0.000008  loss: 0.7445 (0.7397)  time: 0.2516  data: 0.0000  max mem: 10917
[13:30:34.735456] Epoch: [44]  [344/345]  eta: 0:00:00  lr: 0.000008  loss: 0.7452 (0.7398)  time: 0.2516  data: 0.0001  max mem: 10917
[13:30:34.793682] Epoch: [44] Total time: 0:01:26 (0.2512 s / it)
[13:30:34.794150] Averaged stats: lr: 0.000008  loss: 0.7452 (0.7398)
[13:30:35.035739] Test:  [  0/345]  eta: 0:01:22  loss: 0.6925 (0.6925)  time: 0.2387  data: 0.1583  max mem: 10917
[13:30:35.856575] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7086 (0.7100)  time: 0.0963  data: 0.0145  max mem: 10917
[13:30:36.681359] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7095 (0.7100)  time: 0.0822  data: 0.0001  max mem: 10917
[13:30:37.510119] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7082 (0.7089)  time: 0.0826  data: 0.0001  max mem: 10917
[13:30:38.341648] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7086 (0.7095)  time: 0.0830  data: 0.0001  max mem: 10917
[13:30:39.177091] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7112 (0.7095)  time: 0.0833  data: 0.0001  max mem: 10917
[13:30:40.017196] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7078 (0.7095)  time: 0.0837  data: 0.0001  max mem: 10917
[13:30:40.860280] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7055 (0.7086)  time: 0.0841  data: 0.0001  max mem: 10917
[13:30:41.706633] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7009 (0.7078)  time: 0.0844  data: 0.0001  max mem: 10917
[13:30:42.555492] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7067 (0.7086)  time: 0.0847  data: 0.0001  max mem: 10917
[13:30:43.409482] Test:  [100/345]  eta: 0:00:20  loss: 0.7099 (0.7090)  time: 0.0851  data: 0.0001  max mem: 10917
[13:30:44.266137] Test:  [110/345]  eta: 0:00:20  loss: 0.7149 (0.7092)  time: 0.0855  data: 0.0001  max mem: 10917
[13:30:45.127469] Test:  [120/345]  eta: 0:00:19  loss: 0.7148 (0.7091)  time: 0.0859  data: 0.0001  max mem: 10917
[13:30:45.990921] Test:  [130/345]  eta: 0:00:18  loss: 0.7001 (0.7087)  time: 0.0862  data: 0.0001  max mem: 10917
[13:30:46.856840] Test:  [140/345]  eta: 0:00:17  loss: 0.6999 (0.7085)  time: 0.0864  data: 0.0001  max mem: 10917
[13:30:47.727272] Test:  [150/345]  eta: 0:00:16  loss: 0.7107 (0.7088)  time: 0.0868  data: 0.0001  max mem: 10917
[13:30:48.600734] Test:  [160/345]  eta: 0:00:15  loss: 0.7123 (0.7090)  time: 0.0871  data: 0.0001  max mem: 10917
[13:30:49.479612] Test:  [170/345]  eta: 0:00:15  loss: 0.7110 (0.7091)  time: 0.0875  data: 0.0001  max mem: 10917
[13:30:50.361145] Test:  [180/345]  eta: 0:00:14  loss: 0.7110 (0.7092)  time: 0.0879  data: 0.0001  max mem: 10917
[13:30:51.245980] Test:  [190/345]  eta: 0:00:13  loss: 0.7099 (0.7091)  time: 0.0883  data: 0.0001  max mem: 10917
[13:30:52.135654] Test:  [200/345]  eta: 0:00:12  loss: 0.7071 (0.7092)  time: 0.0887  data: 0.0001  max mem: 10917
[13:30:53.027608] Test:  [210/345]  eta: 0:00:11  loss: 0.7055 (0.7091)  time: 0.0890  data: 0.0001  max mem: 10917
[13:30:53.923070] Test:  [220/345]  eta: 0:00:10  loss: 0.7068 (0.7092)  time: 0.0893  data: 0.0001  max mem: 10917
[13:30:54.821406] Test:  [230/345]  eta: 0:00:09  loss: 0.7094 (0.7094)  time: 0.0896  data: 0.0001  max mem: 10917
[13:30:55.723372] Test:  [240/345]  eta: 0:00:09  loss: 0.7086 (0.7094)  time: 0.0900  data: 0.0001  max mem: 10917
[13:30:56.629319] Test:  [250/345]  eta: 0:00:08  loss: 0.7086 (0.7095)  time: 0.0903  data: 0.0001  max mem: 10917
[13:30:57.538746] Test:  [260/345]  eta: 0:00:07  loss: 0.7097 (0.7096)  time: 0.0907  data: 0.0001  max mem: 10917
[13:30:58.451259] Test:  [270/345]  eta: 0:00:06  loss: 0.7106 (0.7097)  time: 0.0910  data: 0.0001  max mem: 10917
[13:30:59.367412] Test:  [280/345]  eta: 0:00:05  loss: 0.7056 (0.7097)  time: 0.0914  data: 0.0001  max mem: 10917
[13:31:00.286739] Test:  [290/345]  eta: 0:00:04  loss: 0.7061 (0.7097)  time: 0.0917  data: 0.0001  max mem: 10917
[13:31:01.210125] Test:  [300/345]  eta: 0:00:03  loss: 0.7117 (0.7099)  time: 0.0921  data: 0.0001  max mem: 10917
[13:31:02.136193] Test:  [310/345]  eta: 0:00:03  loss: 0.7089 (0.7099)  time: 0.0924  data: 0.0001  max mem: 10917
[13:31:03.065192] Test:  [320/345]  eta: 0:00:02  loss: 0.7022 (0.7096)  time: 0.0927  data: 0.0001  max mem: 10917
[13:31:03.997639] Test:  [330/345]  eta: 0:00:01  loss: 0.7031 (0.7096)  time: 0.0930  data: 0.0001  max mem: 10917
[13:31:04.933806] Test:  [340/345]  eta: 0:00:00  loss: 0.7090 (0.7097)  time: 0.0934  data: 0.0001  max mem: 10917
[13:31:05.309985] Test:  [344/345]  eta: 0:00:00  loss: 0.7108 (0.7095)  time: 0.0935  data: 0.0001  max mem: 10917
[13:31:05.374471] Test: Total time: 0:00:30 (0.0886 s / it)
[13:31:15.977220] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8770 (0.8770)  time: 0.2252  data: 0.1452  max mem: 10917
[13:31:16.790066] Test:  [10/57]  eta: 0:00:04  loss: 0.9043 (0.9201)  time: 0.0943  data: 0.0133  max mem: 10917
[13:31:17.607029] Test:  [20/57]  eta: 0:00:03  loss: 0.9118 (0.9061)  time: 0.0814  data: 0.0001  max mem: 10917
[13:31:18.428620] Test:  [30/57]  eta: 0:00:02  loss: 0.7954 (0.8638)  time: 0.0819  data: 0.0001  max mem: 10917
[13:31:19.252792] Test:  [40/57]  eta: 0:00:01  loss: 0.7817 (0.8410)  time: 0.0822  data: 0.0001  max mem: 10917
[13:31:20.080961] Test:  [50/57]  eta: 0:00:00  loss: 0.7686 (0.8338)  time: 0.0826  data: 0.0001  max mem: 10917
[13:31:20.531199] Test:  [56/57]  eta: 0:00:00  loss: 0.8038 (0.8412)  time: 0.0804  data: 0.0001  max mem: 10917
[13:31:20.588448] Test: Total time: 0:00:04 (0.0849 s / it)
[13:31:22.426482] Dice score of the network on the train images: 0.829587, val images: 0.809002
[13:31:22.430028] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:31:22.828766] Epoch: [45]  [  0/345]  eta: 0:02:17  lr: 0.000008  loss: 0.7389 (0.7389)  time: 0.3980  data: 0.1460  max mem: 10917
[13:31:27.818610] Epoch: [45]  [ 20/345]  eta: 0:01:23  lr: 0.000008  loss: 0.7409 (0.7413)  time: 0.2494  data: 0.0001  max mem: 10917
[13:31:32.806651] Epoch: [45]  [ 40/345]  eta: 0:01:17  lr: 0.000008  loss: 0.7360 (0.7386)  time: 0.2494  data: 0.0000  max mem: 10917
[13:31:37.801191] Epoch: [45]  [ 60/345]  eta: 0:01:11  lr: 0.000008  loss: 0.7337 (0.7372)  time: 0.2497  data: 0.0001  max mem: 10917
[13:31:42.803192] Epoch: [45]  [ 80/345]  eta: 0:01:06  lr: 0.000008  loss: 0.7411 (0.7380)  time: 0.2501  data: 0.0000  max mem: 10917
[13:31:47.811633] Epoch: [45]  [100/345]  eta: 0:01:01  lr: 0.000007  loss: 0.7379 (0.7382)  time: 0.2504  data: 0.0000  max mem: 10917
[13:31:52.820562] Epoch: [45]  [120/345]  eta: 0:00:56  lr: 0.000007  loss: 0.7370 (0.7385)  time: 0.2504  data: 0.0000  max mem: 10917
[13:31:57.828980] Epoch: [45]  [140/345]  eta: 0:00:51  lr: 0.000007  loss: 0.7425 (0.7393)  time: 0.2504  data: 0.0000  max mem: 10917
[13:32:02.837677] Epoch: [45]  [160/345]  eta: 0:00:46  lr: 0.000007  loss: 0.7308 (0.7384)  time: 0.2504  data: 0.0000  max mem: 10917
[13:32:07.852955] Epoch: [45]  [180/345]  eta: 0:00:41  lr: 0.000007  loss: 0.7321 (0.7382)  time: 0.2507  data: 0.0000  max mem: 10917
[13:32:12.870655] Epoch: [45]  [200/345]  eta: 0:00:36  lr: 0.000007  loss: 0.7381 (0.7385)  time: 0.2508  data: 0.0000  max mem: 10917
[13:32:17.887608] Epoch: [45]  [220/345]  eta: 0:00:31  lr: 0.000006  loss: 0.7374 (0.7384)  time: 0.2508  data: 0.0000  max mem: 10917
[13:32:22.909153] Epoch: [45]  [240/345]  eta: 0:00:26  lr: 0.000006  loss: 0.7374 (0.7384)  time: 0.2510  data: 0.0000  max mem: 10917
[13:32:27.934997] Epoch: [45]  [260/345]  eta: 0:00:21  lr: 0.000006  loss: 0.7342 (0.7386)  time: 0.2513  data: 0.0000  max mem: 10917
[13:32:32.958651] Epoch: [45]  [280/345]  eta: 0:00:16  lr: 0.000006  loss: 0.7321 (0.7386)  time: 0.2511  data: 0.0000  max mem: 10917
[13:32:37.985784] Epoch: [45]  [300/345]  eta: 0:00:11  lr: 0.000006  loss: 0.7368 (0.7386)  time: 0.2513  data: 0.0000  max mem: 10917
[13:32:43.012137] Epoch: [45]  [320/345]  eta: 0:00:06  lr: 0.000006  loss: 0.7407 (0.7386)  time: 0.2513  data: 0.0000  max mem: 10917
[13:32:48.040057] Epoch: [45]  [340/345]  eta: 0:00:01  lr: 0.000005  loss: 0.7391 (0.7386)  time: 0.2514  data: 0.0001  max mem: 10917
[13:32:49.046255] Epoch: [45]  [344/345]  eta: 0:00:00  lr: 0.000005  loss: 0.7422 (0.7386)  time: 0.2514  data: 0.0001  max mem: 10917
[13:32:49.104590] Epoch: [45] Total time: 0:01:26 (0.2512 s / it)
[13:32:49.105078] Averaged stats: lr: 0.000005  loss: 0.7422 (0.7386)
[13:32:49.342852] Test:  [  0/345]  eta: 0:01:21  loss: 0.6951 (0.6951)  time: 0.2349  data: 0.1549  max mem: 10917
[13:32:50.164066] Test:  [ 10/345]  eta: 0:00:32  loss: 0.6978 (0.7033)  time: 0.0959  data: 0.0142  max mem: 10917
[13:32:50.987400] Test:  [ 20/345]  eta: 0:00:29  loss: 0.6999 (0.7052)  time: 0.0822  data: 0.0001  max mem: 10917
[13:32:51.814006] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7024 (0.7041)  time: 0.0824  data: 0.0001  max mem: 10917
[13:32:52.644463] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7026 (0.7031)  time: 0.0828  data: 0.0001  max mem: 10917
[13:32:53.478127] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7029 (0.7032)  time: 0.0832  data: 0.0001  max mem: 10917
[13:32:54.316020] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7045 (0.7043)  time: 0.0835  data: 0.0001  max mem: 10917
[13:32:55.156538] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7103 (0.7053)  time: 0.0839  data: 0.0001  max mem: 10917
[13:32:56.000137] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7025 (0.7056)  time: 0.0842  data: 0.0001  max mem: 10917
[13:32:56.847719] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7010 (0.7052)  time: 0.0845  data: 0.0001  max mem: 10917
[13:32:57.698482] Test:  [100/345]  eta: 0:00:20  loss: 0.7051 (0.7054)  time: 0.0849  data: 0.0001  max mem: 10917
[13:32:58.553343] Test:  [110/345]  eta: 0:00:19  loss: 0.7077 (0.7057)  time: 0.0852  data: 0.0001  max mem: 10917
[13:32:59.411640] Test:  [120/345]  eta: 0:00:19  loss: 0.7057 (0.7058)  time: 0.0856  data: 0.0001  max mem: 10917
[13:33:00.273569] Test:  [130/345]  eta: 0:00:18  loss: 0.7008 (0.7056)  time: 0.0860  data: 0.0001  max mem: 10917
[13:33:01.139619] Test:  [140/345]  eta: 0:00:17  loss: 0.7118 (0.7065)  time: 0.0863  data: 0.0001  max mem: 10917
[13:33:02.009652] Test:  [150/345]  eta: 0:00:16  loss: 0.7097 (0.7069)  time: 0.0868  data: 0.0001  max mem: 10917
[13:33:02.881651] Test:  [160/345]  eta: 0:00:15  loss: 0.7032 (0.7064)  time: 0.0871  data: 0.0001  max mem: 10917
[13:33:03.757468] Test:  [170/345]  eta: 0:00:14  loss: 0.7026 (0.7064)  time: 0.0873  data: 0.0001  max mem: 10917
[13:33:04.638278] Test:  [180/345]  eta: 0:00:14  loss: 0.7084 (0.7066)  time: 0.0878  data: 0.0001  max mem: 10917
[13:33:05.520961] Test:  [190/345]  eta: 0:00:13  loss: 0.7106 (0.7067)  time: 0.0881  data: 0.0001  max mem: 10917
[13:33:06.407279] Test:  [200/345]  eta: 0:00:12  loss: 0.7078 (0.7069)  time: 0.0884  data: 0.0001  max mem: 10917
[13:33:07.297939] Test:  [210/345]  eta: 0:00:11  loss: 0.7096 (0.7072)  time: 0.0888  data: 0.0001  max mem: 10917
[13:33:08.192315] Test:  [220/345]  eta: 0:00:10  loss: 0.7105 (0.7074)  time: 0.0892  data: 0.0001  max mem: 10917
[13:33:09.089299] Test:  [230/345]  eta: 0:00:09  loss: 0.7060 (0.7073)  time: 0.0895  data: 0.0001  max mem: 10917
[13:33:09.991140] Test:  [240/345]  eta: 0:00:09  loss: 0.7035 (0.7072)  time: 0.0899  data: 0.0001  max mem: 10917
[13:33:10.895907] Test:  [250/345]  eta: 0:00:08  loss: 0.7096 (0.7074)  time: 0.0902  data: 0.0001  max mem: 10917
[13:33:11.804195] Test:  [260/345]  eta: 0:00:07  loss: 0.7096 (0.7075)  time: 0.0906  data: 0.0001  max mem: 10917
[13:33:12.715824] Test:  [270/345]  eta: 0:00:06  loss: 0.7092 (0.7075)  time: 0.0909  data: 0.0001  max mem: 10917
[13:33:13.630722] Test:  [280/345]  eta: 0:00:05  loss: 0.7045 (0.7075)  time: 0.0913  data: 0.0001  max mem: 10917
[13:33:14.548354] Test:  [290/345]  eta: 0:00:04  loss: 0.7115 (0.7078)  time: 0.0916  data: 0.0001  max mem: 10917
[13:33:15.470882] Test:  [300/345]  eta: 0:00:03  loss: 0.7115 (0.7079)  time: 0.0920  data: 0.0001  max mem: 10917
[13:33:16.396404] Test:  [310/345]  eta: 0:00:03  loss: 0.7069 (0.7080)  time: 0.0924  data: 0.0001  max mem: 10917
[13:33:17.324601] Test:  [320/345]  eta: 0:00:02  loss: 0.7108 (0.7079)  time: 0.0926  data: 0.0001  max mem: 10917
[13:33:18.257688] Test:  [330/345]  eta: 0:00:01  loss: 0.7068 (0.7079)  time: 0.0930  data: 0.0001  max mem: 10917
[13:33:19.193150] Test:  [340/345]  eta: 0:00:00  loss: 0.7050 (0.7080)  time: 0.0934  data: 0.0001  max mem: 10917
[13:33:19.569072] Test:  [344/345]  eta: 0:00:00  loss: 0.7068 (0.7080)  time: 0.0935  data: 0.0001  max mem: 10917
[13:33:19.626911] Test: Total time: 0:00:30 (0.0885 s / it)
[13:33:30.235982] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8790 (0.8790)  time: 0.2237  data: 0.1434  max mem: 10917
[13:33:31.050220] Test:  [10/57]  eta: 0:00:04  loss: 0.9137 (0.9248)  time: 0.0943  data: 0.0131  max mem: 10917
[13:33:31.867216] Test:  [20/57]  eta: 0:00:03  loss: 0.9137 (0.9100)  time: 0.0815  data: 0.0001  max mem: 10917
[13:33:32.688132] Test:  [30/57]  eta: 0:00:02  loss: 0.7992 (0.8672)  time: 0.0818  data: 0.0001  max mem: 10917
[13:33:33.512823] Test:  [40/57]  eta: 0:00:01  loss: 0.7813 (0.8443)  time: 0.0822  data: 0.0001  max mem: 10917
[13:33:34.340559] Test:  [50/57]  eta: 0:00:00  loss: 0.7711 (0.8370)  time: 0.0826  data: 0.0001  max mem: 10917
[13:33:34.790713] Test:  [56/57]  eta: 0:00:00  loss: 0.8089 (0.8443)  time: 0.0804  data: 0.0001  max mem: 10917
[13:33:34.847722] Test: Total time: 0:00:04 (0.0848 s / it)
[13:33:36.674552] Dice score of the network on the train images: 0.831082, val images: 0.809517
[13:33:36.678135] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:33:37.076009] Epoch: [46]  [  0/345]  eta: 0:02:17  lr: 0.000005  loss: 0.7522 (0.7522)  time: 0.3972  data: 0.1457  max mem: 10917
[13:33:42.063042] Epoch: [46]  [ 20/345]  eta: 0:01:23  lr: 0.000005  loss: 0.7356 (0.7357)  time: 0.2493  data: 0.0001  max mem: 10917
[13:33:47.051572] Epoch: [46]  [ 40/345]  eta: 0:01:17  lr: 0.000005  loss: 0.7425 (0.7380)  time: 0.2494  data: 0.0000  max mem: 10917
[13:33:52.043228] Epoch: [46]  [ 60/345]  eta: 0:01:11  lr: 0.000005  loss: 0.7392 (0.7396)  time: 0.2495  data: 0.0000  max mem: 10917
[13:33:57.054767] Epoch: [46]  [ 80/345]  eta: 0:01:06  lr: 0.000005  loss: 0.7323 (0.7390)  time: 0.2505  data: 0.0001  max mem: 10917
[13:34:02.069916] Epoch: [46]  [100/345]  eta: 0:01:01  lr: 0.000005  loss: 0.7350 (0.7387)  time: 0.2507  data: 0.0001  max mem: 10917
[13:34:07.078881] Epoch: [46]  [120/345]  eta: 0:00:56  lr: 0.000005  loss: 0.7325 (0.7380)  time: 0.2504  data: 0.0001  max mem: 10917
[13:34:12.090702] Epoch: [46]  [140/345]  eta: 0:00:51  lr: 0.000004  loss: 0.7347 (0.7382)  time: 0.2505  data: 0.0001  max mem: 10917
[13:34:17.102087] Epoch: [46]  [160/345]  eta: 0:00:46  lr: 0.000004  loss: 0.7399 (0.7386)  time: 0.2505  data: 0.0001  max mem: 10917
[13:34:22.113034] Epoch: [46]  [180/345]  eta: 0:00:41  lr: 0.000004  loss: 0.7409 (0.7389)  time: 0.2505  data: 0.0001  max mem: 10917
[13:34:27.142177] Epoch: [46]  [200/345]  eta: 0:00:36  lr: 0.000004  loss: 0.7321 (0.7383)  time: 0.2514  data: 0.0000  max mem: 10917
[13:34:32.250229] Epoch: [46]  [220/345]  eta: 0:00:31  lr: 0.000004  loss: 0.7363 (0.7384)  time: 0.2554  data: 0.0000  max mem: 10917
[13:34:37.282103] Epoch: [46]  [240/345]  eta: 0:00:26  lr: 0.000004  loss: 0.7378 (0.7386)  time: 0.2516  data: 0.0000  max mem: 10917
[13:34:42.316291] Epoch: [46]  [260/345]  eta: 0:00:21  lr: 0.000004  loss: 0.7354 (0.7383)  time: 0.2517  data: 0.0000  max mem: 10917
[13:34:47.356485] Epoch: [46]  [280/345]  eta: 0:00:16  lr: 0.000003  loss: 0.7371 (0.7383)  time: 0.2520  data: 0.0000  max mem: 10917
[13:34:52.394815] Epoch: [46]  [300/345]  eta: 0:00:11  lr: 0.000003  loss: 0.7319 (0.7380)  time: 0.2519  data: 0.0001  max mem: 10917
[13:34:57.434720] Epoch: [46]  [320/345]  eta: 0:00:06  lr: 0.000003  loss: 0.7325 (0.7379)  time: 0.2520  data: 0.0000  max mem: 10917
[13:35:02.478451] Epoch: [46]  [340/345]  eta: 0:00:01  lr: 0.000003  loss: 0.7377 (0.7380)  time: 0.2522  data: 0.0000  max mem: 10917
[13:35:03.486579] Epoch: [46]  [344/345]  eta: 0:00:00  lr: 0.000003  loss: 0.7377 (0.7381)  time: 0.2522  data: 0.0001  max mem: 10917
[13:35:03.549202] Epoch: [46] Total time: 0:01:26 (0.2518 s / it)
[13:35:03.549532] Averaged stats: lr: 0.000003  loss: 0.7377 (0.7381)
[13:35:03.794266] Test:  [  0/345]  eta: 0:01:23  loss: 0.7010 (0.7010)  time: 0.2410  data: 0.1608  max mem: 10917
[13:35:04.625810] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7060 (0.7074)  time: 0.0974  data: 0.0157  max mem: 10917
[13:35:05.449410] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7039 (0.7044)  time: 0.0827  data: 0.0006  max mem: 10917
[13:35:06.276372] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7001 (0.7038)  time: 0.0825  data: 0.0001  max mem: 10917
[13:35:07.106992] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7031 (0.7042)  time: 0.0828  data: 0.0001  max mem: 10917
[13:35:07.942088] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7024 (0.7040)  time: 0.0832  data: 0.0001  max mem: 10917
[13:35:08.779861] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7098 (0.7058)  time: 0.0836  data: 0.0001  max mem: 10917
[13:35:09.621127] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7130 (0.7064)  time: 0.0839  data: 0.0001  max mem: 10917
[13:35:10.465936] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7081 (0.7066)  time: 0.0843  data: 0.0001  max mem: 10917
[13:35:11.313983] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7052 (0.7068)  time: 0.0846  data: 0.0001  max mem: 10917
[13:35:12.165997] Test:  [100/345]  eta: 0:00:20  loss: 0.6996 (0.7066)  time: 0.0850  data: 0.0001  max mem: 10917
[13:35:13.021598] Test:  [110/345]  eta: 0:00:20  loss: 0.7022 (0.7074)  time: 0.0853  data: 0.0001  max mem: 10917
[13:35:13.880847] Test:  [120/345]  eta: 0:00:19  loss: 0.7083 (0.7076)  time: 0.0857  data: 0.0001  max mem: 10917
[13:35:14.743089] Test:  [130/345]  eta: 0:00:18  loss: 0.7079 (0.7075)  time: 0.0860  data: 0.0001  max mem: 10917
[13:35:15.608693] Test:  [140/345]  eta: 0:00:17  loss: 0.7090 (0.7080)  time: 0.0863  data: 0.0001  max mem: 10917
[13:35:16.477532] Test:  [150/345]  eta: 0:00:16  loss: 0.7069 (0.7079)  time: 0.0867  data: 0.0001  max mem: 10917
[13:35:17.350751] Test:  [160/345]  eta: 0:00:15  loss: 0.7062 (0.7081)  time: 0.0871  data: 0.0001  max mem: 10917
[13:35:18.227496] Test:  [170/345]  eta: 0:00:15  loss: 0.7089 (0.7082)  time: 0.0875  data: 0.0001  max mem: 10917
[13:35:19.107661] Test:  [180/345]  eta: 0:00:14  loss: 0.7037 (0.7079)  time: 0.0878  data: 0.0001  max mem: 10917
[13:35:19.990308] Test:  [190/345]  eta: 0:00:13  loss: 0.7054 (0.7083)  time: 0.0881  data: 0.0001  max mem: 10917
[13:35:20.877078] Test:  [200/345]  eta: 0:00:12  loss: 0.7098 (0.7084)  time: 0.0884  data: 0.0001  max mem: 10917
[13:35:21.767873] Test:  [210/345]  eta: 0:00:11  loss: 0.7110 (0.7085)  time: 0.0888  data: 0.0001  max mem: 10917
[13:35:22.661920] Test:  [220/345]  eta: 0:00:10  loss: 0.7081 (0.7084)  time: 0.0892  data: 0.0001  max mem: 10917
[13:35:23.560041] Test:  [230/345]  eta: 0:00:09  loss: 0.7072 (0.7085)  time: 0.0896  data: 0.0001  max mem: 10917
[13:35:24.462200] Test:  [240/345]  eta: 0:00:09  loss: 0.7058 (0.7083)  time: 0.0900  data: 0.0001  max mem: 10917
[13:35:25.367147] Test:  [250/345]  eta: 0:00:08  loss: 0.7025 (0.7080)  time: 0.0903  data: 0.0001  max mem: 10917
[13:35:26.274902] Test:  [260/345]  eta: 0:00:07  loss: 0.7004 (0.7079)  time: 0.0906  data: 0.0001  max mem: 10917
[13:35:27.186148] Test:  [270/345]  eta: 0:00:06  loss: 0.7002 (0.7077)  time: 0.0909  data: 0.0001  max mem: 10917
[13:35:28.100951] Test:  [280/345]  eta: 0:00:05  loss: 0.7013 (0.7075)  time: 0.0913  data: 0.0001  max mem: 10917
[13:35:29.019885] Test:  [290/345]  eta: 0:00:04  loss: 0.7035 (0.7074)  time: 0.0916  data: 0.0001  max mem: 10917
[13:35:29.942647] Test:  [300/345]  eta: 0:00:03  loss: 0.7077 (0.7076)  time: 0.0920  data: 0.0001  max mem: 10917
[13:35:30.867743] Test:  [310/345]  eta: 0:00:03  loss: 0.7087 (0.7075)  time: 0.0923  data: 0.0001  max mem: 10917
[13:35:31.797327] Test:  [320/345]  eta: 0:00:02  loss: 0.7024 (0.7074)  time: 0.0927  data: 0.0001  max mem: 10917
[13:35:32.730733] Test:  [330/345]  eta: 0:00:01  loss: 0.7022 (0.7075)  time: 0.0931  data: 0.0001  max mem: 10917
[13:35:33.667821] Test:  [340/345]  eta: 0:00:00  loss: 0.7087 (0.7076)  time: 0.0935  data: 0.0001  max mem: 10917
[13:35:34.043545] Test:  [344/345]  eta: 0:00:00  loss: 0.7140 (0.7078)  time: 0.0936  data: 0.0001  max mem: 10917
[13:35:34.101509] Test: Total time: 0:00:30 (0.0885 s / it)
[13:35:44.778275] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8773 (0.8773)  time: 0.2237  data: 0.1438  max mem: 10917
[13:35:45.593093] Test:  [10/57]  eta: 0:00:04  loss: 0.9144 (0.9227)  time: 0.0943  data: 0.0132  max mem: 10917
[13:35:46.411158] Test:  [20/57]  eta: 0:00:03  loss: 0.9144 (0.9080)  time: 0.0816  data: 0.0001  max mem: 10917
[13:35:47.231795] Test:  [30/57]  eta: 0:00:02  loss: 0.7985 (0.8656)  time: 0.0819  data: 0.0001  max mem: 10917
[13:35:48.056106] Test:  [40/57]  eta: 0:00:01  loss: 0.7824 (0.8430)  time: 0.0822  data: 0.0001  max mem: 10917
[13:35:48.885126] Test:  [50/57]  eta: 0:00:00  loss: 0.7702 (0.8357)  time: 0.0826  data: 0.0001  max mem: 10917
[13:35:49.335566] Test:  [56/57]  eta: 0:00:00  loss: 0.8064 (0.8434)  time: 0.0804  data: 0.0001  max mem: 10917
[13:35:49.393260] Test: Total time: 0:00:04 (0.0849 s / it)
[13:35:51.222315] Dice score of the network on the train images: 0.831340, val images: 0.809668
[13:35:51.225748] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:35:51.626131] Epoch: [47]  [  0/345]  eta: 0:02:17  lr: 0.000003  loss: 0.7424 (0.7424)  time: 0.3996  data: 0.1470  max mem: 10917
[13:35:56.636934] Epoch: [47]  [ 20/345]  eta: 0:01:23  lr: 0.000003  loss: 0.7376 (0.7377)  time: 0.2505  data: 0.0001  max mem: 10917
[13:36:01.650785] Epoch: [47]  [ 40/345]  eta: 0:01:17  lr: 0.000003  loss: 0.7388 (0.7394)  time: 0.2506  data: 0.0001  max mem: 10917
[13:36:06.663932] Epoch: [47]  [ 60/345]  eta: 0:01:12  lr: 0.000003  loss: 0.7361 (0.7401)  time: 0.2506  data: 0.0001  max mem: 10917
[13:36:11.679815] Epoch: [47]  [ 80/345]  eta: 0:01:06  lr: 0.000003  loss: 0.7407 (0.7398)  time: 0.2507  data: 0.0001  max mem: 10917
[13:36:16.705880] Epoch: [47]  [100/345]  eta: 0:01:01  lr: 0.000003  loss: 0.7364 (0.7393)  time: 0.2513  data: 0.0001  max mem: 10917
[13:36:21.733014] Epoch: [47]  [120/345]  eta: 0:00:56  lr: 0.000002  loss: 0.7327 (0.7382)  time: 0.2513  data: 0.0001  max mem: 10917
[13:36:26.760687] Epoch: [47]  [140/345]  eta: 0:00:51  lr: 0.000002  loss: 0.7343 (0.7377)  time: 0.2513  data: 0.0001  max mem: 10917
[13:36:31.788679] Epoch: [47]  [160/345]  eta: 0:00:46  lr: 0.000002  loss: 0.7354 (0.7380)  time: 0.2514  data: 0.0001  max mem: 10917
[13:36:36.821296] Epoch: [47]  [180/345]  eta: 0:00:41  lr: 0.000002  loss: 0.7364 (0.7379)  time: 0.2516  data: 0.0001  max mem: 10917
[13:36:41.855563] Epoch: [47]  [200/345]  eta: 0:00:36  lr: 0.000002  loss: 0.7362 (0.7381)  time: 0.2517  data: 0.0000  max mem: 10917
[13:36:46.892656] Epoch: [47]  [220/345]  eta: 0:00:31  lr: 0.000002  loss: 0.7366 (0.7378)  time: 0.2518  data: 0.0001  max mem: 10917
[13:36:51.932685] Epoch: [47]  [240/345]  eta: 0:00:26  lr: 0.000002  loss: 0.7405 (0.7378)  time: 0.2520  data: 0.0001  max mem: 10917
[13:36:56.971893] Epoch: [47]  [260/345]  eta: 0:00:21  lr: 0.000002  loss: 0.7377 (0.7379)  time: 0.2519  data: 0.0000  max mem: 10917
[13:37:02.013279] Epoch: [47]  [280/345]  eta: 0:00:16  lr: 0.000002  loss: 0.7363 (0.7378)  time: 0.2520  data: 0.0001  max mem: 10917
[13:37:07.057801] Epoch: [47]  [300/345]  eta: 0:00:11  lr: 0.000002  loss: 0.7384 (0.7382)  time: 0.2522  data: 0.0000  max mem: 10917
[13:37:12.104843] Epoch: [47]  [320/345]  eta: 0:00:06  lr: 0.000001  loss: 0.7327 (0.7379)  time: 0.2523  data: 0.0001  max mem: 10917
[13:37:17.152703] Epoch: [47]  [340/345]  eta: 0:00:01  lr: 0.000001  loss: 0.7323 (0.7377)  time: 0.2524  data: 0.0001  max mem: 10917
[13:37:18.162759] Epoch: [47]  [344/345]  eta: 0:00:00  lr: 0.000001  loss: 0.7386 (0.7377)  time: 0.2524  data: 0.0001  max mem: 10917
[13:37:18.220511] Epoch: [47] Total time: 0:01:26 (0.2522 s / it)
[13:37:18.220948] Averaged stats: lr: 0.000001  loss: 0.7386 (0.7377)
[13:37:18.465992] Test:  [  0/345]  eta: 0:01:23  loss: 0.6961 (0.6961)  time: 0.2411  data: 0.1609  max mem: 10917
[13:37:19.294552] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7131 (0.7124)  time: 0.0971  data: 0.0154  max mem: 10917
[13:37:20.118680] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7070 (0.7080)  time: 0.0826  data: 0.0005  max mem: 10917
[13:37:20.945440] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7033 (0.7070)  time: 0.0825  data: 0.0001  max mem: 10917
[13:37:21.776571] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7053 (0.7090)  time: 0.0828  data: 0.0001  max mem: 10917
[13:37:22.610115] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7077 (0.7080)  time: 0.0832  data: 0.0001  max mem: 10917
[13:37:23.447632] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7053 (0.7076)  time: 0.0835  data: 0.0001  max mem: 10917
[13:37:24.289788] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7074 (0.7078)  time: 0.0839  data: 0.0001  max mem: 10917
[13:37:25.134736] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7085 (0.7073)  time: 0.0843  data: 0.0001  max mem: 10917
[13:37:25.983751] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7027 (0.7065)  time: 0.0847  data: 0.0001  max mem: 10917
[13:37:26.836068] Test:  [100/345]  eta: 0:00:20  loss: 0.7021 (0.7064)  time: 0.0850  data: 0.0001  max mem: 10917
[13:37:27.692134] Test:  [110/345]  eta: 0:00:20  loss: 0.7021 (0.7064)  time: 0.0854  data: 0.0001  max mem: 10917
[13:37:28.551507] Test:  [120/345]  eta: 0:00:19  loss: 0.7104 (0.7068)  time: 0.0857  data: 0.0001  max mem: 10917
[13:37:29.413894] Test:  [130/345]  eta: 0:00:18  loss: 0.7077 (0.7065)  time: 0.0860  data: 0.0001  max mem: 10917
[13:37:30.279929] Test:  [140/345]  eta: 0:00:17  loss: 0.7000 (0.7064)  time: 0.0864  data: 0.0001  max mem: 10917
[13:37:31.149967] Test:  [150/345]  eta: 0:00:16  loss: 0.7023 (0.7062)  time: 0.0867  data: 0.0001  max mem: 10917
[13:37:32.022569] Test:  [160/345]  eta: 0:00:15  loss: 0.7059 (0.7063)  time: 0.0871  data: 0.0001  max mem: 10917
[13:37:32.899431] Test:  [170/345]  eta: 0:00:15  loss: 0.7095 (0.7068)  time: 0.0874  data: 0.0001  max mem: 10917
[13:37:33.779841] Test:  [180/345]  eta: 0:00:14  loss: 0.7119 (0.7070)  time: 0.0878  data: 0.0001  max mem: 10917
[13:37:34.663095] Test:  [190/345]  eta: 0:00:13  loss: 0.7050 (0.7069)  time: 0.0881  data: 0.0001  max mem: 10917
[13:37:35.550544] Test:  [200/345]  eta: 0:00:12  loss: 0.7053 (0.7069)  time: 0.0885  data: 0.0001  max mem: 10917
[13:37:36.441766] Test:  [210/345]  eta: 0:00:11  loss: 0.7053 (0.7069)  time: 0.0889  data: 0.0001  max mem: 10917
[13:37:37.335644] Test:  [220/345]  eta: 0:00:10  loss: 0.7039 (0.7070)  time: 0.0892  data: 0.0001  max mem: 10917
[13:37:38.233831] Test:  [230/345]  eta: 0:00:09  loss: 0.7035 (0.7069)  time: 0.0896  data: 0.0001  max mem: 10917
[13:37:39.136045] Test:  [240/345]  eta: 0:00:09  loss: 0.7110 (0.7073)  time: 0.0900  data: 0.0001  max mem: 10917
[13:37:40.041256] Test:  [250/345]  eta: 0:00:08  loss: 0.7104 (0.7073)  time: 0.0903  data: 0.0001  max mem: 10917
[13:37:40.950071] Test:  [260/345]  eta: 0:00:07  loss: 0.7100 (0.7075)  time: 0.0907  data: 0.0001  max mem: 10917
[13:37:41.862348] Test:  [270/345]  eta: 0:00:06  loss: 0.7098 (0.7075)  time: 0.0910  data: 0.0001  max mem: 10917
[13:37:42.777987] Test:  [280/345]  eta: 0:00:05  loss: 0.7056 (0.7075)  time: 0.0913  data: 0.0001  max mem: 10917
[13:37:43.697010] Test:  [290/345]  eta: 0:00:04  loss: 0.7112 (0.7076)  time: 0.0917  data: 0.0001  max mem: 10917
[13:37:44.619788] Test:  [300/345]  eta: 0:00:03  loss: 0.7096 (0.7078)  time: 0.0920  data: 0.0001  max mem: 10917
[13:37:45.545534] Test:  [310/345]  eta: 0:00:03  loss: 0.7056 (0.7077)  time: 0.0924  data: 0.0001  max mem: 10917
[13:37:46.474450] Test:  [320/345]  eta: 0:00:02  loss: 0.7066 (0.7077)  time: 0.0927  data: 0.0001  max mem: 10917
[13:37:47.407726] Test:  [330/345]  eta: 0:00:01  loss: 0.7073 (0.7075)  time: 0.0931  data: 0.0001  max mem: 10917
[13:37:48.343721] Test:  [340/345]  eta: 0:00:00  loss: 0.7066 (0.7077)  time: 0.0934  data: 0.0001  max mem: 10917
[13:37:48.719524] Test:  [344/345]  eta: 0:00:00  loss: 0.7066 (0.7076)  time: 0.0936  data: 0.0001  max mem: 10917
[13:37:48.778621] Test: Total time: 0:00:30 (0.0886 s / it)
[13:37:59.503534] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8781 (0.8781)  time: 0.2232  data: 0.1433  max mem: 10917
[13:38:00.317453] Test:  [10/57]  eta: 0:00:04  loss: 0.9125 (0.9221)  time: 0.0942  data: 0.0131  max mem: 10917
[13:38:01.135288] Test:  [20/57]  eta: 0:00:03  loss: 0.9125 (0.9071)  time: 0.0815  data: 0.0001  max mem: 10917
[13:38:01.956568] Test:  [30/57]  eta: 0:00:02  loss: 0.7964 (0.8645)  time: 0.0819  data: 0.0001  max mem: 10917
[13:38:02.781373] Test:  [40/57]  eta: 0:00:01  loss: 0.7813 (0.8417)  time: 0.0823  data: 0.0001  max mem: 10917
[13:38:03.609652] Test:  [50/57]  eta: 0:00:00  loss: 0.7689 (0.8344)  time: 0.0826  data: 0.0001  max mem: 10917
[13:38:04.059540] Test:  [56/57]  eta: 0:00:00  loss: 0.8055 (0.8423)  time: 0.0804  data: 0.0001  max mem: 10917
[13:38:04.117546] Test: Total time: 0:00:04 (0.0849 s / it)
[13:38:05.925302] Dice score of the network on the train images: 0.828808, val images: 0.810467
[13:38:05.928883] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:38:06.328120] Epoch: [48]  [  0/345]  eta: 0:02:17  lr: 0.000001  loss: 0.7423 (0.7423)  time: 0.3984  data: 0.1464  max mem: 10917
[13:38:11.330781] Epoch: [48]  [ 20/345]  eta: 0:01:23  lr: 0.000001  loss: 0.7345 (0.7377)  time: 0.2501  data: 0.0000  max mem: 10917
[13:38:16.337266] Epoch: [48]  [ 40/345]  eta: 0:01:17  lr: 0.000001  loss: 0.7386 (0.7378)  time: 0.2503  data: 0.0000  max mem: 10917
[13:38:21.338911] Epoch: [48]  [ 60/345]  eta: 0:01:11  lr: 0.000001  loss: 0.7370 (0.7378)  time: 0.2500  data: 0.0000  max mem: 10917
[13:38:26.352413] Epoch: [48]  [ 80/345]  eta: 0:01:06  lr: 0.000001  loss: 0.7379 (0.7377)  time: 0.2506  data: 0.0000  max mem: 10917
[13:38:31.373106] Epoch: [48]  [100/345]  eta: 0:01:01  lr: 0.000001  loss: 0.7418 (0.7394)  time: 0.2510  data: 0.0000  max mem: 10917
[13:38:36.394380] Epoch: [48]  [120/345]  eta: 0:00:56  lr: 0.000001  loss: 0.7366 (0.7392)  time: 0.2510  data: 0.0000  max mem: 10917
[13:38:41.419764] Epoch: [48]  [140/345]  eta: 0:00:51  lr: 0.000001  loss: 0.7442 (0.7394)  time: 0.2512  data: 0.0000  max mem: 10917
[13:38:46.430579] Epoch: [48]  [160/345]  eta: 0:00:46  lr: 0.000001  loss: 0.7400 (0.7393)  time: 0.2505  data: 0.0000  max mem: 10917
[13:38:51.456689] Epoch: [48]  [180/345]  eta: 0:00:41  lr: 0.000001  loss: 0.7398 (0.7398)  time: 0.2513  data: 0.0000  max mem: 10917
[13:38:56.481346] Epoch: [48]  [200/345]  eta: 0:00:36  lr: 0.000001  loss: 0.7335 (0.7393)  time: 0.2512  data: 0.0000  max mem: 10917
[13:39:01.507738] Epoch: [48]  [220/345]  eta: 0:00:31  lr: 0.000001  loss: 0.7352 (0.7389)  time: 0.2513  data: 0.0000  max mem: 10917
[13:39:06.540116] Epoch: [48]  [240/345]  eta: 0:00:26  lr: 0.000001  loss: 0.7308 (0.7385)  time: 0.2516  data: 0.0001  max mem: 10917
[13:39:11.570190] Epoch: [48]  [260/345]  eta: 0:00:21  lr: 0.000001  loss: 0.7352 (0.7384)  time: 0.2515  data: 0.0000  max mem: 10917
[13:39:16.608871] Epoch: [48]  [280/345]  eta: 0:00:16  lr: 0.000000  loss: 0.7271 (0.7378)  time: 0.2519  data: 0.0000  max mem: 10917
[13:39:21.646777] Epoch: [48]  [300/345]  eta: 0:00:11  lr: 0.000000  loss: 0.7364 (0.7377)  time: 0.2519  data: 0.0000  max mem: 10917
[13:39:26.686000] Epoch: [48]  [320/345]  eta: 0:00:06  lr: 0.000000  loss: 0.7301 (0.7374)  time: 0.2519  data: 0.0000  max mem: 10917
[13:39:31.727225] Epoch: [48]  [340/345]  eta: 0:00:01  lr: 0.000000  loss: 0.7335 (0.7374)  time: 0.2520  data: 0.0000  max mem: 10917
[13:39:32.733967] Epoch: [48]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.7398 (0.7375)  time: 0.2519  data: 0.0001  max mem: 10917
[13:39:32.793443] Epoch: [48] Total time: 0:01:26 (0.2518 s / it)
[13:39:32.793742] Averaged stats: lr: 0.000000  loss: 0.7398 (0.7375)
[13:39:33.029934] Test:  [  0/345]  eta: 0:01:20  loss: 0.7206 (0.7206)  time: 0.2324  data: 0.1526  max mem: 10917
[13:39:33.876317] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7068 (0.7057)  time: 0.0980  data: 0.0164  max mem: 10917
[13:39:34.699264] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7052 (0.7077)  time: 0.0834  data: 0.0014  max mem: 10917
[13:39:35.526855] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7051 (0.7082)  time: 0.0825  data: 0.0001  max mem: 10917
[13:39:36.358183] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7051 (0.7074)  time: 0.0829  data: 0.0001  max mem: 10917
[13:39:37.192323] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7094 (0.7095)  time: 0.0832  data: 0.0001  max mem: 10917
[13:39:38.030374] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7171 (0.7096)  time: 0.0836  data: 0.0001  max mem: 10917
[13:39:38.872452] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7016 (0.7086)  time: 0.0840  data: 0.0001  max mem: 10917
[13:39:39.717263] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7038 (0.7083)  time: 0.0843  data: 0.0001  max mem: 10917
[13:39:40.565659] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7022 (0.7076)  time: 0.0846  data: 0.0001  max mem: 10917
[13:39:41.418185] Test:  [100/345]  eta: 0:00:20  loss: 0.7022 (0.7076)  time: 0.0850  data: 0.0001  max mem: 10917
[13:39:42.274192] Test:  [110/345]  eta: 0:00:20  loss: 0.7034 (0.7070)  time: 0.0854  data: 0.0001  max mem: 10917
[13:39:43.133784] Test:  [120/345]  eta: 0:00:19  loss: 0.7031 (0.7076)  time: 0.0857  data: 0.0001  max mem: 10917
[13:39:43.996228] Test:  [130/345]  eta: 0:00:18  loss: 0.7093 (0.7081)  time: 0.0861  data: 0.0001  max mem: 10917
[13:39:44.862565] Test:  [140/345]  eta: 0:00:17  loss: 0.7109 (0.7083)  time: 0.0864  data: 0.0001  max mem: 10917
[13:39:45.732658] Test:  [150/345]  eta: 0:00:16  loss: 0.7072 (0.7081)  time: 0.0868  data: 0.0001  max mem: 10917
[13:39:46.605110] Test:  [160/345]  eta: 0:00:15  loss: 0.7045 (0.7080)  time: 0.0871  data: 0.0001  max mem: 10917
[13:39:47.481830] Test:  [170/345]  eta: 0:00:15  loss: 0.7034 (0.7078)  time: 0.0874  data: 0.0001  max mem: 10917
[13:39:48.362786] Test:  [180/345]  eta: 0:00:14  loss: 0.7035 (0.7080)  time: 0.0878  data: 0.0001  max mem: 10917
[13:39:49.245732] Test:  [190/345]  eta: 0:00:13  loss: 0.7035 (0.7078)  time: 0.0881  data: 0.0001  max mem: 10917
[13:39:50.133243] Test:  [200/345]  eta: 0:00:12  loss: 0.7041 (0.7079)  time: 0.0885  data: 0.0001  max mem: 10917
[13:39:51.023811] Test:  [210/345]  eta: 0:00:11  loss: 0.7079 (0.7077)  time: 0.0889  data: 0.0001  max mem: 10917
[13:39:51.917188] Test:  [220/345]  eta: 0:00:10  loss: 0.7062 (0.7077)  time: 0.0891  data: 0.0001  max mem: 10917
[13:39:52.814761] Test:  [230/345]  eta: 0:00:09  loss: 0.7095 (0.7078)  time: 0.0895  data: 0.0001  max mem: 10917
[13:39:53.716358] Test:  [240/345]  eta: 0:00:09  loss: 0.7015 (0.7074)  time: 0.0899  data: 0.0001  max mem: 10917
[13:39:54.620240] Test:  [250/345]  eta: 0:00:08  loss: 0.7039 (0.7074)  time: 0.0902  data: 0.0001  max mem: 10917
[13:39:55.527957] Test:  [260/345]  eta: 0:00:07  loss: 0.7085 (0.7076)  time: 0.0905  data: 0.0001  max mem: 10917
[13:39:56.440375] Test:  [270/345]  eta: 0:00:06  loss: 0.7085 (0.7076)  time: 0.0910  data: 0.0001  max mem: 10917
[13:39:57.355501] Test:  [280/345]  eta: 0:00:05  loss: 0.7065 (0.7077)  time: 0.0913  data: 0.0001  max mem: 10917
[13:39:58.274260] Test:  [290/345]  eta: 0:00:04  loss: 0.7074 (0.7077)  time: 0.0916  data: 0.0001  max mem: 10917
[13:39:59.196714] Test:  [300/345]  eta: 0:00:03  loss: 0.7041 (0.7076)  time: 0.0920  data: 0.0001  max mem: 10917
[13:40:00.122539] Test:  [310/345]  eta: 0:00:03  loss: 0.7032 (0.7076)  time: 0.0924  data: 0.0001  max mem: 10917
[13:40:01.051342] Test:  [320/345]  eta: 0:00:02  loss: 0.7007 (0.7074)  time: 0.0927  data: 0.0001  max mem: 10917
[13:40:01.984468] Test:  [330/345]  eta: 0:00:01  loss: 0.7007 (0.7074)  time: 0.0930  data: 0.0001  max mem: 10917
[13:40:02.919939] Test:  [340/345]  eta: 0:00:00  loss: 0.7037 (0.7073)  time: 0.0934  data: 0.0001  max mem: 10917
[13:40:03.295599] Test:  [344/345]  eta: 0:00:00  loss: 0.7037 (0.7073)  time: 0.0935  data: 0.0001  max mem: 10917
[13:40:03.353466] Test: Total time: 0:00:30 (0.0886 s / it)
[13:40:14.101674] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8794 (0.8794)  time: 0.2218  data: 0.1421  max mem: 10917
[13:40:14.914981] Test:  [10/57]  eta: 0:00:04  loss: 0.9135 (0.9256)  time: 0.0940  data: 0.0130  max mem: 10917
[13:40:15.731681] Test:  [20/57]  eta: 0:00:03  loss: 0.9135 (0.9104)  time: 0.0814  data: 0.0001  max mem: 10917
[13:40:16.552422] Test:  [30/57]  eta: 0:00:02  loss: 0.7984 (0.8673)  time: 0.0818  data: 0.0001  max mem: 10917
[13:40:17.377620] Test:  [40/57]  eta: 0:00:01  loss: 0.7821 (0.8444)  time: 0.0822  data: 0.0001  max mem: 10917
[13:40:18.205855] Test:  [50/57]  eta: 0:00:00  loss: 0.7706 (0.8370)  time: 0.0826  data: 0.0001  max mem: 10917
[13:40:18.655603] Test:  [56/57]  eta: 0:00:00  loss: 0.8083 (0.8448)  time: 0.0804  data: 0.0001  max mem: 10917
[13:40:18.712096] Test: Total time: 0:00:04 (0.0848 s / it)
[13:40:20.504284] Dice score of the network on the train images: 0.832214, val images: 0.809557
[13:40:20.507958] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:40:20.906992] Epoch: [49]  [  0/345]  eta: 0:02:17  lr: 0.000000  loss: 0.7433 (0.7433)  time: 0.3982  data: 0.1468  max mem: 10917
[13:40:25.908753] Epoch: [49]  [ 20/345]  eta: 0:01:23  lr: 0.000000  loss: 0.7381 (0.7391)  time: 0.2500  data: 0.0001  max mem: 10917
[13:40:30.912190] Epoch: [49]  [ 40/345]  eta: 0:01:17  lr: 0.000000  loss: 0.7375 (0.7400)  time: 0.2501  data: 0.0000  max mem: 10917
[13:40:35.918681] Epoch: [49]  [ 60/345]  eta: 0:01:11  lr: 0.000000  loss: 0.7337 (0.7380)  time: 0.2503  data: 0.0001  max mem: 10917
[13:40:40.926131] Epoch: [49]  [ 80/345]  eta: 0:01:06  lr: 0.000000  loss: 0.7337 (0.7367)  time: 0.2503  data: 0.0000  max mem: 10917
[13:40:45.946039] Epoch: [49]  [100/345]  eta: 0:01:01  lr: 0.000000  loss: 0.7356 (0.7362)  time: 0.2510  data: 0.0000  max mem: 10917
[13:40:50.966840] Epoch: [49]  [120/345]  eta: 0:00:56  lr: 0.000000  loss: 0.7383 (0.7370)  time: 0.2510  data: 0.0000  max mem: 10917
[13:40:55.984190] Epoch: [49]  [140/345]  eta: 0:00:51  lr: 0.000000  loss: 0.7334 (0.7370)  time: 0.2508  data: 0.0000  max mem: 10917
[13:41:00.998174] Epoch: [49]  [160/345]  eta: 0:00:46  lr: 0.000000  loss: 0.7341 (0.7369)  time: 0.2507  data: 0.0001  max mem: 10917
[13:41:06.008926] Epoch: [49]  [180/345]  eta: 0:00:41  lr: 0.000000  loss: 0.7304 (0.7365)  time: 0.2505  data: 0.0001  max mem: 10917
[13:41:11.019934] Epoch: [49]  [200/345]  eta: 0:00:36  lr: 0.000000  loss: 0.7435 (0.7373)  time: 0.2505  data: 0.0001  max mem: 10917
[13:41:16.030141] Epoch: [49]  [220/345]  eta: 0:00:31  lr: 0.000000  loss: 0.7302 (0.7370)  time: 0.2505  data: 0.0001  max mem: 10917
[13:41:21.048427] Epoch: [49]  [240/345]  eta: 0:00:26  lr: 0.000000  loss: 0.7435 (0.7374)  time: 0.2509  data: 0.0001  max mem: 10917
[13:41:26.068286] Epoch: [49]  [260/345]  eta: 0:00:21  lr: 0.000000  loss: 0.7330 (0.7377)  time: 0.2509  data: 0.0000  max mem: 10917
[13:41:31.089153] Epoch: [49]  [280/345]  eta: 0:00:16  lr: 0.000000  loss: 0.7345 (0.7377)  time: 0.2510  data: 0.0000  max mem: 10917
[13:41:36.114547] Epoch: [49]  [300/345]  eta: 0:00:11  lr: 0.000000  loss: 0.7353 (0.7376)  time: 0.2512  data: 0.0000  max mem: 10917
[13:41:41.139858] Epoch: [49]  [320/345]  eta: 0:00:06  lr: 0.000000  loss: 0.7390 (0.7379)  time: 0.2512  data: 0.0000  max mem: 10917
[13:41:46.168927] Epoch: [49]  [340/345]  eta: 0:00:01  lr: 0.000000  loss: 0.7281 (0.7375)  time: 0.2514  data: 0.0001  max mem: 10917
[13:41:47.175181] Epoch: [49]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.7313 (0.7375)  time: 0.2514  data: 0.0001  max mem: 10917
[13:41:47.233088] Epoch: [49] Total time: 0:01:26 (0.2514 s / it)
[13:41:47.233590] Averaged stats: lr: 0.000000  loss: 0.7313 (0.7375)
[13:41:47.473820] Test:  [  0/345]  eta: 0:01:21  loss: 0.7316 (0.7316)  time: 0.2373  data: 0.1571  max mem: 10917
[13:41:48.318657] Test:  [ 10/345]  eta: 0:00:32  loss: 0.7153 (0.7109)  time: 0.0983  data: 0.0167  max mem: 10917
[13:41:49.142406] Test:  [ 20/345]  eta: 0:00:29  loss: 0.7061 (0.7097)  time: 0.0833  data: 0.0014  max mem: 10917
[13:41:49.970317] Test:  [ 30/345]  eta: 0:00:27  loss: 0.7126 (0.7098)  time: 0.0825  data: 0.0001  max mem: 10917
[13:41:50.800642] Test:  [ 40/345]  eta: 0:00:26  loss: 0.7060 (0.7088)  time: 0.0829  data: 0.0001  max mem: 10917
[13:41:51.635737] Test:  [ 50/345]  eta: 0:00:25  loss: 0.7060 (0.7094)  time: 0.0832  data: 0.0001  max mem: 10917
[13:41:52.473978] Test:  [ 60/345]  eta: 0:00:24  loss: 0.7018 (0.7084)  time: 0.0836  data: 0.0001  max mem: 10917
[13:41:53.316395] Test:  [ 70/345]  eta: 0:00:23  loss: 0.7044 (0.7089)  time: 0.0840  data: 0.0001  max mem: 10917
[13:41:54.161534] Test:  [ 80/345]  eta: 0:00:22  loss: 0.7075 (0.7087)  time: 0.0843  data: 0.0001  max mem: 10917
[13:41:55.010782] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7063 (0.7082)  time: 0.0847  data: 0.0001  max mem: 10917
[13:41:55.862554] Test:  [100/345]  eta: 0:00:20  loss: 0.7091 (0.7086)  time: 0.0850  data: 0.0001  max mem: 10917
[13:41:56.718694] Test:  [110/345]  eta: 0:00:20  loss: 0.7040 (0.7079)  time: 0.0853  data: 0.0001  max mem: 10917
[13:41:57.578509] Test:  [120/345]  eta: 0:00:19  loss: 0.7056 (0.7082)  time: 0.0857  data: 0.0001  max mem: 10917
[13:41:58.441421] Test:  [130/345]  eta: 0:00:18  loss: 0.7121 (0.7087)  time: 0.0861  data: 0.0001  max mem: 10917
[13:41:59.307618] Test:  [140/345]  eta: 0:00:17  loss: 0.7119 (0.7088)  time: 0.0864  data: 0.0001  max mem: 10917
[13:42:00.178198] Test:  [150/345]  eta: 0:00:16  loss: 0.7060 (0.7084)  time: 0.0868  data: 0.0001  max mem: 10917
[13:42:01.052000] Test:  [160/345]  eta: 0:00:15  loss: 0.7044 (0.7086)  time: 0.0872  data: 0.0001  max mem: 10917
[13:42:01.929352] Test:  [170/345]  eta: 0:00:15  loss: 0.7069 (0.7086)  time: 0.0875  data: 0.0001  max mem: 10917
[13:42:02.811775] Test:  [180/345]  eta: 0:00:14  loss: 0.7058 (0.7084)  time: 0.0879  data: 0.0001  max mem: 10917
[13:42:03.695789] Test:  [190/345]  eta: 0:00:13  loss: 0.7071 (0.7085)  time: 0.0883  data: 0.0001  max mem: 10917
[13:42:04.583231] Test:  [200/345]  eta: 0:00:12  loss: 0.7071 (0.7084)  time: 0.0885  data: 0.0001  max mem: 10917
[13:42:05.474563] Test:  [210/345]  eta: 0:00:11  loss: 0.7048 (0.7084)  time: 0.0889  data: 0.0001  max mem: 10917
[13:42:06.369009] Test:  [220/345]  eta: 0:00:10  loss: 0.7024 (0.7081)  time: 0.0892  data: 0.0001  max mem: 10917
[13:42:07.266868] Test:  [230/345]  eta: 0:00:09  loss: 0.7039 (0.7082)  time: 0.0896  data: 0.0001  max mem: 10917
[13:42:08.169074] Test:  [240/345]  eta: 0:00:09  loss: 0.7120 (0.7083)  time: 0.0900  data: 0.0001  max mem: 10917
[13:42:09.074191] Test:  [250/345]  eta: 0:00:08  loss: 0.7034 (0.7079)  time: 0.0903  data: 0.0001  max mem: 10917
[13:42:09.982583] Test:  [260/345]  eta: 0:00:07  loss: 0.6999 (0.7079)  time: 0.0906  data: 0.0001  max mem: 10917
[13:42:10.895322] Test:  [270/345]  eta: 0:00:06  loss: 0.7050 (0.7079)  time: 0.0910  data: 0.0001  max mem: 10917
[13:42:11.810758] Test:  [280/345]  eta: 0:00:05  loss: 0.7063 (0.7079)  time: 0.0914  data: 0.0001  max mem: 10917
[13:42:12.730318] Test:  [290/345]  eta: 0:00:04  loss: 0.7037 (0.7078)  time: 0.0917  data: 0.0001  max mem: 10917
[13:42:13.652687] Test:  [300/345]  eta: 0:00:03  loss: 0.7037 (0.7077)  time: 0.0921  data: 0.0001  max mem: 10917
[13:42:14.578763] Test:  [310/345]  eta: 0:00:03  loss: 0.7072 (0.7076)  time: 0.0924  data: 0.0001  max mem: 10917
[13:42:15.508253] Test:  [320/345]  eta: 0:00:02  loss: 0.7040 (0.7076)  time: 0.0927  data: 0.0001  max mem: 10917
[13:42:16.440682] Test:  [330/345]  eta: 0:00:01  loss: 0.7040 (0.7075)  time: 0.0930  data: 0.0001  max mem: 10917
[13:42:17.377522] Test:  [340/345]  eta: 0:00:00  loss: 0.7117 (0.7076)  time: 0.0934  data: 0.0001  max mem: 10917
[13:42:17.753494] Test:  [344/345]  eta: 0:00:00  loss: 0.7117 (0.7076)  time: 0.0936  data: 0.0001  max mem: 10917
[13:42:17.811849] Test: Total time: 0:00:30 (0.0886 s / it)
[13:42:28.320017] Test:  [ 0/57]  eta: 0:00:12  loss: 0.8791 (0.8791)  time: 0.2258  data: 0.1457  max mem: 10917
[13:42:29.133215] Test:  [10/57]  eta: 0:00:04  loss: 0.9136 (0.9242)  time: 0.0944  data: 0.0133  max mem: 10917
[13:42:29.950847] Test:  [20/57]  eta: 0:00:03  loss: 0.9136 (0.9092)  time: 0.0815  data: 0.0001  max mem: 10917
[13:42:30.772996] Test:  [30/57]  eta: 0:00:02  loss: 0.7972 (0.8663)  time: 0.0819  data: 0.0001  max mem: 10917
[13:42:31.597754] Test:  [40/57]  eta: 0:00:01  loss: 0.7819 (0.8434)  time: 0.0823  data: 0.0001  max mem: 10917
[13:42:32.425603] Test:  [50/57]  eta: 0:00:00  loss: 0.7700 (0.8361)  time: 0.0826  data: 0.0001  max mem: 10917
[13:42:32.875670] Test:  [56/57]  eta: 0:00:00  loss: 0.8072 (0.8439)  time: 0.0804  data: 0.0001  max mem: 10917
[13:42:32.932925] Test: Total time: 0:00:04 (0.0849 s / it)
[13:42:34.741332] Dice score of the network on the train images: 0.830850, val images: 0.809929
[13:42:34.743158] Training time 1:52:24
[13:42:36.082801] Load pre-trained checkpoint from: /root/seg_framework/MS-Mamba/output_dir/mslesseg/checkpoints_0/checkpoint-best_dice_model_0.pth
[13:42:36.099325] <All keys matched successfully>
[13:42:36.541149] Test:  [  0/246]  eta: 0:01:33    time: 0.3805  data: 0.1758  max mem: 10917
[13:42:37.953937] Test:  [ 10/246]  eta: 0:00:38    time: 0.1630  data: 0.0161  max mem: 10917
[13:42:42.783571] ---------------------------------
[13:42:42.783795] Patient 1:
[13:42:42.783882]       precision: 0.4277286231517792
[13:42:42.783948]       recall: 0.5727452039718628
[13:42:42.784009]       dice_score: 0.4897269904613495
[13:42:42.787488] Test:  [ 20/246]  eta: 0:01:11    time: 0.3123  data: 0.0001  max mem: 10917
[13:42:44.193801] Test:  [ 30/246]  eta: 0:00:55    time: 0.3119  data: 0.0001  max mem: 10917
[13:42:49.006717] ---------------------------------
[13:42:49.006942] Patient 2:
[13:42:49.007021]       precision: 0.5285118222236633
[13:42:49.007086]       recall: 0.5754669308662415
[13:42:49.007148]       dice_score: 0.5509908199310303
[13:42:49.007696] Test:  [ 40/246]  eta: 0:01:04    time: 0.3110  data: 0.0001  max mem: 10917
[13:42:50.417489] Test:  [ 50/246]  eta: 0:00:54    time: 0.3111  data: 0.0001  max mem: 10917
[13:42:51.964968] Test:  [ 60/246]  eta: 0:00:48    time: 0.1478  data: 0.0001  max mem: 10917
[13:42:55.367383] ---------------------------------
[13:42:55.367604] Patient 3:
[13:42:55.367680]       precision: 0.36755111813545227
[13:42:55.367746]       recall: 0.46352165937423706
[13:42:55.367806]       dice_score: 0.4099951386451721
[13:42:56.618506] Test:  [ 70/246]  eta: 0:00:50    time: 0.3100  data: 0.0001  max mem: 10917
[13:42:58.166180] Test:  [ 80/246]  eta: 0:00:45    time: 0.3100  data: 0.0001  max mem: 10917
[13:43:01.563721] ---------------------------------
[13:43:01.563953] Patient 4:
[13:43:01.564034]       precision: 0.5293295979499817
[13:43:01.564099]       recall: 0.5739525556564331
[13:43:01.564161]       dice_score: 0.5507386922836304
[13:43:02.813603] Test:  [ 90/246]  eta: 0:00:45    time: 0.3097  data: 0.0001  max mem: 10917
[13:43:04.358789] Test:  [100/246]  eta: 0:00:40    time: 0.3096  data: 0.0001  max mem: 10917
[13:43:07.947592] ---------------------------------
[13:43:07.947812] Patient 5:
[13:43:07.947893]       precision: 0.36771106719970703
[13:43:07.947957]       recall: 0.46352165937423706
[13:43:07.948018]       dice_score: 0.41009464859962463
[13:43:09.042960] Test:  [110/246]  eta: 0:00:40    time: 0.3114  data: 0.0001  max mem: 10917
[13:43:10.588248] Test:  [120/246]  eta: 0:00:35    time: 0.3114  data: 0.0001  max mem: 10917
[13:43:14.145652] ---------------------------------
[13:43:14.145868] Patient 6:
[13:43:14.145943]       precision: 0.35872751474380493
[13:43:14.146007]       recall: 0.4701042175292969
[13:43:14.146067]       dice_score: 0.4069325625896454
[13:43:15.240275] Test:  [130/246]  eta: 0:00:34    time: 0.3098  data: 0.0001  max mem: 10917
[13:43:16.784390] Test:  [140/246]  eta: 0:00:30    time: 0.3098  data: 0.0001  max mem: 10917
[13:43:20.506708] ---------------------------------
[13:43:20.506936] Patient 7:
[13:43:20.507014]       precision: 0.735197126865387
[13:43:20.507079]       recall: 0.82041996717453
[13:43:20.507140]       dice_score: 0.7754741311073303
[13:43:21.447721] Test:  [150/246]  eta: 0:00:28    time: 0.3103  data: 0.0001  max mem: 10917
[13:43:22.989973] Test:  [160/246]  eta: 0:00:25    time: 0.3102  data: 0.0001  max mem: 10917
[13:43:26.728155] ---------------------------------
[13:43:26.728381] Patient 8:
[13:43:26.728458]       precision: 0.8515204787254333
[13:43:26.728524]       recall: 0.6243806481361389
[13:43:26.728584]       dice_score: 0.7204722166061401
[13:43:27.667142] Test:  [170/246]  eta: 0:00:22    time: 0.3109  data: 0.0001  max mem: 10917
[13:43:29.209612] Test:  [180/246]  eta: 0:00:19    time: 0.3109  data: 0.0001  max mem: 10917
[13:43:32.953359] ---------------------------------
[13:43:32.953575] Patient 9:
[13:43:32.953649]       precision: 0.6567471623420715
[13:43:32.953715]       recall: 0.8320685029029846
[13:43:32.953776]       dice_score: 0.7340850234031677
[13:43:33.891782] Test:  [190/246]  eta: 0:00:16    time: 0.3112  data: 0.0001  max mem: 10917
[13:43:35.431567] Test:  [200/246]  eta: 0:00:13    time: 0.3111  data: 0.0001  max mem: 10917
[13:43:39.354627] ---------------------------------
[13:43:39.354868] Patient 10:
[13:43:39.354952]       precision: 0.6589901447296143
[13:43:39.355020]       recall: 0.8304292559623718
[13:43:39.355083]       dice_score: 0.7348430156707764
[13:43:40.140344] Test:  [210/246]  eta: 0:00:10    time: 0.3124  data: 0.0001  max mem: 10917
[13:43:41.679030] Test:  [220/246]  eta: 0:00:07    time: 0.3123  data: 0.0001  max mem: 10917
[13:43:45.608952] ---------------------------------
[13:43:45.609174] Patient 11:
[13:43:45.609259]       precision: 0.8492491841316223
[13:43:45.609322]       recall: 0.8041023015975952
[13:43:45.609381]       dice_score: 0.8260593414306641
[13:43:46.393700] Test:  [230/246]  eta: 0:00:04    time: 0.3126  data: 0.0001  max mem: 10917
[13:43:47.934844] Test:  [240/246]  eta: 0:00:01    time: 0.3127  data: 0.0001  max mem: 10917
[13:43:51.886265] ---------------------------------
[13:43:51.886488] Patient 12:
[13:43:51.886564]       precision: 0.5921137928962708
[13:43:51.886630]       recall: 0.8259693384170532
[13:43:51.886689]       dice_score: 0.6897590160369873
[13:43:51.887056] Test:  [245/246]  eta: 0:00:00    time: 0.3128  data: 0.0001  max mem: 10917
[13:43:51.944434] Test: Total time: 0:01:15 (0.3081 s / it)
[13:43:51.944826] ================================
[13:43:51.944907] Averaged over all patients:
[13:43:51.945176]       precision: 0.5769 ± 0.1708
[13:43:51.945338]       recall: 0.6547 ± 0.1497
[13:43:51.945467]       dice_score: 0.6083 ± 0.1490
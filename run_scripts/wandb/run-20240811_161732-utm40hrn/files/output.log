Not using distributed mode
[16:17:34.884921] job dir: /root/seg_framework/MS-Mamba/run_scripts
[16:17:34.885069] Namespace(accum_iter=1,
model='SegFormer3D',
in_channels=1,
lr=None,
blr=0.001,
min_lr=0,
dist_on_itp=False,
warmup_epochs=20,
device='cuda:0',
seed=42,
layer_decay=0.75,
clip_grad=None,
num_workers=8,
pin_mem=True,
resume='',
mask_mode='concatenate to image',
world_size=1,
embed_dim=1,
local_rank=-1,
dist_url='env://',
nb_classes=2,
data_dir='/root/MSLesSeg24/data',
datalist=None,
preprocess=False,
dim=2,
distributed=False)
[16:17:34.885187] device  cuda:0
[16:17:34.886242] Starting for fold 0
[16:17:35.078861] Elements in data_dir_paths: 11052
[16:17:35.113795] Elements in data_dir_paths: 1803
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/segformer/fold_0/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/segformer/fold_0/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[16:17:36.941883] number of params: 47338583
[16:17:36.942133] model: Vivim2D(
  (encoder): mamba_block(
    (downsample_layers): SegformerEncoder(
      (patch_embeddings): ModuleList(
        (0): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (1): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (2): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (3): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (block): ModuleList(
        (0): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): Identity()
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.003703703870996833)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.007407407741993666)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.011111111380159855)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.014814815483987331)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.018518518656492233)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.02222222276031971)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (2): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.025925926864147186)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.029629630967974663)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03333333507180214)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03703703731298447)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04074074327945709)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04444444552063942)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.048148151487112045)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.051851850003004074)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0555555559694767)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.05925925821065903)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06296296417713165)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06666667014360428)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07037036865949631)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07407407462596893)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07777778059244156)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08148147910833359)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08518518507480621)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08888889104127884)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (3): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.09259259700775146)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0962962955236435)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.10000000149011612)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (layer_norm): ModuleList(
        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): SegformerDecodeHead(
    (linear_c): ModuleList(
      (0): SegformerMLP(
        (proj): Linear(in_features=64, out_features=768, bias=True)
      )
      (1): SegformerMLP(
        (proj): Linear(in_features=128, out_features=768, bias=True)
      )
      (2): SegformerMLP(
        (proj): Linear(in_features=320, out_features=768, bias=True)
      )
      (3): SegformerMLP(
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
    )
    (linear_fuse): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (batch_norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): ReLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Conv2d(768, 150, kernel_size=(1, 1), stride=(1, 1))
  )
  (out): Conv2d(768, 1, kernel_size=(1, 1), stride=(1, 1))
)
[16:17:36.944552] base lr: 1.00e-03
[16:17:36.944620] actual lr: 1.25e-04
[16:17:36.944679] accumulate grad iterations: 1
[16:17:36.944729] effective batch size: 32
[16:17:36.945926] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.000125
    maximize: False
    weight_decay: 0.01
)
[16:17:36.948109] Start training for 50 epochs
[16:17:36.948206] Number of samples in train dataloader:  345
[16:17:36.949982] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/segformer/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
[16:17:41.344023] Epoch: [0]  [  0/345]  eta: 0:25:15  lr: 0.000000  loss: 1.7300 (1.7300)  time: 4.3930  data: 0.5830  max mem: 11902
[16:17:46.137874] Epoch: [0]  [ 20/345]  eta: 0:02:22  lr: 0.000000  loss: 1.7256 (1.7245)  time: 0.2396  data: 0.0001  max mem: 11902
[16:17:50.951224] Epoch: [0]  [ 40/345]  eta: 0:01:44  lr: 0.000001  loss: 1.7185 (1.7226)  time: 0.2406  data: 0.0001  max mem: 11902
[16:17:55.771130] Epoch: [0]  [ 60/345]  eta: 0:01:27  lr: 0.000001  loss: 1.7201 (1.7219)  time: 0.2410  data: 0.0001  max mem: 11902
[16:18:00.606133] Epoch: [0]  [ 80/345]  eta: 0:01:17  lr: 0.000001  loss: 1.7117 (1.7195)  time: 0.2417  data: 0.0001  max mem: 11902
[16:18:05.456361] Epoch: [0]  [100/345]  eta: 0:01:09  lr: 0.000002  loss: 1.7073 (1.7169)  time: 0.2425  data: 0.0001  max mem: 11902
[16:18:10.313467] Epoch: [0]  [120/345]  eta: 0:01:02  lr: 0.000002  loss: 1.6995 (1.7141)  time: 0.2428  data: 0.0001  max mem: 11902
[16:18:15.177041] Epoch: [0]  [140/345]  eta: 0:00:55  lr: 0.000003  loss: 1.6885 (1.7107)  time: 0.2431  data: 0.0001  max mem: 11902
[16:18:20.050784] Epoch: [0]  [160/345]  eta: 0:00:49  lr: 0.000003  loss: 1.6800 (1.7067)  time: 0.2436  data: 0.0001  max mem: 11902
[16:18:24.932106] Epoch: [0]  [180/345]  eta: 0:00:43  lr: 0.000003  loss: 1.6567 (1.7013)  time: 0.2440  data: 0.0001  max mem: 11902
[16:18:29.816392] Epoch: [0]  [200/345]  eta: 0:00:38  lr: 0.000004  loss: 1.6302 (1.6942)  time: 0.2442  data: 0.0001  max mem: 11902
[16:18:34.706268] Epoch: [0]  [220/345]  eta: 0:00:32  lr: 0.000004  loss: 1.5926 (1.6853)  time: 0.2445  data: 0.0001  max mem: 11902
[16:18:39.595868] Epoch: [0]  [240/345]  eta: 0:00:27  lr: 0.000004  loss: 1.5326 (1.6729)  time: 0.2444  data: 0.0001  max mem: 11902
[16:18:44.492390] Epoch: [0]  [260/345]  eta: 0:00:21  lr: 0.000005  loss: 1.4558 (1.6562)  time: 0.2448  data: 0.0001  max mem: 11902
[16:18:49.390984] Epoch: [0]  [280/345]  eta: 0:00:16  lr: 0.000005  loss: 1.3852 (1.6369)  time: 0.2449  data: 0.0001  max mem: 11902
[16:18:54.287706] Epoch: [0]  [300/345]  eta: 0:00:11  lr: 0.000005  loss: 1.3327 (1.6173)  time: 0.2448  data: 0.0001  max mem: 11902
[16:18:59.265761] Epoch: [0]  [320/345]  eta: 0:00:06  lr: 0.000006  loss: 1.2674 (1.5965)  time: 0.2489  data: 0.0001  max mem: 11902
[16:19:04.160600] Epoch: [0]  [340/345]  eta: 0:00:01  lr: 0.000006  loss: 1.2545 (1.5774)  time: 0.2447  data: 0.0001  max mem: 11902
[16:19:05.141080] Epoch: [0]  [344/345]  eta: 0:00:00  lr: 0.000006  loss: 1.2524 (1.5735)  time: 0.2447  data: 0.0001  max mem: 11902
[16:19:05.212187] Epoch: [0] Total time: 0:01:28 (0.2558 s / it)
[16:19:05.212393] Averaged stats: lr: 0.000006  loss: 1.2524 (1.5735)
[16:19:05.742235] Test:  [  0/345]  eta: 0:03:01  loss: 1.2130 (1.2130)  time: 0.5260  data: 0.4414  max mem: 11902
[16:19:06.534801] Test:  [ 10/345]  eta: 0:00:40  loss: 1.2290 (1.2387)  time: 0.1197  data: 0.0402  max mem: 11902
[16:19:07.332591] Test:  [ 20/345]  eta: 0:00:32  loss: 1.2290 (1.2343)  time: 0.0794  data: 0.0001  max mem: 11902
[16:19:08.134119] Test:  [ 30/345]  eta: 0:00:29  loss: 1.2327 (1.2395)  time: 0.0799  data: 0.0001  max mem: 11902
[16:19:08.937941] Test:  [ 40/345]  eta: 0:00:27  loss: 1.2192 (1.2338)  time: 0.0802  data: 0.0001  max mem: 11902
[16:19:09.742988] Test:  [ 50/345]  eta: 0:00:26  loss: 1.2160 (1.2299)  time: 0.0804  data: 0.0001  max mem: 11902
[16:19:10.554333] Test:  [ 60/345]  eta: 0:00:24  loss: 1.2373 (1.2363)  time: 0.0807  data: 0.0001  max mem: 11902
[16:19:11.368426] Test:  [ 70/345]  eta: 0:00:23  loss: 1.2373 (1.2351)  time: 0.0812  data: 0.0001  max mem: 11902
[16:19:12.186255] Test:  [ 80/345]  eta: 0:00:22  loss: 1.2160 (1.2337)  time: 0.0815  data: 0.0001  max mem: 11902
[16:19:13.008328] Test:  [ 90/345]  eta: 0:00:21  loss: 1.2250 (1.2321)  time: 0.0819  data: 0.0001  max mem: 11902
[16:19:13.832969] Test:  [100/345]  eta: 0:00:20  loss: 1.2250 (1.2308)  time: 0.0823  data: 0.0001  max mem: 11902
[16:19:14.662097] Test:  [110/345]  eta: 0:00:19  loss: 1.2207 (1.2330)  time: 0.0826  data: 0.0001  max mem: 11902
[16:19:15.494118] Test:  [120/345]  eta: 0:00:19  loss: 1.2394 (1.2342)  time: 0.0830  data: 0.0001  max mem: 11902
[16:19:16.330178] Test:  [130/345]  eta: 0:00:18  loss: 1.2394 (1.2340)  time: 0.0833  data: 0.0001  max mem: 11902
[16:19:17.169683] Test:  [140/345]  eta: 0:00:17  loss: 1.2072 (1.2318)  time: 0.0837  data: 0.0001  max mem: 11902
[16:19:18.012909] Test:  [150/345]  eta: 0:00:16  loss: 1.2050 (1.2304)  time: 0.0841  data: 0.0001  max mem: 11902
[16:19:18.859836] Test:  [160/345]  eta: 0:00:15  loss: 1.2109 (1.2300)  time: 0.0844  data: 0.0001  max mem: 11902
[16:19:19.710702] Test:  [170/345]  eta: 0:00:14  loss: 1.1956 (1.2287)  time: 0.0848  data: 0.0001  max mem: 11902
[16:19:20.564165] Test:  [180/345]  eta: 0:00:13  loss: 1.1956 (1.2274)  time: 0.0851  data: 0.0001  max mem: 11902
[16:19:21.421972] Test:  [190/345]  eta: 0:00:13  loss: 1.2110 (1.2277)  time: 0.0855  data: 0.0001  max mem: 11902
[16:19:22.282756] Test:  [200/345]  eta: 0:00:12  loss: 1.2216 (1.2272)  time: 0.0859  data: 0.0001  max mem: 11902
[16:19:23.438329] Test:  [210/345]  eta: 0:00:11  loss: 1.2337 (1.2285)  time: 0.1008  data: 0.0001  max mem: 11902
[16:19:24.342791] Test:  [220/345]  eta: 0:00:10  loss: 1.2337 (1.2280)  time: 0.1029  data: 0.0001  max mem: 11902
[16:19:25.369741] Test:  [230/345]  eta: 0:00:10  loss: 1.2113 (1.2275)  time: 0.0965  data: 0.0001  max mem: 11902
[16:19:26.273074] Test:  [240/345]  eta: 0:00:09  loss: 1.2129 (1.2273)  time: 0.0964  data: 0.0001  max mem: 11902
[16:19:27.405928] Test:  [250/345]  eta: 0:00:08  loss: 1.2373 (1.2281)  time: 0.1017  data: 0.0001  max mem: 11902
[16:19:28.553091] Test:  [260/345]  eta: 0:00:07  loss: 1.2226 (1.2271)  time: 0.1139  data: 0.0001  max mem: 11902
[16:19:29.464468] Test:  [270/345]  eta: 0:00:06  loss: 1.2128 (1.2275)  time: 0.1029  data: 0.0001  max mem: 11902
[16:19:30.641700] Test:  [280/345]  eta: 0:00:05  loss: 1.2176 (1.2272)  time: 0.1044  data: 0.0001  max mem: 11902
[16:19:31.754667] Test:  [290/345]  eta: 0:00:05  loss: 1.2148 (1.2271)  time: 0.1144  data: 0.0001  max mem: 11902
[16:19:33.006599] Test:  [300/345]  eta: 0:00:04  loss: 1.2331 (1.2275)  time: 0.1182  data: 0.0001  max mem: 11902
[16:19:34.164640] Test:  [310/345]  eta: 0:00:03  loss: 1.2393 (1.2278)  time: 0.1204  data: 0.0001  max mem: 11902
[16:19:35.294794] Test:  [320/345]  eta: 0:00:02  loss: 1.2378 (1.2285)  time: 0.1143  data: 0.0001  max mem: 11902
[16:19:36.313401] Test:  [330/345]  eta: 0:00:01  loss: 1.2255 (1.2282)  time: 0.1074  data: 0.0001  max mem: 11902
[16:19:37.619968] Test:  [340/345]  eta: 0:00:00  loss: 1.2195 (1.2282)  time: 0.1162  data: 0.0001  max mem: 11902
[16:19:38.413049] Test:  [344/345]  eta: 0:00:00  loss: 1.2371 (1.2284)  time: 0.1363  data: 0.0001  max mem: 11902
[16:19:38.487129] Test: Total time: 0:00:33 (0.0964 s / it)
[16:19:48.634783] Test:  [ 0/57]  eta: 0:00:26  loss: 1.2107 (1.2107)  time: 0.4635  data: 0.3865  max mem: 11902
[16:19:49.421674] Test:  [10/57]  eta: 0:00:05  loss: 1.2148 (1.2767)  time: 0.1136  data: 0.0353  max mem: 11902
[16:19:50.213807] Test:  [20/57]  eta: 0:00:03  loss: 1.1978 (1.2559)  time: 0.0789  data: 0.0001  max mem: 11902
[16:19:51.007552] Test:  [30/57]  eta: 0:00:02  loss: 1.1210 (1.2082)  time: 0.0792  data: 0.0001  max mem: 11902
[16:19:51.804395] Test:  [40/57]  eta: 0:00:01  loss: 1.1043 (1.1854)  time: 0.0795  data: 0.0001  max mem: 11902
[16:19:52.605456] Test:  [50/57]  eta: 0:00:00  loss: 1.1047 (1.1839)  time: 0.0798  data: 0.0001  max mem: 11902
[16:19:53.471153] Test:  [56/57]  eta: 0:00:00  loss: 1.1362 (1.1933)  time: 0.0992  data: 0.0001  max mem: 11902
[16:19:53.543233] Test: Total time: 0:00:05 (0.0943 s / it)
[16:19:55.420052] Dice score of the network on the train images: 0.051473, val images: 0.121929
[16:19:55.420299] saving best_prec_model_0 @ epoch 0
[16:19:56.147129] saving best_rec_model_0 @ epoch 0
[16:19:56.832382] saving best_dice_model_0 @ epoch 0
[16:19:57.513472] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:19:58.096247] Epoch: [1]  [  0/345]  eta: 0:03:20  lr: 0.000006  loss: 1.3578 (1.3578)  time: 0.5817  data: 0.3223  max mem: 11902
[16:20:02.966644] Epoch: [1]  [ 20/345]  eta: 0:01:24  lr: 0.000007  loss: 1.2662 (1.2589)  time: 0.2435  data: 0.0001  max mem: 11902
[16:20:07.839779] Epoch: [1]  [ 40/345]  eta: 0:01:16  lr: 0.000007  loss: 1.2037 (1.2354)  time: 0.2436  data: 0.0001  max mem: 11902
[16:20:12.721274] Epoch: [1]  [ 60/345]  eta: 0:01:11  lr: 0.000007  loss: 1.2060 (1.2288)  time: 0.2440  data: 0.0001  max mem: 11902
[16:20:17.603703] Epoch: [1]  [ 80/345]  eta: 0:01:05  lr: 0.000008  loss: 1.1654 (1.2162)  time: 0.2441  data: 0.0001  max mem: 11902
[16:20:22.489948] Epoch: [1]  [100/345]  eta: 0:01:00  lr: 0.000008  loss: 1.1620 (1.2060)  time: 0.2443  data: 0.0001  max mem: 11902
[16:20:27.380462] Epoch: [1]  [120/345]  eta: 0:00:55  lr: 0.000008  loss: 1.1607 (1.1991)  time: 0.2445  data: 0.0001  max mem: 11902
[16:20:32.268458] Epoch: [1]  [140/345]  eta: 0:00:50  lr: 0.000009  loss: 1.1254 (1.1907)  time: 0.2444  data: 0.0001  max mem: 11902
[16:20:37.154143] Epoch: [1]  [160/345]  eta: 0:00:45  lr: 0.000009  loss: 1.1022 (1.1807)  time: 0.2442  data: 0.0001  max mem: 11902
[16:20:42.043304] Epoch: [1]  [180/345]  eta: 0:00:40  lr: 0.000010  loss: 1.1130 (1.1739)  time: 0.2444  data: 0.0001  max mem: 11902
[16:20:46.931033] Epoch: [1]  [200/345]  eta: 0:00:35  lr: 0.000010  loss: 1.0867 (1.1669)  time: 0.2443  data: 0.0001  max mem: 11902
[16:20:51.824720] Epoch: [1]  [220/345]  eta: 0:00:30  lr: 0.000010  loss: 1.0622 (1.1583)  time: 0.2446  data: 0.0001  max mem: 11902
[16:20:56.721831] Epoch: [1]  [240/345]  eta: 0:00:25  lr: 0.000011  loss: 1.0563 (1.1512)  time: 0.2448  data: 0.0001  max mem: 11902
[16:21:01.620635] Epoch: [1]  [260/345]  eta: 0:00:20  lr: 0.000011  loss: 1.0546 (1.1449)  time: 0.2449  data: 0.0001  max mem: 11902
[16:21:06.520046] Epoch: [1]  [280/345]  eta: 0:00:15  lr: 0.000011  loss: 1.0516 (1.1392)  time: 0.2449  data: 0.0001  max mem: 11902
[16:21:11.431258] Epoch: [1]  [300/345]  eta: 0:00:11  lr: 0.000012  loss: 1.0282 (1.1325)  time: 0.2455  data: 0.0001  max mem: 11902
[16:21:16.341976] Epoch: [1]  [320/345]  eta: 0:00:06  lr: 0.000012  loss: 1.0326 (1.1273)  time: 0.2455  data: 0.0001  max mem: 11902
[16:21:21.250169] Epoch: [1]  [340/345]  eta: 0:00:01  lr: 0.000012  loss: 1.0241 (1.1215)  time: 0.2454  data: 0.0001  max mem: 11902
[16:21:22.231184] Epoch: [1]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 1.0190 (1.1200)  time: 0.2452  data: 0.0001  max mem: 11902
[16:21:22.314731] Epoch: [1] Total time: 0:01:24 (0.2458 s / it)
[16:21:22.315258] Averaged stats: lr: 0.000012  loss: 1.0190 (1.1200)
[16:21:22.742918] Test:  [  0/345]  eta: 0:02:25  loss: 1.0080 (1.0080)  time: 0.4231  data: 0.3457  max mem: 11902
[16:21:23.539964] Test:  [ 10/345]  eta: 0:00:37  loss: 1.0076 (1.0050)  time: 0.1108  data: 0.0317  max mem: 11902
[16:21:24.337539] Test:  [ 20/345]  eta: 0:00:31  loss: 1.0036 (1.0019)  time: 0.0796  data: 0.0002  max mem: 11902
[16:21:25.137557] Test:  [ 30/345]  eta: 0:00:28  loss: 0.9970 (1.0069)  time: 0.0798  data: 0.0001  max mem: 11902
[16:21:25.942209] Test:  [ 40/345]  eta: 0:00:26  loss: 0.9970 (1.0075)  time: 0.0802  data: 0.0001  max mem: 11902
[16:21:26.750207] Test:  [ 50/345]  eta: 0:00:25  loss: 0.9906 (1.0021)  time: 0.0806  data: 0.0001  max mem: 11902
[16:21:27.561768] Test:  [ 60/345]  eta: 0:00:24  loss: 0.9838 (1.0000)  time: 0.0809  data: 0.0001  max mem: 11902
[16:21:28.377215] Test:  [ 70/345]  eta: 0:00:23  loss: 1.0011 (1.0021)  time: 0.0813  data: 0.0001  max mem: 11902
[16:21:29.195835] Test:  [ 80/345]  eta: 0:00:22  loss: 1.0043 (1.0017)  time: 0.0816  data: 0.0001  max mem: 11902
[16:21:30.016975] Test:  [ 90/345]  eta: 0:00:21  loss: 0.9963 (1.0021)  time: 0.0819  data: 0.0001  max mem: 11902
[16:21:30.842859] Test:  [100/345]  eta: 0:00:20  loss: 1.0007 (1.0024)  time: 0.0823  data: 0.0001  max mem: 11902
[16:21:31.672203] Test:  [110/345]  eta: 0:00:19  loss: 1.0007 (1.0030)  time: 0.0827  data: 0.0001  max mem: 11902
[16:21:32.504329] Test:  [120/345]  eta: 0:00:18  loss: 1.0253 (1.0061)  time: 0.0830  data: 0.0001  max mem: 11902
[16:21:33.340570] Test:  [130/345]  eta: 0:00:18  loss: 1.0223 (1.0066)  time: 0.0833  data: 0.0001  max mem: 11902
[16:21:34.180323] Test:  [140/345]  eta: 0:00:17  loss: 1.0129 (1.0064)  time: 0.0837  data: 0.0001  max mem: 11902
[16:21:35.023416] Test:  [150/345]  eta: 0:00:16  loss: 0.9949 (1.0054)  time: 0.0841  data: 0.0001  max mem: 11902
[16:21:35.869832] Test:  [160/345]  eta: 0:00:15  loss: 0.9909 (1.0047)  time: 0.0844  data: 0.0001  max mem: 11902
[16:21:36.720124] Test:  [170/345]  eta: 0:00:14  loss: 0.9854 (1.0035)  time: 0.0848  data: 0.0001  max mem: 11902
[16:21:37.573480] Test:  [180/345]  eta: 0:00:13  loss: 0.9868 (1.0035)  time: 0.0851  data: 0.0001  max mem: 11902
[16:21:38.430775] Test:  [190/345]  eta: 0:00:13  loss: 0.9868 (1.0030)  time: 0.0855  data: 0.0001  max mem: 11902
[16:21:39.292134] Test:  [200/345]  eta: 0:00:12  loss: 0.9706 (1.0018)  time: 0.0859  data: 0.0001  max mem: 11902
[16:21:40.157030] Test:  [210/345]  eta: 0:00:11  loss: 0.9758 (1.0018)  time: 0.0863  data: 0.0001  max mem: 11902
[16:21:41.288224] Test:  [220/345]  eta: 0:00:10  loss: 0.9839 (1.0017)  time: 0.0997  data: 0.0001  max mem: 11902
[16:21:42.191066] Test:  [230/345]  eta: 0:00:09  loss: 0.9957 (1.0023)  time: 0.1016  data: 0.0001  max mem: 11902
[16:21:43.065800] Test:  [240/345]  eta: 0:00:09  loss: 1.0180 (1.0037)  time: 0.0888  data: 0.0001  max mem: 11902
[16:21:44.109470] Test:  [250/345]  eta: 0:00:08  loss: 1.0111 (1.0033)  time: 0.0959  data: 0.0001  max mem: 11902
[16:21:45.001307] Test:  [260/345]  eta: 0:00:07  loss: 0.9842 (1.0031)  time: 0.0967  data: 0.0001  max mem: 11902
[16:21:46.060152] Test:  [270/345]  eta: 0:00:06  loss: 0.9842 (1.0022)  time: 0.0975  data: 0.0001  max mem: 11902
[16:21:46.966112] Test:  [280/345]  eta: 0:00:05  loss: 0.9938 (1.0033)  time: 0.0982  data: 0.0001  max mem: 11902
[16:21:48.031195] Test:  [290/345]  eta: 0:00:04  loss: 1.0117 (1.0031)  time: 0.0985  data: 0.0001  max mem: 11902
[16:21:48.941429] Test:  [300/345]  eta: 0:00:03  loss: 0.9865 (1.0030)  time: 0.0987  data: 0.0001  max mem: 11902
[16:21:50.047806] Test:  [310/345]  eta: 0:00:03  loss: 1.0144 (1.0033)  time: 0.1008  data: 0.0001  max mem: 11902
[16:21:51.200936] Test:  [320/345]  eta: 0:00:02  loss: 1.0152 (1.0042)  time: 0.1129  data: 0.0001  max mem: 11902
[16:21:52.142252] Test:  [330/345]  eta: 0:00:01  loss: 0.9962 (1.0033)  time: 0.1047  data: 0.0001  max mem: 11902
[16:21:53.272321] Test:  [340/345]  eta: 0:00:00  loss: 0.9722 (1.0024)  time: 0.1035  data: 0.0001  max mem: 11902
[16:21:53.716736] Test:  [344/345]  eta: 0:00:00  loss: 0.9797 (1.0030)  time: 0.1068  data: 0.0001  max mem: 11902
[16:21:53.797034] Test: Total time: 0:00:31 (0.0912 s / it)
[16:22:03.679703] Test:  [ 0/57]  eta: 0:00:23  loss: 1.0005 (1.0005)  time: 0.4122  data: 0.3350  max mem: 11902
[16:22:04.468682] Test:  [10/57]  eta: 0:00:05  loss: 1.0264 (1.0859)  time: 0.1091  data: 0.0305  max mem: 11902
[16:22:05.258738] Test:  [20/57]  eta: 0:00:03  loss: 0.9969 (1.0522)  time: 0.0789  data: 0.0001  max mem: 11902
[16:22:06.055105] Test:  [30/57]  eta: 0:00:02  loss: 0.8731 (0.9777)  time: 0.0793  data: 0.0001  max mem: 11902
[16:22:06.854276] Test:  [40/57]  eta: 0:00:01  loss: 0.8213 (0.9394)  time: 0.0797  data: 0.0001  max mem: 11902
[16:22:07.657176] Test:  [50/57]  eta: 0:00:00  loss: 0.8355 (0.9330)  time: 0.0800  data: 0.0001  max mem: 11902
[16:22:08.093022] Test:  [56/57]  eta: 0:00:00  loss: 0.9259 (0.9474)  time: 0.0779  data: 0.0000  max mem: 11902
[16:22:08.156863] Test: Total time: 0:00:04 (0.0858 s / it)
[16:22:09.814132] Dice score of the network on the train images: 0.185415, val images: 0.252861
[16:22:09.814370] saving best_prec_model_0 @ epoch 1
[16:22:10.814488] saving best_rec_model_0 @ epoch 1
[16:22:11.860176] saving best_dice_model_0 @ epoch 1
[16:22:12.784765] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:22:13.424891] Epoch: [2]  [  0/345]  eta: 0:03:40  lr: 0.000013  loss: 1.0123 (1.0123)  time: 0.6390  data: 0.3869  max mem: 11902
[16:22:18.294459] Epoch: [2]  [ 20/345]  eta: 0:01:25  lr: 0.000013  loss: 1.0050 (1.0159)  time: 0.2434  data: 0.0001  max mem: 11902
[16:22:23.168674] Epoch: [2]  [ 40/345]  eta: 0:01:17  lr: 0.000013  loss: 0.9816 (1.0012)  time: 0.2437  data: 0.0001  max mem: 11902
[16:22:28.052718] Epoch: [2]  [ 60/345]  eta: 0:01:11  lr: 0.000014  loss: 1.0092 (1.0029)  time: 0.2442  data: 0.0001  max mem: 11902
[16:22:32.930233] Epoch: [2]  [ 80/345]  eta: 0:01:05  lr: 0.000014  loss: 0.9614 (0.9952)  time: 0.2438  data: 0.0001  max mem: 11902
[16:22:37.814730] Epoch: [2]  [100/345]  eta: 0:01:00  lr: 0.000014  loss: 0.9477 (0.9898)  time: 0.2442  data: 0.0001  max mem: 11902
[16:22:42.703718] Epoch: [2]  [120/345]  eta: 0:00:55  lr: 0.000015  loss: 0.9546 (0.9858)  time: 0.2444  data: 0.0001  max mem: 11902
[16:22:47.583753] Epoch: [2]  [140/345]  eta: 0:00:50  lr: 0.000015  loss: 0.9388 (0.9814)  time: 0.2440  data: 0.0001  max mem: 11902
[16:22:52.461609] Epoch: [2]  [160/345]  eta: 0:00:45  lr: 0.000015  loss: 0.9522 (0.9777)  time: 0.2438  data: 0.0001  max mem: 11902
[16:22:57.350918] Epoch: [2]  [180/345]  eta: 0:00:40  lr: 0.000016  loss: 0.9284 (0.9722)  time: 0.2444  data: 0.0001  max mem: 11902
[16:23:02.245922] Epoch: [2]  [200/345]  eta: 0:00:35  lr: 0.000016  loss: 0.9174 (0.9665)  time: 0.2447  data: 0.0001  max mem: 11902

[16:23:07.139536] Epoch: [2]  [220/345]  eta: 0:00:30  lr: 0.000016  loss: 0.8809 (0.9599)  time: 0.2446  data: 0.0001  max mem: 11902
[16:23:12.038977] Epoch: [2]  [240/345]  eta: 0:00:25  lr: 0.000017  loss: 0.9070 (0.9554)  time: 0.2449  data: 0.0000  max mem: 11902
[16:23:16.936799] Epoch: [2]  [260/345]  eta: 0:00:20  lr: 0.000017  loss: 0.9070 (0.9522)  time: 0.2448  data: 0.0001  max mem: 11902
[16:23:21.840596] Epoch: [2]  [280/345]  eta: 0:00:15  lr: 0.000018  loss: 0.8918 (0.9479)  time: 0.2451  data: 0.0001  max mem: 11902
[16:23:26.749446] Epoch: [2]  [300/345]  eta: 0:00:11  lr: 0.000018  loss: 0.8751 (0.9433)  time: 0.2454  data: 0.0001  max mem: 11902
[16:23:31.655793] Epoch: [2]  [320/345]  eta: 0:00:06  lr: 0.000018  loss: 0.8634 (0.9390)  time: 0.2453  data: 0.0001  max mem: 11902
[16:23:36.559485] Epoch: [2]  [340/345]  eta: 0:00:01  lr: 0.000019  loss: 0.8390 (0.9336)  time: 0.2451  data: 0.0001  max mem: 11902
[16:23:37.540955] Epoch: [2]  [344/345]  eta: 0:00:00  lr: 0.000019  loss: 0.8399 (0.9330)  time: 0.2451  data: 0.0001  max mem: 11902
[16:23:37.612010] Epoch: [2] Total time: 0:01:24 (0.2459 s / it)
[16:23:37.612380] Averaged stats: lr: 0.000019  loss: 0.8399 (0.9330)
[16:23:38.051373] Test:  [  0/345]  eta: 0:02:29  loss: 0.7910 (0.7910)  time: 0.4345  data: 0.3573  max mem: 11902
[16:23:38.848013] Test:  [ 10/345]  eta: 0:00:37  loss: 0.8011 (0.8120)  time: 0.1118  data: 0.0329  max mem: 11902
[16:23:39.647534] Test:  [ 20/345]  eta: 0:00:31  loss: 0.8100 (0.8191)  time: 0.0797  data: 0.0003  max mem: 11902
[16:23:40.450135] Test:  [ 30/345]  eta: 0:00:28  loss: 0.8281 (0.8216)  time: 0.0800  data: 0.0001  max mem: 11902
[16:23:41.252870] Test:  [ 40/345]  eta: 0:00:27  loss: 0.8246 (0.8174)  time: 0.0802  data: 0.0001  max mem: 11902
[16:23:42.061323] Test:  [ 50/345]  eta: 0:00:25  loss: 0.8246 (0.8242)  time: 0.0805  data: 0.0001  max mem: 11902
[16:23:42.873186] Test:  [ 60/345]  eta: 0:00:24  loss: 0.8042 (0.8203)  time: 0.0809  data: 0.0001  max mem: 11902
[16:23:43.688531] Test:  [ 70/345]  eta: 0:00:23  loss: 0.8052 (0.8230)  time: 0.0813  data: 0.0001  max mem: 11902
[16:23:44.506186] Test:  [ 80/345]  eta: 0:00:22  loss: 0.8374 (0.8232)  time: 0.0816  data: 0.0001  max mem: 11902
[16:23:45.327716] Test:  [ 90/345]  eta: 0:00:21  loss: 0.8147 (0.8228)  time: 0.0819  data: 0.0001  max mem: 11902
[16:23:46.152828] Test:  [100/345]  eta: 0:00:20  loss: 0.8148 (0.8239)  time: 0.0823  data: 0.0001  max mem: 11902
[16:23:46.982421] Test:  [110/345]  eta: 0:00:19  loss: 0.8161 (0.8240)  time: 0.0826  data: 0.0001  max mem: 11902
[16:23:47.815762] Test:  [120/345]  eta: 0:00:18  loss: 0.8119 (0.8220)  time: 0.0831  data: 0.0001  max mem: 11902
[16:23:48.651970] Test:  [130/345]  eta: 0:00:18  loss: 0.8100 (0.8222)  time: 0.0834  data: 0.0001  max mem: 11902
[16:23:49.491186] Test:  [140/345]  eta: 0:00:17  loss: 0.8176 (0.8216)  time: 0.0837  data: 0.0001  max mem: 11902
[16:23:50.334795] Test:  [150/345]  eta: 0:00:16  loss: 0.7976 (0.8207)  time: 0.0841  data: 0.0001  max mem: 11902
[16:23:51.182671] Test:  [160/345]  eta: 0:00:15  loss: 0.7992 (0.8203)  time: 0.0845  data: 0.0001  max mem: 11902
[16:23:52.034136] Test:  [170/345]  eta: 0:00:14  loss: 0.8099 (0.8203)  time: 0.0849  data: 0.0001  max mem: 11902
[16:23:52.887059] Test:  [180/345]  eta: 0:00:13  loss: 0.8053 (0.8190)  time: 0.0852  data: 0.0001  max mem: 11902
[16:23:53.745051] Test:  [190/345]  eta: 0:00:13  loss: 0.7973 (0.8183)  time: 0.0855  data: 0.0001  max mem: 11902
[16:23:54.606942] Test:  [200/345]  eta: 0:00:12  loss: 0.7914 (0.8167)  time: 0.0859  data: 0.0001  max mem: 11902
[16:23:55.472850] Test:  [210/345]  eta: 0:00:11  loss: 0.7914 (0.8171)  time: 0.0863  data: 0.0001  max mem: 11902
[16:23:56.341548] Test:  [220/345]  eta: 0:00:10  loss: 0.8307 (0.8171)  time: 0.0867  data: 0.0001  max mem: 11902
[16:23:57.213929] Test:  [230/345]  eta: 0:00:09  loss: 0.8128 (0.8171)  time: 0.0870  data: 0.0001  max mem: 11902
[16:23:58.090962] Test:  [240/345]  eta: 0:00:08  loss: 0.7936 (0.8167)  time: 0.0874  data: 0.0001  max mem: 11902
[16:23:58.970429] Test:  [250/345]  eta: 0:00:08  loss: 0.8179 (0.8169)  time: 0.0877  data: 0.0001  max mem: 11902
[16:23:59.852989] Test:  [260/345]  eta: 0:00:07  loss: 0.8119 (0.8161)  time: 0.0880  data: 0.0001  max mem: 11902
[16:24:00.738833] Test:  [270/345]  eta: 0:00:06  loss: 0.7973 (0.8167)  time: 0.0883  data: 0.0001  max mem: 11902
[16:24:01.628447] Test:  [280/345]  eta: 0:00:05  loss: 0.8049 (0.8160)  time: 0.0887  data: 0.0001  max mem: 11902
[16:24:02.521223] Test:  [290/345]  eta: 0:00:04  loss: 0.8217 (0.8172)  time: 0.0891  data: 0.0001  max mem: 11902
[16:24:03.417171] Test:  [300/345]  eta: 0:00:03  loss: 0.8554 (0.8180)  time: 0.0894  data: 0.0001  max mem: 11902
[16:24:04.317194] Test:  [310/345]  eta: 0:00:03  loss: 0.8206 (0.8181)  time: 0.0897  data: 0.0001  max mem: 11902
[16:24:05.220684] Test:  [320/345]  eta: 0:00:02  loss: 0.8278 (0.8190)  time: 0.0901  data: 0.0001  max mem: 11902
[16:24:06.127791] Test:  [330/345]  eta: 0:00:01  loss: 0.8431 (0.8197)  time: 0.0905  data: 0.0001  max mem: 11902
[16:24:07.039651] Test:  [340/345]  eta: 0:00:00  loss: 0.8429 (0.8206)  time: 0.0909  data: 0.0001  max mem: 11902
[16:24:07.404785] Test:  [344/345]  eta: 0:00:00  loss: 0.8707 (0.8211)  time: 0.0910  data: 0.0001  max mem: 11902
[16:24:07.471319] Test: Total time: 0:00:29 (0.0865 s / it)
[16:24:17.275527] Test:  [ 0/57]  eta: 0:00:23  loss: 0.8658 (0.8658)  time: 0.4118  data: 0.3346  max mem: 11902
[16:24:18.063486] Test:  [10/57]  eta: 0:00:05  loss: 0.8208 (0.8845)  time: 0.1090  data: 0.0305  max mem: 11902
[16:24:18.855233] Test:  [20/57]  eta: 0:00:03  loss: 0.8202 (0.8619)  time: 0.0789  data: 0.0001  max mem: 11902
[16:24:19.652350] Test:  [30/57]  eta: 0:00:02  loss: 0.6875 (0.7797)  time: 0.0794  data: 0.0001  max mem: 11902
[16:24:20.453556] Test:  [40/57]  eta: 0:00:01  loss: 0.6021 (0.7351)  time: 0.0799  data: 0.0001  max mem: 11902
[16:24:21.256683] Test:  [50/57]  eta: 0:00:00  loss: 0.6594 (0.7315)  time: 0.0802  data: 0.0001  max mem: 11902
[16:24:21.691678] Test:  [56/57]  eta: 0:00:00  loss: 0.7401 (0.7533)  time: 0.0779  data: 0.0000  max mem: 11902
[16:24:21.753268] Test: Total time: 0:00:04 (0.0858 s / it)
[16:24:23.397607] Dice score of the network on the train images: 0.505419, val images: 0.578235
[16:24:23.397840] saving best_prec_model_0 @ epoch 2
[16:24:24.405177] saving best_rec_model_0 @ epoch 2
[16:24:25.358966] saving best_dice_model_0 @ epoch 2
[16:24:26.265350] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:24:26.897585] Epoch: [3]  [  0/345]  eta: 0:03:37  lr: 0.000019  loss: 0.8160 (0.8160)  time: 0.6313  data: 0.3880  max mem: 11902
[16:24:31.753696] Epoch: [3]  [ 20/345]  eta: 0:01:24  lr: 0.000019  loss: 0.8401 (0.8446)  time: 0.2427  data: 0.0001  max mem: 11902
[16:24:36.617153] Epoch: [3]  [ 40/345]  eta: 0:01:16  lr: 0.000019  loss: 0.8310 (0.8437)  time: 0.2431  data: 0.0001  max mem: 11902
[16:24:41.490591] Epoch: [3]  [ 60/345]  eta: 0:01:11  lr: 0.000020  loss: 0.8229 (0.8375)  time: 0.2436  data: 0.0001  max mem: 11902
[16:24:46.367017] Epoch: [3]  [ 80/345]  eta: 0:01:05  lr: 0.000020  loss: 0.8166 (0.8335)  time: 0.2438  data: 0.0001  max mem: 11902
[16:24:51.242560] Epoch: [3]  [100/345]  eta: 0:01:00  lr: 0.000021  loss: 0.7945 (0.8265)  time: 0.2437  data: 0.0001  max mem: 11902
[16:24:56.124181] Epoch: [3]  [120/345]  eta: 0:00:55  lr: 0.000021  loss: 0.7819 (0.8200)  time: 0.2440  data: 0.0001  max mem: 11902
[16:25:01.004538] Epoch: [3]  [140/345]  eta: 0:00:50  lr: 0.000021  loss: 0.7737 (0.8148)  time: 0.2440  data: 0.0001  max mem: 11902
[16:25:05.961522] Epoch: [3]  [160/345]  eta: 0:00:45  lr: 0.000022  loss: 0.7577 (0.8085)  time: 0.2478  data: 0.0001  max mem: 11902
[16:25:10.845773] Epoch: [3]  [180/345]  eta: 0:00:40  lr: 0.000022  loss: 0.7365 (0.8015)  time: 0.2442  data: 0.0001  max mem: 11902
[16:25:15.738200] Epoch: [3]  [200/345]  eta: 0:00:35  lr: 0.000022  loss: 0.7404 (0.7960)  time: 0.2446  data: 0.0001  max mem: 11902
[16:25:20.625631] Epoch: [3]  [220/345]  eta: 0:00:30  lr: 0.000023  loss: 0.7068 (0.7888)  time: 0.2443  data: 0.0001  max mem: 11902
[16:25:25.518839] Epoch: [3]  [240/345]  eta: 0:00:25  lr: 0.000023  loss: 0.7381 (0.7842)  time: 0.2446  data: 0.0001  max mem: 11902
[16:25:30.411106] Epoch: [3]  [260/345]  eta: 0:00:20  lr: 0.000023  loss: 0.7024 (0.7794)  time: 0.2446  data: 0.0001  max mem: 11902
[16:25:35.310108] Epoch: [3]  [280/345]  eta: 0:00:15  lr: 0.000024  loss: 0.6928 (0.7738)  time: 0.2449  data: 0.0001  max mem: 11902
[16:25:40.208494] Epoch: [3]  [300/345]  eta: 0:00:11  lr: 0.000024  loss: 0.7128 (0.7697)  time: 0.2449  data: 0.0001  max mem: 11902
[16:25:45.112934] Epoch: [3]  [320/345]  eta: 0:00:06  lr: 0.000025  loss: 0.6865 (0.7653)  time: 0.2452  data: 0.0001  max mem: 11902
[16:25:50.005467] Epoch: [3]  [340/345]  eta: 0:00:01  lr: 0.000025  loss: 0.6893 (0.7615)  time: 0.2446  data: 0.0001  max mem: 11902
[16:25:50.984789] Epoch: [3]  [344/345]  eta: 0:00:00  lr: 0.000025  loss: 0.6800 (0.7601)  time: 0.2446  data: 0.0001  max mem: 11902
[16:25:51.056902] Epoch: [3] Total time: 0:01:24 (0.2458 s / it)
[16:25:51.057447] Averaged stats: lr: 0.000025  loss: 0.6800 (0.7601)
[16:25:51.551758] Test:  [  0/345]  eta: 0:02:48  loss: 0.6355 (0.6355)  time: 0.4898  data: 0.4124  max mem: 11902
[16:25:52.345888] Test:  [ 10/345]  eta: 0:00:39  loss: 0.6769 (0.6798)  time: 0.1166  data: 0.0376  max mem: 11902
[16:25:53.144070] Test:  [ 20/345]  eta: 0:00:32  loss: 0.6769 (0.6772)  time: 0.0795  data: 0.0001  max mem: 11902
[16:25:53.945782] Test:  [ 30/345]  eta: 0:00:29  loss: 0.6725 (0.6809)  time: 0.0799  data: 0.0001  max mem: 11902
[16:25:54.749163] Test:  [ 40/345]  eta: 0:00:27  loss: 0.6789 (0.6810)  time: 0.0802  data: 0.0001  max mem: 11902
[16:25:55.557971] Test:  [ 50/345]  eta: 0:00:25  loss: 0.6816 (0.6795)  time: 0.0805  data: 0.0001  max mem: 11902
[16:25:56.369851] Test:  [ 60/345]  eta: 0:00:24  loss: 0.6816 (0.6811)  time: 0.0810  data: 0.0001  max mem: 11902
[16:25:57.186651] Test:  [ 70/345]  eta: 0:00:23  loss: 0.6778 (0.6794)  time: 0.0814  data: 0.0001  max mem: 11902
[16:25:58.005040] Test:  [ 80/345]  eta: 0:00:22  loss: 0.6838 (0.6819)  time: 0.0817  data: 0.0001  max mem: 11902
[16:25:58.827794] Test:  [ 90/345]  eta: 0:00:21  loss: 0.7011 (0.6837)  time: 0.0820  data: 0.0001  max mem: 11902
[16:25:59.653731] Test:  [100/345]  eta: 0:00:20  loss: 0.6985 (0.6859)  time: 0.0824  data: 0.0001  max mem: 11902
[16:26:00.484064] Test:  [110/345]  eta: 0:00:19  loss: 0.6982 (0.6868)  time: 0.0827  data: 0.0001  max mem: 11902
[16:26:01.315497] Test:  [120/345]  eta: 0:00:19  loss: 0.6718 (0.6860)  time: 0.0830  data: 0.0001  max mem: 11902
[16:26:02.151885] Test:  [130/345]  eta: 0:00:18  loss: 0.6698 (0.6860)  time: 0.0833  data: 0.0001  max mem: 11902
[16:26:02.992209] Test:  [140/345]  eta: 0:00:17  loss: 0.6695 (0.6851)  time: 0.0837  data: 0.0001  max mem: 11902
[16:26:03.835641] Test:  [150/345]  eta: 0:00:16  loss: 0.6646 (0.6848)  time: 0.0841  data: 0.0001  max mem: 11902
[16:26:04.682673] Test:  [160/345]  eta: 0:00:15  loss: 0.6607 (0.6827)  time: 0.0844  data: 0.0001  max mem: 11902
[16:26:05.533452] Test:  [170/345]  eta: 0:00:14  loss: 0.6544 (0.6825)  time: 0.0848  data: 0.0001  max mem: 11902
[16:26:06.387809] Test:  [180/345]  eta: 0:00:13  loss: 0.6771 (0.6830)  time: 0.0852  data: 0.0001  max mem: 11902
[16:26:07.246667] Test:  [190/345]  eta: 0:00:13  loss: 0.6742 (0.6815)  time: 0.0856  data: 0.0001  max mem: 11902
[16:26:08.108331] Test:  [200/345]  eta: 0:00:12  loss: 0.6572 (0.6808)  time: 0.0859  data: 0.0001  max mem: 11902
[16:26:08.973424] Test:  [210/345]  eta: 0:00:11  loss: 0.6601 (0.6799)  time: 0.0863  data: 0.0001  max mem: 11902
[16:26:09.841202] Test:  [220/345]  eta: 0:00:10  loss: 0.6663 (0.6802)  time: 0.0866  data: 0.0001  max mem: 11902
[16:26:10.713743] Test:  [230/345]  eta: 0:00:09  loss: 0.6701 (0.6802)  time: 0.0869  data: 0.0001  max mem: 11902
[16:26:11.589246] Test:  [240/345]  eta: 0:00:08  loss: 0.6558 (0.6798)  time: 0.0873  data: 0.0001  max mem: 11902
[16:26:12.468857] Test:  [250/345]  eta: 0:00:08  loss: 0.6558 (0.6799)  time: 0.0877  data: 0.0001  max mem: 11902
[16:26:13.351601] Test:  [260/345]  eta: 0:00:07  loss: 0.6688 (0.6805)  time: 0.0880  data: 0.0001  max mem: 11902
[16:26:14.237539] Test:  [270/345]  eta: 0:00:06  loss: 0.6500 (0.6798)  time: 0.0883  data: 0.0001  max mem: 11902
[16:26:15.127435] Test:  [280/345]  eta: 0:00:05  loss: 0.6575 (0.6795)  time: 0.0887  data: 0.0001  max mem: 11902
[16:26:16.021730] Test:  [290/345]  eta: 0:00:04  loss: 0.6869 (0.6802)  time: 0.0891  data: 0.0001  max mem: 11902
[16:26:16.918095] Test:  [300/345]  eta: 0:00:03  loss: 0.6792 (0.6801)  time: 0.0895  data: 0.0001  max mem: 11902
[16:26:17.818752] Test:  [310/345]  eta: 0:00:03  loss: 0.6716 (0.6798)  time: 0.0898  data: 0.0001  max mem: 11902
[16:26:18.721574] Test:  [320/345]  eta: 0:00:02  loss: 0.6755 (0.6800)  time: 0.0901  data: 0.0001  max mem: 11902
[16:26:19.629557] Test:  [330/345]  eta: 0:00:01  loss: 0.6919 (0.6804)  time: 0.0905  data: 0.0001  max mem: 11902
[16:26:20.539836] Test:  [340/345]  eta: 0:00:00  loss: 0.6919 (0.6808)  time: 0.0909  data: 0.0001  max mem: 11902
[16:26:20.905934] Test:  [344/345]  eta: 0:00:00  loss: 0.6919 (0.6805)  time: 0.0910  data: 0.0001  max mem: 11902
[16:26:20.974835] Test: Total time: 0:00:29 (0.0867 s / it)
[16:26:30.793327] Test:  [ 0/57]  eta: 0:00:24  loss: 0.7077 (0.7077)  time: 0.4279  data: 0.3509  max mem: 11902
[16:26:31.581928] Test:  [10/57]  eta: 0:00:05  loss: 0.6981 (0.7395)  time: 0.1105  data: 0.0320  max mem: 11902
[16:26:32.374146] Test:  [20/57]  eta: 0:00:03  loss: 0.6565 (0.7017)  time: 0.0789  data: 0.0001  max mem: 11902
[16:26:33.170128] Test:  [30/57]  eta: 0:00:02  loss: 0.5358 (0.6260)  time: 0.0793  data: 0.0001  max mem: 11902
[16:26:33.970767] Test:  [40/57]  eta: 0:00:01  loss: 0.4627 (0.5850)  time: 0.0798  data: 0.0001  max mem: 11902
[16:26:34.773079] Test:  [50/57]  eta: 0:00:00  loss: 0.4821 (0.5883)  time: 0.0801  data: 0.0001  max mem: 11902
[16:26:35.208969] Test:  [56/57]  eta: 0:00:00  loss: 0.6210 (0.6156)  time: 0.0779  data: 0.0000  max mem: 11902
[16:26:35.272714] Test: Total time: 0:00:04 (0.0861 s / it)
[16:26:36.898397] Dice score of the network on the train images: 0.528280, val images: 0.600697
[16:26:36.898619] saving best_prec_model_0 @ epoch 3
[16:26:37.898763] saving best_rec_model_0 @ epoch 3
[16:26:38.848735] saving best_dice_model_0 @ epoch 3
[16:26:39.724398] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:26:40.304932] Epoch: [4]  [  0/345]  eta: 0:03:19  lr: 0.000025  loss: 0.7258 (0.7258)  time: 0.5793  data: 0.3342  max mem: 11902
[16:26:45.163775] Epoch: [4]  [ 20/345]  eta: 0:01:24  lr: 0.000025  loss: 0.6685 (0.6815)  time: 0.2429  data: 0.0001  max mem: 11902
[16:26:50.023635] Epoch: [4]  [ 40/345]  eta: 0:01:16  lr: 0.000026  loss: 0.6624 (0.6804)  time: 0.2430  data: 0.0001  max mem: 11902
[16:26:54.906365] Epoch: [4]  [ 60/345]  eta: 0:01:10  lr: 0.000026  loss: 0.6459 (0.6744)  time: 0.2441  data: 0.0001  max mem: 11902
[16:26:59.791710] Epoch: [4]  [ 80/345]  eta: 0:01:05  lr: 0.000026  loss: 0.6573 (0.6684)  time: 0.2442  data: 0.0001  max mem: 11902
[16:27:04.677319] Epoch: [4]  [100/345]  eta: 0:01:00  lr: 0.000027  loss: 0.6284 (0.6627)  time: 0.2442  data: 0.0001  max mem: 11902
[16:27:09.563059] Epoch: [4]  [120/345]  eta: 0:00:55  lr: 0.000027  loss: 0.6255 (0.6584)  time: 0.2442  data: 0.0001  max mem: 11902
[16:27:14.453570] Epoch: [4]  [140/345]  eta: 0:00:50  lr: 0.000028  loss: 0.5934 (0.6510)  time: 0.2445  data: 0.0001  max mem: 11902
[16:27:19.340786] Epoch: [4]  [160/345]  eta: 0:00:45  lr: 0.000028  loss: 0.6103 (0.6479)  time: 0.2443  data: 0.0000  max mem: 11902
[16:27:24.229118] Epoch: [4]  [180/345]  eta: 0:00:40  lr: 0.000028  loss: 0.6184 (0.6441)  time: 0.2444  data: 0.0001  max mem: 11902
[16:27:29.118630] Epoch: [4]  [200/345]  eta: 0:00:35  lr: 0.000029  loss: 0.5968 (0.6404)  time: 0.2444  data: 0.0001  max mem: 11902
[16:27:34.014223] Epoch: [4]  [220/345]  eta: 0:00:30  lr: 0.000029  loss: 0.5974 (0.6371)  time: 0.2447  data: 0.0001  max mem: 11902
[16:27:38.911970] Epoch: [4]  [240/345]  eta: 0:00:25  lr: 0.000029  loss: 0.5779 (0.6324)  time: 0.2448  data: 0.0000  max mem: 11902
[16:27:43.807316] Epoch: [4]  [260/345]  eta: 0:00:20  lr: 0.000030  loss: 0.5616 (0.6277)  time: 0.2447  data: 0.0001  max mem: 11902
[16:27:48.709500] Epoch: [4]  [280/345]  eta: 0:00:15  lr: 0.000030  loss: 0.5311 (0.6212)  time: 0.2451  data: 0.0001  max mem: 11902
[16:27:53.610202] Epoch: [4]  [300/345]  eta: 0:00:11  lr: 0.000030  loss: 0.5407 (0.6164)  time: 0.2450  data: 0.0000  max mem: 11902
[16:27:58.512639] Epoch: [4]  [320/345]  eta: 0:00:06  lr: 0.000031  loss: 0.5510 (0.6128)  time: 0.2451  data: 0.0001  max mem: 11902
[16:28:03.415248] Epoch: [4]  [340/345]  eta: 0:00:01  lr: 0.000031  loss: 0.5530 (0.6101)  time: 0.2451  data: 0.0001  max mem: 11902
[16:28:04.396652] Epoch: [4]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 0.5497 (0.6094)  time: 0.2451  data: 0.0001  max mem: 11902
[16:28:04.467768] Epoch: [4] Total time: 0:01:24 (0.2456 s / it)
[16:28:04.468237] Averaged stats: lr: 0.000031  loss: 0.5497 (0.6094)
[16:28:04.902006] Test:  [  0/345]  eta: 0:02:28  loss: 0.5106 (0.5106)  time: 0.4293  data: 0.3521  max mem: 11902
[16:28:05.700580] Test:  [ 10/345]  eta: 0:00:37  loss: 0.5188 (0.5266)  time: 0.1115  data: 0.0327  max mem: 11902
[16:28:06.498243] Test:  [ 20/345]  eta: 0:00:31  loss: 0.5188 (0.5248)  time: 0.0797  data: 0.0004  max mem: 11902
[16:28:07.299442] Test:  [ 30/345]  eta: 0:00:28  loss: 0.5117 (0.5267)  time: 0.0799  data: 0.0001  max mem: 11902
[16:28:08.102162] Test:  [ 40/345]  eta: 0:00:26  loss: 0.5107 (0.5257)  time: 0.0801  data: 0.0001  max mem: 11902
[16:28:08.908148] Test:  [ 50/345]  eta: 0:00:25  loss: 0.5056 (0.5259)  time: 0.0804  data: 0.0001  max mem: 11902
[16:28:09.719796] Test:  [ 60/345]  eta: 0:00:24  loss: 0.5113 (0.5235)  time: 0.0808  data: 0.0001  max mem: 11902
[16:28:10.533787] Test:  [ 70/345]  eta: 0:00:23  loss: 0.5307 (0.5252)  time: 0.0812  data: 0.0001  max mem: 11902
[16:28:11.351149] Test:  [ 80/345]  eta: 0:00:22  loss: 0.5233 (0.5235)  time: 0.0815  data: 0.0001  max mem: 11902
[16:28:12.173038] Test:  [ 90/345]  eta: 0:00:21  loss: 0.5078 (0.5221)  time: 0.0819  data: 0.0001  max mem: 11902
[16:28:12.998509] Test:  [100/345]  eta: 0:00:20  loss: 0.5189 (0.5221)  time: 0.0823  data: 0.0001  max mem: 11902
[16:28:13.826614] Test:  [110/345]  eta: 0:00:19  loss: 0.4975 (0.5193)  time: 0.0826  data: 0.0001  max mem: 11902
[16:28:14.659798] Test:  [120/345]  eta: 0:00:18  loss: 0.4975 (0.5195)  time: 0.0830  data: 0.0001  max mem: 11902
[16:28:15.495782] Test:  [130/345]  eta: 0:00:18  loss: 0.5315 (0.5218)  time: 0.0834  data: 0.0001  max mem: 11902
[16:28:16.336213] Test:  [140/345]  eta: 0:00:17  loss: 0.5216 (0.5219)  time: 0.0837  data: 0.0001  max mem: 11902
[16:28:17.179768] Test:  [150/345]  eta: 0:00:16  loss: 0.5166 (0.5219)  time: 0.0841  data: 0.0001  max mem: 11902
[16:28:18.025945] Test:  [160/345]  eta: 0:00:15  loss: 0.5253 (0.5228)  time: 0.0844  data: 0.0001  max mem: 11902
[16:28:18.875460] Test:  [170/345]  eta: 0:00:14  loss: 0.5433 (0.5250)  time: 0.0847  data: 0.0001  max mem: 11902
[16:28:19.728739] Test:  [180/345]  eta: 0:00:13  loss: 0.5545 (0.5264)  time: 0.0851  data: 0.0001  max mem: 11902
[16:28:20.585777] Test:  [190/345]  eta: 0:00:13  loss: 0.5484 (0.5272)  time: 0.0854  data: 0.0001  max mem: 11902
[16:28:21.447109] Test:  [200/345]  eta: 0:00:12  loss: 0.5422 (0.5274)  time: 0.0858  data: 0.0001  max mem: 11902
[16:28:22.310673] Test:  [210/345]  eta: 0:00:11  loss: 0.5367 (0.5278)  time: 0.0862  data: 0.0001  max mem: 11902
[16:28:23.178785] Test:  [220/345]  eta: 0:00:10  loss: 0.5274 (0.5282)  time: 0.0865  data: 0.0001  max mem: 11902
[16:28:24.050603] Test:  [230/345]  eta: 0:00:09  loss: 0.5187 (0.5273)  time: 0.0869  data: 0.0001  max mem: 11902
[16:28:24.926148] Test:  [240/345]  eta: 0:00:08  loss: 0.5205 (0.5274)  time: 0.0873  data: 0.0001  max mem: 11902
[16:28:25.805499] Test:  [250/345]  eta: 0:00:08  loss: 0.5312 (0.5275)  time: 0.0877  data: 0.0001  max mem: 11902
[16:28:26.686652] Test:  [260/345]  eta: 0:00:07  loss: 0.5281 (0.5277)  time: 0.0880  data: 0.0001  max mem: 11902
[16:28:27.571440] Test:  [270/345]  eta: 0:00:06  loss: 0.5481 (0.5291)  time: 0.0882  data: 0.0001  max mem: 11902
[16:28:28.460918] Test:  [280/345]  eta: 0:00:05  loss: 0.5329 (0.5286)  time: 0.0886  data: 0.0001  max mem: 11902
[16:28:29.353108] Test:  [290/345]  eta: 0:00:04  loss: 0.5204 (0.5280)  time: 0.0890  data: 0.0001  max mem: 11902
[16:28:30.250097] Test:  [300/345]  eta: 0:00:03  loss: 0.5120 (0.5272)  time: 0.0894  data: 0.0001  max mem: 11902
[16:28:31.150273] Test:  [310/345]  eta: 0:00:02  loss: 0.5107 (0.5270)  time: 0.0898  data: 0.0001  max mem: 11902
[16:28:32.053489] Test:  [320/345]  eta: 0:00:02  loss: 0.4993 (0.5263)  time: 0.0901  data: 0.0001  max mem: 11902
[16:28:32.961222] Test:  [330/345]  eta: 0:00:01  loss: 0.5118 (0.5266)  time: 0.0905  data: 0.0001  max mem: 11902
[16:28:33.869882] Test:  [340/345]  eta: 0:00:00  loss: 0.5118 (0.5266)  time: 0.0908  data: 0.0001  max mem: 11902
[16:28:34.235024] Test:  [344/345]  eta: 0:00:00  loss: 0.5078 (0.5265)  time: 0.0909  data: 0.0001  max mem: 11902
[16:28:34.306119] Test: Total time: 0:00:29 (0.0865 s / it)
[16:28:44.150369] Test:  [ 0/57]  eta: 0:00:22  loss: 0.5718 (0.5718)  time: 0.3963  data: 0.3187  max mem: 11902
[16:28:44.943132] Test:  [10/57]  eta: 0:00:05  loss: 0.5532 (0.5899)  time: 0.1080  data: 0.0295  max mem: 11902
[16:28:45.736877] Test:  [20/57]  eta: 0:00:03  loss: 0.5019 (0.5424)  time: 0.0792  data: 0.0003  max mem: 11902
[16:28:46.533870] Test:  [30/57]  eta: 0:00:02  loss: 0.3411 (0.4720)  time: 0.0794  data: 0.0001  max mem: 11902
[16:28:47.333473] Test:  [40/57]  eta: 0:00:01  loss: 0.3284 (0.4370)  time: 0.0797  data: 0.0001  max mem: 11902
[16:28:48.135562] Test:  [50/57]  eta: 0:00:00  loss: 0.3364 (0.4418)  time: 0.0800  data: 0.0001  max mem: 11902
[16:28:48.571480] Test:  [56/57]  eta: 0:00:00  loss: 0.4274 (0.4721)  time: 0.0778  data: 0.0001  max mem: 11902
[16:28:48.638377] Test: Total time: 0:00:04 (0.0857 s / it)
[16:28:50.279092] Dice score of the network on the train images: 0.625254, val images: 0.709820
[16:28:50.279318] saving best_prec_model_0 @ epoch 4
[16:28:51.345753] saving best_rec_model_0 @ epoch 4
[16:28:52.282377] saving best_dice_model_0 @ epoch 4
[16:28:53.206888] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:28:53.792340] Epoch: [5]  [  0/345]  eta: 0:03:21  lr: 0.000031  loss: 0.5677 (0.5677)  time: 0.5843  data: 0.3393  max mem: 11902
[16:28:58.644675] Epoch: [5]  [ 20/345]  eta: 0:01:24  lr: 0.000032  loss: 0.5365 (0.5359)  time: 0.2426  data: 0.0001  max mem: 11902
[16:29:03.510858] Epoch: [5]  [ 40/345]  eta: 0:01:16  lr: 0.000032  loss: 0.5455 (0.5405)  time: 0.2433  data: 0.0001  max mem: 11902
[16:29:08.385641] Epoch: [5]  [ 60/345]  eta: 0:01:10  lr: 0.000032  loss: 0.5300 (0.5358)  time: 0.2437  data: 0.0001  max mem: 11902
[16:29:13.263385] Epoch: [5]  [ 80/345]  eta: 0:01:05  lr: 0.000033  loss: 0.5361 (0.5350)  time: 0.2438  data: 0.0001  max mem: 11902
[16:29:18.131724] Epoch: [5]  [100/345]  eta: 0:01:00  lr: 0.000033  loss: 0.5230 (0.5343)  time: 0.2434  data: 0.0001  max mem: 11902
[16:29:23.017660] Epoch: [5]  [120/345]  eta: 0:00:55  lr: 0.000033  loss: 0.5094 (0.5324)  time: 0.2443  data: 0.0001  max mem: 11902
[16:29:27.906490] Epoch: [5]  [140/345]  eta: 0:00:50  lr: 0.000034  loss: 0.5199 (0.5323)  time: 0.2444  data: 0.0001  max mem: 11902
[16:29:32.791874] Epoch: [5]  [160/345]  eta: 0:00:45  lr: 0.000034  loss: 0.5003 (0.5283)  time: 0.2442  data: 0.0001  max mem: 11902

[16:29:37.686987] Epoch: [5]  [180/345]  eta: 0:00:40  lr: 0.000035  loss: 0.4914 (0.5244)  time: 0.2447  data: 0.0001  max mem: 11902
[16:29:42.584271] Epoch: [5]  [200/345]  eta: 0:00:35  lr: 0.000035  loss: 0.4867 (0.5218)  time: 0.2448  data: 0.0001  max mem: 11902
[16:29:47.477026] Epoch: [5]  [220/345]  eta: 0:00:30  lr: 0.000035  loss: 0.4673 (0.5173)  time: 0.2446  data: 0.0001  max mem: 11902
[16:29:52.373840] Epoch: [5]  [240/345]  eta: 0:00:25  lr: 0.000036  loss: 0.4618 (0.5137)  time: 0.2448  data: 0.0001  max mem: 11902
[16:29:57.265230] Epoch: [5]  [260/345]  eta: 0:00:20  lr: 0.000036  loss: 0.4728 (0.5112)  time: 0.2445  data: 0.0001  max mem: 11902
[16:30:02.160144] Epoch: [5]  [280/345]  eta: 0:00:15  lr: 0.000036  loss: 0.4766 (0.5101)  time: 0.2447  data: 0.0001  max mem: 11902
[16:30:07.062945] Epoch: [5]  [300/345]  eta: 0:00:11  lr: 0.000037  loss: 0.4693 (0.5081)  time: 0.2450  data: 0.0001  max mem: 11902
[16:30:11.964681] Epoch: [5]  [320/345]  eta: 0:00:06  lr: 0.000037  loss: 0.4868 (0.5061)  time: 0.2450  data: 0.0001  max mem: 11902
[16:30:16.863956] Epoch: [5]  [340/345]  eta: 0:00:01  lr: 0.000037  loss: 0.4675 (0.5050)  time: 0.2449  data: 0.0001  max mem: 11902
[16:30:17.841865] Epoch: [5]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 0.4587 (0.5043)  time: 0.2446  data: 0.0001  max mem: 11902
[16:30:17.909981] Epoch: [5] Total time: 0:01:24 (0.2455 s / it)
[16:30:17.910162] Averaged stats: lr: 0.000037  loss: 0.4587 (0.5043)
[16:30:18.365859] Test:  [  0/345]  eta: 0:02:35  loss: 0.5022 (0.5022)  time: 0.4519  data: 0.3746  max mem: 11902
[16:30:19.164407] Test:  [ 10/345]  eta: 0:00:38  loss: 0.4760 (0.4762)  time: 0.1136  data: 0.0346  max mem: 11902
[16:30:19.963266] Test:  [ 20/345]  eta: 0:00:31  loss: 0.4564 (0.4662)  time: 0.0798  data: 0.0003  max mem: 11902
[16:30:20.764930] Test:  [ 30/345]  eta: 0:00:28  loss: 0.4539 (0.4650)  time: 0.0799  data: 0.0001  max mem: 11902
[16:30:21.570533] Test:  [ 40/345]  eta: 0:00:27  loss: 0.4455 (0.4646)  time: 0.0803  data: 0.0001  max mem: 11902
[16:30:22.379517] Test:  [ 50/345]  eta: 0:00:25  loss: 0.4521 (0.4673)  time: 0.0806  data: 0.0001  max mem: 11902
[16:30:23.192156] Test:  [ 60/345]  eta: 0:00:24  loss: 0.4521 (0.4651)  time: 0.0810  data: 0.0001  max mem: 11902
[16:30:24.007140] Test:  [ 70/345]  eta: 0:00:23  loss: 0.4570 (0.4664)  time: 0.0813  data: 0.0001  max mem: 11902
[16:30:24.826496] Test:  [ 80/345]  eta: 0:00:22  loss: 0.4604 (0.4667)  time: 0.0816  data: 0.0001  max mem: 11902
[16:30:25.649267] Test:  [ 90/345]  eta: 0:00:21  loss: 0.4604 (0.4673)  time: 0.0820  data: 0.0001  max mem: 11902
[16:30:26.476360] Test:  [100/345]  eta: 0:00:20  loss: 0.4663 (0.4670)  time: 0.0824  data: 0.0001  max mem: 11902
[16:30:27.305404] Test:  [110/345]  eta: 0:00:19  loss: 0.4804 (0.4692)  time: 0.0827  data: 0.0001  max mem: 11902
[16:30:28.138385] Test:  [120/345]  eta: 0:00:18  loss: 0.4837 (0.4704)  time: 0.0830  data: 0.0001  max mem: 11902
[16:30:28.975117] Test:  [130/345]  eta: 0:00:18  loss: 0.4706 (0.4697)  time: 0.0834  data: 0.0001  max mem: 11902
[16:30:29.816296] Test:  [140/345]  eta: 0:00:17  loss: 0.4553 (0.4692)  time: 0.0838  data: 0.0001  max mem: 11902
[16:30:30.660456] Test:  [150/345]  eta: 0:00:16  loss: 0.4875 (0.4708)  time: 0.0842  data: 0.0001  max mem: 11902
[16:30:31.506739] Test:  [160/345]  eta: 0:00:15  loss: 0.4875 (0.4719)  time: 0.0845  data: 0.0001  max mem: 11902
[16:30:32.359015] Test:  [170/345]  eta: 0:00:14  loss: 0.4816 (0.4731)  time: 0.0848  data: 0.0001  max mem: 11902
[16:30:33.213372] Test:  [180/345]  eta: 0:00:13  loss: 0.4816 (0.4730)  time: 0.0852  data: 0.0001  max mem: 11902
[16:30:34.071069] Test:  [190/345]  eta: 0:00:13  loss: 0.4679 (0.4725)  time: 0.0855  data: 0.0001  max mem: 11902
[16:30:34.933650] Test:  [200/345]  eta: 0:00:12  loss: 0.4679 (0.4727)  time: 0.0859  data: 0.0001  max mem: 11902
[16:30:35.799692] Test:  [210/345]  eta: 0:00:11  loss: 0.4734 (0.4726)  time: 0.0864  data: 0.0001  max mem: 11902
[16:30:36.668539] Test:  [220/345]  eta: 0:00:10  loss: 0.4777 (0.4734)  time: 0.0867  data: 0.0001  max mem: 11902
[16:30:37.540982] Test:  [230/345]  eta: 0:00:09  loss: 0.4797 (0.4734)  time: 0.0870  data: 0.0001  max mem: 11902
[16:30:38.417159] Test:  [240/345]  eta: 0:00:08  loss: 0.5016 (0.4752)  time: 0.0874  data: 0.0001  max mem: 11902
[16:30:39.298654] Test:  [250/345]  eta: 0:00:08  loss: 0.5011 (0.4750)  time: 0.0878  data: 0.0001  max mem: 11902
[16:30:40.181361] Test:  [260/345]  eta: 0:00:07  loss: 0.4833 (0.4752)  time: 0.0881  data: 0.0001  max mem: 11902
[16:30:41.066810] Test:  [270/345]  eta: 0:00:06  loss: 0.4885 (0.4756)  time: 0.0883  data: 0.0001  max mem: 11902
[16:30:41.956153] Test:  [280/345]  eta: 0:00:05  loss: 0.4772 (0.4755)  time: 0.0887  data: 0.0001  max mem: 11902
[16:30:42.849543] Test:  [290/345]  eta: 0:00:04  loss: 0.4768 (0.4762)  time: 0.0891  data: 0.0001  max mem: 11902
[16:30:43.747542] Test:  [300/345]  eta: 0:00:03  loss: 0.4759 (0.4761)  time: 0.0895  data: 0.0001  max mem: 11902
[16:30:44.647483] Test:  [310/345]  eta: 0:00:03  loss: 0.4759 (0.4761)  time: 0.0898  data: 0.0001  max mem: 11902
[16:30:45.551106] Test:  [320/345]  eta: 0:00:02  loss: 0.4815 (0.4764)  time: 0.0901  data: 0.0001  max mem: 11902
[16:30:46.459374] Test:  [330/345]  eta: 0:00:01  loss: 0.4531 (0.4758)  time: 0.0905  data: 0.0001  max mem: 11902
[16:30:47.369896] Test:  [340/345]  eta: 0:00:00  loss: 0.4531 (0.4759)  time: 0.0909  data: 0.0001  max mem: 11902
[16:30:47.735221] Test:  [344/345]  eta: 0:00:00  loss: 0.4590 (0.4760)  time: 0.0910  data: 0.0001  max mem: 11902
[16:30:47.805538] Test: Total time: 0:00:29 (0.0866 s / it)
[16:30:57.664107] Test:  [ 0/57]  eta: 0:00:24  loss: 0.5377 (0.5377)  time: 0.4298  data: 0.3529  max mem: 11902
[16:30:58.452951] Test:  [10/57]  eta: 0:00:05  loss: 0.5400 (0.5711)  time: 0.1107  data: 0.0322  max mem: 11902
[16:30:59.244516] Test:  [20/57]  eta: 0:00:03  loss: 0.5152 (0.5503)  time: 0.0789  data: 0.0001  max mem: 11902
[16:31:00.039812] Test:  [30/57]  eta: 0:00:02  loss: 0.3433 (0.4770)  time: 0.0793  data: 0.0001  max mem: 11902
[16:31:00.840172] Test:  [40/57]  eta: 0:00:01  loss: 0.3193 (0.4414)  time: 0.0797  data: 0.0001  max mem: 11902
[16:31:01.643053] Test:  [50/57]  eta: 0:00:00  loss: 0.3275 (0.4389)  time: 0.0801  data: 0.0001  max mem: 11902
[16:31:02.077479] Test:  [56/57]  eta: 0:00:00  loss: 0.3976 (0.4695)  time: 0.0778  data: 0.0001  max mem: 11902
[16:31:02.155741] Test: Total time: 0:00:04 (0.0864 s / it)
[16:31:03.782975] Dice score of the network on the train images: 0.634480, val images: 0.405986
[16:31:03.783206] saving best_rec_model_0 @ epoch 5
[16:31:04.737151] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:31:05.352098] Epoch: [6]  [  0/345]  eta: 0:03:31  lr: 0.000038  loss: 0.4855 (0.4855)  time: 0.6138  data: 0.3687  max mem: 11902
[16:31:10.210461] Epoch: [6]  [ 20/345]  eta: 0:01:24  lr: 0.000038  loss: 0.4580 (0.4738)  time: 0.2429  data: 0.0001  max mem: 11902
[16:31:15.090662] Epoch: [6]  [ 40/345]  eta: 0:01:16  lr: 0.000038  loss: 0.4608 (0.4681)  time: 0.2440  data: 0.0001  max mem: 11902
[16:31:19.978520] Epoch: [6]  [ 60/345]  eta: 0:01:11  lr: 0.000039  loss: 0.4543 (0.4656)  time: 0.2443  data: 0.0001  max mem: 11902
[16:31:24.852120] Epoch: [6]  [ 80/345]  eta: 0:01:05  lr: 0.000039  loss: 0.4517 (0.4657)  time: 0.2436  data: 0.0001  max mem: 11902
[16:31:29.732832] Epoch: [6]  [100/345]  eta: 0:01:00  lr: 0.000039  loss: 0.4625 (0.4658)  time: 0.2440  data: 0.0001  max mem: 11902
[16:31:34.609583] Epoch: [6]  [120/345]  eta: 0:00:55  lr: 0.000040  loss: 0.4402 (0.4625)  time: 0.2438  data: 0.0001  max mem: 11902
[16:31:39.500832] Epoch: [6]  [140/345]  eta: 0:00:50  lr: 0.000040  loss: 0.4428 (0.4604)  time: 0.2445  data: 0.0001  max mem: 11902
[16:31:44.392830] Epoch: [6]  [160/345]  eta: 0:00:45  lr: 0.000040  loss: 0.4334 (0.4588)  time: 0.2446  data: 0.0001  max mem: 11902
[16:31:49.292368] Epoch: [6]  [180/345]  eta: 0:00:40  lr: 0.000041  loss: 0.4513 (0.4574)  time: 0.2449  data: 0.0001  max mem: 11902
[16:31:54.186942] Epoch: [6]  [200/345]  eta: 0:00:35  lr: 0.000041  loss: 0.4460 (0.4565)  time: 0.2447  data: 0.0001  max mem: 11902
[16:31:59.077937] Epoch: [6]  [220/345]  eta: 0:00:30  lr: 0.000041  loss: 0.4329 (0.4552)  time: 0.2445  data: 0.0001  max mem: 11902
[16:32:03.985495] Epoch: [6]  [240/345]  eta: 0:00:25  lr: 0.000042  loss: 0.4129 (0.4540)  time: 0.2453  data: 0.0001  max mem: 11902
[16:32:08.894988] Epoch: [6]  [260/345]  eta: 0:00:20  lr: 0.000042  loss: 0.4063 (0.4507)  time: 0.2454  data: 0.0001  max mem: 11902
[16:32:13.793785] Epoch: [6]  [280/345]  eta: 0:00:15  lr: 0.000043  loss: 0.4238 (0.4484)  time: 0.2449  data: 0.0001  max mem: 11902
[16:32:18.769905] Epoch: [6]  [300/345]  eta: 0:00:11  lr: 0.000043  loss: 0.4060 (0.4465)  time: 0.2488  data: 0.0001  max mem: 11902
[16:32:23.677453] Epoch: [6]  [320/345]  eta: 0:00:06  lr: 0.000043  loss: 0.3871 (0.4440)  time: 0.2453  data: 0.0001  max mem: 11902
[16:32:28.569780] Epoch: [6]  [340/345]  eta: 0:00:01  lr: 0.000044  loss: 0.3998 (0.4424)  time: 0.2446  data: 0.0001  max mem: 11902
[16:32:29.546379] Epoch: [6]  [344/345]  eta: 0:00:00  lr: 0.000044  loss: 0.4046 (0.4424)  time: 0.2443  data: 0.0001  max mem: 11902
[16:32:29.616547] Epoch: [6] Total time: 0:01:24 (0.2460 s / it)
[16:32:29.616877] Averaged stats: lr: 0.000044  loss: 0.4046 (0.4424)
[16:32:30.104698] Test:  [  0/345]  eta: 0:02:46  loss: 0.4538 (0.4538)  time: 0.4835  data: 0.4062  max mem: 11902
[16:32:30.898228] Test:  [ 10/345]  eta: 0:00:38  loss: 0.4335 (0.4336)  time: 0.1160  data: 0.0370  max mem: 11902
[16:32:31.695163] Test:  [ 20/345]  eta: 0:00:32  loss: 0.4010 (0.4207)  time: 0.0794  data: 0.0001  max mem: 11902
[16:32:32.498520] Test:  [ 30/345]  eta: 0:00:29  loss: 0.3994 (0.4157)  time: 0.0798  data: 0.0001  max mem: 11902
[16:32:33.303428] Test:  [ 40/345]  eta: 0:00:27  loss: 0.4102 (0.4180)  time: 0.0803  data: 0.0001  max mem: 11902
[16:32:34.112458] Test:  [ 50/345]  eta: 0:00:25  loss: 0.4153 (0.4186)  time: 0.0806  data: 0.0001  max mem: 11902
[16:32:34.923515] Test:  [ 60/345]  eta: 0:00:24  loss: 0.4127 (0.4165)  time: 0.0809  data: 0.0001  max mem: 11902
[16:32:35.738260] Test:  [ 70/345]  eta: 0:00:23  loss: 0.3997 (0.4152)  time: 0.0812  data: 0.0001  max mem: 11902
[16:32:36.557017] Test:  [ 80/345]  eta: 0:00:22  loss: 0.3977 (0.4132)  time: 0.0816  data: 0.0001  max mem: 11902
[16:32:37.378569] Test:  [ 90/345]  eta: 0:00:21  loss: 0.3957 (0.4110)  time: 0.0819  data: 0.0001  max mem: 11902
[16:32:38.203161] Test:  [100/345]  eta: 0:00:20  loss: 0.3957 (0.4094)  time: 0.0822  data: 0.0001  max mem: 11902
[16:32:39.032317] Test:  [110/345]  eta: 0:00:19  loss: 0.3958 (0.4084)  time: 0.0826  data: 0.0001  max mem: 11902
[16:32:39.864578] Test:  [120/345]  eta: 0:00:19  loss: 0.3914 (0.4058)  time: 0.0830  data: 0.0001  max mem: 11902
[16:32:40.701055] Test:  [130/345]  eta: 0:00:18  loss: 0.3839 (0.4063)  time: 0.0834  data: 0.0001  max mem: 11902
[16:32:41.541323] Test:  [140/345]  eta: 0:00:17  loss: 0.4131 (0.4084)  time: 0.0838  data: 0.0001  max mem: 11902
[16:32:42.383757] Test:  [150/345]  eta: 0:00:16  loss: 0.3982 (0.4073)  time: 0.0840  data: 0.0001  max mem: 11902
[16:32:43.230712] Test:  [160/345]  eta: 0:00:15  loss: 0.4036 (0.4085)  time: 0.0844  data: 0.0001  max mem: 11902
[16:32:44.080373] Test:  [170/345]  eta: 0:00:14  loss: 0.4065 (0.4088)  time: 0.0848  data: 0.0001  max mem: 11902
[16:32:44.934207] Test:  [180/345]  eta: 0:00:13  loss: 0.4051 (0.4087)  time: 0.0851  data: 0.0001  max mem: 11902
[16:32:45.791567] Test:  [190/345]  eta: 0:00:13  loss: 0.4168 (0.4089)  time: 0.0855  data: 0.0001  max mem: 11902
[16:32:46.652668] Test:  [200/345]  eta: 0:00:12  loss: 0.4034 (0.4085)  time: 0.0858  data: 0.0001  max mem: 11902
[16:32:47.517288] Test:  [210/345]  eta: 0:00:11  loss: 0.4108 (0.4100)  time: 0.0862  data: 0.0001  max mem: 11902
[16:32:48.386048] Test:  [220/345]  eta: 0:00:10  loss: 0.4187 (0.4099)  time: 0.0866  data: 0.0001  max mem: 11902
[16:32:49.257704] Test:  [230/345]  eta: 0:00:09  loss: 0.4051 (0.4093)  time: 0.0870  data: 0.0001  max mem: 11902
[16:32:50.133043] Test:  [240/345]  eta: 0:00:08  loss: 0.4044 (0.4094)  time: 0.0873  data: 0.0001  max mem: 11902
[16:32:51.011378] Test:  [250/345]  eta: 0:00:08  loss: 0.4228 (0.4094)  time: 0.0876  data: 0.0001  max mem: 11902
[16:32:51.893867] Test:  [260/345]  eta: 0:00:07  loss: 0.4228 (0.4099)  time: 0.0879  data: 0.0001  max mem: 11902
[16:32:52.779697] Test:  [270/345]  eta: 0:00:06  loss: 0.4141 (0.4098)  time: 0.0883  data: 0.0001  max mem: 11902
[16:32:53.669222] Test:  [280/345]  eta: 0:00:05  loss: 0.3992 (0.4096)  time: 0.0887  data: 0.0001  max mem: 11902
[16:32:54.561498] Test:  [290/345]  eta: 0:00:04  loss: 0.4144 (0.4096)  time: 0.0890  data: 0.0001  max mem: 11902
[16:32:55.457946] Test:  [300/345]  eta: 0:00:03  loss: 0.4176 (0.4101)  time: 0.0894  data: 0.0001  max mem: 11902
[16:32:56.357451] Test:  [310/345]  eta: 0:00:03  loss: 0.4108 (0.4102)  time: 0.0897  data: 0.0001  max mem: 11902
[16:32:57.260881] Test:  [320/345]  eta: 0:00:02  loss: 0.3970 (0.4100)  time: 0.0901  data: 0.0001  max mem: 11902
[16:32:58.166820] Test:  [330/345]  eta: 0:00:01  loss: 0.4105 (0.4105)  time: 0.0904  data: 0.0001  max mem: 11902
[16:32:59.077046] Test:  [340/345]  eta: 0:00:00  loss: 0.4067 (0.4103)  time: 0.0908  data: 0.0001  max mem: 11902
[16:32:59.442866] Test:  [344/345]  eta: 0:00:00  loss: 0.4035 (0.4100)  time: 0.0910  data: 0.0001  max mem: 11902
[16:32:59.512541] Test: Total time: 0:00:29 (0.0866 s / it)
[16:33:09.383031] Test:  [ 0/57]  eta: 0:00:22  loss: 0.4923 (0.4923)  time: 0.3915  data: 0.3141  max mem: 11902
[16:33:10.188734] Test:  [10/57]  eta: 0:00:05  loss: 0.4749 (0.5065)  time: 0.1087  data: 0.0302  max mem: 11902
[16:33:10.982087] Test:  [20/57]  eta: 0:00:03  loss: 0.4631 (0.4943)  time: 0.0798  data: 0.0010  max mem: 11902
[16:33:11.777561] Test:  [30/57]  eta: 0:00:02  loss: 0.3283 (0.4312)  time: 0.0794  data: 0.0001  max mem: 11902
[16:33:12.578876] Test:  [40/57]  eta: 0:00:01  loss: 0.2966 (0.4031)  time: 0.0798  data: 0.0001  max mem: 11902
[16:33:13.381153] Test:  [50/57]  eta: 0:00:00  loss: 0.3047 (0.4037)  time: 0.0801  data: 0.0001  max mem: 11902
[16:33:13.816130] Test:  [56/57]  eta: 0:00:00  loss: 0.3648 (0.4106)  time: 0.0778  data: 0.0000  max mem: 11902
[16:33:13.896377] Test: Total time: 0:00:04 (0.0861 s / it)
[16:33:15.526647] Dice score of the network on the train images: 0.709629, val images: 0.548466
[16:33:15.530257] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:33:16.116460] Epoch: [7]  [  0/345]  eta: 0:03:21  lr: 0.000044  loss: 0.3718 (0.3718)  time: 0.5852  data: 0.3406  max mem: 11902
[16:33:20.973241] Epoch: [7]  [ 20/345]  eta: 0:01:24  lr: 0.000044  loss: 0.4028 (0.4088)  time: 0.2428  data: 0.0001  max mem: 11902
[16:33:25.836811] Epoch: [7]  [ 40/345]  eta: 0:01:16  lr: 0.000044  loss: 0.3987 (0.4105)  time: 0.2431  data: 0.0001  max mem: 11902
[16:33:30.711061] Epoch: [7]  [ 60/345]  eta: 0:01:10  lr: 0.000045  loss: 0.3967 (0.4073)  time: 0.2437  data: 0.0001  max mem: 11902
[16:33:35.581802] Epoch: [7]  [ 80/345]  eta: 0:01:05  lr: 0.000045  loss: 0.4156 (0.4103)  time: 0.2435  data: 0.0001  max mem: 11902
[16:33:40.472346] Epoch: [7]  [100/345]  eta: 0:01:00  lr: 0.000046  loss: 0.4068 (0.4086)  time: 0.2445  data: 0.0001  max mem: 11902
[16:33:45.357447] Epoch: [7]  [120/345]  eta: 0:00:55  lr: 0.000046  loss: 0.3847 (0.4062)  time: 0.2442  data: 0.0001  max mem: 11902
[16:33:50.245076] Epoch: [7]  [140/345]  eta: 0:00:50  lr: 0.000046  loss: 0.3634 (0.4037)  time: 0.2443  data: 0.0001  max mem: 11902
[16:33:55.137681] Epoch: [7]  [160/345]  eta: 0:00:45  lr: 0.000047  loss: 0.4159 (0.4047)  time: 0.2446  data: 0.0000  max mem: 11902
[16:34:00.023355] Epoch: [7]  [180/345]  eta: 0:00:40  lr: 0.000047  loss: 0.3838 (0.4027)  time: 0.2442  data: 0.0001  max mem: 11902
[16:34:04.916093] Epoch: [7]  [200/345]  eta: 0:00:35  lr: 0.000047  loss: 0.3797 (0.4014)  time: 0.2446  data: 0.0001  max mem: 11902
[16:34:09.803340] Epoch: [7]  [220/345]  eta: 0:00:30  lr: 0.000048  loss: 0.3758 (0.3991)  time: 0.2443  data: 0.0001  max mem: 11902
[16:34:14.690159] Epoch: [7]  [240/345]  eta: 0:00:25  lr: 0.000048  loss: 0.3823 (0.3987)  time: 0.2443  data: 0.0001  max mem: 11902
[16:34:19.574415] Epoch: [7]  [260/345]  eta: 0:00:20  lr: 0.000048  loss: 0.3944 (0.3982)  time: 0.2442  data: 0.0001  max mem: 11902
[16:34:24.460462] Epoch: [7]  [280/345]  eta: 0:00:15  lr: 0.000049  loss: 0.3774 (0.3975)  time: 0.2443  data: 0.0001  max mem: 11902
[16:34:29.351489] Epoch: [7]  [300/345]  eta: 0:00:11  lr: 0.000049  loss: 0.3882 (0.3974)  time: 0.2445  data: 0.0001  max mem: 11902
[16:34:34.239081] Epoch: [7]  [320/345]  eta: 0:00:06  lr: 0.000050  loss: 0.3794 (0.3961)  time: 0.2443  data: 0.0001  max mem: 11902
[16:34:39.129239] Epoch: [7]  [340/345]  eta: 0:00:01  lr: 0.000050  loss: 0.3951 (0.3964)  time: 0.2445  data: 0.0001  max mem: 11902
[16:34:40.107153] Epoch: [7]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.3951 (0.3963)  time: 0.2444  data: 0.0001  max mem: 11902
[16:34:40.188002] Epoch: [7] Total time: 0:01:24 (0.2454 s / it)
[16:34:40.188602] Averaged stats: lr: 0.000050  loss: 0.3951 (0.3963)
[16:34:40.621379] Test:  [  0/345]  eta: 0:02:27  loss: 0.4203 (0.4203)  time: 0.4284  data: 0.3512  max mem: 11902
[16:34:41.433241] Test:  [ 10/345]  eta: 0:00:37  loss: 0.3610 (0.3661)  time: 0.1127  data: 0.0337  max mem: 11902
[16:34:42.229642] Test:  [ 20/345]  eta: 0:00:31  loss: 0.3572 (0.3636)  time: 0.0803  data: 0.0010  max mem: 11902
[16:34:43.030026] Test:  [ 30/345]  eta: 0:00:28  loss: 0.3548 (0.3615)  time: 0.0798  data: 0.0001  max mem: 11902
[16:34:43.833163] Test:  [ 40/345]  eta: 0:00:27  loss: 0.3470 (0.3589)  time: 0.0801  data: 0.0001  max mem: 11902
[16:34:44.640742] Test:  [ 50/345]  eta: 0:00:25  loss: 0.3443 (0.3560)  time: 0.0805  data: 0.0001  max mem: 11902
[16:34:45.453024] Test:  [ 60/345]  eta: 0:00:24  loss: 0.3678 (0.3589)  time: 0.0809  data: 0.0001  max mem: 11902
[16:34:46.268235] Test:  [ 70/345]  eta: 0:00:23  loss: 0.3742 (0.3613)  time: 0.0813  data: 0.0001  max mem: 11902
[16:34:47.085463] Test:  [ 80/345]  eta: 0:00:22  loss: 0.3647 (0.3620)  time: 0.0816  data: 0.0001  max mem: 11902
[16:34:47.907098] Test:  [ 90/345]  eta: 0:00:21  loss: 0.3647 (0.3642)  time: 0.0819  data: 0.0001  max mem: 11902
[16:34:48.731904] Test:  [100/345]  eta: 0:00:20  loss: 0.3775 (0.3658)  time: 0.0822  data: 0.0001  max mem: 11902
[16:34:49.560672] Test:  [110/345]  eta: 0:00:19  loss: 0.3750 (0.3672)  time: 0.0826  data: 0.0001  max mem: 11902
[16:34:50.393993] Test:  [120/345]  eta: 0:00:18  loss: 0.3659 (0.3659)  time: 0.0830  data: 0.0001  max mem: 11902
[16:34:51.230267] Test:  [130/345]  eta: 0:00:18  loss: 0.3539 (0.3656)  time: 0.0834  data: 0.0001  max mem: 11902
[16:34:52.070979] Test:  [140/345]  eta: 0:00:17  loss: 0.3611 (0.3660)  time: 0.0838  data: 0.0001  max mem: 11902
[16:34:52.914399] Test:  [150/345]  eta: 0:00:16  loss: 0.3606 (0.3658)  time: 0.0841  data: 0.0001  max mem: 11902
[16:34:53.760220] Test:  [160/345]  eta: 0:00:15  loss: 0.3563 (0.3658)  time: 0.0844  data: 0.0001  max mem: 11902
[16:34:54.611241] Test:  [170/345]  eta: 0:00:14  loss: 0.3515 (0.3658)  time: 0.0848  data: 0.0001  max mem: 11902
[16:34:55.464604] Test:  [180/345]  eta: 0:00:13  loss: 0.3515 (0.3655)  time: 0.0851  data: 0.0001  max mem: 11902
[16:34:56.321613] Test:  [190/345]  eta: 0:00:13  loss: 0.3617 (0.3661)  time: 0.0854  data: 0.0001  max mem: 11902
[16:34:57.182715] Test:  [200/345]  eta: 0:00:12  loss: 0.3724 (0.3667)  time: 0.0858  data: 0.0001  max mem: 11902
[16:34:58.046422] Test:  [210/345]  eta: 0:00:11  loss: 0.3511 (0.3656)  time: 0.0862  data: 0.0001  max mem: 11902
[16:34:58.914490] Test:  [220/345]  eta: 0:00:10  loss: 0.3418 (0.3658)  time: 0.0865  data: 0.0001  max mem: 11902
[16:34:59.786126] Test:  [230/345]  eta: 0:00:09  loss: 0.3726 (0.3660)  time: 0.0869  data: 0.0001  max mem: 11902
[16:35:00.660418] Test:  [240/345]  eta: 0:00:08  loss: 0.3726 (0.3663)  time: 0.0872  data: 0.0001  max mem: 11902
[16:35:01.538781] Test:  [250/345]  eta: 0:00:08  loss: 0.3647 (0.3658)  time: 0.0876  data: 0.0001  max mem: 11902
[16:35:02.421272] Test:  [260/345]  eta: 0:00:07  loss: 0.3647 (0.3655)  time: 0.0880  data: 0.0001  max mem: 11902
[16:35:03.307029] Test:  [270/345]  eta: 0:00:06  loss: 0.3547 (0.3649)  time: 0.0883  data: 0.0001  max mem: 11902
[16:35:04.197059] Test:  [280/345]  eta: 0:00:05  loss: 0.3547 (0.3649)  time: 0.0887  data: 0.0001  max mem: 11902
[16:35:05.090204] Test:  [290/345]  eta: 0:00:04  loss: 0.3703 (0.3654)  time: 0.0890  data: 0.0001  max mem: 11902
[16:35:05.986857] Test:  [300/345]  eta: 0:00:03  loss: 0.3753 (0.3656)  time: 0.0894  data: 0.0001  max mem: 11902
[16:35:06.886434] Test:  [310/345]  eta: 0:00:03  loss: 0.3665 (0.3658)  time: 0.0897  data: 0.0001  max mem: 11902
[16:35:07.790487] Test:  [320/345]  eta: 0:00:02  loss: 0.3631 (0.3659)  time: 0.0901  data: 0.0001  max mem: 11902
[16:35:08.696604] Test:  [330/345]  eta: 0:00:01  loss: 0.3435 (0.3650)  time: 0.0905  data: 0.0001  max mem: 11902
[16:35:09.606109] Test:  [340/345]  eta: 0:00:00  loss: 0.3425 (0.3648)  time: 0.0907  data: 0.0001  max mem: 11902
[16:35:09.971860] Test:  [344/345]  eta: 0:00:00  loss: 0.3443 (0.3646)  time: 0.0909  data: 0.0001  max mem: 11902
[16:35:10.034497] Test: Total time: 0:00:29 (0.0865 s / it)
[16:35:19.830592] Test:  [ 0/57]  eta: 0:00:22  loss: 0.4720 (0.4720)  time: 0.4023  data: 0.3254  max mem: 11902
[16:35:20.624184] Test:  [10/57]  eta: 0:00:05  loss: 0.4610 (0.4645)  time: 0.1086  data: 0.0301  max mem: 11902
[16:35:21.415695] Test:  [20/57]  eta: 0:00:03  loss: 0.4097 (0.4407)  time: 0.0792  data: 0.0004  max mem: 11902
[16:35:22.210996] Test:  [30/57]  eta: 0:00:02  loss: 0.3056 (0.3980)  time: 0.0793  data: 0.0001  max mem: 11902
[16:35:23.010873] Test:  [40/57]  eta: 0:00:01  loss: 0.3093 (0.3836)  time: 0.0797  data: 0.0001  max mem: 11902
[16:35:23.813915] Test:  [50/57]  eta: 0:00:00  loss: 0.3548 (0.3908)  time: 0.0801  data: 0.0001  max mem: 11902
[16:35:24.249859] Test:  [56/57]  eta: 0:00:00  loss: 0.3932 (0.4163)  time: 0.0779  data: 0.0000  max mem: 11902
[16:35:24.316666] Test: Total time: 0:00:04 (0.0858 s / it)
[16:35:25.953115] Dice score of the network on the train images: 0.750095, val images: 0.509972
[16:35:25.956779] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:35:26.538062] Epoch: [8]  [  0/345]  eta: 0:03:20  lr: 0.000050  loss: 0.3812 (0.3812)  time: 0.5803  data: 0.3352  max mem: 11902
[16:35:31.394268] Epoch: [8]  [ 20/345]  eta: 0:01:24  lr: 0.000050  loss: 0.3840 (0.3904)  time: 0.2428  data: 0.0001  max mem: 11902
[16:35:36.269705] Epoch: [8]  [ 40/345]  eta: 0:01:16  lr: 0.000051  loss: 0.3717 (0.3838)  time: 0.2437  data: 0.0001  max mem: 11902
[16:35:41.139351] Epoch: [8]  [ 60/345]  eta: 0:01:10  lr: 0.000051  loss: 0.3680 (0.3761)  time: 0.2434  data: 0.0001  max mem: 11902
[16:35:46.016244] Epoch: [8]  [ 80/345]  eta: 0:01:05  lr: 0.000051  loss: 0.3501 (0.3716)  time: 0.2438  data: 0.0001  max mem: 11902
[16:35:50.903069] Epoch: [8]  [100/345]  eta: 0:01:00  lr: 0.000052  loss: 0.3631 (0.3707)  time: 0.2443  data: 0.0001  max mem: 11902
[16:35:55.786160] Epoch: [8]  [120/345]  eta: 0:00:55  lr: 0.000052  loss: 0.3369 (0.3684)  time: 0.2441  data: 0.0001  max mem: 11902
[16:36:00.664364] Epoch: [8]  [140/345]  eta: 0:00:50  lr: 0.000053  loss: 0.3657 (0.3673)  time: 0.2439  data: 0.0001  max mem: 11902
[16:36:05.557582] Epoch: [8]  [160/345]  eta: 0:00:45  lr: 0.000053  loss: 0.3597 (0.3672)  time: 0.2446  data: 0.0001  max mem: 11902
[16:36:10.454651] Epoch: [8]  [180/345]  eta: 0:00:40  lr: 0.000053  loss: 0.3526 (0.3664)  time: 0.2448  data: 0.0001  max mem: 11902
[16:36:15.356370] Epoch: [8]  [200/345]  eta: 0:00:35  lr: 0.000054  loss: 0.3659 (0.3660)  time: 0.2450  data: 0.0001  max mem: 11902
[16:36:20.237032] Epoch: [8]  [220/345]  eta: 0:00:30  lr: 0.000054  loss: 0.3253 (0.3639)  time: 0.2440  data: 0.0001  max mem: 11902
[16:36:25.117928] Epoch: [8]  [240/345]  eta: 0:00:25  lr: 0.000054  loss: 0.3271 (0.3618)  time: 0.2440  data: 0.0001  max mem: 11902
[16:36:30.002437] Epoch: [8]  [260/345]  eta: 0:00:20  lr: 0.000055  loss: 0.3249 (0.3597)  time: 0.2442  data: 0.0001  max mem: 11902
[16:36:34.892528] Epoch: [8]  [280/345]  eta: 0:00:15  lr: 0.000055  loss: 0.3500 (0.3589)  time: 0.2445  data: 0.0001  max mem: 11902
[16:36:39.792891] Epoch: [8]  [300/345]  eta: 0:00:11  lr: 0.000055  loss: 0.3517 (0.3580)  time: 0.2450  data: 0.0001  max mem: 11902
[16:36:44.695774] Epoch: [8]  [320/345]  eta: 0:00:06  lr: 0.000056  loss: 0.3420 (0.3573)  time: 0.2451  data: 0.0001  max mem: 11902
[16:36:49.592541] Epoch: [8]  [340/345]  eta: 0:00:01  lr: 0.000056  loss: 0.3400 (0.3568)  time: 0.2448  data: 0.0001  max mem: 11902
[16:36:50.570434] Epoch: [8]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.3400 (0.3567)  time: 0.2447  data: 0.0001  max mem: 11902
[16:36:50.649133] Epoch: [8] Total time: 0:01:24 (0.2455 s / it)
[16:36:50.649336] Averaged stats: lr: 0.000056  loss: 0.3400 (0.3567)
[16:36:51.092053] Test:  [  0/345]  eta: 0:02:31  loss: 0.3382 (0.3382)  time: 0.4387  data: 0.3615  max mem: 11902
[16:36:51.892822] Test:  [ 10/345]  eta: 0:00:37  loss: 0.3382 (0.3330)  time: 0.1126  data: 0.0335  max mem: 11902
[16:36:52.690058] Test:  [ 20/345]  eta: 0:00:31  loss: 0.3406 (0.3359)  time: 0.0798  data: 0.0004  max mem: 11902
[16:36:53.489805] Test:  [ 30/345]  eta: 0:00:28  loss: 0.3370 (0.3375)  time: 0.0798  data: 0.0001  max mem: 11902
[16:36:54.292747] Test:  [ 40/345]  eta: 0:00:27  loss: 0.3268 (0.3344)  time: 0.0801  data: 0.0001  max mem: 11902
[16:36:55.100847] Test:  [ 50/345]  eta: 0:00:25  loss: 0.3170 (0.3319)  time: 0.0805  data: 0.0001  max mem: 11902
[16:36:55.912256] Test:  [ 60/345]  eta: 0:00:24  loss: 0.3265 (0.3320)  time: 0.0809  data: 0.0001  max mem: 11902
[16:36:56.727060] Test:  [ 70/345]  eta: 0:00:23  loss: 0.3362 (0.3341)  time: 0.0812  data: 0.0001  max mem: 11902
[16:36:57.545247] Test:  [ 80/345]  eta: 0:00:22  loss: 0.3290 (0.3347)  time: 0.0816  data: 0.0001  max mem: 11902
[16:36:58.366750] Test:  [ 90/345]  eta: 0:00:21  loss: 0.3261 (0.3322)  time: 0.0819  data: 0.0001  max mem: 11902
[16:36:59.191140] Test:  [100/345]  eta: 0:00:20  loss: 0.3383 (0.3339)  time: 0.0822  data: 0.0001  max mem: 11902
[16:37:00.019592] Test:  [110/345]  eta: 0:00:19  loss: 0.3390 (0.3327)  time: 0.0826  data: 0.0001  max mem: 11902
[16:37:00.852957] Test:  [120/345]  eta: 0:00:18  loss: 0.3209 (0.3326)  time: 0.0830  data: 0.0001  max mem: 11902
[16:37:01.689039] Test:  [130/345]  eta: 0:00:18  loss: 0.3380 (0.3324)  time: 0.0834  data: 0.0001  max mem: 11902
[16:37:02.528817] Test:  [140/345]  eta: 0:00:17  loss: 0.3400 (0.3329)  time: 0.0837  data: 0.0001  max mem: 11902
[16:37:03.371817] Test:  [150/345]  eta: 0:00:16  loss: 0.3233 (0.3322)  time: 0.0841  data: 0.0001  max mem: 11902
[16:37:04.217674] Test:  [160/345]  eta: 0:00:15  loss: 0.3109 (0.3310)  time: 0.0844  data: 0.0001  max mem: 11902
[16:37:05.068397] Test:  [170/345]  eta: 0:00:14  loss: 0.3177 (0.3307)  time: 0.0848  data: 0.0001  max mem: 11902
[16:37:05.921924] Test:  [180/345]  eta: 0:00:13  loss: 0.3294 (0.3312)  time: 0.0851  data: 0.0001  max mem: 11902
[16:37:06.778907] Test:  [190/345]  eta: 0:00:13  loss: 0.3413 (0.3311)  time: 0.0854  data: 0.0001  max mem: 11902
[16:37:07.639469] Test:  [200/345]  eta: 0:00:12  loss: 0.3277 (0.3318)  time: 0.0858  data: 0.0001  max mem: 11902
[16:37:08.502983] Test:  [210/345]  eta: 0:00:11  loss: 0.3341 (0.3315)  time: 0.0861  data: 0.0001  max mem: 11902
[16:37:09.370644] Test:  [220/345]  eta: 0:00:10  loss: 0.3310 (0.3313)  time: 0.0865  data: 0.0001  max mem: 11902
[16:37:10.241809] Test:  [230/345]  eta: 0:00:09  loss: 0.3310 (0.3310)  time: 0.0869  data: 0.0001  max mem: 11902
[16:37:11.117025] Test:  [240/345]  eta: 0:00:08  loss: 0.3321 (0.3317)  time: 0.0872  data: 0.0001  max mem: 11902
[16:37:11.996012] Test:  [250/345]  eta: 0:00:08  loss: 0.3386 (0.3320)  time: 0.0876  data: 0.0001  max mem: 11902
[16:37:12.877639] Test:  [260/345]  eta: 0:00:07  loss: 0.3265 (0.3321)  time: 0.0880  data: 0.0001  max mem: 11902
[16:37:13.763685] Test:  [270/345]  eta: 0:00:06  loss: 0.3237 (0.3321)  time: 0.0883  data: 0.0001  max mem: 11902
[16:37:14.652684] Test:  [280/345]  eta: 0:00:05  loss: 0.3424 (0.3326)  time: 0.0887  data: 0.0001  max mem: 11902
[16:37:15.545355] Test:  [290/345]  eta: 0:00:04  loss: 0.3526 (0.3330)  time: 0.0890  data: 0.0001  max mem: 11902
[16:37:16.441350] Test:  [300/345]  eta: 0:00:03  loss: 0.3345 (0.3328)  time: 0.0894  data: 0.0001  max mem: 11902
[16:37:17.340899] Test:  [310/345]  eta: 0:00:03  loss: 0.3312 (0.3332)  time: 0.0897  data: 0.0001  max mem: 11902
[16:37:18.245031] Test:  [320/345]  eta: 0:00:02  loss: 0.3424 (0.3334)  time: 0.0901  data: 0.0001  max mem: 11902
[16:37:19.152118] Test:  [330/345]  eta: 0:00:01  loss: 0.3295 (0.3329)  time: 0.0905  data: 0.0001  max mem: 11902
[16:37:20.062022] Test:  [340/345]  eta: 0:00:00  loss: 0.3051 (0.3326)  time: 0.0908  data: 0.0001  max mem: 11902
[16:37:20.427007] Test:  [344/345]  eta: 0:00:00  loss: 0.3415 (0.3330)  time: 0.0909  data: 0.0001  max mem: 11902
[16:37:20.499483] Test: Total time: 0:00:29 (0.0865 s / it)
[16:37:30.318237] Test:  [ 0/57]  eta: 0:00:22  loss: 0.4566 (0.4566)  time: 0.4030  data: 0.3240  max mem: 11902
[16:37:31.110853] Test:  [10/57]  eta: 0:00:05  loss: 0.4416 (0.4583)  time: 0.1086  data: 0.0301  max mem: 11902
[16:37:31.904408] Test:  [20/57]  eta: 0:00:03  loss: 0.4122 (0.4531)  time: 0.0792  data: 0.0004  max mem: 11902
[16:37:32.700468] Test:  [30/57]  eta: 0:00:02  loss: 0.3021 (0.3973)  time: 0.0794  data: 0.0001  max mem: 11902
[16:37:33.499562] Test:  [40/57]  eta: 0:00:01  loss: 0.2647 (0.3685)  time: 0.0797  data: 0.0001  max mem: 11902
[16:37:34.301917] Test:  [50/57]  eta: 0:00:00  loss: 0.2767 (0.3690)  time: 0.0800  data: 0.0001  max mem: 11902
[16:37:34.737852] Test:  [56/57]  eta: 0:00:00  loss: 0.3337 (0.3728)  time: 0.0779  data: 0.0000  max mem: 11902
[16:37:34.814567] Test: Total time: 0:00:04 (0.0860 s / it)
[16:37:36.458262] Dice score of the network on the train images: 0.715602, val images: 0.485827
[16:37:36.458487] saving best_rec_model_0 @ epoch 8
[16:37:37.426950] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:37:38.009583] Epoch: [9]  [  0/345]  eta: 0:03:20  lr: 0.000056  loss: 0.2789 (0.2789)  time: 0.5816  data: 0.3356  max mem: 11902
[16:37:42.874006] Epoch: [9]  [ 20/345]  eta: 0:01:24  lr: 0.000057  loss: 0.3334 (0.3317)  time: 0.2432  data: 0.0001  max mem: 11902
[16:37:47.757820] Epoch: [9]  [ 40/345]  eta: 0:01:16  lr: 0.000057  loss: 0.3310 (0.3350)  time: 0.2441  data: 0.0001  max mem: 11902
[16:37:52.631272] Epoch: [9]  [ 60/345]  eta: 0:01:11  lr: 0.000057  loss: 0.3433 (0.3399)  time: 0.2436  data: 0.0001  max mem: 11902
[16:37:57.513718] Epoch: [9]  [ 80/345]  eta: 0:01:05  lr: 0.000058  loss: 0.3179 (0.3350)  time: 0.2441  data: 0.0001  max mem: 11902
[16:38:02.402160] Epoch: [9]  [100/345]  eta: 0:01:00  lr: 0.000058  loss: 0.3198 (0.3320)  time: 0.2444  data: 0.0001  max mem: 11902
[16:38:07.293815] Epoch: [9]  [120/345]  eta: 0:00:55  lr: 0.000058  loss: 0.3469 (0.3330)  time: 0.2445  data: 0.0001  max mem: 11902
[16:38:12.187710] Epoch: [9]  [140/345]  eta: 0:00:50  lr: 0.000059  loss: 0.3287 (0.3333)  time: 0.2447  data: 0.0001  max mem: 11902
[16:38:17.082218] Epoch: [9]  [160/345]  eta: 0:00:45  lr: 0.000059  loss: 0.3264 (0.3337)  time: 0.2447  data: 0.0001  max mem: 11902
[16:38:21.972404] Epoch: [9]  [180/345]  eta: 0:00:40  lr: 0.000060  loss: 0.3435 (0.3351)  time: 0.2445  data: 0.0001  max mem: 11902
[16:38:26.868925] Epoch: [9]  [200/345]  eta: 0:00:35  lr: 0.000060  loss: 0.3422 (0.3353)  time: 0.2448  data: 0.0001  max mem: 11902
[16:38:31.766215] Epoch: [9]  [220/345]  eta: 0:00:30  lr: 0.000060  loss: 0.3372 (0.3353)  time: 0.2448  data: 0.0001  max mem: 11902
[16:38:36.666498] Epoch: [9]  [240/345]  eta: 0:00:25  lr: 0.000061  loss: 0.3076 (0.3339)  time: 0.2450  data: 0.0001  max mem: 11902
[16:38:41.566353] Epoch: [9]  [260/345]  eta: 0:00:20  lr: 0.000061  loss: 0.3125 (0.3329)  time: 0.2449  data: 0.0001  max mem: 11902
[16:38:46.537018] Epoch: [9]  [280/345]  eta: 0:00:15  lr: 0.000061  loss: 0.3058 (0.3318)  time: 0.2485  data: 0.0001  max mem: 11902
[16:38:51.435544] Epoch: [9]  [300/345]  eta: 0:00:11  lr: 0.000062  loss: 0.2971 (0.3306)  time: 0.2449  data: 0.0001  max mem: 11902

[16:38:56.337817] Epoch: [9]  [320/345]  eta: 0:00:06  lr: 0.000062  loss: 0.3131 (0.3295)  time: 0.2451  data: 0.0001  max mem: 11902
[16:39:01.226559] Epoch: [9]  [340/345]  eta: 0:00:01  lr: 0.000062  loss: 0.3149 (0.3288)  time: 0.2444  data: 0.0001  max mem: 11902
[16:39:02.204276] Epoch: [9]  [344/345]  eta: 0:00:00  lr: 0.000062  loss: 0.3096 (0.3288)  time: 0.2441  data: 0.0001  max mem: 11902
[16:39:02.274955] Epoch: [9] Total time: 0:01:24 (0.2459 s / it)
[16:39:02.275334] Averaged stats: lr: 0.000062  loss: 0.3096 (0.3288)
[16:39:02.716742] Test:  [  0/345]  eta: 0:02:30  loss: 0.2573 (0.2573)  time: 0.4361  data: 0.3591  max mem: 11902
[16:39:03.517459] Test:  [ 10/345]  eta: 0:00:37  loss: 0.2842 (0.2897)  time: 0.1123  data: 0.0333  max mem: 11902
[16:39:04.316646] Test:  [ 20/345]  eta: 0:00:31  loss: 0.3074 (0.3104)  time: 0.0799  data: 0.0004  max mem: 11902
[16:39:05.119785] Test:  [ 30/345]  eta: 0:00:28  loss: 0.3132 (0.3064)  time: 0.0800  data: 0.0001  max mem: 11902
[16:39:05.924328] Test:  [ 40/345]  eta: 0:00:27  loss: 0.2998 (0.3030)  time: 0.0803  data: 0.0001  max mem: 11902
[16:39:06.731483] Test:  [ 50/345]  eta: 0:00:25  loss: 0.2998 (0.3034)  time: 0.0805  data: 0.0001  max mem: 11902
[16:39:07.544145] Test:  [ 60/345]  eta: 0:00:24  loss: 0.3065 (0.3048)  time: 0.0809  data: 0.0001  max mem: 11902
[16:39:08.359747] Test:  [ 70/345]  eta: 0:00:23  loss: 0.2937 (0.3033)  time: 0.0813  data: 0.0001  max mem: 11902
[16:39:09.177391] Test:  [ 80/345]  eta: 0:00:22  loss: 0.2898 (0.3028)  time: 0.0816  data: 0.0001  max mem: 11902
[16:39:09.999687] Test:  [ 90/345]  eta: 0:00:21  loss: 0.2891 (0.3023)  time: 0.0819  data: 0.0001  max mem: 11902
[16:39:10.825628] Test:  [100/345]  eta: 0:00:20  loss: 0.2950 (0.3005)  time: 0.0823  data: 0.0001  max mem: 11902
[16:39:11.655405] Test:  [110/345]  eta: 0:00:19  loss: 0.2888 (0.3001)  time: 0.0827  data: 0.0001  max mem: 11902
[16:39:12.488823] Test:  [120/345]  eta: 0:00:18  loss: 0.2967 (0.3008)  time: 0.0831  data: 0.0001  max mem: 11902
[16:39:13.325362] Test:  [130/345]  eta: 0:00:18  loss: 0.3035 (0.3012)  time: 0.0834  data: 0.0001  max mem: 11902
[16:39:14.165969] Test:  [140/345]  eta: 0:00:17  loss: 0.2937 (0.3005)  time: 0.0838  data: 0.0001  max mem: 11902
[16:39:15.009323] Test:  [150/345]  eta: 0:00:16  loss: 0.2937 (0.3015)  time: 0.0841  data: 0.0001  max mem: 11902
[16:39:15.855631] Test:  [160/345]  eta: 0:00:15  loss: 0.2990 (0.3011)  time: 0.0844  data: 0.0001  max mem: 11902
[16:39:16.706976] Test:  [170/345]  eta: 0:00:14  loss: 0.2906 (0.3007)  time: 0.0848  data: 0.0001  max mem: 11902
[16:39:17.561016] Test:  [180/345]  eta: 0:00:13  loss: 0.2941 (0.3005)  time: 0.0852  data: 0.0001  max mem: 11902
[16:39:18.418971] Test:  [190/345]  eta: 0:00:13  loss: 0.2941 (0.3001)  time: 0.0855  data: 0.0001  max mem: 11902
[16:39:19.280837] Test:  [200/345]  eta: 0:00:12  loss: 0.2836 (0.2993)  time: 0.0859  data: 0.0001  max mem: 11902
[16:39:20.146236] Test:  [210/345]  eta: 0:00:11  loss: 0.2936 (0.2997)  time: 0.0863  data: 0.0001  max mem: 11902
[16:39:21.015345] Test:  [220/345]  eta: 0:00:10  loss: 0.2942 (0.2991)  time: 0.0866  data: 0.0001  max mem: 11902
[16:39:21.886850] Test:  [230/345]  eta: 0:00:09  loss: 0.2866 (0.2989)  time: 0.0869  data: 0.0001  max mem: 11902
[16:39:22.763642] Test:  [240/345]  eta: 0:00:08  loss: 0.2952 (0.2995)  time: 0.0873  data: 0.0001  max mem: 11902
[16:39:23.643315] Test:  [250/345]  eta: 0:00:08  loss: 0.3020 (0.2996)  time: 0.0877  data: 0.0001  max mem: 11902
[16:39:24.526223] Test:  [260/345]  eta: 0:00:07  loss: 0.3016 (0.2997)  time: 0.0880  data: 0.0001  max mem: 11902
[16:39:25.412815] Test:  [270/345]  eta: 0:00:06  loss: 0.3089 (0.3003)  time: 0.0884  data: 0.0001  max mem: 11902
[16:39:26.301967] Test:  [280/345]  eta: 0:00:05  loss: 0.3047 (0.3004)  time: 0.0887  data: 0.0001  max mem: 11902
[16:39:27.194994] Test:  [290/345]  eta: 0:00:04  loss: 0.3035 (0.3003)  time: 0.0890  data: 0.0001  max mem: 11902
[16:39:28.091823] Test:  [300/345]  eta: 0:00:03  loss: 0.3087 (0.3009)  time: 0.0894  data: 0.0001  max mem: 11902
[16:39:28.993001] Test:  [310/345]  eta: 0:00:03  loss: 0.3060 (0.3008)  time: 0.0898  data: 0.0001  max mem: 11902
[16:39:29.897118] Test:  [320/345]  eta: 0:00:02  loss: 0.2974 (0.3011)  time: 0.0902  data: 0.0001  max mem: 11902
[16:39:30.804239] Test:  [330/345]  eta: 0:00:01  loss: 0.2943 (0.3010)  time: 0.0905  data: 0.0001  max mem: 11902
[16:39:31.714349] Test:  [340/345]  eta: 0:00:00  loss: 0.2956 (0.3016)  time: 0.0908  data: 0.0001  max mem: 11902
[16:39:32.080059] Test:  [344/345]  eta: 0:00:00  loss: 0.3106 (0.3016)  time: 0.0910  data: 0.0001  max mem: 11902
[16:39:32.141262] Test: Total time: 0:00:29 (0.0866 s / it)
[16:39:42.033971] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4495 (0.4495)  time: 0.4104  data: 0.3331  max mem: 11902
[16:39:42.822371] Test:  [10/57]  eta: 0:00:05  loss: 0.4186 (0.4269)  time: 0.1089  data: 0.0304  max mem: 11902
[16:39:43.615224] Test:  [20/57]  eta: 0:00:03  loss: 0.3981 (0.4206)  time: 0.0790  data: 0.0001  max mem: 11902
[16:39:44.409726] Test:  [30/57]  eta: 0:00:02  loss: 0.2830 (0.3738)  time: 0.0793  data: 0.0001  max mem: 11902
[16:39:45.209465] Test:  [40/57]  eta: 0:00:01  loss: 0.2545 (0.3487)  time: 0.0796  data: 0.0001  max mem: 11902
[16:39:46.011333] Test:  [50/57]  eta: 0:00:00  loss: 0.2907 (0.3535)  time: 0.0800  data: 0.0001  max mem: 11902
[16:39:46.447091] Test:  [56/57]  eta: 0:00:00  loss: 0.3266 (0.3773)  time: 0.0779  data: 0.0001  max mem: 11902
[16:39:46.520992] Test: Total time: 0:00:04 (0.0859 s / it)
[16:39:48.183625] Dice score of the network on the train images: 0.754549, val images: 0.431617
[16:39:48.187280] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:39:48.764339] Epoch: [10]  [  0/345]  eta: 0:03:18  lr: 0.000063  loss: 0.3610 (0.3610)  time: 0.5760  data: 0.3292  max mem: 11902
[16:39:53.640561] Epoch: [10]  [ 20/345]  eta: 0:01:24  lr: 0.000063  loss: 0.3169 (0.3200)  time: 0.2438  data: 0.0001  max mem: 11902
[16:39:58.515833] Epoch: [10]  [ 40/345]  eta: 0:01:16  lr: 0.000063  loss: 0.3105 (0.3189)  time: 0.2437  data: 0.0001  max mem: 11902
[16:40:03.389210] Epoch: [10]  [ 60/345]  eta: 0:01:11  lr: 0.000064  loss: 0.3029 (0.3147)  time: 0.2436  data: 0.0001  max mem: 11902
[16:40:08.275848] Epoch: [10]  [ 80/345]  eta: 0:01:05  lr: 0.000064  loss: 0.3093 (0.3128)  time: 0.2443  data: 0.0001  max mem: 11902
[16:40:13.161512] Epoch: [10]  [100/345]  eta: 0:01:00  lr: 0.000064  loss: 0.2874 (0.3088)  time: 0.2442  data: 0.0001  max mem: 11902
[16:40:18.052848] Epoch: [10]  [120/345]  eta: 0:00:55  lr: 0.000065  loss: 0.2977 (0.3087)  time: 0.2445  data: 0.0001  max mem: 11902
[16:40:22.935941] Epoch: [10]  [140/345]  eta: 0:00:50  lr: 0.000065  loss: 0.2946 (0.3078)  time: 0.2441  data: 0.0001  max mem: 11902
[16:40:27.823375] Epoch: [10]  [160/345]  eta: 0:00:45  lr: 0.000065  loss: 0.2890 (0.3073)  time: 0.2443  data: 0.0001  max mem: 11902
[16:40:32.713214] Epoch: [10]  [180/345]  eta: 0:00:40  lr: 0.000066  loss: 0.3224 (0.3091)  time: 0.2444  data: 0.0001  max mem: 11902
[16:40:37.602655] Epoch: [10]  [200/345]  eta: 0:00:35  lr: 0.000066  loss: 0.3075 (0.3100)  time: 0.2444  data: 0.0001  max mem: 11902
[16:40:42.489857] Epoch: [10]  [220/345]  eta: 0:00:30  lr: 0.000066  loss: 0.3049 (0.3097)  time: 0.2443  data: 0.0001  max mem: 11902
[16:40:47.379319] Epoch: [10]  [240/345]  eta: 0:00:25  lr: 0.000067  loss: 0.2805 (0.3093)  time: 0.2444  data: 0.0001  max mem: 11902
[16:40:52.273312] Epoch: [10]  [260/345]  eta: 0:00:20  lr: 0.000067  loss: 0.3030 (0.3088)  time: 0.2447  data: 0.0001  max mem: 11902
[16:40:57.173119] Epoch: [10]  [280/345]  eta: 0:00:15  lr: 0.000068  loss: 0.2947 (0.3081)  time: 0.2449  data: 0.0001  max mem: 11902
[16:41:02.068897] Epoch: [10]  [300/345]  eta: 0:00:11  lr: 0.000068  loss: 0.2903 (0.3076)  time: 0.2447  data: 0.0001  max mem: 11902
[16:41:06.966488] Epoch: [10]  [320/345]  eta: 0:00:06  lr: 0.000068  loss: 0.2902 (0.3069)  time: 0.2448  data: 0.0001  max mem: 11902
[16:41:11.862126] Epoch: [10]  [340/345]  eta: 0:00:01  lr: 0.000069  loss: 0.2774 (0.3057)  time: 0.2447  data: 0.0001  max mem: 11902
[16:41:12.840776] Epoch: [10]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.2727 (0.3053)  time: 0.2447  data: 0.0001  max mem: 11902
[16:41:12.914705] Epoch: [10] Total time: 0:01:24 (0.2456 s / it)
[16:41:12.914964] Averaged stats: lr: 0.000069  loss: 0.2727 (0.3053)
[16:41:13.338601] Test:  [  0/345]  eta: 0:02:24  loss: 0.2790 (0.2790)  time: 0.4200  data: 0.3430  max mem: 11902
[16:41:14.137037] Test:  [ 10/345]  eta: 0:00:37  loss: 0.2662 (0.2738)  time: 0.1107  data: 0.0318  max mem: 11902
[16:41:14.935877] Test:  [ 20/345]  eta: 0:00:31  loss: 0.2662 (0.2770)  time: 0.0798  data: 0.0004  max mem: 11902
[16:41:15.737945] Test:  [ 30/345]  eta: 0:00:28  loss: 0.2813 (0.2783)  time: 0.0800  data: 0.0001  max mem: 11902
[16:41:16.540774] Test:  [ 40/345]  eta: 0:00:26  loss: 0.2774 (0.2812)  time: 0.0802  data: 0.0001  max mem: 11902
[16:41:17.348553] Test:  [ 50/345]  eta: 0:00:25  loss: 0.2769 (0.2813)  time: 0.0805  data: 0.0001  max mem: 11902
[16:41:18.159674] Test:  [ 60/345]  eta: 0:00:24  loss: 0.2776 (0.2832)  time: 0.0809  data: 0.0001  max mem: 11902
[16:41:18.973822] Test:  [ 70/345]  eta: 0:00:23  loss: 0.2776 (0.2825)  time: 0.0812  data: 0.0001  max mem: 11902
[16:41:19.790818] Test:  [ 80/345]  eta: 0:00:22  loss: 0.2752 (0.2822)  time: 0.0815  data: 0.0001  max mem: 11902
[16:41:20.612416] Test:  [ 90/345]  eta: 0:00:21  loss: 0.2658 (0.2806)  time: 0.0819  data: 0.0001  max mem: 11902
[16:41:21.435869] Test:  [100/345]  eta: 0:00:20  loss: 0.2610 (0.2803)  time: 0.0822  data: 0.0001  max mem: 11902
[16:41:22.263722] Test:  [110/345]  eta: 0:00:19  loss: 0.2683 (0.2803)  time: 0.0825  data: 0.0001  max mem: 11902
[16:41:23.094921] Test:  [120/345]  eta: 0:00:18  loss: 0.2647 (0.2800)  time: 0.0829  data: 0.0001  max mem: 11902
[16:41:23.930353] Test:  [130/345]  eta: 0:00:18  loss: 0.2695 (0.2811)  time: 0.0833  data: 0.0001  max mem: 11902
[16:41:24.768469] Test:  [140/345]  eta: 0:00:17  loss: 0.2740 (0.2816)  time: 0.0836  data: 0.0001  max mem: 11902
[16:41:25.610576] Test:  [150/345]  eta: 0:00:16  loss: 0.2736 (0.2815)  time: 0.0839  data: 0.0001  max mem: 11902
[16:41:26.457013] Test:  [160/345]  eta: 0:00:15  loss: 0.2701 (0.2808)  time: 0.0844  data: 0.0001  max mem: 11902
[16:41:27.306738] Test:  [170/345]  eta: 0:00:14  loss: 0.2749 (0.2813)  time: 0.0847  data: 0.0001  max mem: 11902
[16:41:28.160195] Test:  [180/345]  eta: 0:00:13  loss: 0.2888 (0.2823)  time: 0.0851  data: 0.0001  max mem: 11902
[16:41:29.018098] Test:  [190/345]  eta: 0:00:13  loss: 0.2912 (0.2826)  time: 0.0855  data: 0.0001  max mem: 11902
[16:41:29.878659] Test:  [200/345]  eta: 0:00:12  loss: 0.2809 (0.2825)  time: 0.0859  data: 0.0001  max mem: 11902
[16:41:30.742927] Test:  [210/345]  eta: 0:00:11  loss: 0.2625 (0.2819)  time: 0.0862  data: 0.0001  max mem: 11902
[16:41:31.611259] Test:  [220/345]  eta: 0:00:10  loss: 0.2792 (0.2822)  time: 0.0866  data: 0.0001  max mem: 11902
[16:41:32.483836] Test:  [230/345]  eta: 0:00:09  loss: 0.2792 (0.2820)  time: 0.0870  data: 0.0001  max mem: 11902
[16:41:33.357965] Test:  [240/345]  eta: 0:00:08  loss: 0.2746 (0.2820)  time: 0.0873  data: 0.0001  max mem: 11902
[16:41:34.236673] Test:  [250/345]  eta: 0:00:08  loss: 0.2683 (0.2816)  time: 0.0876  data: 0.0001  max mem: 11902
[16:41:35.118659] Test:  [260/345]  eta: 0:00:07  loss: 0.2583 (0.2811)  time: 0.0880  data: 0.0001  max mem: 11902
[16:41:36.004791] Test:  [270/345]  eta: 0:00:06  loss: 0.2693 (0.2813)  time: 0.0883  data: 0.0001  max mem: 11902
[16:41:36.893426] Test:  [280/345]  eta: 0:00:05  loss: 0.2629 (0.2811)  time: 0.0887  data: 0.0001  max mem: 11902
[16:41:37.786410] Test:  [290/345]  eta: 0:00:04  loss: 0.2631 (0.2807)  time: 0.0890  data: 0.0001  max mem: 11902
[16:41:38.683198] Test:  [300/345]  eta: 0:00:03  loss: 0.2771 (0.2804)  time: 0.0894  data: 0.0001  max mem: 11902
[16:41:39.582728] Test:  [310/345]  eta: 0:00:02  loss: 0.2781 (0.2806)  time: 0.0898  data: 0.0001  max mem: 11902
[16:41:40.486166] Test:  [320/345]  eta: 0:00:02  loss: 0.2676 (0.2800)  time: 0.0901  data: 0.0001  max mem: 11902
[16:41:41.392722] Test:  [330/345]  eta: 0:00:01  loss: 0.2602 (0.2797)  time: 0.0904  data: 0.0001  max mem: 11902
[16:41:42.303251] Test:  [340/345]  eta: 0:00:00  loss: 0.2712 (0.2798)  time: 0.0908  data: 0.0001  max mem: 11902
[16:41:42.667913] Test:  [344/345]  eta: 0:00:00  loss: 0.2788 (0.2802)  time: 0.0910  data: 0.0001  max mem: 11902
[16:41:42.730038] Test: Total time: 0:00:29 (0.0864 s / it)
[16:41:52.593207] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4446 (0.4446)  time: 0.4107  data: 0.3333  max mem: 11902
[16:41:53.381237] Test:  [10/57]  eta: 0:00:05  loss: 0.4443 (0.4462)  time: 0.1089  data: 0.0304  max mem: 11902
[16:41:54.174010] Test:  [20/57]  eta: 0:00:03  loss: 0.4095 (0.4343)  time: 0.0789  data: 0.0001  max mem: 11902
[16:41:54.968986] Test:  [30/57]  eta: 0:00:02  loss: 0.2781 (0.3811)  time: 0.0793  data: 0.0001  max mem: 11902
[16:41:55.768009] Test:  [40/57]  eta: 0:00:01  loss: 0.2647 (0.3605)  time: 0.0796  data: 0.0001  max mem: 11902
[16:41:56.569184] Test:  [50/57]  eta: 0:00:00  loss: 0.2920 (0.3649)  time: 0.0800  data: 0.0001  max mem: 11902
[16:41:57.003918] Test:  [56/57]  eta: 0:00:00  loss: 0.3644 (0.3869)  time: 0.0778  data: 0.0001  max mem: 11902
[16:41:57.064149] Test: Total time: 0:00:04 (0.0857 s / it)
[16:41:58.709541] Dice score of the network on the train images: 0.772960, val images: 0.493714
[16:41:58.712930] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:41:59.359059] Epoch: [11]  [  0/345]  eta: 0:03:42  lr: 0.000069  loss: 0.2801 (0.2801)  time: 0.6452  data: 0.3992  max mem: 11902
[16:42:04.229841] Epoch: [11]  [ 20/345]  eta: 0:01:25  lr: 0.000069  loss: 0.2830 (0.2867)  time: 0.2435  data: 0.0001  max mem: 11902

[16:42:09.106337] Epoch: [11]  [ 40/345]  eta: 0:01:17  lr: 0.000069  loss: 0.2854 (0.2908)  time: 0.2438  data: 0.0001  max mem: 11902
[16:42:13.986027] Epoch: [11]  [ 60/345]  eta: 0:01:11  lr: 0.000070  loss: 0.2770 (0.2890)  time: 0.2439  data: 0.0001  max mem: 11902
[16:42:18.870314] Epoch: [11]  [ 80/345]  eta: 0:01:05  lr: 0.000070  loss: 0.2811 (0.2884)  time: 0.2442  data: 0.0001  max mem: 11902
[16:42:23.758820] Epoch: [11]  [100/345]  eta: 0:01:00  lr: 0.000071  loss: 0.2849 (0.2890)  time: 0.2444  data: 0.0001  max mem: 11902
[16:42:28.656074] Epoch: [11]  [120/345]  eta: 0:00:55  lr: 0.000071  loss: 0.3067 (0.2910)  time: 0.2448  data: 0.0001  max mem: 11902
[16:42:33.548919] Epoch: [11]  [140/345]  eta: 0:00:50  lr: 0.000071  loss: 0.2846 (0.2907)  time: 0.2446  data: 0.0001  max mem: 11902
[16:42:38.445242] Epoch: [11]  [160/345]  eta: 0:00:45  lr: 0.000072  loss: 0.2863 (0.2904)  time: 0.2448  data: 0.0001  max mem: 11902
[16:42:43.332670] Epoch: [11]  [180/345]  eta: 0:00:40  lr: 0.000072  loss: 0.2825 (0.2904)  time: 0.2443  data: 0.0001  max mem: 11902
[16:42:48.222044] Epoch: [11]  [200/345]  eta: 0:00:35  lr: 0.000072  loss: 0.2741 (0.2890)  time: 0.2444  data: 0.0001  max mem: 11902
[16:42:53.110225] Epoch: [11]  [220/345]  eta: 0:00:30  lr: 0.000073  loss: 0.2901 (0.2889)  time: 0.2444  data: 0.0001  max mem: 11902
[16:42:58.003226] Epoch: [11]  [240/345]  eta: 0:00:25  lr: 0.000073  loss: 0.2944 (0.2890)  time: 0.2446  data: 0.0001  max mem: 11902
[16:43:02.899503] Epoch: [11]  [260/345]  eta: 0:00:20  lr: 0.000073  loss: 0.2879 (0.2890)  time: 0.2448  data: 0.0001  max mem: 11902
[16:43:07.796992] Epoch: [11]  [280/345]  eta: 0:00:15  lr: 0.000074  loss: 0.2711 (0.2884)  time: 0.2448  data: 0.0001  max mem: 11902
[16:43:12.695619] Epoch: [11]  [300/345]  eta: 0:00:11  lr: 0.000074  loss: 0.2683 (0.2870)  time: 0.2449  data: 0.0001  max mem: 11902
[16:43:17.592328] Epoch: [11]  [320/345]  eta: 0:00:06  lr: 0.000075  loss: 0.2708 (0.2862)  time: 0.2448  data: 0.0001  max mem: 11902
[16:43:22.486502] Epoch: [11]  [340/345]  eta: 0:00:01  lr: 0.000075  loss: 0.2946 (0.2868)  time: 0.2447  data: 0.0001  max mem: 11902
[16:43:23.465504] Epoch: [11]  [344/345]  eta: 0:00:00  lr: 0.000075  loss: 0.2874 (0.2865)  time: 0.2445  data: 0.0001  max mem: 11902
[16:43:23.524299] Epoch: [11] Total time: 0:01:24 (0.2458 s / it)
[16:43:23.524642] Averaged stats: lr: 0.000075  loss: 0.2874 (0.2865)
[16:43:23.957954] Test:  [  0/345]  eta: 0:02:27  loss: 0.2482 (0.2482)  time: 0.4284  data: 0.3513  max mem: 11902
[16:43:24.767562] Test:  [ 10/345]  eta: 0:00:37  loss: 0.2598 (0.2603)  time: 0.1124  data: 0.0336  max mem: 11902
[16:43:25.564896] Test:  [ 20/345]  eta: 0:00:31  loss: 0.2599 (0.2611)  time: 0.0802  data: 0.0010  max mem: 11902
[16:43:26.365867] Test:  [ 30/345]  eta: 0:00:28  loss: 0.2635 (0.2646)  time: 0.0798  data: 0.0001  max mem: 11902
[16:43:27.170007] Test:  [ 40/345]  eta: 0:00:27  loss: 0.2595 (0.2627)  time: 0.0802  data: 0.0001  max mem: 11902
[16:43:27.978651] Test:  [ 50/345]  eta: 0:00:25  loss: 0.2595 (0.2639)  time: 0.0805  data: 0.0001  max mem: 11902
[16:43:28.788824] Test:  [ 60/345]  eta: 0:00:24  loss: 0.2733 (0.2653)  time: 0.0809  data: 0.0001  max mem: 11902
[16:43:29.603605] Test:  [ 70/345]  eta: 0:00:23  loss: 0.2789 (0.2675)  time: 0.0812  data: 0.0001  max mem: 11902
[16:43:30.421744] Test:  [ 80/345]  eta: 0:00:22  loss: 0.2651 (0.2675)  time: 0.0816  data: 0.0001  max mem: 11902
[16:43:31.243431] Test:  [ 90/345]  eta: 0:00:21  loss: 0.2651 (0.2671)  time: 0.0819  data: 0.0001  max mem: 11902
[16:43:32.067463] Test:  [100/345]  eta: 0:00:20  loss: 0.2662 (0.2677)  time: 0.0822  data: 0.0001  max mem: 11902
[16:43:32.896594] Test:  [110/345]  eta: 0:00:19  loss: 0.2601 (0.2672)  time: 0.0826  data: 0.0001  max mem: 11902
[16:43:33.729329] Test:  [120/345]  eta: 0:00:18  loss: 0.2645 (0.2678)  time: 0.0830  data: 0.0001  max mem: 11902
[16:43:34.565342] Test:  [130/345]  eta: 0:00:18  loss: 0.2555 (0.2664)  time: 0.0833  data: 0.0001  max mem: 11902
[16:43:35.404583] Test:  [140/345]  eta: 0:00:17  loss: 0.2531 (0.2666)  time: 0.0837  data: 0.0001  max mem: 11902
[16:43:36.246800] Test:  [150/345]  eta: 0:00:16  loss: 0.2575 (0.2658)  time: 0.0840  data: 0.0001  max mem: 11902
[16:43:37.093538] Test:  [160/345]  eta: 0:00:15  loss: 0.2554 (0.2655)  time: 0.0844  data: 0.0001  max mem: 11902
[16:43:37.944057] Test:  [170/345]  eta: 0:00:14  loss: 0.2565 (0.2650)  time: 0.0848  data: 0.0001  max mem: 11902
[16:43:38.797122] Test:  [180/345]  eta: 0:00:13  loss: 0.2565 (0.2652)  time: 0.0851  data: 0.0001  max mem: 11902
[16:43:39.654009] Test:  [190/345]  eta: 0:00:13  loss: 0.2521 (0.2645)  time: 0.0854  data: 0.0001  max mem: 11902
[16:43:40.516034] Test:  [200/345]  eta: 0:00:12  loss: 0.2548 (0.2650)  time: 0.0858  data: 0.0001  max mem: 11902
[16:43:41.380172] Test:  [210/345]  eta: 0:00:11  loss: 0.2642 (0.2650)  time: 0.0862  data: 0.0001  max mem: 11902
[16:43:42.248348] Test:  [220/345]  eta: 0:00:10  loss: 0.2597 (0.2650)  time: 0.0865  data: 0.0001  max mem: 11902
[16:43:43.119699] Test:  [230/345]  eta: 0:00:09  loss: 0.2633 (0.2650)  time: 0.0869  data: 0.0001  max mem: 11902
[16:43:43.994330] Test:  [240/345]  eta: 0:00:08  loss: 0.2734 (0.2655)  time: 0.0872  data: 0.0001  max mem: 11902
[16:43:44.874351] Test:  [250/345]  eta: 0:00:08  loss: 0.2737 (0.2657)  time: 0.0876  data: 0.0001  max mem: 11902
[16:43:45.756799] Test:  [260/345]  eta: 0:00:07  loss: 0.2542 (0.2653)  time: 0.0880  data: 0.0001  max mem: 11902
[16:43:46.642187] Test:  [270/345]  eta: 0:00:06  loss: 0.2529 (0.2652)  time: 0.0883  data: 0.0001  max mem: 11902
[16:43:47.531781] Test:  [280/345]  eta: 0:00:05  loss: 0.2566 (0.2651)  time: 0.0887  data: 0.0001  max mem: 11902
[16:43:48.424931] Test:  [290/345]  eta: 0:00:04  loss: 0.2552 (0.2651)  time: 0.0890  data: 0.0001  max mem: 11902
[16:43:49.322417] Test:  [300/345]  eta: 0:00:03  loss: 0.2611 (0.2650)  time: 0.0895  data: 0.0001  max mem: 11902
[16:43:50.221972] Test:  [310/345]  eta: 0:00:03  loss: 0.2695 (0.2655)  time: 0.0898  data: 0.0001  max mem: 11902
[16:43:51.124528] Test:  [320/345]  eta: 0:00:02  loss: 0.2753 (0.2657)  time: 0.0900  data: 0.0001  max mem: 11902
[16:43:52.031865] Test:  [330/345]  eta: 0:00:01  loss: 0.2678 (0.2658)  time: 0.0904  data: 0.0001  max mem: 11902
[16:43:52.941765] Test:  [340/345]  eta: 0:00:00  loss: 0.2678 (0.2656)  time: 0.0908  data: 0.0001  max mem: 11902
[16:43:53.307101] Test:  [344/345]  eta: 0:00:00  loss: 0.2684 (0.2657)  time: 0.0910  data: 0.0001  max mem: 11902
[16:43:53.378180] Test: Total time: 0:00:29 (0.0865 s / it)
[16:44:03.180986] Test:  [ 0/57]  eta: 0:00:22  loss: 0.4518 (0.4518)  time: 0.3974  data: 0.3205  max mem: 11902
[16:44:03.976955] Test:  [10/57]  eta: 0:00:05  loss: 0.4426 (0.4495)  time: 0.1084  data: 0.0299  max mem: 11902
[16:44:04.769960] Test:  [20/57]  eta: 0:00:03  loss: 0.4384 (0.4601)  time: 0.0794  data: 0.0004  max mem: 11902
[16:44:05.564878] Test:  [30/57]  eta: 0:00:02  loss: 0.3081 (0.4065)  time: 0.0793  data: 0.0001  max mem: 11902
[16:44:06.364574] Test:  [40/57]  eta: 0:00:01  loss: 0.3003 (0.3833)  time: 0.0797  data: 0.0001  max mem: 11902
[16:44:07.166399] Test:  [50/57]  eta: 0:00:00  loss: 0.3170 (0.3908)  time: 0.0800  data: 0.0001  max mem: 11902
[16:44:07.602394] Test:  [56/57]  eta: 0:00:00  loss: 0.3920 (0.4128)  time: 0.0779  data: 0.0001  max mem: 11902
[16:44:07.678249] Test: Total time: 0:00:04 (0.0859 s / it)
[16:44:09.348865] Dice score of the network on the train images: 0.797585, val images: 0.391828
[16:44:09.352324] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:44:09.948969] Epoch: [12]  [  0/345]  eta: 0:03:25  lr: 0.000075  loss: 0.2513 (0.2513)  time: 0.5956  data: 0.3498  max mem: 11902
[16:44:14.822057] Epoch: [12]  [ 20/345]  eta: 0:01:24  lr: 0.000075  loss: 0.2744 (0.2735)  time: 0.2436  data: 0.0001  max mem: 11902
[16:44:19.691299] Epoch: [12]  [ 40/345]  eta: 0:01:16  lr: 0.000076  loss: 0.2672 (0.2720)  time: 0.2434  data: 0.0001  max mem: 11902
[16:44:24.558752] Epoch: [12]  [ 60/345]  eta: 0:01:11  lr: 0.000076  loss: 0.2593 (0.2665)  time: 0.2433  data: 0.0001  max mem: 11902
[16:44:29.426442] Epoch: [12]  [ 80/345]  eta: 0:01:05  lr: 0.000076  loss: 0.2660 (0.2681)  time: 0.2433  data: 0.0001  max mem: 11902
[16:44:34.295798] Epoch: [12]  [100/345]  eta: 0:01:00  lr: 0.000077  loss: 0.2570 (0.2658)  time: 0.2434  data: 0.0001  max mem: 11902
[16:44:39.179532] Epoch: [12]  [120/345]  eta: 0:00:55  lr: 0.000077  loss: 0.2650 (0.2662)  time: 0.2441  data: 0.0001  max mem: 11902
[16:44:44.056387] Epoch: [12]  [140/345]  eta: 0:00:50  lr: 0.000078  loss: 0.2685 (0.2665)  time: 0.2438  data: 0.0001  max mem: 11902
[16:44:48.935095] Epoch: [12]  [160/345]  eta: 0:00:45  lr: 0.000078  loss: 0.2580 (0.2657)  time: 0.2439  data: 0.0001  max mem: 11902
[16:44:53.811939] Epoch: [12]  [180/345]  eta: 0:00:40  lr: 0.000078  loss: 0.2744 (0.2669)  time: 0.2438  data: 0.0001  max mem: 11902
[16:44:58.706323] Epoch: [12]  [200/345]  eta: 0:00:35  lr: 0.000079  loss: 0.2625 (0.2670)  time: 0.2447  data: 0.0001  max mem: 11902
[16:45:03.604161] Epoch: [12]  [220/345]  eta: 0:00:30  lr: 0.000079  loss: 0.2678 (0.2679)  time: 0.2448  data: 0.0001  max mem: 11902
[16:45:08.506311] Epoch: [12]  [240/345]  eta: 0:00:25  lr: 0.000079  loss: 0.3027 (0.2708)  time: 0.2451  data: 0.0001  max mem: 11902
[16:45:13.406644] Epoch: [12]  [260/345]  eta: 0:00:20  lr: 0.000080  loss: 0.2982 (0.2725)  time: 0.2450  data: 0.0001  max mem: 11902
[16:45:18.310861] Epoch: [12]  [280/345]  eta: 0:00:15  lr: 0.000080  loss: 0.2785 (0.2728)  time: 0.2452  data: 0.0001  max mem: 11902
[16:45:23.213729] Epoch: [12]  [300/345]  eta: 0:00:11  lr: 0.000080  loss: 0.2657 (0.2721)  time: 0.2451  data: 0.0001  max mem: 11902
[16:45:28.119123] Epoch: [12]  [320/345]  eta: 0:00:06  lr: 0.000081  loss: 0.2596 (0.2715)  time: 0.2452  data: 0.0001  max mem: 11902
[16:45:33.017401] Epoch: [12]  [340/345]  eta: 0:00:01  lr: 0.000081  loss: 0.2716 (0.2720)  time: 0.2449  data: 0.0001  max mem: 11902
[16:45:33.996631] Epoch: [12]  [344/345]  eta: 0:00:00  lr: 0.000081  loss: 0.2716 (0.2722)  time: 0.2448  data: 0.0001  max mem: 11902
[16:45:34.067271] Epoch: [12] Total time: 0:01:24 (0.2456 s / it)
[16:45:34.067730] Averaged stats: lr: 0.000081  loss: 0.2716 (0.2722)
[16:45:34.500176] Test:  [  0/345]  eta: 0:02:27  loss: 0.1929 (0.1929)  time: 0.4278  data: 0.3504  max mem: 11902
[16:45:35.300493] Test:  [ 10/345]  eta: 0:00:37  loss: 0.2500 (0.2466)  time: 0.1115  data: 0.0325  max mem: 11902
[16:45:36.099200] Test:  [ 20/345]  eta: 0:00:31  loss: 0.2454 (0.2441)  time: 0.0798  data: 0.0004  max mem: 11902
[16:45:36.901427] Test:  [ 30/345]  eta: 0:00:28  loss: 0.2454 (0.2516)  time: 0.0800  data: 0.0001  max mem: 11902
[16:45:37.706680] Test:  [ 40/345]  eta: 0:00:27  loss: 0.2595 (0.2535)  time: 0.0803  data: 0.0001  max mem: 11902
[16:45:38.516079] Test:  [ 50/345]  eta: 0:00:25  loss: 0.2452 (0.2536)  time: 0.0807  data: 0.0001  max mem: 11902
[16:45:39.327726] Test:  [ 60/345]  eta: 0:00:24  loss: 0.2514 (0.2520)  time: 0.0810  data: 0.0001  max mem: 11902
[16:45:40.142675] Test:  [ 70/345]  eta: 0:00:23  loss: 0.2450 (0.2512)  time: 0.0813  data: 0.0001  max mem: 11902
[16:45:40.961488] Test:  [ 80/345]  eta: 0:00:22  loss: 0.2467 (0.2514)  time: 0.0816  data: 0.0001  max mem: 11902
[16:45:41.783556] Test:  [ 90/345]  eta: 0:00:21  loss: 0.2467 (0.2523)  time: 0.0820  data: 0.0001  max mem: 11902
[16:45:42.609269] Test:  [100/345]  eta: 0:00:20  loss: 0.2448 (0.2515)  time: 0.0823  data: 0.0001  max mem: 11902
[16:45:43.438902] Test:  [110/345]  eta: 0:00:19  loss: 0.2404 (0.2507)  time: 0.0827  data: 0.0001  max mem: 11902
[16:45:44.272084] Test:  [120/345]  eta: 0:00:18  loss: 0.2467 (0.2507)  time: 0.0831  data: 0.0001  max mem: 11902
[16:45:45.108772] Test:  [130/345]  eta: 0:00:18  loss: 0.2475 (0.2505)  time: 0.0834  data: 0.0001  max mem: 11902
[16:45:45.948934] Test:  [140/345]  eta: 0:00:17  loss: 0.2458 (0.2493)  time: 0.0838  data: 0.0001  max mem: 11902
[16:45:46.792278] Test:  [150/345]  eta: 0:00:16  loss: 0.2468 (0.2498)  time: 0.0841  data: 0.0001  max mem: 11902
[16:45:47.639932] Test:  [160/345]  eta: 0:00:15  loss: 0.2510 (0.2496)  time: 0.0845  data: 0.0001  max mem: 11902
[16:45:48.491385] Test:  [170/345]  eta: 0:00:14  loss: 0.2609 (0.2501)  time: 0.0849  data: 0.0001  max mem: 11902
[16:45:49.345613] Test:  [180/345]  eta: 0:00:13  loss: 0.2609 (0.2499)  time: 0.0852  data: 0.0001  max mem: 11902
[16:45:50.204064] Test:  [190/345]  eta: 0:00:13  loss: 0.2451 (0.2500)  time: 0.0855  data: 0.0001  max mem: 11902
[16:45:51.065464] Test:  [200/345]  eta: 0:00:12  loss: 0.2559 (0.2509)  time: 0.0859  data: 0.0001  max mem: 11902
[16:45:51.930570] Test:  [210/345]  eta: 0:00:11  loss: 0.2492 (0.2510)  time: 0.0863  data: 0.0001  max mem: 11902
[16:45:52.798900] Test:  [220/345]  eta: 0:00:10  loss: 0.2480 (0.2508)  time: 0.0866  data: 0.0001  max mem: 11902
[16:45:53.671199] Test:  [230/345]  eta: 0:00:09  loss: 0.2486 (0.2509)  time: 0.0870  data: 0.0001  max mem: 11902
[16:45:54.546124] Test:  [240/345]  eta: 0:00:08  loss: 0.2609 (0.2513)  time: 0.0873  data: 0.0001  max mem: 11902
[16:45:55.424779] Test:  [250/345]  eta: 0:00:08  loss: 0.2412 (0.2506)  time: 0.0876  data: 0.0001  max mem: 11902
[16:45:56.307126] Test:  [260/345]  eta: 0:00:07  loss: 0.2305 (0.2498)  time: 0.0880  data: 0.0001  max mem: 11902
[16:45:57.193352] Test:  [270/345]  eta: 0:00:06  loss: 0.2437 (0.2502)  time: 0.0884  data: 0.0001  max mem: 11902
[16:45:58.083042] Test:  [280/345]  eta: 0:00:05  loss: 0.2559 (0.2505)  time: 0.0887  data: 0.0001  max mem: 11902
[16:45:58.976188] Test:  [290/345]  eta: 0:00:04  loss: 0.2577 (0.2507)  time: 0.0891  data: 0.0001  max mem: 11902
[16:45:59.872166] Test:  [300/345]  eta: 0:00:03  loss: 0.2515 (0.2509)  time: 0.0894  data: 0.0001  max mem: 11902
[16:46:00.772027] Test:  [310/345]  eta: 0:00:03  loss: 0.2550 (0.2512)  time: 0.0897  data: 0.0001  max mem: 11902
[16:46:01.674782] Test:  [320/345]  eta: 0:00:02  loss: 0.2547 (0.2510)  time: 0.0901  data: 0.0001  max mem: 11902
[16:46:02.581560] Test:  [330/345]  eta: 0:00:01  loss: 0.2427 (0.2512)  time: 0.0904  data: 0.0001  max mem: 11902
[16:46:03.491423] Test:  [340/345]  eta: 0:00:00  loss: 0.2535 (0.2515)  time: 0.0908  data: 0.0001  max mem: 11902
[16:46:03.856623] Test:  [344/345]  eta: 0:00:00  loss: 0.2618 (0.2517)  time: 0.0909  data: 0.0001  max mem: 11902
[16:46:03.923106] Test: Total time: 0:00:29 (0.0865 s / it)
[16:46:13.775950] Test:  [ 0/57]  eta: 0:00:22  loss: 0.4317 (0.4317)  time: 0.3984  data: 0.3216  max mem: 11902
[16:46:14.581232] Test:  [10/57]  eta: 0:00:05  loss: 0.4317 (0.4230)  time: 0.1093  data: 0.0310  max mem: 11902
[16:46:15.373855] Test:  [20/57]  eta: 0:00:03  loss: 0.3927 (0.4245)  time: 0.0798  data: 0.0010  max mem: 11902
[16:46:16.170854] Test:  [30/57]  eta: 0:00:02  loss: 0.2704 (0.3720)  time: 0.0794  data: 0.0001  max mem: 11902
[16:46:16.970902] Test:  [40/57]  eta: 0:00:01  loss: 0.2537 (0.3500)  time: 0.0798  data: 0.0001  max mem: 11902
[16:46:17.775414] Test:  [50/57]  eta: 0:00:00  loss: 0.2746 (0.3551)  time: 0.0802  data: 0.0001  max mem: 11902
[16:46:18.213415] Test:  [56/57]  eta: 0:00:00  loss: 0.3672 (0.3965)  time: 0.0781  data: 0.0001  max mem: 11902
[16:46:18.285120] Test: Total time: 0:00:04 (0.0861 s / it)
[16:46:19.948675] Dice score of the network on the train images: 0.783532, val images: 0.397737
[16:46:19.952394] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:46:20.579504] Epoch: [13]  [  0/345]  eta: 0:03:36  lr: 0.000081  loss: 0.2360 (0.2360)  time: 0.6262  data: 0.3825  max mem: 11902

[16:46:25.438426] Epoch: [13]  [ 20/345]  eta: 0:01:24  lr: 0.000082  loss: 0.2463 (0.2494)  time: 0.2429  data: 0.0001  max mem: 11902
[16:46:30.321433] Epoch: [13]  [ 40/345]  eta: 0:01:17  lr: 0.000082  loss: 0.2649 (0.2578)  time: 0.2441  data: 0.0001  max mem: 11902
[16:46:35.279921] Epoch: [13]  [ 60/345]  eta: 0:01:11  lr: 0.000082  loss: 0.2547 (0.2591)  time: 0.2479  data: 0.0001  max mem: 11902
[16:46:40.170742] Epoch: [13]  [ 80/345]  eta: 0:01:06  lr: 0.000083  loss: 0.2441 (0.2574)  time: 0.2445  data: 0.0001  max mem: 11902
[16:46:45.051387] Epoch: [13]  [100/345]  eta: 0:01:00  lr: 0.000083  loss: 0.2553 (0.2578)  time: 0.2440  data: 0.0001  max mem: 11902
[16:46:49.945384] Epoch: [13]  [120/345]  eta: 0:00:55  lr: 0.000083  loss: 0.2504 (0.2570)  time: 0.2447  data: 0.0001  max mem: 11902
[16:46:54.841370] Epoch: [13]  [140/345]  eta: 0:00:50  lr: 0.000084  loss: 0.2639 (0.2578)  time: 0.2448  data: 0.0001  max mem: 11902
[16:46:59.732124] Epoch: [13]  [160/345]  eta: 0:00:45  lr: 0.000084  loss: 0.2431 (0.2568)  time: 0.2445  data: 0.0001  max mem: 11902
[16:47:04.627475] Epoch: [13]  [180/345]  eta: 0:00:40  lr: 0.000085  loss: 0.2603 (0.2582)  time: 0.2447  data: 0.0001  max mem: 11902
[16:47:09.515180] Epoch: [13]  [200/345]  eta: 0:00:35  lr: 0.000085  loss: 0.2483 (0.2574)  time: 0.2443  data: 0.0001  max mem: 11902
[16:47:14.405818] Epoch: [13]  [220/345]  eta: 0:00:30  lr: 0.000085  loss: 0.2550 (0.2572)  time: 0.2445  data: 0.0001  max mem: 11902
[16:47:19.303523] Epoch: [13]  [240/345]  eta: 0:00:25  lr: 0.000086  loss: 0.2542 (0.2575)  time: 0.2448  data: 0.0001  max mem: 11902
[16:47:24.190455] Epoch: [13]  [260/345]  eta: 0:00:20  lr: 0.000086  loss: 0.2432 (0.2568)  time: 0.2443  data: 0.0001  max mem: 11902
[16:47:29.080143] Epoch: [13]  [280/345]  eta: 0:00:15  lr: 0.000086  loss: 0.2680 (0.2570)  time: 0.2444  data: 0.0001  max mem: 11902
[16:47:33.983509] Epoch: [13]  [300/345]  eta: 0:00:11  lr: 0.000087  loss: 0.2627 (0.2574)  time: 0.2451  data: 0.0001  max mem: 11902
[16:47:38.878868] Epoch: [13]  [320/345]  eta: 0:00:06  lr: 0.000087  loss: 0.2735 (0.2585)  time: 0.2447  data: 0.0001  max mem: 11902
[16:47:43.771791] Epoch: [13]  [340/345]  eta: 0:00:01  lr: 0.000087  loss: 0.2534 (0.2584)  time: 0.2446  data: 0.0001  max mem: 11902
[16:47:44.753037] Epoch: [13]  [344/345]  eta: 0:00:00  lr: 0.000087  loss: 0.2538 (0.2584)  time: 0.2448  data: 0.0001  max mem: 11902
[16:47:44.825779] Epoch: [13] Total time: 0:01:24 (0.2460 s / it)
[16:47:44.826060] Averaged stats: lr: 0.000087  loss: 0.2538 (0.2584)
[16:47:45.271947] Test:  [  0/345]  eta: 0:02:32  loss: 0.2226 (0.2226)  time: 0.4409  data: 0.3638  max mem: 11902
[16:47:46.072797] Test:  [ 10/345]  eta: 0:00:37  loss: 0.2350 (0.2271)  time: 0.1128  data: 0.0339  max mem: 11902
[16:47:46.869849] Test:  [ 20/345]  eta: 0:00:31  loss: 0.2321 (0.2313)  time: 0.0798  data: 0.0005  max mem: 11902
[16:47:47.671504] Test:  [ 30/345]  eta: 0:00:28  loss: 0.2385 (0.2400)  time: 0.0799  data: 0.0001  max mem: 11902
[16:47:48.474404] Test:  [ 40/345]  eta: 0:00:27  loss: 0.2509 (0.2407)  time: 0.0802  data: 0.0001  max mem: 11902
[16:47:49.281383] Test:  [ 50/345]  eta: 0:00:25  loss: 0.2386 (0.2394)  time: 0.0804  data: 0.0001  max mem: 11902
[16:47:50.093257] Test:  [ 60/345]  eta: 0:00:24  loss: 0.2308 (0.2396)  time: 0.0809  data: 0.0001  max mem: 11902
[16:47:50.908017] Test:  [ 70/345]  eta: 0:00:23  loss: 0.2362 (0.2407)  time: 0.0813  data: 0.0001  max mem: 11902
[16:47:51.726269] Test:  [ 80/345]  eta: 0:00:22  loss: 0.2550 (0.2413)  time: 0.0816  data: 0.0001  max mem: 11902
[16:47:52.549054] Test:  [ 90/345]  eta: 0:00:21  loss: 0.2526 (0.2417)  time: 0.0820  data: 0.0001  max mem: 11902
[16:47:53.374830] Test:  [100/345]  eta: 0:00:20  loss: 0.2403 (0.2414)  time: 0.0824  data: 0.0001  max mem: 11902
[16:47:54.203978] Test:  [110/345]  eta: 0:00:19  loss: 0.2410 (0.2415)  time: 0.0827  data: 0.0001  max mem: 11902
[16:47:55.037264] Test:  [120/345]  eta: 0:00:18  loss: 0.2436 (0.2419)  time: 0.0831  data: 0.0001  max mem: 11902
[16:47:55.873651] Test:  [130/345]  eta: 0:00:18  loss: 0.2311 (0.2405)  time: 0.0834  data: 0.0001  max mem: 11902
[16:47:56.713784] Test:  [140/345]  eta: 0:00:17  loss: 0.2333 (0.2416)  time: 0.0838  data: 0.0001  max mem: 11902
[16:47:57.557446] Test:  [150/345]  eta: 0:00:16  loss: 0.2451 (0.2418)  time: 0.0841  data: 0.0001  max mem: 11902
[16:47:58.404330] Test:  [160/345]  eta: 0:00:15  loss: 0.2401 (0.2415)  time: 0.0845  data: 0.0001  max mem: 11902
[16:47:59.254597] Test:  [170/345]  eta: 0:00:14  loss: 0.2412 (0.2419)  time: 0.0848  data: 0.0001  max mem: 11902
[16:48:00.107766] Test:  [180/345]  eta: 0:00:13  loss: 0.2492 (0.2417)  time: 0.0851  data: 0.0001  max mem: 11902
[16:48:00.964449] Test:  [190/345]  eta: 0:00:13  loss: 0.2314 (0.2413)  time: 0.0854  data: 0.0001  max mem: 11902
[16:48:01.825023] Test:  [200/345]  eta: 0:00:12  loss: 0.2283 (0.2408)  time: 0.0858  data: 0.0001  max mem: 11902
[16:48:02.689323] Test:  [210/345]  eta: 0:00:11  loss: 0.2351 (0.2405)  time: 0.0862  data: 0.0001  max mem: 11902
[16:48:03.557503] Test:  [220/345]  eta: 0:00:10  loss: 0.2354 (0.2407)  time: 0.0866  data: 0.0001  max mem: 11902
[16:48:04.429442] Test:  [230/345]  eta: 0:00:09  loss: 0.2349 (0.2402)  time: 0.0869  data: 0.0001  max mem: 11902
[16:48:05.304132] Test:  [240/345]  eta: 0:00:08  loss: 0.2362 (0.2402)  time: 0.0873  data: 0.0001  max mem: 11902
[16:48:06.183044] Test:  [250/345]  eta: 0:00:08  loss: 0.2467 (0.2404)  time: 0.0876  data: 0.0001  max mem: 11902
[16:48:07.065395] Test:  [260/345]  eta: 0:00:07  loss: 0.2331 (0.2405)  time: 0.0880  data: 0.0001  max mem: 11902
[16:48:07.952373] Test:  [270/345]  eta: 0:00:06  loss: 0.2308 (0.2401)  time: 0.0884  data: 0.0001  max mem: 11902
[16:48:08.841343] Test:  [280/345]  eta: 0:00:05  loss: 0.2263 (0.2398)  time: 0.0887  data: 0.0001  max mem: 11902
[16:48:09.733467] Test:  [290/345]  eta: 0:00:04  loss: 0.2275 (0.2395)  time: 0.0890  data: 0.0001  max mem: 11902
[16:48:10.630287] Test:  [300/345]  eta: 0:00:03  loss: 0.2343 (0.2399)  time: 0.0894  data: 0.0001  max mem: 11902
[16:48:11.530590] Test:  [310/345]  eta: 0:00:03  loss: 0.2339 (0.2398)  time: 0.0898  data: 0.0001  max mem: 11902
[16:48:12.433926] Test:  [320/345]  eta: 0:00:02  loss: 0.2348 (0.2399)  time: 0.0901  data: 0.0001  max mem: 11902
[16:48:13.341332] Test:  [330/345]  eta: 0:00:01  loss: 0.2468 (0.2401)  time: 0.0905  data: 0.0001  max mem: 11902
[16:48:14.251977] Test:  [340/345]  eta: 0:00:00  loss: 0.2413 (0.2405)  time: 0.0908  data: 0.0001  max mem: 11902
[16:48:14.617933] Test:  [344/345]  eta: 0:00:00  loss: 0.2407 (0.2405)  time: 0.0910  data: 0.0001  max mem: 11902
[16:48:14.694202] Test: Total time: 0:00:29 (0.0866 s / it)
[16:48:24.632654] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4423 (0.4423)  time: 0.4409  data: 0.3637  max mem: 11902
[16:48:25.422478] Test:  [10/57]  eta: 0:00:05  loss: 0.4091 (0.4139)  time: 0.1118  data: 0.0332  max mem: 11902
[16:48:26.213829] Test:  [20/57]  eta: 0:00:03  loss: 0.3961 (0.4114)  time: 0.0790  data: 0.0001  max mem: 11902
[16:48:27.011404] Test:  [30/57]  eta: 0:00:02  loss: 0.2632 (0.3599)  time: 0.0794  data: 0.0001  max mem: 11902
[16:48:27.811318] Test:  [40/57]  eta: 0:00:01  loss: 0.2488 (0.3404)  time: 0.0798  data: 0.0001  max mem: 11902
[16:48:28.616019] Test:  [50/57]  eta: 0:00:00  loss: 0.2703 (0.3481)  time: 0.0802  data: 0.0001  max mem: 11902
[16:48:29.052473] Test:  [56/57]  eta: 0:00:00  loss: 0.3545 (0.3782)  time: 0.0780  data: 0.0001  max mem: 11902
[16:48:29.124347] Test: Total time: 0:00:04 (0.0866 s / it)
[16:48:30.793150] Dice score of the network on the train images: 0.785299, val images: 0.495080
[16:48:30.797385] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:48:31.416740] Epoch: [14]  [  0/345]  eta: 0:03:33  lr: 0.000087  loss: 0.2579 (0.2579)  time: 0.6183  data: 0.3734  max mem: 11902
[16:48:36.279704] Epoch: [14]  [ 20/345]  eta: 0:01:24  lr: 0.000088  loss: 0.2399 (0.2420)  time: 0.2431  data: 0.0001  max mem: 11902
[16:48:41.149810] Epoch: [14]  [ 40/345]  eta: 0:01:16  lr: 0.000088  loss: 0.2416 (0.2425)  time: 0.2435  data: 0.0001  max mem: 11902
[16:48:46.016170] Epoch: [14]  [ 60/345]  eta: 0:01:11  lr: 0.000089  loss: 0.2401 (0.2424)  time: 0.2433  data: 0.0001  max mem: 11902
[16:48:50.887515] Epoch: [14]  [ 80/345]  eta: 0:01:05  lr: 0.000089  loss: 0.2545 (0.2466)  time: 0.2435  data: 0.0001  max mem: 11902
[16:48:55.766007] Epoch: [14]  [100/345]  eta: 0:01:00  lr: 0.000089  loss: 0.2400 (0.2458)  time: 0.2439  data: 0.0001  max mem: 11902
[16:49:00.659837] Epoch: [14]  [120/345]  eta: 0:00:55  lr: 0.000090  loss: 0.2419 (0.2474)  time: 0.2447  data: 0.0001  max mem: 11902
[16:49:05.558234] Epoch: [14]  [140/345]  eta: 0:00:50  lr: 0.000090  loss: 0.2511 (0.2481)  time: 0.2449  data: 0.0001  max mem: 11902
[16:49:10.459127] Epoch: [14]  [160/345]  eta: 0:00:45  lr: 0.000090  loss: 0.2419 (0.2480)  time: 0.2450  data: 0.0001  max mem: 11902
[16:49:15.348879] Epoch: [14]  [180/345]  eta: 0:00:40  lr: 0.000091  loss: 0.2597 (0.2493)  time: 0.2444  data: 0.0001  max mem: 11902
[16:49:20.249582] Epoch: [14]  [200/345]  eta: 0:00:35  lr: 0.000091  loss: 0.2458 (0.2493)  time: 0.2450  data: 0.0001  max mem: 11902
[16:49:25.145419] Epoch: [14]  [220/345]  eta: 0:00:30  lr: 0.000091  loss: 0.2401 (0.2485)  time: 0.2447  data: 0.0001  max mem: 11902
[16:49:30.041476] Epoch: [14]  [240/345]  eta: 0:00:25  lr: 0.000092  loss: 0.2431 (0.2474)  time: 0.2448  data: 0.0001  max mem: 11902
[16:49:34.942329] Epoch: [14]  [260/345]  eta: 0:00:20  lr: 0.000092  loss: 0.2577 (0.2484)  time: 0.2450  data: 0.0001  max mem: 11902
[16:49:39.844413] Epoch: [14]  [280/345]  eta: 0:00:15  lr: 0.000093  loss: 0.2343 (0.2479)  time: 0.2451  data: 0.0001  max mem: 11902
[16:49:44.743576] Epoch: [14]  [300/345]  eta: 0:00:11  lr: 0.000093  loss: 0.2331 (0.2470)  time: 0.2449  data: 0.0001  max mem: 11902
[16:49:49.635467] Epoch: [14]  [320/345]  eta: 0:00:06  lr: 0.000093  loss: 0.2481 (0.2473)  time: 0.2445  data: 0.0001  max mem: 11902
[16:49:54.525673] Epoch: [14]  [340/345]  eta: 0:00:01  lr: 0.000094  loss: 0.2373 (0.2476)  time: 0.2445  data: 0.0001  max mem: 11902
[16:49:55.502781] Epoch: [14]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.2374 (0.2477)  time: 0.2443  data: 0.0001  max mem: 11902
[16:49:55.572584] Epoch: [14] Total time: 0:01:24 (0.2457 s / it)
[16:49:55.572902] Averaged stats: lr: 0.000094  loss: 0.2374 (0.2477)
[16:49:56.018774] Test:  [  0/345]  eta: 0:02:32  loss: 0.2718 (0.2718)  time: 0.4418  data: 0.3642  max mem: 11902
[16:49:56.821451] Test:  [ 10/345]  eta: 0:00:37  loss: 0.2473 (0.2432)  time: 0.1130  data: 0.0338  max mem: 11902
[16:49:57.619035] Test:  [ 20/345]  eta: 0:00:31  loss: 0.2314 (0.2362)  time: 0.0799  data: 0.0004  max mem: 11902
[16:49:58.419945] Test:  [ 30/345]  eta: 0:00:28  loss: 0.2314 (0.2367)  time: 0.0799  data: 0.0001  max mem: 11902
[16:49:59.225738] Test:  [ 40/345]  eta: 0:00:27  loss: 0.2393 (0.2406)  time: 0.0803  data: 0.0001  max mem: 11902
[16:50:00.033670] Test:  [ 50/345]  eta: 0:00:25  loss: 0.2428 (0.2395)  time: 0.0806  data: 0.0001  max mem: 11902
[16:50:00.845361] Test:  [ 60/345]  eta: 0:00:24  loss: 0.2261 (0.2367)  time: 0.0809  data: 0.0001  max mem: 11902
[16:50:01.659440] Test:  [ 70/345]  eta: 0:00:23  loss: 0.2270 (0.2369)  time: 0.0812  data: 0.0001  max mem: 11902
[16:50:02.477904] Test:  [ 80/345]  eta: 0:00:22  loss: 0.2283 (0.2366)  time: 0.0816  data: 0.0001  max mem: 11902
[16:50:03.300287] Test:  [ 90/345]  eta: 0:00:21  loss: 0.2332 (0.2370)  time: 0.0820  data: 0.0001  max mem: 11902
[16:50:04.126245] Test:  [100/345]  eta: 0:00:20  loss: 0.2332 (0.2365)  time: 0.0824  data: 0.0001  max mem: 11902
[16:50:04.955190] Test:  [110/345]  eta: 0:00:19  loss: 0.2388 (0.2375)  time: 0.0827  data: 0.0001  max mem: 11902
[16:50:05.787511] Test:  [120/345]  eta: 0:00:18  loss: 0.2388 (0.2381)  time: 0.0830  data: 0.0001  max mem: 11902
[16:50:06.623163] Test:  [130/345]  eta: 0:00:18  loss: 0.2349 (0.2388)  time: 0.0833  data: 0.0001  max mem: 11902
[16:50:07.462774] Test:  [140/345]  eta: 0:00:17  loss: 0.2340 (0.2387)  time: 0.0837  data: 0.0001  max mem: 11902
[16:50:08.305902] Test:  [150/345]  eta: 0:00:16  loss: 0.2501 (0.2403)  time: 0.0841  data: 0.0001  max mem: 11902
[16:50:09.152595] Test:  [160/345]  eta: 0:00:15  loss: 0.2480 (0.2410)  time: 0.0844  data: 0.0001  max mem: 11902
[16:50:10.003238] Test:  [170/345]  eta: 0:00:14  loss: 0.2376 (0.2410)  time: 0.0848  data: 0.0001  max mem: 11902
[16:50:10.857703] Test:  [180/345]  eta: 0:00:13  loss: 0.2352 (0.2404)  time: 0.0852  data: 0.0001  max mem: 11902
[16:50:11.715361] Test:  [190/345]  eta: 0:00:13  loss: 0.2238 (0.2399)  time: 0.0855  data: 0.0001  max mem: 11902
[16:50:12.576669] Test:  [200/345]  eta: 0:00:12  loss: 0.2289 (0.2397)  time: 0.0859  data: 0.0001  max mem: 11902
[16:50:13.441234] Test:  [210/345]  eta: 0:00:11  loss: 0.2310 (0.2393)  time: 0.0862  data: 0.0001  max mem: 11902
[16:50:14.310090] Test:  [220/345]  eta: 0:00:10  loss: 0.2410 (0.2397)  time: 0.0866  data: 0.0001  max mem: 11902
[16:50:15.182761] Test:  [230/345]  eta: 0:00:09  loss: 0.2306 (0.2393)  time: 0.0870  data: 0.0001  max mem: 11902
[16:50:16.058921] Test:  [240/345]  eta: 0:00:08  loss: 0.2336 (0.2395)  time: 0.0873  data: 0.0001  max mem: 11902
[16:50:16.937786] Test:  [250/345]  eta: 0:00:08  loss: 0.2391 (0.2393)  time: 0.0877  data: 0.0001  max mem: 11902
[16:50:17.820471] Test:  [260/345]  eta: 0:00:07  loss: 0.2357 (0.2395)  time: 0.0880  data: 0.0001  max mem: 11902
[16:50:18.706968] Test:  [270/345]  eta: 0:00:06  loss: 0.2337 (0.2392)  time: 0.0884  data: 0.0001  max mem: 11902
[16:50:19.596677] Test:  [280/345]  eta: 0:00:05  loss: 0.2337 (0.2394)  time: 0.0887  data: 0.0001  max mem: 11902
[16:50:20.489719] Test:  [290/345]  eta: 0:00:04  loss: 0.2342 (0.2392)  time: 0.0891  data: 0.0001  max mem: 11902
[16:50:21.385740] Test:  [300/345]  eta: 0:00:03  loss: 0.2277 (0.2389)  time: 0.0894  data: 0.0001  max mem: 11902
[16:50:22.286692] Test:  [310/345]  eta: 0:00:03  loss: 0.2393 (0.2392)  time: 0.0898  data: 0.0001  max mem: 11902
[16:50:23.190413] Test:  [320/345]  eta: 0:00:02  loss: 0.2494 (0.2397)  time: 0.0902  data: 0.0001  max mem: 11902
[16:50:24.098275] Test:  [330/345]  eta: 0:00:01  loss: 0.2470 (0.2398)  time: 0.0905  data: 0.0001  max mem: 11902
[16:50:25.008022] Test:  [340/345]  eta: 0:00:00  loss: 0.2411 (0.2399)  time: 0.0908  data: 0.0001  max mem: 11902
[16:50:25.374366] Test:  [344/345]  eta: 0:00:00  loss: 0.2435 (0.2399)  time: 0.0910  data: 0.0001  max mem: 11902
[16:50:25.451226] Test: Total time: 0:00:29 (0.0866 s / it)
[16:50:35.284225] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4404 (0.4404)  time: 0.4172  data: 0.3400  max mem: 11902
[16:50:36.072911] Test:  [10/57]  eta: 0:00:05  loss: 0.4079 (0.4293)  time: 0.1095  data: 0.0310  max mem: 11902
[16:50:36.865025] Test:  [20/57]  eta: 0:00:03  loss: 0.3985 (0.4258)  time: 0.0790  data: 0.0001  max mem: 11902
[16:50:37.660970] Test:  [30/57]  eta: 0:00:02  loss: 0.2975 (0.3859)  time: 0.0793  data: 0.0001  max mem: 11902
[16:50:38.460652] Test:  [40/57]  eta: 0:00:01  loss: 0.2930 (0.3709)  time: 0.0797  data: 0.0001  max mem: 11902
[16:50:39.262569] Test:  [50/57]  eta: 0:00:00  loss: 0.3283 (0.3738)  time: 0.0800  data: 0.0001  max mem: 11902
[16:50:39.698845] Test:  [56/57]  eta: 0:00:00  loss: 0.3592 (0.3794)  time: 0.0779  data: 0.0001  max mem: 11902
[16:50:39.767063] Test: Total time: 0:00:04 (0.0860 s / it)
[16:50:41.423880] Dice score of the network on the train images: 0.804525, val images: 0.554844
[16:50:41.427495] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:50:42.004507] Epoch: [15]  [  0/345]  eta: 0:03:18  lr: 0.000094  loss: 0.2065 (0.2065)  time: 0.5759  data: 0.3273  max mem: 11902
[16:50:46.879142] Epoch: [15]  [ 20/345]  eta: 0:01:24  lr: 0.000094  loss: 0.2376 (0.2359)  time: 0.2437  data: 0.0001  max mem: 11902
[16:50:51.756064] Epoch: [15]  [ 40/345]  eta: 0:01:16  lr: 0.000094  loss: 0.2374 (0.2381)  time: 0.2438  data: 0.0001  max mem: 11902
[16:50:56.635707] Epoch: [15]  [ 60/345]  eta: 0:01:11  lr: 0.000095  loss: 0.2410 (0.2399)  time: 0.2439  data: 0.0001  max mem: 11902
[16:51:01.521161] Epoch: [15]  [ 80/345]  eta: 0:01:05  lr: 0.000095  loss: 0.2479 (0.2414)  time: 0.2442  data: 0.0001  max mem: 11902
[16:51:06.403353] Epoch: [15]  [100/345]  eta: 0:01:00  lr: 0.000096  loss: 0.2347 (0.2422)  time: 0.2441  data: 0.0001  max mem: 11902
[16:51:11.288724] Epoch: [15]  [120/345]  eta: 0:00:55  lr: 0.000096  loss: 0.2269 (0.2419)  time: 0.2442  data: 0.0001  max mem: 11902
[16:51:16.172407] Epoch: [15]  [140/345]  eta: 0:00:50  lr: 0.000096  loss: 0.2354 (0.2423)  time: 0.2441  data: 0.0001  max mem: 11902
[16:51:21.049990] Epoch: [15]  [160/345]  eta: 0:00:45  lr: 0.000097  loss: 0.2373 (0.2422)  time: 0.2438  data: 0.0001  max mem: 11902
[16:51:25.946875] Epoch: [15]  [180/345]  eta: 0:00:40  lr: 0.000097  loss: 0.2419 (0.2417)  time: 0.2448  data: 0.0001  max mem: 11902
[16:51:30.841640] Epoch: [15]  [200/345]  eta: 0:00:35  lr: 0.000097  loss: 0.2571 (0.2430)  time: 0.2447  data: 0.0001  max mem: 11902
[16:51:35.740089] Epoch: [15]  [220/345]  eta: 0:00:30  lr: 0.000098  loss: 0.2180 (0.2420)  time: 0.2449  data: 0.0001  max mem: 11902
[16:51:40.642059] Epoch: [15]  [240/345]  eta: 0:00:25  lr: 0.000098  loss: 0.2411 (0.2419)  time: 0.2451  data: 0.0001  max mem: 11902
[16:51:45.531186] Epoch: [15]  [260/345]  eta: 0:00:20  lr: 0.000098  loss: 0.2443 (0.2420)  time: 0.2444  data: 0.0001  max mem: 11902
[16:51:50.426685] Epoch: [15]  [280/345]  eta: 0:00:15  lr: 0.000099  loss: 0.2461 (0.2421)  time: 0.2447  data: 0.0001  max mem: 11902
[16:51:55.333851] Epoch: [15]  [300/345]  eta: 0:00:11  lr: 0.000099  loss: 0.2389 (0.2423)  time: 0.2453  data: 0.0001  max mem: 11902
[16:52:00.230017] Epoch: [15]  [320/345]  eta: 0:00:06  lr: 0.000100  loss: 0.2430 (0.2424)  time: 0.2448  data: 0.0001  max mem: 11902
[16:52:05.127105] Epoch: [15]  [340/345]  eta: 0:00:01  lr: 0.000100  loss: 0.2338 (0.2418)  time: 0.2448  data: 0.0001  max mem: 11902
[16:52:06.106496] Epoch: [15]  [344/345]  eta: 0:00:00  lr: 0.000100  loss: 0.2358 (0.2419)  time: 0.2448  data: 0.0001  max mem: 11902
[16:52:06.174879] Epoch: [15] Total time: 0:01:24 (0.2456 s / it)
[16:52:06.175207] Averaged stats: lr: 0.000100  loss: 0.2358 (0.2419)
[16:52:06.622908] Test:  [  0/345]  eta: 0:02:32  loss: 0.2416 (0.2416)  time: 0.4432  data: 0.3662  max mem: 11902
[16:52:07.422626] Test:  [ 10/345]  eta: 0:00:37  loss: 0.2416 (0.2326)  time: 0.1129  data: 0.0339  max mem: 11902
[16:52:08.221788] Test:  [ 20/345]  eta: 0:00:31  loss: 0.2356 (0.2271)  time: 0.0799  data: 0.0004  max mem: 11902
[16:52:09.024310] Test:  [ 30/345]  eta: 0:00:28  loss: 0.2153 (0.2278)  time: 0.0800  data: 0.0001  max mem: 11902
[16:52:09.828268] Test:  [ 40/345]  eta: 0:00:27  loss: 0.2153 (0.2254)  time: 0.0802  data: 0.0001  max mem: 11902
[16:52:10.635762] Test:  [ 50/345]  eta: 0:00:25  loss: 0.2183 (0.2251)  time: 0.0805  data: 0.0001  max mem: 11902
[16:52:11.448003] Test:  [ 60/345]  eta: 0:00:24  loss: 0.2183 (0.2247)  time: 0.0809  data: 0.0001  max mem: 11902
[16:52:12.262680] Test:  [ 70/345]  eta: 0:00:23  loss: 0.2178 (0.2246)  time: 0.0813  data: 0.0001  max mem: 11902
[16:52:13.080736] Test:  [ 80/345]  eta: 0:00:22  loss: 0.2220 (0.2238)  time: 0.0816  data: 0.0001  max mem: 11902
[16:52:13.902633] Test:  [ 90/345]  eta: 0:00:21  loss: 0.2193 (0.2228)  time: 0.0819  data: 0.0001  max mem: 11902
[16:52:14.727999] Test:  [100/345]  eta: 0:00:20  loss: 0.2100 (0.2229)  time: 0.0823  data: 0.0001  max mem: 11902
[16:52:15.557072] Test:  [110/345]  eta: 0:00:19  loss: 0.2279 (0.2229)  time: 0.0826  data: 0.0001  max mem: 11902
[16:52:16.390285] Test:  [120/345]  eta: 0:00:18  loss: 0.2279 (0.2225)  time: 0.0830  data: 0.0001  max mem: 11902
[16:52:17.226114] Test:  [130/345]  eta: 0:00:18  loss: 0.2166 (0.2221)  time: 0.0834  data: 0.0001  max mem: 11902
[16:52:18.066158] Test:  [140/345]  eta: 0:00:17  loss: 0.2231 (0.2231)  time: 0.0837  data: 0.0001  max mem: 11902
[16:52:18.908675] Test:  [150/345]  eta: 0:00:16  loss: 0.2164 (0.2228)  time: 0.0840  data: 0.0001  max mem: 11902
[16:52:19.754870] Test:  [160/345]  eta: 0:00:15  loss: 0.2127 (0.2223)  time: 0.0844  data: 0.0001  max mem: 11902
[16:52:20.604957] Test:  [170/345]  eta: 0:00:14  loss: 0.2147 (0.2221)  time: 0.0847  data: 0.0001  max mem: 11902
[16:52:21.458438] Test:  [180/345]  eta: 0:00:13  loss: 0.2247 (0.2228)  time: 0.0851  data: 0.0001  max mem: 11902
[16:52:22.316459] Test:  [190/345]  eta: 0:00:13  loss: 0.2223 (0.2224)  time: 0.0855  data: 0.0001  max mem: 11902
[16:52:23.177927] Test:  [200/345]  eta: 0:00:12  loss: 0.2248 (0.2231)  time: 0.0859  data: 0.0001  max mem: 11902
[16:52:24.043245] Test:  [210/345]  eta: 0:00:11  loss: 0.2154 (0.2226)  time: 0.0863  data: 0.0001  max mem: 11902
[16:52:24.912210] Test:  [220/345]  eta: 0:00:10  loss: 0.2260 (0.2234)  time: 0.0866  data: 0.0001  max mem: 11902
[16:52:25.784089] Test:  [230/345]  eta: 0:00:09  loss: 0.2319 (0.2238)  time: 0.0870  data: 0.0001  max mem: 11902
[16:52:26.660127] Test:  [240/345]  eta: 0:00:08  loss: 0.2255 (0.2235)  time: 0.0873  data: 0.0001  max mem: 11902
[16:52:27.538735] Test:  [250/345]  eta: 0:00:08  loss: 0.2201 (0.2235)  time: 0.0877  data: 0.0001  max mem: 11902
[16:52:28.421539] Test:  [260/345]  eta: 0:00:07  loss: 0.2290 (0.2237)  time: 0.0880  data: 0.0001  max mem: 11902
[16:52:29.307382] Test:  [270/345]  eta: 0:00:06  loss: 0.2166 (0.2233)  time: 0.0884  data: 0.0001  max mem: 11902
[16:52:30.196978] Test:  [280/345]  eta: 0:00:05  loss: 0.2101 (0.2229)  time: 0.0887  data: 0.0001  max mem: 11902
[16:52:31.091091] Test:  [290/345]  eta: 0:00:04  loss: 0.2208 (0.2229)  time: 0.0891  data: 0.0001  max mem: 11902
[16:52:31.987462] Test:  [300/345]  eta: 0:00:03  loss: 0.2212 (0.2230)  time: 0.0894  data: 0.0001  max mem: 11902
[16:52:32.887778] Test:  [310/345]  eta: 0:00:03  loss: 0.2207 (0.2229)  time: 0.0898  data: 0.0001  max mem: 11902
[16:52:33.791870] Test:  [320/345]  eta: 0:00:02  loss: 0.2196 (0.2228)  time: 0.0901  data: 0.0001  max mem: 11902
[16:52:34.700576] Test:  [330/345]  eta: 0:00:01  loss: 0.2214 (0.2228)  time: 0.0906  data: 0.0001  max mem: 11902
[16:52:35.610627] Test:  [340/345]  eta: 0:00:00  loss: 0.2129 (0.2227)  time: 0.0909  data: 0.0001  max mem: 11902
[16:52:35.975616] Test:  [344/345]  eta: 0:00:00  loss: 0.2129 (0.2226)  time: 0.0910  data: 0.0001  max mem: 11902
[16:52:36.034456] Test: Total time: 0:00:29 (0.0865 s / it)
[16:52:45.944788] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4318 (0.4318)  time: 0.4194  data: 0.3425  max mem: 11902
[16:52:46.733033] Test:  [10/57]  eta: 0:00:05  loss: 0.4216 (0.4352)  time: 0.1097  data: 0.0313  max mem: 11902
[16:52:47.526153] Test:  [20/57]  eta: 0:00:03  loss: 0.4143 (0.4193)  time: 0.0790  data: 0.0001  max mem: 11902
[16:52:48.322895] Test:  [30/57]  eta: 0:00:02  loss: 0.2949 (0.3750)  time: 0.0794  data: 0.0001  max mem: 11902
[16:52:49.123875] Test:  [40/57]  eta: 0:00:01  loss: 0.2922 (0.3583)  time: 0.0798  data: 0.0001  max mem: 11902
[16:52:49.928874] Test:  [50/57]  eta: 0:00:00  loss: 0.3032 (0.3616)  time: 0.0802  data: 0.0001  max mem: 11902
[16:52:50.366353] Test:  [56/57]  eta: 0:00:00  loss: 0.3656 (0.3784)  time: 0.0781  data: 0.0001  max mem: 11902
[16:52:50.438229] Test: Total time: 0:00:04 (0.0862 s / it)
[16:52:52.100085] Dice score of the network on the train images: 0.819052, val images: 0.690979
[16:52:52.100296] saving best_prec_model_0 @ epoch 15
[16:52:53.116431] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:52:53.728249] Epoch: [16]  [  0/345]  eta: 0:03:30  lr: 0.000100  loss: 0.3020 (0.3020)  time: 0.6107  data: 0.3647  max mem: 11902
[16:52:58.604786] Epoch: [16]  [ 20/345]  eta: 0:01:24  lr: 0.000100  loss: 0.2285 (0.2361)  time: 0.2438  data: 0.0001  max mem: 11902
[16:53:03.489645] Epoch: [16]  [ 40/345]  eta: 0:01:17  lr: 0.000101  loss: 0.2230 (0.2346)  time: 0.2442  data: 0.0001  max mem: 11902
[16:53:08.449003] Epoch: [16]  [ 60/345]  eta: 0:01:11  lr: 0.000101  loss: 0.2169 (0.2322)  time: 0.2479  data: 0.0001  max mem: 11902
[16:53:13.336585] Epoch: [16]  [ 80/345]  eta: 0:01:06  lr: 0.000101  loss: 0.2335 (0.2309)  time: 0.2443  data: 0.0001  max mem: 11902
[16:53:18.228957] Epoch: [16]  [100/345]  eta: 0:01:00  lr: 0.000102  loss: 0.2117 (0.2296)  time: 0.2446  data: 0.0001  max mem: 11902
[16:53:23.120319] Epoch: [16]  [120/345]  eta: 0:00:55  lr: 0.000102  loss: 0.2222 (0.2288)  time: 0.2445  data: 0.0001  max mem: 11902
[16:53:28.017432] Epoch: [16]  [140/345]  eta: 0:00:50  lr: 0.000103  loss: 0.2315 (0.2296)  time: 0.2448  data: 0.0001  max mem: 11902
[16:53:32.916202] Epoch: [16]  [160/345]  eta: 0:00:45  lr: 0.000103  loss: 0.2128 (0.2282)  time: 0.2449  data: 0.0001  max mem: 11902
[16:53:37.810937] Epoch: [16]  [180/345]  eta: 0:00:40  lr: 0.000103  loss: 0.2281 (0.2287)  time: 0.2447  data: 0.0001  max mem: 11902
[16:53:42.702346] Epoch: [16]  [200/345]  eta: 0:00:35  lr: 0.000104  loss: 0.2213 (0.2285)  time: 0.2445  data: 0.0001  max mem: 11902
[16:53:47.604463] Epoch: [16]  [220/345]  eta: 0:00:30  lr: 0.000104  loss: 0.2238 (0.2288)  time: 0.2451  data: 0.0001  max mem: 11902
[16:53:52.498213] Epoch: [16]  [240/345]  eta: 0:00:25  lr: 0.000104  loss: 0.2269 (0.2289)  time: 0.2446  data: 0.0001  max mem: 11902
[16:53:57.401520] Epoch: [16]  [260/345]  eta: 0:00:20  lr: 0.000105  loss: 0.2314 (0.2292)  time: 0.2451  data: 0.0001  max mem: 11902
[16:54:02.306105] Epoch: [16]  [280/345]  eta: 0:00:16  lr: 0.000105  loss: 0.2310 (0.2302)  time: 0.2452  data: 0.0001  max mem: 11902
[16:54:07.209131] Epoch: [16]  [300/345]  eta: 0:00:11  lr: 0.000105  loss: 0.2363 (0.2308)  time: 0.2451  data: 0.0001  max mem: 11902
[16:54:12.104645] Epoch: [16]  [320/345]  eta: 0:00:06  lr: 0.000106  loss: 0.2177 (0.2306)  time: 0.2447  data: 0.0001  max mem: 11902
[16:54:16.997955] Epoch: [16]  [340/345]  eta: 0:00:01  lr: 0.000106  loss: 0.2271 (0.2308)  time: 0.2446  data: 0.0001  max mem: 11902
[16:54:17.977768] Epoch: [16]  [344/345]  eta: 0:00:00  lr: 0.000106  loss: 0.2303 (0.2309)  time: 0.2445  data: 0.0001  max mem: 11902
[16:54:18.045280] Epoch: [16] Total time: 0:01:24 (0.2462 s / it)
[16:54:18.045464] Averaged stats: lr: 0.000106  loss: 0.2303 (0.2309)
[16:54:18.476269] Test:  [  0/345]  eta: 0:02:27  loss: 0.2572 (0.2572)  time: 0.4264  data: 0.3495  max mem: 11902
[16:54:19.288443] Test:  [ 10/345]  eta: 0:00:37  loss: 0.2049 (0.2131)  time: 0.1125  data: 0.0334  max mem: 11902
[16:54:20.085565] Test:  [ 20/345]  eta: 0:00:31  loss: 0.2176 (0.2213)  time: 0.0804  data: 0.0009  max mem: 11902
[16:54:20.885643] Test:  [ 30/345]  eta: 0:00:28  loss: 0.2176 (0.2205)  time: 0.0798  data: 0.0001  max mem: 11902
[16:54:21.689280] Test:  [ 40/345]  eta: 0:00:27  loss: 0.2113 (0.2197)  time: 0.0801  data: 0.0001  max mem: 11902
[16:54:22.498776] Test:  [ 50/345]  eta: 0:00:25  loss: 0.2084 (0.2185)  time: 0.0806  data: 0.0001  max mem: 11902
[16:54:23.310166] Test:  [ 60/345]  eta: 0:00:24  loss: 0.2096 (0.2190)  time: 0.0810  data: 0.0001  max mem: 11902
[16:54:24.125402] Test:  [ 70/345]  eta: 0:00:23  loss: 0.2104 (0.2184)  time: 0.0813  data: 0.0001  max mem: 11902
[16:54:24.943730] Test:  [ 80/345]  eta: 0:00:22  loss: 0.2104 (0.2171)  time: 0.0816  data: 0.0001  max mem: 11902
[16:54:25.765747] Test:  [ 90/345]  eta: 0:00:21  loss: 0.2071 (0.2168)  time: 0.0819  data: 0.0001  max mem: 11902
[16:54:26.590037] Test:  [100/345]  eta: 0:00:20  loss: 0.2061 (0.2151)  time: 0.0822  data: 0.0001  max mem: 11902
[16:54:27.418104] Test:  [110/345]  eta: 0:00:19  loss: 0.2035 (0.2147)  time: 0.0826  data: 0.0001  max mem: 11902
[16:54:28.250633] Test:  [120/345]  eta: 0:00:18  loss: 0.2168 (0.2146)  time: 0.0830  data: 0.0001  max mem: 11902
[16:54:29.086486] Test:  [130/345]  eta: 0:00:18  loss: 0.2166 (0.2142)  time: 0.0833  data: 0.0001  max mem: 11902
[16:54:29.926825] Test:  [140/345]  eta: 0:00:17  loss: 0.2093 (0.2140)  time: 0.0837  data: 0.0001  max mem: 11902
[16:54:30.769657] Test:  [150/345]  eta: 0:00:16  loss: 0.2126 (0.2143)  time: 0.0841  data: 0.0001  max mem: 11902
[16:54:31.616484] Test:  [160/345]  eta: 0:00:15  loss: 0.2209 (0.2148)  time: 0.0844  data: 0.0001  max mem: 11902
[16:54:32.468112] Test:  [170/345]  eta: 0:00:14  loss: 0.2160 (0.2146)  time: 0.0848  data: 0.0001  max mem: 11902
[16:54:33.321974] Test:  [180/345]  eta: 0:00:13  loss: 0.2117 (0.2150)  time: 0.0852  data: 0.0001  max mem: 11902
[16:54:34.179076] Test:  [190/345]  eta: 0:00:13  loss: 0.2128 (0.2152)  time: 0.0855  data: 0.0001  max mem: 11902
[16:54:35.040335] Test:  [200/345]  eta: 0:00:12  loss: 0.2104 (0.2154)  time: 0.0858  data: 0.0001  max mem: 11902
[16:54:35.905806] Test:  [210/345]  eta: 0:00:11  loss: 0.2140 (0.2162)  time: 0.0863  data: 0.0001  max mem: 11902
[16:54:36.774270] Test:  [220/345]  eta: 0:00:10  loss: 0.2208 (0.2162)  time: 0.0866  data: 0.0001  max mem: 11902
[16:54:37.646650] Test:  [230/345]  eta: 0:00:09  loss: 0.2208 (0.2164)  time: 0.0870  data: 0.0001  max mem: 11902
[16:54:38.522204] Test:  [240/345]  eta: 0:00:08  loss: 0.2123 (0.2163)  time: 0.0873  data: 0.0001  max mem: 11902
[16:54:39.401566] Test:  [250/345]  eta: 0:00:08  loss: 0.2126 (0.2165)  time: 0.0877  data: 0.0001  max mem: 11902
[16:54:40.283911] Test:  [260/345]  eta: 0:00:07  loss: 0.2173 (0.2171)  time: 0.0880  data: 0.0001  max mem: 11902
[16:54:41.169607] Test:  [270/345]  eta: 0:00:06  loss: 0.2274 (0.2176)  time: 0.0883  data: 0.0001  max mem: 11902
[16:54:42.059158] Test:  [280/345]  eta: 0:00:05  loss: 0.2286 (0.2178)  time: 0.0887  data: 0.0001  max mem: 11902
[16:54:42.951606] Test:  [290/345]  eta: 0:00:04  loss: 0.2260 (0.2185)  time: 0.0890  data: 0.0001  max mem: 11902
[16:54:43.849129] Test:  [300/345]  eta: 0:00:03  loss: 0.2194 (0.2184)  time: 0.0894  data: 0.0001  max mem: 11902
[16:54:44.748706] Test:  [310/345]  eta: 0:00:03  loss: 0.2103 (0.2181)  time: 0.0898  data: 0.0001  max mem: 11902
[16:54:45.652439] Test:  [320/345]  eta: 0:00:02  loss: 0.2199 (0.2184)  time: 0.0901  data: 0.0001  max mem: 11902
[16:54:46.559794] Test:  [330/345]  eta: 0:00:01  loss: 0.2260 (0.2185)  time: 0.0905  data: 0.0001  max mem: 11902
[16:54:47.471013] Test:  [340/345]  eta: 0:00:00  loss: 0.2230 (0.2186)  time: 0.0909  data: 0.0001  max mem: 11902
[16:54:47.836251] Test:  [344/345]  eta: 0:00:00  loss: 0.2170 (0.2185)  time: 0.0910  data: 0.0001  max mem: 11902
[16:54:47.900406] Test: Total time: 0:00:29 (0.0865 s / it)
[16:54:57.856250] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4309 (0.4309)  time: 0.4721  data: 0.3951  max mem: 11902
[16:54:58.644636] Test:  [10/57]  eta: 0:00:05  loss: 0.4178 (0.4202)  time: 0.1145  data: 0.0360  max mem: 11902
[16:54:59.437298] Test:  [20/57]  eta: 0:00:03  loss: 0.3794 (0.4032)  time: 0.0789  data: 0.0001  max mem: 11902
[16:55:00.232182] Test:  [30/57]  eta: 0:00:02  loss: 0.2684 (0.3596)  time: 0.0793  data: 0.0001  max mem: 11902
[16:55:01.031518] Test:  [40/57]  eta: 0:00:01  loss: 0.2302 (0.3337)  time: 0.0796  data: 0.0001  max mem: 11902
[16:55:01.834626] Test:  [50/57]  eta: 0:00:00  loss: 0.2736 (0.3341)  time: 0.0801  data: 0.0001  max mem: 11902
[16:55:02.270482] Test:  [56/57]  eta: 0:00:00  loss: 0.3131 (0.3573)  time: 0.0779  data: 0.0001  max mem: 11902
[16:55:02.338042] Test: Total time: 0:00:04 (0.0869 s / it)
[16:55:04.041187] Dice score of the network on the train images: 0.793024, val images: 0.495317
[16:55:04.044751] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:55:04.688224] Epoch: [17]  [  0/345]  eta: 0:03:41  lr: 0.000106  loss: 0.1907 (0.1907)  time: 0.6426  data: 0.3981  max mem: 11902
[16:55:09.550675] Epoch: [17]  [ 20/345]  eta: 0:01:25  lr: 0.000107  loss: 0.2184 (0.2173)  time: 0.2431  data: 0.0001  max mem: 11902
[16:55:14.418401] Epoch: [17]  [ 40/345]  eta: 0:01:17  lr: 0.000107  loss: 0.2131 (0.2158)  time: 0.2433  data: 0.0001  max mem: 11902
[16:55:19.293286] Epoch: [17]  [ 60/345]  eta: 0:01:11  lr: 0.000107  loss: 0.2094 (0.2145)  time: 0.2437  data: 0.0001  max mem: 11902
[16:55:24.177711] Epoch: [17]  [ 80/345]  eta: 0:01:05  lr: 0.000108  loss: 0.2301 (0.2200)  time: 0.2442  data: 0.0001  max mem: 11902
[16:55:29.049758] Epoch: [17]  [100/345]  eta: 0:01:00  lr: 0.000108  loss: 0.2199 (0.2212)  time: 0.2436  data: 0.0001  max mem: 11902
[16:55:33.927234] Epoch: [17]  [120/345]  eta: 0:00:55  lr: 0.000108  loss: 0.2242 (0.2233)  time: 0.2438  data: 0.0001  max mem: 11902
[16:55:38.807420] Epoch: [17]  [140/345]  eta: 0:00:50  lr: 0.000109  loss: 0.2195 (0.2227)  time: 0.2440  data: 0.0001  max mem: 11902
[16:55:43.683958] Epoch: [17]  [160/345]  eta: 0:00:45  lr: 0.000109  loss: 0.2132 (0.2219)  time: 0.2438  data: 0.0001  max mem: 11902
[16:55:48.558400] Epoch: [17]  [180/345]  eta: 0:00:40  lr: 0.000110  loss: 0.2158 (0.2218)  time: 0.2437  data: 0.0001  max mem: 11902
[16:55:53.440572] Epoch: [17]  [200/345]  eta: 0:00:35  lr: 0.000110  loss: 0.2300 (0.2229)  time: 0.2441  data: 0.0001  max mem: 11902
[16:55:58.323901] Epoch: [17]  [220/345]  eta: 0:00:30  lr: 0.000110  loss: 0.2169 (0.2227)  time: 0.2441  data: 0.0001  max mem: 11902
[16:56:03.225236] Epoch: [17]  [240/345]  eta: 0:00:25  lr: 0.000111  loss: 0.2129 (0.2226)  time: 0.2450  data: 0.0001  max mem: 11902
[16:56:08.125181] Epoch: [17]  [260/345]  eta: 0:00:20  lr: 0.000111  loss: 0.2192 (0.2224)  time: 0.2449  data: 0.0001  max mem: 11902
[16:56:13.031484] Epoch: [17]  [280/345]  eta: 0:00:15  lr: 0.000111  loss: 0.2218 (0.2225)  time: 0.2453  data: 0.0001  max mem: 11902
[16:56:17.939112] Epoch: [17]  [300/345]  eta: 0:00:11  lr: 0.000112  loss: 0.2280 (0.2232)  time: 0.2453  data: 0.0001  max mem: 11902
[16:56:22.851247] Epoch: [17]  [320/345]  eta: 0:00:06  lr: 0.000112  loss: 0.2337 (0.2239)  time: 0.2456  data: 0.0001  max mem: 11902
[16:56:27.756338] Epoch: [17]  [340/345]  eta: 0:00:01  lr: 0.000112  loss: 0.2153 (0.2240)  time: 0.2452  data: 0.0001  max mem: 11902
[16:56:28.736079] Epoch: [17]  [344/345]  eta: 0:00:00  lr: 0.000112  loss: 0.2203 (0.2239)  time: 0.2449  data: 0.0001  max mem: 11902
[16:56:28.810252] Epoch: [17] Total time: 0:01:24 (0.2457 s / it)
[16:56:28.810453] Averaged stats: lr: 0.000112  loss: 0.2203 (0.2239)
[16:56:29.252410] Test:  [  0/345]  eta: 0:02:30  loss: 0.2073 (0.2073)  time: 0.4376  data: 0.3606  max mem: 11902
[16:56:30.051491] Test:  [ 10/345]  eta: 0:00:37  loss: 0.2143 (0.2082)  time: 0.1123  data: 0.0332  max mem: 11902
[16:56:30.848871] Test:  [ 20/345]  eta: 0:00:31  loss: 0.2151 (0.2111)  time: 0.0797  data: 0.0003  max mem: 11902
[16:56:31.650102] Test:  [ 30/345]  eta: 0:00:28  loss: 0.2151 (0.2126)  time: 0.0799  data: 0.0001  max mem: 11902
[16:56:32.455021] Test:  [ 40/345]  eta: 0:00:27  loss: 0.2076 (0.2131)  time: 0.0802  data: 0.0001  max mem: 11902
[16:56:33.263201] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1995 (0.2101)  time: 0.0806  data: 0.0001  max mem: 11902
[16:56:34.074552] Test:  [ 60/345]  eta: 0:00:24  loss: 0.2070 (0.2163)  time: 0.0809  data: 0.0001  max mem: 11902
[16:56:34.889447] Test:  [ 70/345]  eta: 0:00:23  loss: 0.2133 (0.2151)  time: 0.0812  data: 0.0001  max mem: 11902
[16:56:35.707947] Test:  [ 80/345]  eta: 0:00:22  loss: 0.2007 (0.2145)  time: 0.0816  data: 0.0001  max mem: 11902
[16:56:36.530387] Test:  [ 90/345]  eta: 0:00:21  loss: 0.2052 (0.2153)  time: 0.0820  data: 0.0001  max mem: 11902
[16:56:37.355330] Test:  [100/345]  eta: 0:00:20  loss: 0.2052 (0.2160)  time: 0.0823  data: 0.0001  max mem: 11902
[16:56:38.184091] Test:  [110/345]  eta: 0:00:19  loss: 0.2165 (0.2162)  time: 0.0826  data: 0.0001  max mem: 11902
[16:56:39.017007] Test:  [120/345]  eta: 0:00:18  loss: 0.2123 (0.2155)  time: 0.0830  data: 0.0001  max mem: 11902
[16:56:39.853068] Test:  [130/345]  eta: 0:00:18  loss: 0.2099 (0.2159)  time: 0.0834  data: 0.0001  max mem: 11902
[16:56:40.692451] Test:  [140/345]  eta: 0:00:17  loss: 0.2106 (0.2159)  time: 0.0837  data: 0.0001  max mem: 11902
[16:56:41.536252] Test:  [150/345]  eta: 0:00:16  loss: 0.2072 (0.2152)  time: 0.0841  data: 0.0001  max mem: 11902
[16:56:42.382826] Test:  [160/345]  eta: 0:00:15  loss: 0.2096 (0.2151)  time: 0.0844  data: 0.0001  max mem: 11902
[16:56:43.233940] Test:  [170/345]  eta: 0:00:14  loss: 0.2024 (0.2143)  time: 0.0848  data: 0.0001  max mem: 11902
[16:56:44.087895] Test:  [180/345]  eta: 0:00:13  loss: 0.2062 (0.2147)  time: 0.0852  data: 0.0001  max mem: 11902
[16:56:44.945454] Test:  [190/345]  eta: 0:00:13  loss: 0.2132 (0.2142)  time: 0.0855  data: 0.0001  max mem: 11902
[16:56:45.806890] Test:  [200/345]  eta: 0:00:12  loss: 0.2139 (0.2140)  time: 0.0859  data: 0.0001  max mem: 11902
[16:56:46.671549] Test:  [210/345]  eta: 0:00:11  loss: 0.2190 (0.2144)  time: 0.0862  data: 0.0001  max mem: 11902
[16:56:47.540056] Test:  [220/345]  eta: 0:00:10  loss: 0.2140 (0.2145)  time: 0.0866  data: 0.0001  max mem: 11902
[16:56:48.412429] Test:  [230/345]  eta: 0:00:09  loss: 0.2176 (0.2147)  time: 0.0870  data: 0.0001  max mem: 11902
[16:56:49.288144] Test:  [240/345]  eta: 0:00:08  loss: 0.2158 (0.2146)  time: 0.0873  data: 0.0001  max mem: 11902
[16:56:50.167026] Test:  [250/345]  eta: 0:00:08  loss: 0.2132 (0.2152)  time: 0.0877  data: 0.0001  max mem: 11902
[16:56:51.049161] Test:  [260/345]  eta: 0:00:07  loss: 0.2175 (0.2151)  time: 0.0880  data: 0.0001  max mem: 11902
[16:56:51.934612] Test:  [270/345]  eta: 0:00:06  loss: 0.2175 (0.2150)  time: 0.0883  data: 0.0001  max mem: 11902
[16:56:52.823652] Test:  [280/345]  eta: 0:00:05  loss: 0.2187 (0.2149)  time: 0.0886  data: 0.0001  max mem: 11902
[16:56:53.717050] Test:  [290/345]  eta: 0:00:04  loss: 0.2069 (0.2147)  time: 0.0890  data: 0.0001  max mem: 11902
[16:56:54.613563] Test:  [300/345]  eta: 0:00:03  loss: 0.2067 (0.2149)  time: 0.0894  data: 0.0001  max mem: 11902
[16:56:55.513215] Test:  [310/345]  eta: 0:00:03  loss: 0.2045 (0.2143)  time: 0.0897  data: 0.0001  max mem: 11902
[16:56:56.416699] Test:  [320/345]  eta: 0:00:02  loss: 0.2043 (0.2142)  time: 0.0901  data: 0.0001  max mem: 11902
[16:56:57.324484] Test:  [330/345]  eta: 0:00:01  loss: 0.2097 (0.2142)  time: 0.0905  data: 0.0001  max mem: 11902
[16:56:58.233033] Test:  [340/345]  eta: 0:00:00  loss: 0.2107 (0.2142)  time: 0.0908  data: 0.0001  max mem: 11902
[16:56:58.598732] Test:  [344/345]  eta: 0:00:00  loss: 0.2111 (0.2142)  time: 0.0909  data: 0.0001  max mem: 11902
[16:56:58.659736] Test: Total time: 0:00:29 (0.0865 s / it)
[16:57:08.664604] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4368 (0.4368)  time: 0.4149  data: 0.3377  max mem: 11902
[16:57:09.453462] Test:  [10/57]  eta: 0:00:05  loss: 0.4368 (0.4278)  time: 0.1093  data: 0.0308  max mem: 11902
[16:57:10.244873] Test:  [20/57]  eta: 0:00:03  loss: 0.3678 (0.4219)  time: 0.0789  data: 0.0001  max mem: 11902
[16:57:11.041242] Test:  [30/57]  eta: 0:00:02  loss: 0.2574 (0.3655)  time: 0.0793  data: 0.0001  max mem: 11902
[16:57:11.842683] Test:  [40/57]  eta: 0:00:01  loss: 0.2494 (0.3414)  time: 0.0798  data: 0.0001  max mem: 11902
[16:57:12.646144] Test:  [50/57]  eta: 0:00:00  loss: 0.2670 (0.3475)  time: 0.0802  data: 0.0001  max mem: 11902
[16:57:13.082033] Test:  [56/57]  eta: 0:00:00  loss: 0.3380 (0.3841)  time: 0.0780  data: 0.0001  max mem: 11902
[16:57:13.154825] Test: Total time: 0:00:04 (0.0861 s / it)
[16:57:14.821579] Dice score of the network on the train images: 0.794662, val images: 0.377182
[16:57:14.825073] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:57:15.405695] Epoch: [18]  [  0/345]  eta: 0:03:20  lr: 0.000113  loss: 0.1962 (0.1962)  time: 0.5798  data: 0.3345  max mem: 11902
[16:57:20.269808] Epoch: [18]  [ 20/345]  eta: 0:01:24  lr: 0.000113  loss: 0.2181 (0.2207)  time: 0.2432  data: 0.0001  max mem: 11902
[16:57:25.137833] Epoch: [18]  [ 40/345]  eta: 0:01:16  lr: 0.000113  loss: 0.2218 (0.2207)  time: 0.2434  data: 0.0001  max mem: 11902
[16:57:30.008621] Epoch: [18]  [ 60/345]  eta: 0:01:10  lr: 0.000114  loss: 0.2190 (0.2220)  time: 0.2435  data: 0.0001  max mem: 11902
[16:57:34.882743] Epoch: [18]  [ 80/345]  eta: 0:01:05  lr: 0.000114  loss: 0.2263 (0.2222)  time: 0.2437  data: 0.0001  max mem: 11902
[16:57:39.757352] Epoch: [18]  [100/345]  eta: 0:01:00  lr: 0.000114  loss: 0.2112 (0.2211)  time: 0.2437  data: 0.0001  max mem: 11902
[16:57:44.646712] Epoch: [18]  [120/345]  eta: 0:00:55  lr: 0.000115  loss: 0.2196 (0.2217)  time: 0.2444  data: 0.0001  max mem: 11902
[16:57:49.533187] Epoch: [18]  [140/345]  eta: 0:00:50  lr: 0.000115  loss: 0.2063 (0.2198)  time: 0.2443  data: 0.0001  max mem: 11902
[16:57:54.427540] Epoch: [18]  [160/345]  eta: 0:00:45  lr: 0.000115  loss: 0.2061 (0.2188)  time: 0.2447  data: 0.0001  max mem: 11902
[16:57:59.324814] Epoch: [18]  [180/345]  eta: 0:00:40  lr: 0.000116  loss: 0.2060 (0.2178)  time: 0.2448  data: 0.0001  max mem: 11902
[16:58:04.225215] Epoch: [18]  [200/345]  eta: 0:00:35  lr: 0.000116  loss: 0.2099 (0.2174)  time: 0.2450  data: 0.0001  max mem: 11902
[16:58:09.125232] Epoch: [18]  [220/345]  eta: 0:00:30  lr: 0.000116  loss: 0.2141 (0.2179)  time: 0.2450  data: 0.0001  max mem: 11902
[16:58:14.018763] Epoch: [18]  [240/345]  eta: 0:00:25  lr: 0.000117  loss: 0.2115 (0.2175)  time: 0.2446  data: 0.0001  max mem: 11902
[16:58:18.908858] Epoch: [18]  [260/345]  eta: 0:00:20  lr: 0.000117  loss: 0.2109 (0.2175)  time: 0.2445  data: 0.0001  max mem: 11902
[16:58:23.797482] Epoch: [18]  [280/345]  eta: 0:00:15  lr: 0.000118  loss: 0.2097 (0.2179)  time: 0.2444  data: 0.0001  max mem: 11902
[16:58:28.686144] Epoch: [18]  [300/345]  eta: 0:00:11  lr: 0.000118  loss: 0.2012 (0.2169)  time: 0.2444  data: 0.0001  max mem: 11902
[16:58:33.581195] Epoch: [18]  [320/345]  eta: 0:00:06  lr: 0.000118  loss: 0.2225 (0.2174)  time: 0.2447  data: 0.0001  max mem: 11902
[16:58:38.472722] Epoch: [18]  [340/345]  eta: 0:00:01  lr: 0.000119  loss: 0.2102 (0.2172)  time: 0.2445  data: 0.0001  max mem: 11902
[16:58:39.448661] Epoch: [18]  [344/345]  eta: 0:00:00  lr: 0.000119  loss: 0.2102 (0.2174)  time: 0.2444  data: 0.0001  max mem: 11902
[16:58:39.520391] Epoch: [18] Total time: 0:01:24 (0.2455 s / it)
[16:58:39.520672] Averaged stats: lr: 0.000119  loss: 0.2102 (0.2174)
[16:58:39.962787] Test:  [  0/345]  eta: 0:02:31  loss: 0.2275 (0.2275)  time: 0.4381  data: 0.3605  max mem: 11902
[16:58:40.762516] Test:  [ 10/345]  eta: 0:00:37  loss: 0.2043 (0.2047)  time: 0.1124  data: 0.0333  max mem: 11902
[16:58:41.559889] Test:  [ 20/345]  eta: 0:00:31  loss: 0.2067 (0.2091)  time: 0.0797  data: 0.0003  max mem: 11902
[16:58:42.360422] Test:  [ 30/345]  eta: 0:00:28  loss: 0.2067 (0.2040)  time: 0.0798  data: 0.0001  max mem: 11902
[16:58:43.163806] Test:  [ 40/345]  eta: 0:00:27  loss: 0.2000 (0.2056)  time: 0.0801  data: 0.0001  max mem: 11902
[16:58:43.972837] Test:  [ 50/345]  eta: 0:00:25  loss: 0.2116 (0.2070)  time: 0.0805  data: 0.0001  max mem: 11902
[16:58:44.784456] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1976 (0.2065)  time: 0.0809  data: 0.0001  max mem: 11902
[16:58:45.600091] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1953 (0.2044)  time: 0.0813  data: 0.0001  max mem: 11902
[16:58:46.418758] Test:  [ 80/345]  eta: 0:00:22  loss: 0.2022 (0.2046)  time: 0.0816  data: 0.0001  max mem: 11902
[16:58:47.241034] Test:  [ 90/345]  eta: 0:00:21  loss: 0.2007 (0.2050)  time: 0.0819  data: 0.0001  max mem: 11902
[16:58:48.066380] Test:  [100/345]  eta: 0:00:20  loss: 0.2005 (0.2043)  time: 0.0823  data: 0.0001  max mem: 11902
[16:58:48.896309] Test:  [110/345]  eta: 0:00:19  loss: 0.2026 (0.2050)  time: 0.0827  data: 0.0001  max mem: 11902
[16:58:49.728978] Test:  [120/345]  eta: 0:00:18  loss: 0.2030 (0.2050)  time: 0.0830  data: 0.0001  max mem: 11902
[16:58:50.565777] Test:  [130/345]  eta: 0:00:18  loss: 0.2035 (0.2048)  time: 0.0834  data: 0.0001  max mem: 11902
[16:58:51.405791] Test:  [140/345]  eta: 0:00:17  loss: 0.1948 (0.2038)  time: 0.0837  data: 0.0001  max mem: 11902
[16:58:52.248507] Test:  [150/345]  eta: 0:00:16  loss: 0.1948 (0.2039)  time: 0.0840  data: 0.0001  max mem: 11902
[16:58:53.095599] Test:  [160/345]  eta: 0:00:15  loss: 0.1959 (0.2031)  time: 0.0844  data: 0.0001  max mem: 11902
[16:58:53.945815] Test:  [170/345]  eta: 0:00:14  loss: 0.1927 (0.2025)  time: 0.0848  data: 0.0001  max mem: 11902
[16:58:54.800404] Test:  [180/345]  eta: 0:00:13  loss: 0.1958 (0.2030)  time: 0.0851  data: 0.0001  max mem: 11902
[16:58:55.658897] Test:  [190/345]  eta: 0:00:13  loss: 0.1995 (0.2023)  time: 0.0855  data: 0.0001  max mem: 11902
[16:58:56.520981] Test:  [200/345]  eta: 0:00:12  loss: 0.1979 (0.2022)  time: 0.0859  data: 0.0001  max mem: 11902
[16:58:57.385800] Test:  [210/345]  eta: 0:00:11  loss: 0.2007 (0.2022)  time: 0.0863  data: 0.0001  max mem: 11902
[16:58:58.254687] Test:  [220/345]  eta: 0:00:10  loss: 0.2009 (0.2021)  time: 0.0866  data: 0.0001  max mem: 11902
[16:58:59.126678] Test:  [230/345]  eta: 0:00:09  loss: 0.2027 (0.2027)  time: 0.0870  data: 0.0001  max mem: 11902
[16:59:00.002403] Test:  [240/345]  eta: 0:00:08  loss: 0.2068 (0.2030)  time: 0.0873  data: 0.0001  max mem: 11902
[16:59:00.881854] Test:  [250/345]  eta: 0:00:08  loss: 0.2125 (0.2037)  time: 0.0877  data: 0.0001  max mem: 11902
[16:59:01.764320] Test:  [260/345]  eta: 0:00:07  loss: 0.2051 (0.2037)  time: 0.0880  data: 0.0001  max mem: 11902
[16:59:02.649752] Test:  [270/345]  eta: 0:00:06  loss: 0.1926 (0.2035)  time: 0.0883  data: 0.0001  max mem: 11902
[16:59:03.540137] Test:  [280/345]  eta: 0:00:05  loss: 0.1981 (0.2036)  time: 0.0887  data: 0.0001  max mem: 11902
[16:59:04.432972] Test:  [290/345]  eta: 0:00:04  loss: 0.1916 (0.2031)  time: 0.0891  data: 0.0001  max mem: 11902
[16:59:05.329710] Test:  [300/345]  eta: 0:00:03  loss: 0.1822 (0.2028)  time: 0.0894  data: 0.0001  max mem: 11902
[16:59:06.229892] Test:  [310/345]  eta: 0:00:03  loss: 0.1872 (0.2025)  time: 0.0898  data: 0.0001  max mem: 11902
[16:59:07.132633] Test:  [320/345]  eta: 0:00:02  loss: 0.1895 (0.2021)  time: 0.0901  data: 0.0001  max mem: 11902
[16:59:08.039793] Test:  [330/345]  eta: 0:00:01  loss: 0.1942 (0.2020)  time: 0.0904  data: 0.0001  max mem: 11902
[16:59:08.950853] Test:  [340/345]  eta: 0:00:00  loss: 0.1927 (0.2017)  time: 0.0909  data: 0.0001  max mem: 11902
[16:59:09.316109] Test:  [344/345]  eta: 0:00:00  loss: 0.1927 (0.2017)  time: 0.0910  data: 0.0001  max mem: 11902
[16:59:09.391345] Test: Total time: 0:00:29 (0.0866 s / it)
[16:59:19.217680] Test:  [ 0/57]  eta: 0:00:22  loss: 0.4291 (0.4291)  time: 0.4033  data: 0.3264  max mem: 11902
[16:59:20.012978] Test:  [10/57]  eta: 0:00:05  loss: 0.4206 (0.4139)  time: 0.1089  data: 0.0304  max mem: 11902
[16:59:20.804153] Test:  [20/57]  eta: 0:00:03  loss: 0.3789 (0.4023)  time: 0.0792  data: 0.0005  max mem: 11902
[16:59:21.600687] Test:  [30/57]  eta: 0:00:02  loss: 0.2614 (0.3532)  time: 0.0793  data: 0.0001  max mem: 11902
[16:59:22.402753] Test:  [40/57]  eta: 0:00:01  loss: 0.2431 (0.3312)  time: 0.0799  data: 0.0001  max mem: 11902
[16:59:23.205482] Test:  [50/57]  eta: 0:00:00  loss: 0.2650 (0.3396)  time: 0.0802  data: 0.0001  max mem: 11902
[16:59:23.641749] Test:  [56/57]  eta: 0:00:00  loss: 0.3370 (0.3835)  time: 0.0779  data: 0.0000  max mem: 11902
[16:59:23.714180] Test: Total time: 0:00:04 (0.0860 s / it)
[16:59:25.381270] Dice score of the network on the train images: 0.817184, val images: 0.474724
[16:59:25.384937] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[16:59:25.983228] Epoch: [19]  [  0/345]  eta: 0:03:26  lr: 0.000119  loss: 0.2512 (0.2512)  time: 0.5974  data: 0.3529  max mem: 11902
[16:59:30.851013] Epoch: [19]  [ 20/345]  eta: 0:01:24  lr: 0.000119  loss: 0.2182 (0.2207)  time: 0.2433  data: 0.0001  max mem: 11902
[16:59:35.722166] Epoch: [19]  [ 40/345]  eta: 0:01:16  lr: 0.000119  loss: 0.2059 (0.2192)  time: 0.2435  data: 0.0001  max mem: 11902
[16:59:40.593284] Epoch: [19]  [ 60/345]  eta: 0:01:11  lr: 0.000120  loss: 0.2018 (0.2150)  time: 0.2435  data: 0.0001  max mem: 11902
[16:59:45.470959] Epoch: [19]  [ 80/345]  eta: 0:01:05  lr: 0.000120  loss: 0.2147 (0.2146)  time: 0.2438  data: 0.0000  max mem: 11902
[16:59:50.350076] Epoch: [19]  [100/345]  eta: 0:01:00  lr: 0.000121  loss: 0.2084 (0.2135)  time: 0.2439  data: 0.0001  max mem: 11902
[16:59:55.238376] Epoch: [19]  [120/345]  eta: 0:00:55  lr: 0.000121  loss: 0.2057 (0.2133)  time: 0.2444  data: 0.0001  max mem: 11902
[17:00:00.124142] Epoch: [19]  [140/345]  eta: 0:00:50  lr: 0.000121  loss: 0.2084 (0.2127)  time: 0.2442  data: 0.0001  max mem: 11902
[17:00:05.010924] Epoch: [19]  [160/345]  eta: 0:00:45  lr: 0.000122  loss: 0.2003 (0.2116)  time: 0.2443  data: 0.0001  max mem: 11902
[17:00:09.902906] Epoch: [19]  [180/345]  eta: 0:00:40  lr: 0.000122  loss: 0.2147 (0.2121)  time: 0.2446  data: 0.0001  max mem: 11902
[17:00:14.869005] Epoch: [19]  [200/345]  eta: 0:00:35  lr: 0.000122  loss: 0.2029 (0.2115)  time: 0.2483  data: 0.0001  max mem: 11902
[17:00:19.764954] Epoch: [19]  [220/345]  eta: 0:00:30  lr: 0.000123  loss: 0.1986 (0.2110)  time: 0.2448  data: 0.0001  max mem: 11902
[17:00:24.662808] Epoch: [19]  [240/345]  eta: 0:00:25  lr: 0.000123  loss: 0.2083 (0.2108)  time: 0.2448  data: 0.0001  max mem: 11902
[17:00:29.560797] Epoch: [19]  [260/345]  eta: 0:00:20  lr: 0.000123  loss: 0.2129 (0.2108)  time: 0.2448  data: 0.0001  max mem: 11902
[17:00:34.465059] Epoch: [19]  [280/345]  eta: 0:00:15  lr: 0.000124  loss: 0.2030 (0.2107)  time: 0.2452  data: 0.0001  max mem: 11902
[17:00:39.364938] Epoch: [19]  [300/345]  eta: 0:00:11  lr: 0.000124  loss: 0.2052 (0.2105)  time: 0.2449  data: 0.0001  max mem: 11902
[17:00:44.272844] Epoch: [19]  [320/345]  eta: 0:00:06  lr: 0.000125  loss: 0.2322 (0.2116)  time: 0.2453  data: 0.0001  max mem: 11902
[17:00:49.171403] Epoch: [19]  [340/345]  eta: 0:00:01  lr: 0.000125  loss: 0.2336 (0.2130)  time: 0.2449  data: 0.0001  max mem: 11902
[17:00:50.151530] Epoch: [19]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.2373 (0.2132)  time: 0.2449  data: 0.0001  max mem: 11902
[17:00:50.232611] Epoch: [19] Total time: 0:01:24 (0.2459 s / it)
[17:00:50.233098] Averaged stats: lr: 0.000125  loss: 0.2373 (0.2132)
[17:00:50.736621] Test:  [  0/345]  eta: 0:02:52  loss: 0.2317 (0.2317)  time: 0.4994  data: 0.4221  max mem: 11902
[17:00:51.529410] Test:  [ 10/345]  eta: 0:00:39  loss: 0.2173 (0.2190)  time: 0.1174  data: 0.0385  max mem: 11902
[17:00:52.328276] Test:  [ 20/345]  eta: 0:00:32  loss: 0.2141 (0.2146)  time: 0.0795  data: 0.0001  max mem: 11902
[17:00:53.129951] Test:  [ 30/345]  eta: 0:00:29  loss: 0.2103 (0.2143)  time: 0.0799  data: 0.0001  max mem: 11902
[17:00:53.934338] Test:  [ 40/345]  eta: 0:00:27  loss: 0.2080 (0.2108)  time: 0.0802  data: 0.0001  max mem: 11902
[17:00:54.740805] Test:  [ 50/345]  eta: 0:00:26  loss: 0.1941 (0.2091)  time: 0.0805  data: 0.0001  max mem: 11902
[17:00:55.552701] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1921 (0.2084)  time: 0.0808  data: 0.0001  max mem: 11902
[17:00:56.367236] Test:  [ 70/345]  eta: 0:00:23  loss: 0.2094 (0.2114)  time: 0.0812  data: 0.0001  max mem: 11902
[17:00:57.184279] Test:  [ 80/345]  eta: 0:00:22  loss: 0.2140 (0.2113)  time: 0.0815  data: 0.0001  max mem: 11902
[17:00:58.006194] Test:  [ 90/345]  eta: 0:00:21  loss: 0.2133 (0.2117)  time: 0.0819  data: 0.0001  max mem: 11902
[17:00:58.831533] Test:  [100/345]  eta: 0:00:20  loss: 0.2202 (0.2126)  time: 0.0823  data: 0.0001  max mem: 11902
[17:00:59.660731] Test:  [110/345]  eta: 0:00:19  loss: 0.2188 (0.2130)  time: 0.0826  data: 0.0001  max mem: 11902
[17:01:00.493905] Test:  [120/345]  eta: 0:00:19  loss: 0.2185 (0.2133)  time: 0.0830  data: 0.0001  max mem: 11902
[17:01:01.329314] Test:  [130/345]  eta: 0:00:18  loss: 0.2153 (0.2135)  time: 0.0834  data: 0.0001  max mem: 11902
[17:01:02.169888] Test:  [140/345]  eta: 0:00:17  loss: 0.2153 (0.2138)  time: 0.0837  data: 0.0001  max mem: 11902
[17:01:03.012985] Test:  [150/345]  eta: 0:00:16  loss: 0.2135 (0.2135)  time: 0.0841  data: 0.0001  max mem: 11902
[17:01:03.858548] Test:  [160/345]  eta: 0:00:15  loss: 0.2017 (0.2130)  time: 0.0844  data: 0.0001  max mem: 11902
[17:01:04.708452] Test:  [170/345]  eta: 0:00:14  loss: 0.2078 (0.2132)  time: 0.0847  data: 0.0001  max mem: 11902
[17:01:05.560999] Test:  [180/345]  eta: 0:00:13  loss: 0.2044 (0.2130)  time: 0.0850  data: 0.0001  max mem: 11902
[17:01:06.417562] Test:  [190/345]  eta: 0:00:13  loss: 0.2131 (0.2133)  time: 0.0854  data: 0.0001  max mem: 11902
[17:01:07.277574] Test:  [200/345]  eta: 0:00:12  loss: 0.2196 (0.2138)  time: 0.0858  data: 0.0001  max mem: 11902
[17:01:08.141854] Test:  [210/345]  eta: 0:00:11  loss: 0.2114 (0.2135)  time: 0.0862  data: 0.0001  max mem: 11902
[17:01:09.009576] Test:  [220/345]  eta: 0:00:10  loss: 0.2114 (0.2138)  time: 0.0865  data: 0.0001  max mem: 11902
[17:01:09.881637] Test:  [230/345]  eta: 0:00:09  loss: 0.2155 (0.2137)  time: 0.0869  data: 0.0001  max mem: 11902
[17:01:10.756134] Test:  [240/345]  eta: 0:00:08  loss: 0.2111 (0.2133)  time: 0.0872  data: 0.0001  max mem: 11902
[17:01:11.635290] Test:  [250/345]  eta: 0:00:08  loss: 0.2080 (0.2135)  time: 0.0876  data: 0.0001  max mem: 11902
[17:01:12.516730] Test:  [260/345]  eta: 0:00:07  loss: 0.2176 (0.2135)  time: 0.0880  data: 0.0001  max mem: 11902
[17:01:13.402547] Test:  [270/345]  eta: 0:00:06  loss: 0.2063 (0.2133)  time: 0.0883  data: 0.0001  max mem: 11902
[17:01:14.293291] Test:  [280/345]  eta: 0:00:05  loss: 0.2097 (0.2138)  time: 0.0888  data: 0.0001  max mem: 11902
[17:01:15.186045] Test:  [290/345]  eta: 0:00:04  loss: 0.2181 (0.2136)  time: 0.0891  data: 0.0001  max mem: 11902
[17:01:16.083093] Test:  [300/345]  eta: 0:00:03  loss: 0.2181 (0.2141)  time: 0.0894  data: 0.0001  max mem: 11902
[17:01:16.983182] Test:  [310/345]  eta: 0:00:03  loss: 0.2179 (0.2141)  time: 0.0898  data: 0.0001  max mem: 11902
[17:01:17.886829] Test:  [320/345]  eta: 0:00:02  loss: 0.2155 (0.2147)  time: 0.0901  data: 0.0001  max mem: 11902
[17:01:18.794502] Test:  [330/345]  eta: 0:00:01  loss: 0.2050 (0.2143)  time: 0.0905  data: 0.0001  max mem: 11902
[17:01:19.704441] Test:  [340/345]  eta: 0:00:00  loss: 0.2010 (0.2144)  time: 0.0908  data: 0.0001  max mem: 11902
[17:01:20.069961] Test:  [344/345]  eta: 0:00:00  loss: 0.2028 (0.2145)  time: 0.0910  data: 0.0001  max mem: 11902
[17:01:20.138651] Test: Total time: 0:00:29 (0.0867 s / it)
[17:01:29.973158] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4240 (0.4240)  time: 0.4049  data: 0.3277  max mem: 11902
[17:01:30.769775] Test:  [10/57]  eta: 0:00:05  loss: 0.3874 (0.4219)  time: 0.1091  data: 0.0305  max mem: 11902
[17:01:31.561837] Test:  [20/57]  eta: 0:00:03  loss: 0.3874 (0.4053)  time: 0.0793  data: 0.0004  max mem: 11902
[17:01:32.359441] Test:  [30/57]  eta: 0:00:02  loss: 0.2611 (0.3530)  time: 0.0794  data: 0.0001  max mem: 11902
[17:01:33.161451] Test:  [40/57]  eta: 0:00:01  loss: 0.2554 (0.3321)  time: 0.0799  data: 0.0001  max mem: 11902
[17:01:33.963915] Test:  [50/57]  eta: 0:00:00  loss: 0.2763 (0.3286)  time: 0.0802  data: 0.0001  max mem: 11902
[17:01:34.400351] Test:  [56/57]  eta: 0:00:00  loss: 0.2963 (0.3387)  time: 0.0779  data: 0.0001  max mem: 11902
[17:01:34.478542] Test: Total time: 0:00:04 (0.0862 s / it)
[17:01:36.157863] Dice score of the network on the train images: 0.817541, val images: 0.786981
[17:01:36.158092] saving best_prec_model_0 @ epoch 19
[17:01:37.163071] saving best_dice_model_0 @ epoch 19
[17:01:38.120867] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:01:38.759805] Epoch: [20]  [  0/345]  eta: 0:03:40  lr: 0.000125  loss: 0.2131 (0.2131)  time: 0.6378  data: 0.3922  max mem: 11902
[17:01:43.638618] Epoch: [20]  [ 20/345]  eta: 0:01:25  lr: 0.000125  loss: 0.2233 (0.2248)  time: 0.2439  data: 0.0001  max mem: 11902
[17:01:48.517243] Epoch: [20]  [ 40/345]  eta: 0:01:17  lr: 0.000125  loss: 0.2199 (0.2214)  time: 0.2439  data: 0.0001  max mem: 11902
[17:01:53.380664] Epoch: [20]  [ 60/345]  eta: 0:01:11  lr: 0.000125  loss: 0.1941 (0.2145)  time: 0.2431  data: 0.0001  max mem: 11902
[17:01:58.256338] Epoch: [20]  [ 80/345]  eta: 0:01:05  lr: 0.000125  loss: 0.2002 (0.2123)  time: 0.2437  data: 0.0001  max mem: 11902
[17:02:03.147576] Epoch: [20]  [100/345]  eta: 0:01:00  lr: 0.000125  loss: 0.2002 (0.2101)  time: 0.2445  data: 0.0001  max mem: 11902
[17:02:08.031186] Epoch: [20]  [120/345]  eta: 0:00:55  lr: 0.000125  loss: 0.2018 (0.2091)  time: 0.2441  data: 0.0001  max mem: 11902
[17:02:12.922734] Epoch: [20]  [140/345]  eta: 0:00:50  lr: 0.000125  loss: 0.2137 (0.2097)  time: 0.2445  data: 0.0001  max mem: 11902
[17:02:17.809975] Epoch: [20]  [160/345]  eta: 0:00:45  lr: 0.000125  loss: 0.2088 (0.2098)  time: 0.2443  data: 0.0001  max mem: 11902
[17:02:22.705171] Epoch: [20]  [180/345]  eta: 0:00:40  lr: 0.000125  loss: 0.2045 (0.2100)  time: 0.2447  data: 0.0001  max mem: 11902
[17:02:27.601527] Epoch: [20]  [200/345]  eta: 0:00:35  lr: 0.000125  loss: 0.2032 (0.2092)  time: 0.2448  data: 0.0001  max mem: 11902
[17:02:32.494110] Epoch: [20]  [220/345]  eta: 0:00:30  lr: 0.000125  loss: 0.1977 (0.2080)  time: 0.2446  data: 0.0001  max mem: 11902
[17:02:37.389874] Epoch: [20]  [240/345]  eta: 0:00:25  lr: 0.000125  loss: 0.2017 (0.2075)  time: 0.2447  data: 0.0001  max mem: 11902
[17:02:42.285779] Epoch: [20]  [260/345]  eta: 0:00:20  lr: 0.000125  loss: 0.1918 (0.2070)  time: 0.2448  data: 0.0001  max mem: 11902
[17:02:47.187045] Epoch: [20]  [280/345]  eta: 0:00:15  lr: 0.000125  loss: 0.1977 (0.2063)  time: 0.2450  data: 0.0001  max mem: 11902
[17:02:52.090398] Epoch: [20]  [300/345]  eta: 0:00:11  lr: 0.000125  loss: 0.1947 (0.2063)  time: 0.2451  data: 0.0001  max mem: 11902
[17:02:56.995262] Epoch: [20]  [320/345]  eta: 0:00:06  lr: 0.000125  loss: 0.1915 (0.2060)  time: 0.2452  data: 0.0001  max mem: 11902
[17:03:01.897720] Epoch: [20]  [340/345]  eta: 0:00:01  lr: 0.000125  loss: 0.2121 (0.2065)  time: 0.2451  data: 0.0001  max mem: 11902
[17:03:02.876536] Epoch: [20]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.2115 (0.2064)  time: 0.2448  data: 0.0001  max mem: 11902
[17:03:02.941684] Epoch: [20] Total time: 0:01:24 (0.2459 s / it)
[17:03:02.942207] Averaged stats: lr: 0.000125  loss: 0.2115 (0.2064)
[17:03:03.395388] Test:  [  0/345]  eta: 0:02:34  loss: 0.2422 (0.2422)  time: 0.4488  data: 0.3716  max mem: 11902
[17:03:04.189799] Test:  [ 10/345]  eta: 0:00:37  loss: 0.1947 (0.2023)  time: 0.1129  data: 0.0339  max mem: 11902
[17:03:04.989379] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1945 (0.1974)  time: 0.0796  data: 0.0001  max mem: 11902
[17:03:05.791505] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1874 (0.1955)  time: 0.0800  data: 0.0001  max mem: 11902
[17:03:06.595242] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1850 (0.1928)  time: 0.0802  data: 0.0001  max mem: 11902
[17:03:07.403381] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1823 (0.1928)  time: 0.0805  data: 0.0001  max mem: 11902
[17:03:08.215643] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1873 (0.1945)  time: 0.0809  data: 0.0001  max mem: 11902
[17:03:09.031078] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1932 (0.1951)  time: 0.0813  data: 0.0001  max mem: 11902
[17:03:09.850177] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1932 (0.1947)  time: 0.0816  data: 0.0001  max mem: 11902
[17:03:10.672208] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1861 (0.1934)  time: 0.0820  data: 0.0001  max mem: 11902
[17:03:11.497676] Test:  [100/345]  eta: 0:00:20  loss: 0.1816 (0.1929)  time: 0.0823  data: 0.0001  max mem: 11902
[17:03:12.327558] Test:  [110/345]  eta: 0:00:19  loss: 0.1843 (0.1931)  time: 0.0827  data: 0.0001  max mem: 11902
[17:03:13.159101] Test:  [120/345]  eta: 0:00:18  loss: 0.1854 (0.1920)  time: 0.0830  data: 0.0001  max mem: 11902
[17:03:13.995142] Test:  [130/345]  eta: 0:00:18  loss: 0.1875 (0.1924)  time: 0.0833  data: 0.0001  max mem: 11902
[17:03:14.835724] Test:  [140/345]  eta: 0:00:17  loss: 0.1929 (0.1924)  time: 0.0838  data: 0.0001  max mem: 11902
[17:03:15.679269] Test:  [150/345]  eta: 0:00:16  loss: 0.1925 (0.1925)  time: 0.0841  data: 0.0001  max mem: 11902
[17:03:16.526548] Test:  [160/345]  eta: 0:00:15  loss: 0.1895 (0.1924)  time: 0.0845  data: 0.0001  max mem: 11902
[17:03:17.377971] Test:  [170/345]  eta: 0:00:14  loss: 0.1951 (0.1928)  time: 0.0849  data: 0.0001  max mem: 11902
[17:03:18.232543] Test:  [180/345]  eta: 0:00:13  loss: 0.1970 (0.1931)  time: 0.0852  data: 0.0001  max mem: 11902
[17:03:19.090584] Test:  [190/345]  eta: 0:00:13  loss: 0.1954 (0.1931)  time: 0.0856  data: 0.0001  max mem: 11902
[17:03:19.953361] Test:  [200/345]  eta: 0:00:12  loss: 0.1801 (0.1927)  time: 0.0860  data: 0.0001  max mem: 11902
[17:03:20.818368] Test:  [210/345]  eta: 0:00:11  loss: 0.1801 (0.1925)  time: 0.0863  data: 0.0001  max mem: 11902
[17:03:21.688199] Test:  [220/345]  eta: 0:00:10  loss: 0.1833 (0.1924)  time: 0.0867  data: 0.0001  max mem: 11902
[17:03:22.560361] Test:  [230/345]  eta: 0:00:09  loss: 0.2033 (0.1932)  time: 0.0870  data: 0.0001  max mem: 11902
[17:03:23.436090] Test:  [240/345]  eta: 0:00:08  loss: 0.1976 (0.1930)  time: 0.0873  data: 0.0001  max mem: 11902
[17:03:24.316223] Test:  [250/345]  eta: 0:00:08  loss: 0.1865 (0.1926)  time: 0.0877  data: 0.0001  max mem: 11902
[17:03:25.198752] Test:  [260/345]  eta: 0:00:07  loss: 0.1800 (0.1925)  time: 0.0881  data: 0.0001  max mem: 11902
[17:03:26.085056] Test:  [270/345]  eta: 0:00:06  loss: 0.1914 (0.1929)  time: 0.0884  data: 0.0001  max mem: 11902
[17:03:26.976235] Test:  [280/345]  eta: 0:00:05  loss: 0.2047 (0.1932)  time: 0.0888  data: 0.0001  max mem: 11902
[17:03:27.868447] Test:  [290/345]  eta: 0:00:04  loss: 0.1865 (0.1928)  time: 0.0891  data: 0.0001  max mem: 11902
[17:03:28.765572] Test:  [300/345]  eta: 0:00:03  loss: 0.1765 (0.1928)  time: 0.0894  data: 0.0001  max mem: 11902
[17:03:29.666533] Test:  [310/345]  eta: 0:00:03  loss: 0.1880 (0.1926)  time: 0.0898  data: 0.0001  max mem: 11902
[17:03:30.570023] Test:  [320/345]  eta: 0:00:02  loss: 0.1880 (0.1925)  time: 0.0902  data: 0.0001  max mem: 11902
[17:03:31.477711] Test:  [330/345]  eta: 0:00:01  loss: 0.1974 (0.1927)  time: 0.0905  data: 0.0001  max mem: 11902
[17:03:32.388901] Test:  [340/345]  eta: 0:00:00  loss: 0.1942 (0.1926)  time: 0.0909  data: 0.0001  max mem: 11902
[17:03:32.755303] Test:  [344/345]  eta: 0:00:00  loss: 0.1872 (0.1925)  time: 0.0910  data: 0.0001  max mem: 11902
[17:03:32.824396] Test: Total time: 0:00:29 (0.0866 s / it)
[17:03:42.696712] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4511 (0.4511)  time: 0.4195  data: 0.3425  max mem: 11902
[17:03:43.489618] Test:  [10/57]  eta: 0:00:05  loss: 0.3800 (0.4254)  time: 0.1101  data: 0.0316  max mem: 11902
[17:03:44.281234] Test:  [20/57]  eta: 0:00:03  loss: 0.3995 (0.4181)  time: 0.0791  data: 0.0003  max mem: 11902
[17:03:45.076972] Test:  [30/57]  eta: 0:00:02  loss: 0.2841 (0.3658)  time: 0.0793  data: 0.0001  max mem: 11902
[17:03:45.877928] Test:  [40/57]  eta: 0:00:01  loss: 0.2812 (0.3496)  time: 0.0798  data: 0.0001  max mem: 11902
[17:03:46.680449] Test:  [50/57]  eta: 0:00:00  loss: 0.3042 (0.3512)  time: 0.0801  data: 0.0001  max mem: 11902
[17:03:47.116180] Test:  [56/57]  eta: 0:00:00  loss: 0.3352 (0.3603)  time: 0.0779  data: 0.0000  max mem: 11902
[17:03:47.186317] Test: Total time: 0:00:04 (0.0861 s / it)
[17:03:48.857776] Dice score of the network on the train images: 0.825880, val images: 0.679237
[17:03:48.861306] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:03:49.452539] Epoch: [21]  [  0/345]  eta: 0:03:23  lr: 0.000125  loss: 0.2165 (0.2165)  time: 0.5901  data: 0.3443  max mem: 11902
[17:03:54.327892] Epoch: [21]  [ 20/345]  eta: 0:01:24  lr: 0.000125  loss: 0.1969 (0.2021)  time: 0.2437  data: 0.0001  max mem: 11902
[17:03:59.202790] Epoch: [21]  [ 40/345]  eta: 0:01:16  lr: 0.000125  loss: 0.1948 (0.2019)  time: 0.2437  data: 0.0001  max mem: 11902
[17:04:04.068903] Epoch: [21]  [ 60/345]  eta: 0:01:11  lr: 0.000125  loss: 0.2055 (0.2035)  time: 0.2433  data: 0.0001  max mem: 11902
[17:04:08.947702] Epoch: [21]  [ 80/345]  eta: 0:01:05  lr: 0.000124  loss: 0.1959 (0.2026)  time: 0.2439  data: 0.0001  max mem: 11902
[17:04:13.835858] Epoch: [21]  [100/345]  eta: 0:01:00  lr: 0.000124  loss: 0.1929 (0.2024)  time: 0.2444  data: 0.0001  max mem: 11902
[17:04:18.722340] Epoch: [21]  [120/345]  eta: 0:00:55  lr: 0.000124  loss: 0.1966 (0.2026)  time: 0.2443  data: 0.0001  max mem: 11902
[17:04:23.612836] Epoch: [21]  [140/345]  eta: 0:00:50  lr: 0.000124  loss: 0.1915 (0.2020)  time: 0.2445  data: 0.0001  max mem: 11902
[17:04:28.503291] Epoch: [21]  [160/345]  eta: 0:00:45  lr: 0.000124  loss: 0.1986 (0.2024)  time: 0.2445  data: 0.0001  max mem: 11902
[17:04:33.395024] Epoch: [21]  [180/345]  eta: 0:00:40  lr: 0.000124  loss: 0.1949 (0.2014)  time: 0.2445  data: 0.0001  max mem: 11902
[17:04:38.288179] Epoch: [21]  [200/345]  eta: 0:00:35  lr: 0.000124  loss: 0.1911 (0.2007)  time: 0.2446  data: 0.0001  max mem: 11902
[17:04:43.188006] Epoch: [21]  [220/345]  eta: 0:00:30  lr: 0.000124  loss: 0.1933 (0.2005)  time: 0.2449  data: 0.0001  max mem: 11902
[17:04:48.094283] Epoch: [21]  [240/345]  eta: 0:00:25  lr: 0.000124  loss: 0.1911 (0.2003)  time: 0.2453  data: 0.0001  max mem: 11902
[17:04:53.000205] Epoch: [21]  [260/345]  eta: 0:00:20  lr: 0.000124  loss: 0.2008 (0.2004)  time: 0.2453  data: 0.0001  max mem: 11902
[17:04:57.890160] Epoch: [21]  [280/345]  eta: 0:00:15  lr: 0.000124  loss: 0.1905 (0.2000)  time: 0.2445  data: 0.0001  max mem: 11902
[17:05:02.786684] Epoch: [21]  [300/345]  eta: 0:00:11  lr: 0.000124  loss: 0.1932 (0.2000)  time: 0.2448  data: 0.0001  max mem: 11902
[17:05:07.755437] Epoch: [21]  [320/345]  eta: 0:00:06  lr: 0.000124  loss: 0.1962 (0.1999)  time: 0.2484  data: 0.0001  max mem: 11902
[17:05:12.659505] Epoch: [21]  [340/345]  eta: 0:00:01  lr: 0.000124  loss: 0.1923 (0.1997)  time: 0.2452  data: 0.0001  max mem: 11902
[17:05:13.638217] Epoch: [21]  [344/345]  eta: 0:00:00  lr: 0.000124  loss: 0.1923 (0.1997)  time: 0.2449  data: 0.0001  max mem: 11902
[17:05:13.709932] Epoch: [21] Total time: 0:01:24 (0.2459 s / it)
[17:05:13.710140] Averaged stats: lr: 0.000124  loss: 0.1923 (0.1997)
[17:05:14.140202] Test:  [  0/345]  eta: 0:02:26  loss: 0.2109 (0.2109)  time: 0.4255  data: 0.3481  max mem: 11902
[17:05:14.938617] Test:  [ 10/345]  eta: 0:00:37  loss: 0.1927 (0.1903)  time: 0.1112  data: 0.0321  max mem: 11902
[17:05:15.737146] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1916 (0.1941)  time: 0.0797  data: 0.0003  max mem: 11902
[17:05:16.538385] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1986 (0.1953)  time: 0.0799  data: 0.0001  max mem: 11902
[17:05:17.343001] Test:  [ 40/345]  eta: 0:00:26  loss: 0.1879 (0.1938)  time: 0.0802  data: 0.0001  max mem: 11902
[17:05:18.151717] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1859 (0.1960)  time: 0.0806  data: 0.0001  max mem: 11902
[17:05:18.962893] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1982 (0.1948)  time: 0.0809  data: 0.0001  max mem: 11902
[17:05:19.777389] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1961 (0.1966)  time: 0.0812  data: 0.0001  max mem: 11902
[17:05:20.595404] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1980 (0.1971)  time: 0.0816  data: 0.0001  max mem: 11902
[17:05:21.417533] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1882 (0.1958)  time: 0.0819  data: 0.0001  max mem: 11902
[17:05:22.243097] Test:  [100/345]  eta: 0:00:20  loss: 0.1786 (0.1945)  time: 0.0823  data: 0.0001  max mem: 11902
[17:05:23.072943] Test:  [110/345]  eta: 0:00:19  loss: 0.1828 (0.1947)  time: 0.0827  data: 0.0001  max mem: 11902
[17:05:23.905432] Test:  [120/345]  eta: 0:00:18  loss: 0.1919 (0.1942)  time: 0.0831  data: 0.0001  max mem: 11902
[17:05:24.742363] Test:  [130/345]  eta: 0:00:18  loss: 0.1874 (0.1932)  time: 0.0834  data: 0.0001  max mem: 11902
[17:05:25.582653] Test:  [140/345]  eta: 0:00:17  loss: 0.1878 (0.1929)  time: 0.0838  data: 0.0001  max mem: 11902
[17:05:26.426985] Test:  [150/345]  eta: 0:00:16  loss: 0.1918 (0.1931)  time: 0.0841  data: 0.0001  max mem: 11902
[17:05:27.273799] Test:  [160/345]  eta: 0:00:15  loss: 0.1889 (0.1925)  time: 0.0844  data: 0.0001  max mem: 11902
[17:05:28.124069] Test:  [170/345]  eta: 0:00:14  loss: 0.1801 (0.1924)  time: 0.0848  data: 0.0001  max mem: 11902
[17:05:28.978641] Test:  [180/345]  eta: 0:00:13  loss: 0.1802 (0.1921)  time: 0.0852  data: 0.0001  max mem: 11902
[17:05:29.835969] Test:  [190/345]  eta: 0:00:13  loss: 0.1804 (0.1920)  time: 0.0855  data: 0.0001  max mem: 11902
[17:05:30.697911] Test:  [200/345]  eta: 0:00:12  loss: 0.1804 (0.1919)  time: 0.0859  data: 0.0001  max mem: 11902
[17:05:31.563299] Test:  [210/345]  eta: 0:00:11  loss: 0.1783 (0.1911)  time: 0.0863  data: 0.0001  max mem: 11902
[17:05:32.431568] Test:  [220/345]  eta: 0:00:10  loss: 0.1803 (0.1910)  time: 0.0866  data: 0.0001  max mem: 11902
[17:05:33.302614] Test:  [230/345]  eta: 0:00:09  loss: 0.1840 (0.1913)  time: 0.0869  data: 0.0001  max mem: 11902
[17:05:34.178021] Test:  [240/345]  eta: 0:00:08  loss: 0.1816 (0.1908)  time: 0.0873  data: 0.0001  max mem: 11902
[17:05:35.057253] Test:  [250/345]  eta: 0:00:08  loss: 0.1787 (0.1906)  time: 0.0877  data: 0.0001  max mem: 11902
[17:05:35.938964] Test:  [260/345]  eta: 0:00:07  loss: 0.1816 (0.1905)  time: 0.0880  data: 0.0001  max mem: 11902
[17:05:36.824886] Test:  [270/345]  eta: 0:00:06  loss: 0.1827 (0.1905)  time: 0.0883  data: 0.0001  max mem: 11902
[17:05:37.714826] Test:  [280/345]  eta: 0:00:05  loss: 0.1807 (0.1905)  time: 0.0887  data: 0.0001  max mem: 11902
[17:05:38.607657] Test:  [290/345]  eta: 0:00:04  loss: 0.1761 (0.1900)  time: 0.0891  data: 0.0001  max mem: 11902
[17:05:39.505077] Test:  [300/345]  eta: 0:00:03  loss: 0.1787 (0.1899)  time: 0.0894  data: 0.0001  max mem: 11902
[17:05:40.404903] Test:  [310/345]  eta: 0:00:03  loss: 0.1864 (0.1898)  time: 0.0898  data: 0.0001  max mem: 11902
[17:05:41.309001] Test:  [320/345]  eta: 0:00:02  loss: 0.1836 (0.1894)  time: 0.0901  data: 0.0001  max mem: 11902
[17:05:42.216355] Test:  [330/345]  eta: 0:00:01  loss: 0.1708 (0.1894)  time: 0.0905  data: 0.0001  max mem: 11902
[17:05:43.127329] Test:  [340/345]  eta: 0:00:00  loss: 0.1897 (0.1896)  time: 0.0909  data: 0.0001  max mem: 11902
[17:05:43.493505] Test:  [344/345]  eta: 0:00:00  loss: 0.1806 (0.1894)  time: 0.0910  data: 0.0001  max mem: 11902
[17:05:43.564664] Test: Total time: 0:00:29 (0.0865 s / it)
[17:05:53.306214] Test:  [ 0/57]  eta: 0:00:22  loss: 0.4438 (0.4438)  time: 0.3958  data: 0.3185  max mem: 11902
[17:05:54.112281] Test:  [10/57]  eta: 0:00:05  loss: 0.4074 (0.4528)  time: 0.1091  data: 0.0306  max mem: 11902
[17:05:54.905614] Test:  [20/57]  eta: 0:00:03  loss: 0.4036 (0.4400)  time: 0.0799  data: 0.0010  max mem: 11902
[17:05:55.700774] Test:  [30/57]  eta: 0:00:02  loss: 0.2719 (0.3781)  time: 0.0794  data: 0.0001  max mem: 11902
[17:05:56.499849] Test:  [40/57]  eta: 0:00:01  loss: 0.2421 (0.3545)  time: 0.0796  data: 0.0001  max mem: 11902
[17:05:57.301357] Test:  [50/57]  eta: 0:00:00  loss: 0.2953 (0.3560)  time: 0.0800  data: 0.0001  max mem: 11902
[17:05:57.736864] Test:  [56/57]  eta: 0:00:00  loss: 0.3705 (0.3899)  time: 0.0778  data: 0.0001  max mem: 11902
[17:05:57.804993] Test: Total time: 0:00:04 (0.0859 s / it)
[17:05:59.478518] Dice score of the network on the train images: 0.824336, val images: 0.482182
[17:05:59.482079] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:06:00.068363] Epoch: [22]  [  0/345]  eta: 0:03:21  lr: 0.000124  loss: 0.1714 (0.1714)  time: 0.5852  data: 0.3385  max mem: 11902
[17:06:04.933539] Epoch: [22]  [ 20/345]  eta: 0:01:24  lr: 0.000124  loss: 0.1846 (0.1867)  time: 0.2432  data: 0.0001  max mem: 11902
[17:06:09.812769] Epoch: [22]  [ 40/345]  eta: 0:01:16  lr: 0.000123  loss: 0.1928 (0.1914)  time: 0.2439  data: 0.0001  max mem: 11902
[17:06:14.698427] Epoch: [22]  [ 60/345]  eta: 0:01:11  lr: 0.000123  loss: 0.1966 (0.1940)  time: 0.2442  data: 0.0001  max mem: 11902
[17:06:19.583821] Epoch: [22]  [ 80/345]  eta: 0:01:05  lr: 0.000123  loss: 0.1898 (0.1951)  time: 0.2442  data: 0.0001  max mem: 11902
[17:06:24.474923] Epoch: [22]  [100/345]  eta: 0:01:00  lr: 0.000123  loss: 0.1829 (0.1939)  time: 0.2445  data: 0.0001  max mem: 11902
[17:06:29.369504] Epoch: [22]  [120/345]  eta: 0:00:55  lr: 0.000123  loss: 0.1969 (0.1946)  time: 0.2447  data: 0.0001  max mem: 11902
[17:06:34.262841] Epoch: [22]  [140/345]  eta: 0:00:50  lr: 0.000123  loss: 0.1988 (0.1954)  time: 0.2446  data: 0.0001  max mem: 11902
[17:06:39.155319] Epoch: [22]  [160/345]  eta: 0:00:45  lr: 0.000123  loss: 0.1939 (0.1957)  time: 0.2446  data: 0.0001  max mem: 11902
[17:06:44.055480] Epoch: [22]  [180/345]  eta: 0:00:40  lr: 0.000123  loss: 0.1939 (0.1958)  time: 0.2450  data: 0.0001  max mem: 11902
[17:06:48.955108] Epoch: [22]  [200/345]  eta: 0:00:35  lr: 0.000123  loss: 0.1933 (0.1961)  time: 0.2449  data: 0.0001  max mem: 11902
[17:06:53.862226] Epoch: [22]  [220/345]  eta: 0:00:30  lr: 0.000123  loss: 0.1909 (0.1958)  time: 0.2453  data: 0.0001  max mem: 11902
[17:06:58.766080] Epoch: [22]  [240/345]  eta: 0:00:25  lr: 0.000123  loss: 0.1950 (0.1962)  time: 0.2451  data: 0.0001  max mem: 11902
[17:07:03.670798] Epoch: [22]  [260/345]  eta: 0:00:20  lr: 0.000122  loss: 0.1831 (0.1957)  time: 0.2452  data: 0.0001  max mem: 11902
[17:07:08.583662] Epoch: [22]  [280/345]  eta: 0:00:15  lr: 0.000122  loss: 0.1922 (0.1960)  time: 0.2456  data: 0.0001  max mem: 11902
[17:07:13.477707] Epoch: [22]  [300/345]  eta: 0:00:11  lr: 0.000122  loss: 0.1905 (0.1956)  time: 0.2447  data: 0.0001  max mem: 11902
[17:07:18.369299] Epoch: [22]  [320/345]  eta: 0:00:06  lr: 0.000122  loss: 0.1858 (0.1954)  time: 0.2445  data: 0.0001  max mem: 11902
[17:07:23.265279] Epoch: [22]  [340/345]  eta: 0:00:01  lr: 0.000122  loss: 0.1892 (0.1952)  time: 0.2448  data: 0.0001  max mem: 11902
[17:07:24.244529] Epoch: [22]  [344/345]  eta: 0:00:00  lr: 0.000122  loss: 0.1857 (0.1951)  time: 0.2448  data: 0.0001  max mem: 11902
[17:07:24.309577] Epoch: [22] Total time: 0:01:24 (0.2459 s / it)
[17:07:24.309784] Averaged stats: lr: 0.000122  loss: 0.1857 (0.1951)
[17:07:24.801600] Test:  [  0/345]  eta: 0:02:48  loss: 0.1874 (0.1874)  time: 0.4873  data: 0.4103  max mem: 11902
[17:07:25.597202] Test:  [ 10/345]  eta: 0:00:39  loss: 0.1867 (0.1844)  time: 0.1165  data: 0.0374  max mem: 11902
[17:07:26.395381] Test:  [ 20/345]  eta: 0:00:32  loss: 0.1778 (0.1838)  time: 0.0796  data: 0.0001  max mem: 11902
[17:07:27.197804] Test:  [ 30/345]  eta: 0:00:29  loss: 0.1811 (0.1850)  time: 0.0799  data: 0.0001  max mem: 11902
[17:07:28.004330] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1852 (0.1856)  time: 0.0803  data: 0.0001  max mem: 11902
[17:07:28.812596] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1925 (0.1888)  time: 0.0806  data: 0.0001  max mem: 11902
[17:07:29.625591] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1911 (0.1870)  time: 0.0810  data: 0.0001  max mem: 11902
[17:07:30.439984] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1760 (0.1851)  time: 0.0813  data: 0.0001  max mem: 11902
[17:07:31.258554] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1689 (0.1831)  time: 0.0816  data: 0.0001  max mem: 11902
[17:07:32.081485] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1679 (0.1832)  time: 0.0820  data: 0.0001  max mem: 11902
[17:07:32.907467] Test:  [100/345]  eta: 0:00:20  loss: 0.1869 (0.1841)  time: 0.0823  data: 0.0001  max mem: 11902
[17:07:33.737454] Test:  [110/345]  eta: 0:00:19  loss: 0.1855 (0.1838)  time: 0.0827  data: 0.0001  max mem: 11902
[17:07:34.570825] Test:  [120/345]  eta: 0:00:19  loss: 0.1893 (0.1851)  time: 0.0831  data: 0.0001  max mem: 11902
[17:07:35.408062] Test:  [130/345]  eta: 0:00:18  loss: 0.1958 (0.1858)  time: 0.0834  data: 0.0001  max mem: 11902
[17:07:36.248914] Test:  [140/345]  eta: 0:00:17  loss: 0.1902 (0.1864)  time: 0.0838  data: 0.0001  max mem: 11902
[17:07:37.093099] Test:  [150/345]  eta: 0:00:16  loss: 0.1873 (0.1862)  time: 0.0841  data: 0.0001  max mem: 11902
[17:07:37.940157] Test:  [160/345]  eta: 0:00:15  loss: 0.1845 (0.1868)  time: 0.0844  data: 0.0001  max mem: 11902
[17:07:38.791745] Test:  [170/345]  eta: 0:00:14  loss: 0.1800 (0.1862)  time: 0.0848  data: 0.0001  max mem: 11902
[17:07:39.646233] Test:  [180/345]  eta: 0:00:13  loss: 0.1800 (0.1865)  time: 0.0852  data: 0.0001  max mem: 11902
[17:07:40.504085] Test:  [190/345]  eta: 0:00:13  loss: 0.1934 (0.1869)  time: 0.0855  data: 0.0001  max mem: 11902
[17:07:41.366827] Test:  [200/345]  eta: 0:00:12  loss: 0.1865 (0.1868)  time: 0.0859  data: 0.0001  max mem: 11902
[17:07:42.232443] Test:  [210/345]  eta: 0:00:11  loss: 0.1725 (0.1868)  time: 0.0863  data: 0.0001  max mem: 11902
[17:07:43.101419] Test:  [220/345]  eta: 0:00:10  loss: 0.1725 (0.1866)  time: 0.0866  data: 0.0001  max mem: 11902
[17:07:43.973792] Test:  [230/345]  eta: 0:00:09  loss: 0.1738 (0.1864)  time: 0.0870  data: 0.0001  max mem: 11902
[17:07:44.850446] Test:  [240/345]  eta: 0:00:08  loss: 0.1786 (0.1862)  time: 0.0874  data: 0.0001  max mem: 11902
[17:07:45.729530] Test:  [250/345]  eta: 0:00:08  loss: 0.1815 (0.1862)  time: 0.0877  data: 0.0001  max mem: 11902
[17:07:46.612053] Test:  [260/345]  eta: 0:00:07  loss: 0.1737 (0.1857)  time: 0.0880  data: 0.0001  max mem: 11902
[17:07:47.498761] Test:  [270/345]  eta: 0:00:06  loss: 0.1751 (0.1857)  time: 0.0884  data: 0.0001  max mem: 11902
[17:07:48.389504] Test:  [280/345]  eta: 0:00:05  loss: 0.1857 (0.1859)  time: 0.0888  data: 0.0001  max mem: 11902
[17:07:49.282799] Test:  [290/345]  eta: 0:00:04  loss: 0.1842 (0.1859)  time: 0.0891  data: 0.0001  max mem: 11902
[17:07:50.180576] Test:  [300/345]  eta: 0:00:03  loss: 0.1838 (0.1860)  time: 0.0895  data: 0.0001  max mem: 11902
[17:07:51.082056] Test:  [310/345]  eta: 0:00:03  loss: 0.1838 (0.1859)  time: 0.0899  data: 0.0001  max mem: 11902
[17:07:51.987852] Test:  [320/345]  eta: 0:00:02  loss: 0.1743 (0.1856)  time: 0.0903  data: 0.0001  max mem: 11902
[17:07:52.895622] Test:  [330/345]  eta: 0:00:01  loss: 0.1798 (0.1857)  time: 0.0906  data: 0.0001  max mem: 11902
[17:07:53.806032] Test:  [340/345]  eta: 0:00:00  loss: 0.1808 (0.1853)  time: 0.0909  data: 0.0001  max mem: 11902
[17:07:54.172023] Test:  [344/345]  eta: 0:00:00  loss: 0.1732 (0.1850)  time: 0.0910  data: 0.0001  max mem: 11902
[17:07:54.242497] Test: Total time: 0:00:29 (0.0868 s / it)
[17:08:04.098130] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4531 (0.4531)  time: 0.4049  data: 0.3278  max mem: 11902
[17:08:04.891573] Test:  [10/57]  eta: 0:00:05  loss: 0.4157 (0.4551)  time: 0.1088  data: 0.0304  max mem: 11902
[17:08:05.683601] Test:  [20/57]  eta: 0:00:03  loss: 0.4157 (0.4514)  time: 0.0792  data: 0.0004  max mem: 11902
[17:08:06.479280] Test:  [30/57]  eta: 0:00:02  loss: 0.2800 (0.3904)  time: 0.0793  data: 0.0001  max mem: 11902
[17:08:07.278605] Test:  [40/57]  eta: 0:00:01  loss: 0.2738 (0.3658)  time: 0.0797  data: 0.0001  max mem: 11902
[17:08:08.081505] Test:  [50/57]  eta: 0:00:00  loss: 0.3110 (0.3711)  time: 0.0801  data: 0.0001  max mem: 11902
[17:08:08.517585] Test:  [56/57]  eta: 0:00:00  loss: 0.3622 (0.4072)  time: 0.0779  data: 0.0001  max mem: 11902
[17:08:08.585935] Test: Total time: 0:00:04 (0.0859 s / it)
[17:08:10.232498] Dice score of the network on the train images: 0.837990, val images: 0.354868
[17:08:10.236027] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:08:10.810515] Epoch: [23]  [  0/345]  eta: 0:03:17  lr: 0.000122  loss: 0.2050 (0.2050)  time: 0.5734  data: 0.3268  max mem: 11902
[17:08:15.686367] Epoch: [23]  [ 20/345]  eta: 0:01:24  lr: 0.000122  loss: 0.1946 (0.1971)  time: 0.2437  data: 0.0001  max mem: 11902
[17:08:20.559631] Epoch: [23]  [ 40/345]  eta: 0:01:16  lr: 0.000122  loss: 0.1840 (0.1948)  time: 0.2436  data: 0.0001  max mem: 11902
[17:08:25.432943] Epoch: [23]  [ 60/345]  eta: 0:01:10  lr: 0.000122  loss: 0.1883 (0.1944)  time: 0.2436  data: 0.0001  max mem: 11902
[17:08:30.309949] Epoch: [23]  [ 80/345]  eta: 0:01:05  lr: 0.000121  loss: 0.1942 (0.1945)  time: 0.2438  data: 0.0001  max mem: 11902
[17:08:35.191787] Epoch: [23]  [100/345]  eta: 0:01:00  lr: 0.000121  loss: 0.1929 (0.1945)  time: 0.2441  data: 0.0001  max mem: 11902
[17:08:40.078420] Epoch: [23]  [120/345]  eta: 0:00:55  lr: 0.000121  loss: 0.1893 (0.1953)  time: 0.2443  data: 0.0001  max mem: 11902
[17:08:44.967706] Epoch: [23]  [140/345]  eta: 0:00:50  lr: 0.000121  loss: 0.1839 (0.1939)  time: 0.2444  data: 0.0001  max mem: 11902
[17:08:49.861168] Epoch: [23]  [160/345]  eta: 0:00:45  lr: 0.000121  loss: 0.1856 (0.1925)  time: 0.2446  data: 0.0001  max mem: 11902
[17:08:54.757225] Epoch: [23]  [180/345]  eta: 0:00:40  lr: 0.000121  loss: 0.1833 (0.1917)  time: 0.2448  data: 0.0001  max mem: 11902
[17:08:59.651978] Epoch: [23]  [200/345]  eta: 0:00:35  lr: 0.000121  loss: 0.1812 (0.1912)  time: 0.2447  data: 0.0001  max mem: 11902
[17:09:04.552467] Epoch: [23]  [220/345]  eta: 0:00:30  lr: 0.000121  loss: 0.1799 (0.1906)  time: 0.2450  data: 0.0001  max mem: 11902
[17:09:09.454327] Epoch: [23]  [240/345]  eta: 0:00:25  lr: 0.000120  loss: 0.1904 (0.1909)  time: 0.2450  data: 0.0001  max mem: 11902
[17:09:14.357661] Epoch: [23]  [260/345]  eta: 0:00:20  lr: 0.000120  loss: 0.1704 (0.1903)  time: 0.2451  data: 0.0001  max mem: 11902
[17:09:19.255181] Epoch: [23]  [280/345]  eta: 0:00:15  lr: 0.000120  loss: 0.1870 (0.1903)  time: 0.2448  data: 0.0001  max mem: 11902
[17:09:24.166388] Epoch: [23]  [300/345]  eta: 0:00:11  lr: 0.000120  loss: 0.1851 (0.1903)  time: 0.2455  data: 0.0001  max mem: 11902
[17:09:29.066521] Epoch: [23]  [320/345]  eta: 0:00:06  lr: 0.000120  loss: 0.1791 (0.1898)  time: 0.2450  data: 0.0001  max mem: 11902
[17:09:33.966352] Epoch: [23]  [340/345]  eta: 0:00:01  lr: 0.000120  loss: 0.1881 (0.1895)  time: 0.2449  data: 0.0001  max mem: 11902
[17:09:34.945595] Epoch: [23]  [344/345]  eta: 0:00:00  lr: 0.000120  loss: 0.1881 (0.1895)  time: 0.2448  data: 0.0001  max mem: 11902
[17:09:35.010674] Epoch: [23] Total time: 0:01:24 (0.2457 s / it)
[17:09:35.010967] Averaged stats: lr: 0.000120  loss: 0.1881 (0.1895)
[17:09:35.449938] Test:  [  0/345]  eta: 0:02:29  loss: 0.2157 (0.2157)  time: 0.4348  data: 0.3571  max mem: 11902
[17:09:36.242624] Test:  [ 10/345]  eta: 0:00:37  loss: 0.1760 (0.1845)  time: 0.1115  data: 0.0326  max mem: 11902
[17:09:37.042250] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1708 (0.1755)  time: 0.0795  data: 0.0001  max mem: 11902
[17:09:37.843337] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1723 (0.1765)  time: 0.0800  data: 0.0001  max mem: 11902
[17:09:38.646130] Test:  [ 40/345]  eta: 0:00:26  loss: 0.1710 (0.1748)  time: 0.0801  data: 0.0001  max mem: 11902
[17:09:39.453642] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1743 (0.1786)  time: 0.0804  data: 0.0001  max mem: 11902
[17:09:40.266110] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1787 (0.1785)  time: 0.0809  data: 0.0001  max mem: 11902
[17:09:41.081068] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1790 (0.1789)  time: 0.0813  data: 0.0001  max mem: 11902
[17:09:41.898944] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1897 (0.1812)  time: 0.0816  data: 0.0001  max mem: 11902
[17:09:42.721701] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1825 (0.1813)  time: 0.0820  data: 0.0001  max mem: 11902
[17:09:43.548138] Test:  [100/345]  eta: 0:00:20  loss: 0.1749 (0.1801)  time: 0.0824  data: 0.0001  max mem: 11902
[17:09:44.377890] Test:  [110/345]  eta: 0:00:19  loss: 0.1726 (0.1796)  time: 0.0827  data: 0.0001  max mem: 11902
[17:09:45.210166] Test:  [120/345]  eta: 0:00:18  loss: 0.1779 (0.1799)  time: 0.0830  data: 0.0001  max mem: 11902
[17:09:46.047013] Test:  [130/345]  eta: 0:00:18  loss: 0.1795 (0.1799)  time: 0.0834  data: 0.0001  max mem: 11902
[17:09:46.887291] Test:  [140/345]  eta: 0:00:17  loss: 0.1749 (0.1803)  time: 0.0838  data: 0.0001  max mem: 11902
[17:09:47.730018] Test:  [150/345]  eta: 0:00:16  loss: 0.1839 (0.1807)  time: 0.0841  data: 0.0001  max mem: 11902
[17:09:48.576184] Test:  [160/345]  eta: 0:00:15  loss: 0.1809 (0.1804)  time: 0.0844  data: 0.0001  max mem: 11902
[17:09:49.427329] Test:  [170/345]  eta: 0:00:14  loss: 0.1743 (0.1801)  time: 0.0848  data: 0.0001  max mem: 11902
[17:09:50.283587] Test:  [180/345]  eta: 0:00:13  loss: 0.1693 (0.1792)  time: 0.0853  data: 0.0001  max mem: 11902
[17:09:51.141283] Test:  [190/345]  eta: 0:00:13  loss: 0.1832 (0.1797)  time: 0.0856  data: 0.0001  max mem: 11902
[17:09:52.002814] Test:  [200/345]  eta: 0:00:12  loss: 0.1894 (0.1800)  time: 0.0859  data: 0.0001  max mem: 11902
[17:09:52.866824] Test:  [210/345]  eta: 0:00:11  loss: 0.1791 (0.1804)  time: 0.0862  data: 0.0001  max mem: 11902
[17:09:53.735841] Test:  [220/345]  eta: 0:00:10  loss: 0.1778 (0.1798)  time: 0.0866  data: 0.0001  max mem: 11902
[17:09:54.607577] Test:  [230/345]  eta: 0:00:09  loss: 0.1682 (0.1795)  time: 0.0870  data: 0.0001  max mem: 11902
[17:09:55.483339] Test:  [240/345]  eta: 0:00:08  loss: 0.1758 (0.1797)  time: 0.0873  data: 0.0001  max mem: 11902
[17:09:56.362140] Test:  [250/345]  eta: 0:00:08  loss: 0.1758 (0.1793)  time: 0.0877  data: 0.0001  max mem: 11902
[17:09:57.245355] Test:  [260/345]  eta: 0:00:07  loss: 0.1741 (0.1796)  time: 0.0880  data: 0.0001  max mem: 11902
[17:09:58.131767] Test:  [270/345]  eta: 0:00:06  loss: 0.1804 (0.1793)  time: 0.0884  data: 0.0001  max mem: 11902
[17:09:59.021947] Test:  [280/345]  eta: 0:00:05  loss: 0.1747 (0.1795)  time: 0.0888  data: 0.0001  max mem: 11902
[17:09:59.915213] Test:  [290/345]  eta: 0:00:04  loss: 0.1795 (0.1797)  time: 0.0891  data: 0.0001  max mem: 11902
[17:10:00.812483] Test:  [300/345]  eta: 0:00:03  loss: 0.1838 (0.1799)  time: 0.0894  data: 0.0001  max mem: 11902
[17:10:01.713039] Test:  [310/345]  eta: 0:00:03  loss: 0.1838 (0.1797)  time: 0.0898  data: 0.0001  max mem: 11902
[17:10:02.616201] Test:  [320/345]  eta: 0:00:02  loss: 0.1800 (0.1799)  time: 0.0901  data: 0.0001  max mem: 11902
[17:10:03.523562] Test:  [330/345]  eta: 0:00:01  loss: 0.1853 (0.1802)  time: 0.0905  data: 0.0001  max mem: 11902
[17:10:04.435574] Test:  [340/345]  eta: 0:00:00  loss: 0.1834 (0.1799)  time: 0.0909  data: 0.0001  max mem: 11902
[17:10:04.801365] Test:  [344/345]  eta: 0:00:00  loss: 0.1809 (0.1800)  time: 0.0911  data: 0.0001  max mem: 11902
[17:10:04.862685] Test: Total time: 0:00:29 (0.0865 s / it)
[17:10:14.773022] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4445 (0.4445)  time: 0.4650  data: 0.3877  max mem: 11902
[17:10:15.561570] Test:  [10/57]  eta: 0:00:05  loss: 0.4445 (0.4737)  time: 0.1138  data: 0.0354  max mem: 11902
[17:10:16.354036] Test:  [20/57]  eta: 0:00:03  loss: 0.4488 (0.4771)  time: 0.0790  data: 0.0001  max mem: 11902
[17:10:17.150605] Test:  [30/57]  eta: 0:00:02  loss: 0.2894 (0.4086)  time: 0.0794  data: 0.0001  max mem: 11902
[17:10:17.950973] Test:  [40/57]  eta: 0:00:01  loss: 0.2693 (0.3801)  time: 0.0798  data: 0.0001  max mem: 11902
[17:10:18.753775] Test:  [50/57]  eta: 0:00:00  loss: 0.2978 (0.3843)  time: 0.0801  data: 0.0001  max mem: 11902
[17:10:19.191037] Test:  [56/57]  eta: 0:00:00  loss: 0.3930 (0.4214)  time: 0.0780  data: 0.0001  max mem: 11902
[17:10:19.261728] Test: Total time: 0:00:04 (0.0869 s / it)
[17:10:20.910914] Dice score of the network on the train images: 0.836801, val images: 0.391626
[17:10:20.914612] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:10:21.494812] Epoch: [24]  [  0/345]  eta: 0:03:19  lr: 0.000120  loss: 0.1937 (0.1937)  time: 0.5793  data: 0.3339  max mem: 11902
[17:10:26.365331] Epoch: [24]  [ 20/345]  eta: 0:01:24  lr: 0.000119  loss: 0.1739 (0.1865)  time: 0.2435  data: 0.0001  max mem: 11902
[17:10:31.243100] Epoch: [24]  [ 40/345]  eta: 0:01:16  lr: 0.000119  loss: 0.1844 (0.1874)  time: 0.2438  data: 0.0001  max mem: 11902
[17:10:36.126405] Epoch: [24]  [ 60/345]  eta: 0:01:11  lr: 0.000119  loss: 0.1734 (0.1849)  time: 0.2441  data: 0.0001  max mem: 11902
[17:10:41.007537] Epoch: [24]  [ 80/345]  eta: 0:01:05  lr: 0.000119  loss: 0.1875 (0.1860)  time: 0.2440  data: 0.0001  max mem: 11902
[17:10:45.890714] Epoch: [24]  [100/345]  eta: 0:01:00  lr: 0.000119  loss: 0.1807 (0.1849)  time: 0.2441  data: 0.0001  max mem: 11902
[17:10:50.765743] Epoch: [24]  [120/345]  eta: 0:00:55  lr: 0.000119  loss: 0.1766 (0.1842)  time: 0.2437  data: 0.0001  max mem: 11902
[17:10:55.644126] Epoch: [24]  [140/345]  eta: 0:00:50  lr: 0.000118  loss: 0.1853 (0.1854)  time: 0.2439  data: 0.0001  max mem: 11902
[17:11:00.526363] Epoch: [24]  [160/345]  eta: 0:00:45  lr: 0.000118  loss: 0.1871 (0.1859)  time: 0.2441  data: 0.0001  max mem: 11902
[17:11:05.417523] Epoch: [24]  [180/345]  eta: 0:00:40  lr: 0.000118  loss: 0.1741 (0.1847)  time: 0.2445  data: 0.0001  max mem: 11902
[17:11:10.319921] Epoch: [24]  [200/345]  eta: 0:00:35  lr: 0.000118  loss: 0.1733 (0.1847)  time: 0.2451  data: 0.0001  max mem: 11902
[17:11:15.225348] Epoch: [24]  [220/345]  eta: 0:00:30  lr: 0.000118  loss: 0.1812 (0.1840)  time: 0.2452  data: 0.0001  max mem: 11902
[17:11:20.123007] Epoch: [24]  [240/345]  eta: 0:00:25  lr: 0.000118  loss: 0.1806 (0.1842)  time: 0.2448  data: 0.0001  max mem: 11902
[17:11:25.025773] Epoch: [24]  [260/345]  eta: 0:00:20  lr: 0.000117  loss: 0.1864 (0.1843)  time: 0.2451  data: 0.0001  max mem: 11902
[17:11:29.931998] Epoch: [24]  [280/345]  eta: 0:00:15  lr: 0.000117  loss: 0.1766 (0.1840)  time: 0.2453  data: 0.0001  max mem: 11902
[17:11:34.844225] Epoch: [24]  [300/345]  eta: 0:00:11  lr: 0.000117  loss: 0.1845 (0.1840)  time: 0.2456  data: 0.0001  max mem: 11902
[17:11:39.749829] Epoch: [24]  [320/345]  eta: 0:00:06  lr: 0.000117  loss: 0.1660 (0.1834)  time: 0.2452  data: 0.0001  max mem: 11902
[17:11:44.649563] Epoch: [24]  [340/345]  eta: 0:00:01  lr: 0.000117  loss: 0.1868 (0.1835)  time: 0.2449  data: 0.0001  max mem: 11902
[17:11:45.631191] Epoch: [24]  [344/345]  eta: 0:00:00  lr: 0.000117  loss: 0.1868 (0.1835)  time: 0.2450  data: 0.0001  max mem: 11902
[17:11:45.698493] Epoch: [24] Total time: 0:01:24 (0.2457 s / it)
[17:11:45.699100] Averaged stats: lr: 0.000117  loss: 0.1868 (0.1835)
[17:11:46.123018] Test:  [  0/345]  eta: 0:02:24  loss: 0.1888 (0.1888)  time: 0.4192  data: 0.3420  max mem: 11902
[17:11:46.924675] Test:  [ 10/345]  eta: 0:00:37  loss: 0.1716 (0.1668)  time: 0.1109  data: 0.0318  max mem: 11902
[17:11:47.721690] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1750 (0.1767)  time: 0.0799  data: 0.0005  max mem: 11902
[17:11:48.522705] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1750 (0.1731)  time: 0.0798  data: 0.0001  max mem: 11902
[17:11:49.326821] Test:  [ 40/345]  eta: 0:00:26  loss: 0.1640 (0.1706)  time: 0.0802  data: 0.0001  max mem: 11902
[17:11:50.135522] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1722 (0.1723)  time: 0.0806  data: 0.0001  max mem: 11902
[17:11:50.948069] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1715 (0.1722)  time: 0.0810  data: 0.0001  max mem: 11902
[17:11:51.764762] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1672 (0.1725)  time: 0.0814  data: 0.0001  max mem: 11902
[17:11:52.584157] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1741 (0.1731)  time: 0.0817  data: 0.0001  max mem: 11902
[17:11:53.406828] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1695 (0.1729)  time: 0.0820  data: 0.0001  max mem: 11902
[17:11:54.232668] Test:  [100/345]  eta: 0:00:20  loss: 0.1650 (0.1733)  time: 0.0824  data: 0.0001  max mem: 11902
[17:11:55.062582] Test:  [110/345]  eta: 0:00:19  loss: 0.1675 (0.1732)  time: 0.0827  data: 0.0001  max mem: 11902
[17:11:55.895537] Test:  [120/345]  eta: 0:00:18  loss: 0.1669 (0.1724)  time: 0.0830  data: 0.0001  max mem: 11902
[17:11:56.732600] Test:  [130/345]  eta: 0:00:18  loss: 0.1624 (0.1722)  time: 0.0834  data: 0.0001  max mem: 11902
[17:11:57.573224] Test:  [140/345]  eta: 0:00:17  loss: 0.1709 (0.1724)  time: 0.0838  data: 0.0001  max mem: 11902
[17:11:58.418319] Test:  [150/345]  eta: 0:00:16  loss: 0.1744 (0.1729)  time: 0.0842  data: 0.0001  max mem: 11902
[17:11:59.267640] Test:  [160/345]  eta: 0:00:15  loss: 0.1638 (0.1724)  time: 0.0846  data: 0.0001  max mem: 11902
[17:12:00.118764] Test:  [170/345]  eta: 0:00:14  loss: 0.1665 (0.1726)  time: 0.0849  data: 0.0001  max mem: 11902
[17:12:00.973773] Test:  [180/345]  eta: 0:00:13  loss: 0.1768 (0.1731)  time: 0.0852  data: 0.0001  max mem: 11902
[17:12:01.833896] Test:  [190/345]  eta: 0:00:13  loss: 0.1717 (0.1731)  time: 0.0856  data: 0.0001  max mem: 11902
[17:12:02.695600] Test:  [200/345]  eta: 0:00:12  loss: 0.1607 (0.1726)  time: 0.0860  data: 0.0001  max mem: 11902
[17:12:03.561404] Test:  [210/345]  eta: 0:00:11  loss: 0.1597 (0.1732)  time: 0.0863  data: 0.0001  max mem: 11902
[17:12:04.430390] Test:  [220/345]  eta: 0:00:10  loss: 0.1730 (0.1732)  time: 0.0867  data: 0.0001  max mem: 11902
[17:12:05.303115] Test:  [230/345]  eta: 0:00:09  loss: 0.1730 (0.1735)  time: 0.0870  data: 0.0001  max mem: 11902
[17:12:06.179996] Test:  [240/345]  eta: 0:00:08  loss: 0.1683 (0.1732)  time: 0.0874  data: 0.0001  max mem: 11902
[17:12:07.060051] Test:  [250/345]  eta: 0:00:08  loss: 0.1797 (0.1735)  time: 0.0878  data: 0.0001  max mem: 11902
[17:12:07.943659] Test:  [260/345]  eta: 0:00:07  loss: 0.1800 (0.1733)  time: 0.0881  data: 0.0001  max mem: 11902
[17:12:08.831654] Test:  [270/345]  eta: 0:00:06  loss: 0.1682 (0.1730)  time: 0.0885  data: 0.0001  max mem: 11902
[17:12:09.722834] Test:  [280/345]  eta: 0:00:05  loss: 0.1690 (0.1732)  time: 0.0889  data: 0.0001  max mem: 11902
[17:12:10.617175] Test:  [290/345]  eta: 0:00:04  loss: 0.1691 (0.1731)  time: 0.0892  data: 0.0001  max mem: 11902
[17:12:11.514754] Test:  [300/345]  eta: 0:00:03  loss: 0.1714 (0.1735)  time: 0.0895  data: 0.0001  max mem: 11902
[17:12:12.415080] Test:  [310/345]  eta: 0:00:03  loss: 0.1721 (0.1736)  time: 0.0898  data: 0.0001  max mem: 11902
[17:12:13.319151] Test:  [320/345]  eta: 0:00:02  loss: 0.1772 (0.1741)  time: 0.0902  data: 0.0001  max mem: 11902
[17:12:14.226661] Test:  [330/345]  eta: 0:00:01  loss: 0.1659 (0.1734)  time: 0.0905  data: 0.0001  max mem: 11902
[17:12:15.138180] Test:  [340/345]  eta: 0:00:00  loss: 0.1602 (0.1733)  time: 0.0909  data: 0.0001  max mem: 11902
[17:12:15.504202] Test:  [344/345]  eta: 0:00:00  loss: 0.1672 (0.1734)  time: 0.0911  data: 0.0001  max mem: 11902
[17:12:15.572765] Test: Total time: 0:00:29 (0.0866 s / it)
[17:12:25.468808] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4492 (0.4492)  time: 0.4412  data: 0.3640  max mem: 11902
[17:12:26.256951] Test:  [10/57]  eta: 0:00:05  loss: 0.3949 (0.4267)  time: 0.1117  data: 0.0332  max mem: 11902
[17:12:27.049057] Test:  [20/57]  eta: 0:00:03  loss: 0.3949 (0.4320)  time: 0.0789  data: 0.0001  max mem: 11902
[17:12:27.846421] Test:  [30/57]  eta: 0:00:02  loss: 0.2867 (0.3744)  time: 0.0794  data: 0.0001  max mem: 11902
[17:12:28.648259] Test:  [40/57]  eta: 0:00:01  loss: 0.2749 (0.3540)  time: 0.0799  data: 0.0001  max mem: 11902
[17:12:29.450426] Test:  [50/57]  eta: 0:00:00  loss: 0.2979 (0.3575)  time: 0.0801  data: 0.0001  max mem: 11902
[17:12:29.886014] Test:  [56/57]  eta: 0:00:00  loss: 0.3528 (0.3748)  time: 0.0779  data: 0.0001  max mem: 11902
[17:12:29.948720] Test: Total time: 0:00:04 (0.0863 s / it)
[17:12:31.622494] Dice score of the network on the train images: 0.841928, val images: 0.574434
[17:12:31.626292] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:12:32.213142] Epoch: [25]  [  0/345]  eta: 0:03:22  lr: 0.000117  loss: 0.1765 (0.1765)  time: 0.5857  data: 0.3400  max mem: 11902
[17:12:37.087528] Epoch: [25]  [ 20/345]  eta: 0:01:24  lr: 0.000116  loss: 0.1771 (0.1785)  time: 0.2437  data: 0.0001  max mem: 11902
[17:12:41.963802] Epoch: [25]  [ 40/345]  eta: 0:01:16  lr: 0.000116  loss: 0.1774 (0.1780)  time: 0.2438  data: 0.0001  max mem: 11902
[17:12:46.834718] Epoch: [25]  [ 60/345]  eta: 0:01:11  lr: 0.000116  loss: 0.1708 (0.1763)  time: 0.2435  data: 0.0001  max mem: 11902
[17:12:51.702044] Epoch: [25]  [ 80/345]  eta: 0:01:05  lr: 0.000116  loss: 0.1805 (0.1785)  time: 0.2433  data: 0.0001  max mem: 11902
[17:12:56.577175] Epoch: [25]  [100/345]  eta: 0:01:00  lr: 0.000116  loss: 0.1859 (0.1805)  time: 0.2437  data: 0.0001  max mem: 11902
[17:13:01.536591] Epoch: [25]  [120/345]  eta: 0:00:55  lr: 0.000115  loss: 0.1892 (0.1814)  time: 0.2479  data: 0.0001  max mem: 11902
[17:13:06.431738] Epoch: [25]  [140/345]  eta: 0:00:50  lr: 0.000115  loss: 0.1913 (0.1821)  time: 0.2447  data: 0.0001  max mem: 11902
[17:13:11.326436] Epoch: [25]  [160/345]  eta: 0:00:45  lr: 0.000115  loss: 0.1704 (0.1816)  time: 0.2447  data: 0.0001  max mem: 11902
[17:13:16.223640] Epoch: [25]  [180/345]  eta: 0:00:40  lr: 0.000115  loss: 0.1688 (0.1811)  time: 0.2448  data: 0.0001  max mem: 11902
[17:13:21.120033] Epoch: [25]  [200/345]  eta: 0:00:35  lr: 0.000115  loss: 0.1741 (0.1805)  time: 0.2448  data: 0.0001  max mem: 11902
[17:13:26.020621] Epoch: [25]  [220/345]  eta: 0:00:30  lr: 0.000114  loss: 0.1703 (0.1803)  time: 0.2450  data: 0.0001  max mem: 11902
[17:13:30.923746] Epoch: [25]  [240/345]  eta: 0:00:25  lr: 0.000114  loss: 0.1763 (0.1802)  time: 0.2451  data: 0.0001  max mem: 11902
[17:13:35.830950] Epoch: [25]  [260/345]  eta: 0:00:20  lr: 0.000114  loss: 0.1901 (0.1815)  time: 0.2453  data: 0.0001  max mem: 11902
[17:13:40.732495] Epoch: [25]  [280/345]  eta: 0:00:15  lr: 0.000114  loss: 0.1779 (0.1818)  time: 0.2450  data: 0.0001  max mem: 11902
[17:13:45.633087] Epoch: [25]  [300/345]  eta: 0:00:11  lr: 0.000114  loss: 0.1804 (0.1816)  time: 0.2450  data: 0.0001  max mem: 11902
[17:13:50.536396] Epoch: [25]  [320/345]  eta: 0:00:06  lr: 0.000113  loss: 0.1753 (0.1813)  time: 0.2451  data: 0.0001  max mem: 11902
[17:13:55.425646] Epoch: [25]  [340/345]  eta: 0:00:01  lr: 0.000113  loss: 0.1695 (0.1811)  time: 0.2444  data: 0.0001  max mem: 11902
[17:13:56.404007] Epoch: [25]  [344/345]  eta: 0:00:00  lr: 0.000113  loss: 0.1693 (0.1809)  time: 0.2443  data: 0.0001  max mem: 11902
[17:13:56.480668] Epoch: [25] Total time: 0:01:24 (0.2460 s / it)
[17:13:56.480968] Averaged stats: lr: 0.000113  loss: 0.1693 (0.1809)
[17:13:56.978234] Test:  [  0/345]  eta: 0:02:50  loss: 0.1472 (0.1472)  time: 0.4932  data: 0.4161  max mem: 11902
[17:13:57.773856] Test:  [ 10/345]  eta: 0:00:39  loss: 0.1575 (0.1637)  time: 0.1171  data: 0.0379  max mem: 11902
[17:13:58.573578] Test:  [ 20/345]  eta: 0:00:32  loss: 0.1727 (0.1699)  time: 0.0797  data: 0.0001  max mem: 11902
[17:13:59.376402] Test:  [ 30/345]  eta: 0:00:29  loss: 0.1727 (0.1692)  time: 0.0800  data: 0.0001  max mem: 11902
[17:14:00.180803] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1575 (0.1679)  time: 0.0803  data: 0.0001  max mem: 11902
[17:14:00.988265] Test:  [ 50/345]  eta: 0:00:26  loss: 0.1601 (0.1681)  time: 0.0805  data: 0.0001  max mem: 11902
[17:14:01.800652] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1713 (0.1688)  time: 0.0809  data: 0.0001  max mem: 11902
[17:14:02.616048] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1644 (0.1692)  time: 0.0813  data: 0.0001  max mem: 11902
[17:14:03.434300] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1602 (0.1677)  time: 0.0816  data: 0.0001  max mem: 11902
[17:14:04.256524] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1619 (0.1682)  time: 0.0819  data: 0.0001  max mem: 11902
[17:14:05.082598] Test:  [100/345]  eta: 0:00:20  loss: 0.1692 (0.1683)  time: 0.0823  data: 0.0001  max mem: 11902
[17:14:05.911361] Test:  [110/345]  eta: 0:00:19  loss: 0.1694 (0.1684)  time: 0.0827  data: 0.0001  max mem: 11902
[17:14:06.744429] Test:  [120/345]  eta: 0:00:19  loss: 0.1752 (0.1696)  time: 0.0830  data: 0.0001  max mem: 11902
[17:14:07.581285] Test:  [130/345]  eta: 0:00:18  loss: 0.1752 (0.1697)  time: 0.0834  data: 0.0001  max mem: 11902
[17:14:08.421519] Test:  [140/345]  eta: 0:00:17  loss: 0.1625 (0.1694)  time: 0.0838  data: 0.0001  max mem: 11902
[17:14:09.265241] Test:  [150/345]  eta: 0:00:16  loss: 0.1631 (0.1693)  time: 0.0841  data: 0.0001  max mem: 11902
[17:14:10.112234] Test:  [160/345]  eta: 0:00:15  loss: 0.1646 (0.1692)  time: 0.0845  data: 0.0001  max mem: 11902
[17:14:10.963472] Test:  [170/345]  eta: 0:00:14  loss: 0.1632 (0.1691)  time: 0.0848  data: 0.0001  max mem: 11902
[17:14:11.817646] Test:  [180/345]  eta: 0:00:13  loss: 0.1626 (0.1691)  time: 0.0852  data: 0.0001  max mem: 11902
[17:14:12.675859] Test:  [190/345]  eta: 0:00:13  loss: 0.1667 (0.1690)  time: 0.0855  data: 0.0001  max mem: 11902
[17:14:13.537604] Test:  [200/345]  eta: 0:00:12  loss: 0.1720 (0.1695)  time: 0.0859  data: 0.0001  max mem: 11902
[17:14:14.402819] Test:  [210/345]  eta: 0:00:11  loss: 0.1678 (0.1695)  time: 0.0863  data: 0.0001  max mem: 11902
[17:14:15.271971] Test:  [220/345]  eta: 0:00:10  loss: 0.1666 (0.1693)  time: 0.0867  data: 0.0001  max mem: 11902
[17:14:16.145430] Test:  [230/345]  eta: 0:00:09  loss: 0.1592 (0.1695)  time: 0.0871  data: 0.0001  max mem: 11902
[17:14:17.021659] Test:  [240/345]  eta: 0:00:08  loss: 0.1638 (0.1697)  time: 0.0874  data: 0.0001  max mem: 11902
[17:14:17.900621] Test:  [250/345]  eta: 0:00:08  loss: 0.1638 (0.1696)  time: 0.0877  data: 0.0001  max mem: 11902
[17:14:18.784728] Test:  [260/345]  eta: 0:00:07  loss: 0.1592 (0.1695)  time: 0.0881  data: 0.0001  max mem: 11902
[17:14:19.670467] Test:  [270/345]  eta: 0:00:06  loss: 0.1673 (0.1696)  time: 0.0884  data: 0.0001  max mem: 11902
[17:14:20.560894] Test:  [280/345]  eta: 0:00:05  loss: 0.1673 (0.1695)  time: 0.0887  data: 0.0001  max mem: 11902
[17:14:21.454498] Test:  [290/345]  eta: 0:00:04  loss: 0.1692 (0.1696)  time: 0.0891  data: 0.0001  max mem: 11902
[17:14:22.351736] Test:  [300/345]  eta: 0:00:03  loss: 0.1715 (0.1699)  time: 0.0895  data: 0.0001  max mem: 11902
[17:14:23.252820] Test:  [310/345]  eta: 0:00:03  loss: 0.1689 (0.1698)  time: 0.0898  data: 0.0001  max mem: 11902
[17:14:24.156349] Test:  [320/345]  eta: 0:00:02  loss: 0.1637 (0.1698)  time: 0.0902  data: 0.0001  max mem: 11902
[17:14:25.065179] Test:  [330/345]  eta: 0:00:01  loss: 0.1644 (0.1698)  time: 0.0906  data: 0.0001  max mem: 11902
[17:14:25.976092] Test:  [340/345]  eta: 0:00:00  loss: 0.1603 (0.1697)  time: 0.0909  data: 0.0001  max mem: 11902
[17:14:26.342637] Test:  [344/345]  eta: 0:00:00  loss: 0.1644 (0.1698)  time: 0.0911  data: 0.0001  max mem: 11902
[17:14:26.413725] Test: Total time: 0:00:29 (0.0868 s / it)
[17:14:36.315816] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4468 (0.4468)  time: 0.4064  data: 0.3290  max mem: 11902
[17:14:37.109080] Test:  [10/57]  eta: 0:00:05  loss: 0.3950 (0.4273)  time: 0.1090  data: 0.0304  max mem: 11902
[17:14:37.902087] Test:  [20/57]  eta: 0:00:03  loss: 0.3950 (0.4209)  time: 0.0792  data: 0.0003  max mem: 11902
[17:14:38.702512] Test:  [30/57]  eta: 0:00:02  loss: 0.2576 (0.3616)  time: 0.0796  data: 0.0001  max mem: 11902
[17:14:39.504495] Test:  [40/57]  eta: 0:00:01  loss: 0.2547 (0.3387)  time: 0.0801  data: 0.0001  max mem: 11902
[17:14:40.306319] Test:  [50/57]  eta: 0:00:00  loss: 0.2743 (0.3434)  time: 0.0801  data: 0.0001  max mem: 11902
[17:14:40.741887] Test:  [56/57]  eta: 0:00:00  loss: 0.3335 (0.3709)  time: 0.0779  data: 0.0000  max mem: 11902
[17:14:40.818397] Test: Total time: 0:00:04 (0.0861 s / it)
[17:14:42.515941] Dice score of the network on the train images: 0.835118, val images: 0.591557
[17:14:42.519328] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:14:43.129953] Epoch: [26]  [  0/345]  eta: 0:03:30  lr: 0.000113  loss: 0.1632 (0.1632)  time: 0.6098  data: 0.3539  max mem: 11902
[17:14:48.005835] Epoch: [26]  [ 20/345]  eta: 0:01:24  lr: 0.000113  loss: 0.1614 (0.1669)  time: 0.2437  data: 0.0001  max mem: 11902
[17:14:52.881377] Epoch: [26]  [ 40/345]  eta: 0:01:17  lr: 0.000113  loss: 0.1624 (0.1675)  time: 0.2437  data: 0.0001  max mem: 11902
[17:14:57.756111] Epoch: [26]  [ 60/345]  eta: 0:01:11  lr: 0.000112  loss: 0.1791 (0.1716)  time: 0.2437  data: 0.0001  max mem: 11902
[17:15:02.632528] Epoch: [26]  [ 80/345]  eta: 0:01:05  lr: 0.000112  loss: 0.1674 (0.1712)  time: 0.2438  data: 0.0001  max mem: 11902
[17:15:07.512245] Epoch: [26]  [100/345]  eta: 0:01:00  lr: 0.000112  loss: 0.1761 (0.1724)  time: 0.2439  data: 0.0001  max mem: 11902
[17:15:12.395698] Epoch: [26]  [120/345]  eta: 0:00:55  lr: 0.000112  loss: 0.1679 (0.1728)  time: 0.2441  data: 0.0001  max mem: 11902
[17:15:17.284449] Epoch: [26]  [140/345]  eta: 0:00:50  lr: 0.000111  loss: 0.1686 (0.1719)  time: 0.2444  data: 0.0001  max mem: 11902
[17:15:22.173152] Epoch: [26]  [160/345]  eta: 0:00:45  lr: 0.000111  loss: 0.1693 (0.1727)  time: 0.2444  data: 0.0001  max mem: 11902
[17:15:27.062916] Epoch: [26]  [180/345]  eta: 0:00:40  lr: 0.000111  loss: 0.1635 (0.1718)  time: 0.2445  data: 0.0001  max mem: 11902
[17:15:31.956939] Epoch: [26]  [200/345]  eta: 0:00:35  lr: 0.000111  loss: 0.1905 (0.1734)  time: 0.2447  data: 0.0001  max mem: 11902
[17:15:36.851013] Epoch: [26]  [220/345]  eta: 0:00:30  lr: 0.000110  loss: 0.1773 (0.1738)  time: 0.2447  data: 0.0001  max mem: 11902
[17:15:41.750065] Epoch: [26]  [240/345]  eta: 0:00:25  lr: 0.000110  loss: 0.1679 (0.1741)  time: 0.2449  data: 0.0001  max mem: 11902
[17:15:46.646278] Epoch: [26]  [260/345]  eta: 0:00:20  lr: 0.000110  loss: 0.1778 (0.1742)  time: 0.2448  data: 0.0001  max mem: 11902
[17:15:51.543912] Epoch: [26]  [280/345]  eta: 0:00:15  lr: 0.000110  loss: 0.1632 (0.1735)  time: 0.2448  data: 0.0001  max mem: 11902
[17:15:56.449115] Epoch: [26]  [300/345]  eta: 0:00:11  lr: 0.000110  loss: 0.1788 (0.1740)  time: 0.2452  data: 0.0001  max mem: 11902
[17:16:01.352234] Epoch: [26]  [320/345]  eta: 0:00:06  lr: 0.000109  loss: 0.1823 (0.1746)  time: 0.2451  data: 0.0001  max mem: 11902
[17:16:06.250348] Epoch: [26]  [340/345]  eta: 0:00:01  lr: 0.000109  loss: 0.1735 (0.1747)  time: 0.2449  data: 0.0001  max mem: 11902
[17:16:07.231373] Epoch: [26]  [344/345]  eta: 0:00:00  lr: 0.000109  loss: 0.1777 (0.1748)  time: 0.2449  data: 0.0001  max mem: 11902
[17:16:07.305290] Epoch: [26] Total time: 0:01:24 (0.2458 s / it)
[17:16:07.305674] Averaged stats: lr: 0.000109  loss: 0.1777 (0.1748)
[17:16:07.811345] Test:  [  0/345]  eta: 0:02:52  loss: 0.1822 (0.1822)  time: 0.5012  data: 0.4242  max mem: 11902
[17:16:08.607143] Test:  [ 10/345]  eta: 0:00:39  loss: 0.1519 (0.1555)  time: 0.1178  data: 0.0387  max mem: 11902
[17:16:09.405111] Test:  [ 20/345]  eta: 0:00:32  loss: 0.1521 (0.1581)  time: 0.0796  data: 0.0001  max mem: 11902
[17:16:10.207216] Test:  [ 30/345]  eta: 0:00:29  loss: 0.1545 (0.1606)  time: 0.0799  data: 0.0001  max mem: 11902
[17:16:11.012291] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1596 (0.1619)  time: 0.0803  data: 0.0001  max mem: 11902
[17:16:11.820227] Test:  [ 50/345]  eta: 0:00:26  loss: 0.1674 (0.1631)  time: 0.0806  data: 0.0001  max mem: 11902
[17:16:12.632239] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1724 (0.1649)  time: 0.0809  data: 0.0001  max mem: 11902
[17:16:13.445384] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1512 (0.1627)  time: 0.0812  data: 0.0001  max mem: 11902
[17:16:14.263333] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1519 (0.1629)  time: 0.0815  data: 0.0001  max mem: 11902
[17:16:15.085285] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1620 (0.1631)  time: 0.0819  data: 0.0001  max mem: 11902
[17:16:15.909822] Test:  [100/345]  eta: 0:00:20  loss: 0.1579 (0.1628)  time: 0.0823  data: 0.0001  max mem: 11902
[17:16:16.739400] Test:  [110/345]  eta: 0:00:19  loss: 0.1579 (0.1639)  time: 0.0826  data: 0.0001  max mem: 11902
[17:16:17.572654] Test:  [120/345]  eta: 0:00:19  loss: 0.1590 (0.1638)  time: 0.0831  data: 0.0001  max mem: 11902
[17:16:18.409027] Test:  [130/345]  eta: 0:00:18  loss: 0.1590 (0.1635)  time: 0.0834  data: 0.0001  max mem: 11902
[17:16:19.248836] Test:  [140/345]  eta: 0:00:17  loss: 0.1603 (0.1636)  time: 0.0837  data: 0.0001  max mem: 11902
[17:16:20.091560] Test:  [150/345]  eta: 0:00:16  loss: 0.1659 (0.1644)  time: 0.0841  data: 0.0001  max mem: 11902
[17:16:20.938131] Test:  [160/345]  eta: 0:00:15  loss: 0.1629 (0.1640)  time: 0.0844  data: 0.0001  max mem: 11902
[17:16:21.788119] Test:  [170/345]  eta: 0:00:14  loss: 0.1642 (0.1642)  time: 0.0847  data: 0.0001  max mem: 11902
[17:16:22.642291] Test:  [180/345]  eta: 0:00:13  loss: 0.1642 (0.1642)  time: 0.0851  data: 0.0001  max mem: 11902
[17:16:23.498986] Test:  [190/345]  eta: 0:00:13  loss: 0.1607 (0.1640)  time: 0.0855  data: 0.0001  max mem: 11902
[17:16:24.360104] Test:  [200/345]  eta: 0:00:12  loss: 0.1676 (0.1646)  time: 0.0858  data: 0.0001  max mem: 11902
[17:16:25.224913] Test:  [210/345]  eta: 0:00:11  loss: 0.1699 (0.1646)  time: 0.0862  data: 0.0001  max mem: 11902
[17:16:26.093282] Test:  [220/345]  eta: 0:00:10  loss: 0.1601 (0.1649)  time: 0.0866  data: 0.0001  max mem: 11902
[17:16:26.965034] Test:  [230/345]  eta: 0:00:09  loss: 0.1613 (0.1650)  time: 0.0869  data: 0.0001  max mem: 11902
[17:16:27.839916] Test:  [240/345]  eta: 0:00:08  loss: 0.1596 (0.1648)  time: 0.0873  data: 0.0001  max mem: 11902
[17:16:28.720293] Test:  [250/345]  eta: 0:00:08  loss: 0.1658 (0.1651)  time: 0.0877  data: 0.0001  max mem: 11902
[17:16:29.602344] Test:  [260/345]  eta: 0:00:07  loss: 0.1634 (0.1648)  time: 0.0881  data: 0.0001  max mem: 11902
[17:16:30.487847] Test:  [270/345]  eta: 0:00:06  loss: 0.1617 (0.1648)  time: 0.0883  data: 0.0001  max mem: 11902
[17:16:31.377517] Test:  [280/345]  eta: 0:00:05  loss: 0.1617 (0.1645)  time: 0.0887  data: 0.0001  max mem: 11902
[17:16:32.271188] Test:  [290/345]  eta: 0:00:04  loss: 0.1627 (0.1647)  time: 0.0891  data: 0.0001  max mem: 11902
[17:16:33.168928] Test:  [300/345]  eta: 0:00:03  loss: 0.1570 (0.1646)  time: 0.0895  data: 0.0001  max mem: 11902
[17:16:34.069332] Test:  [310/345]  eta: 0:00:03  loss: 0.1598 (0.1650)  time: 0.0898  data: 0.0001  max mem: 11902
[17:16:34.973215] Test:  [320/345]  eta: 0:00:02  loss: 0.1533 (0.1647)  time: 0.0901  data: 0.0001  max mem: 11902
[17:16:35.881753] Test:  [330/345]  eta: 0:00:01  loss: 0.1523 (0.1647)  time: 0.0906  data: 0.0001  max mem: 11902
[17:16:36.791385] Test:  [340/345]  eta: 0:00:00  loss: 0.1613 (0.1642)  time: 0.0909  data: 0.0001  max mem: 11902
[17:16:37.156550] Test:  [344/345]  eta: 0:00:00  loss: 0.1608 (0.1644)  time: 0.0909  data: 0.0001  max mem: 11902
[17:16:37.216633] Test: Total time: 0:00:29 (0.0867 s / it)
[17:16:47.146752] Test:  [ 0/57]  eta: 0:00:22  loss: 0.4526 (0.4526)  time: 0.4017  data: 0.3248  max mem: 11902
[17:16:47.955118] Test:  [10/57]  eta: 0:00:05  loss: 0.4195 (0.4421)  time: 0.1099  data: 0.0314  max mem: 11902
[17:16:48.747616] Test:  [20/57]  eta: 0:00:03  loss: 0.4115 (0.4337)  time: 0.0800  data: 0.0011  max mem: 11902
[17:16:49.542963] Test:  [30/57]  eta: 0:00:02  loss: 0.2681 (0.3800)  time: 0.0793  data: 0.0001  max mem: 11902
[17:16:50.344293] Test:  [40/57]  eta: 0:00:01  loss: 0.2602 (0.3574)  time: 0.0798  data: 0.0001  max mem: 11902
[17:16:51.146439] Test:  [50/57]  eta: 0:00:00  loss: 0.2941 (0.3593)  time: 0.0801  data: 0.0001  max mem: 11902
[17:16:51.582569] Test:  [56/57]  eta: 0:00:00  loss: 0.3486 (0.3808)  time: 0.0779  data: 0.0001  max mem: 11902
[17:16:51.652050] Test: Total time: 0:00:04 (0.0861 s / it)
[17:16:53.382190] Dice score of the network on the train images: 0.844112, val images: 0.711111
[17:16:53.385709] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:16:54.046294] Epoch: [27]  [  0/345]  eta: 0:03:47  lr: 0.000109  loss: 0.1827 (0.1827)  time: 0.6597  data: 0.4115  max mem: 11902
[17:16:58.925120] Epoch: [27]  [ 20/345]  eta: 0:01:25  lr: 0.000109  loss: 0.1628 (0.1718)  time: 0.2439  data: 0.0001  max mem: 11902

[17:17:03.802648] Epoch: [27]  [ 40/345]  eta: 0:01:17  lr: 0.000108  loss: 0.1610 (0.1662)  time: 0.2438  data: 0.0001  max mem: 11902
[17:17:08.686393] Epoch: [27]  [ 60/345]  eta: 0:01:11  lr: 0.000108  loss: 0.1557 (0.1657)  time: 0.2441  data: 0.0001  max mem: 11902
[17:17:13.570432] Epoch: [27]  [ 80/345]  eta: 0:01:06  lr: 0.000108  loss: 0.1679 (0.1670)  time: 0.2442  data: 0.0001  max mem: 11902
[17:17:18.461870] Epoch: [27]  [100/345]  eta: 0:01:00  lr: 0.000108  loss: 0.1752 (0.1688)  time: 0.2445  data: 0.0001  max mem: 11902
[17:17:23.352901] Epoch: [27]  [120/345]  eta: 0:00:55  lr: 0.000107  loss: 0.1604 (0.1692)  time: 0.2445  data: 0.0001  max mem: 11902
[17:17:28.243900] Epoch: [27]  [140/345]  eta: 0:00:50  lr: 0.000107  loss: 0.1585 (0.1677)  time: 0.2445  data: 0.0001  max mem: 11902
[17:17:33.133052] Epoch: [27]  [160/345]  eta: 0:00:45  lr: 0.000107  loss: 0.1578 (0.1668)  time: 0.2444  data: 0.0001  max mem: 11902
[17:17:38.018203] Epoch: [27]  [180/345]  eta: 0:00:40  lr: 0.000107  loss: 0.1627 (0.1675)  time: 0.2442  data: 0.0001  max mem: 11902
[17:17:42.911639] Epoch: [27]  [200/345]  eta: 0:00:35  lr: 0.000106  loss: 0.1701 (0.1680)  time: 0.2446  data: 0.0001  max mem: 11902
[17:17:47.808373] Epoch: [27]  [220/345]  eta: 0:00:30  lr: 0.000106  loss: 0.1680 (0.1684)  time: 0.2448  data: 0.0001  max mem: 11902
[17:17:52.708230] Epoch: [27]  [240/345]  eta: 0:00:25  lr: 0.000106  loss: 0.1709 (0.1688)  time: 0.2450  data: 0.0001  max mem: 11902
[17:17:57.606004] Epoch: [27]  [260/345]  eta: 0:00:20  lr: 0.000106  loss: 0.1643 (0.1690)  time: 0.2448  data: 0.0001  max mem: 11902
[17:18:02.508635] Epoch: [27]  [280/345]  eta: 0:00:15  lr: 0.000105  loss: 0.1615 (0.1688)  time: 0.2451  data: 0.0001  max mem: 11902
[17:18:07.411877] Epoch: [27]  [300/345]  eta: 0:00:11  lr: 0.000105  loss: 0.1706 (0.1691)  time: 0.2451  data: 0.0000  max mem: 11902
[17:18:12.314740] Epoch: [27]  [320/345]  eta: 0:00:06  lr: 0.000105  loss: 0.1662 (0.1692)  time: 0.2451  data: 0.0001  max mem: 11902
[17:18:17.211008] Epoch: [27]  [340/345]  eta: 0:00:01  lr: 0.000104  loss: 0.1818 (0.1699)  time: 0.2448  data: 0.0001  max mem: 11902
[17:18:18.188934] Epoch: [27]  [344/345]  eta: 0:00:00  lr: 0.000104  loss: 0.1818 (0.1701)  time: 0.2447  data: 0.0001  max mem: 11902
[17:18:18.268042] Epoch: [27] Total time: 0:01:24 (0.2460 s / it)
[17:18:18.268501] Averaged stats: lr: 0.000104  loss: 0.1818 (0.1701)
[17:18:18.760667] Test:  [  0/345]  eta: 0:02:48  loss: 0.1817 (0.1817)  time: 0.4877  data: 0.4103  max mem: 11902
[17:18:19.556457] Test:  [ 10/345]  eta: 0:00:39  loss: 0.1610 (0.1644)  time: 0.1166  data: 0.0374  max mem: 11902
[17:18:20.353534] Test:  [ 20/345]  eta: 0:00:32  loss: 0.1513 (0.1630)  time: 0.0795  data: 0.0001  max mem: 11902
[17:18:21.154072] Test:  [ 30/345]  eta: 0:00:29  loss: 0.1608 (0.1632)  time: 0.0798  data: 0.0001  max mem: 11902
[17:18:21.957188] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1681 (0.1648)  time: 0.0801  data: 0.0001  max mem: 11902
[17:18:22.765105] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1633 (0.1635)  time: 0.0805  data: 0.0001  max mem: 11902
[17:18:23.577084] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1551 (0.1628)  time: 0.0809  data: 0.0001  max mem: 11902
[17:18:24.392899] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1591 (0.1626)  time: 0.0813  data: 0.0001  max mem: 11902
[17:18:25.210590] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1696 (0.1639)  time: 0.0816  data: 0.0001  max mem: 11902
[17:18:26.033552] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1640 (0.1632)  time: 0.0820  data: 0.0001  max mem: 11902
[17:18:26.858577] Test:  [100/345]  eta: 0:00:20  loss: 0.1588 (0.1633)  time: 0.0823  data: 0.0001  max mem: 11902
[17:18:27.687424] Test:  [110/345]  eta: 0:00:19  loss: 0.1554 (0.1628)  time: 0.0826  data: 0.0001  max mem: 11902
[17:18:28.519977] Test:  [120/345]  eta: 0:00:19  loss: 0.1554 (0.1622)  time: 0.0830  data: 0.0001  max mem: 11902
[17:18:29.356694] Test:  [130/345]  eta: 0:00:18  loss: 0.1648 (0.1628)  time: 0.0834  data: 0.0001  max mem: 11902
[17:18:30.196189] Test:  [140/345]  eta: 0:00:17  loss: 0.1673 (0.1632)  time: 0.0837  data: 0.0001  max mem: 11902
[17:18:31.038961] Test:  [150/345]  eta: 0:00:16  loss: 0.1637 (0.1635)  time: 0.0840  data: 0.0001  max mem: 11902
[17:18:31.885063] Test:  [160/345]  eta: 0:00:15  loss: 0.1601 (0.1629)  time: 0.0844  data: 0.0001  max mem: 11902
[17:18:32.736611] Test:  [170/345]  eta: 0:00:14  loss: 0.1542 (0.1625)  time: 0.0848  data: 0.0001  max mem: 11902
[17:18:33.590384] Test:  [180/345]  eta: 0:00:13  loss: 0.1549 (0.1625)  time: 0.0852  data: 0.0001  max mem: 11902
[17:18:34.447788] Test:  [190/345]  eta: 0:00:13  loss: 0.1549 (0.1624)  time: 0.0855  data: 0.0001  max mem: 11902
[17:18:35.308980] Test:  [200/345]  eta: 0:00:12  loss: 0.1534 (0.1621)  time: 0.0858  data: 0.0001  max mem: 11902
[17:18:36.173560] Test:  [210/345]  eta: 0:00:11  loss: 0.1571 (0.1620)  time: 0.0862  data: 0.0001  max mem: 11902
[17:18:37.041807] Test:  [220/345]  eta: 0:00:10  loss: 0.1543 (0.1617)  time: 0.0866  data: 0.0001  max mem: 11902
[17:18:37.913204] Test:  [230/345]  eta: 0:00:09  loss: 0.1572 (0.1620)  time: 0.0869  data: 0.0001  max mem: 11902
[17:18:38.788888] Test:  [240/345]  eta: 0:00:08  loss: 0.1617 (0.1621)  time: 0.0873  data: 0.0001  max mem: 11902
[17:18:39.668392] Test:  [250/345]  eta: 0:00:08  loss: 0.1617 (0.1627)  time: 0.0877  data: 0.0001  max mem: 11902
[17:18:40.550451] Test:  [260/345]  eta: 0:00:07  loss: 0.1718 (0.1628)  time: 0.0880  data: 0.0001  max mem: 11902
[17:18:41.436704] Test:  [270/345]  eta: 0:00:06  loss: 0.1600 (0.1629)  time: 0.0884  data: 0.0001  max mem: 11902
[17:18:42.325981] Test:  [280/345]  eta: 0:00:05  loss: 0.1580 (0.1629)  time: 0.0887  data: 0.0001  max mem: 11902
[17:18:43.219663] Test:  [290/345]  eta: 0:00:04  loss: 0.1580 (0.1629)  time: 0.0891  data: 0.0001  max mem: 11902
[17:18:44.115581] Test:  [300/345]  eta: 0:00:03  loss: 0.1567 (0.1632)  time: 0.0894  data: 0.0001  max mem: 11902
[17:18:45.016486] Test:  [310/345]  eta: 0:00:03  loss: 0.1706 (0.1634)  time: 0.0898  data: 0.0001  max mem: 11902
[17:18:45.919329] Test:  [320/345]  eta: 0:00:02  loss: 0.1646 (0.1634)  time: 0.0901  data: 0.0001  max mem: 11902
[17:18:46.826954] Test:  [330/345]  eta: 0:00:01  loss: 0.1618 (0.1634)  time: 0.0905  data: 0.0001  max mem: 11902
[17:18:47.738095] Test:  [340/345]  eta: 0:00:00  loss: 0.1504 (0.1631)  time: 0.0909  data: 0.0001  max mem: 11902
[17:18:48.103524] Test:  [344/345]  eta: 0:00:00  loss: 0.1504 (0.1633)  time: 0.0910  data: 0.0001  max mem: 11902
[17:18:48.172329] Test: Total time: 0:00:29 (0.0867 s / it)
[17:18:58.149270] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4375 (0.4375)  time: 0.4722  data: 0.3951  max mem: 11902
[17:18:58.937892] Test:  [10/57]  eta: 0:00:05  loss: 0.3923 (0.4119)  time: 0.1145  data: 0.0360  max mem: 11902
[17:18:59.731680] Test:  [20/57]  eta: 0:00:03  loss: 0.4010 (0.4023)  time: 0.0790  data: 0.0001  max mem: 11902
[17:19:00.527656] Test:  [30/57]  eta: 0:00:02  loss: 0.2656 (0.3467)  time: 0.0794  data: 0.0001  max mem: 11902
[17:19:01.327020] Test:  [40/57]  eta: 0:00:01  loss: 0.2449 (0.3272)  time: 0.0797  data: 0.0001  max mem: 11902
[17:19:02.130306] Test:  [50/57]  eta: 0:00:00  loss: 0.2749 (0.3312)  time: 0.0801  data: 0.0001  max mem: 11902
[17:19:02.567568] Test:  [56/57]  eta: 0:00:00  loss: 0.3327 (0.3531)  time: 0.0780  data: 0.0001  max mem: 11902
[17:19:02.644622] Test: Total time: 0:00:04 (0.0872 s / it)
[17:19:04.369049] Dice score of the network on the train images: 0.851893, val images: 0.753126
[17:19:04.373157] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:19:04.971615] Epoch: [28]  [  0/345]  eta: 0:03:26  lr: 0.000104  loss: 0.1884 (0.1884)  time: 0.5974  data: 0.3516  max mem: 11902
[17:19:09.829207] Epoch: [28]  [ 20/345]  eta: 0:01:24  lr: 0.000104  loss: 0.1623 (0.1659)  time: 0.2428  data: 0.0001  max mem: 11902
[17:19:14.708035] Epoch: [28]  [ 40/345]  eta: 0:01:16  lr: 0.000104  loss: 0.1669 (0.1688)  time: 0.2439  data: 0.0001  max mem: 11902
[17:19:19.589149] Epoch: [28]  [ 60/345]  eta: 0:01:11  lr: 0.000103  loss: 0.1708 (0.1691)  time: 0.2440  data: 0.0001  max mem: 11902
[17:19:24.470350] Epoch: [28]  [ 80/345]  eta: 0:01:05  lr: 0.000103  loss: 0.1703 (0.1692)  time: 0.2440  data: 0.0001  max mem: 11902
[17:19:29.346636] Epoch: [28]  [100/345]  eta: 0:01:00  lr: 0.000103  loss: 0.1588 (0.1682)  time: 0.2438  data: 0.0001  max mem: 11902
[17:19:34.221440] Epoch: [28]  [120/345]  eta: 0:00:55  lr: 0.000103  loss: 0.1639 (0.1677)  time: 0.2437  data: 0.0001  max mem: 11902
[17:19:39.106269] Epoch: [28]  [140/345]  eta: 0:00:50  lr: 0.000102  loss: 0.1623 (0.1674)  time: 0.2442  data: 0.0001  max mem: 11902

[17:19:43.998413] Epoch: [28]  [160/345]  eta: 0:00:45  lr: 0.000102  loss: 0.1688 (0.1676)  time: 0.2446  data: 0.0001  max mem: 11902
[17:19:48.887480] Epoch: [28]  [180/345]  eta: 0:00:40  lr: 0.000102  loss: 0.1509 (0.1669)  time: 0.2444  data: 0.0001  max mem: 11902
[17:19:53.785078] Epoch: [28]  [200/345]  eta: 0:00:35  lr: 0.000101  loss: 0.1676 (0.1676)  time: 0.2448  data: 0.0001  max mem: 11902
[17:19:58.674804] Epoch: [28]  [220/345]  eta: 0:00:30  lr: 0.000101  loss: 0.1629 (0.1675)  time: 0.2444  data: 0.0001  max mem: 11902
[17:20:03.574528] Epoch: [28]  [240/345]  eta: 0:00:25  lr: 0.000101  loss: 0.1617 (0.1676)  time: 0.2449  data: 0.0001  max mem: 11902
[17:20:08.472179] Epoch: [28]  [260/345]  eta: 0:00:20  lr: 0.000101  loss: 0.1631 (0.1677)  time: 0.2448  data: 0.0001  max mem: 11902
[17:20:13.455302] Epoch: [28]  [280/345]  eta: 0:00:15  lr: 0.000100  loss: 0.1628 (0.1678)  time: 0.2491  data: 0.0001  max mem: 11902
[17:20:18.351421] Epoch: [28]  [300/345]  eta: 0:00:11  lr: 0.000100  loss: 0.1626 (0.1678)  time: 0.2448  data: 0.0001  max mem: 11902
[17:20:23.253669] Epoch: [28]  [320/345]  eta: 0:00:06  lr: 0.000100  loss: 0.1636 (0.1676)  time: 0.2451  data: 0.0001  max mem: 11902
[17:20:28.150445] Epoch: [28]  [340/345]  eta: 0:00:01  lr: 0.000099  loss: 0.1625 (0.1674)  time: 0.2448  data: 0.0001  max mem: 11902
[17:20:29.130244] Epoch: [28]  [344/345]  eta: 0:00:00  lr: 0.000099  loss: 0.1642 (0.1675)  time: 0.2448  data: 0.0001  max mem: 11902
[17:20:29.202262] Epoch: [28] Total time: 0:01:24 (0.2459 s / it)
[17:20:29.202700] Averaged stats: lr: 0.000099  loss: 0.1642 (0.1675)
[17:20:29.629141] Test:  [  0/345]  eta: 0:02:25  loss: 0.1380 (0.1380)  time: 0.4222  data: 0.3452  max mem: 11902
[17:20:30.428185] Test:  [ 10/345]  eta: 0:00:37  loss: 0.1559 (0.1543)  time: 0.1109  data: 0.0319  max mem: 11902
[17:20:31.228359] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1579 (0.1573)  time: 0.0798  data: 0.0003  max mem: 11902
[17:20:32.030283] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1584 (0.1582)  time: 0.0800  data: 0.0001  max mem: 11902
[17:20:32.833453] Test:  [ 40/345]  eta: 0:00:26  loss: 0.1493 (0.1579)  time: 0.0802  data: 0.0001  max mem: 11902
[17:20:33.641074] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1474 (0.1547)  time: 0.0804  data: 0.0001  max mem: 11902
[17:20:34.453671] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1463 (0.1554)  time: 0.0809  data: 0.0001  max mem: 11902
[17:20:35.269866] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1557 (0.1556)  time: 0.0814  data: 0.0001  max mem: 11902
[17:20:36.087912] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1559 (0.1559)  time: 0.0816  data: 0.0001  max mem: 11902
[17:20:36.911578] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1593 (0.1565)  time: 0.0820  data: 0.0001  max mem: 11902
[17:20:37.738572] Test:  [100/345]  eta: 0:00:20  loss: 0.1590 (0.1569)  time: 0.0824  data: 0.0001  max mem: 11902
[17:20:38.568486] Test:  [110/345]  eta: 0:00:19  loss: 0.1561 (0.1575)  time: 0.0827  data: 0.0001  max mem: 11902
[17:20:39.401408] Test:  [120/345]  eta: 0:00:18  loss: 0.1625 (0.1584)  time: 0.0831  data: 0.0001  max mem: 11902
[17:20:40.238809] Test:  [130/345]  eta: 0:00:18  loss: 0.1625 (0.1584)  time: 0.0834  data: 0.0001  max mem: 11902
[17:20:41.079808] Test:  [140/345]  eta: 0:00:17  loss: 0.1528 (0.1589)  time: 0.0839  data: 0.0001  max mem: 11902
[17:20:41.924504] Test:  [150/345]  eta: 0:00:16  loss: 0.1610 (0.1590)  time: 0.0842  data: 0.0001  max mem: 11902
[17:20:42.773046] Test:  [160/345]  eta: 0:00:15  loss: 0.1577 (0.1589)  time: 0.0846  data: 0.0001  max mem: 11902
[17:20:43.623910] Test:  [170/345]  eta: 0:00:14  loss: 0.1516 (0.1583)  time: 0.0849  data: 0.0001  max mem: 11902
[17:20:44.477714] Test:  [180/345]  eta: 0:00:13  loss: 0.1529 (0.1588)  time: 0.0852  data: 0.0001  max mem: 11902
[17:20:45.336353] Test:  [190/345]  eta: 0:00:13  loss: 0.1583 (0.1589)  time: 0.0855  data: 0.0001  max mem: 11902
[17:20:46.198102] Test:  [200/345]  eta: 0:00:12  loss: 0.1583 (0.1590)  time: 0.0859  data: 0.0001  max mem: 11902
[17:20:47.062955] Test:  [210/345]  eta: 0:00:11  loss: 0.1541 (0.1586)  time: 0.0863  data: 0.0001  max mem: 11902
[17:20:47.932096] Test:  [220/345]  eta: 0:00:10  loss: 0.1470 (0.1581)  time: 0.0866  data: 0.0001  max mem: 11902
[17:20:48.804339] Test:  [230/345]  eta: 0:00:09  loss: 0.1470 (0.1579)  time: 0.0870  data: 0.0001  max mem: 11902
[17:20:49.681526] Test:  [240/345]  eta: 0:00:08  loss: 0.1443 (0.1576)  time: 0.0874  data: 0.0001  max mem: 11902
[17:20:50.562038] Test:  [250/345]  eta: 0:00:08  loss: 0.1518 (0.1574)  time: 0.0878  data: 0.0001  max mem: 11902
[17:20:51.444797] Test:  [260/345]  eta: 0:00:07  loss: 0.1535 (0.1573)  time: 0.0881  data: 0.0001  max mem: 11902
[17:20:52.331552] Test:  [270/345]  eta: 0:00:06  loss: 0.1537 (0.1571)  time: 0.0884  data: 0.0001  max mem: 11902
[17:20:53.222000] Test:  [280/345]  eta: 0:00:05  loss: 0.1487 (0.1574)  time: 0.0888  data: 0.0001  max mem: 11902
[17:20:54.116138] Test:  [290/345]  eta: 0:00:04  loss: 0.1499 (0.1572)  time: 0.0892  data: 0.0001  max mem: 11902
[17:20:55.014325] Test:  [300/345]  eta: 0:00:03  loss: 0.1499 (0.1572)  time: 0.0896  data: 0.0001  max mem: 11902
[17:20:55.915810] Test:  [310/345]  eta: 0:00:03  loss: 0.1610 (0.1573)  time: 0.0899  data: 0.0001  max mem: 11902
[17:20:56.820084] Test:  [320/345]  eta: 0:00:02  loss: 0.1524 (0.1571)  time: 0.0902  data: 0.0001  max mem: 11902
[17:20:57.727526] Test:  [330/345]  eta: 0:00:01  loss: 0.1517 (0.1570)  time: 0.0905  data: 0.0001  max mem: 11902
[17:20:58.639435] Test:  [340/345]  eta: 0:00:00  loss: 0.1533 (0.1568)  time: 0.0909  data: 0.0001  max mem: 11902
[17:20:59.005223] Test:  [344/345]  eta: 0:00:00  loss: 0.1533 (0.1567)  time: 0.0911  data: 0.0001  max mem: 11902
[17:20:59.077709] Test: Total time: 0:00:29 (0.0866 s / it)
[17:21:09.005746] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4417 (0.4417)  time: 0.4138  data: 0.3366  max mem: 11902
[17:21:09.803649] Test:  [10/57]  eta: 0:00:05  loss: 0.4151 (0.4402)  time: 0.1101  data: 0.0315  max mem: 11902
[17:21:10.595775] Test:  [20/57]  eta: 0:00:03  loss: 0.4059 (0.4390)  time: 0.0794  data: 0.0006  max mem: 11902
[17:21:11.393475] Test:  [30/57]  eta: 0:00:02  loss: 0.2631 (0.3766)  time: 0.0794  data: 0.0001  max mem: 11902
[17:21:12.195671] Test:  [40/57]  eta: 0:00:01  loss: 0.2553 (0.3523)  time: 0.0799  data: 0.0001  max mem: 11902
[17:21:12.999172] Test:  [50/57]  eta: 0:00:00  loss: 0.2779 (0.3567)  time: 0.0802  data: 0.0001  max mem: 11902
[17:21:13.434959] Test:  [56/57]  eta: 0:00:00  loss: 0.3573 (0.3842)  time: 0.0780  data: 0.0000  max mem: 11902
[17:21:13.507700] Test: Total time: 0:00:04 (0.0863 s / it)
[17:21:15.261428] Dice score of the network on the train images: 0.856813, val images: 0.632040
[17:21:15.265128] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:21:15.850110] Epoch: [29]  [  0/345]  eta: 0:03:21  lr: 0.000099  loss: 0.1615 (0.1615)  time: 0.5839  data: 0.3382  max mem: 11902
[17:21:20.705825] Epoch: [29]  [ 20/345]  eta: 0:01:24  lr: 0.000099  loss: 0.1603 (0.1725)  time: 0.2427  data: 0.0001  max mem: 11902
[17:21:25.566795] Epoch: [29]  [ 40/345]  eta: 0:01:16  lr: 0.000099  loss: 0.1662 (0.1718)  time: 0.2430  data: 0.0001  max mem: 11902
[17:21:30.427897] Epoch: [29]  [ 60/345]  eta: 0:01:10  lr: 0.000098  loss: 0.1578 (0.1676)  time: 0.2430  data: 0.0001  max mem: 11902
[17:21:35.296850] Epoch: [29]  [ 80/345]  eta: 0:01:05  lr: 0.000098  loss: 0.1624 (0.1670)  time: 0.2434  data: 0.0001  max mem: 11902

[17:21:40.165120] Epoch: [29]  [100/345]  eta: 0:01:00  lr: 0.000098  loss: 0.1514 (0.1666)  time: 0.2434  data: 0.0001  max mem: 11902
[17:21:45.036454] Epoch: [29]  [120/345]  eta: 0:00:55  lr: 0.000097  loss: 0.1617 (0.1663)  time: 0.2435  data: 0.0001  max mem: 11902
[17:21:49.908393] Epoch: [29]  [140/345]  eta: 0:00:50  lr: 0.000097  loss: 0.1553 (0.1657)  time: 0.2436  data: 0.0001  max mem: 11902
[17:21:54.787314] Epoch: [29]  [160/345]  eta: 0:00:45  lr: 0.000097  loss: 0.1697 (0.1661)  time: 0.2439  data: 0.0001  max mem: 11902
[17:21:59.665846] Epoch: [29]  [180/345]  eta: 0:00:40  lr: 0.000096  loss: 0.1586 (0.1658)  time: 0.2439  data: 0.0001  max mem: 11902
[17:22:04.545505] Epoch: [29]  [200/345]  eta: 0:00:35  lr: 0.000096  loss: 0.1691 (0.1661)  time: 0.2439  data: 0.0001  max mem: 11902
[17:22:09.428010] Epoch: [29]  [220/345]  eta: 0:00:30  lr: 0.000096  loss: 0.1520 (0.1654)  time: 0.2441  data: 0.0001  max mem: 11902
[17:22:14.313644] Epoch: [29]  [240/345]  eta: 0:00:25  lr: 0.000095  loss: 0.1684 (0.1657)  time: 0.2442  data: 0.0001  max mem: 11902
[17:22:19.196811] Epoch: [29]  [260/345]  eta: 0:00:20  lr: 0.000095  loss: 0.1585 (0.1657)  time: 0.2441  data: 0.0001  max mem: 11902
[17:22:24.080445] Epoch: [29]  [280/345]  eta: 0:00:15  lr: 0.000095  loss: 0.1626 (0.1657)  time: 0.2441  data: 0.0001  max mem: 11902
[17:22:28.967377] Epoch: [29]  [300/345]  eta: 0:00:11  lr: 0.000094  loss: 0.1625 (0.1649)  time: 0.2443  data: 0.0001  max mem: 11902
[17:22:33.857632] Epoch: [29]  [320/345]  eta: 0:00:06  lr: 0.000094  loss: 0.1549 (0.1645)  time: 0.2445  data: 0.0001  max mem: 11902
[17:22:38.745488] Epoch: [29]  [340/345]  eta: 0:00:01  lr: 0.000094  loss: 0.1494 (0.1640)  time: 0.2443  data: 0.0001  max mem: 11902
[17:22:39.723736] Epoch: [29]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.1500 (0.1639)  time: 0.2443  data: 0.0001  max mem: 11902
[17:22:39.795696] Epoch: [29] Total time: 0:01:24 (0.2450 s / it)
[17:22:39.796033] Averaged stats: lr: 0.000094  loss: 0.1500 (0.1639)
[17:22:40.224778] Test:  [  0/345]  eta: 0:02:26  loss: 0.1161 (0.1161)  time: 0.4239  data: 0.3470  max mem: 11902
[17:22:41.036382] Test:  [ 10/345]  eta: 0:00:37  loss: 0.1491 (0.1486)  time: 0.1122  data: 0.0332  max mem: 11902
[17:22:41.836132] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1491 (0.1488)  time: 0.0805  data: 0.0010  max mem: 11902
[17:22:42.637611] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1495 (0.1496)  time: 0.0800  data: 0.0001  max mem: 11902
[17:22:43.443490] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1546 (0.1513)  time: 0.0803  data: 0.0001  max mem: 11902
[17:22:44.251425] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1468 (0.1506)  time: 0.0806  data: 0.0001  max mem: 11902
[17:22:45.062547] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1468 (0.1519)  time: 0.0809  data: 0.0001  max mem: 11902
[17:22:45.876296] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1509 (0.1527)  time: 0.0812  data: 0.0001  max mem: 11902
[17:22:46.694638] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1494 (0.1526)  time: 0.0815  data: 0.0001  max mem: 11902
[17:22:47.516386] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1531 (0.1537)  time: 0.0819  data: 0.0001  max mem: 11902
[17:22:48.341778] Test:  [100/345]  eta: 0:00:20  loss: 0.1500 (0.1526)  time: 0.0823  data: 0.0001  max mem: 11902
[17:22:49.171515] Test:  [110/345]  eta: 0:00:19  loss: 0.1412 (0.1528)  time: 0.0827  data: 0.0001  max mem: 11902
[17:22:50.004087] Test:  [120/345]  eta: 0:00:18  loss: 0.1492 (0.1527)  time: 0.0831  data: 0.0001  max mem: 11902
[17:22:50.839859] Test:  [130/345]  eta: 0:00:18  loss: 0.1416 (0.1516)  time: 0.0834  data: 0.0001  max mem: 11902
[17:22:51.680534] Test:  [140/345]  eta: 0:00:17  loss: 0.1457 (0.1522)  time: 0.0837  data: 0.0001  max mem: 11902
[17:22:52.525636] Test:  [150/345]  eta: 0:00:16  loss: 0.1613 (0.1525)  time: 0.0842  data: 0.0001  max mem: 11902
[17:22:53.373629] Test:  [160/345]  eta: 0:00:15  loss: 0.1508 (0.1523)  time: 0.0846  data: 0.0001  max mem: 11902
[17:22:54.224563] Test:  [170/345]  eta: 0:00:14  loss: 0.1475 (0.1521)  time: 0.0848  data: 0.0001  max mem: 11902
[17:22:55.079136] Test:  [180/345]  eta: 0:00:13  loss: 0.1527 (0.1526)  time: 0.0852  data: 0.0001  max mem: 11902
[17:22:55.937933] Test:  [190/345]  eta: 0:00:13  loss: 0.1529 (0.1527)  time: 0.0856  data: 0.0001  max mem: 11902
[17:22:56.800695] Test:  [200/345]  eta: 0:00:12  loss: 0.1456 (0.1522)  time: 0.0860  data: 0.0001  max mem: 11902
[17:22:57.667625] Test:  [210/345]  eta: 0:00:11  loss: 0.1400 (0.1517)  time: 0.0864  data: 0.0001  max mem: 11902
[17:22:58.537894] Test:  [220/345]  eta: 0:00:10  loss: 0.1456 (0.1523)  time: 0.0868  data: 0.0001  max mem: 11902
[17:22:59.410734] Test:  [230/345]  eta: 0:00:09  loss: 0.1576 (0.1525)  time: 0.0871  data: 0.0001  max mem: 11902
[17:23:00.287362] Test:  [240/345]  eta: 0:00:08  loss: 0.1501 (0.1523)  time: 0.0874  data: 0.0001  max mem: 11902
[17:23:01.167762] Test:  [250/345]  eta: 0:00:08  loss: 0.1419 (0.1522)  time: 0.0878  data: 0.0001  max mem: 11902
[17:23:02.050996] Test:  [260/345]  eta: 0:00:07  loss: 0.1471 (0.1519)  time: 0.0881  data: 0.0001  max mem: 11902
[17:23:02.937482] Test:  [270/345]  eta: 0:00:06  loss: 0.1477 (0.1521)  time: 0.0884  data: 0.0001  max mem: 11902
[17:23:03.827897] Test:  [280/345]  eta: 0:00:05  loss: 0.1571 (0.1525)  time: 0.0888  data: 0.0001  max mem: 11902
[17:23:04.720722] Test:  [290/345]  eta: 0:00:04  loss: 0.1571 (0.1529)  time: 0.0891  data: 0.0001  max mem: 11902
[17:23:05.617845] Test:  [300/345]  eta: 0:00:03  loss: 0.1567 (0.1529)  time: 0.0894  data: 0.0001  max mem: 11902
[17:23:06.518197] Test:  [310/345]  eta: 0:00:03  loss: 0.1526 (0.1529)  time: 0.0898  data: 0.0001  max mem: 11902
[17:23:07.422704] Test:  [320/345]  eta: 0:00:02  loss: 0.1526 (0.1530)  time: 0.0902  data: 0.0001  max mem: 11902
[17:23:08.331136] Test:  [330/345]  eta: 0:00:01  loss: 0.1520 (0.1529)  time: 0.0906  data: 0.0001  max mem: 11902
[17:23:09.241514] Test:  [340/345]  eta: 0:00:00  loss: 0.1556 (0.1532)  time: 0.0909  data: 0.0001  max mem: 11902
[17:23:09.607027] Test:  [344/345]  eta: 0:00:00  loss: 0.1540 (0.1532)  time: 0.0910  data: 0.0001  max mem: 11902
[17:23:09.682217] Test: Total time: 0:00:29 (0.0866 s / it)
[17:23:19.556137] Test:  [ 0/57]  eta: 0:00:22  loss: 0.4552 (0.4552)  time: 0.4025  data: 0.3254  max mem: 11902
[17:23:20.356056] Test:  [10/57]  eta: 0:00:05  loss: 0.4033 (0.4361)  time: 0.1092  data: 0.0306  max mem: 11902
[17:23:21.148653] Test:  [20/57]  eta: 0:00:03  loss: 0.4033 (0.4340)  time: 0.0795  data: 0.0006  max mem: 11902
[17:23:21.946799] Test:  [30/57]  eta: 0:00:02  loss: 0.2695 (0.3726)  time: 0.0795  data: 0.0001  max mem: 11902
[17:23:22.748651] Test:  [40/57]  eta: 0:00:01  loss: 0.2537 (0.3481)  time: 0.0799  data: 0.0001  max mem: 11902
[17:23:23.553925] Test:  [50/57]  eta: 0:00:00  loss: 0.2792 (0.3538)  time: 0.0803  data: 0.0001  max mem: 11902
[17:23:23.989779] Test:  [56/57]  eta: 0:00:00  loss: 0.3556 (0.3877)  time: 0.0781  data: 0.0000  max mem: 11902
[17:23:24.055282] Test: Total time: 0:00:04 (0.0860 s / it)
[17:23:25.797795] Dice score of the network on the train images: 0.855580, val images: 0.638830
[17:23:25.801143] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:23:26.443637] Epoch: [30]  [  0/345]  eta: 0:03:41  lr: 0.000094  loss: 0.1440 (0.1440)  time: 0.6416  data: 0.3951  max mem: 11902
[17:23:31.311357] Epoch: [30]  [ 20/345]  eta: 0:01:25  lr: 0.000093  loss: 0.1530 (0.1538)  time: 0.2433  data: 0.0001  max mem: 11902
[17:23:36.192780] Epoch: [30]  [ 40/345]  eta: 0:01:17  lr: 0.000093  loss: 0.1536 (0.1555)  time: 0.2440  data: 0.0001  max mem: 11902
[17:23:41.065094] Epoch: [30]  [ 60/345]  eta: 0:01:11  lr: 0.000093  loss: 0.1513 (0.1544)  time: 0.2436  data: 0.0001  max mem: 11902
[17:23:45.944416] Epoch: [30]  [ 80/345]  eta: 0:01:05  lr: 0.000092  loss: 0.1598 (0.1558)  time: 0.2439  data: 0.0001  max mem: 11902
[17:23:50.821093] Epoch: [30]  [100/345]  eta: 0:01:00  lr: 0.000092  loss: 0.1515 (0.1554)  time: 0.2438  data: 0.0001  max mem: 11902
[17:23:55.712497] Epoch: [30]  [120/345]  eta: 0:00:55  lr: 0.000092  loss: 0.1576 (0.1561)  time: 0.2445  data: 0.0001  max mem: 11902
[17:24:00.604572] Epoch: [30]  [140/345]  eta: 0:00:50  lr: 0.000091  loss: 0.1491 (0.1564)  time: 0.2446  data: 0.0001  max mem: 11902
[17:24:05.503177] Epoch: [30]  [160/345]  eta: 0:00:45  lr: 0.000091  loss: 0.1667 (0.1580)  time: 0.2449  data: 0.0001  max mem: 11902
[17:24:10.397857] Epoch: [30]  [180/345]  eta: 0:00:40  lr: 0.000091  loss: 0.1640 (0.1587)  time: 0.2447  data: 0.0001  max mem: 11902
[17:24:15.287260] Epoch: [30]  [200/345]  eta: 0:00:35  lr: 0.000090  loss: 0.1569 (0.1589)  time: 0.2444  data: 0.0001  max mem: 11902
[17:24:20.177568] Epoch: [30]  [220/345]  eta: 0:00:30  lr: 0.000090  loss: 0.1632 (0.1594)  time: 0.2445  data: 0.0001  max mem: 11902
[17:24:25.064616] Epoch: [30]  [240/345]  eta: 0:00:25  lr: 0.000090  loss: 0.1615 (0.1598)  time: 0.2443  data: 0.0001  max mem: 11902
[17:24:29.955841] Epoch: [30]  [260/345]  eta: 0:00:20  lr: 0.000089  loss: 0.1464 (0.1596)  time: 0.2445  data: 0.0001  max mem: 11902
[17:24:34.844317] Epoch: [30]  [280/345]  eta: 0:00:15  lr: 0.000089  loss: 0.1556 (0.1594)  time: 0.2444  data: 0.0001  max mem: 11902
[17:24:39.740114] Epoch: [30]  [300/345]  eta: 0:00:11  lr: 0.000089  loss: 0.1537 (0.1592)  time: 0.2448  data: 0.0001  max mem: 11902
[17:24:44.641857] Epoch: [30]  [320/345]  eta: 0:00:06  lr: 0.000088  loss: 0.1578 (0.1592)  time: 0.2450  data: 0.0001  max mem: 11902
[17:24:49.547563] Epoch: [30]  [340/345]  eta: 0:00:01  lr: 0.000088  loss: 0.1520 (0.1591)  time: 0.2452  data: 0.0001  max mem: 11902
[17:24:50.527769] Epoch: [30]  [344/345]  eta: 0:00:00  lr: 0.000088  loss: 0.1501 (0.1592)  time: 0.2450  data: 0.0001  max mem: 11902
[17:24:50.589174] Epoch: [30] Total time: 0:01:24 (0.2458 s / it)
[17:24:50.590055] Averaged stats: lr: 0.000088  loss: 0.1501 (0.1592)
[17:24:51.043847] Test:  [  0/345]  eta: 0:02:34  loss: 0.1519 (0.1519)  time: 0.4492  data: 0.3721  max mem: 11902
[17:24:51.840773] Test:  [ 10/345]  eta: 0:00:37  loss: 0.1566 (0.1525)  time: 0.1132  data: 0.0340  max mem: 11902
[17:24:52.640451] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1566 (0.1542)  time: 0.0797  data: 0.0001  max mem: 11902
[17:24:53.443456] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1499 (0.1534)  time: 0.0800  data: 0.0001  max mem: 11902
[17:24:54.247256] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1481 (0.1521)  time: 0.0803  data: 0.0001  max mem: 11902
[17:24:55.054991] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1487 (0.1517)  time: 0.0805  data: 0.0001  max mem: 11902
[17:24:55.867022] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1495 (0.1519)  time: 0.0809  data: 0.0001  max mem: 11902
[17:24:56.682500] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1495 (0.1522)  time: 0.0813  data: 0.0001  max mem: 11902
[17:24:57.500572] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1461 (0.1512)  time: 0.0816  data: 0.0001  max mem: 11902
[17:24:58.323216] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1450 (0.1512)  time: 0.0820  data: 0.0001  max mem: 11902
[17:24:59.149136] Test:  [100/345]  eta: 0:00:20  loss: 0.1391 (0.1502)  time: 0.0823  data: 0.0001  max mem: 11902
[17:24:59.978793] Test:  [110/345]  eta: 0:00:19  loss: 0.1383 (0.1503)  time: 0.0827  data: 0.0001  max mem: 11902
[17:25:00.812448] Test:  [120/345]  eta: 0:00:18  loss: 0.1589 (0.1516)  time: 0.0831  data: 0.0001  max mem: 11902
[17:25:01.650503] Test:  [130/345]  eta: 0:00:18  loss: 0.1572 (0.1518)  time: 0.0835  data: 0.0001  max mem: 11902
[17:25:02.490381] Test:  [140/345]  eta: 0:00:17  loss: 0.1442 (0.1508)  time: 0.0838  data: 0.0001  max mem: 11902
[17:25:03.333566] Test:  [150/345]  eta: 0:00:16  loss: 0.1411 (0.1505)  time: 0.0841  data: 0.0001  max mem: 11902
[17:25:04.181119] Test:  [160/345]  eta: 0:00:15  loss: 0.1527 (0.1507)  time: 0.0845  data: 0.0001  max mem: 11902
[17:25:05.032371] Test:  [170/345]  eta: 0:00:14  loss: 0.1545 (0.1511)  time: 0.0849  data: 0.0001  max mem: 11902
[17:25:05.887234] Test:  [180/345]  eta: 0:00:13  loss: 0.1495 (0.1507)  time: 0.0852  data: 0.0001  max mem: 11902
[17:25:06.744765] Test:  [190/345]  eta: 0:00:13  loss: 0.1463 (0.1504)  time: 0.0855  data: 0.0001  max mem: 11902
[17:25:07.606974] Test:  [200/345]  eta: 0:00:12  loss: 0.1467 (0.1505)  time: 0.0859  data: 0.0001  max mem: 11902
[17:25:08.473053] Test:  [210/345]  eta: 0:00:11  loss: 0.1467 (0.1505)  time: 0.0863  data: 0.0001  max mem: 11902
[17:25:09.343293] Test:  [220/345]  eta: 0:00:10  loss: 0.1469 (0.1503)  time: 0.0867  data: 0.0001  max mem: 11902
[17:25:10.216988] Test:  [230/345]  eta: 0:00:09  loss: 0.1469 (0.1502)  time: 0.0871  data: 0.0001  max mem: 11902
[17:25:11.092075] Test:  [240/345]  eta: 0:00:08  loss: 0.1385 (0.1498)  time: 0.0874  data: 0.0001  max mem: 11902
[17:25:11.971317] Test:  [250/345]  eta: 0:00:08  loss: 0.1415 (0.1499)  time: 0.0876  data: 0.0001  max mem: 11902
[17:25:12.853937] Test:  [260/345]  eta: 0:00:07  loss: 0.1430 (0.1496)  time: 0.0880  data: 0.0001  max mem: 11902
[17:25:13.740039] Test:  [270/345]  eta: 0:00:06  loss: 0.1429 (0.1496)  time: 0.0884  data: 0.0001  max mem: 11902
[17:25:14.630878] Test:  [280/345]  eta: 0:00:05  loss: 0.1376 (0.1492)  time: 0.0888  data: 0.0001  max mem: 11902
[17:25:15.525049] Test:  [290/345]  eta: 0:00:04  loss: 0.1388 (0.1493)  time: 0.0892  data: 0.0001  max mem: 11902
[17:25:16.421974] Test:  [300/345]  eta: 0:00:03  loss: 0.1470 (0.1493)  time: 0.0895  data: 0.0001  max mem: 11902
[17:25:17.323357] Test:  [310/345]  eta: 0:00:03  loss: 0.1475 (0.1493)  time: 0.0899  data: 0.0001  max mem: 11902
[17:25:18.226797] Test:  [320/345]  eta: 0:00:02  loss: 0.1516 (0.1493)  time: 0.0902  data: 0.0001  max mem: 11902
[17:25:19.134605] Test:  [330/345]  eta: 0:00:01  loss: 0.1492 (0.1493)  time: 0.0905  data: 0.0001  max mem: 11902
[17:25:20.045635] Test:  [340/345]  eta: 0:00:00  loss: 0.1501 (0.1495)  time: 0.0909  data: 0.0001  max mem: 11902
[17:25:20.410470] Test:  [344/345]  eta: 0:00:00  loss: 0.1501 (0.1495)  time: 0.0910  data: 0.0001  max mem: 11902
[17:25:20.485657] Test: Total time: 0:00:29 (0.0866 s / it)
[17:25:30.376479] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4766 (0.4766)  time: 0.4074  data: 0.3302  max mem: 11902
[17:25:31.170681] Test:  [10/57]  eta: 0:00:05  loss: 0.4296 (0.4358)  time: 0.1092  data: 0.0308  max mem: 11902
[17:25:31.963788] Test:  [20/57]  eta: 0:00:03  loss: 0.4186 (0.4295)  time: 0.0793  data: 0.0005  max mem: 11902
[17:25:32.758400] Test:  [30/57]  eta: 0:00:02  loss: 0.2655 (0.3724)  time: 0.0793  data: 0.0001  max mem: 11902
[17:25:33.558103] Test:  [40/57]  eta: 0:00:01  loss: 0.2672 (0.3557)  time: 0.0797  data: 0.0001  max mem: 11902
[17:25:34.360349] Test:  [50/57]  eta: 0:00:00  loss: 0.3135 (0.3653)  time: 0.0800  data: 0.0001  max mem: 11902
[17:25:34.796533] Test:  [56/57]  eta: 0:00:00  loss: 0.3889 (0.3919)  time: 0.0779  data: 0.0000  max mem: 11902
[17:25:34.862081] Test: Total time: 0:00:04 (0.0859 s / it)
[17:25:36.586008] Dice score of the network on the train images: 0.862257, val images: 0.713118
[17:25:36.589787] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:25:37.189954] Epoch: [31]  [  0/345]  eta: 0:03:26  lr: 0.000088  loss: 0.1642 (0.1642)  time: 0.5991  data: 0.3549  max mem: 11902
[17:25:42.050438] Epoch: [31]  [ 20/345]  eta: 0:01:24  lr: 0.000088  loss: 0.1557 (0.1550)  time: 0.2430  data: 0.0001  max mem: 11902
[17:25:46.919769] Epoch: [31]  [ 40/345]  eta: 0:01:16  lr: 0.000087  loss: 0.1561 (0.1551)  time: 0.2434  data: 0.0001  max mem: 11902
[17:25:51.785221] Epoch: [31]  [ 60/345]  eta: 0:01:10  lr: 0.000087  loss: 0.1515 (0.1542)  time: 0.2432  data: 0.0001  max mem: 11902
[17:25:56.654050] Epoch: [31]  [ 80/345]  eta: 0:01:05  lr: 0.000087  loss: 0.1461 (0.1540)  time: 0.2434  data: 0.0001  max mem: 11902
[17:26:01.526747] Epoch: [31]  [100/345]  eta: 0:01:00  lr: 0.000086  loss: 0.1501 (0.1535)  time: 0.2436  data: 0.0001  max mem: 11902
[17:26:06.402768] Epoch: [31]  [120/345]  eta: 0:00:55  lr: 0.000086  loss: 0.1404 (0.1517)  time: 0.2438  data: 0.0001  max mem: 11902
[17:26:11.291678] Epoch: [31]  [140/345]  eta: 0:00:50  lr: 0.000085  loss: 0.1512 (0.1520)  time: 0.2444  data: 0.0001  max mem: 11902
[17:26:16.173332] Epoch: [31]  [160/345]  eta: 0:00:45  lr: 0.000085  loss: 0.1521 (0.1517)  time: 0.2440  data: 0.0001  max mem: 11902
[17:26:21.056899] Epoch: [31]  [180/345]  eta: 0:00:40  lr: 0.000085  loss: 0.1536 (0.1522)  time: 0.2441  data: 0.0001  max mem: 11902
[17:26:25.936552] Epoch: [31]  [200/345]  eta: 0:00:35  lr: 0.000084  loss: 0.1412 (0.1520)  time: 0.2439  data: 0.0001  max mem: 11902
[17:26:30.821534] Epoch: [31]  [220/345]  eta: 0:00:30  lr: 0.000084  loss: 0.1581 (0.1531)  time: 0.2442  data: 0.0001  max mem: 11902
[17:26:35.709879] Epoch: [31]  [240/345]  eta: 0:00:25  lr: 0.000084  loss: 0.1507 (0.1531)  time: 0.2444  data: 0.0001  max mem: 11902
[17:26:40.599143] Epoch: [31]  [260/345]  eta: 0:00:20  lr: 0.000083  loss: 0.1643 (0.1539)  time: 0.2444  data: 0.0001  max mem: 11902
[17:26:45.488684] Epoch: [31]  [280/345]  eta: 0:00:15  lr: 0.000083  loss: 0.1564 (0.1541)  time: 0.2444  data: 0.0001  max mem: 11902
[17:26:50.378998] Epoch: [31]  [300/345]  eta: 0:00:11  lr: 0.000083  loss: 0.1528 (0.1542)  time: 0.2445  data: 0.0001  max mem: 11902
[17:26:55.273089] Epoch: [31]  [320/345]  eta: 0:00:06  lr: 0.000082  loss: 0.1458 (0.1540)  time: 0.2447  data: 0.0001  max mem: 11902
[17:27:00.162303] Epoch: [31]  [340/345]  eta: 0:00:01  lr: 0.000082  loss: 0.1477 (0.1542)  time: 0.2444  data: 0.0001  max mem: 11902
[17:27:01.141154] Epoch: [31]  [344/345]  eta: 0:00:00  lr: 0.000082  loss: 0.1575 (0.1543)  time: 0.2444  data: 0.0001  max mem: 11902
[17:27:01.212882] Epoch: [31] Total time: 0:01:24 (0.2453 s / it)
[17:27:01.213065] Averaged stats: lr: 0.000082  loss: 0.1575 (0.1543)
[17:27:01.649674] Test:  [  0/345]  eta: 0:02:29  loss: 0.1432 (0.1432)  time: 0.4322  data: 0.3547  max mem: 11902
[17:27:02.452061] Test:  [ 10/345]  eta: 0:00:37  loss: 0.1362 (0.1391)  time: 0.1121  data: 0.0331  max mem: 11902
[17:27:03.250747] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1383 (0.1462)  time: 0.0800  data: 0.0005  max mem: 11902
[17:27:04.052866] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1372 (0.1431)  time: 0.0799  data: 0.0001  max mem: 11902
[17:27:04.857656] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1362 (0.1428)  time: 0.0803  data: 0.0001  max mem: 11902
[17:27:05.666035] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1376 (0.1418)  time: 0.0806  data: 0.0001  max mem: 11902
[17:27:06.477813] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1385 (0.1419)  time: 0.0809  data: 0.0001  max mem: 11902
[17:27:07.292269] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1350 (0.1413)  time: 0.0812  data: 0.0001  max mem: 11902
[17:27:08.110661] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1371 (0.1429)  time: 0.0816  data: 0.0001  max mem: 11902
[17:27:08.933773] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1484 (0.1434)  time: 0.0820  data: 0.0001  max mem: 11902
[17:27:09.760527] Test:  [100/345]  eta: 0:00:20  loss: 0.1459 (0.1441)  time: 0.0824  data: 0.0001  max mem: 11902
[17:27:10.590528] Test:  [110/345]  eta: 0:00:19  loss: 0.1489 (0.1449)  time: 0.0827  data: 0.0001  max mem: 11902
[17:27:11.423233] Test:  [120/345]  eta: 0:00:18  loss: 0.1534 (0.1458)  time: 0.0831  data: 0.0001  max mem: 11902
[17:27:12.260052] Test:  [130/345]  eta: 0:00:18  loss: 0.1521 (0.1460)  time: 0.0834  data: 0.0001  max mem: 11902
[17:27:13.100190] Test:  [140/345]  eta: 0:00:17  loss: 0.1442 (0.1460)  time: 0.0838  data: 0.0001  max mem: 11902
[17:27:13.944059] Test:  [150/345]  eta: 0:00:16  loss: 0.1396 (0.1457)  time: 0.0841  data: 0.0001  max mem: 11902
[17:27:14.791241] Test:  [160/345]  eta: 0:00:15  loss: 0.1343 (0.1450)  time: 0.0845  data: 0.0001  max mem: 11902
[17:27:15.643097] Test:  [170/345]  eta: 0:00:14  loss: 0.1385 (0.1453)  time: 0.0849  data: 0.0001  max mem: 11902
[17:27:16.498105] Test:  [180/345]  eta: 0:00:13  loss: 0.1385 (0.1449)  time: 0.0853  data: 0.0001  max mem: 11902
[17:27:17.357112] Test:  [190/345]  eta: 0:00:13  loss: 0.1387 (0.1448)  time: 0.0856  data: 0.0001  max mem: 11902
[17:27:18.219580] Test:  [200/345]  eta: 0:00:12  loss: 0.1387 (0.1447)  time: 0.0860  data: 0.0001  max mem: 11902
[17:27:19.085355] Test:  [210/345]  eta: 0:00:11  loss: 0.1389 (0.1446)  time: 0.0863  data: 0.0001  max mem: 11902
[17:27:19.954087] Test:  [220/345]  eta: 0:00:10  loss: 0.1389 (0.1445)  time: 0.0866  data: 0.0001  max mem: 11902
[17:27:20.827609] Test:  [230/345]  eta: 0:00:09  loss: 0.1395 (0.1447)  time: 0.0870  data: 0.0001  max mem: 11902
[17:27:21.702930] Test:  [240/345]  eta: 0:00:08  loss: 0.1463 (0.1447)  time: 0.0874  data: 0.0001  max mem: 11902
[17:27:22.583614] Test:  [250/345]  eta: 0:00:08  loss: 0.1348 (0.1446)  time: 0.0877  data: 0.0001  max mem: 11902
[17:27:23.467103] Test:  [260/345]  eta: 0:00:07  loss: 0.1384 (0.1444)  time: 0.0881  data: 0.0001  max mem: 11902
[17:27:24.354392] Test:  [270/345]  eta: 0:00:06  loss: 0.1385 (0.1441)  time: 0.0884  data: 0.0001  max mem: 11902
[17:27:25.244644] Test:  [280/345]  eta: 0:00:05  loss: 0.1376 (0.1438)  time: 0.0888  data: 0.0001  max mem: 11902
[17:27:26.138170] Test:  [290/345]  eta: 0:00:04  loss: 0.1413 (0.1440)  time: 0.0891  data: 0.0001  max mem: 11902
[17:27:27.034771] Test:  [300/345]  eta: 0:00:03  loss: 0.1491 (0.1443)  time: 0.0894  data: 0.0001  max mem: 11902
[17:27:27.935761] Test:  [310/345]  eta: 0:00:03  loss: 0.1429 (0.1442)  time: 0.0898  data: 0.0001  max mem: 11902
[17:27:28.839245] Test:  [320/345]  eta: 0:00:02  loss: 0.1457 (0.1444)  time: 0.0901  data: 0.0001  max mem: 11902
[17:27:29.747179] Test:  [330/345]  eta: 0:00:01  loss: 0.1389 (0.1442)  time: 0.0905  data: 0.0001  max mem: 11902
[17:27:30.658742] Test:  [340/345]  eta: 0:00:00  loss: 0.1374 (0.1441)  time: 0.0909  data: 0.0001  max mem: 11902
[17:27:31.025023] Test:  [344/345]  eta: 0:00:00  loss: 0.1386 (0.1441)  time: 0.0911  data: 0.0001  max mem: 11902
[17:27:31.095548] Test: Total time: 0:00:29 (0.0866 s / it)
[17:27:41.111774] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4505 (0.4505)  time: 0.4553  data: 0.3781  max mem: 11902
[17:27:41.899950] Test:  [10/57]  eta: 0:00:05  loss: 0.4190 (0.4349)  time: 0.1130  data: 0.0345  max mem: 11902
[17:27:42.691855] Test:  [20/57]  eta: 0:00:03  loss: 0.3974 (0.4267)  time: 0.0789  data: 0.0001  max mem: 11902
[17:27:43.487221] Test:  [30/57]  eta: 0:00:02  loss: 0.2660 (0.3685)  time: 0.0793  data: 0.0001  max mem: 11902
[17:27:44.288698] Test:  [40/57]  eta: 0:00:01  loss: 0.2631 (0.3480)  time: 0.0798  data: 0.0001  max mem: 11902
[17:27:45.091584] Test:  [50/57]  eta: 0:00:00  loss: 0.3029 (0.3558)  time: 0.0802  data: 0.0001  max mem: 11902
[17:27:45.527583] Test:  [56/57]  eta: 0:00:00  loss: 0.3417 (0.3918)  time: 0.0779  data: 0.0000  max mem: 11902
[17:27:45.599835] Test: Total time: 0:00:04 (0.0867 s / it)
[17:27:47.328914] Dice score of the network on the train images: 0.860644, val images: 0.702610
[17:27:47.332414] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:27:47.919032] Epoch: [32]  [  0/345]  eta: 0:03:22  lr: 0.000082  loss: 0.1760 (0.1760)  time: 0.5858  data: 0.3399  max mem: 11902
[17:27:52.773138] Epoch: [32]  [ 20/345]  eta: 0:01:24  lr: 0.000081  loss: 0.1455 (0.1514)  time: 0.2427  data: 0.0001  max mem: 11902
[17:27:57.640421] Epoch: [32]  [ 40/345]  eta: 0:01:16  lr: 0.000081  loss: 0.1476 (0.1504)  time: 0.2433  data: 0.0001  max mem: 11902
[17:28:02.584233] Epoch: [32]  [ 60/345]  eta: 0:01:11  lr: 0.000081  loss: 0.1438 (0.1501)  time: 0.2472  data: 0.0001  max mem: 11902
[17:28:07.455392] Epoch: [32]  [ 80/345]  eta: 0:01:05  lr: 0.000080  loss: 0.1424 (0.1499)  time: 0.2435  data: 0.0001  max mem: 11902
[17:28:12.342461] Epoch: [32]  [100/345]  eta: 0:01:00  lr: 0.000080  loss: 0.1454 (0.1502)  time: 0.2443  data: 0.0001  max mem: 11902
[17:28:17.233260] Epoch: [32]  [120/345]  eta: 0:00:55  lr: 0.000080  loss: 0.1402 (0.1487)  time: 0.2445  data: 0.0001  max mem: 11902
[17:28:22.121534] Epoch: [32]  [140/345]  eta: 0:00:50  lr: 0.000079  loss: 0.1462 (0.1490)  time: 0.2444  data: 0.0001  max mem: 11902
[17:28:27.010874] Epoch: [32]  [160/345]  eta: 0:00:45  lr: 0.000079  loss: 0.1613 (0.1506)  time: 0.2444  data: 0.0001  max mem: 11902
[17:28:31.901273] Epoch: [32]  [180/345]  eta: 0:00:40  lr: 0.000079  loss: 0.1417 (0.1498)  time: 0.2445  data: 0.0001  max mem: 11902
[17:28:36.798811] Epoch: [32]  [200/345]  eta: 0:00:35  lr: 0.000078  loss: 0.1512 (0.1509)  time: 0.2448  data: 0.0001  max mem: 11902
[17:28:41.697703] Epoch: [32]  [220/345]  eta: 0:00:30  lr: 0.000078  loss: 0.1451 (0.1508)  time: 0.2449  data: 0.0001  max mem: 11902
[17:28:46.596943] Epoch: [32]  [240/345]  eta: 0:00:25  lr: 0.000077  loss: 0.1514 (0.1508)  time: 0.2449  data: 0.0001  max mem: 11902
[17:28:51.496858] Epoch: [32]  [260/345]  eta: 0:00:20  lr: 0.000077  loss: 0.1452 (0.1506)  time: 0.2449  data: 0.0001  max mem: 11902
[17:28:56.401331] Epoch: [32]  [280/345]  eta: 0:00:15  lr: 0.000077  loss: 0.1506 (0.1507)  time: 0.2452  data: 0.0001  max mem: 11902
[17:29:01.302063] Epoch: [32]  [300/345]  eta: 0:00:11  lr: 0.000076  loss: 0.1512 (0.1509)  time: 0.2450  data: 0.0001  max mem: 11902
[17:29:06.209097] Epoch: [32]  [320/345]  eta: 0:00:06  lr: 0.000076  loss: 0.1435 (0.1510)  time: 0.2453  data: 0.0001  max mem: 11902
[17:29:11.111551] Epoch: [32]  [340/345]  eta: 0:00:01  lr: 0.000076  loss: 0.1380 (0.1506)  time: 0.2451  data: 0.0001  max mem: 11902
[17:29:12.090687] Epoch: [32]  [344/345]  eta: 0:00:00  lr: 0.000076  loss: 0.1380 (0.1509)  time: 0.2450  data: 0.0001  max mem: 11902
[17:29:12.166509] Epoch: [32] Total time: 0:01:24 (0.2459 s / it)
[17:29:12.166749] Averaged stats: lr: 0.000076  loss: 0.1380 (0.1509)
[17:29:12.626656] Test:  [  0/345]  eta: 0:02:37  loss: 0.1729 (0.1729)  time: 0.4558  data: 0.3785  max mem: 11902
[17:29:13.419912] Test:  [ 10/345]  eta: 0:00:38  loss: 0.1498 (0.1451)  time: 0.1134  data: 0.0345  max mem: 11902
[17:29:14.218762] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1345 (0.1430)  time: 0.0795  data: 0.0001  max mem: 11902
[17:29:15.020290] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1345 (0.1409)  time: 0.0799  data: 0.0001  max mem: 11902
[17:29:15.823607] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1423 (0.1423)  time: 0.0802  data: 0.0001  max mem: 11902
[17:29:16.630838] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1423 (0.1410)  time: 0.0804  data: 0.0001  max mem: 11902
[17:29:17.443465] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1410 (0.1414)  time: 0.0809  data: 0.0001  max mem: 11902
[17:29:18.259022] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1336 (0.1410)  time: 0.0813  data: 0.0001  max mem: 11902
[17:29:19.076894] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1379 (0.1423)  time: 0.0816  data: 0.0001  max mem: 11902
[17:29:19.899537] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1411 (0.1415)  time: 0.0819  data: 0.0001  max mem: 11902
[17:29:20.725483] Test:  [100/345]  eta: 0:00:20  loss: 0.1277 (0.1411)  time: 0.0823  data: 0.0001  max mem: 11902
[17:29:21.554872] Test:  [110/345]  eta: 0:00:19  loss: 0.1403 (0.1411)  time: 0.0827  data: 0.0001  max mem: 11902
[17:29:22.386666] Test:  [120/345]  eta: 0:00:18  loss: 0.1382 (0.1405)  time: 0.0830  data: 0.0001  max mem: 11902
[17:29:23.223177] Test:  [130/345]  eta: 0:00:18  loss: 0.1302 (0.1405)  time: 0.0833  data: 0.0001  max mem: 11902
[17:29:24.064587] Test:  [140/345]  eta: 0:00:17  loss: 0.1415 (0.1411)  time: 0.0838  data: 0.0001  max mem: 11902
[17:29:24.907438] Test:  [150/345]  eta: 0:00:16  loss: 0.1422 (0.1408)  time: 0.0841  data: 0.0001  max mem: 11902
[17:29:25.754944] Test:  [160/345]  eta: 0:00:15  loss: 0.1397 (0.1410)  time: 0.0844  data: 0.0001  max mem: 11902
[17:29:26.605275] Test:  [170/345]  eta: 0:00:14  loss: 0.1382 (0.1411)  time: 0.0848  data: 0.0001  max mem: 11902
[17:29:27.459664] Test:  [180/345]  eta: 0:00:13  loss: 0.1371 (0.1409)  time: 0.0852  data: 0.0001  max mem: 11902
[17:29:28.317357] Test:  [190/345]  eta: 0:00:13  loss: 0.1386 (0.1414)  time: 0.0855  data: 0.0001  max mem: 11902
[17:29:29.179709] Test:  [200/345]  eta: 0:00:12  loss: 0.1395 (0.1417)  time: 0.0859  data: 0.0001  max mem: 11902
[17:29:30.045354] Test:  [210/345]  eta: 0:00:11  loss: 0.1420 (0.1419)  time: 0.0863  data: 0.0001  max mem: 11902
[17:29:30.915175] Test:  [220/345]  eta: 0:00:10  loss: 0.1489 (0.1421)  time: 0.0867  data: 0.0001  max mem: 11902
[17:29:31.787578] Test:  [230/345]  eta: 0:00:09  loss: 0.1430 (0.1419)  time: 0.0870  data: 0.0001  max mem: 11902
[17:29:32.663911] Test:  [240/345]  eta: 0:00:08  loss: 0.1374 (0.1419)  time: 0.0874  data: 0.0001  max mem: 11902
[17:29:33.544541] Test:  [250/345]  eta: 0:00:08  loss: 0.1378 (0.1420)  time: 0.0878  data: 0.0001  max mem: 11902
[17:29:34.427366] Test:  [260/345]  eta: 0:00:07  loss: 0.1389 (0.1421)  time: 0.0881  data: 0.0001  max mem: 11902
[17:29:35.313893] Test:  [270/345]  eta: 0:00:06  loss: 0.1370 (0.1419)  time: 0.0884  data: 0.0001  max mem: 11902
[17:29:36.205358] Test:  [280/345]  eta: 0:00:05  loss: 0.1332 (0.1420)  time: 0.0888  data: 0.0001  max mem: 11902
[17:29:37.099739] Test:  [290/345]  eta: 0:00:04  loss: 0.1368 (0.1419)  time: 0.0892  data: 0.0001  max mem: 11902
[17:29:37.998587] Test:  [300/345]  eta: 0:00:03  loss: 0.1368 (0.1419)  time: 0.0896  data: 0.0001  max mem: 11902
[17:29:38.900772] Test:  [310/345]  eta: 0:00:03  loss: 0.1365 (0.1420)  time: 0.0900  data: 0.0001  max mem: 11902
[17:29:39.806272] Test:  [320/345]  eta: 0:00:02  loss: 0.1330 (0.1417)  time: 0.0903  data: 0.0001  max mem: 11902
[17:29:40.713335] Test:  [330/345]  eta: 0:00:01  loss: 0.1330 (0.1417)  time: 0.0906  data: 0.0001  max mem: 11902
[17:29:41.624299] Test:  [340/345]  eta: 0:00:00  loss: 0.1365 (0.1419)  time: 0.0908  data: 0.0001  max mem: 11902
[17:29:41.990040] Test:  [344/345]  eta: 0:00:00  loss: 0.1365 (0.1418)  time: 0.0910  data: 0.0001  max mem: 11902
[17:29:42.061203] Test: Total time: 0:00:29 (0.0866 s / it)
[17:29:51.999536] Test:  [ 0/57]  eta: 0:00:22  loss: 0.4628 (0.4628)  time: 0.4012  data: 0.3244  max mem: 11902
[17:29:52.795884] Test:  [10/57]  eta: 0:00:05  loss: 0.4299 (0.4519)  time: 0.1088  data: 0.0302  max mem: 11902
[17:29:53.587851] Test:  [20/57]  eta: 0:00:03  loss: 0.4299 (0.4429)  time: 0.0793  data: 0.0005  max mem: 11902
[17:29:54.385457] Test:  [30/57]  eta: 0:00:02  loss: 0.2819 (0.3814)  time: 0.0794  data: 0.0001  max mem: 11902
[17:29:55.186628] Test:  [40/57]  eta: 0:00:01  loss: 0.2748 (0.3599)  time: 0.0799  data: 0.0001  max mem: 11902
[17:29:55.989113] Test:  [50/57]  eta: 0:00:00  loss: 0.3071 (0.3654)  time: 0.0801  data: 0.0001  max mem: 11902
[17:29:56.424897] Test:  [56/57]  eta: 0:00:00  loss: 0.3631 (0.3965)  time: 0.0779  data: 0.0001  max mem: 11902
[17:29:56.495928] Test: Total time: 0:00:04 (0.0859 s / it)
[17:29:58.239830] Dice score of the network on the train images: 0.869590, val images: 0.727485
[17:29:58.243488] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:29:58.848254] Epoch: [33]  [  0/345]  eta: 0:03:28  lr: 0.000075  loss: 0.1303 (0.1303)  time: 0.6037  data: 0.3592  max mem: 11902
[17:30:03.709043] Epoch: [33]  [ 20/345]  eta: 0:01:24  lr: 0.000075  loss: 0.1500 (0.1510)  time: 0.2430  data: 0.0001  max mem: 11902
[17:30:08.570757] Epoch: [33]  [ 40/345]  eta: 0:01:16  lr: 0.000075  loss: 0.1464 (0.1507)  time: 0.2430  data: 0.0001  max mem: 11902
[17:30:13.447025] Epoch: [33]  [ 60/345]  eta: 0:01:11  lr: 0.000074  loss: 0.1405 (0.1481)  time: 0.2438  data: 0.0001  max mem: 11902
[17:30:18.332453] Epoch: [33]  [ 80/345]  eta: 0:01:05  lr: 0.000074  loss: 0.1539 (0.1487)  time: 0.2442  data: 0.0001  max mem: 11902
[17:30:23.216937] Epoch: [33]  [100/345]  eta: 0:01:00  lr: 0.000074  loss: 0.1445 (0.1494)  time: 0.2442  data: 0.0001  max mem: 11902
[17:30:28.107365] Epoch: [33]  [120/345]  eta: 0:00:55  lr: 0.000073  loss: 0.1503 (0.1498)  time: 0.2445  data: 0.0001  max mem: 11902
[17:30:33.000503] Epoch: [33]  [140/345]  eta: 0:00:50  lr: 0.000073  loss: 0.1415 (0.1491)  time: 0.2446  data: 0.0001  max mem: 11902
[17:30:37.895884] Epoch: [33]  [160/345]  eta: 0:00:45  lr: 0.000073  loss: 0.1388 (0.1485)  time: 0.2447  data: 0.0001  max mem: 11902
[17:30:42.793223] Epoch: [33]  [180/345]  eta: 0:00:40  lr: 0.000072  loss: 0.1411 (0.1482)  time: 0.2448  data: 0.0001  max mem: 11902
[17:30:47.694058] Epoch: [33]  [200/345]  eta: 0:00:35  lr: 0.000072  loss: 0.1602 (0.1492)  time: 0.2450  data: 0.0001  max mem: 11902
[17:30:52.578170] Epoch: [33]  [220/345]  eta: 0:00:30  lr: 0.000071  loss: 0.1451 (0.1491)  time: 0.2442  data: 0.0001  max mem: 11902
[17:30:57.473087] Epoch: [33]  [240/345]  eta: 0:00:25  lr: 0.000071  loss: 0.1455 (0.1492)  time: 0.2447  data: 0.0001  max mem: 11902
[17:31:02.373174] Epoch: [33]  [260/345]  eta: 0:00:20  lr: 0.000071  loss: 0.1381 (0.1488)  time: 0.2450  data: 0.0001  max mem: 11902
[17:31:07.281075] Epoch: [33]  [280/345]  eta: 0:00:15  lr: 0.000070  loss: 0.1435 (0.1486)  time: 0.2453  data: 0.0001  max mem: 11902
[17:31:12.191194] Epoch: [33]  [300/345]  eta: 0:00:11  lr: 0.000070  loss: 0.1404 (0.1483)  time: 0.2455  data: 0.0001  max mem: 11902
[17:31:17.099840] Epoch: [33]  [320/345]  eta: 0:00:06  lr: 0.000070  loss: 0.1378 (0.1481)  time: 0.2454  data: 0.0001  max mem: 11902
[17:31:22.002526] Epoch: [33]  [340/345]  eta: 0:00:01  lr: 0.000069  loss: 0.1489 (0.1481)  time: 0.2451  data: 0.0001  max mem: 11902
[17:31:22.980917] Epoch: [33]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.1489 (0.1479)  time: 0.2449  data: 0.0001  max mem: 11902
[17:31:23.050635] Epoch: [33] Total time: 0:01:24 (0.2458 s / it)
[17:31:23.051101] Averaged stats: lr: 0.000069  loss: 0.1489 (0.1479)
[17:31:23.500854] Test:  [  0/345]  eta: 0:02:33  loss: 0.1212 (0.1212)  time: 0.4448  data: 0.3674  max mem: 11902
[17:31:24.295226] Test:  [ 10/345]  eta: 0:00:37  loss: 0.1456 (0.1414)  time: 0.1125  data: 0.0335  max mem: 11902
[17:31:25.094946] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1393 (0.1378)  time: 0.0796  data: 0.0001  max mem: 11902
[17:31:25.897539] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1387 (0.1396)  time: 0.0800  data: 0.0001  max mem: 11902
[17:31:26.701375] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1387 (0.1402)  time: 0.0802  data: 0.0001  max mem: 11902
[17:31:27.510172] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1441 (0.1413)  time: 0.0805  data: 0.0001  max mem: 11902
[17:31:28.321692] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1423 (0.1409)  time: 0.0810  data: 0.0001  max mem: 11902
[17:31:29.137733] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1377 (0.1409)  time: 0.0813  data: 0.0001  max mem: 11902
[17:31:29.956374] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1318 (0.1397)  time: 0.0816  data: 0.0001  max mem: 11902
[17:31:30.778852] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1331 (0.1410)  time: 0.0820  data: 0.0001  max mem: 11902
[17:31:31.604209] Test:  [100/345]  eta: 0:00:20  loss: 0.1375 (0.1407)  time: 0.0823  data: 0.0001  max mem: 11902
[17:31:32.433983] Test:  [110/345]  eta: 0:00:19  loss: 0.1328 (0.1402)  time: 0.0827  data: 0.0001  max mem: 11902
[17:31:33.267647] Test:  [120/345]  eta: 0:00:18  loss: 0.1372 (0.1402)  time: 0.0831  data: 0.0001  max mem: 11902
[17:31:34.103880] Test:  [130/345]  eta: 0:00:18  loss: 0.1374 (0.1399)  time: 0.0834  data: 0.0001  max mem: 11902
[17:31:34.944059] Test:  [140/345]  eta: 0:00:17  loss: 0.1290 (0.1398)  time: 0.0838  data: 0.0001  max mem: 11902
[17:31:35.788438] Test:  [150/345]  eta: 0:00:16  loss: 0.1303 (0.1394)  time: 0.0841  data: 0.0001  max mem: 11902
[17:31:36.636680] Test:  [160/345]  eta: 0:00:15  loss: 0.1306 (0.1392)  time: 0.0845  data: 0.0001  max mem: 11902
[17:31:37.488730] Test:  [170/345]  eta: 0:00:14  loss: 0.1353 (0.1397)  time: 0.0849  data: 0.0001  max mem: 11902
[17:31:38.343116] Test:  [180/345]  eta: 0:00:13  loss: 0.1368 (0.1395)  time: 0.0852  data: 0.0001  max mem: 11902
[17:31:39.200633] Test:  [190/345]  eta: 0:00:13  loss: 0.1368 (0.1396)  time: 0.0855  data: 0.0001  max mem: 11902
[17:31:40.062825] Test:  [200/345]  eta: 0:00:12  loss: 0.1368 (0.1394)  time: 0.0859  data: 0.0001  max mem: 11902
[17:31:40.927403] Test:  [210/345]  eta: 0:00:11  loss: 0.1333 (0.1394)  time: 0.0862  data: 0.0001  max mem: 11902
[17:31:41.797672] Test:  [220/345]  eta: 0:00:10  loss: 0.1333 (0.1390)  time: 0.0867  data: 0.0001  max mem: 11902
[17:31:42.669841] Test:  [230/345]  eta: 0:00:09  loss: 0.1319 (0.1390)  time: 0.0871  data: 0.0001  max mem: 11902
[17:31:43.545420] Test:  [240/345]  eta: 0:00:08  loss: 0.1415 (0.1392)  time: 0.0873  data: 0.0001  max mem: 11902
[17:31:44.425218] Test:  [250/345]  eta: 0:00:08  loss: 0.1406 (0.1393)  time: 0.0877  data: 0.0001  max mem: 11902
[17:31:45.307434] Test:  [260/345]  eta: 0:00:07  loss: 0.1363 (0.1393)  time: 0.0880  data: 0.0001  max mem: 11902
[17:31:46.193374] Test:  [270/345]  eta: 0:00:06  loss: 0.1388 (0.1394)  time: 0.0883  data: 0.0001  max mem: 11902
[17:31:47.083571] Test:  [280/345]  eta: 0:00:05  loss: 0.1365 (0.1392)  time: 0.0887  data: 0.0001  max mem: 11902
[17:31:47.976959] Test:  [290/345]  eta: 0:00:04  loss: 0.1332 (0.1391)  time: 0.0891  data: 0.0001  max mem: 11902
[17:31:48.874922] Test:  [300/345]  eta: 0:00:03  loss: 0.1363 (0.1394)  time: 0.0895  data: 0.0001  max mem: 11902
[17:31:49.775326] Test:  [310/345]  eta: 0:00:03  loss: 0.1406 (0.1396)  time: 0.0899  data: 0.0001  max mem: 11902
[17:31:50.679175] Test:  [320/345]  eta: 0:00:02  loss: 0.1412 (0.1397)  time: 0.0901  data: 0.0001  max mem: 11902
[17:31:51.586184] Test:  [330/345]  eta: 0:00:01  loss: 0.1412 (0.1397)  time: 0.0905  data: 0.0001  max mem: 11902
[17:31:52.497214] Test:  [340/345]  eta: 0:00:00  loss: 0.1434 (0.1397)  time: 0.0908  data: 0.0001  max mem: 11902
[17:31:52.863752] Test:  [344/345]  eta: 0:00:00  loss: 0.1434 (0.1399)  time: 0.0911  data: 0.0001  max mem: 11902
[17:31:52.921302] Test: Total time: 0:00:29 (0.0866 s / it)
[17:32:02.886746] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4659 (0.4659)  time: 0.4165  data: 0.3393  max mem: 11902
[17:32:03.675779] Test:  [10/57]  eta: 0:00:05  loss: 0.4279 (0.4660)  time: 0.1095  data: 0.0310  max mem: 11902
[17:32:04.467972] Test:  [20/57]  eta: 0:00:03  loss: 0.4211 (0.4475)  time: 0.0790  data: 0.0001  max mem: 11902
[17:32:05.262913] Test:  [30/57]  eta: 0:00:02  loss: 0.2698 (0.3875)  time: 0.0793  data: 0.0001  max mem: 11902
[17:32:06.063829] Test:  [40/57]  eta: 0:00:01  loss: 0.2698 (0.3665)  time: 0.0797  data: 0.0001  max mem: 11902
[17:32:06.865468] Test:  [50/57]  eta: 0:00:00  loss: 0.3067 (0.3748)  time: 0.0801  data: 0.0001  max mem: 11902
[17:32:07.301306] Test:  [56/57]  eta: 0:00:00  loss: 0.3572 (0.4093)  time: 0.0779  data: 0.0000  max mem: 11902
[17:32:07.369842] Test: Total time: 0:00:04 (0.0860 s / it)
[17:32:09.107982] Dice score of the network on the train images: 0.864933, val images: 0.723204
[17:32:09.111597] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:32:09.715865] Epoch: [34]  [  0/345]  eta: 0:03:28  lr: 0.000069  loss: 0.1213 (0.1213)  time: 0.6031  data: 0.3570  max mem: 11902
[17:32:14.587474] Epoch: [34]  [ 20/345]  eta: 0:01:24  lr: 0.000069  loss: 0.1353 (0.1387)  time: 0.2435  data: 0.0001  max mem: 11902
[17:32:19.468533] Epoch: [34]  [ 40/345]  eta: 0:01:17  lr: 0.000068  loss: 0.1367 (0.1413)  time: 0.2440  data: 0.0001  max mem: 11902
[17:32:24.348833] Epoch: [34]  [ 60/345]  eta: 0:01:11  lr: 0.000068  loss: 0.1344 (0.1402)  time: 0.2440  data: 0.0001  max mem: 11902
[17:32:29.234080] Epoch: [34]  [ 80/345]  eta: 0:01:05  lr: 0.000068  loss: 0.1370 (0.1402)  time: 0.2442  data: 0.0001  max mem: 11902
[17:32:34.118538] Epoch: [34]  [100/345]  eta: 0:01:00  lr: 0.000067  loss: 0.1471 (0.1420)  time: 0.2442  data: 0.0001  max mem: 11902

[17:32:38.994944] Epoch: [34]  [120/345]  eta: 0:00:55  lr: 0.000067  loss: 0.1407 (0.1424)  time: 0.2438  data: 0.0001  max mem: 11902
[17:32:43.880701] Epoch: [34]  [140/345]  eta: 0:00:50  lr: 0.000066  loss: 0.1416 (0.1427)  time: 0.2442  data: 0.0001  max mem: 11902
[17:32:48.775222] Epoch: [34]  [160/345]  eta: 0:00:45  lr: 0.000066  loss: 0.1406 (0.1429)  time: 0.2447  data: 0.0001  max mem: 11902
[17:32:53.673363] Epoch: [34]  [180/345]  eta: 0:00:40  lr: 0.000066  loss: 0.1404 (0.1436)  time: 0.2449  data: 0.0001  max mem: 11902
[17:32:58.570827] Epoch: [34]  [200/345]  eta: 0:00:35  lr: 0.000065  loss: 0.1398 (0.1435)  time: 0.2448  data: 0.0001  max mem: 11902
[17:33:03.469604] Epoch: [34]  [220/345]  eta: 0:00:30  lr: 0.000065  loss: 0.1350 (0.1434)  time: 0.2449  data: 0.0001  max mem: 11902
[17:33:08.370688] Epoch: [34]  [240/345]  eta: 0:00:25  lr: 0.000064  loss: 0.1483 (0.1441)  time: 0.2450  data: 0.0001  max mem: 11902
[17:33:13.277663] Epoch: [34]  [260/345]  eta: 0:00:20  lr: 0.000064  loss: 0.1494 (0.1449)  time: 0.2453  data: 0.0001  max mem: 11902
[17:33:18.180391] Epoch: [34]  [280/345]  eta: 0:00:15  lr: 0.000064  loss: 0.1463 (0.1449)  time: 0.2451  data: 0.0001  max mem: 11902
[17:33:23.087649] Epoch: [34]  [300/345]  eta: 0:00:11  lr: 0.000063  loss: 0.1419 (0.1450)  time: 0.2453  data: 0.0001  max mem: 11902
[17:33:27.995917] Epoch: [34]  [320/345]  eta: 0:00:06  lr: 0.000063  loss: 0.1384 (0.1449)  time: 0.2454  data: 0.0001  max mem: 11902
[17:33:32.898098] Epoch: [34]  [340/345]  eta: 0:00:01  lr: 0.000063  loss: 0.1366 (0.1444)  time: 0.2451  data: 0.0001  max mem: 11902
[17:33:33.878048] Epoch: [34]  [344/345]  eta: 0:00:00  lr: 0.000063  loss: 0.1360 (0.1443)  time: 0.2449  data: 0.0001  max mem: 11902
[17:33:33.938805] Epoch: [34] Total time: 0:01:24 (0.2459 s / it)
[17:33:33.939419] Averaged stats: lr: 0.000063  loss: 0.1360 (0.1443)
[17:33:34.371194] Test:  [  0/345]  eta: 0:02:27  loss: 0.1292 (0.1292)  time: 0.4268  data: 0.3498  max mem: 11902
[17:33:35.172240] Test:  [ 10/345]  eta: 0:00:37  loss: 0.1340 (0.1355)  time: 0.1116  data: 0.0326  max mem: 11902
[17:33:35.971949] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1377 (0.1361)  time: 0.0800  data: 0.0005  max mem: 11902
[17:33:36.773712] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1351 (0.1374)  time: 0.0800  data: 0.0001  max mem: 11902
[17:33:37.576726] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1338 (0.1356)  time: 0.0802  data: 0.0001  max mem: 11902
[17:33:38.383374] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1308 (0.1355)  time: 0.0804  data: 0.0001  max mem: 11902
[17:33:39.195584] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1336 (0.1358)  time: 0.0809  data: 0.0001  max mem: 11902
[17:33:40.010215] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1317 (0.1353)  time: 0.0813  data: 0.0001  max mem: 11902
[17:33:40.828150] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1237 (0.1342)  time: 0.0816  data: 0.0001  max mem: 11902
[17:33:41.651340] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1295 (0.1345)  time: 0.0820  data: 0.0001  max mem: 11902
[17:33:42.477416] Test:  [100/345]  eta: 0:00:20  loss: 0.1344 (0.1351)  time: 0.0824  data: 0.0001  max mem: 11902
[17:33:43.306206] Test:  [110/345]  eta: 0:00:19  loss: 0.1354 (0.1354)  time: 0.0827  data: 0.0001  max mem: 11902
[17:33:44.139645] Test:  [120/345]  eta: 0:00:18  loss: 0.1375 (0.1360)  time: 0.0830  data: 0.0001  max mem: 11902
[17:33:44.975767] Test:  [130/345]  eta: 0:00:18  loss: 0.1345 (0.1360)  time: 0.0834  data: 0.0001  max mem: 11902
[17:33:45.815503] Test:  [140/345]  eta: 0:00:17  loss: 0.1315 (0.1355)  time: 0.0837  data: 0.0001  max mem: 11902
[17:33:46.658842] Test:  [150/345]  eta: 0:00:16  loss: 0.1338 (0.1359)  time: 0.0841  data: 0.0001  max mem: 11902
[17:33:47.505904] Test:  [160/345]  eta: 0:00:15  loss: 0.1397 (0.1359)  time: 0.0845  data: 0.0001  max mem: 11902
[17:33:48.357421] Test:  [170/345]  eta: 0:00:14  loss: 0.1342 (0.1363)  time: 0.0849  data: 0.0001  max mem: 11902
[17:33:49.211189] Test:  [180/345]  eta: 0:00:13  loss: 0.1294 (0.1360)  time: 0.0852  data: 0.0001  max mem: 11902
[17:33:50.070624] Test:  [190/345]  eta: 0:00:13  loss: 0.1287 (0.1357)  time: 0.0856  data: 0.0001  max mem: 11902
[17:33:50.932656] Test:  [200/345]  eta: 0:00:12  loss: 0.1245 (0.1358)  time: 0.0860  data: 0.0001  max mem: 11902
[17:33:51.798338] Test:  [210/345]  eta: 0:00:11  loss: 0.1408 (0.1362)  time: 0.0863  data: 0.0001  max mem: 11902
[17:33:52.667496] Test:  [220/345]  eta: 0:00:10  loss: 0.1399 (0.1362)  time: 0.0867  data: 0.0001  max mem: 11902
[17:33:53.539841] Test:  [230/345]  eta: 0:00:09  loss: 0.1399 (0.1365)  time: 0.0870  data: 0.0001  max mem: 11902
[17:33:54.416323] Test:  [240/345]  eta: 0:00:08  loss: 0.1401 (0.1364)  time: 0.0874  data: 0.0001  max mem: 11902
[17:33:55.296861] Test:  [250/345]  eta: 0:00:08  loss: 0.1305 (0.1364)  time: 0.0878  data: 0.0001  max mem: 11902
[17:33:56.180747] Test:  [260/345]  eta: 0:00:07  loss: 0.1305 (0.1361)  time: 0.0881  data: 0.0001  max mem: 11902
[17:33:57.066560] Test:  [270/345]  eta: 0:00:06  loss: 0.1333 (0.1364)  time: 0.0884  data: 0.0001  max mem: 11902
[17:33:57.957161] Test:  [280/345]  eta: 0:00:05  loss: 0.1365 (0.1361)  time: 0.0888  data: 0.0001  max mem: 11902
[17:33:58.851021] Test:  [290/345]  eta: 0:00:04  loss: 0.1312 (0.1360)  time: 0.0891  data: 0.0001  max mem: 11902
[17:33:59.749806] Test:  [300/345]  eta: 0:00:03  loss: 0.1312 (0.1360)  time: 0.0896  data: 0.0001  max mem: 11902
[17:34:00.650454] Test:  [310/345]  eta: 0:00:03  loss: 0.1304 (0.1358)  time: 0.0899  data: 0.0001  max mem: 11902
[17:34:01.554656] Test:  [320/345]  eta: 0:00:02  loss: 0.1299 (0.1359)  time: 0.0902  data: 0.0001  max mem: 11902
[17:34:02.462575] Test:  [330/345]  eta: 0:00:01  loss: 0.1378 (0.1361)  time: 0.0905  data: 0.0001  max mem: 11902
[17:34:03.374543] Test:  [340/345]  eta: 0:00:00  loss: 0.1388 (0.1363)  time: 0.0909  data: 0.0001  max mem: 11902
[17:34:03.740652] Test:  [344/345]  eta: 0:00:00  loss: 0.1378 (0.1362)  time: 0.0911  data: 0.0001  max mem: 11902
[17:34:03.816847] Test: Total time: 0:00:29 (0.0866 s / it)
[17:34:13.691822] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4705 (0.4705)  time: 0.4398  data: 0.3626  max mem: 11902
[17:34:14.480139] Test:  [10/57]  eta: 0:00:05  loss: 0.4298 (0.4433)  time: 0.1116  data: 0.0331  max mem: 11902
[17:34:15.272528] Test:  [20/57]  eta: 0:00:03  loss: 0.4255 (0.4324)  time: 0.0789  data: 0.0001  max mem: 11902
[17:34:16.068360] Test:  [30/57]  eta: 0:00:02  loss: 0.2673 (0.3716)  time: 0.0793  data: 0.0001  max mem: 11902
[17:34:16.867707] Test:  [40/57]  eta: 0:00:01  loss: 0.2509 (0.3502)  time: 0.0797  data: 0.0001  max mem: 11902
[17:34:17.669872] Test:  [50/57]  eta: 0:00:00  loss: 0.2939 (0.3548)  time: 0.0800  data: 0.0001  max mem: 11902
[17:34:18.105866] Test:  [56/57]  eta: 0:00:00  loss: 0.3365 (0.3874)  time: 0.0779  data: 0.0000  max mem: 11902
[17:34:18.177005] Test: Total time: 0:00:04 (0.0864 s / it)
[17:34:19.919918] Dice score of the network on the train images: 0.862632, val images: 0.737126
[17:34:19.923695] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:34:20.515994] Epoch: [35]  [  0/345]  eta: 0:03:24  lr: 0.000063  loss: 0.1154 (0.1154)  time: 0.5913  data: 0.3453  max mem: 11902
[17:34:25.388434] Epoch: [35]  [ 20/345]  eta: 0:01:24  lr: 0.000062  loss: 0.1293 (0.1337)  time: 0.2436  data: 0.0001  max mem: 11902
[17:34:30.273468] Epoch: [35]  [ 40/345]  eta: 0:01:16  lr: 0.000062  loss: 0.1460 (0.1399)  time: 0.2442  data: 0.0001  max mem: 11902
[17:34:35.159333] Epoch: [35]  [ 60/345]  eta: 0:01:11  lr: 0.000061  loss: 0.1458 (0.1415)  time: 0.2442  data: 0.0001  max mem: 11902
[17:34:40.046569] Epoch: [35]  [ 80/345]  eta: 0:01:05  lr: 0.000061  loss: 0.1339 (0.1412)  time: 0.2443  data: 0.0001  max mem: 11902
[17:34:44.920900] Epoch: [35]  [100/345]  eta: 0:01:00  lr: 0.000061  loss: 0.1482 (0.1418)  time: 0.2437  data: 0.0001  max mem: 11902
[17:34:49.790702] Epoch: [35]  [120/345]  eta: 0:00:55  lr: 0.000060  loss: 0.1405 (0.1423)  time: 0.2434  data: 0.0001  max mem: 11902
[17:34:54.676887] Epoch: [35]  [140/345]  eta: 0:00:50  lr: 0.000060  loss: 0.1406 (0.1418)  time: 0.2443  data: 0.0001  max mem: 11902
[17:34:59.575215] Epoch: [35]  [160/345]  eta: 0:00:45  lr: 0.000059  loss: 0.1377 (0.1421)  time: 0.2449  data: 0.0001  max mem: 11902
[17:35:04.476750] Epoch: [35]  [180/345]  eta: 0:00:40  lr: 0.000059  loss: 0.1364 (0.1418)  time: 0.2450  data: 0.0001  max mem: 11902
[17:35:09.368652] Epoch: [35]  [200/345]  eta: 0:00:35  lr: 0.000059  loss: 0.1469 (0.1423)  time: 0.2445  data: 0.0001  max mem: 11902
[17:35:14.335804] Epoch: [35]  [220/345]  eta: 0:00:30  lr: 0.000058  loss: 0.1412 (0.1423)  time: 0.2483  data: 0.0001  max mem: 11902
[17:35:19.233400] Epoch: [35]  [240/345]  eta: 0:00:25  lr: 0.000058  loss: 0.1359 (0.1421)  time: 0.2448  data: 0.0001  max mem: 11902
[17:35:24.119043] Epoch: [35]  [260/345]  eta: 0:00:20  lr: 0.000058  loss: 0.1333 (0.1419)  time: 0.2442  data: 0.0001  max mem: 11902
[17:35:29.027733] Epoch: [35]  [280/345]  eta: 0:00:15  lr: 0.000057  loss: 0.1476 (0.1424)  time: 0.2454  data: 0.0001  max mem: 11902
[17:35:33.918282] Epoch: [35]  [300/345]  eta: 0:00:11  lr: 0.000057  loss: 0.1378 (0.1422)  time: 0.2445  data: 0.0001  max mem: 11902
[17:35:38.816047] Epoch: [35]  [320/345]  eta: 0:00:06  lr: 0.000056  loss: 0.1332 (0.1421)  time: 0.2449  data: 0.0001  max mem: 11902
[17:35:43.705408] Epoch: [35]  [340/345]  eta: 0:00:01  lr: 0.000056  loss: 0.1308 (0.1416)  time: 0.2444  data: 0.0001  max mem: 11902
[17:35:44.683868] Epoch: [35]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.1308 (0.1416)  time: 0.2445  data: 0.0001  max mem: 11902
[17:35:44.748445] Epoch: [35] Total time: 0:01:24 (0.2459 s / it)
[17:35:44.748655] Averaged stats: lr: 0.000056  loss: 0.1308 (0.1416)
[17:35:45.198340] Test:  [  0/345]  eta: 0:02:33  loss: 0.1781 (0.1781)  time: 0.4450  data: 0.3677  max mem: 11902
[17:35:46.013659] Test:  [ 10/345]  eta: 0:00:38  loss: 0.1207 (0.1316)  time: 0.1145  data: 0.0355  max mem: 11902
[17:35:46.812396] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1271 (0.1319)  time: 0.0806  data: 0.0012  max mem: 11902
[17:35:47.613447] Test:  [ 30/345]  eta: 0:00:29  loss: 0.1244 (0.1295)  time: 0.0799  data: 0.0001  max mem: 11902
[17:35:48.416299] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1223 (0.1289)  time: 0.0801  data: 0.0001  max mem: 11902
[17:35:49.225020] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1243 (0.1308)  time: 0.0805  data: 0.0001  max mem: 11902
[17:35:50.037093] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1352 (0.1312)  time: 0.0809  data: 0.0001  max mem: 11902
[17:35:50.851156] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1337 (0.1321)  time: 0.0812  data: 0.0001  max mem: 11902
[17:35:51.669137] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1272 (0.1314)  time: 0.0815  data: 0.0001  max mem: 11902
[17:35:52.491236] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1244 (0.1311)  time: 0.0819  data: 0.0001  max mem: 11902
[17:35:53.317209] Test:  [100/345]  eta: 0:00:20  loss: 0.1234 (0.1304)  time: 0.0823  data: 0.0001  max mem: 11902
[17:35:54.146725] Test:  [110/345]  eta: 0:00:19  loss: 0.1236 (0.1307)  time: 0.0827  data: 0.0001  max mem: 11902
[17:35:54.979249] Test:  [120/345]  eta: 0:00:18  loss: 0.1338 (0.1308)  time: 0.0830  data: 0.0001  max mem: 11902
[17:35:55.816575] Test:  [130/345]  eta: 0:00:18  loss: 0.1338 (0.1315)  time: 0.0834  data: 0.0001  max mem: 11902
[17:35:56.656921] Test:  [140/345]  eta: 0:00:17  loss: 0.1319 (0.1323)  time: 0.0838  data: 0.0001  max mem: 11902
[17:35:57.500490] Test:  [150/345]  eta: 0:00:16  loss: 0.1291 (0.1322)  time: 0.0841  data: 0.0001  max mem: 11902
[17:35:58.347589] Test:  [160/345]  eta: 0:00:15  loss: 0.1290 (0.1321)  time: 0.0845  data: 0.0001  max mem: 11902
[17:35:59.199099] Test:  [170/345]  eta: 0:00:14  loss: 0.1290 (0.1321)  time: 0.0849  data: 0.0001  max mem: 11902
[17:36:00.054213] Test:  [180/345]  eta: 0:00:13  loss: 0.1283 (0.1323)  time: 0.0852  data: 0.0001  max mem: 11902
[17:36:00.912834] Test:  [190/345]  eta: 0:00:13  loss: 0.1310 (0.1324)  time: 0.0856  data: 0.0001  max mem: 11902
[17:36:01.774443] Test:  [200/345]  eta: 0:00:12  loss: 0.1390 (0.1326)  time: 0.0859  data: 0.0001  max mem: 11902
[17:36:02.639844] Test:  [210/345]  eta: 0:00:11  loss: 0.1390 (0.1325)  time: 0.0863  data: 0.0001  max mem: 11902
[17:36:03.508464] Test:  [220/345]  eta: 0:00:10  loss: 0.1331 (0.1328)  time: 0.0866  data: 0.0001  max mem: 11902
[17:36:04.380803] Test:  [230/345]  eta: 0:00:09  loss: 0.1362 (0.1327)  time: 0.0870  data: 0.0001  max mem: 11902
[17:36:05.256650] Test:  [240/345]  eta: 0:00:08  loss: 0.1260 (0.1324)  time: 0.0873  data: 0.0001  max mem: 11902
[17:36:06.135877] Test:  [250/345]  eta: 0:00:08  loss: 0.1222 (0.1327)  time: 0.0877  data: 0.0001  max mem: 11902
[17:36:07.019906] Test:  [260/345]  eta: 0:00:07  loss: 0.1369 (0.1326)  time: 0.0881  data: 0.0001  max mem: 11902
[17:36:07.905502] Test:  [270/345]  eta: 0:00:06  loss: 0.1369 (0.1327)  time: 0.0884  data: 0.0001  max mem: 11902
[17:36:08.795709] Test:  [280/345]  eta: 0:00:05  loss: 0.1306 (0.1326)  time: 0.0887  data: 0.0001  max mem: 11902
[17:36:09.689586] Test:  [290/345]  eta: 0:00:04  loss: 0.1235 (0.1324)  time: 0.0891  data: 0.0001  max mem: 11902
[17:36:10.587639] Test:  [300/345]  eta: 0:00:03  loss: 0.1221 (0.1326)  time: 0.0895  data: 0.0001  max mem: 11902
[17:36:11.488890] Test:  [310/345]  eta: 0:00:03  loss: 0.1274 (0.1327)  time: 0.0899  data: 0.0001  max mem: 11902
[17:36:12.392767] Test:  [320/345]  eta: 0:00:02  loss: 0.1338 (0.1329)  time: 0.0902  data: 0.0001  max mem: 11902
[17:36:13.300840] Test:  [330/345]  eta: 0:00:01  loss: 0.1277 (0.1326)  time: 0.0905  data: 0.0001  max mem: 11902
[17:36:14.212479] Test:  [340/345]  eta: 0:00:00  loss: 0.1271 (0.1328)  time: 0.0909  data: 0.0001  max mem: 11902
[17:36:14.578490] Test:  [344/345]  eta: 0:00:00  loss: 0.1302 (0.1329)  time: 0.0910  data: 0.0001  max mem: 11902
[17:36:14.640599] Test: Total time: 0:00:29 (0.0866 s / it)
[17:36:24.614235] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4507 (0.4507)  time: 0.4387  data: 0.3615  max mem: 11902
[17:36:25.404160] Test:  [10/57]  eta: 0:00:05  loss: 0.4358 (0.4378)  time: 0.1116  data: 0.0330  max mem: 11902
[17:36:26.196468] Test:  [20/57]  eta: 0:00:03  loss: 0.4224 (0.4275)  time: 0.0790  data: 0.0001  max mem: 11902
[17:36:26.994163] Test:  [30/57]  eta: 0:00:02  loss: 0.2923 (0.3767)  time: 0.0794  data: 0.0001  max mem: 11902
[17:36:27.796772] Test:  [40/57]  eta: 0:00:01  loss: 0.2806 (0.3591)  time: 0.0799  data: 0.0001  max mem: 11902
[17:36:28.600554] Test:  [50/57]  eta: 0:00:00  loss: 0.3205 (0.3632)  time: 0.0803  data: 0.0001  max mem: 11902
[17:36:29.036194] Test:  [56/57]  eta: 0:00:00  loss: 0.3641 (0.3926)  time: 0.0780  data: 0.0000  max mem: 11902
[17:36:29.101060] Test: Total time: 0:00:04 (0.0864 s / it)
[17:36:30.845608] Dice score of the network on the train images: 0.872077, val images: 0.737019
[17:36:30.849920] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:36:31.462746] Epoch: [36]  [  0/345]  eta: 0:03:31  lr: 0.000056  loss: 0.1199 (0.1199)  time: 0.6118  data: 0.3661  max mem: 11902
[17:36:36.343807] Epoch: [36]  [ 20/345]  eta: 0:01:24  lr: 0.000056  loss: 0.1310 (0.1369)  time: 0.2440  data: 0.0001  max mem: 11902
[17:36:41.228601] Epoch: [36]  [ 40/345]  eta: 0:01:17  lr: 0.000055  loss: 0.1418 (0.1396)  time: 0.2442  data: 0.0001  max mem: 11902
[17:36:46.110832] Epoch: [36]  [ 60/345]  eta: 0:01:11  lr: 0.000055  loss: 0.1340 (0.1399)  time: 0.2441  data: 0.0001  max mem: 11902
[17:36:51.003058] Epoch: [36]  [ 80/345]  eta: 0:01:05  lr: 0.000054  loss: 0.1310 (0.1412)  time: 0.2446  data: 0.0001  max mem: 11902
[17:36:55.904147] Epoch: [36]  [100/345]  eta: 0:01:00  lr: 0.000054  loss: 0.1311 (0.1400)  time: 0.2450  data: 0.0001  max mem: 11902
[17:37:00.794725] Epoch: [36]  [120/345]  eta: 0:00:55  lr: 0.000054  loss: 0.1314 (0.1390)  time: 0.2445  data: 0.0001  max mem: 11902
[17:37:05.686447] Epoch: [36]  [140/345]  eta: 0:00:50  lr: 0.000053  loss: 0.1369 (0.1398)  time: 0.2445  data: 0.0001  max mem: 11902
[17:37:10.580616] Epoch: [36]  [160/345]  eta: 0:00:45  lr: 0.000053  loss: 0.1260 (0.1387)  time: 0.2447  data: 0.0001  max mem: 11902
[17:37:15.470638] Epoch: [36]  [180/345]  eta: 0:00:40  lr: 0.000053  loss: 0.1322 (0.1383)  time: 0.2445  data: 0.0001  max mem: 11902
[17:37:20.376571] Epoch: [36]  [200/345]  eta: 0:00:35  lr: 0.000052  loss: 0.1341 (0.1382)  time: 0.2452  data: 0.0001  max mem: 11902
[17:37:25.283607] Epoch: [36]  [220/345]  eta: 0:00:30  lr: 0.000052  loss: 0.1351 (0.1380)  time: 0.2453  data: 0.0001  max mem: 11902
[17:37:30.191498] Epoch: [36]  [240/345]  eta: 0:00:25  lr: 0.000051  loss: 0.1353 (0.1379)  time: 0.2453  data: 0.0001  max mem: 11902
[17:37:35.090568] Epoch: [36]  [260/345]  eta: 0:00:20  lr: 0.000051  loss: 0.1374 (0.1380)  time: 0.2449  data: 0.0001  max mem: 11902
[17:37:39.990965] Epoch: [36]  [280/345]  eta: 0:00:15  lr: 0.000051  loss: 0.1391 (0.1382)  time: 0.2450  data: 0.0001  max mem: 11902
[17:37:44.886919] Epoch: [36]  [300/345]  eta: 0:00:11  lr: 0.000050  loss: 0.1413 (0.1383)  time: 0.2448  data: 0.0001  max mem: 11902
[17:37:49.779490] Epoch: [36]  [320/345]  eta: 0:00:06  lr: 0.000050  loss: 0.1350 (0.1382)  time: 0.2446  data: 0.0001  max mem: 11902
[17:37:54.672580] Epoch: [36]  [340/345]  eta: 0:00:01  lr: 0.000050  loss: 0.1282 (0.1381)  time: 0.2446  data: 0.0001  max mem: 11902
[17:37:55.650667] Epoch: [36]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.1351 (0.1381)  time: 0.2445  data: 0.0001  max mem: 11902
[17:37:55.731897] Epoch: [36] Total time: 0:01:24 (0.2460 s / it)
[17:37:55.732275] Averaged stats: lr: 0.000050  loss: 0.1351 (0.1381)
[17:37:56.183674] Test:  [  0/345]  eta: 0:02:34  loss: 0.1589 (0.1589)  time: 0.4467  data: 0.3694  max mem: 11902
[17:37:56.986600] Test:  [ 10/345]  eta: 0:00:38  loss: 0.1353 (0.1339)  time: 0.1135  data: 0.0344  max mem: 11902
[17:37:57.786751] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1338 (0.1325)  time: 0.0801  data: 0.0005  max mem: 11902
[17:37:58.589580] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1276 (0.1313)  time: 0.0801  data: 0.0001  max mem: 11902
[17:37:59.393392] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1303 (0.1328)  time: 0.0803  data: 0.0001  max mem: 11902
[17:38:00.200473] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1343 (0.1346)  time: 0.0805  data: 0.0001  max mem: 11902
[17:38:01.013340] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1379 (0.1345)  time: 0.0809  data: 0.0001  max mem: 11902
[17:38:01.828417] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1292 (0.1340)  time: 0.0813  data: 0.0001  max mem: 11902
[17:38:02.646713] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1272 (0.1329)  time: 0.0816  data: 0.0001  max mem: 11902
[17:38:03.468937] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1273 (0.1322)  time: 0.0820  data: 0.0001  max mem: 11902
[17:38:04.294933] Test:  [100/345]  eta: 0:00:20  loss: 0.1286 (0.1320)  time: 0.0823  data: 0.0001  max mem: 11902
[17:38:05.124324] Test:  [110/345]  eta: 0:00:19  loss: 0.1321 (0.1320)  time: 0.0827  data: 0.0001  max mem: 11902
[17:38:05.957053] Test:  [120/345]  eta: 0:00:18  loss: 0.1297 (0.1320)  time: 0.0830  data: 0.0001  max mem: 11902
[17:38:06.793513] Test:  [130/345]  eta: 0:00:18  loss: 0.1297 (0.1320)  time: 0.0834  data: 0.0001  max mem: 11902
[17:38:07.633995] Test:  [140/345]  eta: 0:00:17  loss: 0.1269 (0.1319)  time: 0.0838  data: 0.0001  max mem: 11902
[17:38:08.477574] Test:  [150/345]  eta: 0:00:16  loss: 0.1261 (0.1321)  time: 0.0841  data: 0.0001  max mem: 11902
[17:38:09.324768] Test:  [160/345]  eta: 0:00:15  loss: 0.1280 (0.1317)  time: 0.0845  data: 0.0001  max mem: 11902
[17:38:10.176642] Test:  [170/345]  eta: 0:00:14  loss: 0.1334 (0.1323)  time: 0.0849  data: 0.0001  max mem: 11902
[17:38:11.032032] Test:  [180/345]  eta: 0:00:13  loss: 0.1364 (0.1320)  time: 0.0853  data: 0.0001  max mem: 11902
[17:38:11.889672] Test:  [190/345]  eta: 0:00:13  loss: 0.1278 (0.1321)  time: 0.0856  data: 0.0001  max mem: 11902
[17:38:12.751176] Test:  [200/345]  eta: 0:00:12  loss: 0.1337 (0.1323)  time: 0.0859  data: 0.0001  max mem: 11902
[17:38:13.616490] Test:  [210/345]  eta: 0:00:11  loss: 0.1321 (0.1325)  time: 0.0863  data: 0.0001  max mem: 11902
[17:38:14.485604] Test:  [220/345]  eta: 0:00:10  loss: 0.1236 (0.1321)  time: 0.0866  data: 0.0001  max mem: 11902
[17:38:15.358388] Test:  [230/345]  eta: 0:00:09  loss: 0.1215 (0.1319)  time: 0.0870  data: 0.0001  max mem: 11902
[17:38:16.234485] Test:  [240/345]  eta: 0:00:08  loss: 0.1242 (0.1317)  time: 0.0874  data: 0.0001  max mem: 11902
[17:38:17.114337] Test:  [250/345]  eta: 0:00:08  loss: 0.1244 (0.1318)  time: 0.0877  data: 0.0001  max mem: 11902
[17:38:17.998007] Test:  [260/345]  eta: 0:00:07  loss: 0.1275 (0.1316)  time: 0.0881  data: 0.0001  max mem: 11902
[17:38:18.885354] Test:  [270/345]  eta: 0:00:06  loss: 0.1215 (0.1314)  time: 0.0885  data: 0.0001  max mem: 11902
[17:38:19.775905] Test:  [280/345]  eta: 0:00:05  loss: 0.1293 (0.1317)  time: 0.0888  data: 0.0001  max mem: 11902
[17:38:20.669847] Test:  [290/345]  eta: 0:00:04  loss: 0.1363 (0.1323)  time: 0.0892  data: 0.0001  max mem: 11902
[17:38:21.568779] Test:  [300/345]  eta: 0:00:03  loss: 0.1378 (0.1326)  time: 0.0895  data: 0.0001  max mem: 11902
[17:38:22.470797] Test:  [310/345]  eta: 0:00:03  loss: 0.1293 (0.1324)  time: 0.0899  data: 0.0001  max mem: 11902
[17:38:23.375756] Test:  [320/345]  eta: 0:00:02  loss: 0.1293 (0.1325)  time: 0.0903  data: 0.0001  max mem: 11902
[17:38:24.283633] Test:  [330/345]  eta: 0:00:01  loss: 0.1218 (0.1323)  time: 0.0906  data: 0.0001  max mem: 11902
[17:38:25.193846] Test:  [340/345]  eta: 0:00:00  loss: 0.1215 (0.1321)  time: 0.0908  data: 0.0001  max mem: 11902
[17:38:25.559770] Test:  [344/345]  eta: 0:00:00  loss: 0.1180 (0.1319)  time: 0.0910  data: 0.0001  max mem: 11902
[17:38:25.627231] Test: Total time: 0:00:29 (0.0866 s / it)
[17:38:35.521863] Test:  [ 0/57]  eta: 0:00:24  loss: 0.4660 (0.4660)  time: 0.4228  data: 0.3458  max mem: 11902
[17:38:36.314146] Test:  [10/57]  eta: 0:00:05  loss: 0.4300 (0.4351)  time: 0.1104  data: 0.0320  max mem: 11902
[17:38:37.108053] Test:  [20/57]  eta: 0:00:03  loss: 0.4288 (0.4260)  time: 0.0792  data: 0.0003  max mem: 11902
[17:38:37.903251] Test:  [30/57]  eta: 0:00:02  loss: 0.2725 (0.3706)  time: 0.0794  data: 0.0001  max mem: 11902
[17:38:38.704233] Test:  [40/57]  eta: 0:00:01  loss: 0.2622 (0.3518)  time: 0.0797  data: 0.0001  max mem: 11902
[17:38:39.506852] Test:  [50/57]  eta: 0:00:00  loss: 0.3028 (0.3568)  time: 0.0801  data: 0.0001  max mem: 11902
[17:38:39.943056] Test:  [56/57]  eta: 0:00:00  loss: 0.3471 (0.3876)  time: 0.0779  data: 0.0000  max mem: 11902
[17:38:40.016938] Test: Total time: 0:00:04 (0.0863 s / it)
[17:38:41.767654] Dice score of the network on the train images: 0.870932, val images: 0.760007
[17:38:41.771308] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:38:42.371790] Epoch: [37]  [  0/345]  eta: 0:03:26  lr: 0.000050  loss: 0.1278 (0.1278)  time: 0.5994  data: 0.3536  max mem: 11902
[17:38:47.235019] Epoch: [37]  [ 20/345]  eta: 0:01:24  lr: 0.000049  loss: 0.1406 (0.1429)  time: 0.2431  data: 0.0001  max mem: 11902
[17:38:52.102180] Epoch: [37]  [ 40/345]  eta: 0:01:16  lr: 0.000049  loss: 0.1290 (0.1382)  time: 0.2433  data: 0.0001  max mem: 11902
[17:38:56.969770] Epoch: [37]  [ 60/345]  eta: 0:01:10  lr: 0.000048  loss: 0.1341 (0.1374)  time: 0.2433  data: 0.0001  max mem: 11902
[17:39:01.834856] Epoch: [37]  [ 80/345]  eta: 0:01:05  lr: 0.000048  loss: 0.1341 (0.1375)  time: 0.2432  data: 0.0001  max mem: 11902
[17:39:06.720884] Epoch: [37]  [100/345]  eta: 0:01:00  lr: 0.000048  loss: 0.1281 (0.1369)  time: 0.2443  data: 0.0001  max mem: 11902
[17:39:11.610835] Epoch: [37]  [120/345]  eta: 0:00:55  lr: 0.000047  loss: 0.1274 (0.1368)  time: 0.2445  data: 0.0001  max mem: 11902
[17:39:16.505501] Epoch: [37]  [140/345]  eta: 0:00:50  lr: 0.000047  loss: 0.1279 (0.1365)  time: 0.2447  data: 0.0001  max mem: 11902
[17:39:21.400143] Epoch: [37]  [160/345]  eta: 0:00:45  lr: 0.000047  loss: 0.1324 (0.1362)  time: 0.2447  data: 0.0001  max mem: 11902
[17:39:26.289321] Epoch: [37]  [180/345]  eta: 0:00:40  lr: 0.000046  loss: 0.1361 (0.1366)  time: 0.2444  data: 0.0001  max mem: 11902
[17:39:31.185654] Epoch: [37]  [200/345]  eta: 0:00:35  lr: 0.000046  loss: 0.1392 (0.1373)  time: 0.2448  data: 0.0001  max mem: 11902
[17:39:36.076566] Epoch: [37]  [220/345]  eta: 0:00:30  lr: 0.000045  loss: 0.1326 (0.1372)  time: 0.2445  data: 0.0001  max mem: 11902
[17:39:40.962364] Epoch: [37]  [240/345]  eta: 0:00:25  lr: 0.000045  loss: 0.1325 (0.1367)  time: 0.2442  data: 0.0001  max mem: 11902
[17:39:45.856216] Epoch: [37]  [260/345]  eta: 0:00:20  lr: 0.000045  loss: 0.1284 (0.1364)  time: 0.2446  data: 0.0001  max mem: 11902
[17:39:50.752238] Epoch: [37]  [280/345]  eta: 0:00:15  lr: 0.000044  loss: 0.1292 (0.1360)  time: 0.2448  data: 0.0001  max mem: 11902
[17:39:55.657259] Epoch: [37]  [300/345]  eta: 0:00:11  lr: 0.000044  loss: 0.1295 (0.1360)  time: 0.2452  data: 0.0001  max mem: 11902
[17:40:00.564369] Epoch: [37]  [320/345]  eta: 0:00:06  lr: 0.000044  loss: 0.1289 (0.1358)  time: 0.2453  data: 0.0001  max mem: 11902
[17:40:05.467758] Epoch: [37]  [340/345]  eta: 0:00:01  lr: 0.000043  loss: 0.1375 (0.1357)  time: 0.2451  data: 0.0001  max mem: 11902
[17:40:06.447178] Epoch: [37]  [344/345]  eta: 0:00:00  lr: 0.000043  loss: 0.1296 (0.1356)  time: 0.2450  data: 0.0001  max mem: 11902
[17:40:06.523496] Epoch: [37] Total time: 0:01:24 (0.2457 s / it)
[17:40:06.523851] Averaged stats: lr: 0.000043  loss: 0.1296 (0.1356)
[17:40:06.955628] Test:  [  0/345]  eta: 0:02:27  loss: 0.1321 (0.1321)  time: 0.4274  data: 0.3500  max mem: 11902
[17:40:07.775005] Test:  [ 10/345]  eta: 0:00:37  loss: 0.1317 (0.1305)  time: 0.1133  data: 0.0343  max mem: 11902
[17:40:08.572149] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1295 (0.1311)  time: 0.0807  data: 0.0014  max mem: 11902
[17:40:09.374630] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1266 (0.1296)  time: 0.0799  data: 0.0001  max mem: 11902
[17:40:10.179766] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1223 (0.1285)  time: 0.0803  data: 0.0001  max mem: 11902
[17:40:10.989637] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1223 (0.1287)  time: 0.0807  data: 0.0001  max mem: 11902
[17:40:11.801308] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1276 (0.1285)  time: 0.0810  data: 0.0001  max mem: 11902
[17:40:12.616126] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1285 (0.1299)  time: 0.0813  data: 0.0001  max mem: 11902
[17:40:13.434962] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1341 (0.1300)  time: 0.0816  data: 0.0001  max mem: 11902
[17:40:14.257116] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1264 (0.1293)  time: 0.0820  data: 0.0001  max mem: 11902
[17:40:15.082892] Test:  [100/345]  eta: 0:00:20  loss: 0.1264 (0.1292)  time: 0.0823  data: 0.0001  max mem: 11902
[17:40:15.913123] Test:  [110/345]  eta: 0:00:19  loss: 0.1218 (0.1284)  time: 0.0827  data: 0.0001  max mem: 11902
[17:40:16.746138] Test:  [120/345]  eta: 0:00:18  loss: 0.1162 (0.1275)  time: 0.0831  data: 0.0001  max mem: 11902
[17:40:17.584397] Test:  [130/345]  eta: 0:00:18  loss: 0.1162 (0.1274)  time: 0.0835  data: 0.0001  max mem: 11902
[17:40:18.425586] Test:  [140/345]  eta: 0:00:17  loss: 0.1248 (0.1274)  time: 0.0839  data: 0.0001  max mem: 11902
[17:40:19.268013] Test:  [150/345]  eta: 0:00:16  loss: 0.1248 (0.1269)  time: 0.0841  data: 0.0001  max mem: 11902
[17:40:20.115396] Test:  [160/345]  eta: 0:00:15  loss: 0.1263 (0.1269)  time: 0.0844  data: 0.0001  max mem: 11902
[17:40:20.966970] Test:  [170/345]  eta: 0:00:14  loss: 0.1332 (0.1273)  time: 0.0849  data: 0.0001  max mem: 11902
[17:40:21.820837] Test:  [180/345]  eta: 0:00:13  loss: 0.1344 (0.1274)  time: 0.0852  data: 0.0001  max mem: 11902
[17:40:22.678459] Test:  [190/345]  eta: 0:00:13  loss: 0.1199 (0.1272)  time: 0.0855  data: 0.0001  max mem: 11902
[17:40:23.540548] Test:  [200/345]  eta: 0:00:12  loss: 0.1177 (0.1269)  time: 0.0859  data: 0.0001  max mem: 11902
[17:40:24.407124] Test:  [210/345]  eta: 0:00:11  loss: 0.1237 (0.1270)  time: 0.0864  data: 0.0001  max mem: 11902
[17:40:25.277787] Test:  [220/345]  eta: 0:00:10  loss: 0.1203 (0.1266)  time: 0.0868  data: 0.0001  max mem: 11902
[17:40:26.149860] Test:  [230/345]  eta: 0:00:09  loss: 0.1198 (0.1268)  time: 0.0871  data: 0.0001  max mem: 11902
[17:40:27.025585] Test:  [240/345]  eta: 0:00:08  loss: 0.1287 (0.1272)  time: 0.0873  data: 0.0001  max mem: 11902
[17:40:27.905409] Test:  [250/345]  eta: 0:00:08  loss: 0.1296 (0.1275)  time: 0.0877  data: 0.0001  max mem: 11902
[17:40:28.788449] Test:  [260/345]  eta: 0:00:07  loss: 0.1228 (0.1272)  time: 0.0881  data: 0.0001  max mem: 11902
[17:40:29.675964] Test:  [270/345]  eta: 0:00:06  loss: 0.1221 (0.1272)  time: 0.0885  data: 0.0001  max mem: 11902
[17:40:30.566801] Test:  [280/345]  eta: 0:00:05  loss: 0.1183 (0.1269)  time: 0.0889  data: 0.0001  max mem: 11902
[17:40:31.460587] Test:  [290/345]  eta: 0:00:04  loss: 0.1216 (0.1271)  time: 0.0892  data: 0.0001  max mem: 11902
[17:40:32.359003] Test:  [300/345]  eta: 0:00:03  loss: 0.1226 (0.1268)  time: 0.0895  data: 0.0001  max mem: 11902
[17:40:33.260722] Test:  [310/345]  eta: 0:00:03  loss: 0.1200 (0.1267)  time: 0.0899  data: 0.0001  max mem: 11902
[17:40:34.166216] Test:  [320/345]  eta: 0:00:02  loss: 0.1248 (0.1270)  time: 0.0903  data: 0.0001  max mem: 11902
[17:40:35.075271] Test:  [330/345]  eta: 0:00:01  loss: 0.1260 (0.1270)  time: 0.0907  data: 0.0001  max mem: 11902
[17:40:35.985899] Test:  [340/345]  eta: 0:00:00  loss: 0.1238 (0.1270)  time: 0.0909  data: 0.0001  max mem: 11902
[17:40:36.351723] Test:  [344/345]  eta: 0:00:00  loss: 0.1260 (0.1270)  time: 0.0911  data: 0.0001  max mem: 11902
[17:40:36.412354] Test: Total time: 0:00:29 (0.0866 s / it)
[17:40:46.348344] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4547 (0.4547)  time: 0.4597  data: 0.3826  max mem: 11902
[17:40:47.137651] Test:  [10/57]  eta: 0:00:05  loss: 0.4273 (0.4280)  time: 0.1134  data: 0.0349  max mem: 11902
[17:40:47.929223] Test:  [20/57]  eta: 0:00:03  loss: 0.4273 (0.4225)  time: 0.0790  data: 0.0001  max mem: 11902
[17:40:48.725558] Test:  [30/57]  eta: 0:00:02  loss: 0.2712 (0.3660)  time: 0.0793  data: 0.0001  max mem: 11902
[17:40:49.525727] Test:  [40/57]  eta: 0:00:01  loss: 0.2698 (0.3456)  time: 0.0798  data: 0.0001  max mem: 11902
[17:40:50.328848] Test:  [50/57]  eta: 0:00:00  loss: 0.2999 (0.3505)  time: 0.0801  data: 0.0001  max mem: 11902
[17:40:50.766034] Test:  [56/57]  eta: 0:00:00  loss: 0.3526 (0.3791)  time: 0.0780  data: 0.0000  max mem: 11902
[17:40:50.845871] Test: Total time: 0:00:04 (0.0870 s / it)
[17:40:52.599757] Dice score of the network on the train images: 0.874268, val images: 0.758692
[17:40:52.603582] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:40:53.191362] Epoch: [38]  [  0/345]  eta: 0:03:22  lr: 0.000043  loss: 0.1158 (0.1158)  time: 0.5867  data: 0.3403  max mem: 11902
[17:40:58.067094] Epoch: [38]  [ 20/345]  eta: 0:01:24  lr: 0.000043  loss: 0.1331 (0.1396)  time: 0.2437  data: 0.0001  max mem: 11902
[17:41:02.948721] Epoch: [38]  [ 40/345]  eta: 0:01:16  lr: 0.000042  loss: 0.1234 (0.1334)  time: 0.2440  data: 0.0001  max mem: 11902
[17:41:07.835077] Epoch: [38]  [ 60/345]  eta: 0:01:11  lr: 0.000042  loss: 0.1263 (0.1327)  time: 0.2443  data: 0.0001  max mem: 11902
[17:41:12.724981] Epoch: [38]  [ 80/345]  eta: 0:01:05  lr: 0.000042  loss: 0.1338 (0.1341)  time: 0.2445  data: 0.0001  max mem: 11902
[17:41:17.610253] Epoch: [38]  [100/345]  eta: 0:01:00  lr: 0.000041  loss: 0.1215 (0.1327)  time: 0.2442  data: 0.0001  max mem: 11902
[17:41:22.501129] Epoch: [38]  [120/345]  eta: 0:00:55  lr: 0.000041  loss: 0.1208 (0.1325)  time: 0.2445  data: 0.0001  max mem: 11902
[17:41:27.391098] Epoch: [38]  [140/345]  eta: 0:00:50  lr: 0.000041  loss: 0.1436 (0.1340)  time: 0.2444  data: 0.0001  max mem: 11902
[17:41:32.286062] Epoch: [38]  [160/345]  eta: 0:00:45  lr: 0.000040  loss: 0.1295 (0.1343)  time: 0.2447  data: 0.0001  max mem: 11902
[17:41:37.178041] Epoch: [38]  [180/345]  eta: 0:00:40  lr: 0.000040  loss: 0.1220 (0.1332)  time: 0.2446  data: 0.0001  max mem: 11902
[17:41:42.078108] Epoch: [38]  [200/345]  eta: 0:00:35  lr: 0.000040  loss: 0.1273 (0.1328)  time: 0.2450  data: 0.0001  max mem: 11902
[17:41:46.977316] Epoch: [38]  [220/345]  eta: 0:00:30  lr: 0.000039  loss: 0.1313 (0.1326)  time: 0.2449  data: 0.0001  max mem: 11902
[17:41:51.877581] Epoch: [38]  [240/345]  eta: 0:00:25  lr: 0.000039  loss: 0.1232 (0.1321)  time: 0.2450  data: 0.0001  max mem: 11902
[17:41:56.779814] Epoch: [38]  [260/345]  eta: 0:00:20  lr: 0.000039  loss: 0.1256 (0.1321)  time: 0.2451  data: 0.0001  max mem: 11902
[17:42:01.692367] Epoch: [38]  [280/345]  eta: 0:00:15  lr: 0.000038  loss: 0.1310 (0.1320)  time: 0.2456  data: 0.0001  max mem: 11902
[17:42:06.598650] Epoch: [38]  [300/345]  eta: 0:00:11  lr: 0.000038  loss: 0.1344 (0.1323)  time: 0.2453  data: 0.0001  max mem: 11902
[17:42:11.495291] Epoch: [38]  [320/345]  eta: 0:00:06  lr: 0.000038  loss: 0.1331 (0.1323)  time: 0.2448  data: 0.0001  max mem: 11902
[17:42:16.384056] Epoch: [38]  [340/345]  eta: 0:00:01  lr: 0.000037  loss: 0.1298 (0.1324)  time: 0.2444  data: 0.0001  max mem: 11902
[17:42:17.362221] Epoch: [38]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 0.1299 (0.1324)  time: 0.2442  data: 0.0001  max mem: 11902
[17:42:17.433630] Epoch: [38] Total time: 0:01:24 (0.2459 s / it)
[17:42:17.434062] Averaged stats: lr: 0.000037  loss: 0.1299 (0.1324)
[17:42:17.882911] Test:  [  0/345]  eta: 0:02:33  loss: 0.1488 (0.1488)  time: 0.4442  data: 0.3670  max mem: 11902
[17:42:18.701774] Test:  [ 10/345]  eta: 0:00:38  loss: 0.1182 (0.1199)  time: 0.1147  data: 0.0357  max mem: 11902
[17:42:19.500560] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1112 (0.1174)  time: 0.0808  data: 0.0014  max mem: 11902
[17:42:20.303374] Test:  [ 30/345]  eta: 0:00:29  loss: 0.1194 (0.1215)  time: 0.0800  data: 0.0001  max mem: 11902
[17:42:21.108184] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1200 (0.1212)  time: 0.0803  data: 0.0001  max mem: 11902
[17:42:21.915532] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1162 (0.1227)  time: 0.0805  data: 0.0001  max mem: 11902
[17:42:22.727461] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1269 (0.1239)  time: 0.0809  data: 0.0001  max mem: 11902
[17:42:23.541204] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1239 (0.1242)  time: 0.0812  data: 0.0001  max mem: 11902
[17:42:24.359744] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1186 (0.1238)  time: 0.0815  data: 0.0001  max mem: 11902
[17:42:25.181459] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1180 (0.1239)  time: 0.0819  data: 0.0001  max mem: 11902
[17:42:26.007531] Test:  [100/345]  eta: 0:00:20  loss: 0.1173 (0.1247)  time: 0.0823  data: 0.0001  max mem: 11902
[17:42:26.836754] Test:  [110/345]  eta: 0:00:19  loss: 0.1200 (0.1246)  time: 0.0827  data: 0.0001  max mem: 11902
[17:42:27.670106] Test:  [120/345]  eta: 0:00:19  loss: 0.1197 (0.1240)  time: 0.0831  data: 0.0001  max mem: 11902
[17:42:28.507671] Test:  [130/345]  eta: 0:00:18  loss: 0.1182 (0.1242)  time: 0.0835  data: 0.0001  max mem: 11902
[17:42:29.347639] Test:  [140/345]  eta: 0:00:17  loss: 0.1234 (0.1241)  time: 0.0838  data: 0.0001  max mem: 11902
[17:42:30.191812] Test:  [150/345]  eta: 0:00:16  loss: 0.1226 (0.1244)  time: 0.0841  data: 0.0001  max mem: 11902
[17:42:31.039055] Test:  [160/345]  eta: 0:00:15  loss: 0.1226 (0.1245)  time: 0.0845  data: 0.0001  max mem: 11902
[17:42:31.890607] Test:  [170/345]  eta: 0:00:14  loss: 0.1203 (0.1241)  time: 0.0849  data: 0.0001  max mem: 11902
[17:42:32.744995] Test:  [180/345]  eta: 0:00:13  loss: 0.1114 (0.1236)  time: 0.0852  data: 0.0001  max mem: 11902
[17:42:33.604030] Test:  [190/345]  eta: 0:00:13  loss: 0.1176 (0.1238)  time: 0.0856  data: 0.0001  max mem: 11902
[17:42:34.466055] Test:  [200/345]  eta: 0:00:12  loss: 0.1237 (0.1240)  time: 0.0860  data: 0.0001  max mem: 11902
[17:42:35.332205] Test:  [210/345]  eta: 0:00:11  loss: 0.1149 (0.1236)  time: 0.0863  data: 0.0001  max mem: 11902
[17:42:36.200697] Test:  [220/345]  eta: 0:00:10  loss: 0.1149 (0.1236)  time: 0.0867  data: 0.0001  max mem: 11902
[17:42:37.073412] Test:  [230/345]  eta: 0:00:09  loss: 0.1228 (0.1240)  time: 0.0870  data: 0.0001  max mem: 11902
[17:42:37.949662] Test:  [240/345]  eta: 0:00:08  loss: 0.1267 (0.1238)  time: 0.0874  data: 0.0001  max mem: 11902
[17:42:38.829344] Test:  [250/345]  eta: 0:00:08  loss: 0.1191 (0.1238)  time: 0.0877  data: 0.0001  max mem: 11902
[17:42:39.713337] Test:  [260/345]  eta: 0:00:07  loss: 0.1265 (0.1243)  time: 0.0881  data: 0.0001  max mem: 11902
[17:42:40.600510] Test:  [270/345]  eta: 0:00:06  loss: 0.1294 (0.1246)  time: 0.0885  data: 0.0001  max mem: 11902
[17:42:41.492164] Test:  [280/345]  eta: 0:00:05  loss: 0.1231 (0.1243)  time: 0.0889  data: 0.0001  max mem: 11902
[17:42:42.386513] Test:  [290/345]  eta: 0:00:04  loss: 0.1199 (0.1243)  time: 0.0892  data: 0.0001  max mem: 11902
[17:42:43.284841] Test:  [300/345]  eta: 0:00:03  loss: 0.1223 (0.1244)  time: 0.0896  data: 0.0001  max mem: 11902
[17:42:44.186303] Test:  [310/345]  eta: 0:00:03  loss: 0.1321 (0.1247)  time: 0.0899  data: 0.0001  max mem: 11902
[17:42:45.091159] Test:  [320/345]  eta: 0:00:02  loss: 0.1253 (0.1246)  time: 0.0902  data: 0.0001  max mem: 11902
[17:42:45.998264] Test:  [330/345]  eta: 0:00:01  loss: 0.1178 (0.1245)  time: 0.0905  data: 0.0001  max mem: 11902
[17:42:46.909502] Test:  [340/345]  eta: 0:00:00  loss: 0.1178 (0.1245)  time: 0.0909  data: 0.0001  max mem: 11902
[17:42:47.274315] Test:  [344/345]  eta: 0:00:00  loss: 0.1243 (0.1245)  time: 0.0910  data: 0.0001  max mem: 11902
[17:42:47.350909] Test: Total time: 0:00:29 (0.0867 s / it)
[17:42:57.334253] Test:  [ 0/57]  eta: 0:00:27  loss: 0.4559 (0.4559)  time: 0.4831  data: 0.4059  max mem: 11902
[17:42:58.122151] Test:  [10/57]  eta: 0:00:05  loss: 0.4309 (0.4454)  time: 0.1155  data: 0.0370  max mem: 11902
[17:42:58.913592] Test:  [20/57]  eta: 0:00:03  loss: 0.4303 (0.4362)  time: 0.0789  data: 0.0001  max mem: 11902
[17:42:59.710695] Test:  [30/57]  eta: 0:00:02  loss: 0.2718 (0.3794)  time: 0.0794  data: 0.0001  max mem: 11902
[17:43:00.512596] Test:  [40/57]  eta: 0:00:01  loss: 0.2710 (0.3591)  time: 0.0799  data: 0.0001  max mem: 11902
[17:43:01.315302] Test:  [50/57]  eta: 0:00:00  loss: 0.3056 (0.3632)  time: 0.0802  data: 0.0001  max mem: 11902
[17:43:01.750726] Test:  [56/57]  eta: 0:00:00  loss: 0.3580 (0.3946)  time: 0.0779  data: 0.0001  max mem: 11902
[17:43:01.809167] Test: Total time: 0:00:04 (0.0870 s / it)
[17:43:03.560708] Dice score of the network on the train images: 0.874600, val images: 0.737532
[17:43:03.564499] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:43:04.150252] Epoch: [39]  [  0/345]  eta: 0:03:21  lr: 0.000037  loss: 0.1193 (0.1193)  time: 0.5846  data: 0.3384  max mem: 11902
[17:43:09.098324] Epoch: [39]  [ 20/345]  eta: 0:01:25  lr: 0.000037  loss: 0.1274 (0.1279)  time: 0.2473  data: 0.0001  max mem: 11902
[17:43:13.978907] Epoch: [39]  [ 40/345]  eta: 0:01:17  lr: 0.000036  loss: 0.1229 (0.1266)  time: 0.2440  data: 0.0001  max mem: 11902
[17:43:18.863006] Epoch: [39]  [ 60/345]  eta: 0:01:11  lr: 0.000036  loss: 0.1307 (0.1294)  time: 0.2442  data: 0.0001  max mem: 11902
[17:43:23.749682] Epoch: [39]  [ 80/345]  eta: 0:01:06  lr: 0.000036  loss: 0.1341 (0.1306)  time: 0.2443  data: 0.0001  max mem: 11902
[17:43:28.642015] Epoch: [39]  [100/345]  eta: 0:01:00  lr: 0.000035  loss: 0.1259 (0.1299)  time: 0.2446  data: 0.0001  max mem: 11902
[17:43:33.530532] Epoch: [39]  [120/345]  eta: 0:00:55  lr: 0.000035  loss: 0.1223 (0.1293)  time: 0.2444  data: 0.0001  max mem: 11902
[17:43:38.421023] Epoch: [39]  [140/345]  eta: 0:00:50  lr: 0.000035  loss: 0.1291 (0.1295)  time: 0.2445  data: 0.0001  max mem: 11902
[17:43:43.317482] Epoch: [39]  [160/345]  eta: 0:00:45  lr: 0.000034  loss: 0.1357 (0.1303)  time: 0.2448  data: 0.0001  max mem: 11902
[17:43:48.217738] Epoch: [39]  [180/345]  eta: 0:00:40  lr: 0.000034  loss: 0.1255 (0.1295)  time: 0.2450  data: 0.0001  max mem: 11902
[17:43:53.118869] Epoch: [39]  [200/345]  eta: 0:00:35  lr: 0.000034  loss: 0.1259 (0.1296)  time: 0.2450  data: 0.0001  max mem: 11902
[17:43:58.022291] Epoch: [39]  [220/345]  eta: 0:00:30  lr: 0.000033  loss: 0.1349 (0.1306)  time: 0.2451  data: 0.0001  max mem: 11902
[17:44:02.932417] Epoch: [39]  [240/345]  eta: 0:00:25  lr: 0.000033  loss: 0.1321 (0.1306)  time: 0.2455  data: 0.0001  max mem: 11902
[17:44:07.837236] Epoch: [39]  [260/345]  eta: 0:00:20  lr: 0.000033  loss: 0.1245 (0.1304)  time: 0.2452  data: 0.0001  max mem: 11902
[17:44:12.741980] Epoch: [39]  [280/345]  eta: 0:00:15  lr: 0.000032  loss: 0.1200 (0.1298)  time: 0.2452  data: 0.0001  max mem: 11902
[17:44:17.647939] Epoch: [39]  [300/345]  eta: 0:00:11  lr: 0.000032  loss: 0.1257 (0.1296)  time: 0.2453  data: 0.0001  max mem: 11902
[17:44:22.561310] Epoch: [39]  [320/345]  eta: 0:00:06  lr: 0.000032  loss: 0.1294 (0.1297)  time: 0.2456  data: 0.0001  max mem: 11902
[17:44:27.468093] Epoch: [39]  [340/345]  eta: 0:00:01  lr: 0.000031  loss: 0.1254 (0.1297)  time: 0.2453  data: 0.0001  max mem: 11902
[17:44:28.449333] Epoch: [39]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 0.1232 (0.1296)  time: 0.2453  data: 0.0001  max mem: 11902
[17:44:28.509620] Epoch: [39] Total time: 0:01:24 (0.2462 s / it)
[17:44:28.509995] Averaged stats: lr: 0.000031  loss: 0.1232 (0.1296)
[17:44:28.925573] Test:  [  0/345]  eta: 0:02:22  loss: 0.0998 (0.0998)  time: 0.4121  data: 0.3349  max mem: 11902
[17:44:29.726281] Test:  [ 10/345]  eta: 0:00:36  loss: 0.1283 (0.1241)  time: 0.1101  data: 0.0312  max mem: 11902
[17:44:30.523631] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1283 (0.1274)  time: 0.0798  data: 0.0005  max mem: 11902
[17:44:31.324809] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1200 (0.1240)  time: 0.0798  data: 0.0001  max mem: 11902
[17:44:32.127706] Test:  [ 40/345]  eta: 0:00:26  loss: 0.1167 (0.1241)  time: 0.0801  data: 0.0001  max mem: 11902
[17:44:32.935828] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1147 (0.1228)  time: 0.0805  data: 0.0001  max mem: 11902
[17:44:33.748102] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1191 (0.1234)  time: 0.0809  data: 0.0001  max mem: 11902
[17:44:34.563425] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1170 (0.1218)  time: 0.0813  data: 0.0001  max mem: 11902
[17:44:35.381859] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1141 (0.1209)  time: 0.0816  data: 0.0001  max mem: 11902
[17:44:36.205333] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1156 (0.1212)  time: 0.0820  data: 0.0001  max mem: 11902
[17:44:37.030675] Test:  [100/345]  eta: 0:00:20  loss: 0.1131 (0.1214)  time: 0.0824  data: 0.0001  max mem: 11902
[17:44:37.861017] Test:  [110/345]  eta: 0:00:19  loss: 0.1178 (0.1216)  time: 0.0827  data: 0.0001  max mem: 11902
[17:44:38.693669] Test:  [120/345]  eta: 0:00:18  loss: 0.1167 (0.1213)  time: 0.0831  data: 0.0001  max mem: 11902
[17:44:39.530530] Test:  [130/345]  eta: 0:00:18  loss: 0.1108 (0.1209)  time: 0.0834  data: 0.0001  max mem: 11902
[17:44:40.371329] Test:  [140/345]  eta: 0:00:17  loss: 0.1162 (0.1210)  time: 0.0838  data: 0.0001  max mem: 11902
[17:44:41.214654] Test:  [150/345]  eta: 0:00:16  loss: 0.1189 (0.1212)  time: 0.0841  data: 0.0001  max mem: 11902
[17:44:42.062702] Test:  [160/345]  eta: 0:00:15  loss: 0.1205 (0.1214)  time: 0.0845  data: 0.0001  max mem: 11902
[17:44:42.913981] Test:  [170/345]  eta: 0:00:14  loss: 0.1153 (0.1214)  time: 0.0849  data: 0.0001  max mem: 11902
[17:44:43.769054] Test:  [180/345]  eta: 0:00:13  loss: 0.1183 (0.1214)  time: 0.0852  data: 0.0001  max mem: 11902
[17:44:44.627843] Test:  [190/345]  eta: 0:00:13  loss: 0.1183 (0.1211)  time: 0.0856  data: 0.0001  max mem: 11902
[17:44:45.489918] Test:  [200/345]  eta: 0:00:12  loss: 0.1204 (0.1214)  time: 0.0860  data: 0.0001  max mem: 11902
[17:44:46.355922] Test:  [210/345]  eta: 0:00:11  loss: 0.1205 (0.1215)  time: 0.0863  data: 0.0001  max mem: 11902
[17:44:47.225516] Test:  [220/345]  eta: 0:00:10  loss: 0.1178 (0.1217)  time: 0.0867  data: 0.0001  max mem: 11902
[17:44:48.098867] Test:  [230/345]  eta: 0:00:09  loss: 0.1158 (0.1214)  time: 0.0871  data: 0.0001  max mem: 11902
[17:44:48.975150] Test:  [240/345]  eta: 0:00:08  loss: 0.1158 (0.1215)  time: 0.0874  data: 0.0001  max mem: 11902
[17:44:49.856876] Test:  [250/345]  eta: 0:00:08  loss: 0.1206 (0.1215)  time: 0.0878  data: 0.0001  max mem: 11902
[17:44:50.739877] Test:  [260/345]  eta: 0:00:07  loss: 0.1206 (0.1215)  time: 0.0881  data: 0.0001  max mem: 11902
[17:44:51.627455] Test:  [270/345]  eta: 0:00:06  loss: 0.1166 (0.1214)  time: 0.0884  data: 0.0001  max mem: 11902
[17:44:52.518571] Test:  [280/345]  eta: 0:00:05  loss: 0.1098 (0.1211)  time: 0.0889  data: 0.0001  max mem: 11902
[17:44:53.412442] Test:  [290/345]  eta: 0:00:04  loss: 0.1137 (0.1212)  time: 0.0892  data: 0.0001  max mem: 11902
[17:44:54.309198] Test:  [300/345]  eta: 0:00:03  loss: 0.1171 (0.1212)  time: 0.0895  data: 0.0001  max mem: 11902
[17:44:55.211207] Test:  [310/345]  eta: 0:00:03  loss: 0.1173 (0.1214)  time: 0.0899  data: 0.0001  max mem: 11902
[17:44:56.115310] Test:  [320/345]  eta: 0:00:02  loss: 0.1217 (0.1214)  time: 0.0902  data: 0.0001  max mem: 11902
[17:44:57.023224] Test:  [330/345]  eta: 0:00:01  loss: 0.1217 (0.1216)  time: 0.0905  data: 0.0001  max mem: 11902
[17:44:57.935087] Test:  [340/345]  eta: 0:00:00  loss: 0.1171 (0.1215)  time: 0.0909  data: 0.0001  max mem: 11902
[17:44:58.299938] Test:  [344/345]  eta: 0:00:00  loss: 0.1171 (0.1215)  time: 0.0910  data: 0.0001  max mem: 11902
[17:44:58.369232] Test: Total time: 0:00:29 (0.0865 s / it)
[17:45:08.302212] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4582 (0.4582)  time: 0.4037  data: 0.3264  max mem: 11902
[17:45:09.099066] Test:  [10/57]  eta: 0:00:05  loss: 0.4278 (0.4443)  time: 0.1091  data: 0.0305  max mem: 11902
[17:45:09.890819] Test:  [20/57]  eta: 0:00:03  loss: 0.4278 (0.4356)  time: 0.0794  data: 0.0005  max mem: 11902
[17:45:10.687620] Test:  [30/57]  eta: 0:00:02  loss: 0.2783 (0.3814)  time: 0.0794  data: 0.0001  max mem: 11902
[17:45:11.488397] Test:  [40/57]  eta: 0:00:01  loss: 0.2740 (0.3620)  time: 0.0798  data: 0.0001  max mem: 11902
[17:45:12.291881] Test:  [50/57]  eta: 0:00:00  loss: 0.3145 (0.3659)  time: 0.0802  data: 0.0001  max mem: 11902
[17:45:12.727390] Test:  [56/57]  eta: 0:00:00  loss: 0.3636 (0.3947)  time: 0.0779  data: 0.0000  max mem: 11902
[17:45:12.787973] Test: Total time: 0:00:04 (0.0858 s / it)
[17:45:14.557076] Dice score of the network on the train images: 0.878761, val images: 0.731973
[17:45:14.560918] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:45:15.216512] Epoch: [40]  [  0/345]  eta: 0:03:45  lr: 0.000031  loss: 0.1389 (0.1389)  time: 0.6546  data: 0.4091  max mem: 11902
[17:45:20.103214] Epoch: [40]  [ 20/345]  eta: 0:01:25  lr: 0.000031  loss: 0.1249 (0.1282)  time: 0.2443  data: 0.0001  max mem: 11902
[17:45:24.992346] Epoch: [40]  [ 40/345]  eta: 0:01:17  lr: 0.000031  loss: 0.1150 (0.1227)  time: 0.2444  data: 0.0001  max mem: 11902
[17:45:29.890876] Epoch: [40]  [ 60/345]  eta: 0:01:11  lr: 0.000030  loss: 0.1259 (0.1238)  time: 0.2449  data: 0.0001  max mem: 11902
[17:45:34.786240] Epoch: [40]  [ 80/345]  eta: 0:01:06  lr: 0.000030  loss: 0.1221 (0.1230)  time: 0.2447  data: 0.0001  max mem: 11902
[17:45:39.691177] Epoch: [40]  [100/345]  eta: 0:01:00  lr: 0.000030  loss: 0.1265 (0.1241)  time: 0.2452  data: 0.0001  max mem: 11902
[17:45:44.591958] Epoch: [40]  [120/345]  eta: 0:00:55  lr: 0.000029  loss: 0.1168 (0.1242)  time: 0.2450  data: 0.0001  max mem: 11902
[17:45:49.495661] Epoch: [40]  [140/345]  eta: 0:00:50  lr: 0.000029  loss: 0.1258 (0.1249)  time: 0.2451  data: 0.0001  max mem: 11902
[17:45:54.396885] Epoch: [40]  [160/345]  eta: 0:00:45  lr: 0.000029  loss: 0.1184 (0.1246)  time: 0.2450  data: 0.0001  max mem: 11902
[17:45:59.308509] Epoch: [40]  [180/345]  eta: 0:00:40  lr: 0.000028  loss: 0.1243 (0.1246)  time: 0.2455  data: 0.0001  max mem: 11902
[17:46:04.214162] Epoch: [40]  [200/345]  eta: 0:00:35  lr: 0.000028  loss: 0.1351 (0.1256)  time: 0.2452  data: 0.0001  max mem: 11902
[17:46:09.123178] Epoch: [40]  [220/345]  eta: 0:00:30  lr: 0.000028  loss: 0.1229 (0.1257)  time: 0.2454  data: 0.0001  max mem: 11902
[17:46:14.034568] Epoch: [40]  [240/345]  eta: 0:00:25  lr: 0.000027  loss: 0.1244 (0.1260)  time: 0.2455  data: 0.0001  max mem: 11902
[17:46:18.950325] Epoch: [40]  [260/345]  eta: 0:00:20  lr: 0.000027  loss: 0.1234 (0.1260)  time: 0.2457  data: 0.0001  max mem: 11902
[17:46:23.867397] Epoch: [40]  [280/345]  eta: 0:00:16  lr: 0.000027  loss: 0.1339 (0.1266)  time: 0.2458  data: 0.0001  max mem: 11902
[17:46:28.782849] Epoch: [40]  [300/345]  eta: 0:00:11  lr: 0.000026  loss: 0.1225 (0.1266)  time: 0.2457  data: 0.0001  max mem: 11902
[17:46:33.694989] Epoch: [40]  [320/345]  eta: 0:00:06  lr: 0.000026  loss: 0.1262 (0.1266)  time: 0.2456  data: 0.0001  max mem: 11902
[17:46:38.602766] Epoch: [40]  [340/345]  eta: 0:00:01  lr: 0.000026  loss: 0.1239 (0.1266)  time: 0.2453  data: 0.0001  max mem: 11902
[17:46:39.584366] Epoch: [40]  [344/345]  eta: 0:00:00  lr: 0.000026  loss: 0.1241 (0.1267)  time: 0.2452  data: 0.0001  max mem: 11902
[17:46:39.657731] Epoch: [40] Total time: 0:01:25 (0.2467 s / it)
[17:46:39.657988] Averaged stats: lr: 0.000026  loss: 0.1241 (0.1267)
[17:46:40.084722] Test:  [  0/345]  eta: 0:02:25  loss: 0.1190 (0.1190)  time: 0.4229  data: 0.3458  max mem: 11902
[17:46:40.906070] Test:  [ 10/345]  eta: 0:00:37  loss: 0.1190 (0.1182)  time: 0.1130  data: 0.0341  max mem: 11902
[17:46:41.703030] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1190 (0.1176)  time: 0.0808  data: 0.0015  max mem: 11902
[17:46:42.504397] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1213 (0.1183)  time: 0.0798  data: 0.0001  max mem: 11902
[17:46:43.309365] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1154 (0.1185)  time: 0.0802  data: 0.0001  max mem: 11902
[17:46:44.117307] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1154 (0.1201)  time: 0.0806  data: 0.0001  max mem: 11902
[17:46:44.928714] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1129 (0.1190)  time: 0.0809  data: 0.0001  max mem: 11902
[17:46:45.744681] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1154 (0.1198)  time: 0.0813  data: 0.0001  max mem: 11902
[17:46:46.563759] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1182 (0.1201)  time: 0.0817  data: 0.0001  max mem: 11902
[17:46:47.385695] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1222 (0.1209)  time: 0.0820  data: 0.0001  max mem: 11902
[17:46:48.211113] Test:  [100/345]  eta: 0:00:20  loss: 0.1222 (0.1221)  time: 0.0823  data: 0.0001  max mem: 11902
[17:46:49.040959] Test:  [110/345]  eta: 0:00:19  loss: 0.1218 (0.1224)  time: 0.0827  data: 0.0001  max mem: 11902
[17:46:49.873677] Test:  [120/345]  eta: 0:00:18  loss: 0.1201 (0.1225)  time: 0.0830  data: 0.0001  max mem: 11902
[17:46:50.710722] Test:  [130/345]  eta: 0:00:18  loss: 0.1201 (0.1225)  time: 0.0834  data: 0.0001  max mem: 11902
[17:46:51.551620] Test:  [140/345]  eta: 0:00:17  loss: 0.1143 (0.1224)  time: 0.0838  data: 0.0001  max mem: 11902
[17:46:52.396132] Test:  [150/345]  eta: 0:00:16  loss: 0.1091 (0.1220)  time: 0.0842  data: 0.0001  max mem: 11902
[17:46:53.244925] Test:  [160/345]  eta: 0:00:15  loss: 0.1098 (0.1214)  time: 0.0846  data: 0.0001  max mem: 11902
[17:46:54.094979] Test:  [170/345]  eta: 0:00:14  loss: 0.1098 (0.1208)  time: 0.0849  data: 0.0001  max mem: 11902
[17:46:54.949339] Test:  [180/345]  eta: 0:00:13  loss: 0.1122 (0.1206)  time: 0.0851  data: 0.0001  max mem: 11902
[17:46:55.807651] Test:  [190/345]  eta: 0:00:13  loss: 0.1152 (0.1206)  time: 0.0855  data: 0.0001  max mem: 11902
[17:46:56.671177] Test:  [200/345]  eta: 0:00:12  loss: 0.1135 (0.1204)  time: 0.0860  data: 0.0001  max mem: 11902
[17:46:57.537357] Test:  [210/345]  eta: 0:00:11  loss: 0.1104 (0.1200)  time: 0.0864  data: 0.0001  max mem: 11902
[17:46:58.407698] Test:  [220/345]  eta: 0:00:10  loss: 0.1106 (0.1198)  time: 0.0868  data: 0.0001  max mem: 11902
[17:46:59.280833] Test:  [230/345]  eta: 0:00:09  loss: 0.1186 (0.1198)  time: 0.0871  data: 0.0001  max mem: 11902
[17:47:00.157330] Test:  [240/345]  eta: 0:00:08  loss: 0.1212 (0.1200)  time: 0.0874  data: 0.0001  max mem: 11902
[17:47:01.038033] Test:  [250/345]  eta: 0:00:08  loss: 0.1200 (0.1199)  time: 0.0878  data: 0.0001  max mem: 11902
[17:47:01.920921] Test:  [260/345]  eta: 0:00:07  loss: 0.1124 (0.1196)  time: 0.0881  data: 0.0001  max mem: 11902
[17:47:02.809767] Test:  [270/345]  eta: 0:00:06  loss: 0.1097 (0.1193)  time: 0.0885  data: 0.0001  max mem: 11902
[17:47:03.700435] Test:  [280/345]  eta: 0:00:05  loss: 0.1149 (0.1194)  time: 0.0889  data: 0.0001  max mem: 11902
[17:47:04.594781] Test:  [290/345]  eta: 0:00:04  loss: 0.1149 (0.1196)  time: 0.0892  data: 0.0001  max mem: 11902
[17:47:05.493953] Test:  [300/345]  eta: 0:00:03  loss: 0.1095 (0.1195)  time: 0.0896  data: 0.0001  max mem: 11902
[17:47:06.397476] Test:  [310/345]  eta: 0:00:03  loss: 0.1107 (0.1195)  time: 0.0900  data: 0.0001  max mem: 11902
[17:47:07.301245] Test:  [320/345]  eta: 0:00:02  loss: 0.1123 (0.1193)  time: 0.0903  data: 0.0001  max mem: 11902
[17:47:08.211037] Test:  [330/345]  eta: 0:00:01  loss: 0.1107 (0.1193)  time: 0.0906  data: 0.0001  max mem: 11902
[17:47:09.122253] Test:  [340/345]  eta: 0:00:00  loss: 0.1162 (0.1193)  time: 0.0910  data: 0.0001  max mem: 11902
[17:47:09.487714] Test:  [344/345]  eta: 0:00:00  loss: 0.1162 (0.1193)  time: 0.0911  data: 0.0001  max mem: 11902
[17:47:09.559775] Test: Total time: 0:00:29 (0.0867 s / it)
[17:47:19.527789] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4817 (0.4817)  time: 0.4451  data: 0.3677  max mem: 11902
[17:47:20.318125] Test:  [10/57]  eta: 0:00:05  loss: 0.4484 (0.4657)  time: 0.1122  data: 0.0335  max mem: 11902
[17:47:21.110470] Test:  [20/57]  eta: 0:00:03  loss: 0.4422 (0.4557)  time: 0.0790  data: 0.0001  max mem: 11902
[17:47:21.906741] Test:  [30/57]  eta: 0:00:02  loss: 0.2802 (0.3984)  time: 0.0793  data: 0.0001  max mem: 11902
[17:47:22.708533] Test:  [40/57]  eta: 0:00:01  loss: 0.2802 (0.3778)  time: 0.0798  data: 0.0001  max mem: 11902
[17:47:23.511016] Test:  [50/57]  eta: 0:00:00  loss: 0.3267 (0.3810)  time: 0.0802  data: 0.0001  max mem: 11902
[17:47:23.946641] Test:  [56/57]  eta: 0:00:00  loss: 0.3707 (0.4129)  time: 0.0779  data: 0.0001  max mem: 11902
[17:47:24.018868] Test: Total time: 0:00:04 (0.0866 s / it)
[17:47:25.761489] Dice score of the network on the train images: 0.881672, val images: 0.720501
[17:47:25.765032] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:47:26.382696] Epoch: [41]  [  0/345]  eta: 0:03:32  lr: 0.000026  loss: 0.1427 (0.1427)  time: 0.6169  data: 0.3709  max mem: 11902
[17:47:31.264101] Epoch: [41]  [ 20/345]  eta: 0:01:25  lr: 0.000025  loss: 0.1254 (0.1298)  time: 0.2440  data: 0.0001  max mem: 11902
[17:47:36.129619] Epoch: [41]  [ 40/345]  eta: 0:01:17  lr: 0.000025  loss: 0.1188 (0.1265)  time: 0.2432  data: 0.0001  max mem: 11902
[17:47:41.001992] Epoch: [41]  [ 60/345]  eta: 0:01:11  lr: 0.000025  loss: 0.1156 (0.1250)  time: 0.2436  data: 0.0001  max mem: 11902
[17:47:45.894876] Epoch: [41]  [ 80/345]  eta: 0:01:05  lr: 0.000025  loss: 0.1236 (0.1252)  time: 0.2446  data: 0.0001  max mem: 11902
[17:47:50.785657] Epoch: [41]  [100/345]  eta: 0:01:00  lr: 0.000024  loss: 0.1194 (0.1255)  time: 0.2445  data: 0.0001  max mem: 11902
[17:47:55.681549] Epoch: [41]  [120/345]  eta: 0:00:55  lr: 0.000024  loss: 0.1192 (0.1253)  time: 0.2447  data: 0.0001  max mem: 11902
[17:48:00.575264] Epoch: [41]  [140/345]  eta: 0:00:50  lr: 0.000024  loss: 0.1262 (0.1262)  time: 0.2446  data: 0.0001  max mem: 11902
[17:48:05.465194] Epoch: [41]  [160/345]  eta: 0:00:45  lr: 0.000023  loss: 0.1221 (0.1262)  time: 0.2445  data: 0.0001  max mem: 11902
[17:48:10.357135] Epoch: [41]  [180/345]  eta: 0:00:40  lr: 0.000023  loss: 0.1186 (0.1259)  time: 0.2446  data: 0.0001  max mem: 11902
[17:48:15.265776] Epoch: [41]  [200/345]  eta: 0:00:35  lr: 0.000023  loss: 0.1210 (0.1259)  time: 0.2454  data: 0.0001  max mem: 11902
[17:48:20.169284] Epoch: [41]  [220/345]  eta: 0:00:30  lr: 0.000022  loss: 0.1224 (0.1259)  time: 0.2451  data: 0.0001  max mem: 11902
[17:48:25.062221] Epoch: [41]  [240/345]  eta: 0:00:25  lr: 0.000022  loss: 0.1300 (0.1262)  time: 0.2446  data: 0.0001  max mem: 11902
[17:48:29.972645] Epoch: [41]  [260/345]  eta: 0:00:20  lr: 0.000022  loss: 0.1185 (0.1258)  time: 0.2455  data: 0.0001  max mem: 11902
[17:48:34.886985] Epoch: [41]  [280/345]  eta: 0:00:15  lr: 0.000022  loss: 0.1221 (0.1257)  time: 0.2457  data: 0.0001  max mem: 11902
[17:48:39.805403] Epoch: [41]  [300/345]  eta: 0:00:11  lr: 0.000021  loss: 0.1177 (0.1254)  time: 0.2459  data: 0.0001  max mem: 11902
[17:48:44.720139] Epoch: [41]  [320/345]  eta: 0:00:06  lr: 0.000021  loss: 0.1184 (0.1252)  time: 0.2457  data: 0.0001  max mem: 11902
[17:48:49.627843] Epoch: [41]  [340/345]  eta: 0:00:01  lr: 0.000021  loss: 0.1163 (0.1249)  time: 0.2453  data: 0.0001  max mem: 11902
[17:48:50.608194] Epoch: [41]  [344/345]  eta: 0:00:00  lr: 0.000021  loss: 0.1130 (0.1248)  time: 0.2452  data: 0.0001  max mem: 11902
[17:48:50.677947] Epoch: [41] Total time: 0:01:24 (0.2461 s / it)
[17:48:50.678300] Averaged stats: lr: 0.000021  loss: 0.1130 (0.1248)
[17:48:51.133641] Test:  [  0/345]  eta: 0:02:35  loss: 0.1339 (0.1339)  time: 0.4504  data: 0.3731  max mem: 11902
[17:48:51.935980] Test:  [ 10/345]  eta: 0:00:38  loss: 0.1176 (0.1210)  time: 0.1138  data: 0.0347  max mem: 11902
[17:48:52.736134] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1177 (0.1219)  time: 0.0800  data: 0.0005  max mem: 11902
[17:48:53.538079] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1149 (0.1182)  time: 0.0800  data: 0.0001  max mem: 11902
[17:48:54.342385] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1104 (0.1179)  time: 0.0802  data: 0.0001  max mem: 11902
[17:48:55.149851] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1104 (0.1182)  time: 0.0805  data: 0.0001  max mem: 11902
[17:48:55.962401] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1115 (0.1179)  time: 0.0809  data: 0.0001  max mem: 11902
[17:48:56.777432] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1130 (0.1168)  time: 0.0813  data: 0.0001  max mem: 11902
[17:48:57.595435] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1131 (0.1174)  time: 0.0816  data: 0.0001  max mem: 11902
[17:48:58.418359] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1172 (0.1169)  time: 0.0820  data: 0.0001  max mem: 11902
[17:48:59.243598] Test:  [100/345]  eta: 0:00:20  loss: 0.1064 (0.1163)  time: 0.0823  data: 0.0001  max mem: 11902
[17:49:00.072287] Test:  [110/345]  eta: 0:00:19  loss: 0.1110 (0.1165)  time: 0.0826  data: 0.0001  max mem: 11902
[17:49:00.906252] Test:  [120/345]  eta: 0:00:18  loss: 0.1149 (0.1172)  time: 0.0831  data: 0.0001  max mem: 11902
[17:49:01.743740] Test:  [130/345]  eta: 0:00:18  loss: 0.1123 (0.1168)  time: 0.0835  data: 0.0001  max mem: 11902
[17:49:02.584803] Test:  [140/345]  eta: 0:00:17  loss: 0.1119 (0.1168)  time: 0.0839  data: 0.0001  max mem: 11902
[17:49:03.427530] Test:  [150/345]  eta: 0:00:16  loss: 0.1114 (0.1166)  time: 0.0841  data: 0.0001  max mem: 11902
[17:49:04.273981] Test:  [160/345]  eta: 0:00:15  loss: 0.1122 (0.1166)  time: 0.0844  data: 0.0001  max mem: 11902
[17:49:05.125529] Test:  [170/345]  eta: 0:00:14  loss: 0.1229 (0.1170)  time: 0.0848  data: 0.0001  max mem: 11902
[17:49:05.980817] Test:  [180/345]  eta: 0:00:13  loss: 0.1221 (0.1174)  time: 0.0853  data: 0.0001  max mem: 11902
[17:49:06.838550] Test:  [190/345]  eta: 0:00:13  loss: 0.1164 (0.1174)  time: 0.0856  data: 0.0001  max mem: 11902
[17:49:07.701211] Test:  [200/345]  eta: 0:00:12  loss: 0.1164 (0.1175)  time: 0.0859  data: 0.0001  max mem: 11902
[17:49:08.566920] Test:  [210/345]  eta: 0:00:11  loss: 0.1132 (0.1173)  time: 0.0863  data: 0.0001  max mem: 11902
[17:49:09.435204] Test:  [220/345]  eta: 0:00:10  loss: 0.1132 (0.1176)  time: 0.0866  data: 0.0001  max mem: 11902
[17:49:10.307860] Test:  [230/345]  eta: 0:00:09  loss: 0.1178 (0.1178)  time: 0.0870  data: 0.0001  max mem: 11902
[17:49:11.183381] Test:  [240/345]  eta: 0:00:08  loss: 0.1117 (0.1177)  time: 0.0873  data: 0.0001  max mem: 11902
[17:49:12.062982] Test:  [250/345]  eta: 0:00:08  loss: 0.1098 (0.1172)  time: 0.0877  data: 0.0001  max mem: 11902
[17:49:12.946485] Test:  [260/345]  eta: 0:00:07  loss: 0.1082 (0.1171)  time: 0.0881  data: 0.0001  max mem: 11902
[17:49:13.833746] Test:  [270/345]  eta: 0:00:06  loss: 0.1112 (0.1170)  time: 0.0885  data: 0.0001  max mem: 11902
[17:49:14.725059] Test:  [280/345]  eta: 0:00:05  loss: 0.1125 (0.1171)  time: 0.0889  data: 0.0001  max mem: 11902
[17:49:15.619235] Test:  [290/345]  eta: 0:00:04  loss: 0.1233 (0.1174)  time: 0.0892  data: 0.0001  max mem: 11902
[17:49:16.516749] Test:  [300/345]  eta: 0:00:03  loss: 0.1095 (0.1170)  time: 0.0895  data: 0.0001  max mem: 11902
[17:49:17.417874] Test:  [310/345]  eta: 0:00:03  loss: 0.1088 (0.1171)  time: 0.0899  data: 0.0001  max mem: 11902
[17:49:18.321768] Test:  [320/345]  eta: 0:00:02  loss: 0.1188 (0.1171)  time: 0.0902  data: 0.0001  max mem: 11902
[17:49:19.230967] Test:  [330/345]  eta: 0:00:01  loss: 0.1160 (0.1173)  time: 0.0906  data: 0.0001  max mem: 11902
[17:49:20.143828] Test:  [340/345]  eta: 0:00:00  loss: 0.1155 (0.1171)  time: 0.0910  data: 0.0001  max mem: 11902
[17:49:20.509406] Test:  [344/345]  eta: 0:00:00  loss: 0.1127 (0.1171)  time: 0.0912  data: 0.0001  max mem: 11902
[17:49:20.574371] Test: Total time: 0:00:29 (0.0866 s / it)
[17:49:30.514356] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4722 (0.4722)  time: 0.4160  data: 0.3387  max mem: 11902
[17:49:31.306399] Test:  [10/57]  eta: 0:00:05  loss: 0.4467 (0.4482)  time: 0.1097  data: 0.0313  max mem: 11902
[17:49:32.100491] Test:  [20/57]  eta: 0:00:03  loss: 0.4369 (0.4413)  time: 0.0792  data: 0.0003  max mem: 11902
[17:49:32.896098] Test:  [30/57]  eta: 0:00:02  loss: 0.2798 (0.3838)  time: 0.0794  data: 0.0001  max mem: 11902
[17:49:33.695428] Test:  [40/57]  eta: 0:00:01  loss: 0.2798 (0.3621)  time: 0.0797  data: 0.0001  max mem: 11902
[17:49:34.497389] Test:  [50/57]  eta: 0:00:00  loss: 0.3151 (0.3652)  time: 0.0800  data: 0.0001  max mem: 11902
[17:49:34.934112] Test:  [56/57]  eta: 0:00:00  loss: 0.3515 (0.3945)  time: 0.0779  data: 0.0000  max mem: 11902
[17:49:35.005125] Test: Total time: 0:00:04 (0.0861 s / it)
[17:49:36.756706] Dice score of the network on the train images: 0.882590, val images: 0.744583
[17:49:36.760071] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:49:37.347218] Epoch: [42]  [  0/345]  eta: 0:03:22  lr: 0.000021  loss: 0.1333 (0.1333)  time: 0.5863  data: 0.3415  max mem: 11902
[17:49:42.205934] Epoch: [42]  [ 20/345]  eta: 0:01:24  lr: 0.000020  loss: 0.1236 (0.1238)  time: 0.2429  data: 0.0001  max mem: 11902
[17:49:47.071758] Epoch: [42]  [ 40/345]  eta: 0:01:16  lr: 0.000020  loss: 0.1118 (0.1207)  time: 0.2432  data: 0.0001  max mem: 11902
[17:49:51.953264] Epoch: [42]  [ 60/345]  eta: 0:01:10  lr: 0.000020  loss: 0.1239 (0.1228)  time: 0.2440  data: 0.0001  max mem: 11902
[17:49:56.850683] Epoch: [42]  [ 80/345]  eta: 0:01:05  lr: 0.000020  loss: 0.1164 (0.1228)  time: 0.2448  data: 0.0001  max mem: 11902
[17:50:01.735812] Epoch: [42]  [100/345]  eta: 0:01:00  lr: 0.000019  loss: 0.1218 (0.1230)  time: 0.2442  data: 0.0001  max mem: 11902
[17:50:06.609934] Epoch: [42]  [120/345]  eta: 0:00:55  lr: 0.000019  loss: 0.1198 (0.1225)  time: 0.2437  data: 0.0001  max mem: 11902
[17:50:11.489873] Epoch: [42]  [140/345]  eta: 0:00:50  lr: 0.000019  loss: 0.1235 (0.1225)  time: 0.2440  data: 0.0001  max mem: 11902
[17:50:16.442437] Epoch: [42]  [160/345]  eta: 0:00:45  lr: 0.000018  loss: 0.1221 (0.1226)  time: 0.2476  data: 0.0001  max mem: 11902
[17:50:21.349882] Epoch: [42]  [180/345]  eta: 0:00:40  lr: 0.000018  loss: 0.1272 (0.1238)  time: 0.2453  data: 0.0001  max mem: 11902
[17:50:26.254601] Epoch: [42]  [200/345]  eta: 0:00:35  lr: 0.000018  loss: 0.1228 (0.1238)  time: 0.2452  data: 0.0001  max mem: 11902
[17:50:31.159403] Epoch: [42]  [220/345]  eta: 0:00:30  lr: 0.000018  loss: 0.1150 (0.1232)  time: 0.2452  data: 0.0001  max mem: 11902
[17:50:36.070491] Epoch: [42]  [240/345]  eta: 0:00:25  lr: 0.000017  loss: 0.1152 (0.1230)  time: 0.2455  data: 0.0001  max mem: 11902
[17:50:40.982043] Epoch: [42]  [260/345]  eta: 0:00:20  lr: 0.000017  loss: 0.1177 (0.1228)  time: 0.2455  data: 0.0001  max mem: 11902
[17:50:45.895738] Epoch: [42]  [280/345]  eta: 0:00:15  lr: 0.000017  loss: 0.1191 (0.1227)  time: 0.2456  data: 0.0001  max mem: 11902
[17:50:50.788175] Epoch: [42]  [300/345]  eta: 0:00:11  lr: 0.000017  loss: 0.1173 (0.1224)  time: 0.2446  data: 0.0001  max mem: 11902
[17:50:55.681583] Epoch: [42]  [320/345]  eta: 0:00:06  lr: 0.000016  loss: 0.1136 (0.1222)  time: 0.2446  data: 0.0001  max mem: 11902
[17:51:00.571401] Epoch: [42]  [340/345]  eta: 0:00:01  lr: 0.000016  loss: 0.1283 (0.1225)  time: 0.2444  data: 0.0001  max mem: 11902
[17:51:01.549577] Epoch: [42]  [344/345]  eta: 0:00:00  lr: 0.000016  loss: 0.1283 (0.1225)  time: 0.2442  data: 0.0001  max mem: 11902
[17:51:01.620955] Epoch: [42] Total time: 0:01:24 (0.2460 s / it)
[17:51:01.621184] Averaged stats: lr: 0.000016  loss: 0.1283 (0.1225)
[17:51:02.046559] Test:  [  0/345]  eta: 0:02:25  loss: 0.1013 (0.1013)  time: 0.4209  data: 0.3436  max mem: 11902
[17:51:02.856720] Test:  [ 10/345]  eta: 0:00:37  loss: 0.1044 (0.1098)  time: 0.1118  data: 0.0329  max mem: 11902
[17:51:03.655239] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1048 (0.1104)  time: 0.0803  data: 0.0010  max mem: 11902
[17:51:04.457136] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1113 (0.1132)  time: 0.0800  data: 0.0001  max mem: 11902
[17:51:05.260959] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1152 (0.1144)  time: 0.0802  data: 0.0001  max mem: 11902
[17:51:06.070495] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1134 (0.1146)  time: 0.0806  data: 0.0001  max mem: 11902
[17:51:06.882558] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1100 (0.1142)  time: 0.0810  data: 0.0001  max mem: 11902
[17:51:07.698520] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1064 (0.1147)  time: 0.0813  data: 0.0001  max mem: 11902
[17:51:08.517664] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1089 (0.1142)  time: 0.0817  data: 0.0001  max mem: 11902
[17:51:09.339303] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1089 (0.1138)  time: 0.0820  data: 0.0001  max mem: 11902
[17:51:10.166035] Test:  [100/345]  eta: 0:00:20  loss: 0.1097 (0.1141)  time: 0.0824  data: 0.0001  max mem: 11902
[17:51:10.997464] Test:  [110/345]  eta: 0:00:19  loss: 0.1133 (0.1145)  time: 0.0828  data: 0.0001  max mem: 11902
[17:51:11.830486] Test:  [120/345]  eta: 0:00:18  loss: 0.1142 (0.1142)  time: 0.0832  data: 0.0001  max mem: 11902
[17:51:12.667058] Test:  [130/345]  eta: 0:00:18  loss: 0.1152 (0.1149)  time: 0.0834  data: 0.0001  max mem: 11902
[17:51:13.507803] Test:  [140/345]  eta: 0:00:17  loss: 0.1184 (0.1149)  time: 0.0838  data: 0.0001  max mem: 11902
[17:51:14.352526] Test:  [150/345]  eta: 0:00:16  loss: 0.1186 (0.1159)  time: 0.0842  data: 0.0001  max mem: 11902
[17:51:15.200486] Test:  [160/345]  eta: 0:00:15  loss: 0.1186 (0.1159)  time: 0.0846  data: 0.0001  max mem: 11902
[17:51:16.051800] Test:  [170/345]  eta: 0:00:14  loss: 0.1057 (0.1158)  time: 0.0849  data: 0.0001  max mem: 11902
[17:51:16.906569] Test:  [180/345]  eta: 0:00:13  loss: 0.1068 (0.1158)  time: 0.0852  data: 0.0001  max mem: 11902
[17:51:17.766915] Test:  [190/345]  eta: 0:00:13  loss: 0.1154 (0.1162)  time: 0.0857  data: 0.0001  max mem: 11902
[17:51:18.628715] Test:  [200/345]  eta: 0:00:12  loss: 0.1042 (0.1156)  time: 0.0860  data: 0.0001  max mem: 11902
[17:51:19.495875] Test:  [210/345]  eta: 0:00:11  loss: 0.1042 (0.1152)  time: 0.0864  data: 0.0001  max mem: 11902
[17:51:20.364960] Test:  [220/345]  eta: 0:00:10  loss: 0.1085 (0.1153)  time: 0.0868  data: 0.0001  max mem: 11902
[17:51:21.238153] Test:  [230/345]  eta: 0:00:09  loss: 0.1100 (0.1153)  time: 0.0870  data: 0.0001  max mem: 11902
[17:51:22.114046] Test:  [240/345]  eta: 0:00:08  loss: 0.1127 (0.1152)  time: 0.0874  data: 0.0001  max mem: 11902
[17:51:22.994604] Test:  [250/345]  eta: 0:00:08  loss: 0.1099 (0.1149)  time: 0.0877  data: 0.0001  max mem: 11902
[17:51:23.877465] Test:  [260/345]  eta: 0:00:07  loss: 0.1112 (0.1152)  time: 0.0881  data: 0.0001  max mem: 11902
[17:51:24.765239] Test:  [270/345]  eta: 0:00:06  loss: 0.1208 (0.1155)  time: 0.0885  data: 0.0001  max mem: 11902
[17:51:25.655924] Test:  [280/345]  eta: 0:00:05  loss: 0.1126 (0.1155)  time: 0.0889  data: 0.0001  max mem: 11902
[17:51:26.550513] Test:  [290/345]  eta: 0:00:04  loss: 0.1068 (0.1155)  time: 0.0892  data: 0.0001  max mem: 11902
[17:51:27.448944] Test:  [300/345]  eta: 0:00:03  loss: 0.1173 (0.1156)  time: 0.0896  data: 0.0001  max mem: 11902
[17:51:28.350277] Test:  [310/345]  eta: 0:00:03  loss: 0.1175 (0.1159)  time: 0.0899  data: 0.0001  max mem: 11902
[17:51:29.255787] Test:  [320/345]  eta: 0:00:02  loss: 0.1153 (0.1159)  time: 0.0903  data: 0.0001  max mem: 11902
[17:51:30.165505] Test:  [330/345]  eta: 0:00:01  loss: 0.1076 (0.1158)  time: 0.0907  data: 0.0001  max mem: 11902
[17:51:31.076466] Test:  [340/345]  eta: 0:00:00  loss: 0.1077 (0.1157)  time: 0.0910  data: 0.0001  max mem: 11902
[17:51:31.441387] Test:  [344/345]  eta: 0:00:00  loss: 0.1125 (0.1157)  time: 0.0910  data: 0.0001  max mem: 11902
[17:51:31.506041] Test: Total time: 0:00:29 (0.0866 s / it)
[17:51:41.447166] Test:  [ 0/57]  eta: 0:00:22  loss: 0.4728 (0.4728)  time: 0.4025  data: 0.3252  max mem: 11902
[17:51:42.255613] Test:  [10/57]  eta: 0:00:05  loss: 0.4472 (0.4609)  time: 0.1100  data: 0.0315  max mem: 11902
[17:51:43.047992] Test:  [20/57]  eta: 0:00:03  loss: 0.4332 (0.4479)  time: 0.0799  data: 0.0011  max mem: 11902
[17:51:43.843321] Test:  [30/57]  eta: 0:00:02  loss: 0.2788 (0.3897)  time: 0.0793  data: 0.0001  max mem: 11902
[17:51:44.644116] Test:  [40/57]  eta: 0:00:01  loss: 0.2760 (0.3674)  time: 0.0797  data: 0.0001  max mem: 11902
[17:51:45.446263] Test:  [50/57]  eta: 0:00:00  loss: 0.3133 (0.3704)  time: 0.0801  data: 0.0001  max mem: 11902
[17:51:45.882006] Test:  [56/57]  eta: 0:00:00  loss: 0.3543 (0.4013)  time: 0.0779  data: 0.0001  max mem: 11902
[17:51:45.947918] Test: Total time: 0:00:04 (0.0860 s / it)
[17:51:47.681499] Dice score of the network on the train images: 0.880869, val images: 0.728253
[17:51:47.685286] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:51:48.275082] Epoch: [43]  [  0/345]  eta: 0:03:23  lr: 0.000016  loss: 0.1055 (0.1055)  time: 0.5887  data: 0.3408  max mem: 11902
[17:51:53.162221] Epoch: [43]  [ 20/345]  eta: 0:01:24  lr: 0.000016  loss: 0.1135 (0.1224)  time: 0.2443  data: 0.0001  max mem: 11902
[17:51:58.053729] Epoch: [43]  [ 40/345]  eta: 0:01:17  lr: 0.000016  loss: 0.1262 (0.1246)  time: 0.2445  data: 0.0001  max mem: 11902
[17:52:02.946168] Epoch: [43]  [ 60/345]  eta: 0:01:11  lr: 0.000015  loss: 0.1231 (0.1246)  time: 0.2446  data: 0.0001  max mem: 11902
[17:52:07.842699] Epoch: [43]  [ 80/345]  eta: 0:01:05  lr: 0.000015  loss: 0.1170 (0.1231)  time: 0.2448  data: 0.0001  max mem: 11902
[17:52:12.735718] Epoch: [43]  [100/345]  eta: 0:01:00  lr: 0.000015  loss: 0.1161 (0.1232)  time: 0.2446  data: 0.0001  max mem: 11902
[17:52:17.618762] Epoch: [43]  [120/345]  eta: 0:00:55  lr: 0.000015  loss: 0.1200 (0.1224)  time: 0.2441  data: 0.0001  max mem: 11902
[17:52:22.506056] Epoch: [43]  [140/345]  eta: 0:00:50  lr: 0.000014  loss: 0.1234 (0.1223)  time: 0.2443  data: 0.0001  max mem: 11902
[17:52:27.387117] Epoch: [43]  [160/345]  eta: 0:00:45  lr: 0.000014  loss: 0.1117 (0.1219)  time: 0.2440  data: 0.0001  max mem: 11902
[17:52:32.275202] Epoch: [43]  [180/345]  eta: 0:00:40  lr: 0.000014  loss: 0.1183 (0.1218)  time: 0.2444  data: 0.0001  max mem: 11902
[17:52:37.162891] Epoch: [43]  [200/345]  eta: 0:00:35  lr: 0.000014  loss: 0.1164 (0.1217)  time: 0.2443  data: 0.0001  max mem: 11902
[17:52:42.054984] Epoch: [43]  [220/345]  eta: 0:00:30  lr: 0.000013  loss: 0.1148 (0.1214)  time: 0.2446  data: 0.0001  max mem: 11902
[17:52:46.949115] Epoch: [43]  [240/345]  eta: 0:00:25  lr: 0.000013  loss: 0.1136 (0.1210)  time: 0.2447  data: 0.0001  max mem: 11902
[17:52:51.846050] Epoch: [43]  [260/345]  eta: 0:00:20  lr: 0.000013  loss: 0.1195 (0.1209)  time: 0.2448  data: 0.0001  max mem: 11902
[17:52:56.749074] Epoch: [43]  [280/345]  eta: 0:00:15  lr: 0.000013  loss: 0.1149 (0.1208)  time: 0.2451  data: 0.0001  max mem: 11902
[17:53:01.663395] Epoch: [43]  [300/345]  eta: 0:00:11  lr: 0.000012  loss: 0.1183 (0.1209)  time: 0.2457  data: 0.0001  max mem: 11902

[17:53:06.576609] Epoch: [43]  [320/345]  eta: 0:00:06  lr: 0.000012  loss: 0.1163 (0.1208)  time: 0.2456  data: 0.0001  max mem: 11902
[17:53:11.480719] Epoch: [43]  [340/345]  eta: 0:00:01  lr: 0.000012  loss: 0.1233 (0.1211)  time: 0.2452  data: 0.0001  max mem: 11902
[17:53:12.461064] Epoch: [43]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 0.1214 (0.1211)  time: 0.2450  data: 0.0001  max mem: 11902
[17:53:12.528275] Epoch: [43] Total time: 0:01:24 (0.2459 s / it)
[17:53:12.528754] Averaged stats: lr: 0.000012  loss: 0.1214 (0.1211)
[17:53:12.971978] Test:  [  0/345]  eta: 0:02:31  loss: 0.1026 (0.1026)  time: 0.4388  data: 0.3617  max mem: 11902
[17:53:13.771831] Test:  [ 10/345]  eta: 0:00:37  loss: 0.1027 (0.1044)  time: 0.1125  data: 0.0335  max mem: 11902
[17:53:14.571767] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1042 (0.1114)  time: 0.0799  data: 0.0004  max mem: 11902
[17:53:15.374511] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1084 (0.1125)  time: 0.0800  data: 0.0001  max mem: 11902
[17:53:16.178285] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1075 (0.1131)  time: 0.0802  data: 0.0001  max mem: 11902
[17:53:16.987121] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1122 (0.1137)  time: 0.0805  data: 0.0001  max mem: 11902
[17:53:17.799556] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1122 (0.1132)  time: 0.0810  data: 0.0001  max mem: 11902
[17:53:18.615790] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1080 (0.1124)  time: 0.0814  data: 0.0001  max mem: 11902
[17:53:19.435712] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1090 (0.1127)  time: 0.0817  data: 0.0001  max mem: 11902
[17:53:20.258526] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1142 (0.1130)  time: 0.0821  data: 0.0001  max mem: 11902
[17:53:21.084496] Test:  [100/345]  eta: 0:00:20  loss: 0.1101 (0.1127)  time: 0.0824  data: 0.0001  max mem: 11902
[17:53:21.915748] Test:  [110/345]  eta: 0:00:19  loss: 0.1101 (0.1135)  time: 0.0828  data: 0.0001  max mem: 11902
[17:53:22.749586] Test:  [120/345]  eta: 0:00:18  loss: 0.1177 (0.1142)  time: 0.0832  data: 0.0001  max mem: 11902
[17:53:23.585760] Test:  [130/345]  eta: 0:00:18  loss: 0.1154 (0.1139)  time: 0.0834  data: 0.0001  max mem: 11902
[17:53:24.427230] Test:  [140/345]  eta: 0:00:17  loss: 0.1083 (0.1141)  time: 0.0838  data: 0.0001  max mem: 11902
[17:53:25.272118] Test:  [150/345]  eta: 0:00:16  loss: 0.1126 (0.1139)  time: 0.0842  data: 0.0001  max mem: 11902
[17:53:26.119343] Test:  [160/345]  eta: 0:00:15  loss: 0.1032 (0.1134)  time: 0.0845  data: 0.0001  max mem: 11902
[17:53:26.970300] Test:  [170/345]  eta: 0:00:14  loss: 0.1123 (0.1138)  time: 0.0848  data: 0.0001  max mem: 11902
[17:53:27.825062] Test:  [180/345]  eta: 0:00:13  loss: 0.1143 (0.1138)  time: 0.0852  data: 0.0001  max mem: 11902
[17:53:28.683920] Test:  [190/345]  eta: 0:00:13  loss: 0.1145 (0.1139)  time: 0.0856  data: 0.0001  max mem: 11902
[17:53:29.546622] Test:  [200/345]  eta: 0:00:12  loss: 0.1144 (0.1136)  time: 0.0860  data: 0.0001  max mem: 11902
[17:53:30.413337] Test:  [210/345]  eta: 0:00:11  loss: 0.1144 (0.1141)  time: 0.0864  data: 0.0001  max mem: 11902
[17:53:31.282952] Test:  [220/345]  eta: 0:00:10  loss: 0.1140 (0.1142)  time: 0.0867  data: 0.0001  max mem: 11902
[17:53:32.156540] Test:  [230/345]  eta: 0:00:09  loss: 0.1048 (0.1141)  time: 0.0871  data: 0.0001  max mem: 11902
[17:53:33.033509] Test:  [240/345]  eta: 0:00:08  loss: 0.1079 (0.1140)  time: 0.0874  data: 0.0001  max mem: 11902
[17:53:33.914951] Test:  [250/345]  eta: 0:00:08  loss: 0.1174 (0.1144)  time: 0.0878  data: 0.0001  max mem: 11902
[17:53:34.798678] Test:  [260/345]  eta: 0:00:07  loss: 0.1080 (0.1142)  time: 0.0882  data: 0.0001  max mem: 11902
[17:53:35.685889] Test:  [270/345]  eta: 0:00:06  loss: 0.1066 (0.1141)  time: 0.0885  data: 0.0001  max mem: 11902
[17:53:36.576573] Test:  [280/345]  eta: 0:00:05  loss: 0.1068 (0.1140)  time: 0.0888  data: 0.0001  max mem: 11902
[17:53:37.470906] Test:  [290/345]  eta: 0:00:04  loss: 0.1032 (0.1137)  time: 0.0892  data: 0.0001  max mem: 11902
[17:53:38.369591] Test:  [300/345]  eta: 0:00:03  loss: 0.1101 (0.1139)  time: 0.0896  data: 0.0001  max mem: 11902
[17:53:39.271539] Test:  [310/345]  eta: 0:00:03  loss: 0.1149 (0.1138)  time: 0.0900  data: 0.0001  max mem: 11902
[17:53:40.177533] Test:  [320/345]  eta: 0:00:02  loss: 0.1149 (0.1138)  time: 0.0903  data: 0.0001  max mem: 11902
[17:53:41.086538] Test:  [330/345]  eta: 0:00:01  loss: 0.1111 (0.1137)  time: 0.0907  data: 0.0001  max mem: 11902
[17:53:41.997864] Test:  [340/345]  eta: 0:00:00  loss: 0.1132 (0.1138)  time: 0.0910  data: 0.0001  max mem: 11902
[17:53:42.364168] Test:  [344/345]  eta: 0:00:00  loss: 0.1132 (0.1138)  time: 0.0911  data: 0.0001  max mem: 11902
[17:53:42.436590] Test: Total time: 0:00:29 (0.0867 s / it)
[17:53:52.357503] Test:  [ 0/57]  eta: 0:00:25  loss: 0.4817 (0.4817)  time: 0.4484  data: 0.3714  max mem: 11902
[17:53:53.147406] Test:  [10/57]  eta: 0:00:05  loss: 0.4424 (0.4736)  time: 0.1125  data: 0.0338  max mem: 11902
[17:53:53.939510] Test:  [20/57]  eta: 0:00:03  loss: 0.4423 (0.4573)  time: 0.0790  data: 0.0001  max mem: 11902
[17:53:54.735919] Test:  [30/57]  eta: 0:00:02  loss: 0.2816 (0.3984)  time: 0.0794  data: 0.0001  max mem: 11902
[17:53:55.537188] Test:  [40/57]  eta: 0:00:01  loss: 0.2816 (0.3780)  time: 0.0798  data: 0.0001  max mem: 11902
[17:53:56.341209] Test:  [50/57]  eta: 0:00:00  loss: 0.3210 (0.3830)  time: 0.0802  data: 0.0001  max mem: 11902
[17:53:56.776846] Test:  [56/57]  eta: 0:00:00  loss: 0.3673 (0.4157)  time: 0.0780  data: 0.0000  max mem: 11902
[17:53:56.850847] Test: Total time: 0:00:04 (0.0867 s / it)
[17:53:58.586842] Dice score of the network on the train images: 0.884832, val images: 0.721985
[17:53:58.590199] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:53:59.247144] Epoch: [44]  [  0/345]  eta: 0:03:46  lr: 0.000012  loss: 0.1158 (0.1158)  time: 0.6558  data: 0.4094  max mem: 11902
[17:54:04.125826] Epoch: [44]  [ 20/345]  eta: 0:01:25  lr: 0.000012  loss: 0.1186 (0.1260)  time: 0.2439  data: 0.0001  max mem: 11902
[17:54:09.011253] Epoch: [44]  [ 40/345]  eta: 0:01:17  lr: 0.000011  loss: 0.1217 (0.1225)  time: 0.2442  data: 0.0001  max mem: 11902
[17:54:13.895332] Epoch: [44]  [ 60/345]  eta: 0:01:11  lr: 0.000011  loss: 0.1080 (0.1198)  time: 0.2442  data: 0.0001  max mem: 11902
[17:54:18.782617] Epoch: [44]  [ 80/345]  eta: 0:01:06  lr: 0.000011  loss: 0.1110 (0.1188)  time: 0.2443  data: 0.0001  max mem: 11902
[17:54:23.680529] Epoch: [44]  [100/345]  eta: 0:01:00  lr: 0.000011  loss: 0.1192 (0.1190)  time: 0.2448  data: 0.0001  max mem: 11902
[17:54:28.573505] Epoch: [44]  [120/345]  eta: 0:00:55  lr: 0.000011  loss: 0.1110 (0.1187)  time: 0.2446  data: 0.0001  max mem: 11902
[17:54:33.455488] Epoch: [44]  [140/345]  eta: 0:00:50  lr: 0.000010  loss: 0.1146 (0.1190)  time: 0.2441  data: 0.0001  max mem: 11902
[17:54:38.352053] Epoch: [44]  [160/345]  eta: 0:00:45  lr: 0.000010  loss: 0.1212 (0.1194)  time: 0.2448  data: 0.0001  max mem: 11902
[17:54:43.231991] Epoch: [44]  [180/345]  eta: 0:00:40  lr: 0.000010  loss: 0.1165 (0.1192)  time: 0.2440  data: 0.0001  max mem: 11902
[17:54:48.115605] Epoch: [44]  [200/345]  eta: 0:00:35  lr: 0.000010  loss: 0.1132 (0.1192)  time: 0.2441  data: 0.0001  max mem: 11902
[17:54:53.000768] Epoch: [44]  [220/345]  eta: 0:00:30  lr: 0.000010  loss: 0.1117 (0.1187)  time: 0.2442  data: 0.0001  max mem: 11902
[17:54:57.886450] Epoch: [44]  [240/345]  eta: 0:00:25  lr: 0.000009  loss: 0.1163 (0.1189)  time: 0.2442  data: 0.0001  max mem: 11902
[17:55:02.779995] Epoch: [44]  [260/345]  eta: 0:00:20  lr: 0.000009  loss: 0.1200 (0.1190)  time: 0.2446  data: 0.0001  max mem: 11902
[17:55:07.690340] Epoch: [44]  [280/345]  eta: 0:00:15  lr: 0.000009  loss: 0.1242 (0.1195)  time: 0.2455  data: 0.0001  max mem: 11902
[17:55:12.598765] Epoch: [44]  [300/345]  eta: 0:00:11  lr: 0.000009  loss: 0.1152 (0.1192)  time: 0.2454  data: 0.0001  max mem: 11902
[17:55:17.518411] Epoch: [44]  [320/345]  eta: 0:00:06  lr: 0.000009  loss: 0.1176 (0.1192)  time: 0.2459  data: 0.0001  max mem: 11902
[17:55:22.419877] Epoch: [44]  [340/345]  eta: 0:00:01  lr: 0.000008  loss: 0.1197 (0.1194)  time: 0.2450  data: 0.0001  max mem: 11902
[17:55:23.399375] Epoch: [44]  [344/345]  eta: 0:00:00  lr: 0.000008  loss: 0.1172 (0.1195)  time: 0.2449  data: 0.0001  max mem: 11902
[17:55:23.457982] Epoch: [44] Total time: 0:01:24 (0.2460 s / it)
[17:55:23.458203] Averaged stats: lr: 0.000008  loss: 0.1172 (0.1195)
[17:55:23.922622] Test:  [  0/345]  eta: 0:02:38  loss: 0.1121 (0.1121)  time: 0.4601  data: 0.3829  max mem: 11902
[17:55:24.720382] Test:  [ 10/345]  eta: 0:00:38  loss: 0.1118 (0.1105)  time: 0.1142  data: 0.0352  max mem: 11902
[17:55:25.518962] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1118 (0.1161)  time: 0.0797  data: 0.0003  max mem: 11902
[17:55:26.320943] Test:  [ 30/345]  eta: 0:00:29  loss: 0.1065 (0.1135)  time: 0.0799  data: 0.0001  max mem: 11902
[17:55:27.125473] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1058 (0.1132)  time: 0.0802  data: 0.0001  max mem: 11902
[17:55:27.933714] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1026 (0.1120)  time: 0.0806  data: 0.0001  max mem: 11902
[17:55:28.746561] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1052 (0.1119)  time: 0.0810  data: 0.0001  max mem: 11902
[17:55:29.561545] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1086 (0.1124)  time: 0.0813  data: 0.0001  max mem: 11902
[17:55:30.380767] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1204 (0.1136)  time: 0.0816  data: 0.0001  max mem: 11902
[17:55:31.202555] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1186 (0.1139)  time: 0.0820  data: 0.0001  max mem: 11902
[17:55:32.028551] Test:  [100/345]  eta: 0:00:20  loss: 0.1087 (0.1135)  time: 0.0823  data: 0.0001  max mem: 11902
[17:55:32.858200] Test:  [110/345]  eta: 0:00:19  loss: 0.1054 (0.1129)  time: 0.0827  data: 0.0001  max mem: 11902
[17:55:33.692221] Test:  [120/345]  eta: 0:00:19  loss: 0.1033 (0.1124)  time: 0.0831  data: 0.0001  max mem: 11902
[17:55:34.528560] Test:  [130/345]  eta: 0:00:18  loss: 0.1016 (0.1120)  time: 0.0834  data: 0.0001  max mem: 11902
[17:55:35.369451] Test:  [140/345]  eta: 0:00:17  loss: 0.1031 (0.1119)  time: 0.0838  data: 0.0001  max mem: 11902
[17:55:36.212895] Test:  [150/345]  eta: 0:00:16  loss: 0.1058 (0.1119)  time: 0.0842  data: 0.0001  max mem: 11902
[17:55:37.061235] Test:  [160/345]  eta: 0:00:15  loss: 0.1115 (0.1123)  time: 0.0845  data: 0.0001  max mem: 11902
[17:55:37.912339] Test:  [170/345]  eta: 0:00:14  loss: 0.1117 (0.1124)  time: 0.0849  data: 0.0001  max mem: 11902
[17:55:38.766075] Test:  [180/345]  eta: 0:00:13  loss: 0.1117 (0.1126)  time: 0.0852  data: 0.0001  max mem: 11902
[17:55:39.623324] Test:  [190/345]  eta: 0:00:13  loss: 0.1097 (0.1123)  time: 0.0855  data: 0.0001  max mem: 11902
[17:55:40.484998] Test:  [200/345]  eta: 0:00:12  loss: 0.1097 (0.1122)  time: 0.0859  data: 0.0001  max mem: 11902
[17:55:41.349519] Test:  [210/345]  eta: 0:00:11  loss: 0.1129 (0.1125)  time: 0.0863  data: 0.0001  max mem: 11902
[17:55:42.217519] Test:  [220/345]  eta: 0:00:10  loss: 0.1188 (0.1129)  time: 0.0866  data: 0.0001  max mem: 11902
[17:55:43.090608] Test:  [230/345]  eta: 0:00:09  loss: 0.1163 (0.1130)  time: 0.0870  data: 0.0001  max mem: 11902
[17:55:43.966258] Test:  [240/345]  eta: 0:00:08  loss: 0.1099 (0.1131)  time: 0.0874  data: 0.0001  max mem: 11902
[17:55:44.847418] Test:  [250/345]  eta: 0:00:08  loss: 0.1105 (0.1133)  time: 0.0878  data: 0.0001  max mem: 11902
[17:55:45.729251] Test:  [260/345]  eta: 0:00:07  loss: 0.1073 (0.1130)  time: 0.0881  data: 0.0001  max mem: 11902
[17:55:46.615012] Test:  [270/345]  eta: 0:00:06  loss: 0.1071 (0.1131)  time: 0.0883  data: 0.0001  max mem: 11902
[17:55:47.505395] Test:  [280/345]  eta: 0:00:05  loss: 0.1071 (0.1133)  time: 0.0887  data: 0.0001  max mem: 11902
[17:55:48.400869] Test:  [290/345]  eta: 0:00:04  loss: 0.1029 (0.1131)  time: 0.0892  data: 0.0001  max mem: 11902
[17:55:49.298607] Test:  [300/345]  eta: 0:00:03  loss: 0.1029 (0.1130)  time: 0.0896  data: 0.0001  max mem: 11902
[17:55:50.200462] Test:  [310/345]  eta: 0:00:03  loss: 0.1021 (0.1128)  time: 0.0899  data: 0.0001  max mem: 11902
[17:55:51.103597] Test:  [320/345]  eta: 0:00:02  loss: 0.1035 (0.1127)  time: 0.0902  data: 0.0001  max mem: 11902
[17:55:52.011558] Test:  [330/345]  eta: 0:00:01  loss: 0.1099 (0.1126)  time: 0.0905  data: 0.0001  max mem: 11902
[17:55:52.924052] Test:  [340/345]  eta: 0:00:00  loss: 0.1042 (0.1125)  time: 0.0910  data: 0.0001  max mem: 11902
[17:55:53.289684] Test:  [344/345]  eta: 0:00:00  loss: 0.1042 (0.1125)  time: 0.0911  data: 0.0001  max mem: 11902
[17:55:53.361971] Test: Total time: 0:00:29 (0.0867 s / it)
[17:56:03.317544] Test:  [ 0/57]  eta: 0:00:26  loss: 0.4797 (0.4797)  time: 0.4728  data: 0.3956  max mem: 11902
[17:56:04.107282] Test:  [10/57]  eta: 0:00:05  loss: 0.4503 (0.4722)  time: 0.1147  data: 0.0361  max mem: 11902
[17:56:04.899442] Test:  [20/57]  eta: 0:00:03  loss: 0.4427 (0.4584)  time: 0.0790  data: 0.0001  max mem: 11902
[17:56:05.695894] Test:  [30/57]  eta: 0:00:02  loss: 0.2784 (0.3979)  time: 0.0794  data: 0.0001  max mem: 11902
[17:56:06.497428] Test:  [40/57]  eta: 0:00:01  loss: 0.2763 (0.3750)  time: 0.0798  data: 0.0001  max mem: 11902
[17:56:07.300593] Test:  [50/57]  eta: 0:00:00  loss: 0.3143 (0.3790)  time: 0.0802  data: 0.0001  max mem: 11902
[17:56:07.736372] Test:  [56/57]  eta: 0:00:00  loss: 0.3615 (0.4126)  time: 0.0779  data: 0.0000  max mem: 11902
[17:56:07.803440] Test: Total time: 0:00:04 (0.0870 s / it)
[17:56:09.543603] Dice score of the network on the train images: 0.883342, val images: 0.723431
[17:56:09.547110] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:56:10.134281] Epoch: [45]  [  0/345]  eta: 0:03:22  lr: 0.000008  loss: 0.1248 (0.1248)  time: 0.5864  data: 0.3401  max mem: 11902
[17:56:15.001565] Epoch: [45]  [ 20/345]  eta: 0:01:24  lr: 0.000008  loss: 0.1187 (0.1237)  time: 0.2433  data: 0.0001  max mem: 11902
[17:56:19.865387] Epoch: [45]  [ 40/345]  eta: 0:01:16  lr: 0.000008  loss: 0.1129 (0.1198)  time: 0.2431  data: 0.0001  max mem: 11902
[17:56:24.729912] Epoch: [45]  [ 60/345]  eta: 0:01:10  lr: 0.000008  loss: 0.1184 (0.1204)  time: 0.2432  data: 0.0001  max mem: 11902
[17:56:29.600583] Epoch: [45]  [ 80/345]  eta: 0:01:05  lr: 0.000008  loss: 0.1142 (0.1189)  time: 0.2435  data: 0.0001  max mem: 11902
[17:56:34.469137] Epoch: [45]  [100/345]  eta: 0:01:00  lr: 0.000007  loss: 0.1148 (0.1187)  time: 0.2434  data: 0.0001  max mem: 11902
[17:56:39.346207] Epoch: [45]  [120/345]  eta: 0:00:55  lr: 0.000007  loss: 0.1094 (0.1179)  time: 0.2438  data: 0.0001  max mem: 11902
[17:56:44.217404] Epoch: [45]  [140/345]  eta: 0:00:50  lr: 0.000007  loss: 0.1128 (0.1183)  time: 0.2435  data: 0.0001  max mem: 11902
[17:56:49.096692] Epoch: [45]  [160/345]  eta: 0:00:45  lr: 0.000007  loss: 0.1166 (0.1180)  time: 0.2439  data: 0.0001  max mem: 11902
[17:56:53.971187] Epoch: [45]  [180/345]  eta: 0:00:40  lr: 0.000007  loss: 0.1181 (0.1182)  time: 0.2437  data: 0.0001  max mem: 11902
[17:56:58.853252] Epoch: [45]  [200/345]  eta: 0:00:35  lr: 0.000007  loss: 0.1121 (0.1182)  time: 0.2441  data: 0.0001  max mem: 11902
[17:57:03.734181] Epoch: [45]  [220/345]  eta: 0:00:30  lr: 0.000006  loss: 0.1112 (0.1183)  time: 0.2440  data: 0.0001  max mem: 11902
[17:57:08.618003] Epoch: [45]  [240/345]  eta: 0:00:25  lr: 0.000006  loss: 0.1175 (0.1183)  time: 0.2442  data: 0.0001  max mem: 11902
[17:57:13.502168] Epoch: [45]  [260/345]  eta: 0:00:20  lr: 0.000006  loss: 0.1089 (0.1177)  time: 0.2442  data: 0.0001  max mem: 11902
[17:57:18.392594] Epoch: [45]  [280/345]  eta: 0:00:15  lr: 0.000006  loss: 0.1106 (0.1175)  time: 0.2445  data: 0.0001  max mem: 11902
[17:57:23.278697] Epoch: [45]  [300/345]  eta: 0:00:11  lr: 0.000006  loss: 0.1090 (0.1177)  time: 0.2443  data: 0.0000  max mem: 11902
[17:57:28.244033] Epoch: [45]  [320/345]  eta: 0:00:06  lr: 0.000006  loss: 0.1162 (0.1178)  time: 0.2482  data: 0.0001  max mem: 11902
[17:57:33.129143] Epoch: [45]  [340/345]  eta: 0:00:01  lr: 0.000005  loss: 0.1121 (0.1180)  time: 0.2442  data: 0.0001  max mem: 11902
[17:57:34.106931] Epoch: [45]  [344/345]  eta: 0:00:00  lr: 0.000005  loss: 0.1129 (0.1179)  time: 0.2443  data: 0.0001  max mem: 11902
[17:57:34.188093] Epoch: [45] Total time: 0:01:24 (0.2453 s / it)
[17:57:34.188316] Averaged stats: lr: 0.000005  loss: 0.1129 (0.1179)
[17:57:34.628343] Test:  [  0/345]  eta: 0:02:30  loss: 0.1148 (0.1148)  time: 0.4358  data: 0.3588  max mem: 11902
[17:57:35.442518] Test:  [ 10/345]  eta: 0:00:38  loss: 0.1129 (0.1083)  time: 0.1135  data: 0.0345  max mem: 11902
[17:57:36.240068] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1090 (0.1091)  time: 0.0805  data: 0.0011  max mem: 11902
[17:57:37.040983] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1048 (0.1094)  time: 0.0799  data: 0.0001  max mem: 11902
[17:57:37.848069] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1054 (0.1096)  time: 0.0803  data: 0.0001  max mem: 11902
[17:57:38.655888] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1068 (0.1092)  time: 0.0806  data: 0.0001  max mem: 11902
[17:57:39.468554] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1109 (0.1110)  time: 0.0809  data: 0.0001  max mem: 11902
[17:57:40.283573] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1135 (0.1120)  time: 0.0813  data: 0.0001  max mem: 11902
[17:57:41.103055] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1106 (0.1110)  time: 0.0816  data: 0.0001  max mem: 11902
[17:57:41.924629] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1064 (0.1107)  time: 0.0820  data: 0.0001  max mem: 11902
[17:57:42.750657] Test:  [100/345]  eta: 0:00:20  loss: 0.1087 (0.1117)  time: 0.0823  data: 0.0001  max mem: 11902
[17:57:43.580119] Test:  [110/345]  eta: 0:00:19  loss: 0.1119 (0.1118)  time: 0.0827  data: 0.0001  max mem: 11902
[17:57:44.413179] Test:  [120/345]  eta: 0:00:18  loss: 0.1136 (0.1115)  time: 0.0831  data: 0.0001  max mem: 11902
[17:57:45.250465] Test:  [130/345]  eta: 0:00:18  loss: 0.1069 (0.1113)  time: 0.0834  data: 0.0001  max mem: 11902
[17:57:46.090668] Test:  [140/345]  eta: 0:00:17  loss: 0.1069 (0.1112)  time: 0.0838  data: 0.0001  max mem: 11902
[17:57:46.934622] Test:  [150/345]  eta: 0:00:16  loss: 0.1099 (0.1116)  time: 0.0841  data: 0.0001  max mem: 11902
[17:57:47.782226] Test:  [160/345]  eta: 0:00:15  loss: 0.1118 (0.1116)  time: 0.0845  data: 0.0001  max mem: 11902
[17:57:48.633399] Test:  [170/345]  eta: 0:00:14  loss: 0.1083 (0.1117)  time: 0.0849  data: 0.0001  max mem: 11902
[17:57:49.488111] Test:  [180/345]  eta: 0:00:13  loss: 0.1082 (0.1116)  time: 0.0852  data: 0.0001  max mem: 11902
[17:57:50.346623] Test:  [190/345]  eta: 0:00:13  loss: 0.1060 (0.1117)  time: 0.0856  data: 0.0001  max mem: 11902
[17:57:51.208590] Test:  [200/345]  eta: 0:00:12  loss: 0.1074 (0.1116)  time: 0.0859  data: 0.0001  max mem: 11902
[17:57:52.075549] Test:  [210/345]  eta: 0:00:11  loss: 0.1036 (0.1111)  time: 0.0864  data: 0.0001  max mem: 11902
[17:57:52.944811] Test:  [220/345]  eta: 0:00:10  loss: 0.1040 (0.1110)  time: 0.0867  data: 0.0001  max mem: 11902
[17:57:53.819063] Test:  [230/345]  eta: 0:00:09  loss: 0.1058 (0.1109)  time: 0.0871  data: 0.0001  max mem: 11902
[17:57:54.696122] Test:  [240/345]  eta: 0:00:08  loss: 0.1037 (0.1107)  time: 0.0875  data: 0.0001  max mem: 11902
[17:57:55.576930] Test:  [250/345]  eta: 0:00:08  loss: 0.1080 (0.1109)  time: 0.0878  data: 0.0001  max mem: 11902
[17:57:56.460834] Test:  [260/345]  eta: 0:00:07  loss: 0.1115 (0.1111)  time: 0.0882  data: 0.0001  max mem: 11902
[17:57:57.349424] Test:  [270/345]  eta: 0:00:06  loss: 0.1005 (0.1107)  time: 0.0886  data: 0.0001  max mem: 11902
[17:57:58.239669] Test:  [280/345]  eta: 0:00:05  loss: 0.1006 (0.1107)  time: 0.0889  data: 0.0001  max mem: 11902
[17:57:59.135635] Test:  [290/345]  eta: 0:00:04  loss: 0.1056 (0.1108)  time: 0.0892  data: 0.0001  max mem: 11902
[17:58:00.033132] Test:  [300/345]  eta: 0:00:03  loss: 0.1183 (0.1109)  time: 0.0896  data: 0.0001  max mem: 11902
[17:58:00.934836] Test:  [310/345]  eta: 0:00:03  loss: 0.1166 (0.1111)  time: 0.0899  data: 0.0001  max mem: 11902
[17:58:01.841222] Test:  [320/345]  eta: 0:00:02  loss: 0.1127 (0.1112)  time: 0.0903  data: 0.0001  max mem: 11902
[17:58:02.749523] Test:  [330/345]  eta: 0:00:01  loss: 0.1126 (0.1113)  time: 0.0907  data: 0.0001  max mem: 11902
[17:58:03.660403] Test:  [340/345]  eta: 0:00:00  loss: 0.1126 (0.1115)  time: 0.0909  data: 0.0001  max mem: 11902
[17:58:04.025305] Test:  [344/345]  eta: 0:00:00  loss: 0.1138 (0.1116)  time: 0.0910  data: 0.0001  max mem: 11902
[17:58:04.096080] Test: Total time: 0:00:29 (0.0867 s / it)
[17:58:14.074816] Test:  [ 0/57]  eta: 0:00:24  loss: 0.4802 (0.4802)  time: 0.4286  data: 0.3515  max mem: 11902
[17:58:14.875262] Test:  [10/57]  eta: 0:00:05  loss: 0.4507 (0.4781)  time: 0.1116  data: 0.0330  max mem: 11902
[17:58:15.669596] Test:  [20/57]  eta: 0:00:03  loss: 0.4434 (0.4622)  time: 0.0796  data: 0.0007  max mem: 11902
[17:58:16.466033] Test:  [30/57]  eta: 0:00:02  loss: 0.2802 (0.4015)  time: 0.0795  data: 0.0001  max mem: 11902
[17:58:17.266477] Test:  [40/57]  eta: 0:00:01  loss: 0.2788 (0.3793)  time: 0.0798  data: 0.0001  max mem: 11902
[17:58:18.070619] Test:  [50/57]  eta: 0:00:00  loss: 0.3173 (0.3833)  time: 0.0802  data: 0.0001  max mem: 11902
[17:58:18.508515] Test:  [56/57]  eta: 0:00:00  loss: 0.3648 (0.4153)  time: 0.0781  data: 0.0001  max mem: 11902
[17:58:18.579261] Test: Total time: 0:00:04 (0.0866 s / it)
[17:58:20.364024] Dice score of the network on the train images: 0.884328, val images: 0.718865
[17:58:20.367504] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[17:58:20.958693] Epoch: [46]  [  0/345]  eta: 0:03:23  lr: 0.000005  loss: 0.1104 (0.1104)  time: 0.5900  data: 0.3446  max mem: 11902
[17:58:25.839757] Epoch: [46]  [ 20/345]  eta: 0:01:24  lr: 0.000005  loss: 0.1170 (0.1191)  time: 0.2440  data: 0.0001  max mem: 11902
[17:58:30.724939] Epoch: [46]  [ 40/345]  eta: 0:01:17  lr: 0.000005  loss: 0.1070 (0.1152)  time: 0.2442  data: 0.0001  max mem: 11902
[17:58:35.607838] Epoch: [46]  [ 60/345]  eta: 0:01:11  lr: 0.000005  loss: 0.1142 (0.1170)  time: 0.2441  data: 0.0001  max mem: 11902
[17:58:40.493631] Epoch: [46]  [ 80/345]  eta: 0:01:05  lr: 0.000005  loss: 0.1081 (0.1164)  time: 0.2442  data: 0.0001  max mem: 11902
[17:58:45.374059] Epoch: [46]  [100/345]  eta: 0:01:00  lr: 0.000005  loss: 0.1205 (0.1171)  time: 0.2440  data: 0.0001  max mem: 11902
[17:58:50.249172] Epoch: [46]  [120/345]  eta: 0:00:55  lr: 0.000005  loss: 0.1100 (0.1164)  time: 0.2437  data: 0.0001  max mem: 11902
[17:58:55.128810] Epoch: [46]  [140/345]  eta: 0:00:50  lr: 0.000004  loss: 0.1125 (0.1167)  time: 0.2439  data: 0.0001  max mem: 11902
[17:59:00.003201] Epoch: [46]  [160/345]  eta: 0:00:45  lr: 0.000004  loss: 0.1167 (0.1169)  time: 0.2437  data: 0.0001  max mem: 11902
[17:59:04.880514] Epoch: [46]  [180/345]  eta: 0:00:40  lr: 0.000004  loss: 0.1109 (0.1165)  time: 0.2438  data: 0.0001  max mem: 11902
[17:59:09.760423] Epoch: [46]  [200/345]  eta: 0:00:35  lr: 0.000004  loss: 0.1151 (0.1168)  time: 0.2440  data: 0.0001  max mem: 11902
[17:59:14.656861] Epoch: [46]  [220/345]  eta: 0:00:30  lr: 0.000004  loss: 0.1110 (0.1168)  time: 0.2448  data: 0.0001  max mem: 11902
[17:59:19.554094] Epoch: [46]  [240/345]  eta: 0:00:25  lr: 0.000004  loss: 0.1145 (0.1171)  time: 0.2448  data: 0.0001  max mem: 11902
[17:59:24.452639] Epoch: [46]  [260/345]  eta: 0:00:20  lr: 0.000004  loss: 0.1122 (0.1172)  time: 0.2449  data: 0.0001  max mem: 11902
[17:59:29.354330] Epoch: [46]  [280/345]  eta: 0:00:15  lr: 0.000003  loss: 0.1160 (0.1173)  time: 0.2450  data: 0.0001  max mem: 11902
[17:59:34.264978] Epoch: [46]  [300/345]  eta: 0:00:11  lr: 0.000003  loss: 0.1091 (0.1171)  time: 0.2455  data: 0.0001  max mem: 11902
[17:59:39.171314] Epoch: [46]  [320/345]  eta: 0:00:06  lr: 0.000003  loss: 0.1115 (0.1172)  time: 0.2453  data: 0.0001  max mem: 11902
[17:59:44.074194] Epoch: [46]  [340/345]  eta: 0:00:01  lr: 0.000003  loss: 0.1169 (0.1174)  time: 0.2451  data: 0.0001  max mem: 11902
[17:59:45.054016] Epoch: [46]  [344/345]  eta: 0:00:00  lr: 0.000003  loss: 0.1170 (0.1175)  time: 0.2450  data: 0.0001  max mem: 11902
[17:59:45.132723] Epoch: [46] Total time: 0:01:24 (0.2457 s / it)
[17:59:45.133078] Averaged stats: lr: 0.000003  loss: 0.1170 (0.1175)
[17:59:45.619587] Test:  [  0/345]  eta: 0:02:46  loss: 0.1115 (0.1115)  time: 0.4819  data: 0.4048  max mem: 11902
[17:59:46.415594] Test:  [ 10/345]  eta: 0:00:38  loss: 0.1154 (0.1188)  time: 0.1161  data: 0.0369  max mem: 11902
[17:59:47.214573] Test:  [ 20/345]  eta: 0:00:32  loss: 0.1044 (0.1115)  time: 0.0796  data: 0.0001  max mem: 11902
[17:59:48.016418] Test:  [ 30/345]  eta: 0:00:29  loss: 0.1048 (0.1154)  time: 0.0800  data: 0.0001  max mem: 11902
[17:59:48.821996] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1073 (0.1129)  time: 0.0803  data: 0.0001  max mem: 11902
[17:59:49.630749] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1062 (0.1122)  time: 0.0806  data: 0.0001  max mem: 11902
[17:59:50.443589] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1039 (0.1112)  time: 0.0810  data: 0.0001  max mem: 11902
[17:59:51.257967] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1041 (0.1116)  time: 0.0813  data: 0.0001  max mem: 11902
[17:59:52.076209] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1107 (0.1119)  time: 0.0816  data: 0.0001  max mem: 11902
[17:59:52.899129] Test:  [ 90/345]  eta: 0:00:21  loss: 0.0991 (0.1106)  time: 0.0820  data: 0.0001  max mem: 11902
[17:59:53.725812] Test:  [100/345]  eta: 0:00:20  loss: 0.1014 (0.1108)  time: 0.0824  data: 0.0001  max mem: 11902
[17:59:54.556334] Test:  [110/345]  eta: 0:00:19  loss: 0.1057 (0.1101)  time: 0.0828  data: 0.0001  max mem: 11902
[17:59:55.389520] Test:  [120/345]  eta: 0:00:19  loss: 0.1031 (0.1105)  time: 0.0831  data: 0.0001  max mem: 11902
[17:59:56.226597] Test:  [130/345]  eta: 0:00:18  loss: 0.1120 (0.1105)  time: 0.0834  data: 0.0001  max mem: 11902
[17:59:57.067835] Test:  [140/345]  eta: 0:00:17  loss: 0.1121 (0.1109)  time: 0.0838  data: 0.0001  max mem: 11902
[17:59:57.912854] Test:  [150/345]  eta: 0:00:16  loss: 0.1113 (0.1109)  time: 0.0842  data: 0.0001  max mem: 11902
[17:59:58.760672] Test:  [160/345]  eta: 0:00:15  loss: 0.1060 (0.1107)  time: 0.0846  data: 0.0001  max mem: 11902
[17:59:59.612760] Test:  [170/345]  eta: 0:00:14  loss: 0.1086 (0.1107)  time: 0.0849  data: 0.0001  max mem: 11902
[18:00:00.468389] Test:  [180/345]  eta: 0:00:13  loss: 0.1076 (0.1104)  time: 0.0853  data: 0.0001  max mem: 11902
[18:00:01.327123] Test:  [190/345]  eta: 0:00:13  loss: 0.1059 (0.1104)  time: 0.0856  data: 0.0001  max mem: 11902
[18:00:02.189390] Test:  [200/345]  eta: 0:00:12  loss: 0.1031 (0.1102)  time: 0.0860  data: 0.0001  max mem: 11902
[18:00:03.056298] Test:  [210/345]  eta: 0:00:11  loss: 0.1031 (0.1106)  time: 0.0864  data: 0.0001  max mem: 11902
[18:00:03.926623] Test:  [220/345]  eta: 0:00:10  loss: 0.1108 (0.1106)  time: 0.0868  data: 0.0001  max mem: 11902
[18:00:04.800094] Test:  [230/345]  eta: 0:00:09  loss: 0.1089 (0.1109)  time: 0.0871  data: 0.0001  max mem: 11902
[18:00:05.676912] Test:  [240/345]  eta: 0:00:08  loss: 0.1064 (0.1105)  time: 0.0874  data: 0.0001  max mem: 11902
[18:00:06.559289] Test:  [250/345]  eta: 0:00:08  loss: 0.1048 (0.1105)  time: 0.0879  data: 0.0001  max mem: 11902
[18:00:07.443544] Test:  [260/345]  eta: 0:00:07  loss: 0.1084 (0.1108)  time: 0.0882  data: 0.0001  max mem: 11902
[18:00:08.330647] Test:  [270/345]  eta: 0:00:06  loss: 0.1224 (0.1114)  time: 0.0885  data: 0.0001  max mem: 11902
[18:00:09.222690] Test:  [280/345]  eta: 0:00:05  loss: 0.1158 (0.1114)  time: 0.0889  data: 0.0001  max mem: 11902
[18:00:10.117478] Test:  [290/345]  eta: 0:00:04  loss: 0.1089 (0.1113)  time: 0.0893  data: 0.0001  max mem: 11902
[18:00:11.015873] Test:  [300/345]  eta: 0:00:03  loss: 0.1050 (0.1110)  time: 0.0896  data: 0.0001  max mem: 11902
[18:00:11.918718] Test:  [310/345]  eta: 0:00:03  loss: 0.1080 (0.1111)  time: 0.0900  data: 0.0001  max mem: 11902
[18:00:12.824664] Test:  [320/345]  eta: 0:00:02  loss: 0.1119 (0.1112)  time: 0.0904  data: 0.0001  max mem: 11902
[18:00:13.732655] Test:  [330/345]  eta: 0:00:01  loss: 0.1072 (0.1111)  time: 0.0906  data: 0.0001  max mem: 11902
[18:00:14.643888] Test:  [340/345]  eta: 0:00:00  loss: 0.1079 (0.1113)  time: 0.0909  data: 0.0001  max mem: 11902
[18:00:15.009869] Test:  [344/345]  eta: 0:00:00  loss: 0.1079 (0.1112)  time: 0.0911  data: 0.0001  max mem: 11902
[18:00:15.078046] Test: Total time: 0:00:29 (0.0868 s / it)
[18:00:25.048519] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4796 (0.4796)  time: 0.4105  data: 0.3336  max mem: 11902
[18:00:25.847663] Test:  [10/57]  eta: 0:00:05  loss: 0.4430 (0.4739)  time: 0.1099  data: 0.0313  max mem: 11902
[18:00:26.640125] Test:  [20/57]  eta: 0:00:03  loss: 0.4416 (0.4588)  time: 0.0795  data: 0.0006  max mem: 11902
[18:00:27.434658] Test:  [30/57]  eta: 0:00:02  loss: 0.2791 (0.3992)  time: 0.0793  data: 0.0001  max mem: 11902
[18:00:28.234164] Test:  [40/57]  eta: 0:00:01  loss: 0.2785 (0.3774)  time: 0.0796  data: 0.0001  max mem: 11902
[18:00:29.036600] Test:  [50/57]  eta: 0:00:00  loss: 0.3180 (0.3820)  time: 0.0800  data: 0.0001  max mem: 11902
[18:00:29.473208] Test:  [56/57]  eta: 0:00:00  loss: 0.3651 (0.4145)  time: 0.0779  data: 0.0000  max mem: 11902
[18:00:29.531241] Test: Total time: 0:00:04 (0.0859 s / it)
[18:00:31.298388] Dice score of the network on the train images: 0.885079, val images: 0.720200
[18:00:31.301992] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[18:00:31.892717] Epoch: [47]  [  0/345]  eta: 0:03:23  lr: 0.000003  loss: 0.1003 (0.1003)  time: 0.5896  data: 0.3448  max mem: 11902
[18:00:36.780033] Epoch: [47]  [ 20/345]  eta: 0:01:24  lr: 0.000003  loss: 0.1153 (0.1155)  time: 0.2443  data: 0.0001  max mem: 11902
[18:00:41.666624] Epoch: [47]  [ 40/345]  eta: 0:01:17  lr: 0.000003  loss: 0.1190 (0.1183)  time: 0.2443  data: 0.0001  max mem: 11902
[18:00:46.551752] Epoch: [47]  [ 60/345]  eta: 0:01:11  lr: 0.000003  loss: 0.1195 (0.1193)  time: 0.2442  data: 0.0001  max mem: 11902
[18:00:51.443539] Epoch: [47]  [ 80/345]  eta: 0:01:05  lr: 0.000003  loss: 0.1155 (0.1189)  time: 0.2445  data: 0.0001  max mem: 11902
[18:00:56.337568] Epoch: [47]  [100/345]  eta: 0:01:00  lr: 0.000003  loss: 0.1159 (0.1184)  time: 0.2446  data: 0.0001  max mem: 11902

[18:01:01.227196] Epoch: [47]  [120/345]  eta: 0:00:55  lr: 0.000002  loss: 0.1083 (0.1179)  time: 0.2444  data: 0.0001  max mem: 11902
[18:01:06.124566] Epoch: [47]  [140/345]  eta: 0:00:50  lr: 0.000002  loss: 0.1079 (0.1175)  time: 0.2448  data: 0.0001  max mem: 11902
[18:01:11.026015] Epoch: [47]  [160/345]  eta: 0:00:45  lr: 0.000002  loss: 0.1105 (0.1172)  time: 0.2450  data: 0.0001  max mem: 11902
[18:01:15.929672] Epoch: [47]  [180/345]  eta: 0:00:40  lr: 0.000002  loss: 0.1073 (0.1168)  time: 0.2451  data: 0.0001  max mem: 11902
[18:01:20.825892] Epoch: [47]  [200/345]  eta: 0:00:35  lr: 0.000002  loss: 0.1141 (0.1170)  time: 0.2448  data: 0.0001  max mem: 11902
[18:01:25.717105] Epoch: [47]  [220/345]  eta: 0:00:30  lr: 0.000002  loss: 0.1195 (0.1169)  time: 0.2445  data: 0.0001  max mem: 11902
[18:01:30.629418] Epoch: [47]  [240/345]  eta: 0:00:25  lr: 0.000002  loss: 0.1115 (0.1169)  time: 0.2456  data: 0.0001  max mem: 11902
[18:01:35.536512] Epoch: [47]  [260/345]  eta: 0:00:20  lr: 0.000002  loss: 0.1144 (0.1171)  time: 0.2453  data: 0.0001  max mem: 11902
[18:01:40.446297] Epoch: [47]  [280/345]  eta: 0:00:15  lr: 0.000002  loss: 0.1143 (0.1171)  time: 0.2454  data: 0.0001  max mem: 11902
[18:01:45.356540] Epoch: [47]  [300/345]  eta: 0:00:11  lr: 0.000002  loss: 0.1124 (0.1172)  time: 0.2455  data: 0.0001  max mem: 11902
[18:01:50.257422] Epoch: [47]  [320/345]  eta: 0:00:06  lr: 0.000001  loss: 0.1117 (0.1171)  time: 0.2450  data: 0.0001  max mem: 11902
[18:01:55.156795] Epoch: [47]  [340/345]  eta: 0:00:01  lr: 0.000001  loss: 0.1139 (0.1169)  time: 0.2449  data: 0.0001  max mem: 11902
[18:01:56.135650] Epoch: [47]  [344/345]  eta: 0:00:00  lr: 0.000001  loss: 0.1132 (0.1168)  time: 0.2448  data: 0.0001  max mem: 11902
[18:01:56.198630] Epoch: [47] Total time: 0:01:24 (0.2461 s / it)
[18:01:56.198891] Averaged stats: lr: 0.000001  loss: 0.1132 (0.1168)
[18:01:56.691180] Test:  [  0/345]  eta: 0:02:48  loss: 0.1510 (0.1510)  time: 0.4875  data: 0.4102  max mem: 11902
[18:01:57.485064] Test:  [ 10/345]  eta: 0:00:38  loss: 0.1192 (0.1200)  time: 0.1164  data: 0.0374  max mem: 11902
[18:01:58.282642] Test:  [ 20/345]  eta: 0:00:32  loss: 0.1188 (0.1221)  time: 0.0795  data: 0.0001  max mem: 11902
[18:01:59.084654] Test:  [ 30/345]  eta: 0:00:29  loss: 0.1130 (0.1161)  time: 0.0799  data: 0.0001  max mem: 11902
[18:01:59.888252] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1040 (0.1135)  time: 0.0802  data: 0.0001  max mem: 11902
[18:02:00.696807] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1088 (0.1144)  time: 0.0805  data: 0.0001  max mem: 11902
[18:02:01.508911] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1111 (0.1145)  time: 0.0810  data: 0.0001  max mem: 11902
[18:02:02.325594] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1087 (0.1144)  time: 0.0814  data: 0.0001  max mem: 11902
[18:02:03.144016] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1115 (0.1140)  time: 0.0817  data: 0.0001  max mem: 11902
[18:02:03.966627] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1157 (0.1136)  time: 0.0820  data: 0.0001  max mem: 11902
[18:02:04.791871] Test:  [100/345]  eta: 0:00:20  loss: 0.1152 (0.1142)  time: 0.0823  data: 0.0001  max mem: 11902
[18:02:05.622080] Test:  [110/345]  eta: 0:00:19  loss: 0.1125 (0.1134)  time: 0.0827  data: 0.0001  max mem: 11902
[18:02:06.455656] Test:  [120/345]  eta: 0:00:19  loss: 0.1080 (0.1137)  time: 0.0831  data: 0.0001  max mem: 11902
[18:02:07.293090] Test:  [130/345]  eta: 0:00:18  loss: 0.1082 (0.1134)  time: 0.0835  data: 0.0001  max mem: 11902
[18:02:08.133486] Test:  [140/345]  eta: 0:00:17  loss: 0.1059 (0.1138)  time: 0.0838  data: 0.0001  max mem: 11902
[18:02:08.978063] Test:  [150/345]  eta: 0:00:16  loss: 0.1059 (0.1131)  time: 0.0842  data: 0.0001  max mem: 11902
[18:02:09.826968] Test:  [160/345]  eta: 0:00:15  loss: 0.1067 (0.1130)  time: 0.0846  data: 0.0001  max mem: 11902
[18:02:10.678913] Test:  [170/345]  eta: 0:00:14  loss: 0.1103 (0.1129)  time: 0.0850  data: 0.0001  max mem: 11902
[18:02:11.533593] Test:  [180/345]  eta: 0:00:13  loss: 0.1095 (0.1124)  time: 0.0853  data: 0.0001  max mem: 11902
[18:02:12.392151] Test:  [190/345]  eta: 0:00:13  loss: 0.1016 (0.1118)  time: 0.0856  data: 0.0001  max mem: 11902
[18:02:13.254076] Test:  [200/345]  eta: 0:00:12  loss: 0.1012 (0.1117)  time: 0.0860  data: 0.0001  max mem: 11902
[18:02:14.119703] Test:  [210/345]  eta: 0:00:11  loss: 0.0990 (0.1112)  time: 0.0863  data: 0.0001  max mem: 11902
[18:02:14.989737] Test:  [220/345]  eta: 0:00:10  loss: 0.1094 (0.1115)  time: 0.0867  data: 0.0001  max mem: 11902
[18:02:15.862694] Test:  [230/345]  eta: 0:00:09  loss: 0.1094 (0.1114)  time: 0.0871  data: 0.0001  max mem: 11902
[18:02:16.739373] Test:  [240/345]  eta: 0:00:08  loss: 0.1088 (0.1115)  time: 0.0874  data: 0.0001  max mem: 11902
[18:02:17.620540] Test:  [250/345]  eta: 0:00:08  loss: 0.1108 (0.1118)  time: 0.0878  data: 0.0001  max mem: 11902
[18:02:18.504333] Test:  [260/345]  eta: 0:00:07  loss: 0.1078 (0.1118)  time: 0.0882  data: 0.0001  max mem: 11902
[18:02:19.391645] Test:  [270/345]  eta: 0:00:06  loss: 0.1073 (0.1116)  time: 0.0885  data: 0.0001  max mem: 11902
[18:02:20.283032] Test:  [280/345]  eta: 0:00:05  loss: 0.1016 (0.1113)  time: 0.0889  data: 0.0001  max mem: 11902
[18:02:21.177896] Test:  [290/345]  eta: 0:00:04  loss: 0.1021 (0.1113)  time: 0.0893  data: 0.0001  max mem: 11902
[18:02:22.074842] Test:  [300/345]  eta: 0:00:03  loss: 0.1094 (0.1112)  time: 0.0895  data: 0.0001  max mem: 11902
[18:02:22.975850] Test:  [310/345]  eta: 0:00:03  loss: 0.1071 (0.1110)  time: 0.0898  data: 0.0001  max mem: 11902
[18:02:23.880329] Test:  [320/345]  eta: 0:00:02  loss: 0.1034 (0.1108)  time: 0.0902  data: 0.0001  max mem: 11902
[18:02:24.789882] Test:  [330/345]  eta: 0:00:01  loss: 0.1015 (0.1107)  time: 0.0906  data: 0.0001  max mem: 11902
[18:02:25.702640] Test:  [340/345]  eta: 0:00:00  loss: 0.0996 (0.1105)  time: 0.0911  data: 0.0001  max mem: 11902
[18:02:26.067996] Test:  [344/345]  eta: 0:00:00  loss: 0.1041 (0.1104)  time: 0.0912  data: 0.0001  max mem: 11902
[18:02:26.127994] Test: Total time: 0:00:29 (0.0867 s / it)
[18:02:36.080277] Test:  [ 0/57]  eta: 0:00:23  loss: 0.4839 (0.4839)  time: 0.4059  data: 0.3289  max mem: 11902
[18:02:36.879388] Test:  [10/57]  eta: 0:00:05  loss: 0.4473 (0.4812)  time: 0.1094  data: 0.0308  max mem: 11902
[18:02:37.672003] Test:  [20/57]  eta: 0:00:03  loss: 0.4442 (0.4645)  time: 0.0795  data: 0.0006  max mem: 11902
[18:02:38.468957] Test:  [30/57]  eta: 0:00:02  loss: 0.2814 (0.4035)  time: 0.0794  data: 0.0001  max mem: 11902
[18:02:39.270580] Test:  [40/57]  eta: 0:00:01  loss: 0.2813 (0.3814)  time: 0.0798  data: 0.0001  max mem: 11902
[18:02:40.073347] Test:  [50/57]  eta: 0:00:00  loss: 0.3189 (0.3856)  time: 0.0802  data: 0.0001  max mem: 11902
[18:02:40.508687] Test:  [56/57]  eta: 0:00:00  loss: 0.3688 (0.4177)  time: 0.0779  data: 0.0001  max mem: 11902
[18:02:40.571185] Test: Total time: 0:00:04 (0.0859 s / it)
[18:02:42.324927] Dice score of the network on the train images: 0.885921, val images: 0.716832
[18:02:42.328422] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[18:02:42.919251] Epoch: [48]  [  0/345]  eta: 0:03:23  lr: 0.000001  loss: 0.1265 (0.1265)  time: 0.5902  data: 0.3443  max mem: 11902
[18:02:47.792381] Epoch: [48]  [ 20/345]  eta: 0:01:24  lr: 0.000001  loss: 0.1116 (0.1173)  time: 0.2436  data: 0.0001  max mem: 11902
[18:02:52.661097] Epoch: [48]  [ 40/345]  eta: 0:01:16  lr: 0.000001  loss: 0.1170 (0.1163)  time: 0.2434  data: 0.0001  max mem: 11902
[18:02:57.525659] Epoch: [48]  [ 60/345]  eta: 0:01:10  lr: 0.000001  loss: 0.1096 (0.1155)  time: 0.2432  data: 0.0001  max mem: 11902
[18:03:02.402838] Epoch: [48]  [ 80/345]  eta: 0:01:05  lr: 0.000001  loss: 0.1122 (0.1151)  time: 0.2438  data: 0.0001  max mem: 11902
[18:03:07.280950] Epoch: [48]  [100/345]  eta: 0:01:00  lr: 0.000001  loss: 0.1202 (0.1163)  time: 0.2439  data: 0.0001  max mem: 11902
[18:03:12.173286] Epoch: [48]  [120/345]  eta: 0:00:55  lr: 0.000001  loss: 0.1212 (0.1175)  time: 0.2446  data: 0.0001  max mem: 11902
[18:03:17.065190] Epoch: [48]  [140/345]  eta: 0:00:50  lr: 0.000001  loss: 0.1154 (0.1173)  time: 0.2446  data: 0.0001  max mem: 11902
[18:03:21.965322] Epoch: [48]  [160/345]  eta: 0:00:45  lr: 0.000001  loss: 0.1143 (0.1172)  time: 0.2450  data: 0.0001  max mem: 11902
[18:03:26.865112] Epoch: [48]  [180/345]  eta: 0:00:40  lr: 0.000001  loss: 0.1051 (0.1165)  time: 0.2449  data: 0.0001  max mem: 11902
[18:03:31.763038] Epoch: [48]  [200/345]  eta: 0:00:35  lr: 0.000001  loss: 0.1096 (0.1165)  time: 0.2449  data: 0.0001  max mem: 11902
[18:03:36.662066] Epoch: [48]  [220/345]  eta: 0:00:30  lr: 0.000001  loss: 0.1125 (0.1162)  time: 0.2449  data: 0.0001  max mem: 11902
[18:03:41.563121] Epoch: [48]  [240/345]  eta: 0:00:25  lr: 0.000001  loss: 0.1197 (0.1167)  time: 0.2450  data: 0.0001  max mem: 11902
[18:03:46.465951] Epoch: [48]  [260/345]  eta: 0:00:20  lr: 0.000001  loss: 0.1195 (0.1171)  time: 0.2451  data: 0.0001  max mem: 11902
[18:03:51.369532] Epoch: [48]  [280/345]  eta: 0:00:15  lr: 0.000000  loss: 0.1020 (0.1164)  time: 0.2451  data: 0.0001  max mem: 11902
[18:03:56.284841] Epoch: [48]  [300/345]  eta: 0:00:11  lr: 0.000000  loss: 0.1151 (0.1164)  time: 0.2457  data: 0.0001  max mem: 11902
[18:04:01.196771] Epoch: [48]  [320/345]  eta: 0:00:06  lr: 0.000000  loss: 0.1149 (0.1165)  time: 0.2455  data: 0.0001  max mem: 11902
[18:04:06.098220] Epoch: [48]  [340/345]  eta: 0:00:01  lr: 0.000000  loss: 0.1154 (0.1166)  time: 0.2450  data: 0.0001  max mem: 11902
[18:04:07.078759] Epoch: [48]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.1171 (0.1166)  time: 0.2450  data: 0.0001  max mem: 11902
[18:04:07.158429] Epoch: [48] Total time: 0:01:24 (0.2459 s / it)
[18:04:07.158785] Averaged stats: lr: 0.000000  loss: 0.1171 (0.1166)
[18:04:07.621125] Test:  [  0/345]  eta: 0:02:37  loss: 0.1270 (0.1270)  time: 0.4576  data: 0.3806  max mem: 11902
[18:04:08.417451] Test:  [ 10/345]  eta: 0:00:38  loss: 0.1139 (0.1096)  time: 0.1139  data: 0.0347  max mem: 11902
[18:04:09.217919] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1107 (0.1114)  time: 0.0797  data: 0.0001  max mem: 11902
[18:04:10.020128] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1169 (0.1153)  time: 0.0801  data: 0.0001  max mem: 11902
[18:04:10.824558] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1207 (0.1177)  time: 0.0802  data: 0.0001  max mem: 11902
[18:04:11.633605] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1155 (0.1162)  time: 0.0806  data: 0.0001  max mem: 11902
[18:04:12.446013] Test:  [ 60/345]  eta: 0:00:24  loss: 0.0998 (0.1136)  time: 0.0810  data: 0.0001  max mem: 11902
[18:04:13.262495] Test:  [ 70/345]  eta: 0:00:23  loss: 0.0998 (0.1128)  time: 0.0814  data: 0.0001  max mem: 11902
[18:04:14.080408] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1060 (0.1125)  time: 0.0816  data: 0.0001  max mem: 11902
[18:04:14.903451] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1078 (0.1120)  time: 0.0820  data: 0.0001  max mem: 11902
[18:04:15.729621] Test:  [100/345]  eta: 0:00:20  loss: 0.1090 (0.1116)  time: 0.0824  data: 0.0001  max mem: 11902
[18:04:16.560424] Test:  [110/345]  eta: 0:00:19  loss: 0.1090 (0.1112)  time: 0.0828  data: 0.0001  max mem: 11902
[18:04:17.393874] Test:  [120/345]  eta: 0:00:19  loss: 0.1115 (0.1110)  time: 0.0831  data: 0.0001  max mem: 11902
[18:04:18.230771] Test:  [130/345]  eta: 0:00:18  loss: 0.1132 (0.1114)  time: 0.0834  data: 0.0001  max mem: 11902
[18:04:19.072162] Test:  [140/345]  eta: 0:00:17  loss: 0.1129 (0.1114)  time: 0.0838  data: 0.0001  max mem: 11902
[18:04:19.917477] Test:  [150/345]  eta: 0:00:16  loss: 0.1036 (0.1107)  time: 0.0843  data: 0.0001  max mem: 11902
[18:04:20.766468] Test:  [160/345]  eta: 0:00:15  loss: 0.1073 (0.1111)  time: 0.0846  data: 0.0001  max mem: 11902
[18:04:21.618712] Test:  [170/345]  eta: 0:00:14  loss: 0.1141 (0.1113)  time: 0.0850  data: 0.0001  max mem: 11902
[18:04:22.474357] Test:  [180/345]  eta: 0:00:13  loss: 0.1066 (0.1112)  time: 0.0853  data: 0.0001  max mem: 11902
[18:04:23.332882] Test:  [190/345]  eta: 0:00:13  loss: 0.1057 (0.1109)  time: 0.0856  data: 0.0001  max mem: 11902
[18:04:24.196407] Test:  [200/345]  eta: 0:00:12  loss: 0.1069 (0.1111)  time: 0.0860  data: 0.0001  max mem: 11902
[18:04:25.062426] Test:  [210/345]  eta: 0:00:11  loss: 0.1070 (0.1112)  time: 0.0864  data: 0.0001  max mem: 11902
[18:04:25.932519] Test:  [220/345]  eta: 0:00:10  loss: 0.1074 (0.1112)  time: 0.0867  data: 0.0001  max mem: 11902
[18:04:26.806296] Test:  [230/345]  eta: 0:00:09  loss: 0.1074 (0.1115)  time: 0.0871  data: 0.0001  max mem: 11902
[18:04:27.682798] Test:  [240/345]  eta: 0:00:08  loss: 0.1019 (0.1109)  time: 0.0874  data: 0.0001  max mem: 11902
[18:04:28.564403] Test:  [250/345]  eta: 0:00:08  loss: 0.0966 (0.1108)  time: 0.0878  data: 0.0001  max mem: 11902
[18:04:29.449137] Test:  [260/345]  eta: 0:00:07  loss: 0.1024 (0.1107)  time: 0.0882  data: 0.0001  max mem: 11902
[18:04:30.336504] Test:  [270/345]  eta: 0:00:06  loss: 0.1024 (0.1105)  time: 0.0885  data: 0.0001  max mem: 11902
[18:04:31.228928] Test:  [280/345]  eta: 0:00:05  loss: 0.1038 (0.1103)  time: 0.0889  data: 0.0001  max mem: 11902
[18:04:32.123090] Test:  [290/345]  eta: 0:00:04  loss: 0.1018 (0.1101)  time: 0.0893  data: 0.0001  max mem: 11902
[18:04:33.021102] Test:  [300/345]  eta: 0:00:03  loss: 0.1058 (0.1100)  time: 0.0895  data: 0.0001  max mem: 11902
[18:04:33.923195] Test:  [310/345]  eta: 0:00:03  loss: 0.1067 (0.1101)  time: 0.0899  data: 0.0001  max mem: 11902
[18:04:34.827785] Test:  [320/345]  eta: 0:00:02  loss: 0.1052 (0.1102)  time: 0.0903  data: 0.0001  max mem: 11902
[18:04:35.736824] Test:  [330/345]  eta: 0:00:01  loss: 0.1086 (0.1102)  time: 0.0906  data: 0.0001  max mem: 11902
[18:04:36.648171] Test:  [340/345]  eta: 0:00:00  loss: 0.1070 (0.1102)  time: 0.0910  data: 0.0001  max mem: 11902
[18:04:37.013270] Test:  [344/345]  eta: 0:00:00  loss: 0.1066 (0.1103)  time: 0.0911  data: 0.0001  max mem: 11902
[18:04:37.082257] Test: Total time: 0:00:29 (0.0867 s / it)
[18:04:47.050490] Test:  [ 0/57]  eta: 0:00:24  loss: 0.4830 (0.4830)  time: 0.4261  data: 0.3491  max mem: 11902
[18:04:47.840389] Test:  [10/57]  eta: 0:00:05  loss: 0.4466 (0.4816)  time: 0.1104  data: 0.0319  max mem: 11902
[18:04:48.633467] Test:  [20/57]  eta: 0:00:03  loss: 0.4442 (0.4650)  time: 0.0791  data: 0.0001  max mem: 11902
[18:04:49.427978] Test:  [30/57]  eta: 0:00:02  loss: 0.2816 (0.4043)  time: 0.0793  data: 0.0001  max mem: 11902
[18:04:50.227644] Test:  [40/57]  eta: 0:00:01  loss: 0.2806 (0.3824)  time: 0.0796  data: 0.0001  max mem: 11902
[18:04:51.029574] Test:  [50/57]  eta: 0:00:00  loss: 0.3198 (0.3869)  time: 0.0800  data: 0.0001  max mem: 11902
[18:04:51.465433] Test:  [56/57]  eta: 0:00:00  loss: 0.3708 (0.4193)  time: 0.0778  data: 0.0000  max mem: 11902
[18:04:51.531701] Test: Total time: 0:00:04 (0.0861 s / it)
[18:04:53.291087] Dice score of the network on the train images: 0.886054, val images: 0.712577
[18:04:53.294793] log_dir: /root/seg_framework/MS-Mamba/output_dir/segformer/train_ft
[18:04:53.882718] Epoch: [49]  [  0/345]  eta: 0:03:22  lr: 0.000000  loss: 0.1107 (0.1107)  time: 0.5873  data: 0.3412  max mem: 11902
[18:04:58.751695] Epoch: [49]  [ 20/345]  eta: 0:01:24  lr: 0.000000  loss: 0.1132 (0.1137)  time: 0.2434  data: 0.0001  max mem: 11902
[18:05:03.624801] Epoch: [49]  [ 40/345]  eta: 0:01:16  lr: 0.000000  loss: 0.1038 (0.1137)  time: 0.2436  data: 0.0001  max mem: 11902
[18:05:08.500154] Epoch: [49]  [ 60/345]  eta: 0:01:11  lr: 0.000000  loss: 0.1149 (0.1154)  time: 0.2437  data: 0.0001  max mem: 11902
[18:05:13.380615] Epoch: [49]  [ 80/345]  eta: 0:01:05  lr: 0.000000  loss: 0.1184 (0.1165)  time: 0.2440  data: 0.0001  max mem: 11902
[18:05:18.272435] Epoch: [49]  [100/345]  eta: 0:01:00  lr: 0.000000  loss: 0.1105 (0.1159)  time: 0.2445  data: 0.0001  max mem: 11902
[18:05:23.234790] Epoch: [49]  [120/345]  eta: 0:00:55  lr: 0.000000  loss: 0.1088 (0.1159)  time: 0.2481  data: 0.0001  max mem: 11902
[18:05:28.122933] Epoch: [49]  [140/345]  eta: 0:00:50  lr: 0.000000  loss: 0.1106 (0.1157)  time: 0.2444  data: 0.0001  max mem: 11902
[18:05:33.015777] Epoch: [49]  [160/345]  eta: 0:00:45  lr: 0.000000  loss: 0.1155 (0.1165)  time: 0.2446  data: 0.0001  max mem: 11902
[18:05:37.916089] Epoch: [49]  [180/345]  eta: 0:00:40  lr: 0.000000  loss: 0.1084 (0.1156)  time: 0.2450  data: 0.0001  max mem: 11902
[18:05:42.817947] Epoch: [49]  [200/345]  eta: 0:00:35  lr: 0.000000  loss: 0.1177 (0.1158)  time: 0.2450  data: 0.0001  max mem: 11902
[18:05:47.723374] Epoch: [49]  [220/345]  eta: 0:00:30  lr: 0.000000  loss: 0.1214 (0.1164)  time: 0.2452  data: 0.0001  max mem: 11902
[18:05:52.628751] Epoch: [49]  [240/345]  eta: 0:00:25  lr: 0.000000  loss: 0.1124 (0.1162)  time: 0.2452  data: 0.0001  max mem: 11902
[18:05:57.533784] Epoch: [49]  [260/345]  eta: 0:00:20  lr: 0.000000  loss: 0.1158 (0.1163)  time: 0.2452  data: 0.0001  max mem: 11902
[18:06:02.441470] Epoch: [49]  [280/345]  eta: 0:00:15  lr: 0.000000  loss: 0.1143 (0.1161)  time: 0.2453  data: 0.0001  max mem: 11902
[18:06:07.354815] Epoch: [49]  [300/345]  eta: 0:00:11  lr: 0.000000  loss: 0.1193 (0.1165)  time: 0.2456  data: 0.0001  max mem: 11902
[18:06:12.264923] Epoch: [49]  [320/345]  eta: 0:00:06  lr: 0.000000  loss: 0.1191 (0.1166)  time: 0.2455  data: 0.0001  max mem: 11902
[18:06:17.168697] Epoch: [49]  [340/345]  eta: 0:00:01  lr: 0.000000  loss: 0.1060 (0.1163)  time: 0.2451  data: 0.0001  max mem: 11902
[18:06:18.147128] Epoch: [49]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.1067 (0.1164)  time: 0.2448  data: 0.0001  max mem: 11902
[18:06:18.208872] Epoch: [49] Total time: 0:01:24 (0.2461 s / it)
[18:06:18.209698] Averaged stats: lr: 0.000000  loss: 0.1067 (0.1164)
[18:06:18.660271] Test:  [  0/345]  eta: 0:02:33  loss: 0.0906 (0.0906)  time: 0.4463  data: 0.3691  max mem: 11902
[18:06:19.461556] Test:  [ 10/345]  eta: 0:00:37  loss: 0.1033 (0.1060)  time: 0.1133  data: 0.0343  max mem: 11902
[18:06:20.259353] Test:  [ 20/345]  eta: 0:00:31  loss: 0.1062 (0.1084)  time: 0.0798  data: 0.0004  max mem: 11902
[18:06:21.060385] Test:  [ 30/345]  eta: 0:00:28  loss: 0.1099 (0.1135)  time: 0.0798  data: 0.0001  max mem: 11902
[18:06:21.864183] Test:  [ 40/345]  eta: 0:00:27  loss: 0.1102 (0.1134)  time: 0.0802  data: 0.0001  max mem: 11902
[18:06:22.673148] Test:  [ 50/345]  eta: 0:00:25  loss: 0.1039 (0.1127)  time: 0.0806  data: 0.0001  max mem: 11902
[18:06:23.485878] Test:  [ 60/345]  eta: 0:00:24  loss: 0.1065 (0.1125)  time: 0.0810  data: 0.0001  max mem: 11902
[18:06:24.301847] Test:  [ 70/345]  eta: 0:00:23  loss: 0.1095 (0.1123)  time: 0.0813  data: 0.0001  max mem: 11902
[18:06:25.121401] Test:  [ 80/345]  eta: 0:00:22  loss: 0.1086 (0.1121)  time: 0.0817  data: 0.0001  max mem: 11902
[18:06:25.944383] Test:  [ 90/345]  eta: 0:00:21  loss: 0.1056 (0.1115)  time: 0.0820  data: 0.0001  max mem: 11902
[18:06:26.770286] Test:  [100/345]  eta: 0:00:20  loss: 0.1039 (0.1113)  time: 0.0824  data: 0.0001  max mem: 11902
[18:06:27.601925] Test:  [110/345]  eta: 0:00:19  loss: 0.1050 (0.1111)  time: 0.0828  data: 0.0001  max mem: 11902
[18:06:28.434598] Test:  [120/345]  eta: 0:00:18  loss: 0.1050 (0.1106)  time: 0.0831  data: 0.0001  max mem: 11902
[18:06:29.272178] Test:  [130/345]  eta: 0:00:18  loss: 0.1052 (0.1110)  time: 0.0834  data: 0.0001  max mem: 11902
[18:06:30.113578] Test:  [140/345]  eta: 0:00:17  loss: 0.1134 (0.1114)  time: 0.0839  data: 0.0001  max mem: 11902
[18:06:30.958611] Test:  [150/345]  eta: 0:00:16  loss: 0.1136 (0.1117)  time: 0.0842  data: 0.0001  max mem: 11902
[18:06:31.806216] Test:  [160/345]  eta: 0:00:15  loss: 0.1077 (0.1112)  time: 0.0845  data: 0.0001  max mem: 11902
[18:06:32.658471] Test:  [170/345]  eta: 0:00:14  loss: 0.1035 (0.1112)  time: 0.0849  data: 0.0001  max mem: 11902
[18:06:33.513485] Test:  [180/345]  eta: 0:00:13  loss: 0.1034 (0.1110)  time: 0.0853  data: 0.0001  max mem: 11902
[18:06:34.372560] Test:  [190/345]  eta: 0:00:13  loss: 0.1056 (0.1110)  time: 0.0856  data: 0.0001  max mem: 11902
[18:06:35.235319] Test:  [200/345]  eta: 0:00:12  loss: 0.0995 (0.1104)  time: 0.0860  data: 0.0001  max mem: 11902
[18:06:36.102209] Test:  [210/345]  eta: 0:00:11  loss: 0.0995 (0.1103)  time: 0.0864  data: 0.0001  max mem: 11902
[18:06:36.972557] Test:  [220/345]  eta: 0:00:10  loss: 0.1092 (0.1102)  time: 0.0868  data: 0.0001  max mem: 11902
[18:06:37.846331] Test:  [230/345]  eta: 0:00:09  loss: 0.1106 (0.1106)  time: 0.0871  data: 0.0001  max mem: 11902
[18:06:38.723150] Test:  [240/345]  eta: 0:00:08  loss: 0.1079 (0.1104)  time: 0.0875  data: 0.0001  max mem: 11902
[18:06:39.603194] Test:  [250/345]  eta: 0:00:08  loss: 0.1034 (0.1105)  time: 0.0878  data: 0.0001  max mem: 11902
[18:06:40.487970] Test:  [260/345]  eta: 0:00:07  loss: 0.1049 (0.1105)  time: 0.0882  data: 0.0001  max mem: 11902
[18:06:41.376672] Test:  [270/345]  eta: 0:00:06  loss: 0.1119 (0.1107)  time: 0.0886  data: 0.0001  max mem: 11902
[18:06:42.268435] Test:  [280/345]  eta: 0:00:05  loss: 0.1079 (0.1109)  time: 0.0889  data: 0.0001  max mem: 11902
[18:06:43.162331] Test:  [290/345]  eta: 0:00:04  loss: 0.1078 (0.1106)  time: 0.0892  data: 0.0001  max mem: 11902
[18:06:44.060257] Test:  [300/345]  eta: 0:00:03  loss: 0.1043 (0.1107)  time: 0.0895  data: 0.0001  max mem: 11902
[18:06:44.962145] Test:  [310/345]  eta: 0:00:03  loss: 0.1043 (0.1107)  time: 0.0899  data: 0.0001  max mem: 11902
[18:06:45.866292] Test:  [320/345]  eta: 0:00:02  loss: 0.1099 (0.1106)  time: 0.0902  data: 0.0001  max mem: 11902
[18:06:46.775494] Test:  [330/345]  eta: 0:00:01  loss: 0.1076 (0.1106)  time: 0.0906  data: 0.0001  max mem: 11902
[18:06:47.687156] Test:  [340/345]  eta: 0:00:00  loss: 0.1057 (0.1104)  time: 0.0910  data: 0.0001  max mem: 11902
[18:06:48.053465] Test:  [344/345]  eta: 0:00:00  loss: 0.1057 (0.1104)  time: 0.0911  data: 0.0001  max mem: 11902
[18:06:48.133882] Test: Total time: 0:00:29 (0.0867 s / it)
[18:06:58.042560] Test:  [ 0/57]  eta: 0:00:22  loss: 0.4827 (0.4827)  time: 0.4012  data: 0.3243  max mem: 11902
[18:06:58.853636] Test:  [10/57]  eta: 0:00:05  loss: 0.4459 (0.4799)  time: 0.1101  data: 0.0315  max mem: 11902
[18:06:59.645364] Test:  [20/57]  eta: 0:00:03  loss: 0.4433 (0.4635)  time: 0.0801  data: 0.0012  max mem: 11902
[18:07:00.442402] Test:  [30/57]  eta: 0:00:02  loss: 0.2809 (0.4029)  time: 0.0794  data: 0.0001  max mem: 11902
[18:07:01.243347] Test:  [40/57]  eta: 0:00:01  loss: 0.2803 (0.3810)  time: 0.0798  data: 0.0001  max mem: 11902
[18:07:02.046880] Test:  [50/57]  eta: 0:00:00  loss: 0.3189 (0.3854)  time: 0.0802  data: 0.0001  max mem: 11902
[18:07:02.482152] Test:  [56/57]  eta: 0:00:00  loss: 0.3691 (0.4175)  time: 0.0779  data: 0.0001  max mem: 11902
[18:07:02.549375] Test: Total time: 0:00:04 (0.0861 s / it)
Traceback (most recent call last):
  File "/root/anaconda3/envs/vivim/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/root/anaconda3/envs/vivim/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/root/seg_framework/MS-Mamba/run_scripts/K_fold_mslesseg_25D.py", line 579, in <module>
    main(args)
  File "/root/seg_framework/MS-Mamba/run_scripts/K_fold_mslesseg_25D.py", line 544, in main
    checkpoint = torch.load(args.finetune, map_location='cpu')
  File "/root/anaconda3/envs/vivim/lib/python3.10/site-packages/torch/serialization.py", line 986, in load
    with _open_file_like(f, 'rb') as opened_file:
  File "/root/anaconda3/envs/vivim/lib/python3.10/site-packages/torch/serialization.py", line 435, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/root/anaconda3/envs/vivim/lib/python3.10/site-packages/torch/serialization.py", line 416, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: '/root/seg_framework/MS-Mamba/output_dir_test/mslesseg/checkpoints_0/checkpoint-best_dice_model_0.pth'
[18:07:04.306371] Dice score of the network on the train images: 0.885945, val images: 0.715814
[18:07:04.307926] Training time 1:49:27
[18:07:05.341430] [18:07:05.341672] [18:07:05.341756] [18:07:05.341830] [18:07:05.341894] [18:07:05.341952] [18:07:05.342011] [18:07:05.342070] [18:07:05.342133]
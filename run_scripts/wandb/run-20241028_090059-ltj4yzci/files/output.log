Not using distributed mode
[09:01:01.437699] job dir: /root/seg_framework/MS-Mamba/run_scripts
[09:01:01.437839] Namespace(accum_iter=1,
model='SegFormer3D',
in_channels=1,
lr=None,
blr=0.001,
min_lr=0,
dist_on_itp=False,
warmup_epochs=20,
device='cuda:0',
seed=42,
layer_decay=0.75,
clip_grad=None,
num_workers=1,
pin_mem=True,
resume='',
mask_mode='concatenate to image',
world_size=1,
embed_dim=1,
local_rank=-1,
dist_url='env://',
nb_classes=2,
data_dir='/root/MSLesSeg24/data',
datalist=None,
preprocess=True,
dim=2,
loss='mask tp1 tp2',
distributed=False)
[09:01:01.437955] device  cuda:0
[09:01:01.438647] Random seed set as 42
[09:01:01.439014] Starting for fold 0
[09:01:01.440982] Preprocessing files...
[09:01:01.441068] Processing patient P9
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/val_ft
[09:01:25.085469] Processing patient P11
[09:01:41.023475] Processing patient P28
[09:01:56.714811] Processing patient P20
[09:02:20.213748] Processing patient P10
[09:02:35.915741] Processing patient P49
[09:02:51.576346] Processing patient P33
[09:03:07.504170] Processing patient P19
[09:03:38.801084] Processing patient P22
[09:03:54.488436] Processing patient P14
[09:04:26.039240] Processing patient P1
[09:04:49.506836] Processing patient P12
[09:05:20.840143] Processing patient P53
[09:05:36.575755] Processing patient P5
[09:05:52.319608] Processing patient P52
[09:06:08.094766] Processing patient P2
[09:06:39.327869] Files preprocessed.
[09:06:39.516243] Elements in data_dir_paths before filtering empty slices: 27468
[09:07:01.509067] Elements in data_dir_paths after filtering empty slices: 11052
[09:07:01.514435] Preprocessing files...
[09:07:01.514531] Processing patient P4
[09:07:24.953706] Processing patient P50
[09:07:40.607698] Processing patient P31
[09:07:56.719698] Processing patient P13
[09:08:12.401111] Files preprocessed.
[09:08:12.435174] Elements in data_dir_paths before filtering empty slices: 3924
[09:08:12.957589] Elements in data_dir_paths after filtering empty slices: 1803
[09:08:12.958236] Preprocessing files...
[09:08:12.958315] Processing patient P3
[09:08:44.292429] Processing patient P51
[09:09:00.238320] Processing patient P7
[09:09:15.898728] Processing patient P8
[09:09:31.533245] Processing patient P6
[09:09:55.005698] Files preprocessed.
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[09:09:56.519100] number of params: 59617303
[09:09:56.519289] model: Vivim2D(
  (encoder): mamba_block(
    (downsample_layers): SegformerEncoder(
      (patch_embeddings): ModuleList(
        (0): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(2, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (1): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (2): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (3): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (block): ModuleList(
        (0): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): Identity()
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.003703703870996833)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.007407407741993666)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.011111111380159855)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.014814815483987331)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.018518518656492233)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.02222222276031971)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (2): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.025925926864147186)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.029629630967974663)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03333333507180214)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03703703731298447)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04074074327945709)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04444444552063942)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.048148151487112045)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.051851850003004074)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0555555559694767)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.05925925821065903)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06296296417713165)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06666667014360428)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07037036865949631)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07407407462596893)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07777778059244156)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08148147910833359)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08518518507480621)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08888889104127884)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (3): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.09259259700775146)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0962962955236435)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.10000000149011612)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (layer_norm): ModuleList(
        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=64, out_features=256, bias=False)
              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (act): SiLU()
              (x_proj): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_b): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_b): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_b): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_s): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_s): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_s): Linear(in_features=4, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=64, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=256, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=64, out_features=256, bias=False)
              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (act): SiLU()
              (x_proj): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_b): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_b): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_b): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_s): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_s): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_s): Linear(in_features=4, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=64, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=256, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (1): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=128, out_features=512, bias=False)
              (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (act): SiLU()
              (x_proj): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_b): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_b): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_b): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_s): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_s): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_s): Linear(in_features=8, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=128, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=128, out_features=512, bias=False)
              (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (act): SiLU()
              (x_proj): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_b): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_b): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_b): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_s): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_s): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_s): Linear(in_features=8, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=128, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (2): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=320, out_features=1280, bias=False)
              (conv1d): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (act): SiLU()
              (x_proj): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_b): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_b): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_b): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_s): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_s): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_s): Linear(in_features=20, out_features=640, bias=True)
              (out_proj): Linear(in_features=640, out_features=320, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(1280, 1280, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=320, out_features=1280, bias=False)
              (conv1d): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (act): SiLU()
              (x_proj): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_b): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_b): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_b): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_s): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_s): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_s): Linear(in_features=20, out_features=640, bias=True)
              (out_proj): Linear(in_features=640, out_features=320, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(1280, 1280, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (3): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=512, out_features=2048, bias=False)
              (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (act): SiLU()
              (x_proj): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_b): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_b): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_b): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_s): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_s): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_s): Linear(in_features=32, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=512, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=512, out_features=2048, bias=False)
              (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (act): SiLU()
              (x_proj): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_b): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_b): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_b): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_s): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_s): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_s): Linear(in_features=32, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=512, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
  )
  (decoder): SegformerDecodeHead(
    (linear_c): ModuleList(
      (0): SegformerMLP(
        (proj): Linear(in_features=64, out_features=768, bias=True)
      )
      (1): SegformerMLP(
        (proj): Linear(in_features=128, out_features=768, bias=True)
      )
      (2): SegformerMLP(
        (proj): Linear(in_features=320, out_features=768, bias=True)
      )
      (3): SegformerMLP(
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
    )
    (linear_fuse): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (batch_norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): ReLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Conv2d(768, 150, kernel_size=(1, 1), stride=(1, 1))
  )
  (out): Conv2d(768, 1, kernel_size=(1, 1), stride=(1, 1))
)
[09:09:56.522456] base lr: 1.00e-03
[09:09:56.522521] actual lr: 1.25e-04
[09:09:56.522574] accumulate grad iterations: 1
[09:09:56.522625] effective batch size: 32
[09:09:56.524223] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.000125
    maximize: False
    weight_decay: 0.01
)
[09:09:56.526282] Start training for 50 epochs
[09:09:56.528259] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
[09:09:58.107057] Epoch: [0]  [  0/345]  eta: 0:09:04  lr: 0.000000  loss: 1.6965 (1.6965)  time: 1.5778  data: 0.1917  max mem: 14473
[09:10:12.470419] Epoch: [0]  [ 20/345]  eta: 0:04:06  lr: 0.000000  loss: 1.6955 (1.6956)  time: 0.7181  data: 0.0001  max mem: 14938
[09:10:27.036775] Epoch: [0]  [ 40/345]  eta: 0:03:46  lr: 0.000001  loss: 1.6917 (1.6936)  time: 0.7283  data: 0.0001  max mem: 14938
[09:10:41.599185] Epoch: [0]  [ 60/345]  eta: 0:03:30  lr: 0.000001  loss: 1.6874 (1.6916)  time: 0.7281  data: 0.0001  max mem: 14938
[09:10:56.267473] Epoch: [0]  [ 80/345]  eta: 0:03:15  lr: 0.000001  loss: 1.6850 (1.6901)  time: 0.7334  data: 0.0001  max mem: 14938
[09:11:11.007301] Epoch: [0]  [100/345]  eta: 0:03:00  lr: 0.000002  loss: 1.6822 (1.6885)  time: 0.7370  data: 0.0001  max mem: 14938
[09:11:25.797934] Epoch: [0]  [120/345]  eta: 0:02:45  lr: 0.000002  loss: 1.6764 (1.6865)  time: 0.7395  data: 0.0001  max mem: 14938
[09:11:40.636564] Epoch: [0]  [140/345]  eta: 0:02:31  lr: 0.000003  loss: 1.6697 (1.6843)  time: 0.7419  data: 0.0001  max mem: 14938
[09:11:55.493128] Epoch: [0]  [160/345]  eta: 0:02:16  lr: 0.000003  loss: 1.6670 (1.6822)  time: 0.7428  data: 0.0001  max mem: 14938
[09:12:10.372992] Epoch: [0]  [180/345]  eta: 0:02:02  lr: 0.000003  loss: 1.6606 (1.6798)  time: 0.7440  data: 0.0001  max mem: 14938
[09:12:25.287990] Epoch: [0]  [200/345]  eta: 0:01:47  lr: 0.000004  loss: 1.6525 (1.6772)  time: 0.7457  data: 0.0001  max mem: 14938
[09:12:40.219951] Epoch: [0]  [220/345]  eta: 0:01:32  lr: 0.000004  loss: 1.6446 (1.6743)  time: 0.7466  data: 0.0001  max mem: 14938
[09:12:55.165057] Epoch: [0]  [240/345]  eta: 0:01:17  lr: 0.000004  loss: 1.6343 (1.6711)  time: 0.7472  data: 0.0001  max mem: 14938

[09:13:10.120489] Epoch: [0]  [260/345]  eta: 0:01:03  lr: 0.000005  loss: 1.6247 (1.6675)  time: 0.7477  data: 0.0001  max mem: 14938
[09:13:25.092130] Epoch: [0]  [280/345]  eta: 0:00:48  lr: 0.000005  loss: 1.6127 (1.6636)  time: 0.7485  data: 0.0001  max mem: 14938
[09:13:40.053498] Epoch: [0]  [300/345]  eta: 0:00:33  lr: 0.000005  loss: 1.5995 (1.6594)  time: 0.7480  data: 0.0001  max mem: 14938
[09:13:55.008005] Epoch: [0]  [320/345]  eta: 0:00:18  lr: 0.000006  loss: 1.5854 (1.6548)  time: 0.7477  data: 0.0001  max mem: 14938
[09:14:09.979069] Epoch: [0]  [340/345]  eta: 0:00:03  lr: 0.000006  loss: 1.5717 (1.6499)  time: 0.7485  data: 0.0001  max mem: 14938
[09:14:12.975831] Epoch: [0]  [344/345]  eta: 0:00:00  lr: 0.000006  loss: 1.5658 (1.6489)  time: 0.7486  data: 0.0001  max mem: 14938
[09:14:13.038763] Epoch: [0] Total time: 0:04:16 (0.7435 s / it)
[09:14:13.039032] Averaged stats: lr: 0.000006  loss: 1.5658 (1.6489)
[09:14:13.367977] Test:  [  0/345]  eta: 0:01:52  loss: 1.5938 (1.5938)  time: 0.3252  data: 0.1429  max mem: 14938
[09:14:15.205841] Test:  [ 10/345]  eta: 0:01:05  loss: 1.5938 (1.5936)  time: 0.1966  data: 0.0131  max mem: 14938
[09:14:17.044968] Test:  [ 20/345]  eta: 0:01:01  loss: 1.5941 (1.5938)  time: 0.1838  data: 0.0001  max mem: 14938
[09:14:18.888065] Test:  [ 30/345]  eta: 0:00:59  loss: 1.5925 (1.5932)  time: 0.1841  data: 0.0001  max mem: 14938
[09:14:20.734508] Test:  [ 40/345]  eta: 0:00:57  loss: 1.5925 (1.5931)  time: 0.1844  data: 0.0001  max mem: 14938
[09:14:22.584555] Test:  [ 50/345]  eta: 0:00:55  loss: 1.5936 (1.5932)  time: 0.1848  data: 0.0001  max mem: 14938
[09:14:24.437719] Test:  [ 60/345]  eta: 0:00:53  loss: 1.5936 (1.5931)  time: 0.1851  data: 0.0001  max mem: 14938
[09:14:26.295279] Test:  [ 70/345]  eta: 0:00:51  loss: 1.5913 (1.5928)  time: 0.1855  data: 0.0001  max mem: 14938
[09:14:28.155119] Test:  [ 80/345]  eta: 0:00:49  loss: 1.5913 (1.5927)  time: 0.1858  data: 0.0001  max mem: 14938
[09:14:30.022633] Test:  [ 90/345]  eta: 0:00:47  loss: 1.5924 (1.5926)  time: 0.1863  data: 0.0001  max mem: 14938
[09:14:31.890879] Test:  [100/345]  eta: 0:00:45  loss: 1.5928 (1.5926)  time: 0.1867  data: 0.0001  max mem: 14938
[09:14:33.762974] Test:  [110/345]  eta: 0:00:43  loss: 1.5931 (1.5926)  time: 0.1870  data: 0.0001  max mem: 14938
[09:14:35.638850] Test:  [120/345]  eta: 0:00:42  loss: 1.5936 (1.5927)  time: 0.1873  data: 0.0001  max mem: 14938
[09:14:37.518025] Test:  [130/345]  eta: 0:00:40  loss: 1.5921 (1.5925)  time: 0.1877  data: 0.0001  max mem: 14938
[09:14:39.398783] Test:  [140/345]  eta: 0:00:38  loss: 1.5925 (1.5925)  time: 0.1879  data: 0.0001  max mem: 14938
[09:14:41.282770] Test:  [150/345]  eta: 0:00:36  loss: 1.5931 (1.5925)  time: 0.1882  data: 0.0001  max mem: 14938
[09:14:43.170800] Test:  [160/345]  eta: 0:00:34  loss: 1.5937 (1.5926)  time: 0.1886  data: 0.0001  max mem: 14938
[09:14:45.062755] Test:  [170/345]  eta: 0:00:32  loss: 1.5926 (1.5926)  time: 0.1889  data: 0.0001  max mem: 14938
[09:14:46.960070] Test:  [180/345]  eta: 0:00:30  loss: 1.5930 (1.5926)  time: 0.1894  data: 0.0001  max mem: 14938
[09:14:48.858011] Test:  [190/345]  eta: 0:00:29  loss: 1.5935 (1.5926)  time: 0.1897  data: 0.0001  max mem: 14938
[09:14:50.761391] Test:  [200/345]  eta: 0:00:27  loss: 1.5923 (1.5926)  time: 0.1900  data: 0.0001  max mem: 14938
[09:14:53.079150] Test:  [210/345]  eta: 0:00:25  loss: 1.5923 (1.5926)  time: 0.2110  data: 0.0001  max mem: 14938
[09:14:54.999884] Test:  [220/345]  eta: 0:00:23  loss: 1.5940 (1.5926)  time: 0.2119  data: 0.0001  max mem: 14938
[09:14:57.050428] Test:  [230/345]  eta: 0:00:21  loss: 1.5944 (1.5927)  time: 0.1985  data: 0.0001  max mem: 14938
[09:14:58.968927] Test:  [240/345]  eta: 0:00:20  loss: 1.5926 (1.5926)  time: 0.1984  data: 0.0001  max mem: 14938
[09:15:01.067427] Test:  [250/345]  eta: 0:00:18  loss: 1.5927 (1.5927)  time: 0.2008  data: 0.0001  max mem: 14938
[09:15:03.168710] Test:  [260/345]  eta: 0:00:16  loss: 1.5921 (1.5926)  time: 0.2099  data: 0.0001  max mem: 14938
[09:15:05.261157] Test:  [270/345]  eta: 0:00:14  loss: 1.5934 (1.5927)  time: 0.2096  data: 0.0001  max mem: 14938
[09:15:07.221052] Test:  [280/345]  eta: 0:00:12  loss: 1.5934 (1.5926)  time: 0.2026  data: 0.0001  max mem: 14938
[09:15:09.344339] Test:  [290/345]  eta: 0:00:10  loss: 1.5909 (1.5926)  time: 0.2041  data: 0.0001  max mem: 14938
[09:15:11.535345] Test:  [300/345]  eta: 0:00:08  loss: 1.5934 (1.5927)  time: 0.2157  data: 0.0001  max mem: 14938
[09:15:13.658931] Test:  [310/345]  eta: 0:00:06  loss: 1.5937 (1.5927)  time: 0.2157  data: 0.0001  max mem: 14938
[09:15:15.761959] Test:  [320/345]  eta: 0:00:04  loss: 1.5932 (1.5927)  time: 0.2113  data: 0.0001  max mem: 14938
[09:15:17.905673] Test:  [330/345]  eta: 0:00:02  loss: 1.5927 (1.5927)  time: 0.2123  data: 0.0001  max mem: 14938
[09:15:19.944479] Test:  [340/345]  eta: 0:00:00  loss: 1.5917 (1.5926)  time: 0.2090  data: 0.0001  max mem: 14938
[09:15:20.969527] Test:  [344/345]  eta: 0:00:00  loss: 1.5918 (1.5927)  time: 0.2201  data: 0.0001  max mem: 14938
[09:15:21.024280] Test: Total time: 0:01:07 (0.1970 s / it)
[09:15:31.308222] Test:  [ 0/57]  eta: 0:00:18  loss: 1.6031 (1.6031)  time: 0.3183  data: 0.1385  max mem: 14938
[09:15:33.121186] Test:  [10/57]  eta: 0:00:09  loss: 1.5973 (1.5980)  time: 0.1937  data: 0.0127  max mem: 14938
[09:15:34.942435] Test:  [20/57]  eta: 0:00:06  loss: 1.5978 (1.5966)  time: 0.1816  data: 0.0001  max mem: 14938
[09:15:36.766292] Test:  [30/57]  eta: 0:00:05  loss: 1.5949 (1.5923)  time: 0.1822  data: 0.0001  max mem: 14938
[09:15:38.593747] Test:  [40/57]  eta: 0:00:03  loss: 1.5840 (1.5894)  time: 0.1825  data: 0.0001  max mem: 14938
[09:15:40.429378] Test:  [50/57]  eta: 0:00:01  loss: 1.5840 (1.5885)  time: 0.1831  data: 0.0001  max mem: 14938
[09:15:41.445777] Test:  [56/57]  eta: 0:00:00  loss: 1.5873 (1.5884)  time: 0.1791  data: 0.0001  max mem: 14938
[09:15:41.506470] Test: Total time: 0:00:10 (0.1845 s / it)
[09:15:43.217566] Dice score of the network on the train images: 0.000000, val images: 0.000000
[09:15:43.217792] saving best_dice_model_0 @ epoch 0
[09:15:44.320198] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:15:45.205017] Epoch: [1]  [  0/345]  eta: 0:05:04  lr: 0.000006  loss: 1.5589 (1.5589)  time: 0.8836  data: 0.1414  max mem: 14938
[09:16:00.081907] Epoch: [1]  [ 20/345]  eta: 0:04:03  lr: 0.000007  loss: 1.5513 (1.5526)  time: 0.7438  data: 0.0001  max mem: 14938
[09:16:14.999850] Epoch: [1]  [ 40/345]  eta: 0:03:48  lr: 0.000007  loss: 1.5420 (1.5472)  time: 0.7458  data: 0.0001  max mem: 14938
[09:16:29.957923] Epoch: [1]  [ 60/345]  eta: 0:03:33  lr: 0.000007  loss: 1.5235 (1.5400)  time: 0.7479  data: 0.0001  max mem: 14938
[09:16:44.932460] Epoch: [1]  [ 80/345]  eta: 0:03:18  lr: 0.000008  loss: 1.5102 (1.5334)  time: 0.7487  data: 0.0001  max mem: 14938
[09:16:59.926612] Epoch: [1]  [100/345]  eta: 0:03:03  lr: 0.000008  loss: 1.4967 (1.5266)  time: 0.7497  data: 0.0001  max mem: 14938
[09:17:14.925703] Epoch: [1]  [120/345]  eta: 0:02:48  lr: 0.000008  loss: 1.4868 (1.5198)  time: 0.7499  data: 0.0001  max mem: 14938
[09:17:29.939961] Epoch: [1]  [140/345]  eta: 0:02:33  lr: 0.000009  loss: 1.4719 (1.5131)  time: 0.7507  data: 0.0001  max mem: 14938
[09:17:44.943398] Epoch: [1]  [160/345]  eta: 0:02:18  lr: 0.000009  loss: 1.4666 (1.5074)  time: 0.7501  data: 0.0001  max mem: 14938
[09:17:59.928716] Epoch: [1]  [180/345]  eta: 0:02:03  lr: 0.000010  loss: 1.4543 (1.5018)  time: 0.7492  data: 0.0001  max mem: 14938
[09:18:14.919071] Epoch: [1]  [200/345]  eta: 0:01:48  lr: 0.000010  loss: 1.4464 (1.4965)  time: 0.7495  data: 0.0001  max mem: 14938
[09:18:29.913014] Epoch: [1]  [220/345]  eta: 0:01:33  lr: 0.000010  loss: 1.4327 (1.4908)  time: 0.7497  data: 0.0001  max mem: 14938
[09:18:44.898714] Epoch: [1]  [240/345]  eta: 0:01:18  lr: 0.000011  loss: 1.4221 (1.4853)  time: 0.7492  data: 0.0001  max mem: 14938
[09:18:59.873603] Epoch: [1]  [260/345]  eta: 0:01:03  lr: 0.000011  loss: 1.4219 (1.4805)  time: 0.7487  data: 0.0001  max mem: 14938
[09:19:14.838434] Epoch: [1]  [280/345]  eta: 0:00:48  lr: 0.000011  loss: 1.4123 (1.4760)  time: 0.7482  data: 0.0001  max mem: 14938
[09:19:29.793442] Epoch: [1]  [300/345]  eta: 0:00:33  lr: 0.000012  loss: 1.4043 (1.4714)  time: 0.7477  data: 0.0001  max mem: 14938
[09:19:44.762690] Epoch: [1]  [320/345]  eta: 0:00:18  lr: 0.000012  loss: 1.4006 (1.4672)  time: 0.7484  data: 0.0001  max mem: 14938
[09:19:59.740159] Epoch: [1]  [340/345]  eta: 0:00:03  lr: 0.000012  loss: 1.3953 (1.4632)  time: 0.7488  data: 0.0001  max mem: 14938
[09:20:02.735772] Epoch: [1]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 1.3953 (1.4624)  time: 0.7491  data: 0.0001  max mem: 14938
[09:20:02.797818] Epoch: [1] Total time: 0:04:18 (0.7492 s / it)
[09:20:02.798202] Averaged stats: lr: 0.000012  loss: 1.3953 (1.4624)
[09:20:03.128148] Test:  [  0/345]  eta: 0:01:52  loss: 1.3930 (1.3930)  time: 0.3257  data: 0.1439  max mem: 14938
[09:20:04.961204] Test:  [ 10/345]  eta: 0:01:05  loss: 1.3928 (1.3932)  time: 0.1962  data: 0.0131  max mem: 14938
[09:20:06.797707] Test:  [ 20/345]  eta: 0:01:01  loss: 1.3929 (1.3935)  time: 0.1834  data: 0.0001  max mem: 14938
[09:20:08.636365] Test:  [ 30/345]  eta: 0:00:59  loss: 1.3929 (1.3933)  time: 0.1837  data: 0.0001  max mem: 14938
[09:20:10.478157] Test:  [ 40/345]  eta: 0:00:57  loss: 1.3927 (1.3930)  time: 0.1840  data: 0.0001  max mem: 14938
[09:20:12.324454] Test:  [ 50/345]  eta: 0:00:55  loss: 1.3925 (1.3929)  time: 0.1844  data: 0.0001  max mem: 14938
[09:20:14.176915] Test:  [ 60/345]  eta: 0:00:53  loss: 1.3926 (1.3929)  time: 0.1849  data: 0.0001  max mem: 14938
[09:20:16.030404] Test:  [ 70/345]  eta: 0:00:51  loss: 1.3935 (1.3931)  time: 0.1852  data: 0.0001  max mem: 14938
[09:20:17.886591] Test:  [ 80/345]  eta: 0:00:49  loss: 1.3934 (1.3931)  time: 0.1854  data: 0.0001  max mem: 14938
[09:20:19.746538] Test:  [ 90/345]  eta: 0:00:47  loss: 1.3921 (1.3930)  time: 0.1858  data: 0.0001  max mem: 14938
[09:20:21.612484] Test:  [100/345]  eta: 0:00:45  loss: 1.3919 (1.3929)  time: 0.1862  data: 0.0001  max mem: 14938
[09:20:23.481044] Test:  [110/345]  eta: 0:00:43  loss: 1.3930 (1.3929)  time: 0.1867  data: 0.0001  max mem: 14938
[09:20:25.350908] Test:  [120/345]  eta: 0:00:41  loss: 1.3930 (1.3929)  time: 0.1869  data: 0.0001  max mem: 14938
[09:20:27.223599] Test:  [130/345]  eta: 0:00:40  loss: 1.3929 (1.3929)  time: 0.1871  data: 0.0001  max mem: 14938
[09:20:29.100290] Test:  [140/345]  eta: 0:00:38  loss: 1.3933 (1.3930)  time: 0.1874  data: 0.0001  max mem: 14938
[09:20:30.982572] Test:  [150/345]  eta: 0:00:36  loss: 1.3927 (1.3929)  time: 0.1879  data: 0.0001  max mem: 14938
[09:20:32.868723] Test:  [160/345]  eta: 0:00:34  loss: 1.3926 (1.3929)  time: 0.1884  data: 0.0001  max mem: 14938
[09:20:34.757796] Test:  [170/345]  eta: 0:00:32  loss: 1.3929 (1.3929)  time: 0.1887  data: 0.0001  max mem: 14938
[09:20:36.652131] Test:  [180/345]  eta: 0:00:30  loss: 1.3933 (1.3930)  time: 0.1891  data: 0.0001  max mem: 14938
[09:20:38.547836] Test:  [190/345]  eta: 0:00:28  loss: 1.3930 (1.3929)  time: 0.1894  data: 0.0001  max mem: 14938
[09:20:40.447626] Test:  [200/345]  eta: 0:00:27  loss: 1.3933 (1.3930)  time: 0.1897  data: 0.0001  max mem: 14938
[09:20:42.352802] Test:  [210/345]  eta: 0:00:25  loss: 1.3935 (1.3930)  time: 0.1902  data: 0.0001  max mem: 14938
[09:20:44.259127] Test:  [220/345]  eta: 0:00:23  loss: 1.3933 (1.3930)  time: 0.1905  data: 0.0001  max mem: 14938
[09:20:46.169445] Test:  [230/345]  eta: 0:00:21  loss: 1.3929 (1.3930)  time: 0.1908  data: 0.0001  max mem: 14938
[09:20:48.085339] Test:  [240/345]  eta: 0:00:19  loss: 1.3929 (1.3929)  time: 0.1912  data: 0.0001  max mem: 14938
[09:20:50.003996] Test:  [250/345]  eta: 0:00:17  loss: 1.3929 (1.3929)  time: 0.1917  data: 0.0001  max mem: 14938
[09:20:51.925117] Test:  [260/345]  eta: 0:00:15  loss: 1.3925 (1.3929)  time: 0.1919  data: 0.0001  max mem: 14938
[09:20:53.849497] Test:  [270/345]  eta: 0:00:14  loss: 1.3925 (1.3929)  time: 0.1922  data: 0.0001  max mem: 14938
[09:20:55.777219] Test:  [280/345]  eta: 0:00:12  loss: 1.3926 (1.3929)  time: 0.1926  data: 0.0001  max mem: 14938
[09:20:57.710246] Test:  [290/345]  eta: 0:00:10  loss: 1.3927 (1.3929)  time: 0.1930  data: 0.0001  max mem: 14938
[09:20:59.644603] Test:  [300/345]  eta: 0:00:08  loss: 1.3926 (1.3929)  time: 0.1933  data: 0.0001  max mem: 14938
[09:21:01.582395] Test:  [310/345]  eta: 0:00:06  loss: 1.3926 (1.3929)  time: 0.1936  data: 0.0001  max mem: 14938
[09:21:03.522583] Test:  [320/345]  eta: 0:00:04  loss: 1.3925 (1.3929)  time: 0.1938  data: 0.0001  max mem: 14938
[09:21:05.468392] Test:  [330/345]  eta: 0:00:02  loss: 1.3925 (1.3929)  time: 0.1942  data: 0.0001  max mem: 14938
[09:21:07.416602] Test:  [340/345]  eta: 0:00:00  loss: 1.3931 (1.3929)  time: 0.1946  data: 0.0001  max mem: 14938
[09:21:08.197200] Test:  [344/345]  eta: 0:00:00  loss: 1.3934 (1.3929)  time: 0.1947  data: 0.0001  max mem: 14938
[09:21:08.252950] Test: Total time: 0:01:05 (0.1897 s / it)
[09:21:18.506366] Test:  [ 0/57]  eta: 0:00:18  loss: 1.4002 (1.4002)  time: 0.3169  data: 0.1380  max mem: 14938
[09:21:20.318586] Test:  [10/57]  eta: 0:00:09  loss: 1.3979 (1.3969)  time: 0.1935  data: 0.0126  max mem: 14938
[09:21:22.137798] Test:  [20/57]  eta: 0:00:06  loss: 1.3979 (1.3960)  time: 0.1815  data: 0.0001  max mem: 14938
[09:21:23.960179] Test:  [30/57]  eta: 0:00:05  loss: 1.3926 (1.3927)  time: 0.1820  data: 0.0001  max mem: 14938
[09:21:25.788561] Test:  [40/57]  eta: 0:00:03  loss: 1.3871 (1.3906)  time: 0.1825  data: 0.0001  max mem: 14938
[09:21:27.620382] Test:  [50/57]  eta: 0:00:01  loss: 1.3871 (1.3899)  time: 0.1830  data: 0.0001  max mem: 14938
[09:21:28.608194] Test:  [56/57]  eta: 0:00:00  loss: 1.3899 (1.3898)  time: 0.1776  data: 0.0001  max mem: 14938
[09:21:28.665629] Test: Total time: 0:00:10 (0.1838 s / it)
[09:21:30.388564] Dice score of the network on the train images: 0.000000, val images: 0.000000
[09:21:30.392685] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:21:31.274474] Epoch: [2]  [  0/345]  eta: 0:05:03  lr: 0.000013  loss: 1.3903 (1.3903)  time: 0.8807  data: 0.1381  max mem: 14938
[09:21:46.165859] Epoch: [2]  [ 20/345]  eta: 0:04:04  lr: 0.000013  loss: 1.3872 (1.3882)  time: 0.7445  data: 0.0001  max mem: 14938
[09:22:01.085192] Epoch: [2]  [ 40/345]  eta: 0:03:48  lr: 0.000013  loss: 1.3834 (1.3868)  time: 0.7459  data: 0.0001  max mem: 14938
[09:22:16.033783] Epoch: [2]  [ 60/345]  eta: 0:03:33  lr: 0.000014  loss: 1.3799 (1.3847)  time: 0.7474  data: 0.0001  max mem: 14938
[09:22:31.019843] Epoch: [2]  [ 80/345]  eta: 0:03:18  lr: 0.000014  loss: 1.3744 (1.3833)  time: 0.7493  data: 0.0001  max mem: 14938
[09:22:46.020801] Epoch: [2]  [100/345]  eta: 0:03:03  lr: 0.000014  loss: 1.3708 (1.3813)  time: 0.7500  data: 0.0001  max mem: 14938
[09:23:01.034476] Epoch: [2]  [120/345]  eta: 0:02:48  lr: 0.000015  loss: 1.3643 (1.3789)  time: 0.7506  data: 0.0001  max mem: 14938
[09:23:16.062782] Epoch: [2]  [140/345]  eta: 0:02:33  lr: 0.000015  loss: 1.3576 (1.3760)  time: 0.7514  data: 0.0001  max mem: 14938
[09:23:31.066568] Epoch: [2]  [160/345]  eta: 0:02:18  lr: 0.000015  loss: 1.3560 (1.3741)  time: 0.7502  data: 0.0001  max mem: 14938
[09:23:46.053524] Epoch: [2]  [180/345]  eta: 0:02:03  lr: 0.000016  loss: 1.3545 (1.3721)  time: 0.7493  data: 0.0001  max mem: 14938
[09:24:01.035299] Epoch: [2]  [200/345]  eta: 0:01:48  lr: 0.000016  loss: 1.3490 (1.3699)  time: 0.7490  data: 0.0001  max mem: 14938
[09:24:16.028397] Epoch: [2]  [220/345]  eta: 0:01:33  lr: 0.000016  loss: 1.3484 (1.3680)  time: 0.7496  data: 0.0001  max mem: 14938
[09:24:31.016604] Epoch: [2]  [240/345]  eta: 0:01:18  lr: 0.000017  loss: 1.3414 (1.3660)  time: 0.7494  data: 0.0001  max mem: 14938
[09:24:46.001360] Epoch: [2]  [260/345]  eta: 0:01:03  lr: 0.000017  loss: 1.3398 (1.3645)  time: 0.7492  data: 0.0001  max mem: 14938

[09:25:00.978144] Epoch: [2]  [280/345]  eta: 0:00:48  lr: 0.000018  loss: 1.3390 (1.3629)  time: 0.7488  data: 0.0001  max mem: 14938
[09:25:15.964873] Epoch: [2]  [300/345]  eta: 0:00:33  lr: 0.000018  loss: 1.3290 (1.3610)  time: 0.7493  data: 0.0001  max mem: 14938
[09:25:30.931342] Epoch: [2]  [320/345]  eta: 0:00:18  lr: 0.000018  loss: 1.3324 (1.3595)  time: 0.7483  data: 0.0001  max mem: 14938
[09:25:45.904184] Epoch: [2]  [340/345]  eta: 0:00:03  lr: 0.000019  loss: 1.3339 (1.3582)  time: 0.7486  data: 0.0001  max mem: 14938
[09:25:48.899658] Epoch: [2]  [344/345]  eta: 0:00:00  lr: 0.000019  loss: 1.3339 (1.3580)  time: 0.7487  data: 0.0001  max mem: 14938
[09:25:48.962799] Epoch: [2] Total time: 0:04:18 (0.7495 s / it)
[09:25:48.963135] Averaged stats: lr: 0.000019  loss: 1.3339 (1.3580)
[09:25:49.295868] Test:  [  0/345]  eta: 0:01:53  loss: 1.3401 (1.3401)  time: 0.3293  data: 0.1478  max mem: 14938
[09:25:51.130730] Test:  [ 10/345]  eta: 0:01:05  loss: 1.3420 (1.3417)  time: 0.1967  data: 0.0135  max mem: 14938
[09:25:52.967896] Test:  [ 20/345]  eta: 0:01:01  loss: 1.3420 (1.3414)  time: 0.1835  data: 0.0001  max mem: 14938
[09:25:54.806117] Test:  [ 30/345]  eta: 0:00:59  loss: 1.3428 (1.3418)  time: 0.1837  data: 0.0001  max mem: 14938
[09:25:56.649551] Test:  [ 40/345]  eta: 0:00:57  loss: 1.3433 (1.3422)  time: 0.1840  data: 0.0001  max mem: 14938
[09:25:58.496470] Test:  [ 50/345]  eta: 0:00:55  loss: 1.3433 (1.3425)  time: 0.1845  data: 0.0001  max mem: 14938
[09:26:00.347268] Test:  [ 60/345]  eta: 0:00:53  loss: 1.3426 (1.3427)  time: 0.1848  data: 0.0001  max mem: 14938
[09:26:02.199692] Test:  [ 70/345]  eta: 0:00:51  loss: 1.3423 (1.3426)  time: 0.1851  data: 0.0001  max mem: 14938
[09:26:04.055097] Test:  [ 80/345]  eta: 0:00:49  loss: 1.3432 (1.3427)  time: 0.1853  data: 0.0001  max mem: 14938
[09:26:05.917288] Test:  [ 90/345]  eta: 0:00:47  loss: 1.3439 (1.3428)  time: 0.1858  data: 0.0001  max mem: 14938
[09:26:07.780028] Test:  [100/345]  eta: 0:00:45  loss: 1.3436 (1.3427)  time: 0.1862  data: 0.0001  max mem: 14938
[09:26:09.646736] Test:  [110/345]  eta: 0:00:43  loss: 1.3429 (1.3428)  time: 0.1864  data: 0.0001  max mem: 14938
[09:26:11.517464] Test:  [120/345]  eta: 0:00:41  loss: 1.3423 (1.3427)  time: 0.1868  data: 0.0001  max mem: 14938
[09:26:13.392964] Test:  [130/345]  eta: 0:00:40  loss: 1.3427 (1.3428)  time: 0.1872  data: 0.0001  max mem: 14938
[09:26:15.271370] Test:  [140/345]  eta: 0:00:38  loss: 1.3431 (1.3428)  time: 0.1876  data: 0.0001  max mem: 14938
[09:26:17.153281] Test:  [150/345]  eta: 0:00:36  loss: 1.3428 (1.3428)  time: 0.1880  data: 0.0001  max mem: 14938
[09:26:19.038274] Test:  [160/345]  eta: 0:00:34  loss: 1.3429 (1.3429)  time: 0.1883  data: 0.0001  max mem: 14938
[09:26:20.927014] Test:  [170/345]  eta: 0:00:32  loss: 1.3426 (1.3428)  time: 0.1886  data: 0.0001  max mem: 14938
[09:26:22.822744] Test:  [180/345]  eta: 0:00:30  loss: 1.3411 (1.3427)  time: 0.1892  data: 0.0001  max mem: 14938
[09:26:24.719734] Test:  [190/345]  eta: 0:00:29  loss: 1.3423 (1.3427)  time: 0.1896  data: 0.0001  max mem: 14938
[09:26:26.617945] Test:  [200/345]  eta: 0:00:27  loss: 1.3428 (1.3428)  time: 0.1897  data: 0.0001  max mem: 14938
[09:26:28.521160] Test:  [210/345]  eta: 0:00:25  loss: 1.3427 (1.3427)  time: 0.1900  data: 0.0001  max mem: 14938
[09:26:30.428472] Test:  [220/345]  eta: 0:00:23  loss: 1.3418 (1.3427)  time: 0.1905  data: 0.0001  max mem: 14938
[09:26:32.338400] Test:  [230/345]  eta: 0:00:21  loss: 1.3439 (1.3428)  time: 0.1908  data: 0.0001  max mem: 14938
[09:26:34.253021] Test:  [240/345]  eta: 0:00:19  loss: 1.3441 (1.3428)  time: 0.1912  data: 0.0001  max mem: 14938
[09:26:36.170381] Test:  [250/345]  eta: 0:00:17  loss: 1.3432 (1.3428)  time: 0.1915  data: 0.0001  max mem: 14938
[09:26:38.090138] Test:  [260/345]  eta: 0:00:15  loss: 1.3429 (1.3428)  time: 0.1918  data: 0.0001  max mem: 14938
[09:26:40.014584] Test:  [270/345]  eta: 0:00:14  loss: 1.3437 (1.3429)  time: 0.1922  data: 0.0001  max mem: 14938
[09:26:41.940436] Test:  [280/345]  eta: 0:00:12  loss: 1.3448 (1.3429)  time: 0.1925  data: 0.0001  max mem: 14938
[09:26:43.871715] Test:  [290/345]  eta: 0:00:10  loss: 1.3435 (1.3429)  time: 0.1928  data: 0.0001  max mem: 14938
[09:26:45.805003] Test:  [300/345]  eta: 0:00:08  loss: 1.3427 (1.3429)  time: 0.1932  data: 0.0001  max mem: 14938
[09:26:47.741182] Test:  [310/345]  eta: 0:00:06  loss: 1.3421 (1.3429)  time: 0.1934  data: 0.0001  max mem: 14938
[09:26:49.681076] Test:  [320/345]  eta: 0:00:04  loss: 1.3428 (1.3429)  time: 0.1937  data: 0.0001  max mem: 14938
[09:26:51.624142] Test:  [330/345]  eta: 0:00:02  loss: 1.3440 (1.3429)  time: 0.1941  data: 0.0001  max mem: 14938
[09:26:53.570572] Test:  [340/345]  eta: 0:00:00  loss: 1.3432 (1.3429)  time: 0.1944  data: 0.0001  max mem: 14938
[09:26:54.350899] Test:  [344/345]  eta: 0:00:00  loss: 1.3435 (1.3429)  time: 0.1946  data: 0.0001  max mem: 14938
[09:26:54.410158] Test: Total time: 0:01:05 (0.1897 s / it)
[09:27:04.611009] Test:  [ 0/57]  eta: 0:00:18  loss: 1.3513 (1.3513)  time: 0.3174  data: 0.1382  max mem: 14938
[09:27:06.424790] Test:  [10/57]  eta: 0:00:09  loss: 1.3483 (1.3475)  time: 0.1937  data: 0.0126  max mem: 14938
[09:27:08.243993] Test:  [20/57]  eta: 0:00:06  loss: 1.3483 (1.3466)  time: 0.1816  data: 0.0001  max mem: 14938
[09:27:10.065357] Test:  [30/57]  eta: 0:00:05  loss: 1.3410 (1.3425)  time: 0.1820  data: 0.0001  max mem: 14938
[09:27:11.892483] Test:  [40/57]  eta: 0:00:03  loss: 1.3346 (1.3398)  time: 0.1824  data: 0.0001  max mem: 14938
[09:27:13.724884] Test:  [50/57]  eta: 0:00:01  loss: 1.3346 (1.3389)  time: 0.1829  data: 0.0001  max mem: 14938
[09:27:14.713106] Test:  [56/57]  eta: 0:00:00  loss: 1.3385 (1.3387)  time: 0.1775  data: 0.0001  max mem: 14938
[09:27:14.748537] Test: Total time: 0:00:10 (0.1834 s / it)
[09:27:16.450718] Dice score of the network on the train images: 0.000000, val images: 0.000000
[09:27:16.455128] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:27:17.340487] Epoch: [3]  [  0/345]  eta: 0:05:05  lr: 0.000019  loss: 1.3233 (1.3233)  time: 0.8842  data: 0.1434  max mem: 14938
[09:27:32.201714] Epoch: [3]  [ 20/345]  eta: 0:04:03  lr: 0.000019  loss: 1.3269 (1.3270)  time: 0.7430  data: 0.0001  max mem: 14938
[09:27:47.092131] Epoch: [3]  [ 40/345]  eta: 0:03:47  lr: 0.000019  loss: 1.3227 (1.3284)  time: 0.7445  data: 0.0001  max mem: 14938
[09:28:02.007033] Epoch: [3]  [ 60/345]  eta: 0:03:32  lr: 0.000020  loss: 1.3264 (1.3277)  time: 0.7457  data: 0.0001  max mem: 14938
[09:28:16.983544] Epoch: [3]  [ 80/345]  eta: 0:03:18  lr: 0.000020  loss: 1.3173 (1.3259)  time: 0.7488  data: 0.0001  max mem: 14938
[09:28:31.973824] Epoch: [3]  [100/345]  eta: 0:03:03  lr: 0.000021  loss: 1.3134 (1.3249)  time: 0.7495  data: 0.0001  max mem: 14938
[09:28:46.957600] Epoch: [3]  [120/345]  eta: 0:02:48  lr: 0.000021  loss: 1.3152 (1.3246)  time: 0.7491  data: 0.0001  max mem: 14938
[09:29:02.071994] Epoch: [3]  [140/345]  eta: 0:02:33  lr: 0.000021  loss: 1.3108 (1.3230)  time: 0.7557  data: 0.0001  max mem: 14938
[09:29:17.053859] Epoch: [3]  [160/345]  eta: 0:02:18  lr: 0.000022  loss: 1.3077 (1.3214)  time: 0.7491  data: 0.0001  max mem: 14938
[09:29:32.035360] Epoch: [3]  [180/345]  eta: 0:02:03  lr: 0.000022  loss: 1.3088 (1.3203)  time: 0.7490  data: 0.0001  max mem: 14938
[09:29:47.008321] Epoch: [3]  [200/345]  eta: 0:01:48  lr: 0.000022  loss: 1.3048 (1.3189)  time: 0.7486  data: 0.0001  max mem: 14938
[09:30:01.974408] Epoch: [3]  [220/345]  eta: 0:01:33  lr: 0.000023  loss: 1.3027 (1.3180)  time: 0.7483  data: 0.0001  max mem: 14938
[09:30:16.946506] Epoch: [3]  [240/345]  eta: 0:01:18  lr: 0.000023  loss: 1.2995 (1.3170)  time: 0.7486  data: 0.0001  max mem: 14938
[09:30:31.920838] Epoch: [3]  [260/345]  eta: 0:01:03  lr: 0.000023  loss: 1.2995 (1.3157)  time: 0.7487  data: 0.0001  max mem: 14938
[09:30:46.901817] Epoch: [3]  [280/345]  eta: 0:00:48  lr: 0.000024  loss: 1.2979 (1.3145)  time: 0.7490  data: 0.0001  max mem: 14938
[09:31:01.887693] Epoch: [3]  [300/345]  eta: 0:00:33  lr: 0.000024  loss: 1.2990 (1.3137)  time: 0.7493  data: 0.0001  max mem: 14938
[09:31:16.872574] Epoch: [3]  [320/345]  eta: 0:00:18  lr: 0.000025  loss: 1.2968 (1.3129)  time: 0.7492  data: 0.0001  max mem: 14938
[09:31:31.847304] Epoch: [3]  [340/345]  eta: 0:00:03  lr: 0.000025  loss: 1.2926 (1.3118)  time: 0.7487  data: 0.0001  max mem: 14938
[09:31:34.844680] Epoch: [3]  [344/345]  eta: 0:00:00  lr: 0.000025  loss: 1.2923 (1.3117)  time: 0.7489  data: 0.0001  max mem: 14938
[09:31:34.908923] Epoch: [3] Total time: 0:04:18 (0.7491 s / it)
[09:31:34.909452] Averaged stats: lr: 0.000025  loss: 1.2923 (1.3117)
[09:31:35.243102] Test:  [  0/345]  eta: 0:01:53  loss: 1.3008 (1.3008)  time: 0.3293  data: 0.1475  max mem: 14938
[09:31:37.078654] Test:  [ 10/345]  eta: 0:01:05  loss: 1.2934 (1.2940)  time: 0.1967  data: 0.0135  max mem: 14938
[09:31:38.917604] Test:  [ 20/345]  eta: 0:01:01  loss: 1.2923 (1.2930)  time: 0.1837  data: 0.0001  max mem: 14938
[09:31:40.759884] Test:  [ 30/345]  eta: 0:00:59  loss: 1.2916 (1.2930)  time: 0.1840  data: 0.0001  max mem: 14938
[09:31:42.604008] Test:  [ 40/345]  eta: 0:00:57  loss: 1.2929 (1.2929)  time: 0.1843  data: 0.0001  max mem: 14938
[09:31:44.453109] Test:  [ 50/345]  eta: 0:00:55  loss: 1.2930 (1.2929)  time: 0.1846  data: 0.0001  max mem: 14938
[09:31:46.305194] Test:  [ 60/345]  eta: 0:00:53  loss: 1.2918 (1.2927)  time: 0.1850  data: 0.0001  max mem: 14938
[09:31:48.160155] Test:  [ 70/345]  eta: 0:00:51  loss: 1.2929 (1.2928)  time: 0.1853  data: 0.0001  max mem: 14938
[09:31:50.017133] Test:  [ 80/345]  eta: 0:00:49  loss: 1.2929 (1.2926)  time: 0.1855  data: 0.0001  max mem: 14938
[09:31:51.880088] Test:  [ 90/345]  eta: 0:00:47  loss: 1.2904 (1.2924)  time: 0.1859  data: 0.0001  max mem: 14938
[09:31:53.747295] Test:  [100/345]  eta: 0:00:45  loss: 1.2901 (1.2923)  time: 0.1864  data: 0.0001  max mem: 14938
[09:31:55.615236] Test:  [110/345]  eta: 0:00:43  loss: 1.2903 (1.2923)  time: 0.1867  data: 0.0001  max mem: 14938
[09:31:57.488850] Test:  [120/345]  eta: 0:00:41  loss: 1.2926 (1.2923)  time: 0.1870  data: 0.0001  max mem: 14938
[09:31:59.364460] Test:  [130/345]  eta: 0:00:40  loss: 1.2911 (1.2920)  time: 0.1874  data: 0.0001  max mem: 14938
[09:32:01.243911] Test:  [140/345]  eta: 0:00:38  loss: 1.2911 (1.2921)  time: 0.1877  data: 0.0001  max mem: 14938
[09:32:03.127667] Test:  [150/345]  eta: 0:00:36  loss: 1.2929 (1.2920)  time: 0.1881  data: 0.0001  max mem: 14938
[09:32:05.013348] Test:  [160/345]  eta: 0:00:34  loss: 1.2924 (1.2921)  time: 0.1884  data: 0.0001  max mem: 14938
[09:32:06.902359] Test:  [170/345]  eta: 0:00:32  loss: 1.2915 (1.2921)  time: 0.1887  data: 0.0001  max mem: 14938
[09:32:08.798267] Test:  [180/345]  eta: 0:00:30  loss: 1.2908 (1.2920)  time: 0.1892  data: 0.0001  max mem: 14938
[09:32:10.695046] Test:  [190/345]  eta: 0:00:29  loss: 1.2918 (1.2920)  time: 0.1896  data: 0.0001  max mem: 14938
[09:32:12.595160] Test:  [200/345]  eta: 0:00:27  loss: 1.2931 (1.2921)  time: 0.1898  data: 0.0001  max mem: 14938
[09:32:14.499378] Test:  [210/345]  eta: 0:00:25  loss: 1.2931 (1.2920)  time: 0.1902  data: 0.0001  max mem: 14938
[09:32:16.406179] Test:  [220/345]  eta: 0:00:23  loss: 1.2907 (1.2920)  time: 0.1905  data: 0.0001  max mem: 14938
[09:32:18.318170] Test:  [230/345]  eta: 0:00:21  loss: 1.2906 (1.2919)  time: 0.1909  data: 0.0001  max mem: 14938
[09:32:20.233535] Test:  [240/345]  eta: 0:00:19  loss: 1.2880 (1.2919)  time: 0.1913  data: 0.0001  max mem: 14938
[09:32:22.153119] Test:  [250/345]  eta: 0:00:17  loss: 1.2926 (1.2920)  time: 0.1917  data: 0.0001  max mem: 14938
[09:32:24.074495] Test:  [260/345]  eta: 0:00:16  loss: 1.2928 (1.2920)  time: 0.1920  data: 0.0001  max mem: 14938
[09:32:25.999866] Test:  [270/345]  eta: 0:00:14  loss: 1.2921 (1.2920)  time: 0.1923  data: 0.0001  max mem: 14938
[09:32:27.930300] Test:  [280/345]  eta: 0:00:12  loss: 1.2910 (1.2919)  time: 0.1927  data: 0.0001  max mem: 14938
[09:32:29.864067] Test:  [290/345]  eta: 0:00:10  loss: 1.2927 (1.2919)  time: 0.1932  data: 0.0001  max mem: 14938
[09:32:31.800536] Test:  [300/345]  eta: 0:00:08  loss: 1.2940 (1.2920)  time: 0.1935  data: 0.0001  max mem: 14938
[09:32:33.738093] Test:  [310/345]  eta: 0:00:06  loss: 1.2940 (1.2920)  time: 0.1936  data: 0.0001  max mem: 14938
[09:32:35.681199] Test:  [320/345]  eta: 0:00:04  loss: 1.2907 (1.2920)  time: 0.1940  data: 0.0001  max mem: 14938
[09:32:37.625987] Test:  [330/345]  eta: 0:00:02  loss: 1.2904 (1.2920)  time: 0.1943  data: 0.0001  max mem: 14938
[09:32:39.574889] Test:  [340/345]  eta: 0:00:00  loss: 1.2917 (1.2920)  time: 0.1946  data: 0.0001  max mem: 14938
[09:32:40.355692] Test:  [344/345]  eta: 0:00:00  loss: 1.2905 (1.2919)  time: 0.1948  data: 0.0001  max mem: 14938
[09:32:40.413644] Test: Total time: 0:01:05 (0.1899 s / it)
[09:32:50.745706] Test:  [ 0/57]  eta: 0:00:18  loss: 1.3057 (1.3057)  time: 0.3171  data: 0.1376  max mem: 14938
[09:32:52.556511] Test:  [10/57]  eta: 0:00:09  loss: 1.3001 (1.2992)  time: 0.1934  data: 0.0126  max mem: 14938
[09:32:54.376336] Test:  [20/57]  eta: 0:00:06  loss: 1.3001 (1.2986)  time: 0.1815  data: 0.0001  max mem: 14938
[09:32:56.200407] Test:  [30/57]  eta: 0:00:05  loss: 1.2845 (1.2908)  time: 0.1821  data: 0.0001  max mem: 14938
[09:32:58.027376] Test:  [40/57]  eta: 0:00:03  loss: 1.2731 (1.2857)  time: 0.1825  data: 0.0001  max mem: 14938
[09:32:59.861342] Test:  [50/57]  eta: 0:00:01  loss: 1.2731 (1.2838)  time: 0.1830  data: 0.0001  max mem: 14938
[09:33:00.850617] Test:  [56/57]  eta: 0:00:00  loss: 1.2807 (1.2836)  time: 0.1777  data: 0.0001  max mem: 14938
[09:33:00.909839] Test: Total time: 0:00:10 (0.1839 s / it)
[09:33:02.627817] Dice score of the network on the train images: 0.000000, val images: 0.000000
[09:33:02.631965] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:33:03.512602] Epoch: [4]  [  0/345]  eta: 0:05:03  lr: 0.000025  loss: 1.2985 (1.2985)  time: 0.8796  data: 0.1385  max mem: 14938
[09:33:18.399873] Epoch: [4]  [ 20/345]  eta: 0:04:03  lr: 0.000025  loss: 1.2862 (1.2910)  time: 0.7443  data: 0.0001  max mem: 14938
[09:33:33.312810] Epoch: [4]  [ 40/345]  eta: 0:03:48  lr: 0.000026  loss: 1.2881 (1.2895)  time: 0.7456  data: 0.0001  max mem: 14938
[09:33:48.257339] Epoch: [4]  [ 60/345]  eta: 0:03:33  lr: 0.000026  loss: 1.2772 (1.2875)  time: 0.7472  data: 0.0001  max mem: 14938
[09:34:03.230109] Epoch: [4]  [ 80/345]  eta: 0:03:18  lr: 0.000026  loss: 1.2739 (1.2849)  time: 0.7486  data: 0.0001  max mem: 14938
[09:34:18.229369] Epoch: [4]  [100/345]  eta: 0:03:03  lr: 0.000027  loss: 1.2696 (1.2826)  time: 0.7499  data: 0.0001  max mem: 14938
[09:34:33.249553] Epoch: [4]  [120/345]  eta: 0:02:48  lr: 0.000027  loss: 1.2638 (1.2796)  time: 0.7510  data: 0.0001  max mem: 14938
[09:34:48.374429] Epoch: [4]  [140/345]  eta: 0:02:33  lr: 0.000028  loss: 1.2584 (1.2768)  time: 0.7562  data: 0.0001  max mem: 14938
[09:35:03.379827] Epoch: [4]  [160/345]  eta: 0:02:18  lr: 0.000028  loss: 1.2646 (1.2751)  time: 0.7502  data: 0.0001  max mem: 14938
[09:35:18.387655] Epoch: [4]  [180/345]  eta: 0:02:03  lr: 0.000028  loss: 1.2414 (1.2719)  time: 0.7503  data: 0.0001  max mem: 14938
[09:35:33.384502] Epoch: [4]  [200/345]  eta: 0:01:48  lr: 0.000029  loss: 1.2342 (1.2682)  time: 0.7498  data: 0.0001  max mem: 14938
[09:35:48.375740] Epoch: [4]  [220/345]  eta: 0:01:33  lr: 0.000029  loss: 1.2287 (1.2650)  time: 0.7495  data: 0.0001  max mem: 14938
[09:36:03.363747] Epoch: [4]  [240/345]  eta: 0:01:18  lr: 0.000029  loss: 1.2205 (1.2614)  time: 0.7494  data: 0.0001  max mem: 14938

[09:36:18.353587] Epoch: [4]  [260/345]  eta: 0:01:03  lr: 0.000030  loss: 1.2116 (1.2577)  time: 0.7494  data: 0.0001  max mem: 14938
[09:36:33.341691] Epoch: [4]  [280/345]  eta: 0:00:48  lr: 0.000030  loss: 1.2046 (1.2540)  time: 0.7494  data: 0.0001  max mem: 14938
[09:36:48.322206] Epoch: [4]  [300/345]  eta: 0:00:33  lr: 0.000030  loss: 1.1858 (1.2499)  time: 0.7490  data: 0.0001  max mem: 14938
[09:37:03.302091] Epoch: [4]  [320/345]  eta: 0:00:18  lr: 0.000031  loss: 1.1773 (1.2456)  time: 0.7489  data: 0.0001  max mem: 14938
[09:37:18.279058] Epoch: [4]  [340/345]  eta: 0:00:03  lr: 0.000031  loss: 1.1822 (1.2420)  time: 0.7488  data: 0.0001  max mem: 14938
[09:37:21.275224] Epoch: [4]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 1.1822 (1.2414)  time: 0.7487  data: 0.0001  max mem: 14938
[09:37:21.339187] Epoch: [4] Total time: 0:04:18 (0.7499 s / it)
[09:37:21.339345] Averaged stats: lr: 0.000031  loss: 1.1822 (1.2414)
[09:37:21.666508] Test:  [  0/345]  eta: 0:01:51  loss: 1.1807 (1.1807)  time: 0.3227  data: 0.1409  max mem: 14938
[09:37:23.501994] Test:  [ 10/345]  eta: 0:01:05  loss: 1.1651 (1.1607)  time: 0.1961  data: 0.0129  max mem: 14938
[09:37:25.339689] Test:  [ 20/345]  eta: 0:01:01  loss: 1.1549 (1.1593)  time: 0.1836  data: 0.0001  max mem: 14938
[09:37:27.179662] Test:  [ 30/345]  eta: 0:00:59  loss: 1.1522 (1.1532)  time: 0.1838  data: 0.0001  max mem: 14938
[09:37:29.023562] Test:  [ 40/345]  eta: 0:00:57  loss: 1.1522 (1.1555)  time: 0.1841  data: 0.0001  max mem: 14938
[09:37:30.871540] Test:  [ 50/345]  eta: 0:00:55  loss: 1.1538 (1.1535)  time: 0.1845  data: 0.0001  max mem: 14938
[09:37:32.723290] Test:  [ 60/345]  eta: 0:00:53  loss: 1.1501 (1.1537)  time: 0.1849  data: 0.0001  max mem: 14938
[09:37:34.577432] Test:  [ 70/345]  eta: 0:00:51  loss: 1.1497 (1.1531)  time: 0.1852  data: 0.0001  max mem: 14938
[09:37:36.434818] Test:  [ 80/345]  eta: 0:00:49  loss: 1.1452 (1.1523)  time: 0.1855  data: 0.0001  max mem: 14938
[09:37:38.296476] Test:  [ 90/345]  eta: 0:00:47  loss: 1.1496 (1.1525)  time: 0.1859  data: 0.0001  max mem: 14938
[09:37:40.160616] Test:  [100/345]  eta: 0:00:45  loss: 1.1515 (1.1519)  time: 0.1862  data: 0.0001  max mem: 14938
[09:37:42.028561] Test:  [110/345]  eta: 0:00:43  loss: 1.1515 (1.1524)  time: 0.1866  data: 0.0001  max mem: 14938
[09:37:43.899482] Test:  [120/345]  eta: 0:00:41  loss: 1.1476 (1.1518)  time: 0.1869  data: 0.0001  max mem: 14938
[09:37:45.773066] Test:  [130/345]  eta: 0:00:40  loss: 1.1431 (1.1506)  time: 0.1872  data: 0.0001  max mem: 14938
[09:37:47.653256] Test:  [140/345]  eta: 0:00:38  loss: 1.1490 (1.1510)  time: 0.1876  data: 0.0001  max mem: 14938
[09:37:49.535909] Test:  [150/345]  eta: 0:00:36  loss: 1.1549 (1.1514)  time: 0.1881  data: 0.0001  max mem: 14938
[09:37:51.420318] Test:  [160/345]  eta: 0:00:34  loss: 1.1491 (1.1500)  time: 0.1883  data: 0.0001  max mem: 14938
[09:37:53.307364] Test:  [170/345]  eta: 0:00:32  loss: 1.1453 (1.1505)  time: 0.1885  data: 0.0001  max mem: 14938
[09:37:55.201306] Test:  [180/345]  eta: 0:00:30  loss: 1.1458 (1.1502)  time: 0.1890  data: 0.0001  max mem: 14938
[09:37:57.097611] Test:  [190/345]  eta: 0:00:29  loss: 1.1444 (1.1499)  time: 0.1895  data: 0.0001  max mem: 14938
[09:37:58.996530] Test:  [200/345]  eta: 0:00:27  loss: 1.1535 (1.1503)  time: 0.1897  data: 0.0001  max mem: 14938
[09:38:00.898748] Test:  [210/345]  eta: 0:00:25  loss: 1.1619 (1.1510)  time: 0.1900  data: 0.0001  max mem: 14938
[09:38:02.805934] Test:  [220/345]  eta: 0:00:23  loss: 1.1642 (1.1514)  time: 0.1904  data: 0.0001  max mem: 14938
[09:38:04.715426] Test:  [230/345]  eta: 0:00:21  loss: 1.1524 (1.1515)  time: 0.1908  data: 0.0001  max mem: 14938
[09:38:06.630506] Test:  [240/345]  eta: 0:00:19  loss: 1.1593 (1.1519)  time: 0.1912  data: 0.0001  max mem: 14938
[09:38:08.548027] Test:  [250/345]  eta: 0:00:17  loss: 1.1619 (1.1520)  time: 0.1916  data: 0.0001  max mem: 14938
[09:38:10.468367] Test:  [260/345]  eta: 0:00:15  loss: 1.1581 (1.1521)  time: 0.1918  data: 0.0001  max mem: 14938
[09:38:12.392287] Test:  [270/345]  eta: 0:00:14  loss: 1.1545 (1.1523)  time: 0.1922  data: 0.0001  max mem: 14938
[09:38:14.320753] Test:  [280/345]  eta: 0:00:12  loss: 1.1563 (1.1528)  time: 0.1926  data: 0.0001  max mem: 14938
[09:38:16.251708] Test:  [290/345]  eta: 0:00:10  loss: 1.1691 (1.1534)  time: 0.1929  data: 0.0001  max mem: 14938
[09:38:18.186205] Test:  [300/345]  eta: 0:00:08  loss: 1.1535 (1.1534)  time: 0.1932  data: 0.0001  max mem: 14938
[09:38:20.125529] Test:  [310/345]  eta: 0:00:06  loss: 1.1511 (1.1536)  time: 0.1936  data: 0.0001  max mem: 14938
[09:38:22.066642] Test:  [320/345]  eta: 0:00:04  loss: 1.1511 (1.1534)  time: 0.1940  data: 0.0001  max mem: 14938
[09:38:24.012649] Test:  [330/345]  eta: 0:00:02  loss: 1.1548 (1.1535)  time: 0.1943  data: 0.0001  max mem: 14938
[09:38:25.959309] Test:  [340/345]  eta: 0:00:00  loss: 1.1591 (1.1534)  time: 0.1946  data: 0.0001  max mem: 14938
[09:38:26.740754] Test:  [344/345]  eta: 0:00:00  loss: 1.1548 (1.1533)  time: 0.1947  data: 0.0001  max mem: 14938
[09:38:26.799503] Test: Total time: 0:01:05 (0.1897 s / it)
[09:38:37.058058] Test:  [ 0/57]  eta: 0:00:17  loss: 1.2299 (1.2299)  time: 0.3137  data: 0.1348  max mem: 14938
[09:38:38.871173] Test:  [10/57]  eta: 0:00:09  loss: 1.2045 (1.1937)  time: 0.1933  data: 0.0123  max mem: 14938
[09:38:40.686745] Test:  [20/57]  eta: 0:00:06  loss: 1.2150 (1.1952)  time: 0.1814  data: 0.0001  max mem: 14938
[09:38:42.509768] Test:  [30/57]  eta: 0:00:05  loss: 1.1272 (1.1480)  time: 0.1819  data: 0.0001  max mem: 14938
[09:38:44.336125] Test:  [40/57]  eta: 0:00:03  loss: 1.0373 (1.1183)  time: 0.1824  data: 0.0001  max mem: 14938
[09:38:46.168690] Test:  [50/57]  eta: 0:00:01  loss: 1.0398 (1.1098)  time: 0.1829  data: 0.0001  max mem: 14938
[09:38:47.156543] Test:  [56/57]  eta: 0:00:00  loss: 1.0972 (1.1138)  time: 0.1775  data: 0.0001  max mem: 14938
[09:38:47.208708] Test: Total time: 0:00:10 (0.1836 s / it)
[09:38:48.901285] Dice score of the network on the train images: 0.523190, val images: 0.622581
[09:38:48.901503] saving best_prec_model_0 @ epoch 4
[09:38:49.968937] saving best_rec_model_0 @ epoch 4
[09:38:51.010874] saving best_dice_model_0 @ epoch 4
[09:38:52.180998] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:38:53.064668] Epoch: [5]  [  0/345]  eta: 0:05:04  lr: 0.000031  loss: 1.2069 (1.2069)  time: 0.8826  data: 0.1419  max mem: 14938
[09:39:07.921499] Epoch: [5]  [ 20/345]  eta: 0:04:03  lr: 0.000032  loss: 1.1559 (1.1634)  time: 0.7428  data: 0.0001  max mem: 14938
[09:39:22.829128] Epoch: [5]  [ 40/345]  eta: 0:03:47  lr: 0.000032  loss: 1.1517 (1.1597)  time: 0.7453  data: 0.0001  max mem: 14938
[09:39:37.778338] Epoch: [5]  [ 60/345]  eta: 0:03:33  lr: 0.000032  loss: 1.1607 (1.1605)  time: 0.7474  data: 0.0001  max mem: 14938
[09:39:52.760415] Epoch: [5]  [ 80/345]  eta: 0:03:18  lr: 0.000033  loss: 1.1419 (1.1573)  time: 0.7491  data: 0.0001  max mem: 14938
[09:40:07.778804] Epoch: [5]  [100/345]  eta: 0:03:03  lr: 0.000033  loss: 1.1393 (1.1539)  time: 0.7509  data: 0.0001  max mem: 14938
[09:40:22.807639] Epoch: [5]  [120/345]  eta: 0:02:48  lr: 0.000033  loss: 1.1145 (1.1489)  time: 0.7514  data: 0.0001  max mem: 14938
[09:40:37.821154] Epoch: [5]  [140/345]  eta: 0:02:33  lr: 0.000034  loss: 1.1219 (1.1451)  time: 0.7506  data: 0.0001  max mem: 14938
[09:40:52.833710] Epoch: [5]  [160/345]  eta: 0:02:18  lr: 0.000034  loss: 1.1242 (1.1422)  time: 0.7506  data: 0.0001  max mem: 14938
[09:41:07.824623] Epoch: [5]  [180/345]  eta: 0:02:03  lr: 0.000035  loss: 1.1243 (1.1399)  time: 0.7495  data: 0.0001  max mem: 14938
[09:41:22.818045] Epoch: [5]  [200/345]  eta: 0:01:48  lr: 0.000035  loss: 1.0985 (1.1365)  time: 0.7496  data: 0.0001  max mem: 14938
[09:41:37.934407] Epoch: [5]  [220/345]  eta: 0:01:33  lr: 0.000035  loss: 1.0902 (1.1323)  time: 0.7558  data: 0.0001  max mem: 14938
[09:41:52.921214] Epoch: [5]  [240/345]  eta: 0:01:18  lr: 0.000036  loss: 1.0831 (1.1286)  time: 0.7493  data: 0.0001  max mem: 14938
[09:42:07.901469] Epoch: [5]  [260/345]  eta: 0:01:03  lr: 0.000036  loss: 1.0779 (1.1252)  time: 0.7490  data: 0.0001  max mem: 14938
[09:42:22.883176] Epoch: [5]  [280/345]  eta: 0:00:48  lr: 0.000036  loss: 1.0883 (1.1231)  time: 0.7490  data: 0.0001  max mem: 14938
[09:42:37.862275] Epoch: [5]  [300/345]  eta: 0:00:33  lr: 0.000037  loss: 1.0671 (1.1192)  time: 0.7489  data: 0.0001  max mem: 14938
[09:42:52.843134] Epoch: [5]  [320/345]  eta: 0:00:18  lr: 0.000037  loss: 1.0662 (1.1166)  time: 0.7490  data: 0.0001  max mem: 14938
[09:43:07.817024] Epoch: [5]  [340/345]  eta: 0:00:03  lr: 0.000037  loss: 1.0663 (1.1136)  time: 0.7486  data: 0.0001  max mem: 14938
[09:43:10.815493] Epoch: [5]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 1.0668 (1.1130)  time: 0.7488  data: 0.0001  max mem: 14938
[09:43:10.879629] Epoch: [5] Total time: 0:04:18 (0.7499 s / it)
[09:43:10.879840] Averaged stats: lr: 0.000037  loss: 1.0668 (1.1130)
[09:43:11.210347] Test:  [  0/345]  eta: 0:01:52  loss: 0.9771 (0.9771)  time: 0.3261  data: 0.1437  max mem: 14938
[09:43:13.045247] Test:  [ 10/345]  eta: 0:01:05  loss: 1.0184 (1.0140)  time: 0.1964  data: 0.0131  max mem: 14938
[09:43:14.881757] Test:  [ 20/345]  eta: 0:01:01  loss: 1.0191 (1.0180)  time: 0.1835  data: 0.0001  max mem: 14938
[09:43:16.723196] Test:  [ 30/345]  eta: 0:00:59  loss: 1.0228 (1.0225)  time: 0.1838  data: 0.0001  max mem: 14938
[09:43:18.566226] Test:  [ 40/345]  eta: 0:00:57  loss: 1.0195 (1.0212)  time: 0.1842  data: 0.0001  max mem: 14938
[09:43:20.414608] Test:  [ 50/345]  eta: 0:00:55  loss: 1.0163 (1.0217)  time: 0.1845  data: 0.0001  max mem: 14938
[09:43:22.265773] Test:  [ 60/345]  eta: 0:00:53  loss: 1.0105 (1.0201)  time: 0.1849  data: 0.0001  max mem: 14938
[09:43:24.118423] Test:  [ 70/345]  eta: 0:00:51  loss: 1.0151 (1.0214)  time: 0.1851  data: 0.0001  max mem: 14938
[09:43:25.976106] Test:  [ 80/345]  eta: 0:00:49  loss: 1.0216 (1.0215)  time: 0.1855  data: 0.0001  max mem: 14938
[09:43:27.837885] Test:  [ 90/345]  eta: 0:00:47  loss: 1.0130 (1.0206)  time: 0.1859  data: 0.0001  max mem: 14938
[09:43:29.701037] Test:  [100/345]  eta: 0:00:45  loss: 1.0130 (1.0199)  time: 0.1862  data: 0.0001  max mem: 14938
[09:43:31.567639] Test:  [110/345]  eta: 0:00:43  loss: 1.0106 (1.0195)  time: 0.1864  data: 0.0001  max mem: 14938
[09:43:33.438983] Test:  [120/345]  eta: 0:00:41  loss: 1.0172 (1.0193)  time: 0.1868  data: 0.0001  max mem: 14938
[09:43:35.311652] Test:  [130/345]  eta: 0:00:40  loss: 1.0233 (1.0201)  time: 0.1872  data: 0.0001  max mem: 14938
[09:43:37.190850] Test:  [140/345]  eta: 0:00:38  loss: 1.0304 (1.0209)  time: 0.1875  data: 0.0001  max mem: 14938
[09:43:39.072095] Test:  [150/345]  eta: 0:00:36  loss: 1.0304 (1.0212)  time: 0.1880  data: 0.0001  max mem: 14938
[09:43:40.957472] Test:  [160/345]  eta: 0:00:34  loss: 1.0272 (1.0208)  time: 0.1883  data: 0.0001  max mem: 14938
[09:43:42.846061] Test:  [170/345]  eta: 0:00:32  loss: 1.0162 (1.0207)  time: 0.1886  data: 0.0001  max mem: 14938
[09:43:44.740693] Test:  [180/345]  eta: 0:00:30  loss: 1.0186 (1.0208)  time: 0.1891  data: 0.0001  max mem: 14938
[09:43:46.637504] Test:  [190/345]  eta: 0:00:29  loss: 1.0175 (1.0204)  time: 0.1895  data: 0.0001  max mem: 14938
[09:43:48.537181] Test:  [200/345]  eta: 0:00:27  loss: 1.0272 (1.0212)  time: 0.1898  data: 0.0001  max mem: 14938
[09:43:50.439045] Test:  [210/345]  eta: 0:00:25  loss: 1.0298 (1.0212)  time: 0.1900  data: 0.0001  max mem: 14938
[09:43:52.345658] Test:  [220/345]  eta: 0:00:23  loss: 1.0058 (1.0202)  time: 0.1904  data: 0.0001  max mem: 14938
[09:43:54.256727] Test:  [230/345]  eta: 0:00:21  loss: 1.0057 (1.0198)  time: 0.1908  data: 0.0001  max mem: 14938
[09:43:56.170513] Test:  [240/345]  eta: 0:00:19  loss: 1.0195 (1.0205)  time: 0.1912  data: 0.0001  max mem: 14938
[09:43:58.087372] Test:  [250/345]  eta: 0:00:17  loss: 1.0291 (1.0204)  time: 0.1915  data: 0.0001  max mem: 14938
[09:44:00.008393] Test:  [260/345]  eta: 0:00:15  loss: 1.0283 (1.0209)  time: 0.1918  data: 0.0001  max mem: 14938
[09:44:01.933180] Test:  [270/345]  eta: 0:00:14  loss: 1.0302 (1.0210)  time: 0.1922  data: 0.0001  max mem: 14938
[09:44:03.861817] Test:  [280/345]  eta: 0:00:12  loss: 1.0298 (1.0214)  time: 0.1926  data: 0.0001  max mem: 14938
[09:44:05.792885] Test:  [290/345]  eta: 0:00:10  loss: 1.0138 (1.0217)  time: 0.1929  data: 0.0001  max mem: 14938
[09:44:07.728296] Test:  [300/345]  eta: 0:00:08  loss: 1.0266 (1.0222)  time: 0.1933  data: 0.0001  max mem: 14938
[09:44:09.666731] Test:  [310/345]  eta: 0:00:06  loss: 1.0230 (1.0220)  time: 0.1936  data: 0.0001  max mem: 14938
[09:44:11.606904] Test:  [320/345]  eta: 0:00:04  loss: 1.0142 (1.0220)  time: 0.1939  data: 0.0001  max mem: 14938
[09:44:13.550297] Test:  [330/345]  eta: 0:00:02  loss: 1.0157 (1.0219)  time: 0.1941  data: 0.0001  max mem: 14938
[09:44:15.497199] Test:  [340/345]  eta: 0:00:00  loss: 1.0160 (1.0216)  time: 0.1945  data: 0.0001  max mem: 14938
[09:44:16.277541] Test:  [344/345]  eta: 0:00:00  loss: 1.0160 (1.0217)  time: 0.1946  data: 0.0001  max mem: 14938
[09:44:16.337892] Test: Total time: 0:01:05 (0.1897 s / it)
[09:44:26.791071] Test:  [ 0/57]  eta: 0:00:18  loss: 1.1080 (1.1080)  time: 0.3163  data: 0.1372  max mem: 14938
[09:44:28.603535] Test:  [10/57]  eta: 0:00:09  loss: 1.0810 (1.0737)  time: 0.1935  data: 0.0125  max mem: 14938
[09:44:30.420691] Test:  [20/57]  eta: 0:00:06  loss: 1.1053 (1.0800)  time: 0.1814  data: 0.0001  max mem: 14938
[09:44:32.243772] Test:  [30/57]  eta: 0:00:05  loss: 0.9630 (1.0236)  time: 0.1820  data: 0.0001  max mem: 14938
[09:44:34.069688] Test:  [40/57]  eta: 0:00:03  loss: 0.8904 (0.9895)  time: 0.1824  data: 0.0001  max mem: 14938
[09:44:35.900914] Test:  [50/57]  eta: 0:00:01  loss: 0.8904 (0.9799)  time: 0.1828  data: 0.0001  max mem: 14938
[09:44:36.888919] Test:  [56/57]  eta: 0:00:00  loss: 0.9683 (0.9850)  time: 0.1774  data: 0.0001  max mem: 14938
[09:44:36.946458] Test: Total time: 0:00:10 (0.1837 s / it)
[09:44:38.654979] Dice score of the network on the train images: 0.669086, val images: 0.730145
[09:44:38.655187] saving best_prec_model_0 @ epoch 5
[09:44:39.750190] saving best_dice_model_0 @ epoch 5
[09:44:40.778774] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:44:41.742611] Epoch: [6]  [  0/345]  eta: 0:05:32  lr: 0.000038  loss: 1.0376 (1.0376)  time: 0.9628  data: 0.1346  max mem: 14938
[09:44:56.598441] Epoch: [6]  [ 20/345]  eta: 0:04:04  lr: 0.000038  loss: 1.0475 (1.0480)  time: 0.7427  data: 0.0001  max mem: 14938
[09:45:11.519123] Epoch: [6]  [ 40/345]  eta: 0:03:48  lr: 0.000038  loss: 1.0442 (1.0501)  time: 0.7460  data: 0.0001  max mem: 14938
[09:45:26.473889] Epoch: [6]  [ 60/345]  eta: 0:03:33  lr: 0.000039  loss: 1.0404 (1.0453)  time: 0.7477  data: 0.0001  max mem: 14938
[09:45:41.470282] Epoch: [6]  [ 80/345]  eta: 0:03:18  lr: 0.000039  loss: 1.0377 (1.0424)  time: 0.7498  data: 0.0001  max mem: 14938
[09:45:56.491693] Epoch: [6]  [100/345]  eta: 0:03:03  lr: 0.000039  loss: 1.0323 (1.0420)  time: 0.7510  data: 0.0001  max mem: 14938
[09:46:11.520974] Epoch: [6]  [120/345]  eta: 0:02:48  lr: 0.000040  loss: 1.0211 (1.0392)  time: 0.7514  data: 0.0001  max mem: 14938
[09:46:26.546827] Epoch: [6]  [140/345]  eta: 0:02:33  lr: 0.000040  loss: 1.0410 (1.0394)  time: 0.7512  data: 0.0001  max mem: 14938
[09:46:41.567146] Epoch: [6]  [160/345]  eta: 0:02:18  lr: 0.000040  loss: 1.0086 (1.0356)  time: 0.7510  data: 0.0001  max mem: 14938
[09:46:56.582983] Epoch: [6]  [180/345]  eta: 0:02:03  lr: 0.000041  loss: 1.0085 (1.0328)  time: 0.7507  data: 0.0001  max mem: 14938
[09:47:11.585593] Epoch: [6]  [200/345]  eta: 0:01:48  lr: 0.000041  loss: 1.0056 (1.0306)  time: 0.7501  data: 0.0001  max mem: 14938
[09:47:26.583125] Epoch: [6]  [220/345]  eta: 0:01:33  lr: 0.000041  loss: 1.0115 (1.0291)  time: 0.7498  data: 0.0001  max mem: 14938
[09:47:41.574345] Epoch: [6]  [240/345]  eta: 0:01:18  lr: 0.000042  loss: 0.9976 (1.0263)  time: 0.7495  data: 0.0001  max mem: 14938
[09:47:56.656751] Epoch: [6]  [260/345]  eta: 0:01:03  lr: 0.000042  loss: 0.9861 (1.0245)  time: 0.7541  data: 0.0001  max mem: 14938
[09:48:11.650691] Epoch: [6]  [280/345]  eta: 0:00:48  lr: 0.000043  loss: 0.9756 (1.0212)  time: 0.7496  data: 0.0001  max mem: 14938
[09:48:26.641299] Epoch: [6]  [300/345]  eta: 0:00:33  lr: 0.000043  loss: 0.9801 (1.0189)  time: 0.7495  data: 0.0001  max mem: 14938
[09:48:41.628086] Epoch: [6]  [320/345]  eta: 0:00:18  lr: 0.000043  loss: 0.9732 (1.0168)  time: 0.7493  data: 0.0001  max mem: 14938
[09:48:56.612497] Epoch: [6]  [340/345]  eta: 0:00:03  lr: 0.000044  loss: 0.9706 (1.0147)  time: 0.7492  data: 0.0001  max mem: 14938
[09:48:59.611064] Epoch: [6]  [344/345]  eta: 0:00:00  lr: 0.000044  loss: 0.9836 (1.0147)  time: 0.7492  data: 0.0001  max mem: 14938
[09:48:59.670629] Epoch: [6] Total time: 0:04:18 (0.7504 s / it)
[09:48:59.671141] Averaged stats: lr: 0.000044  loss: 0.9836 (1.0147)
[09:49:00.005179] Test:  [  0/345]  eta: 0:01:53  loss: 0.9575 (0.9575)  time: 0.3299  data: 0.1485  max mem: 14938
[09:49:01.839193] Test:  [ 10/345]  eta: 0:01:05  loss: 0.9491 (0.9475)  time: 0.1966  data: 0.0136  max mem: 14938
[09:49:03.676002] Test:  [ 20/345]  eta: 0:01:01  loss: 0.9576 (0.9582)  time: 0.1835  data: 0.0001  max mem: 14938
[09:49:05.516570] Test:  [ 30/345]  eta: 0:00:59  loss: 0.9581 (0.9566)  time: 0.1838  data: 0.0001  max mem: 14938
[09:49:07.360755] Test:  [ 40/345]  eta: 0:00:57  loss: 0.9612 (0.9600)  time: 0.1842  data: 0.0001  max mem: 14938
[09:49:09.210254] Test:  [ 50/345]  eta: 0:00:55  loss: 0.9617 (0.9573)  time: 0.1846  data: 0.0001  max mem: 14938
[09:49:11.063808] Test:  [ 60/345]  eta: 0:00:53  loss: 0.9445 (0.9558)  time: 0.1851  data: 0.0001  max mem: 14938
[09:49:12.919180] Test:  [ 70/345]  eta: 0:00:51  loss: 0.9672 (0.9592)  time: 0.1854  data: 0.0001  max mem: 14938
[09:49:14.777922] Test:  [ 80/345]  eta: 0:00:49  loss: 0.9765 (0.9614)  time: 0.1857  data: 0.0001  max mem: 14938
[09:49:16.641156] Test:  [ 90/345]  eta: 0:00:47  loss: 0.9633 (0.9614)  time: 0.1860  data: 0.0001  max mem: 14938
[09:49:18.506747] Test:  [100/345]  eta: 0:00:45  loss: 0.9477 (0.9600)  time: 0.1864  data: 0.0001  max mem: 14938
[09:49:20.374461] Test:  [110/345]  eta: 0:00:43  loss: 0.9476 (0.9593)  time: 0.1866  data: 0.0001  max mem: 14938
[09:49:22.246931] Test:  [120/345]  eta: 0:00:41  loss: 0.9495 (0.9590)  time: 0.1869  data: 0.0001  max mem: 14938
[09:49:24.121759] Test:  [130/345]  eta: 0:00:40  loss: 0.9402 (0.9584)  time: 0.1873  data: 0.0001  max mem: 14938
[09:49:26.000812] Test:  [140/345]  eta: 0:00:38  loss: 0.9402 (0.9573)  time: 0.1876  data: 0.0001  max mem: 14938
[09:49:27.883359] Test:  [150/345]  eta: 0:00:36  loss: 0.9507 (0.9577)  time: 0.1880  data: 0.0001  max mem: 14938
[09:49:29.769486] Test:  [160/345]  eta: 0:00:34  loss: 0.9419 (0.9574)  time: 0.1884  data: 0.0001  max mem: 14938
[09:49:31.658854] Test:  [170/345]  eta: 0:00:32  loss: 0.9405 (0.9580)  time: 0.1887  data: 0.0001  max mem: 14938
[09:49:33.552316] Test:  [180/345]  eta: 0:00:30  loss: 0.9665 (0.9574)  time: 0.1891  data: 0.0001  max mem: 14938
[09:49:35.450665] Test:  [190/345]  eta: 0:00:29  loss: 0.9425 (0.9564)  time: 0.1895  data: 0.0001  max mem: 14938
[09:49:37.351308] Test:  [200/345]  eta: 0:00:27  loss: 0.9419 (0.9561)  time: 0.1899  data: 0.0001  max mem: 14938
[09:49:39.255264] Test:  [210/345]  eta: 0:00:25  loss: 0.9572 (0.9570)  time: 0.1902  data: 0.0001  max mem: 14938
[09:49:41.163056] Test:  [220/345]  eta: 0:00:23  loss: 0.9592 (0.9564)  time: 0.1905  data: 0.0001  max mem: 14938
[09:49:43.074283] Test:  [230/345]  eta: 0:00:21  loss: 0.9399 (0.9561)  time: 0.1909  data: 0.0001  max mem: 14938
[09:49:44.989082] Test:  [240/345]  eta: 0:00:19  loss: 0.9561 (0.9561)  time: 0.1912  data: 0.0001  max mem: 14938
[09:49:46.907895] Test:  [250/345]  eta: 0:00:17  loss: 0.9561 (0.9558)  time: 0.1916  data: 0.0001  max mem: 14938
[09:49:48.829665] Test:  [260/345]  eta: 0:00:16  loss: 0.9315 (0.9551)  time: 0.1920  data: 0.0001  max mem: 14938
[09:49:50.754266] Test:  [270/345]  eta: 0:00:14  loss: 0.9474 (0.9554)  time: 0.1923  data: 0.0001  max mem: 14938
[09:49:52.683723] Test:  [280/345]  eta: 0:00:12  loss: 0.9638 (0.9555)  time: 0.1927  data: 0.0001  max mem: 14938
[09:49:54.614800] Test:  [290/345]  eta: 0:00:10  loss: 0.9522 (0.9550)  time: 0.1929  data: 0.0001  max mem: 14938
[09:49:56.550511] Test:  [300/345]  eta: 0:00:08  loss: 0.9442 (0.9549)  time: 0.1933  data: 0.0001  max mem: 14938
[09:49:58.490534] Test:  [310/345]  eta: 0:00:06  loss: 0.9554 (0.9546)  time: 0.1937  data: 0.0001  max mem: 14938
[09:50:00.432405] Test:  [320/345]  eta: 0:00:04  loss: 0.9556 (0.9548)  time: 0.1940  data: 0.0001  max mem: 14938
[09:50:02.379785] Test:  [330/345]  eta: 0:00:02  loss: 0.9514 (0.9546)  time: 0.1944  data: 0.0001  max mem: 14938
[09:50:04.327762] Test:  [340/345]  eta: 0:00:00  loss: 0.9460 (0.9543)  time: 0.1947  data: 0.0001  max mem: 14938
[09:50:05.108453] Test:  [344/345]  eta: 0:00:00  loss: 0.9460 (0.9541)  time: 0.1948  data: 0.0001  max mem: 14938
[09:50:05.166469] Test: Total time: 0:01:05 (0.1898 s / it)
[09:50:15.547348] Test:  [ 0/57]  eta: 0:00:17  loss: 1.0556 (1.0556)  time: 0.3126  data: 0.1335  max mem: 14938
[09:50:17.359429] Test:  [10/57]  eta: 0:00:09  loss: 1.0112 (1.0111)  time: 0.1931  data: 0.0122  max mem: 14938
[09:50:19.175471] Test:  [20/57]  eta: 0:00:06  loss: 0.9975 (1.0019)  time: 0.1813  data: 0.0001  max mem: 14938
[09:50:20.998392] Test:  [30/57]  eta: 0:00:05  loss: 0.9146 (0.9546)  time: 0.1819  data: 0.0001  max mem: 14938
[09:50:22.827704] Test:  [40/57]  eta: 0:00:03  loss: 0.8345 (0.9256)  time: 0.1826  data: 0.0001  max mem: 14938
[09:50:24.662427] Test:  [50/57]  eta: 0:00:01  loss: 0.8345 (0.9167)  time: 0.1831  data: 0.0001  max mem: 14938
[09:50:25.651028] Test:  [56/57]  eta: 0:00:00  loss: 0.8936 (0.9212)  time: 0.1777  data: 0.0001  max mem: 14938
[09:50:25.712586] Test: Total time: 0:00:10 (0.1838 s / it)
[09:50:27.476517] Dice score of the network on the train images: 0.687676, val images: 0.754042
[09:50:27.476740] saving best_prec_model_0 @ epoch 6
[09:50:28.575968] saving best_rec_model_0 @ epoch 6
[09:50:29.616541] saving best_dice_model_0 @ epoch 6
[09:50:30.657996] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:50:31.542995] Epoch: [7]  [  0/345]  eta: 0:05:04  lr: 0.000044  loss: 0.9420 (0.9420)  time: 0.8838  data: 0.1417  max mem: 14938
[09:50:46.402355] Epoch: [7]  [ 20/345]  eta: 0:04:03  lr: 0.000044  loss: 0.9613 (0.9690)  time: 0.7429  data: 0.0001  max mem: 14938
[09:51:01.304910] Epoch: [7]  [ 40/345]  eta: 0:03:47  lr: 0.000044  loss: 0.9681 (0.9702)  time: 0.7451  data: 0.0001  max mem: 14938
[09:51:16.257461] Epoch: [7]  [ 60/345]  eta: 0:03:33  lr: 0.000045  loss: 0.9554 (0.9665)  time: 0.7476  data: 0.0001  max mem: 14938
[09:51:31.243860] Epoch: [7]  [ 80/345]  eta: 0:03:18  lr: 0.000045  loss: 0.9639 (0.9652)  time: 0.7493  data: 0.0001  max mem: 14938
[09:51:46.269738] Epoch: [7]  [100/345]  eta: 0:03:03  lr: 0.000046  loss: 0.9716 (0.9690)  time: 0.7512  data: 0.0001  max mem: 14938
[09:52:01.303711] Epoch: [7]  [120/345]  eta: 0:02:48  lr: 0.000046  loss: 0.9724 (0.9688)  time: 0.7517  data: 0.0001  max mem: 14938
[09:52:16.318709] Epoch: [7]  [140/345]  eta: 0:02:33  lr: 0.000046  loss: 0.9584 (0.9672)  time: 0.7507  data: 0.0001  max mem: 14938
[09:52:31.324755] Epoch: [7]  [160/345]  eta: 0:02:18  lr: 0.000047  loss: 0.9548 (0.9659)  time: 0.7503  data: 0.0001  max mem: 14938
[09:52:46.325610] Epoch: [7]  [180/345]  eta: 0:02:03  lr: 0.000047  loss: 0.9519 (0.9657)  time: 0.7500  data: 0.0001  max mem: 14938
[09:53:01.308977] Epoch: [7]  [200/345]  eta: 0:01:48  lr: 0.000047  loss: 0.9456 (0.9638)  time: 0.7491  data: 0.0001  max mem: 14938
[09:53:16.288823] Epoch: [7]  [220/345]  eta: 0:01:33  lr: 0.000048  loss: 0.9377 (0.9620)  time: 0.7490  data: 0.0001  max mem: 14938
[09:53:31.283960] Epoch: [7]  [240/345]  eta: 0:01:18  lr: 0.000048  loss: 0.9406 (0.9596)  time: 0.7497  data: 0.0001  max mem: 14938
[09:53:46.279549] Epoch: [7]  [260/345]  eta: 0:01:03  lr: 0.000048  loss: 0.9253 (0.9571)  time: 0.7497  data: 0.0001  max mem: 14938
[09:54:01.281528] Epoch: [7]  [280/345]  eta: 0:00:48  lr: 0.000049  loss: 0.9288 (0.9556)  time: 0.7500  data: 0.0001  max mem: 14938
[09:54:16.347214] Epoch: [7]  [300/345]  eta: 0:00:33  lr: 0.000049  loss: 0.9277 (0.9538)  time: 0.7532  data: 0.0001  max mem: 14938
[09:54:31.309544] Epoch: [7]  [320/345]  eta: 0:00:18  lr: 0.000050  loss: 0.9335 (0.9528)  time: 0.7481  data: 0.0001  max mem: 14938
[09:54:46.276934] Epoch: [7]  [340/345]  eta: 0:00:03  lr: 0.000050  loss: 0.9238 (0.9515)  time: 0.7483  data: 0.0001  max mem: 14938
[09:54:49.271573] Epoch: [7]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.9216 (0.9511)  time: 0.7482  data: 0.0001  max mem: 14938
[09:54:49.331968] Epoch: [7] Total time: 0:04:18 (0.7498 s / it)
[09:54:49.332244] Averaged stats: lr: 0.000050  loss: 0.9216 (0.9511)
[09:54:49.664664] Test:  [  0/345]  eta: 0:01:53  loss: 0.8664 (0.8664)  time: 0.3288  data: 0.1470  max mem: 14938
[09:54:51.499483] Test:  [ 10/345]  eta: 0:01:05  loss: 0.8664 (0.8660)  time: 0.1966  data: 0.0134  max mem: 14938
[09:54:53.337063] Test:  [ 20/345]  eta: 0:01:01  loss: 0.8719 (0.8755)  time: 0.1836  data: 0.0001  max mem: 14938
[09:54:55.178957] Test:  [ 30/345]  eta: 0:00:59  loss: 0.8719 (0.8736)  time: 0.1839  data: 0.0001  max mem: 14938
[09:54:57.022504] Test:  [ 40/345]  eta: 0:00:57  loss: 0.8538 (0.8670)  time: 0.1842  data: 0.0001  max mem: 14938
[09:54:58.871463] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8661 (0.8688)  time: 0.1846  data: 0.0001  max mem: 14938
[09:55:00.723666] Test:  [ 60/345]  eta: 0:00:53  loss: 0.8676 (0.8701)  time: 0.1850  data: 0.0001  max mem: 14938
[09:55:02.577573] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8618 (0.8691)  time: 0.1853  data: 0.0001  max mem: 14938
[09:55:04.434949] Test:  [ 80/345]  eta: 0:00:49  loss: 0.8627 (0.8694)  time: 0.1855  data: 0.0001  max mem: 14938
[09:55:06.297967] Test:  [ 90/345]  eta: 0:00:47  loss: 0.8627 (0.8700)  time: 0.1860  data: 0.0001  max mem: 14938
[09:55:08.163794] Test:  [100/345]  eta: 0:00:45  loss: 0.8724 (0.8706)  time: 0.1864  data: 0.0001  max mem: 14938
[09:55:10.032613] Test:  [110/345]  eta: 0:00:43  loss: 0.8776 (0.8715)  time: 0.1867  data: 0.0001  max mem: 14938
[09:55:11.904229] Test:  [120/345]  eta: 0:00:41  loss: 0.8809 (0.8719)  time: 0.1870  data: 0.0001  max mem: 14938
[09:55:13.779382] Test:  [130/345]  eta: 0:00:40  loss: 0.8777 (0.8722)  time: 0.1873  data: 0.0001  max mem: 14938
[09:55:15.658384] Test:  [140/345]  eta: 0:00:38  loss: 0.8658 (0.8707)  time: 0.1877  data: 0.0001  max mem: 14938
[09:55:17.539290] Test:  [150/345]  eta: 0:00:36  loss: 0.8718 (0.8720)  time: 0.1879  data: 0.0001  max mem: 14938
[09:55:19.424313] Test:  [160/345]  eta: 0:00:34  loss: 0.8857 (0.8723)  time: 0.1882  data: 0.0001  max mem: 14938
[09:55:21.313630] Test:  [170/345]  eta: 0:00:32  loss: 0.8746 (0.8723)  time: 0.1887  data: 0.0001  max mem: 14938
[09:55:23.207481] Test:  [180/345]  eta: 0:00:30  loss: 0.8746 (0.8728)  time: 0.1891  data: 0.0001  max mem: 14938
[09:55:25.104391] Test:  [190/345]  eta: 0:00:29  loss: 0.8720 (0.8722)  time: 0.1895  data: 0.0001  max mem: 14938
[09:55:27.006108] Test:  [200/345]  eta: 0:00:27  loss: 0.8628 (0.8719)  time: 0.1899  data: 0.0001  max mem: 14938
[09:55:28.910138] Test:  [210/345]  eta: 0:00:25  loss: 0.8674 (0.8718)  time: 0.1902  data: 0.0001  max mem: 14938
[09:55:30.818129] Test:  [220/345]  eta: 0:00:23  loss: 0.8674 (0.8719)  time: 0.1905  data: 0.0001  max mem: 14938
[09:55:32.728441] Test:  [230/345]  eta: 0:00:21  loss: 0.8751 (0.8723)  time: 0.1909  data: 0.0001  max mem: 14938
[09:55:34.643440] Test:  [240/345]  eta: 0:00:19  loss: 0.8758 (0.8727)  time: 0.1912  data: 0.0001  max mem: 14938
[09:55:36.560826] Test:  [250/345]  eta: 0:00:17  loss: 0.8733 (0.8720)  time: 0.1916  data: 0.0001  max mem: 14938
[09:55:38.482109] Test:  [260/345]  eta: 0:00:16  loss: 0.8558 (0.8719)  time: 0.1919  data: 0.0001  max mem: 14938
[09:55:40.407687] Test:  [270/345]  eta: 0:00:14  loss: 0.8652 (0.8721)  time: 0.1923  data: 0.0001  max mem: 14938
[09:55:42.335701] Test:  [280/345]  eta: 0:00:12  loss: 0.8738 (0.8723)  time: 0.1926  data: 0.0001  max mem: 14938
[09:55:44.268257] Test:  [290/345]  eta: 0:00:10  loss: 0.8738 (0.8725)  time: 0.1930  data: 0.0001  max mem: 14938
[09:55:46.203847] Test:  [300/345]  eta: 0:00:08  loss: 0.8746 (0.8725)  time: 0.1934  data: 0.0001  max mem: 14938
[09:55:48.140866] Test:  [310/345]  eta: 0:00:06  loss: 0.8746 (0.8729)  time: 0.1936  data: 0.0001  max mem: 14938
[09:55:50.084046] Test:  [320/345]  eta: 0:00:04  loss: 0.8779 (0.8732)  time: 0.1940  data: 0.0001  max mem: 14938
[09:55:52.029551] Test:  [330/345]  eta: 0:00:02  loss: 0.8664 (0.8730)  time: 0.1944  data: 0.0001  max mem: 14938
[09:55:53.977537] Test:  [340/345]  eta: 0:00:00  loss: 0.8671 (0.8730)  time: 0.1946  data: 0.0001  max mem: 14938
[09:55:54.758144] Test:  [344/345]  eta: 0:00:00  loss: 0.8758 (0.8732)  time: 0.1948  data: 0.0001  max mem: 14938
[09:55:54.815513] Test: Total time: 0:01:05 (0.1898 s / it)
[09:56:05.153175] Test:  [ 0/57]  eta: 0:00:18  loss: 0.9834 (0.9834)  time: 0.3171  data: 0.1374  max mem: 14938
[09:56:06.965941] Test:  [10/57]  eta: 0:00:09  loss: 0.9328 (0.9392)  time: 0.1936  data: 0.0126  max mem: 14938
[09:56:08.783933] Test:  [20/57]  eta: 0:00:06  loss: 0.9328 (0.9330)  time: 0.1815  data: 0.0001  max mem: 14938
[09:56:10.608136] Test:  [30/57]  eta: 0:00:05  loss: 0.8347 (0.8889)  time: 0.1821  data: 0.0001  max mem: 14938
[09:56:12.435808] Test:  [40/57]  eta: 0:00:03  loss: 0.7898 (0.8624)  time: 0.1825  data: 0.0001  max mem: 14938
[09:56:14.269816] Test:  [50/57]  eta: 0:00:01  loss: 0.7898 (0.8545)  time: 0.1830  data: 0.0001  max mem: 14938
[09:56:15.259205] Test:  [56/57]  eta: 0:00:00  loss: 0.8269 (0.8590)  time: 0.1777  data: 0.0001  max mem: 14938
[09:56:15.318767] Test: Total time: 0:00:10 (0.1839 s / it)
[09:56:17.055531] Dice score of the network on the train images: 0.728685, val images: 0.787924
[09:56:17.055766] saving best_prec_model_0 @ epoch 7
[09:56:18.151740] saving best_dice_model_0 @ epoch 7
[09:56:19.197218] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[09:56:20.081205] Epoch: [8]  [  0/345]  eta: 0:05:04  lr: 0.000050  loss: 0.9398 (0.9398)  time: 0.8828  data: 0.1434  max mem: 14938
[09:56:34.943677] Epoch: [8]  [ 20/345]  eta: 0:04:03  lr: 0.000050  loss: 0.9159 (0.9239)  time: 0.7431  data: 0.0001  max mem: 14938
[09:56:49.856112] Epoch: [8]  [ 40/345]  eta: 0:03:48  lr: 0.000051  loss: 0.9068 (0.9214)  time: 0.7456  data: 0.0001  max mem: 14938
[09:57:04.801853] Epoch: [8]  [ 60/345]  eta: 0:03:33  lr: 0.000051  loss: 0.9253 (0.9235)  time: 0.7472  data: 0.0001  max mem: 14938
[09:57:19.773974] Epoch: [8]  [ 80/345]  eta: 0:03:18  lr: 0.000051  loss: 0.9185 (0.9212)  time: 0.7486  data: 0.0001  max mem: 14938
[09:57:34.769508] Epoch: [8]  [100/345]  eta: 0:03:03  lr: 0.000052  loss: 0.9160 (0.9207)  time: 0.7497  data: 0.0001  max mem: 14938
[09:57:49.898761] Epoch: [8]  [120/345]  eta: 0:02:48  lr: 0.000052  loss: 0.9223 (0.9202)  time: 0.7564  data: 0.0001  max mem: 14938
[09:58:04.901496] Epoch: [8]  [140/345]  eta: 0:02:33  lr: 0.000053  loss: 0.9305 (0.9215)  time: 0.7501  data: 0.0001  max mem: 14938

[09:58:19.897837] Epoch: [8]  [160/345]  eta: 0:02:18  lr: 0.000053  loss: 0.9115 (0.9206)  time: 0.7498  data: 0.0001  max mem: 14938
[09:58:34.893941] Epoch: [8]  [180/345]  eta: 0:02:03  lr: 0.000053  loss: 0.8999 (0.9196)  time: 0.7498  data: 0.0001  max mem: 14938
[09:58:49.881995] Epoch: [8]  [200/345]  eta: 0:01:48  lr: 0.000054  loss: 0.8878 (0.9170)  time: 0.7494  data: 0.0001  max mem: 14938
[09:59:04.884475] Epoch: [8]  [220/345]  eta: 0:01:33  lr: 0.000054  loss: 0.8971 (0.9149)  time: 0.7501  data: 0.0001  max mem: 14938
[09:59:19.879123] Epoch: [8]  [240/345]  eta: 0:01:18  lr: 0.000054  loss: 0.8955 (0.9137)  time: 0.7497  data: 0.0001  max mem: 14938
[09:59:34.868785] Epoch: [8]  [260/345]  eta: 0:01:03  lr: 0.000055  loss: 0.9034 (0.9133)  time: 0.7494  data: 0.0001  max mem: 14938
[09:59:49.859183] Epoch: [8]  [280/345]  eta: 0:00:48  lr: 0.000055  loss: 0.8996 (0.9123)  time: 0.7495  data: 0.0001  max mem: 14938
[10:00:04.843391] Epoch: [8]  [300/345]  eta: 0:00:33  lr: 0.000055  loss: 0.8888 (0.9109)  time: 0.7492  data: 0.0001  max mem: 14938
[10:00:19.835171] Epoch: [8]  [320/345]  eta: 0:00:18  lr: 0.000056  loss: 0.8821 (0.9098)  time: 0.7495  data: 0.0001  max mem: 14938
[10:00:34.822590] Epoch: [8]  [340/345]  eta: 0:00:03  lr: 0.000056  loss: 0.8792 (0.9082)  time: 0.7493  data: 0.0001  max mem: 14938
[10:00:37.819980] Epoch: [8]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.8876 (0.9079)  time: 0.7493  data: 0.0001  max mem: 14938
[10:00:37.884019] Epoch: [8] Total time: 0:04:18 (0.7498 s / it)
[10:00:37.884439] Averaged stats: lr: 0.000056  loss: 0.8876 (0.9079)
[10:00:38.216537] Test:  [  0/345]  eta: 0:01:53  loss: 0.8737 (0.8737)  time: 0.3279  data: 0.1456  max mem: 14938
[10:00:40.049086] Test:  [ 10/345]  eta: 0:01:05  loss: 0.8421 (0.8474)  time: 0.1963  data: 0.0133  max mem: 14938
[10:00:41.885791] Test:  [ 20/345]  eta: 0:01:01  loss: 0.8386 (0.8387)  time: 0.1834  data: 0.0001  max mem: 14938
[10:00:43.724646] Test:  [ 30/345]  eta: 0:00:59  loss: 0.8429 (0.8426)  time: 0.1837  data: 0.0001  max mem: 14938
[10:00:45.566141] Test:  [ 40/345]  eta: 0:00:57  loss: 0.8510 (0.8453)  time: 0.1840  data: 0.0001  max mem: 14938
[10:00:47.414235] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8484 (0.8447)  time: 0.1844  data: 0.0001  max mem: 14938
[10:00:49.266051] Test:  [ 60/345]  eta: 0:00:53  loss: 0.8423 (0.8463)  time: 0.1849  data: 0.0001  max mem: 14938
[10:00:51.119849] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8522 (0.8477)  time: 0.1852  data: 0.0001  max mem: 14938
[10:00:52.976513] Test:  [ 80/345]  eta: 0:00:49  loss: 0.8581 (0.8480)  time: 0.1855  data: 0.0001  max mem: 14938
[10:00:54.837000] Test:  [ 90/345]  eta: 0:00:47  loss: 0.8548 (0.8496)  time: 0.1858  data: 0.0001  max mem: 14938
[10:00:56.700303] Test:  [100/345]  eta: 0:00:45  loss: 0.8524 (0.8493)  time: 0.1861  data: 0.0001  max mem: 14938
[10:00:58.568483] Test:  [110/345]  eta: 0:00:43  loss: 0.8510 (0.8501)  time: 0.1865  data: 0.0001  max mem: 14938
[10:01:00.440249] Test:  [120/345]  eta: 0:00:41  loss: 0.8615 (0.8501)  time: 0.1869  data: 0.0001  max mem: 14938
[10:01:02.314055] Test:  [130/345]  eta: 0:00:40  loss: 0.8314 (0.8493)  time: 0.1872  data: 0.0001  max mem: 14938
[10:01:04.191331] Test:  [140/345]  eta: 0:00:38  loss: 0.8447 (0.8498)  time: 0.1875  data: 0.0001  max mem: 14938
[10:01:06.071989] Test:  [150/345]  eta: 0:00:36  loss: 0.8447 (0.8496)  time: 0.1878  data: 0.0001  max mem: 14938
[10:01:07.956721] Test:  [160/345]  eta: 0:00:34  loss: 0.8392 (0.8498)  time: 0.1882  data: 0.0001  max mem: 14938
[10:01:09.844350] Test:  [170/345]  eta: 0:00:32  loss: 0.8648 (0.8508)  time: 0.1886  data: 0.0001  max mem: 14938
[10:01:11.737538] Test:  [180/345]  eta: 0:00:30  loss: 0.8536 (0.8502)  time: 0.1890  data: 0.0001  max mem: 14938
[10:01:13.632684] Test:  [190/345]  eta: 0:00:28  loss: 0.8500 (0.8506)  time: 0.1894  data: 0.0001  max mem: 14938
[10:01:15.531208] Test:  [200/345]  eta: 0:00:27  loss: 0.8500 (0.8501)  time: 0.1896  data: 0.0001  max mem: 14938
[10:01:17.433520] Test:  [210/345]  eta: 0:00:25  loss: 0.8473 (0.8503)  time: 0.1900  data: 0.0001  max mem: 14938
[10:01:19.339088] Test:  [220/345]  eta: 0:00:23  loss: 0.8473 (0.8502)  time: 0.1903  data: 0.0001  max mem: 14938
[10:01:21.250119] Test:  [230/345]  eta: 0:00:21  loss: 0.8494 (0.8509)  time: 0.1908  data: 0.0001  max mem: 14938
[10:01:23.163748] Test:  [240/345]  eta: 0:00:19  loss: 0.8554 (0.8509)  time: 0.1912  data: 0.0001  max mem: 14938
[10:01:25.080479] Test:  [250/345]  eta: 0:00:17  loss: 0.8455 (0.8504)  time: 0.1915  data: 0.0001  max mem: 14938
[10:01:26.999700] Test:  [260/345]  eta: 0:00:15  loss: 0.8544 (0.8511)  time: 0.1917  data: 0.0001  max mem: 14938
[10:01:28.923606] Test:  [270/345]  eta: 0:00:14  loss: 0.8615 (0.8510)  time: 0.1921  data: 0.0001  max mem: 14938
[10:01:30.849015] Test:  [280/345]  eta: 0:00:12  loss: 0.8601 (0.8517)  time: 0.1924  data: 0.0001  max mem: 14938
[10:01:32.779727] Test:  [290/345]  eta: 0:00:10  loss: 0.8601 (0.8521)  time: 0.1928  data: 0.0001  max mem: 14938
[10:01:34.715119] Test:  [300/345]  eta: 0:00:08  loss: 0.8566 (0.8523)  time: 0.1933  data: 0.0001  max mem: 14938
[10:01:36.650447] Test:  [310/345]  eta: 0:00:06  loss: 0.8566 (0.8525)  time: 0.1935  data: 0.0001  max mem: 14938
[10:01:38.590539] Test:  [320/345]  eta: 0:00:04  loss: 0.8345 (0.8518)  time: 0.1937  data: 0.0001  max mem: 14938
[10:01:40.533821] Test:  [330/345]  eta: 0:00:02  loss: 0.8416 (0.8517)  time: 0.1941  data: 0.0001  max mem: 14938
[10:01:42.481301] Test:  [340/345]  eta: 0:00:00  loss: 0.8552 (0.8523)  time: 0.1945  data: 0.0001  max mem: 14938
[10:01:43.262734] Test:  [344/345]  eta: 0:00:00  loss: 0.8652 (0.8525)  time: 0.1947  data: 0.0001  max mem: 14938
[10:01:43.322276] Test: Total time: 0:01:05 (0.1897 s / it)
[10:01:53.563004] Test:  [ 0/57]  eta: 0:00:18  loss: 0.9303 (0.9303)  time: 0.3159  data: 0.1367  max mem: 14938
[10:01:55.376846] Test:  [10/57]  eta: 0:00:09  loss: 0.8961 (0.9141)  time: 0.1936  data: 0.0125  max mem: 14938
[10:01:57.195395] Test:  [20/57]  eta: 0:00:06  loss: 0.8961 (0.9083)  time: 0.1816  data: 0.0001  max mem: 14938
[10:01:59.015304] Test:  [30/57]  eta: 0:00:05  loss: 0.8266 (0.8693)  time: 0.1819  data: 0.0001  max mem: 14938
[10:02:00.842478] Test:  [40/57]  eta: 0:00:03  loss: 0.7762 (0.8455)  time: 0.1823  data: 0.0001  max mem: 14938
[10:02:02.677518] Test:  [50/57]  eta: 0:00:01  loss: 0.7762 (0.8382)  time: 0.1831  data: 0.0001  max mem: 14938
[10:02:03.667026] Test:  [56/57]  eta: 0:00:00  loss: 0.8204 (0.8437)  time: 0.1777  data: 0.0001  max mem: 14938
[10:02:03.726309] Test: Total time: 0:00:10 (0.1839 s / it)
[10:02:05.415568] Dice score of the network on the train images: 0.713651, val images: 0.789063
[10:02:05.415799] saving best_rec_model_0 @ epoch 8
[10:02:06.498835] saving best_dice_model_0 @ epoch 8
[10:02:07.548275] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:02:08.428907] Epoch: [9]  [  0/345]  eta: 0:05:03  lr: 0.000056  loss: 0.8770 (0.8770)  time: 0.8794  data: 0.1382  max mem: 14938
[10:02:23.304709] Epoch: [9]  [ 20/345]  eta: 0:04:03  lr: 0.000057  loss: 0.8650 (0.8775)  time: 0.7437  data: 0.0001  max mem: 14938
[10:02:38.226098] Epoch: [9]  [ 40/345]  eta: 0:03:48  lr: 0.000057  loss: 0.9079 (0.8886)  time: 0.7460  data: 0.0001  max mem: 14938
[10:02:53.180844] Epoch: [9]  [ 60/345]  eta: 0:03:33  lr: 0.000057  loss: 0.8855 (0.8903)  time: 0.7477  data: 0.0001  max mem: 14938
[10:03:08.150844] Epoch: [9]  [ 80/345]  eta: 0:03:18  lr: 0.000058  loss: 0.8770 (0.8879)  time: 0.7485  data: 0.0001  max mem: 14938
[10:03:23.168460] Epoch: [9]  [100/345]  eta: 0:03:03  lr: 0.000058  loss: 0.8855 (0.8872)  time: 0.7508  data: 0.0001  max mem: 14938
[10:03:38.212931] Epoch: [9]  [120/345]  eta: 0:02:48  lr: 0.000058  loss: 0.8768 (0.8871)  time: 0.7522  data: 0.0001  max mem: 14938
[10:03:53.246876] Epoch: [9]  [140/345]  eta: 0:02:33  lr: 0.000059  loss: 0.8803 (0.8860)  time: 0.7516  data: 0.0001  max mem: 14938
[10:04:08.270845] Epoch: [9]  [160/345]  eta: 0:02:18  lr: 0.000059  loss: 0.8870 (0.8850)  time: 0.7511  data: 0.0001  max mem: 14938
[10:04:23.293172] Epoch: [9]  [180/345]  eta: 0:02:03  lr: 0.000060  loss: 0.8906 (0.8859)  time: 0.7511  data: 0.0001  max mem: 14938
[10:04:38.307953] Epoch: [9]  [200/345]  eta: 0:01:48  lr: 0.000060  loss: 0.8791 (0.8848)  time: 0.7507  data: 0.0001  max mem: 14938
[10:04:53.315885] Epoch: [9]  [220/345]  eta: 0:01:33  lr: 0.000060  loss: 0.8818 (0.8846)  time: 0.7503  data: 0.0001  max mem: 14938
[10:05:08.318800] Epoch: [9]  [240/345]  eta: 0:01:18  lr: 0.000061  loss: 0.8567 (0.8827)  time: 0.7501  data: 0.0001  max mem: 14938
[10:05:23.403039] Epoch: [9]  [260/345]  eta: 0:01:03  lr: 0.000061  loss: 0.8910 (0.8834)  time: 0.7542  data: 0.0001  max mem: 14938

[10:05:38.398403] Epoch: [9]  [280/345]  eta: 0:00:48  lr: 0.000061  loss: 0.8814 (0.8831)  time: 0.7497  data: 0.0001  max mem: 14938
[10:05:53.401559] Epoch: [9]  [300/345]  eta: 0:00:33  lr: 0.000062  loss: 0.8772 (0.8825)  time: 0.7501  data: 0.0001  max mem: 14938
[10:06:08.394837] Epoch: [9]  [320/345]  eta: 0:00:18  lr: 0.000062  loss: 0.8774 (0.8822)  time: 0.7496  data: 0.0001  max mem: 14938
[10:06:23.392293] Epoch: [9]  [340/345]  eta: 0:00:03  lr: 0.000062  loss: 0.8748 (0.8817)  time: 0.7498  data: 0.0001  max mem: 14938
[10:06:26.389843] Epoch: [9]  [344/345]  eta: 0:00:00  lr: 0.000062  loss: 0.8597 (0.8816)  time: 0.7496  data: 0.0001  max mem: 14938
[10:06:26.453001] Epoch: [9] Total time: 0:04:18 (0.7504 s / it)
[10:06:26.453446] Averaged stats: lr: 0.000062  loss: 0.8597 (0.8816)
[10:06:26.784116] Test:  [  0/345]  eta: 0:01:52  loss: 0.8389 (0.8389)  time: 0.3263  data: 0.1450  max mem: 14938
[10:06:28.616371] Test:  [ 10/345]  eta: 0:01:05  loss: 0.8387 (0.8343)  time: 0.1962  data: 0.0132  max mem: 14938
[10:06:30.452885] Test:  [ 20/345]  eta: 0:01:01  loss: 0.8303 (0.8302)  time: 0.1834  data: 0.0001  max mem: 14938
[10:06:32.293266] Test:  [ 30/345]  eta: 0:00:59  loss: 0.8159 (0.8265)  time: 0.1838  data: 0.0001  max mem: 14938
[10:06:34.135363] Test:  [ 40/345]  eta: 0:00:57  loss: 0.8240 (0.8292)  time: 0.1841  data: 0.0001  max mem: 14938
[10:06:35.982789] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8396 (0.8317)  time: 0.1844  data: 0.0001  max mem: 14938
[10:06:37.833925] Test:  [ 60/345]  eta: 0:00:53  loss: 0.8232 (0.8291)  time: 0.1849  data: 0.0001  max mem: 14938
[10:06:39.687462] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8112 (0.8289)  time: 0.1852  data: 0.0001  max mem: 14938
[10:06:41.543932] Test:  [ 80/345]  eta: 0:00:49  loss: 0.8112 (0.8270)  time: 0.1854  data: 0.0001  max mem: 14938
[10:06:43.406544] Test:  [ 90/345]  eta: 0:00:47  loss: 0.8204 (0.8275)  time: 0.1859  data: 0.0001  max mem: 14938
[10:06:45.270702] Test:  [100/345]  eta: 0:00:45  loss: 0.8204 (0.8275)  time: 0.1863  data: 0.0001  max mem: 14938
[10:06:47.135821] Test:  [110/345]  eta: 0:00:43  loss: 0.8150 (0.8272)  time: 0.1864  data: 0.0001  max mem: 14938
[10:06:49.007154] Test:  [120/345]  eta: 0:00:41  loss: 0.8195 (0.8277)  time: 0.1868  data: 0.0001  max mem: 14938
[10:06:50.881867] Test:  [130/345]  eta: 0:00:40  loss: 0.8232 (0.8275)  time: 0.1872  data: 0.0001  max mem: 14938
[10:06:52.759906] Test:  [140/345]  eta: 0:00:38  loss: 0.8178 (0.8265)  time: 0.1876  data: 0.0001  max mem: 14938
[10:06:54.639358] Test:  [150/345]  eta: 0:00:36  loss: 0.8140 (0.8265)  time: 0.1878  data: 0.0001  max mem: 14938
[10:06:56.523525] Test:  [160/345]  eta: 0:00:34  loss: 0.8199 (0.8262)  time: 0.1881  data: 0.0001  max mem: 14938
[10:06:58.411714] Test:  [170/345]  eta: 0:00:32  loss: 0.8265 (0.8269)  time: 0.1886  data: 0.0001  max mem: 14938
[10:07:00.305160] Test:  [180/345]  eta: 0:00:30  loss: 0.8384 (0.8277)  time: 0.1890  data: 0.0001  max mem: 14938
[10:07:02.199884] Test:  [190/345]  eta: 0:00:28  loss: 0.8280 (0.8275)  time: 0.1894  data: 0.0001  max mem: 14938
[10:07:04.100981] Test:  [200/345]  eta: 0:00:27  loss: 0.8239 (0.8272)  time: 0.1897  data: 0.0001  max mem: 14938
[10:07:06.004258] Test:  [210/345]  eta: 0:00:25  loss: 0.8314 (0.8273)  time: 0.1902  data: 0.0001  max mem: 14938
[10:07:07.909503] Test:  [220/345]  eta: 0:00:23  loss: 0.8322 (0.8275)  time: 0.1904  data: 0.0001  max mem: 14938
[10:07:09.818184] Test:  [230/345]  eta: 0:00:21  loss: 0.8370 (0.8282)  time: 0.1906  data: 0.0001  max mem: 14938
[10:07:11.731362] Test:  [240/345]  eta: 0:00:19  loss: 0.8370 (0.8284)  time: 0.1910  data: 0.0001  max mem: 14938
[10:07:13.648487] Test:  [250/345]  eta: 0:00:17  loss: 0.8255 (0.8284)  time: 0.1915  data: 0.0001  max mem: 14938
[10:07:15.569117] Test:  [260/345]  eta: 0:00:15  loss: 0.8255 (0.8283)  time: 0.1918  data: 0.0001  max mem: 14938
[10:07:17.494503] Test:  [270/345]  eta: 0:00:14  loss: 0.8185 (0.8279)  time: 0.1922  data: 0.0001  max mem: 14938
[10:07:19.421860] Test:  [280/345]  eta: 0:00:12  loss: 0.8213 (0.8280)  time: 0.1926  data: 0.0001  max mem: 14938
[10:07:21.353021] Test:  [290/345]  eta: 0:00:10  loss: 0.8209 (0.8277)  time: 0.1929  data: 0.0001  max mem: 14938
[10:07:23.288756] Test:  [300/345]  eta: 0:00:08  loss: 0.8183 (0.8276)  time: 0.1933  data: 0.0001  max mem: 14938
[10:07:25.225098] Test:  [310/345]  eta: 0:00:06  loss: 0.8210 (0.8279)  time: 0.1936  data: 0.0001  max mem: 14938
[10:07:27.165839] Test:  [320/345]  eta: 0:00:04  loss: 0.8341 (0.8281)  time: 0.1938  data: 0.0001  max mem: 14938
[10:07:29.108803] Test:  [330/345]  eta: 0:00:02  loss: 0.8201 (0.8277)  time: 0.1941  data: 0.0001  max mem: 14938
[10:07:31.055260] Test:  [340/345]  eta: 0:00:00  loss: 0.8218 (0.8279)  time: 0.1944  data: 0.0001  max mem: 14938
[10:07:31.835093] Test:  [344/345]  eta: 0:00:00  loss: 0.8218 (0.8279)  time: 0.1946  data: 0.0001  max mem: 14938
[10:07:31.893013] Test: Total time: 0:01:05 (0.1897 s / it)
[10:07:42.186551] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8882 (0.8882)  time: 0.3175  data: 0.1379  max mem: 14938
[10:07:44.000389] Test:  [10/57]  eta: 0:00:09  loss: 0.8748 (0.8962)  time: 0.1937  data: 0.0126  max mem: 14938
[10:07:45.818990] Test:  [20/57]  eta: 0:00:06  loss: 0.8867 (0.8898)  time: 0.1816  data: 0.0001  max mem: 14938
[10:07:47.640999] Test:  [30/57]  eta: 0:00:05  loss: 0.8083 (0.8542)  time: 0.1820  data: 0.0001  max mem: 14938
[10:07:49.470464] Test:  [40/57]  eta: 0:00:03  loss: 0.7664 (0.8328)  time: 0.1825  data: 0.0001  max mem: 14938
[10:07:51.305956] Test:  [50/57]  eta: 0:00:01  loss: 0.7664 (0.8266)  time: 0.1832  data: 0.0001  max mem: 14938
[10:07:52.295960] Test:  [56/57]  eta: 0:00:00  loss: 0.8096 (0.8317)  time: 0.1778  data: 0.0001  max mem: 14938
[10:07:52.352030] Test: Total time: 0:00:10 (0.1839 s / it)
[10:07:54.076923] Dice score of the network on the train images: 0.746682, val images: 0.800172
[10:07:54.077140] saving best_dice_model_0 @ epoch 9
[10:07:55.140144] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:07:56.020078] Epoch: [10]  [  0/345]  eta: 0:05:03  lr: 0.000063  loss: 0.8882 (0.8882)  time: 0.8788  data: 0.1384  max mem: 14938
[10:08:10.904345] Epoch: [10]  [ 20/345]  eta: 0:04:03  lr: 0.000063  loss: 0.8749 (0.8717)  time: 0.7442  data: 0.0001  max mem: 14938
[10:08:25.833421] Epoch: [10]  [ 40/345]  eta: 0:03:48  lr: 0.000063  loss: 0.8614 (0.8659)  time: 0.7464  data: 0.0001  max mem: 14938
[10:08:40.796174] Epoch: [10]  [ 60/345]  eta: 0:03:33  lr: 0.000064  loss: 0.8647 (0.8656)  time: 0.7481  data: 0.0001  max mem: 14938
[10:08:55.765357] Epoch: [10]  [ 80/345]  eta: 0:03:18  lr: 0.000064  loss: 0.8578 (0.8653)  time: 0.7484  data: 0.0001  max mem: 14938
[10:09:10.748284] Epoch: [10]  [100/345]  eta: 0:03:03  lr: 0.000064  loss: 0.8568 (0.8651)  time: 0.7491  data: 0.0001  max mem: 14938
[10:09:25.760974] Epoch: [10]  [120/345]  eta: 0:02:48  lr: 0.000065  loss: 0.8602 (0.8640)  time: 0.7506  data: 0.0001  max mem: 14938
[10:09:40.806371] Epoch: [10]  [140/345]  eta: 0:02:33  lr: 0.000065  loss: 0.8421 (0.8617)  time: 0.7522  data: 0.0001  max mem: 14938
[10:09:55.849885] Epoch: [10]  [160/345]  eta: 0:02:18  lr: 0.000065  loss: 0.8666 (0.8620)  time: 0.7521  data: 0.0001  max mem: 14938
[10:10:10.883452] Epoch: [10]  [180/345]  eta: 0:02:03  lr: 0.000066  loss: 0.8547 (0.8621)  time: 0.7516  data: 0.0001  max mem: 14938
[10:10:25.895245] Epoch: [10]  [200/345]  eta: 0:01:48  lr: 0.000066  loss: 0.8419 (0.8614)  time: 0.7505  data: 0.0001  max mem: 14938
[10:10:40.897308] Epoch: [10]  [220/345]  eta: 0:01:33  lr: 0.000066  loss: 0.8411 (0.8599)  time: 0.7501  data: 0.0001  max mem: 14938
[10:10:55.897791] Epoch: [10]  [240/345]  eta: 0:01:18  lr: 0.000067  loss: 0.8497 (0.8596)  time: 0.7500  data: 0.0001  max mem: 14938
[10:11:10.898054] Epoch: [10]  [260/345]  eta: 0:01:03  lr: 0.000067  loss: 0.8614 (0.8597)  time: 0.7500  data: 0.0001  max mem: 14938
[10:11:25.888951] Epoch: [10]  [280/345]  eta: 0:00:48  lr: 0.000068  loss: 0.8414 (0.8590)  time: 0.7495  data: 0.0001  max mem: 14938
[10:11:40.860367] Epoch: [10]  [300/345]  eta: 0:00:33  lr: 0.000068  loss: 0.8340 (0.8579)  time: 0.7485  data: 0.0001  max mem: 14938
[10:11:55.920339] Epoch: [10]  [320/345]  eta: 0:00:18  lr: 0.000068  loss: 0.8380 (0.8572)  time: 0.7529  data: 0.0001  max mem: 14938
[10:12:10.890889] Epoch: [10]  [340/345]  eta: 0:00:03  lr: 0.000069  loss: 0.8392 (0.8562)  time: 0.7485  data: 0.0001  max mem: 14938
[10:12:13.888411] Epoch: [10]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.8344 (0.8559)  time: 0.7487  data: 0.0001  max mem: 14938
[10:12:13.951130] Epoch: [10] Total time: 0:04:18 (0.7502 s / it)
[10:12:13.951618] Averaged stats: lr: 0.000069  loss: 0.8344 (0.8559)
[10:12:14.288940] Test:  [  0/345]  eta: 0:01:55  loss: 0.7706 (0.7706)  time: 0.3339  data: 0.1522  max mem: 14938
[10:12:16.123163] Test:  [ 10/345]  eta: 0:01:05  loss: 0.8092 (0.8073)  time: 0.1970  data: 0.0139  max mem: 14938
[10:12:17.959616] Test:  [ 20/345]  eta: 0:01:01  loss: 0.8092 (0.8072)  time: 0.1835  data: 0.0001  max mem: 14938
[10:12:19.799722] Test:  [ 30/345]  eta: 0:00:59  loss: 0.8127 (0.8101)  time: 0.1838  data: 0.0001  max mem: 14938
[10:12:21.642680] Test:  [ 40/345]  eta: 0:00:57  loss: 0.8183 (0.8126)  time: 0.1841  data: 0.0001  max mem: 14938
[10:12:23.493361] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8033 (0.8106)  time: 0.1846  data: 0.0001  max mem: 14938
[10:12:25.344120] Test:  [ 60/345]  eta: 0:00:53  loss: 0.8019 (0.8122)  time: 0.1850  data: 0.0001  max mem: 14938
[10:12:27.198736] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8113 (0.8124)  time: 0.1852  data: 0.0001  max mem: 14938
[10:12:29.056053] Test:  [ 80/345]  eta: 0:00:49  loss: 0.8006 (0.8108)  time: 0.1855  data: 0.0001  max mem: 14938
[10:12:30.917673] Test:  [ 90/345]  eta: 0:00:47  loss: 0.8006 (0.8106)  time: 0.1859  data: 0.0001  max mem: 14938
[10:12:32.781075] Test:  [100/345]  eta: 0:00:45  loss: 0.8165 (0.8116)  time: 0.1862  data: 0.0001  max mem: 14938
[10:12:34.648838] Test:  [110/345]  eta: 0:00:43  loss: 0.8180 (0.8119)  time: 0.1865  data: 0.0001  max mem: 14938
[10:12:36.520318] Test:  [120/345]  eta: 0:00:41  loss: 0.8113 (0.8113)  time: 0.1869  data: 0.0001  max mem: 14938
[10:12:38.396413] Test:  [130/345]  eta: 0:00:40  loss: 0.8073 (0.8113)  time: 0.1873  data: 0.0001  max mem: 14938
[10:12:40.274843] Test:  [140/345]  eta: 0:00:38  loss: 0.7994 (0.8107)  time: 0.1877  data: 0.0001  max mem: 14938
[10:12:42.157158] Test:  [150/345]  eta: 0:00:36  loss: 0.8010 (0.8103)  time: 0.1880  data: 0.0001  max mem: 14938
[10:12:44.040821] Test:  [160/345]  eta: 0:00:34  loss: 0.8142 (0.8109)  time: 0.1882  data: 0.0001  max mem: 14938
[10:12:45.929943] Test:  [170/345]  eta: 0:00:32  loss: 0.8122 (0.8106)  time: 0.1886  data: 0.0001  max mem: 14938
[10:12:47.824367] Test:  [180/345]  eta: 0:00:30  loss: 0.8122 (0.8106)  time: 0.1891  data: 0.0001  max mem: 14938
[10:12:49.721087] Test:  [190/345]  eta: 0:00:29  loss: 0.8212 (0.8116)  time: 0.1895  data: 0.0001  max mem: 14938
[10:12:51.619627] Test:  [200/345]  eta: 0:00:27  loss: 0.8244 (0.8124)  time: 0.1897  data: 0.0001  max mem: 14938
[10:12:53.520593] Test:  [210/345]  eta: 0:00:25  loss: 0.8166 (0.8124)  time: 0.1899  data: 0.0001  max mem: 14938
[10:12:55.426593] Test:  [220/345]  eta: 0:00:23  loss: 0.8111 (0.8128)  time: 0.1903  data: 0.0001  max mem: 14938
[10:12:57.336718] Test:  [230/345]  eta: 0:00:21  loss: 0.8132 (0.8136)  time: 0.1908  data: 0.0001  max mem: 14938
[10:12:59.250786] Test:  [240/345]  eta: 0:00:19  loss: 0.8021 (0.8131)  time: 0.1912  data: 0.0001  max mem: 14938
[10:13:01.169266] Test:  [250/345]  eta: 0:00:17  loss: 0.8083 (0.8132)  time: 0.1916  data: 0.0001  max mem: 14938
[10:13:03.090936] Test:  [260/345]  eta: 0:00:15  loss: 0.8146 (0.8132)  time: 0.1920  data: 0.0001  max mem: 14938
[10:13:05.014267] Test:  [270/345]  eta: 0:00:14  loss: 0.8098 (0.8130)  time: 0.1922  data: 0.0001  max mem: 14938
[10:13:06.941679] Test:  [280/345]  eta: 0:00:12  loss: 0.8066 (0.8131)  time: 0.1925  data: 0.0001  max mem: 14938
[10:13:08.875118] Test:  [290/345]  eta: 0:00:10  loss: 0.8144 (0.8133)  time: 0.1930  data: 0.0001  max mem: 14938
[10:13:10.809291] Test:  [300/345]  eta: 0:00:08  loss: 0.8009 (0.8132)  time: 0.1933  data: 0.0001  max mem: 14938
[10:13:12.746930] Test:  [310/345]  eta: 0:00:06  loss: 0.7869 (0.8124)  time: 0.1935  data: 0.0001  max mem: 14938
[10:13:14.688912] Test:  [320/345]  eta: 0:00:04  loss: 0.8037 (0.8127)  time: 0.1939  data: 0.0001  max mem: 14938
[10:13:16.635417] Test:  [330/345]  eta: 0:00:02  loss: 0.8090 (0.8126)  time: 0.1944  data: 0.0001  max mem: 14938
[10:13:18.583816] Test:  [340/345]  eta: 0:00:00  loss: 0.8083 (0.8129)  time: 0.1947  data: 0.0001  max mem: 14938
[10:13:19.364929] Test:  [344/345]  eta: 0:00:00  loss: 0.8182 (0.8129)  time: 0.1948  data: 0.0001  max mem: 14938
[10:13:19.422874] Test: Total time: 0:01:05 (0.1898 s / it)
[10:13:29.645962] Test:  [ 0/57]  eta: 0:00:17  loss: 0.9047 (0.9047)  time: 0.3153  data: 0.1347  max mem: 14938
[10:13:31.458705] Test:  [10/57]  eta: 0:00:09  loss: 0.9047 (0.9103)  time: 0.1934  data: 0.0123  max mem: 14938
[10:13:33.278032] Test:  [20/57]  eta: 0:00:06  loss: 0.9095 (0.9053)  time: 0.1815  data: 0.0001  max mem: 14938
[10:13:35.101824] Test:  [30/57]  eta: 0:00:05  loss: 0.8076 (0.8621)  time: 0.1821  data: 0.0001  max mem: 14938
[10:13:36.931961] Test:  [40/57]  eta: 0:00:03  loss: 0.7583 (0.8367)  time: 0.1826  data: 0.0001  max mem: 14938
[10:13:38.766802] Test:  [50/57]  eta: 0:00:01  loss: 0.7583 (0.8282)  time: 0.1832  data: 0.0001  max mem: 14938
[10:13:39.756905] Test:  [56/57]  eta: 0:00:00  loss: 0.8000 (0.8332)  time: 0.1778  data: 0.0001  max mem: 14938
[10:13:39.817667] Test: Total time: 0:00:10 (0.1840 s / it)
[10:13:41.506820] Dice score of the network on the train images: 0.769304, val images: 0.811683
[10:13:41.507043] saving best_prec_model_0 @ epoch 10
[10:13:42.572016] saving best_dice_model_0 @ epoch 10
[10:13:43.619396] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:13:44.495064] Epoch: [11]  [  0/345]  eta: 0:05:01  lr: 0.000069  loss: 0.8813 (0.8813)  time: 0.8748  data: 0.1347  max mem: 14938
[10:13:59.365845] Epoch: [11]  [ 20/345]  eta: 0:04:03  lr: 0.000069  loss: 0.8545 (0.8527)  time: 0.7435  data: 0.0001  max mem: 14938
[10:14:14.285704] Epoch: [11]  [ 40/345]  eta: 0:03:48  lr: 0.000069  loss: 0.8310 (0.8454)  time: 0.7459  data: 0.0001  max mem: 14938
[10:14:29.238315] Epoch: [11]  [ 60/345]  eta: 0:03:33  lr: 0.000070  loss: 0.8312 (0.8419)  time: 0.7476  data: 0.0001  max mem: 14938
[10:14:44.205656] Epoch: [11]  [ 80/345]  eta: 0:03:18  lr: 0.000070  loss: 0.8505 (0.8431)  time: 0.7483  data: 0.0001  max mem: 14938
[10:14:59.211179] Epoch: [11]  [100/345]  eta: 0:03:03  lr: 0.000071  loss: 0.8385 (0.8436)  time: 0.7502  data: 0.0001  max mem: 14938
[10:15:14.368945] Epoch: [11]  [120/345]  eta: 0:02:48  lr: 0.000071  loss: 0.8374 (0.8441)  time: 0.7578  data: 0.0001  max mem: 14938
[10:15:29.407814] Epoch: [11]  [140/345]  eta: 0:02:33  lr: 0.000071  loss: 0.8412 (0.8440)  time: 0.7519  data: 0.0001  max mem: 14938
[10:15:44.434532] Epoch: [11]  [160/345]  eta: 0:02:18  lr: 0.000072  loss: 0.8335 (0.8425)  time: 0.7513  data: 0.0001  max mem: 14938
[10:15:59.458087] Epoch: [11]  [180/345]  eta: 0:02:03  lr: 0.000072  loss: 0.8217 (0.8413)  time: 0.7511  data: 0.0001  max mem: 14938
[10:16:14.482142] Epoch: [11]  [200/345]  eta: 0:01:48  lr: 0.000072  loss: 0.8222 (0.8402)  time: 0.7512  data: 0.0001  max mem: 14938
[10:16:29.488431] Epoch: [11]  [220/345]  eta: 0:01:33  lr: 0.000073  loss: 0.8315 (0.8400)  time: 0.7503  data: 0.0001  max mem: 14938
[10:16:44.476772] Epoch: [11]  [240/345]  eta: 0:01:18  lr: 0.000073  loss: 0.8238 (0.8390)  time: 0.7494  data: 0.0001  max mem: 14938
[10:16:59.457768] Epoch: [11]  [260/345]  eta: 0:01:03  lr: 0.000073  loss: 0.8314 (0.8381)  time: 0.7490  data: 0.0001  max mem: 14938
[10:17:14.438221] Epoch: [11]  [280/345]  eta: 0:00:48  lr: 0.000074  loss: 0.8379 (0.8383)  time: 0.7490  data: 0.0001  max mem: 14938
[10:17:29.419542] Epoch: [11]  [300/345]  eta: 0:00:33  lr: 0.000074  loss: 0.8298 (0.8376)  time: 0.7490  data: 0.0001  max mem: 14938
[10:17:44.385740] Epoch: [11]  [320/345]  eta: 0:00:18  lr: 0.000075  loss: 0.8406 (0.8380)  time: 0.7483  data: 0.0001  max mem: 14938
[10:17:59.375691] Epoch: [11]  [340/345]  eta: 0:00:03  lr: 0.000075  loss: 0.8245 (0.8373)  time: 0.7495  data: 0.0001  max mem: 14938
[10:18:02.374700] Epoch: [11]  [344/345]  eta: 0:00:00  lr: 0.000075  loss: 0.8278 (0.8372)  time: 0.7497  data: 0.0001  max mem: 14938
[10:18:02.437341] Epoch: [11] Total time: 0:04:18 (0.7502 s / it)
[10:18:02.437622] Averaged stats: lr: 0.000075  loss: 0.8278 (0.8372)
[10:18:02.770383] Test:  [  0/345]  eta: 0:01:53  loss: 0.8245 (0.8245)  time: 0.3285  data: 0.1467  max mem: 14938
[10:18:04.605777] Test:  [ 10/345]  eta: 0:01:05  loss: 0.8022 (0.8105)  time: 0.1967  data: 0.0134  max mem: 14938
[10:18:06.442768] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7979 (0.8024)  time: 0.1836  data: 0.0001  max mem: 14938
[10:18:08.283982] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7966 (0.8019)  time: 0.1839  data: 0.0001  max mem: 14938
[10:18:10.127736] Test:  [ 40/345]  eta: 0:00:57  loss: 0.8127 (0.8069)  time: 0.1842  data: 0.0001  max mem: 14938
[10:18:11.975699] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8167 (0.8077)  time: 0.1845  data: 0.0001  max mem: 14938
[10:18:13.826004] Test:  [ 60/345]  eta: 0:00:53  loss: 0.8121 (0.8071)  time: 0.1849  data: 0.0001  max mem: 14938
[10:18:15.680363] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8121 (0.8072)  time: 0.1852  data: 0.0001  max mem: 14938
[10:18:17.538423] Test:  [ 80/345]  eta: 0:00:49  loss: 0.8077 (0.8074)  time: 0.1856  data: 0.0001  max mem: 14938
[10:18:19.400686] Test:  [ 90/345]  eta: 0:00:47  loss: 0.8070 (0.8080)  time: 0.1860  data: 0.0001  max mem: 14938
[10:18:21.266374] Test:  [100/345]  eta: 0:00:45  loss: 0.8123 (0.8078)  time: 0.1863  data: 0.0001  max mem: 14938
[10:18:23.134104] Test:  [110/345]  eta: 0:00:43  loss: 0.8123 (0.8084)  time: 0.1866  data: 0.0001  max mem: 14938
[10:18:25.004341] Test:  [120/345]  eta: 0:00:41  loss: 0.8090 (0.8078)  time: 0.1868  data: 0.0001  max mem: 14938
[10:18:26.881015] Test:  [130/345]  eta: 0:00:40  loss: 0.8073 (0.8079)  time: 0.1873  data: 0.0001  max mem: 14938
[10:18:28.759596] Test:  [140/345]  eta: 0:00:38  loss: 0.8079 (0.8085)  time: 0.1877  data: 0.0001  max mem: 14938
[10:18:30.641426] Test:  [150/345]  eta: 0:00:36  loss: 0.8095 (0.8085)  time: 0.1880  data: 0.0001  max mem: 14938
[10:18:32.525317] Test:  [160/345]  eta: 0:00:34  loss: 0.8089 (0.8080)  time: 0.1882  data: 0.0001  max mem: 14938
[10:18:34.413615] Test:  [170/345]  eta: 0:00:32  loss: 0.7988 (0.8076)  time: 0.1886  data: 0.0001  max mem: 14938
[10:18:36.307085] Test:  [180/345]  eta: 0:00:30  loss: 0.8059 (0.8081)  time: 0.1890  data: 0.0001  max mem: 14938
[10:18:38.203683] Test:  [190/345]  eta: 0:00:29  loss: 0.8104 (0.8083)  time: 0.1894  data: 0.0001  max mem: 14938
[10:18:40.104491] Test:  [200/345]  eta: 0:00:27  loss: 0.8057 (0.8079)  time: 0.1898  data: 0.0001  max mem: 14938
[10:18:42.007821] Test:  [210/345]  eta: 0:00:25  loss: 0.8072 (0.8079)  time: 0.1902  data: 0.0001  max mem: 14938
[10:18:43.914926] Test:  [220/345]  eta: 0:00:23  loss: 0.8085 (0.8077)  time: 0.1905  data: 0.0001  max mem: 14938
[10:18:45.826114] Test:  [230/345]  eta: 0:00:21  loss: 0.8049 (0.8074)  time: 0.1909  data: 0.0001  max mem: 14938
[10:18:47.741404] Test:  [240/345]  eta: 0:00:19  loss: 0.8004 (0.8073)  time: 0.1913  data: 0.0001  max mem: 14938
[10:18:49.659275] Test:  [250/345]  eta: 0:00:17  loss: 0.7926 (0.8068)  time: 0.1916  data: 0.0001  max mem: 14938
[10:18:51.579622] Test:  [260/345]  eta: 0:00:15  loss: 0.7926 (0.8066)  time: 0.1919  data: 0.0001  max mem: 14938
[10:18:53.503339] Test:  [270/345]  eta: 0:00:14  loss: 0.8028 (0.8064)  time: 0.1921  data: 0.0001  max mem: 14938
[10:18:55.430987] Test:  [280/345]  eta: 0:00:12  loss: 0.8089 (0.8068)  time: 0.1925  data: 0.0001  max mem: 14938
[10:18:57.362757] Test:  [290/345]  eta: 0:00:10  loss: 0.8228 (0.8071)  time: 0.1929  data: 0.0001  max mem: 14938
[10:18:59.298086] Test:  [300/345]  eta: 0:00:08  loss: 0.8069 (0.8069)  time: 0.1933  data: 0.0001  max mem: 14938
[10:19:01.235652] Test:  [310/345]  eta: 0:00:06  loss: 0.8032 (0.8068)  time: 0.1936  data: 0.0001  max mem: 14938
[10:19:03.177290] Test:  [320/345]  eta: 0:00:04  loss: 0.8053 (0.8071)  time: 0.1939  data: 0.0001  max mem: 14938
[10:19:05.122941] Test:  [330/345]  eta: 0:00:02  loss: 0.8037 (0.8069)  time: 0.1943  data: 0.0001  max mem: 14938
[10:19:07.071982] Test:  [340/345]  eta: 0:00:00  loss: 0.8026 (0.8069)  time: 0.1947  data: 0.0001  max mem: 14938
[10:19:07.853150] Test:  [344/345]  eta: 0:00:00  loss: 0.8007 (0.8068)  time: 0.1948  data: 0.0001  max mem: 14938
[10:19:07.911853] Test: Total time: 0:01:05 (0.1898 s / it)
[10:19:18.262583] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8372 (0.8372)  time: 0.3187  data: 0.1392  max mem: 14938
[10:19:20.077103] Test:  [10/57]  eta: 0:00:09  loss: 0.8549 (0.8774)  time: 0.1939  data: 0.0127  max mem: 14938
[10:19:21.896365] Test:  [20/57]  eta: 0:00:06  loss: 0.8657 (0.8696)  time: 0.1816  data: 0.0001  max mem: 14938
[10:19:23.719246] Test:  [30/57]  eta: 0:00:05  loss: 0.7785 (0.8367)  time: 0.1821  data: 0.0001  max mem: 14938
[10:19:25.547065] Test:  [40/57]  eta: 0:00:03  loss: 0.7590 (0.8178)  time: 0.1825  data: 0.0001  max mem: 14938
[10:19:27.383090] Test:  [50/57]  eta: 0:00:01  loss: 0.7590 (0.8116)  time: 0.1831  data: 0.0001  max mem: 14938
[10:19:28.373085] Test:  [56/57]  eta: 0:00:00  loss: 0.8010 (0.8179)  time: 0.1778  data: 0.0001  max mem: 14938
[10:19:28.429247] Test: Total time: 0:00:10 (0.1840 s / it)
[10:19:30.212310] Dice score of the network on the train images: 0.724824, val images: 0.797653
[10:19:30.212532] saving best_rec_model_0 @ epoch 11
[10:19:31.228479] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:19:32.115579] Epoch: [12]  [  0/345]  eta: 0:05:05  lr: 0.000075  loss: 0.8805 (0.8805)  time: 0.8859  data: 0.1448  max mem: 14938
[10:19:46.972667] Epoch: [12]  [ 20/345]  eta: 0:04:03  lr: 0.000075  loss: 0.8139 (0.8275)  time: 0.7428  data: 0.0001  max mem: 14938
[10:20:01.910013] Epoch: [12]  [ 40/345]  eta: 0:03:48  lr: 0.000076  loss: 0.8228 (0.8293)  time: 0.7468  data: 0.0001  max mem: 14938
[10:20:17.002235] Epoch: [12]  [ 60/345]  eta: 0:03:33  lr: 0.000076  loss: 0.8284 (0.8312)  time: 0.7545  data: 0.0001  max mem: 14938
[10:20:31.975975] Epoch: [12]  [ 80/345]  eta: 0:03:18  lr: 0.000076  loss: 0.8285 (0.8319)  time: 0.7486  data: 0.0001  max mem: 14938
[10:20:46.992964] Epoch: [12]  [100/345]  eta: 0:03:03  lr: 0.000077  loss: 0.8088 (0.8285)  time: 0.7508  data: 0.0001  max mem: 14938
[10:21:02.022408] Epoch: [12]  [120/345]  eta: 0:02:48  lr: 0.000077  loss: 0.8208 (0.8269)  time: 0.7514  data: 0.0001  max mem: 14938
[10:21:17.060507] Epoch: [12]  [140/345]  eta: 0:02:33  lr: 0.000078  loss: 0.8194 (0.8256)  time: 0.7519  data: 0.0001  max mem: 14938
[10:21:32.088924] Epoch: [12]  [160/345]  eta: 0:02:18  lr: 0.000078  loss: 0.8341 (0.8262)  time: 0.7514  data: 0.0001  max mem: 14938
[10:21:47.105610] Epoch: [12]  [180/345]  eta: 0:02:03  lr: 0.000078  loss: 0.8213 (0.8259)  time: 0.7508  data: 0.0001  max mem: 14938
[10:22:02.128379] Epoch: [12]  [200/345]  eta: 0:01:48  lr: 0.000079  loss: 0.8197 (0.8257)  time: 0.7510  data: 0.0001  max mem: 14938
[10:22:17.146835] Epoch: [12]  [220/345]  eta: 0:01:33  lr: 0.000079  loss: 0.8194 (0.8253)  time: 0.7509  data: 0.0001  max mem: 14938
[10:22:32.161993] Epoch: [12]  [240/345]  eta: 0:01:18  lr: 0.000079  loss: 0.8081 (0.8242)  time: 0.7507  data: 0.0001  max mem: 14938
[10:22:47.172456] Epoch: [12]  [260/345]  eta: 0:01:03  lr: 0.000080  loss: 0.8166 (0.8238)  time: 0.7505  data: 0.0001  max mem: 14938
[10:23:02.172582] Epoch: [12]  [280/345]  eta: 0:00:48  lr: 0.000080  loss: 0.8391 (0.8256)  time: 0.7500  data: 0.0001  max mem: 14938
[10:23:17.171384] Epoch: [12]  [300/345]  eta: 0:00:33  lr: 0.000080  loss: 0.8320 (0.8263)  time: 0.7499  data: 0.0001  max mem: 14938
[10:23:32.253856] Epoch: [12]  [320/345]  eta: 0:00:18  lr: 0.000081  loss: 0.8215 (0.8262)  time: 0.7541  data: 0.0001  max mem: 14938
[10:23:47.244358] Epoch: [12]  [340/345]  eta: 0:00:03  lr: 0.000081  loss: 0.8318 (0.8264)  time: 0.7495  data: 0.0001  max mem: 14938
[10:23:50.240291] Epoch: [12]  [344/345]  eta: 0:00:00  lr: 0.000081  loss: 0.8368 (0.8266)  time: 0.7495  data: 0.0001  max mem: 14938
[10:23:50.304654] Epoch: [12] Total time: 0:04:19 (0.7509 s / it)
[10:23:50.305155] Averaged stats: lr: 0.000081  loss: 0.8368 (0.8266)
[10:23:50.638854] Test:  [  0/345]  eta: 0:01:53  loss: 0.8338 (0.8338)  time: 0.3296  data: 0.1488  max mem: 14938
[10:23:52.473469] Test:  [ 10/345]  eta: 0:01:05  loss: 0.8009 (0.8066)  time: 0.1967  data: 0.0136  max mem: 14938
[10:23:54.311502] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7964 (0.8000)  time: 0.1836  data: 0.0001  max mem: 14938
[10:23:56.152349] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7833 (0.7973)  time: 0.1839  data: 0.0001  max mem: 14938
[10:23:57.997032] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7929 (0.7978)  time: 0.1842  data: 0.0001  max mem: 14938
[10:23:59.845584] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7929 (0.7967)  time: 0.1846  data: 0.0001  max mem: 14938
[10:24:01.696455] Test:  [ 60/345]  eta: 0:00:53  loss: 0.8005 (0.7987)  time: 0.1849  data: 0.0001  max mem: 14938
[10:24:03.550238] Test:  [ 70/345]  eta: 0:00:51  loss: 0.8047 (0.7988)  time: 0.1852  data: 0.0001  max mem: 14938
[10:24:05.407840] Test:  [ 80/345]  eta: 0:00:49  loss: 0.8047 (0.7993)  time: 0.1855  data: 0.0001  max mem: 14938
[10:24:07.268979] Test:  [ 90/345]  eta: 0:00:47  loss: 0.8065 (0.7991)  time: 0.1859  data: 0.0001  max mem: 14938
[10:24:09.134069] Test:  [100/345]  eta: 0:00:45  loss: 0.7953 (0.7982)  time: 0.1863  data: 0.0001  max mem: 14938
[10:24:11.002442] Test:  [110/345]  eta: 0:00:43  loss: 0.7953 (0.7981)  time: 0.1866  data: 0.0001  max mem: 14938
[10:24:12.873320] Test:  [120/345]  eta: 0:00:41  loss: 0.7981 (0.7979)  time: 0.1869  data: 0.0001  max mem: 14938
[10:24:14.748422] Test:  [130/345]  eta: 0:00:40  loss: 0.7981 (0.7981)  time: 0.1872  data: 0.0001  max mem: 14938
[10:24:16.626972] Test:  [140/345]  eta: 0:00:38  loss: 0.7974 (0.7978)  time: 0.1876  data: 0.0001  max mem: 14938
[10:24:18.510040] Test:  [150/345]  eta: 0:00:36  loss: 0.7918 (0.7978)  time: 0.1880  data: 0.0001  max mem: 14938
[10:24:20.394387] Test:  [160/345]  eta: 0:00:34  loss: 0.7918 (0.7978)  time: 0.1883  data: 0.0001  max mem: 14938
[10:24:22.282950] Test:  [170/345]  eta: 0:00:32  loss: 0.7916 (0.7973)  time: 0.1886  data: 0.0001  max mem: 14938
[10:24:24.178832] Test:  [180/345]  eta: 0:00:30  loss: 0.7882 (0.7968)  time: 0.1892  data: 0.0001  max mem: 14938
[10:24:26.076449] Test:  [190/345]  eta: 0:00:29  loss: 0.7885 (0.7962)  time: 0.1896  data: 0.0001  max mem: 14938
[10:24:27.974854] Test:  [200/345]  eta: 0:00:27  loss: 0.7936 (0.7965)  time: 0.1898  data: 0.0001  max mem: 14938
[10:24:29.876571] Test:  [210/345]  eta: 0:00:25  loss: 0.7960 (0.7962)  time: 0.1900  data: 0.0001  max mem: 14938
[10:24:31.783964] Test:  [220/345]  eta: 0:00:23  loss: 0.7947 (0.7964)  time: 0.1904  data: 0.0001  max mem: 14938
[10:24:33.695020] Test:  [230/345]  eta: 0:00:21  loss: 0.7967 (0.7962)  time: 0.1909  data: 0.0001  max mem: 14938
[10:24:35.610749] Test:  [240/345]  eta: 0:00:19  loss: 0.7976 (0.7963)  time: 0.1913  data: 0.0001  max mem: 14938
[10:24:37.529193] Test:  [250/345]  eta: 0:00:17  loss: 0.8007 (0.7967)  time: 0.1917  data: 0.0001  max mem: 14938
[10:24:39.450339] Test:  [260/345]  eta: 0:00:15  loss: 0.7980 (0.7966)  time: 0.1919  data: 0.0001  max mem: 14938
[10:24:41.374586] Test:  [270/345]  eta: 0:00:14  loss: 0.7902 (0.7966)  time: 0.1922  data: 0.0001  max mem: 14938
[10:24:43.303764] Test:  [280/345]  eta: 0:00:12  loss: 0.8127 (0.7974)  time: 0.1926  data: 0.0001  max mem: 14938
[10:24:45.235622] Test:  [290/345]  eta: 0:00:10  loss: 0.8137 (0.7976)  time: 0.1930  data: 0.0001  max mem: 14938
[10:24:47.171427] Test:  [300/345]  eta: 0:00:08  loss: 0.7980 (0.7977)  time: 0.1933  data: 0.0001  max mem: 14938
[10:24:49.111635] Test:  [310/345]  eta: 0:00:06  loss: 0.7913 (0.7974)  time: 0.1937  data: 0.0001  max mem: 14938
[10:24:51.055474] Test:  [320/345]  eta: 0:00:04  loss: 0.7913 (0.7974)  time: 0.1942  data: 0.0001  max mem: 14938
[10:24:53.003632] Test:  [330/345]  eta: 0:00:02  loss: 0.7981 (0.7972)  time: 0.1945  data: 0.0001  max mem: 14938
[10:24:54.952954] Test:  [340/345]  eta: 0:00:00  loss: 0.7909 (0.7973)  time: 0.1948  data: 0.0001  max mem: 14938
[10:24:55.734156] Test:  [344/345]  eta: 0:00:00  loss: 0.7909 (0.7973)  time: 0.1949  data: 0.0001  max mem: 14938
[10:24:55.794593] Test: Total time: 0:01:05 (0.1898 s / it)
[10:25:06.124851] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8910 (0.8910)  time: 0.3223  data: 0.1432  max mem: 14938
[10:25:07.938910] Test:  [10/57]  eta: 0:00:09  loss: 0.8827 (0.8919)  time: 0.1941  data: 0.0131  max mem: 14938
[10:25:09.756339] Test:  [20/57]  eta: 0:00:06  loss: 0.8827 (0.8806)  time: 0.1815  data: 0.0001  max mem: 14938
[10:25:11.580459] Test:  [30/57]  eta: 0:00:05  loss: 0.7887 (0.8431)  time: 0.1820  data: 0.0001  max mem: 14938
[10:25:13.408045] Test:  [40/57]  eta: 0:00:03  loss: 0.7591 (0.8206)  time: 0.1825  data: 0.0001  max mem: 14938
[10:25:15.244623] Test:  [50/57]  eta: 0:00:01  loss: 0.7440 (0.8115)  time: 0.1832  data: 0.0001  max mem: 14938
[10:25:16.234122] Test:  [56/57]  eta: 0:00:00  loss: 0.7846 (0.8157)  time: 0.1779  data: 0.0001  max mem: 14938
[10:25:16.291933] Test: Total time: 0:00:10 (0.1840 s / it)
[10:25:18.074056] Dice score of the network on the train images: 0.738067, val images: 0.802198
[10:25:18.077878] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:25:18.960784] Epoch: [13]  [  0/345]  eta: 0:05:04  lr: 0.000081  loss: 0.8190 (0.8190)  time: 0.8821  data: 0.1401  max mem: 14938
[10:25:33.847854] Epoch: [13]  [ 20/345]  eta: 0:04:04  lr: 0.000082  loss: 0.8158 (0.8136)  time: 0.7443  data: 0.0001  max mem: 14938
[10:25:48.761153] Epoch: [13]  [ 40/345]  eta: 0:03:48  lr: 0.000082  loss: 0.8104 (0.8150)  time: 0.7456  data: 0.0001  max mem: 14938
[10:26:03.720535] Epoch: [13]  [ 60/345]  eta: 0:03:33  lr: 0.000082  loss: 0.8253 (0.8188)  time: 0.7479  data: 0.0001  max mem: 14938
[10:26:18.703451] Epoch: [13]  [ 80/345]  eta: 0:03:18  lr: 0.000083  loss: 0.8137 (0.8182)  time: 0.7491  data: 0.0001  max mem: 14938
[10:26:33.704454] Epoch: [13]  [100/345]  eta: 0:03:03  lr: 0.000083  loss: 0.8390 (0.8224)  time: 0.7500  data: 0.0001  max mem: 14938
[10:26:48.720169] Epoch: [13]  [120/345]  eta: 0:02:48  lr: 0.000083  loss: 0.8272 (0.8240)  time: 0.7507  data: 0.0001  max mem: 14938
[10:27:03.733762] Epoch: [13]  [140/345]  eta: 0:02:33  lr: 0.000084  loss: 0.8198 (0.8233)  time: 0.7506  data: 0.0001  max mem: 14938
[10:27:18.741437] Epoch: [13]  [160/345]  eta: 0:02:18  lr: 0.000084  loss: 0.8147 (0.8220)  time: 0.7503  data: 0.0001  max mem: 14938
[10:27:33.744634] Epoch: [13]  [180/345]  eta: 0:02:03  lr: 0.000085  loss: 0.7994 (0.8200)  time: 0.7501  data: 0.0001  max mem: 14938
[10:27:48.739792] Epoch: [13]  [200/345]  eta: 0:01:48  lr: 0.000085  loss: 0.8108 (0.8198)  time: 0.7497  data: 0.0001  max mem: 14938
[10:28:03.727742] Epoch: [13]  [220/345]  eta: 0:01:33  lr: 0.000085  loss: 0.8047 (0.8183)  time: 0.7493  data: 0.0001  max mem: 14938
[10:28:18.715254] Epoch: [13]  [240/345]  eta: 0:01:18  lr: 0.000086  loss: 0.8267 (0.8189)  time: 0.7493  data: 0.0001  max mem: 14938
[10:28:33.701029] Epoch: [13]  [260/345]  eta: 0:01:03  lr: 0.000086  loss: 0.8111 (0.8185)  time: 0.7492  data: 0.0001  max mem: 14938
[10:28:48.678106] Epoch: [13]  [280/345]  eta: 0:00:48  lr: 0.000086  loss: 0.7997 (0.8174)  time: 0.7488  data: 0.0001  max mem: 14938
[10:29:03.645909] Epoch: [13]  [300/345]  eta: 0:00:33  lr: 0.000087  loss: 0.8118 (0.8166)  time: 0.7483  data: 0.0001  max mem: 14938
[10:29:18.627742] Epoch: [13]  [320/345]  eta: 0:00:18  lr: 0.000087  loss: 0.8029 (0.8159)  time: 0.7490  data: 0.0001  max mem: 14938
[10:29:33.590869] Epoch: [13]  [340/345]  eta: 0:00:03  lr: 0.000087  loss: 0.8144 (0.8159)  time: 0.7481  data: 0.0001  max mem: 14938
[10:29:36.584174] Epoch: [13]  [344/345]  eta: 0:00:00  lr: 0.000087  loss: 0.8161 (0.8158)  time: 0.7479  data: 0.0001  max mem: 14938
[10:29:36.649706] Epoch: [13] Total time: 0:04:18 (0.7495 s / it)
[10:29:36.649928] Averaged stats: lr: 0.000087  loss: 0.8161 (0.8158)
[10:29:36.981148] Test:  [  0/345]  eta: 0:01:52  loss: 0.7864 (0.7864)  time: 0.3268  data: 0.1453  max mem: 14938
[10:29:38.815553] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7864 (0.7838)  time: 0.1964  data: 0.0133  max mem: 14938
[10:29:40.652293] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7842 (0.7837)  time: 0.1835  data: 0.0001  max mem: 14938
[10:29:42.492653] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7751 (0.7847)  time: 0.1838  data: 0.0001  max mem: 14938
[10:29:44.337192] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7750 (0.7827)  time: 0.1842  data: 0.0001  max mem: 14938
[10:29:46.185861] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7775 (0.7852)  time: 0.1846  data: 0.0001  max mem: 14938
[10:29:48.037968] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7790 (0.7842)  time: 0.1850  data: 0.0001  max mem: 14938
[10:29:49.890823] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7789 (0.7839)  time: 0.1852  data: 0.0001  max mem: 14938
[10:29:51.748629] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7878 (0.7858)  time: 0.1855  data: 0.0001  max mem: 14938
[10:29:53.609673] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7828 (0.7839)  time: 0.1859  data: 0.0001  max mem: 14938
[10:29:55.476450] Test:  [100/345]  eta: 0:00:45  loss: 0.7760 (0.7835)  time: 0.1863  data: 0.0001  max mem: 14938
[10:29:57.343859] Test:  [110/345]  eta: 0:00:43  loss: 0.7809 (0.7832)  time: 0.1867  data: 0.0001  max mem: 14938
[10:29:59.216020] Test:  [120/345]  eta: 0:00:41  loss: 0.7799 (0.7838)  time: 0.1869  data: 0.0001  max mem: 14938
[10:30:01.092258] Test:  [130/345]  eta: 0:00:40  loss: 0.7912 (0.7841)  time: 0.1874  data: 0.0001  max mem: 14938
[10:30:02.970363] Test:  [140/345]  eta: 0:00:38  loss: 0.7879 (0.7838)  time: 0.1877  data: 0.0001  max mem: 14938
[10:30:04.852729] Test:  [150/345]  eta: 0:00:36  loss: 0.7865 (0.7842)  time: 0.1880  data: 0.0001  max mem: 14938
[10:30:06.737753] Test:  [160/345]  eta: 0:00:34  loss: 0.7847 (0.7837)  time: 0.1883  data: 0.0001  max mem: 14938
[10:30:08.627683] Test:  [170/345]  eta: 0:00:32  loss: 0.7807 (0.7835)  time: 0.1887  data: 0.0001  max mem: 14938
[10:30:10.521890] Test:  [180/345]  eta: 0:00:30  loss: 0.7780 (0.7831)  time: 0.1892  data: 0.0001  max mem: 14938
[10:30:12.421088] Test:  [190/345]  eta: 0:00:29  loss: 0.7809 (0.7833)  time: 0.1896  data: 0.0001  max mem: 14938
[10:30:14.321236] Test:  [200/345]  eta: 0:00:27  loss: 0.7823 (0.7833)  time: 0.1899  data: 0.0001  max mem: 14938
[10:30:16.225200] Test:  [210/345]  eta: 0:00:25  loss: 0.7818 (0.7833)  time: 0.1902  data: 0.0001  max mem: 14938
[10:30:18.134325] Test:  [220/345]  eta: 0:00:23  loss: 0.7869 (0.7833)  time: 0.1906  data: 0.0001  max mem: 14938
[10:30:20.045508] Test:  [230/345]  eta: 0:00:21  loss: 0.7839 (0.7834)  time: 0.1910  data: 0.0001  max mem: 14938
[10:30:21.959629] Test:  [240/345]  eta: 0:00:19  loss: 0.7769 (0.7833)  time: 0.1912  data: 0.0001  max mem: 14938
[10:30:23.880133] Test:  [250/345]  eta: 0:00:17  loss: 0.7707 (0.7829)  time: 0.1917  data: 0.0001  max mem: 14938
[10:30:25.802540] Test:  [260/345]  eta: 0:00:16  loss: 0.7745 (0.7831)  time: 0.1921  data: 0.0001  max mem: 14938
[10:30:27.729567] Test:  [270/345]  eta: 0:00:14  loss: 0.7804 (0.7831)  time: 0.1924  data: 0.0001  max mem: 14938
[10:30:29.659050] Test:  [280/345]  eta: 0:00:12  loss: 0.7801 (0.7830)  time: 0.1928  data: 0.0001  max mem: 14938
[10:30:31.592588] Test:  [290/345]  eta: 0:00:10  loss: 0.7774 (0.7829)  time: 0.1931  data: 0.0001  max mem: 14938
[10:30:33.529481] Test:  [300/345]  eta: 0:00:08  loss: 0.7788 (0.7830)  time: 0.1935  data: 0.0001  max mem: 14938
[10:30:35.468557] Test:  [310/345]  eta: 0:00:06  loss: 0.7769 (0.7829)  time: 0.1937  data: 0.0001  max mem: 14938
[10:30:37.412588] Test:  [320/345]  eta: 0:00:04  loss: 0.7799 (0.7830)  time: 0.1941  data: 0.0001  max mem: 14938
[10:30:39.357448] Test:  [330/345]  eta: 0:00:02  loss: 0.7799 (0.7828)  time: 0.1944  data: 0.0001  max mem: 14938
[10:30:41.305852] Test:  [340/345]  eta: 0:00:00  loss: 0.7729 (0.7827)  time: 0.1946  data: 0.0001  max mem: 14938
[10:30:42.086851] Test:  [344/345]  eta: 0:00:00  loss: 0.7729 (0.7826)  time: 0.1948  data: 0.0001  max mem: 14938
[10:30:42.146491] Test: Total time: 0:01:05 (0.1898 s / it)
[10:30:52.477972] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8530 (0.8530)  time: 0.3168  data: 0.1373  max mem: 14938
[10:30:54.293194] Test:  [10/57]  eta: 0:00:09  loss: 0.8530 (0.8672)  time: 0.1937  data: 0.0125  max mem: 14938
[10:30:56.114279] Test:  [20/57]  eta: 0:00:06  loss: 0.8661 (0.8600)  time: 0.1817  data: 0.0001  max mem: 14938
[10:30:57.937248] Test:  [30/57]  eta: 0:00:05  loss: 0.7661 (0.8268)  time: 0.1821  data: 0.0001  max mem: 14938
[10:30:59.765412] Test:  [40/57]  eta: 0:00:03  loss: 0.7488 (0.8080)  time: 0.1825  data: 0.0001  max mem: 14938
[10:31:01.599260] Test:  [50/57]  eta: 0:00:01  loss: 0.7486 (0.8016)  time: 0.1830  data: 0.0001  max mem: 14938
[10:31:02.589315] Test:  [56/57]  eta: 0:00:00  loss: 0.7875 (0.8067)  time: 0.1777  data: 0.0001  max mem: 14938
[10:31:02.647182] Test: Total time: 0:00:10 (0.1840 s / it)
[10:31:04.394982] Dice score of the network on the train images: 0.744493, val images: 0.798563
[10:31:04.399510] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:31:05.284501] Epoch: [14]  [  0/345]  eta: 0:05:04  lr: 0.000087  loss: 0.8174 (0.8174)  time: 0.8839  data: 0.1423  max mem: 14938
[10:31:20.192087] Epoch: [14]  [ 20/345]  eta: 0:04:04  lr: 0.000088  loss: 0.7969 (0.8018)  time: 0.7453  data: 0.0001  max mem: 14938
[10:31:35.121583] Epoch: [14]  [ 40/345]  eta: 0:03:48  lr: 0.000088  loss: 0.7957 (0.8021)  time: 0.7464  data: 0.0001  max mem: 14938
[10:31:50.080449] Epoch: [14]  [ 60/345]  eta: 0:03:33  lr: 0.000089  loss: 0.8001 (0.8017)  time: 0.7479  data: 0.0001  max mem: 14938
[10:32:05.055969] Epoch: [14]  [ 80/345]  eta: 0:03:18  lr: 0.000089  loss: 0.7925 (0.7995)  time: 0.7487  data: 0.0001  max mem: 14938
[10:32:20.055428] Epoch: [14]  [100/345]  eta: 0:03:03  lr: 0.000089  loss: 0.7844 (0.7979)  time: 0.7499  data: 0.0001  max mem: 14938
[10:32:35.057060] Epoch: [14]  [120/345]  eta: 0:02:48  lr: 0.000090  loss: 0.7884 (0.7972)  time: 0.7500  data: 0.0001  max mem: 14938
[10:32:50.069056] Epoch: [14]  [140/345]  eta: 0:02:33  lr: 0.000090  loss: 0.8000 (0.7975)  time: 0.7506  data: 0.0001  max mem: 14938
[10:33:05.082045] Epoch: [14]  [160/345]  eta: 0:02:18  lr: 0.000090  loss: 0.7935 (0.7975)  time: 0.7506  data: 0.0001  max mem: 14938
[10:33:20.093226] Epoch: [14]  [180/345]  eta: 0:02:03  lr: 0.000091  loss: 0.8010 (0.7981)  time: 0.7505  data: 0.0001  max mem: 14938
[10:33:35.088998] Epoch: [14]  [200/345]  eta: 0:01:48  lr: 0.000091  loss: 0.8032 (0.7988)  time: 0.7497  data: 0.0001  max mem: 14938
[10:33:50.076755] Epoch: [14]  [220/345]  eta: 0:01:33  lr: 0.000091  loss: 0.8038 (0.7990)  time: 0.7493  data: 0.0001  max mem: 14938
[10:34:05.065867] Epoch: [14]  [240/345]  eta: 0:01:18  lr: 0.000092  loss: 0.8047 (0.7996)  time: 0.7494  data: 0.0001  max mem: 14938
[10:34:20.044967] Epoch: [14]  [260/345]  eta: 0:01:03  lr: 0.000092  loss: 0.8008 (0.7999)  time: 0.7489  data: 0.0001  max mem: 14938
[10:34:35.023665] Epoch: [14]  [280/345]  eta: 0:00:48  lr: 0.000093  loss: 0.7927 (0.7999)  time: 0.7489  data: 0.0001  max mem: 14938
[10:34:50.010463] Epoch: [14]  [300/345]  eta: 0:00:33  lr: 0.000093  loss: 0.8037 (0.8005)  time: 0.7493  data: 0.0001  max mem: 14938
[10:35:05.060175] Epoch: [14]  [320/345]  eta: 0:00:18  lr: 0.000093  loss: 0.8063 (0.8013)  time: 0.7524  data: 0.0001  max mem: 14938
[10:35:20.012778] Epoch: [14]  [340/345]  eta: 0:00:03  lr: 0.000094  loss: 0.8014 (0.8016)  time: 0.7476  data: 0.0001  max mem: 14938
[10:35:23.004803] Epoch: [14]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.8014 (0.8015)  time: 0.7477  data: 0.0001  max mem: 14938
[10:35:23.068452] Epoch: [14] Total time: 0:04:18 (0.7498 s / it)
[10:35:23.068873] Averaged stats: lr: 0.000094  loss: 0.8014 (0.8015)
[10:35:23.402157] Test:  [  0/345]  eta: 0:01:53  loss: 0.7661 (0.7661)  time: 0.3299  data: 0.1487  max mem: 14938
[10:35:25.237222] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7661 (0.7656)  time: 0.1967  data: 0.0136  max mem: 14938
[10:35:27.075293] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7713 (0.7693)  time: 0.1836  data: 0.0001  max mem: 14938
[10:35:28.917894] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7713 (0.7669)  time: 0.1840  data: 0.0001  max mem: 14938
[10:35:30.760958] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7595 (0.7665)  time: 0.1842  data: 0.0001  max mem: 14938
[10:35:32.609578] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7571 (0.7664)  time: 0.1845  data: 0.0001  max mem: 14938
[10:35:34.459639] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7572 (0.7674)  time: 0.1849  data: 0.0001  max mem: 14938
[10:35:36.312783] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7659 (0.7672)  time: 0.1851  data: 0.0001  max mem: 14938
[10:35:38.171228] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7671 (0.7682)  time: 0.1855  data: 0.0001  max mem: 14938
[10:35:40.034187] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7720 (0.7679)  time: 0.1860  data: 0.0001  max mem: 14938
[10:35:41.899653] Test:  [100/345]  eta: 0:00:45  loss: 0.7647 (0.7688)  time: 0.1864  data: 0.0001  max mem: 14938
[10:35:43.768048] Test:  [110/345]  eta: 0:00:43  loss: 0.7664 (0.7688)  time: 0.1866  data: 0.0001  max mem: 14938
[10:35:45.640579] Test:  [120/345]  eta: 0:00:41  loss: 0.7664 (0.7686)  time: 0.1870  data: 0.0001  max mem: 14938
[10:35:47.515600] Test:  [130/345]  eta: 0:00:40  loss: 0.7693 (0.7687)  time: 0.1873  data: 0.0001  max mem: 14938
[10:35:49.393476] Test:  [140/345]  eta: 0:00:38  loss: 0.7685 (0.7686)  time: 0.1876  data: 0.0001  max mem: 14938
[10:35:51.276657] Test:  [150/345]  eta: 0:00:36  loss: 0.7621 (0.7680)  time: 0.1880  data: 0.0001  max mem: 14938
[10:35:53.163260] Test:  [160/345]  eta: 0:00:34  loss: 0.7653 (0.7683)  time: 0.1884  data: 0.0001  max mem: 14938
[10:35:55.052012] Test:  [170/345]  eta: 0:00:32  loss: 0.7632 (0.7678)  time: 0.1887  data: 0.0001  max mem: 14938
[10:35:56.946636] Test:  [180/345]  eta: 0:00:30  loss: 0.7611 (0.7676)  time: 0.1891  data: 0.0001  max mem: 14938
[10:35:58.845310] Test:  [190/345]  eta: 0:00:29  loss: 0.7633 (0.7676)  time: 0.1896  data: 0.0001  max mem: 14938
[10:36:00.747706] Test:  [200/345]  eta: 0:00:27  loss: 0.7624 (0.7675)  time: 0.1900  data: 0.0001  max mem: 14938
[10:36:02.651474] Test:  [210/345]  eta: 0:00:25  loss: 0.7614 (0.7675)  time: 0.1903  data: 0.0001  max mem: 14938
[10:36:04.559440] Test:  [220/345]  eta: 0:00:23  loss: 0.7614 (0.7676)  time: 0.1905  data: 0.0001  max mem: 14938
[10:36:06.469715] Test:  [230/345]  eta: 0:00:21  loss: 0.7584 (0.7671)  time: 0.1908  data: 0.0001  max mem: 14938
[10:36:08.383254] Test:  [240/345]  eta: 0:00:19  loss: 0.7584 (0.7674)  time: 0.1911  data: 0.0001  max mem: 14938
[10:36:10.302385] Test:  [250/345]  eta: 0:00:17  loss: 0.7730 (0.7676)  time: 0.1916  data: 0.0001  max mem: 14938
[10:36:12.223573] Test:  [260/345]  eta: 0:00:16  loss: 0.7737 (0.7678)  time: 0.1920  data: 0.0001  max mem: 14938
[10:36:14.149085] Test:  [270/345]  eta: 0:00:14  loss: 0.7721 (0.7681)  time: 0.1923  data: 0.0001  max mem: 14938
[10:36:16.078098] Test:  [280/345]  eta: 0:00:12  loss: 0.7645 (0.7683)  time: 0.1927  data: 0.0001  max mem: 14938
[10:36:18.008992] Test:  [290/345]  eta: 0:00:10  loss: 0.7622 (0.7680)  time: 0.1929  data: 0.0001  max mem: 14938
[10:36:19.944392] Test:  [300/345]  eta: 0:00:08  loss: 0.7722 (0.7683)  time: 0.1933  data: 0.0001  max mem: 14938
[10:36:21.881612] Test:  [310/345]  eta: 0:00:06  loss: 0.7722 (0.7683)  time: 0.1936  data: 0.0001  max mem: 14938
[10:36:23.824307] Test:  [320/345]  eta: 0:00:04  loss: 0.7632 (0.7684)  time: 0.1939  data: 0.0001  max mem: 14938
[10:36:25.768372] Test:  [330/345]  eta: 0:00:02  loss: 0.7694 (0.7685)  time: 0.1943  data: 0.0001  max mem: 14938
[10:36:27.717297] Test:  [340/345]  eta: 0:00:00  loss: 0.7589 (0.7682)  time: 0.1946  data: 0.0001  max mem: 14938
[10:36:28.497807] Test:  [344/345]  eta: 0:00:00  loss: 0.7686 (0.7683)  time: 0.1947  data: 0.0001  max mem: 14938
[10:36:28.557325] Test: Total time: 0:01:05 (0.1898 s / it)
[10:36:38.885115] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8886 (0.8886)  time: 0.3173  data: 0.1374  max mem: 14938
[10:36:40.701072] Test:  [10/57]  eta: 0:00:09  loss: 0.8886 (0.8892)  time: 0.1939  data: 0.0125  max mem: 14938
[10:36:42.522349] Test:  [20/57]  eta: 0:00:06  loss: 0.8941 (0.8840)  time: 0.1818  data: 0.0001  max mem: 14938
[10:36:44.343888] Test:  [30/57]  eta: 0:00:05  loss: 0.7880 (0.8458)  time: 0.1821  data: 0.0001  max mem: 14938
[10:36:46.171246] Test:  [40/57]  eta: 0:00:03  loss: 0.7584 (0.8258)  time: 0.1824  data: 0.0001  max mem: 14938
[10:36:48.004391] Test:  [50/57]  eta: 0:00:01  loss: 0.7534 (0.8188)  time: 0.1830  data: 0.0001  max mem: 14938
[10:36:48.994220] Test:  [56/57]  eta: 0:00:00  loss: 0.7833 (0.8232)  time: 0.1777  data: 0.0001  max mem: 14938
[10:36:49.030143] Test: Total time: 0:00:10 (0.1836 s / it)
[10:36:50.796147] Dice score of the network on the train images: 0.772880, val images: 0.804561
[10:36:50.801276] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:36:51.681864] Epoch: [15]  [  0/345]  eta: 0:05:03  lr: 0.000094  loss: 0.7844 (0.7844)  time: 0.8795  data: 0.1388  max mem: 14938
[10:37:06.561186] Epoch: [15]  [ 20/345]  eta: 0:04:03  lr: 0.000094  loss: 0.7882 (0.7894)  time: 0.7439  data: 0.0001  max mem: 14938
[10:37:21.478251] Epoch: [15]  [ 40/345]  eta: 0:03:48  lr: 0.000094  loss: 0.7900 (0.7938)  time: 0.7458  data: 0.0001  max mem: 14938
[10:37:36.417189] Epoch: [15]  [ 60/345]  eta: 0:03:33  lr: 0.000095  loss: 0.7889 (0.7923)  time: 0.7469  data: 0.0001  max mem: 14938
[10:37:51.378872] Epoch: [15]  [ 80/345]  eta: 0:03:18  lr: 0.000095  loss: 0.7902 (0.7929)  time: 0.7480  data: 0.0001  max mem: 14938
[10:38:06.383432] Epoch: [15]  [100/345]  eta: 0:03:03  lr: 0.000096  loss: 0.7887 (0.7926)  time: 0.7502  data: 0.0001  max mem: 14938
[10:38:21.372104] Epoch: [15]  [120/345]  eta: 0:02:48  lr: 0.000096  loss: 0.8036 (0.7948)  time: 0.7494  data: 0.0001  max mem: 14938
[10:38:36.375834] Epoch: [15]  [140/345]  eta: 0:02:33  lr: 0.000096  loss: 0.7839 (0.7939)  time: 0.7501  data: 0.0001  max mem: 14938
[10:38:51.365909] Epoch: [15]  [160/345]  eta: 0:02:18  lr: 0.000097  loss: 0.7886 (0.7939)  time: 0.7495  data: 0.0001  max mem: 14938
[10:39:06.355608] Epoch: [15]  [180/345]  eta: 0:02:03  lr: 0.000097  loss: 0.8110 (0.7963)  time: 0.7494  data: 0.0001  max mem: 14938
[10:39:21.351416] Epoch: [15]  [200/345]  eta: 0:01:48  lr: 0.000097  loss: 0.7922 (0.7967)  time: 0.7497  data: 0.0001  max mem: 14938
[10:39:36.346037] Epoch: [15]  [220/345]  eta: 0:01:33  lr: 0.000098  loss: 0.7875 (0.7964)  time: 0.7497  data: 0.0001  max mem: 14938
[10:39:51.343913] Epoch: [15]  [240/345]  eta: 0:01:18  lr: 0.000098  loss: 0.7948 (0.7965)  time: 0.7498  data: 0.0001  max mem: 14938
[10:40:06.326981] Epoch: [15]  [260/345]  eta: 0:01:03  lr: 0.000098  loss: 0.7882 (0.7964)  time: 0.7491  data: 0.0001  max mem: 14938

[10:40:21.309083] Epoch: [15]  [280/345]  eta: 0:00:48  lr: 0.000099  loss: 0.7919 (0.7964)  time: 0.7491  data: 0.0001  max mem: 14938
[10:40:36.291046] Epoch: [15]  [300/345]  eta: 0:00:33  lr: 0.000099  loss: 0.7929 (0.7959)  time: 0.7490  data: 0.0001  max mem: 14938
[10:40:51.270355] Epoch: [15]  [320/345]  eta: 0:00:18  lr: 0.000100  loss: 0.7993 (0.7965)  time: 0.7489  data: 0.0001  max mem: 14938
[10:41:06.221325] Epoch: [15]  [340/345]  eta: 0:00:03  lr: 0.000100  loss: 0.8324 (0.7984)  time: 0.7475  data: 0.0001  max mem: 14938
[10:41:09.211531] Epoch: [15]  [344/345]  eta: 0:00:00  lr: 0.000100  loss: 0.8233 (0.7986)  time: 0.7475  data: 0.0001  max mem: 14938
[10:41:09.275532] Epoch: [15] Total time: 0:04:18 (0.7492 s / it)
[10:41:09.276057] Averaged stats: lr: 0.000100  loss: 0.8233 (0.7986)
[10:41:09.609112] Test:  [  0/345]  eta: 0:01:53  loss: 0.7807 (0.7807)  time: 0.3297  data: 0.1484  max mem: 14938
[10:41:11.444483] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7936 (0.7894)  time: 0.1967  data: 0.0136  max mem: 14938
[10:41:13.282393] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7795 (0.7806)  time: 0.1836  data: 0.0001  max mem: 14938
[10:41:15.125456] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7716 (0.7793)  time: 0.1840  data: 0.0001  max mem: 14938
[10:41:16.968372] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7752 (0.7786)  time: 0.1842  data: 0.0001  max mem: 14938
[10:41:18.817517] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7780 (0.7806)  time: 0.1845  data: 0.0001  max mem: 14938
[10:41:20.669698] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7878 (0.7805)  time: 0.1850  data: 0.0001  max mem: 14938
[10:41:22.526060] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7766 (0.7808)  time: 0.1854  data: 0.0001  max mem: 14938
[10:41:24.383516] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7694 (0.7794)  time: 0.1856  data: 0.0001  max mem: 14938
[10:41:26.245104] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7710 (0.7788)  time: 0.1859  data: 0.0001  max mem: 14938
[10:41:28.110967] Test:  [100/345]  eta: 0:00:45  loss: 0.7747 (0.7791)  time: 0.1863  data: 0.0001  max mem: 14938
[10:41:29.978818] Test:  [110/345]  eta: 0:00:43  loss: 0.7859 (0.7792)  time: 0.1866  data: 0.0001  max mem: 14938
[10:41:31.851814] Test:  [120/345]  eta: 0:00:41  loss: 0.7847 (0.7793)  time: 0.1870  data: 0.0001  max mem: 14938
[10:41:33.725733] Test:  [130/345]  eta: 0:00:40  loss: 0.7816 (0.7790)  time: 0.1873  data: 0.0001  max mem: 14938
[10:41:35.604838] Test:  [140/345]  eta: 0:00:38  loss: 0.7789 (0.7796)  time: 0.1876  data: 0.0001  max mem: 14938
[10:41:37.486283] Test:  [150/345]  eta: 0:00:36  loss: 0.7761 (0.7792)  time: 0.1880  data: 0.0001  max mem: 14938
[10:41:39.371766] Test:  [160/345]  eta: 0:00:34  loss: 0.7835 (0.7801)  time: 0.1883  data: 0.0001  max mem: 14938
[10:41:41.260719] Test:  [170/345]  eta: 0:00:32  loss: 0.7935 (0.7798)  time: 0.1887  data: 0.0001  max mem: 14938
[10:41:43.156308] Test:  [180/345]  eta: 0:00:30  loss: 0.7841 (0.7800)  time: 0.1892  data: 0.0001  max mem: 14938
[10:41:45.055463] Test:  [190/345]  eta: 0:00:29  loss: 0.7822 (0.7801)  time: 0.1897  data: 0.0001  max mem: 14938
[10:41:46.956772] Test:  [200/345]  eta: 0:00:27  loss: 0.7772 (0.7800)  time: 0.1900  data: 0.0001  max mem: 14938
[10:41:48.859258] Test:  [210/345]  eta: 0:00:25  loss: 0.7757 (0.7799)  time: 0.1901  data: 0.0001  max mem: 14938
[10:41:50.766044] Test:  [220/345]  eta: 0:00:23  loss: 0.7777 (0.7798)  time: 0.1904  data: 0.0001  max mem: 14938
[10:41:52.676180] Test:  [230/345]  eta: 0:00:21  loss: 0.7777 (0.7800)  time: 0.1908  data: 0.0001  max mem: 14938
[10:41:54.591228] Test:  [240/345]  eta: 0:00:19  loss: 0.7792 (0.7802)  time: 0.1912  data: 0.0001  max mem: 14938
[10:41:56.509517] Test:  [250/345]  eta: 0:00:17  loss: 0.7776 (0.7803)  time: 0.1916  data: 0.0001  max mem: 14938
[10:41:58.430616] Test:  [260/345]  eta: 0:00:16  loss: 0.7703 (0.7799)  time: 0.1919  data: 0.0001  max mem: 14938
[10:42:00.354556] Test:  [270/345]  eta: 0:00:14  loss: 0.7661 (0.7800)  time: 0.1922  data: 0.0001  max mem: 14938
[10:42:02.283565] Test:  [280/345]  eta: 0:00:12  loss: 0.7879 (0.7804)  time: 0.1926  data: 0.0001  max mem: 14938
[10:42:04.214727] Test:  [290/345]  eta: 0:00:10  loss: 0.7894 (0.7806)  time: 0.1930  data: 0.0001  max mem: 14938
[10:42:06.150215] Test:  [300/345]  eta: 0:00:08  loss: 0.7772 (0.7805)  time: 0.1933  data: 0.0001  max mem: 14938
[10:42:08.089415] Test:  [310/345]  eta: 0:00:06  loss: 0.7713 (0.7802)  time: 0.1937  data: 0.0001  max mem: 14938
[10:42:10.029187] Test:  [320/345]  eta: 0:00:04  loss: 0.7780 (0.7802)  time: 0.1939  data: 0.0001  max mem: 14938
[10:42:11.972839] Test:  [330/345]  eta: 0:00:02  loss: 0.7789 (0.7799)  time: 0.1941  data: 0.0001  max mem: 14938
[10:42:13.920917] Test:  [340/345]  eta: 0:00:00  loss: 0.7775 (0.7800)  time: 0.1945  data: 0.0001  max mem: 14938
[10:42:14.703303] Test:  [344/345]  eta: 0:00:00  loss: 0.7718 (0.7799)  time: 0.1948  data: 0.0001  max mem: 14938
[10:42:14.762043] Test: Total time: 0:01:05 (0.1898 s / it)
[10:42:25.173135] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8522 (0.8522)  time: 0.3178  data: 0.1386  max mem: 14938
[10:42:26.987674] Test:  [10/57]  eta: 0:00:09  loss: 0.8875 (0.8862)  time: 0.1938  data: 0.0127  max mem: 14938
[10:42:28.807900] Test:  [20/57]  eta: 0:00:06  loss: 0.8875 (0.8794)  time: 0.1817  data: 0.0001  max mem: 14938
[10:42:30.629411] Test:  [30/57]  eta: 0:00:05  loss: 0.7940 (0.8472)  time: 0.1820  data: 0.0001  max mem: 14938
[10:42:32.456529] Test:  [40/57]  eta: 0:00:03  loss: 0.7806 (0.8311)  time: 0.1824  data: 0.0001  max mem: 14938
[10:42:34.290375] Test:  [50/57]  eta: 0:00:01  loss: 0.7826 (0.8261)  time: 0.1830  data: 0.0001  max mem: 14938
[10:42:35.280519] Test:  [56/57]  eta: 0:00:00  loss: 0.8009 (0.8303)  time: 0.1777  data: 0.0001  max mem: 14938
[10:42:35.339018] Test: Total time: 0:00:10 (0.1839 s / it)
[10:42:37.168997] Dice score of the network on the train images: 0.773644, val images: 0.759041
[10:42:37.169222] saving best_prec_model_0 @ epoch 15
[10:42:38.250741] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:42:39.134353] Epoch: [16]  [  0/345]  eta: 0:05:04  lr: 0.000100  loss: 0.7853 (0.7853)  time: 0.8825  data: 0.1423  max mem: 14938
[10:42:54.022799] Epoch: [16]  [ 20/345]  eta: 0:04:04  lr: 0.000100  loss: 0.8029 (0.7999)  time: 0.7444  data: 0.0001  max mem: 14938
[10:43:08.955334] Epoch: [16]  [ 40/345]  eta: 0:03:48  lr: 0.000101  loss: 0.8080 (0.8018)  time: 0.7466  data: 0.0001  max mem: 14938
[10:43:23.906326] Epoch: [16]  [ 60/345]  eta: 0:03:33  lr: 0.000101  loss: 0.7931 (0.8001)  time: 0.7475  data: 0.0001  max mem: 14938
[10:43:38.902435] Epoch: [16]  [ 80/345]  eta: 0:03:18  lr: 0.000101  loss: 0.7930 (0.7978)  time: 0.7498  data: 0.0001  max mem: 14938
[10:43:53.903111] Epoch: [16]  [100/345]  eta: 0:03:03  lr: 0.000102  loss: 0.7822 (0.7952)  time: 0.7500  data: 0.0001  max mem: 14938
[10:44:08.913127] Epoch: [16]  [120/345]  eta: 0:02:48  lr: 0.000102  loss: 0.7844 (0.7939)  time: 0.7505  data: 0.0001  max mem: 14938
[10:44:23.933729] Epoch: [16]  [140/345]  eta: 0:02:33  lr: 0.000103  loss: 0.7845 (0.7930)  time: 0.7510  data: 0.0001  max mem: 14938
[10:44:39.052692] Epoch: [16]  [160/345]  eta: 0:02:18  lr: 0.000103  loss: 0.7931 (0.7934)  time: 0.7559  data: 0.0001  max mem: 14938
[10:44:54.034467] Epoch: [16]  [180/345]  eta: 0:02:03  lr: 0.000103  loss: 0.7854 (0.7925)  time: 0.7490  data: 0.0001  max mem: 14938
[10:45:09.048572] Epoch: [16]  [200/345]  eta: 0:01:48  lr: 0.000104  loss: 0.7889 (0.7920)  time: 0.7507  data: 0.0001  max mem: 14938
[10:45:24.053038] Epoch: [16]  [220/345]  eta: 0:01:33  lr: 0.000104  loss: 0.7919 (0.7921)  time: 0.7502  data: 0.0001  max mem: 14938
[10:45:39.055557] Epoch: [16]  [240/345]  eta: 0:01:18  lr: 0.000104  loss: 0.7953 (0.7925)  time: 0.7501  data: 0.0001  max mem: 14938
[10:45:54.053800] Epoch: [16]  [260/345]  eta: 0:01:03  lr: 0.000105  loss: 0.8033 (0.7933)  time: 0.7499  data: 0.0001  max mem: 14938
[10:46:09.049754] Epoch: [16]  [280/345]  eta: 0:00:48  lr: 0.000105  loss: 0.7979 (0.7935)  time: 0.7498  data: 0.0001  max mem: 14938
[10:46:24.039486] Epoch: [16]  [300/345]  eta: 0:00:33  lr: 0.000105  loss: 0.7845 (0.7932)  time: 0.7494  data: 0.0001  max mem: 14938
[10:46:39.013604] Epoch: [16]  [320/345]  eta: 0:00:18  lr: 0.000106  loss: 0.7786 (0.7925)  time: 0.7487  data: 0.0001  max mem: 14938
[10:46:53.984719] Epoch: [16]  [340/345]  eta: 0:00:03  lr: 0.000106  loss: 0.7819 (0.7922)  time: 0.7485  data: 0.0001  max mem: 14938
[10:46:56.979708] Epoch: [16]  [344/345]  eta: 0:00:00  lr: 0.000106  loss: 0.7819 (0.7920)  time: 0.7485  data: 0.0001  max mem: 14938
[10:46:57.045407] Epoch: [16] Total time: 0:04:18 (0.7501 s / it)
[10:46:57.045916] Averaged stats: lr: 0.000106  loss: 0.7819 (0.7920)
[10:46:57.379321] Test:  [  0/345]  eta: 0:01:53  loss: 0.7413 (0.7413)  time: 0.3294  data: 0.1483  max mem: 14938
[10:46:59.215102] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7518 (0.7570)  time: 0.1968  data: 0.0135  max mem: 14938
[10:47:01.054506] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7536 (0.7553)  time: 0.1837  data: 0.0001  max mem: 14938
[10:47:02.896498] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7529 (0.7560)  time: 0.1840  data: 0.0001  max mem: 14938
[10:47:04.741480] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7556 (0.7553)  time: 0.1843  data: 0.0001  max mem: 14938
[10:47:06.590481] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7558 (0.7556)  time: 0.1846  data: 0.0001  max mem: 14938
[10:47:08.444621] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7502 (0.7547)  time: 0.1851  data: 0.0001  max mem: 14938
[10:47:10.300191] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7457 (0.7544)  time: 0.1854  data: 0.0001  max mem: 14938
[10:47:12.158672] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7542 (0.7544)  time: 0.1856  data: 0.0001  max mem: 14938
[10:47:14.021700] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7495 (0.7538)  time: 0.1860  data: 0.0001  max mem: 14938
[10:47:15.887094] Test:  [100/345]  eta: 0:00:45  loss: 0.7492 (0.7535)  time: 0.1864  data: 0.0001  max mem: 14938
[10:47:17.755359] Test:  [110/345]  eta: 0:00:43  loss: 0.7499 (0.7532)  time: 0.1866  data: 0.0001  max mem: 14938
[10:47:19.627940] Test:  [120/345]  eta: 0:00:41  loss: 0.7488 (0.7526)  time: 0.1870  data: 0.0001  max mem: 14938
[10:47:21.504680] Test:  [130/345]  eta: 0:00:40  loss: 0.7422 (0.7520)  time: 0.1874  data: 0.0001  max mem: 14938
[10:47:23.384626] Test:  [140/345]  eta: 0:00:38  loss: 0.7518 (0.7523)  time: 0.1878  data: 0.0001  max mem: 14938
[10:47:25.268148] Test:  [150/345]  eta: 0:00:36  loss: 0.7612 (0.7533)  time: 0.1881  data: 0.0001  max mem: 14938
[10:47:27.153525] Test:  [160/345]  eta: 0:00:34  loss: 0.7595 (0.7537)  time: 0.1884  data: 0.0001  max mem: 14938
[10:47:29.044239] Test:  [170/345]  eta: 0:00:32  loss: 0.7483 (0.7533)  time: 0.1888  data: 0.0001  max mem: 14938
[10:47:30.940765] Test:  [180/345]  eta: 0:00:30  loss: 0.7473 (0.7530)  time: 0.1893  data: 0.0001  max mem: 14938
[10:47:32.839504] Test:  [190/345]  eta: 0:00:29  loss: 0.7473 (0.7525)  time: 0.1897  data: 0.0001  max mem: 14938
[10:47:34.741977] Test:  [200/345]  eta: 0:00:27  loss: 0.7438 (0.7523)  time: 0.1900  data: 0.0001  max mem: 14938
[10:47:36.646164] Test:  [210/345]  eta: 0:00:25  loss: 0.7538 (0.7526)  time: 0.1903  data: 0.0001  max mem: 14938
[10:47:38.555296] Test:  [220/345]  eta: 0:00:23  loss: 0.7564 (0.7527)  time: 0.1906  data: 0.0001  max mem: 14938
[10:47:40.466540] Test:  [230/345]  eta: 0:00:21  loss: 0.7536 (0.7529)  time: 0.1910  data: 0.0001  max mem: 14938
[10:47:42.380922] Test:  [240/345]  eta: 0:00:19  loss: 0.7437 (0.7527)  time: 0.1912  data: 0.0001  max mem: 14938
[10:47:44.300087] Test:  [250/345]  eta: 0:00:17  loss: 0.7556 (0.7531)  time: 0.1916  data: 0.0001  max mem: 14938
[10:47:46.221334] Test:  [260/345]  eta: 0:00:16  loss: 0.7546 (0.7529)  time: 0.1920  data: 0.0001  max mem: 14938
[10:47:48.147095] Test:  [270/345]  eta: 0:00:14  loss: 0.7418 (0.7526)  time: 0.1923  data: 0.0001  max mem: 14938
[10:47:50.076837] Test:  [280/345]  eta: 0:00:12  loss: 0.7418 (0.7523)  time: 0.1927  data: 0.0001  max mem: 14938
[10:47:52.008432] Test:  [290/345]  eta: 0:00:10  loss: 0.7534 (0.7526)  time: 0.1930  data: 0.0001  max mem: 14938
[10:47:53.943437] Test:  [300/345]  eta: 0:00:08  loss: 0.7534 (0.7526)  time: 0.1933  data: 0.0001  max mem: 14938
[10:47:55.883518] Test:  [310/345]  eta: 0:00:06  loss: 0.7508 (0.7526)  time: 0.1937  data: 0.0001  max mem: 14938
[10:47:57.825610] Test:  [320/345]  eta: 0:00:04  loss: 0.7501 (0.7527)  time: 0.1941  data: 0.0001  max mem: 14938
[10:47:59.771728] Test:  [330/345]  eta: 0:00:02  loss: 0.7538 (0.7528)  time: 0.1944  data: 0.0001  max mem: 14938
[10:48:01.721017] Test:  [340/345]  eta: 0:00:00  loss: 0.7562 (0.7528)  time: 0.1947  data: 0.0001  max mem: 14938
[10:48:02.502026] Test:  [344/345]  eta: 0:00:00  loss: 0.7562 (0.7529)  time: 0.1949  data: 0.0001  max mem: 14938
[10:48:02.561591] Test: Total time: 0:01:05 (0.1899 s / it)
[10:48:12.992108] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8424 (0.8424)  time: 0.3183  data: 0.1387  max mem: 14938
[10:48:14.807285] Test:  [10/57]  eta: 0:00:09  loss: 0.8807 (0.8769)  time: 0.1939  data: 0.0127  max mem: 14938
[10:48:16.627341] Test:  [20/57]  eta: 0:00:06  loss: 0.8807 (0.8642)  time: 0.1817  data: 0.0001  max mem: 14938
[10:48:18.452002] Test:  [30/57]  eta: 0:00:05  loss: 0.7741 (0.8301)  time: 0.1822  data: 0.0001  max mem: 14938
[10:48:20.281152] Test:  [40/57]  eta: 0:00:03  loss: 0.7581 (0.8114)  time: 0.1826  data: 0.0001  max mem: 14938
[10:48:22.115978] Test:  [50/57]  eta: 0:00:01  loss: 0.7511 (0.8040)  time: 0.1831  data: 0.0001  max mem: 14938
[10:48:23.106013] Test:  [56/57]  eta: 0:00:00  loss: 0.7690 (0.8087)  time: 0.1778  data: 0.0001  max mem: 14938
[10:48:23.164138] Test: Total time: 0:00:10 (0.1841 s / it)
[10:48:24.922885] Dice score of the network on the train images: 0.789371, val images: 0.815232
[10:48:24.923098] saving best_dice_model_0 @ epoch 16
[10:48:26.167918] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:48:27.049925] Epoch: [17]  [  0/345]  eta: 0:05:03  lr: 0.000106  loss: 0.7607 (0.7607)  time: 0.8807  data: 0.1379  max mem: 14938

[10:48:41.932312] Epoch: [17]  [ 20/345]  eta: 0:04:03  lr: 0.000107  loss: 0.7789 (0.7799)  time: 0.7441  data: 0.0001  max mem: 14938
[10:48:56.871759] Epoch: [17]  [ 40/345]  eta: 0:03:48  lr: 0.000107  loss: 0.7822 (0.7831)  time: 0.7469  data: 0.0001  max mem: 14938
[10:49:11.829012] Epoch: [17]  [ 60/345]  eta: 0:03:33  lr: 0.000107  loss: 0.7818 (0.7839)  time: 0.7478  data: 0.0001  max mem: 14938
[10:49:26.815617] Epoch: [17]  [ 80/345]  eta: 0:03:18  lr: 0.000108  loss: 0.7865 (0.7850)  time: 0.7493  data: 0.0001  max mem: 14938
[10:49:41.829939] Epoch: [17]  [100/345]  eta: 0:03:03  lr: 0.000108  loss: 0.7963 (0.7871)  time: 0.7507  data: 0.0001  max mem: 14938
[10:49:56.852421] Epoch: [17]  [120/345]  eta: 0:02:48  lr: 0.000108  loss: 0.7990 (0.7886)  time: 0.7511  data: 0.0001  max mem: 14938
[10:50:11.896722] Epoch: [17]  [140/345]  eta: 0:02:33  lr: 0.000109  loss: 0.7846 (0.7885)  time: 0.7522  data: 0.0001  max mem: 14938
[10:50:26.930386] Epoch: [17]  [160/345]  eta: 0:02:18  lr: 0.000109  loss: 0.7830 (0.7880)  time: 0.7516  data: 0.0001  max mem: 14938
[10:50:41.946021] Epoch: [17]  [180/345]  eta: 0:02:03  lr: 0.000110  loss: 0.7880 (0.7880)  time: 0.7507  data: 0.0001  max mem: 14938
[10:50:56.977444] Epoch: [17]  [200/345]  eta: 0:01:48  lr: 0.000110  loss: 0.7938 (0.7882)  time: 0.7515  data: 0.0001  max mem: 14938
[10:51:11.992670] Epoch: [17]  [220/345]  eta: 0:01:33  lr: 0.000110  loss: 0.7899 (0.7884)  time: 0.7507  data: 0.0001  max mem: 14938
[10:51:27.005029] Epoch: [17]  [240/345]  eta: 0:01:18  lr: 0.000111  loss: 0.7884 (0.7884)  time: 0.7506  data: 0.0001  max mem: 14938
[10:51:42.017024] Epoch: [17]  [260/345]  eta: 0:01:03  lr: 0.000111  loss: 0.7892 (0.7886)  time: 0.7506  data: 0.0001  max mem: 14938
[10:51:57.024406] Epoch: [17]  [280/345]  eta: 0:00:48  lr: 0.000111  loss: 0.7886 (0.7886)  time: 0.7503  data: 0.0001  max mem: 14938
[10:52:12.032012] Epoch: [17]  [300/345]  eta: 0:00:33  lr: 0.000112  loss: 0.8237 (0.7917)  time: 0.7503  data: 0.0001  max mem: 14938
[10:52:27.034398] Epoch: [17]  [320/345]  eta: 0:00:18  lr: 0.000112  loss: 0.8068 (0.7928)  time: 0.7501  data: 0.0001  max mem: 14938
[10:52:42.036516] Epoch: [17]  [340/345]  eta: 0:00:03  lr: 0.000112  loss: 0.7940 (0.7932)  time: 0.7501  data: 0.0001  max mem: 14938
[10:52:45.038530] Epoch: [17]  [344/345]  eta: 0:00:00  lr: 0.000112  loss: 0.8022 (0.7936)  time: 0.7500  data: 0.0001  max mem: 14938
[10:52:45.095684] Epoch: [17] Total time: 0:04:18 (0.7505 s / it)
[10:52:45.096155] Averaged stats: lr: 0.000112  loss: 0.8022 (0.7936)
[10:52:45.430159] Test:  [  0/345]  eta: 0:01:53  loss: 0.7980 (0.7980)  time: 0.3294  data: 0.1478  max mem: 14938
[10:52:47.266819] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7921 (0.7915)  time: 0.1968  data: 0.0135  max mem: 14938
[10:52:49.104534] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7792 (0.7820)  time: 0.1837  data: 0.0001  max mem: 14938
[10:52:50.947039] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7833 (0.7899)  time: 0.1840  data: 0.0001  max mem: 14938
[10:52:52.791338] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7949 (0.7892)  time: 0.1843  data: 0.0001  max mem: 14938
[10:52:54.641145] Test:  [ 50/345]  eta: 0:00:55  loss: 0.8004 (0.7919)  time: 0.1846  data: 0.0001  max mem: 14938
[10:52:56.495678] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7932 (0.7915)  time: 0.1852  data: 0.0001  max mem: 14938
[10:52:58.351742] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7862 (0.7909)  time: 0.1855  data: 0.0001  max mem: 14938
[10:53:00.211112] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7847 (0.7912)  time: 0.1857  data: 0.0001  max mem: 14938
[10:53:02.073044] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7942 (0.7918)  time: 0.1860  data: 0.0001  max mem: 14938
[10:53:03.939764] Test:  [100/345]  eta: 0:00:45  loss: 0.7934 (0.7909)  time: 0.1864  data: 0.0001  max mem: 14938
[10:53:05.808627] Test:  [110/345]  eta: 0:00:43  loss: 0.7803 (0.7907)  time: 0.1867  data: 0.0001  max mem: 14938
[10:53:07.682621] Test:  [120/345]  eta: 0:00:41  loss: 0.7881 (0.7915)  time: 0.1871  data: 0.0001  max mem: 14938
[10:53:09.560471] Test:  [130/345]  eta: 0:00:40  loss: 0.7964 (0.7924)  time: 0.1875  data: 0.0001  max mem: 14938
[10:53:11.441684] Test:  [140/345]  eta: 0:00:38  loss: 0.7969 (0.7922)  time: 0.1879  data: 0.0001  max mem: 14938
[10:53:13.325501] Test:  [150/345]  eta: 0:00:36  loss: 0.7949 (0.7920)  time: 0.1882  data: 0.0001  max mem: 14938
[10:53:15.210928] Test:  [160/345]  eta: 0:00:34  loss: 0.7979 (0.7924)  time: 0.1884  data: 0.0001  max mem: 14938
[10:53:17.101404] Test:  [170/345]  eta: 0:00:32  loss: 0.7961 (0.7927)  time: 0.1887  data: 0.0001  max mem: 14938
[10:53:18.999097] Test:  [180/345]  eta: 0:00:30  loss: 0.7957 (0.7932)  time: 0.1894  data: 0.0001  max mem: 14938
[10:53:20.897777] Test:  [190/345]  eta: 0:00:29  loss: 0.8005 (0.7937)  time: 0.1898  data: 0.0001  max mem: 14938
[10:53:22.799625] Test:  [200/345]  eta: 0:00:27  loss: 0.8005 (0.7934)  time: 0.1900  data: 0.0001  max mem: 14938
[10:53:24.704232] Test:  [210/345]  eta: 0:00:25  loss: 0.7919 (0.7937)  time: 0.1903  data: 0.0001  max mem: 14938
[10:53:26.612461] Test:  [220/345]  eta: 0:00:23  loss: 0.7919 (0.7935)  time: 0.1906  data: 0.0001  max mem: 14938
[10:53:28.524666] Test:  [230/345]  eta: 0:00:21  loss: 0.7884 (0.7934)  time: 0.1910  data: 0.0001  max mem: 14938
[10:53:30.439961] Test:  [240/345]  eta: 0:00:19  loss: 0.7885 (0.7937)  time: 0.1913  data: 0.0001  max mem: 14938
[10:53:32.360066] Test:  [250/345]  eta: 0:00:17  loss: 0.7958 (0.7941)  time: 0.1917  data: 0.0001  max mem: 14938
[10:53:34.283113] Test:  [260/345]  eta: 0:00:16  loss: 0.7888 (0.7939)  time: 0.1921  data: 0.0001  max mem: 14938
[10:53:36.208718] Test:  [270/345]  eta: 0:00:14  loss: 0.7888 (0.7941)  time: 0.1924  data: 0.0001  max mem: 14938
[10:53:38.141285] Test:  [280/345]  eta: 0:00:12  loss: 0.7884 (0.7938)  time: 0.1929  data: 0.0001  max mem: 14938
[10:53:40.075505] Test:  [290/345]  eta: 0:00:10  loss: 0.7783 (0.7933)  time: 0.1933  data: 0.0001  max mem: 14938
[10:53:42.013184] Test:  [300/345]  eta: 0:00:08  loss: 0.7867 (0.7935)  time: 0.1935  data: 0.0001  max mem: 14938
[10:53:43.954281] Test:  [310/345]  eta: 0:00:06  loss: 0.7987 (0.7937)  time: 0.1939  data: 0.0001  max mem: 14938
[10:53:45.896831] Test:  [320/345]  eta: 0:00:04  loss: 0.7842 (0.7932)  time: 0.1941  data: 0.0001  max mem: 14938
[10:53:47.844242] Test:  [330/345]  eta: 0:00:02  loss: 0.7808 (0.7930)  time: 0.1944  data: 0.0001  max mem: 14938
[10:53:49.793691] Test:  [340/345]  eta: 0:00:00  loss: 0.7835 (0.7928)  time: 0.1948  data: 0.0001  max mem: 14938
[10:53:50.576440] Test:  [344/345]  eta: 0:00:00  loss: 0.7835 (0.7926)  time: 0.1949  data: 0.0001  max mem: 14938
[10:53:50.635812] Test: Total time: 0:01:05 (0.1900 s / it)
[10:54:01.012012] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8908 (0.8908)  time: 0.3176  data: 0.1381  max mem: 14938
[10:54:02.827854] Test:  [10/57]  eta: 0:00:09  loss: 0.9263 (0.9260)  time: 0.1939  data: 0.0126  max mem: 14938
[10:54:04.647388] Test:  [20/57]  eta: 0:00:06  loss: 0.9305 (0.9210)  time: 0.1817  data: 0.0001  max mem: 14938
[10:54:06.472233] Test:  [30/57]  eta: 0:00:05  loss: 0.8390 (0.8778)  time: 0.1822  data: 0.0001  max mem: 14938
[10:54:08.301680] Test:  [40/57]  eta: 0:00:03  loss: 0.7734 (0.8516)  time: 0.1827  data: 0.0001  max mem: 14938
[10:54:10.135554] Test:  [50/57]  eta: 0:00:01  loss: 0.7858 (0.8477)  time: 0.1831  data: 0.0001  max mem: 14938
[10:54:11.125531] Test:  [56/57]  eta: 0:00:00  loss: 0.8257 (0.8535)  time: 0.1777  data: 0.0001  max mem: 14938
[10:54:11.185595] Test: Total time: 0:00:10 (0.1841 s / it)
[10:54:12.949687] Dice score of the network on the train images: 0.748813, val images: 0.768509
[10:54:12.953809] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[10:54:13.842511] Epoch: [18]  [  0/345]  eta: 0:05:06  lr: 0.000113  loss: 0.8346 (0.8346)  time: 0.8875  data: 0.1432  max mem: 14938
[10:54:28.741889] Epoch: [18]  [ 20/345]  eta: 0:04:04  lr: 0.000113  loss: 0.7960 (0.8030)  time: 0.7449  data: 0.0001  max mem: 14938
[10:54:43.675752] Epoch: [18]  [ 40/345]  eta: 0:03:48  lr: 0.000113  loss: 0.7909 (0.7996)  time: 0.7466  data: 0.0001  max mem: 14938
[10:54:58.646490] Epoch: [18]  [ 60/345]  eta: 0:03:33  lr: 0.000114  loss: 0.7812 (0.7942)  time: 0.7485  data: 0.0001  max mem: 14938
[10:55:13.649203] Epoch: [18]  [ 80/345]  eta: 0:03:18  lr: 0.000114  loss: 0.8377 (0.8058)  time: 0.7501  data: 0.0001  max mem: 14938
[10:55:28.649147] Epoch: [18]  [100/345]  eta: 0:03:03  lr: 0.000114  loss: 0.8107 (0.8071)  time: 0.7499  data: 0.0001  max mem: 14938
[10:55:43.663362] Epoch: [18]  [120/345]  eta: 0:02:48  lr: 0.000115  loss: 0.8058 (0.8069)  time: 0.7507  data: 0.0001  max mem: 14938
[10:55:58.681269] Epoch: [18]  [140/345]  eta: 0:02:33  lr: 0.000115  loss: 0.8076 (0.8066)  time: 0.7508  data: 0.0001  max mem: 14938
[10:56:13.688967] Epoch: [18]  [160/345]  eta: 0:02:18  lr: 0.000115  loss: 0.7828 (0.8044)  time: 0.7503  data: 0.0001  max mem: 14938
[10:56:28.689048] Epoch: [18]  [180/345]  eta: 0:02:03  lr: 0.000116  loss: 0.7877 (0.8026)  time: 0.7500  data: 0.0001  max mem: 14938
[10:56:43.681165] Epoch: [18]  [200/345]  eta: 0:01:48  lr: 0.000116  loss: 0.7778 (0.8006)  time: 0.7496  data: 0.0001  max mem: 14938
[10:56:58.677873] Epoch: [18]  [220/345]  eta: 0:01:33  lr: 0.000116  loss: 0.7810 (0.7991)  time: 0.7498  data: 0.0001  max mem: 14938
[10:57:13.664255] Epoch: [18]  [240/345]  eta: 0:01:18  lr: 0.000117  loss: 0.7824 (0.7979)  time: 0.7493  data: 0.0001  max mem: 14938
[10:57:28.648519] Epoch: [18]  [260/345]  eta: 0:01:03  lr: 0.000117  loss: 0.7822 (0.7967)  time: 0.7492  data: 0.0001  max mem: 14938
[10:57:43.619510] Epoch: [18]  [280/345]  eta: 0:00:48  lr: 0.000118  loss: 0.7776 (0.7959)  time: 0.7485  data: 0.0001  max mem: 14938
[10:57:58.595694] Epoch: [18]  [300/345]  eta: 0:00:33  lr: 0.000118  loss: 0.7815 (0.7948)  time: 0.7488  data: 0.0001  max mem: 14938
[10:58:13.568099] Epoch: [18]  [320/345]  eta: 0:00:18  lr: 0.000118  loss: 0.7749 (0.7940)  time: 0.7486  data: 0.0001  max mem: 14938
[10:58:28.538911] Epoch: [18]  [340/345]  eta: 0:00:03  lr: 0.000119  loss: 0.7813 (0.7936)  time: 0.7485  data: 0.0001  max mem: 14938
[10:58:31.531648] Epoch: [18]  [344/345]  eta: 0:00:00  lr: 0.000119  loss: 0.7813 (0.7935)  time: 0.7485  data: 0.0001  max mem: 14938
[10:58:31.573946] Epoch: [18] Total time: 0:04:18 (0.7496 s / it)
[10:58:31.574277] Averaged stats: lr: 0.000119  loss: 0.7813 (0.7935)
[10:58:31.911156] Test:  [  0/345]  eta: 0:01:54  loss: 0.7407 (0.7407)  time: 0.3328  data: 0.1518  max mem: 14938
[10:58:33.746673] Test:  [ 10/345]  eta: 0:01:06  loss: 0.7387 (0.7417)  time: 0.1970  data: 0.0139  max mem: 14938
[10:58:35.584591] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7468 (0.7504)  time: 0.1836  data: 0.0001  max mem: 14938
[10:58:37.425873] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7523 (0.7506)  time: 0.1839  data: 0.0001  max mem: 14938
[10:58:39.271671] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7497 (0.7492)  time: 0.1843  data: 0.0001  max mem: 14938
[10:58:41.119147] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7497 (0.7498)  time: 0.1846  data: 0.0001  max mem: 14938
[10:58:42.972076] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7495 (0.7498)  time: 0.1850  data: 0.0001  max mem: 14938
[10:58:44.826382] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7418 (0.7479)  time: 0.1853  data: 0.0001  max mem: 14938
[10:58:46.682899] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7489 (0.7488)  time: 0.1855  data: 0.0001  max mem: 14938
[10:58:48.545404] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7490 (0.7488)  time: 0.1859  data: 0.0001  max mem: 14938
[10:58:50.411802] Test:  [100/345]  eta: 0:00:45  loss: 0.7419 (0.7480)  time: 0.1864  data: 0.0001  max mem: 14938
[10:58:52.280768] Test:  [110/345]  eta: 0:00:43  loss: 0.7406 (0.7486)  time: 0.1867  data: 0.0001  max mem: 14938
[10:58:54.153389] Test:  [120/345]  eta: 0:00:41  loss: 0.7479 (0.7486)  time: 0.1870  data: 0.0001  max mem: 14938
[10:58:56.029724] Test:  [130/345]  eta: 0:00:40  loss: 0.7466 (0.7487)  time: 0.1874  data: 0.0001  max mem: 14938
[10:58:57.909460] Test:  [140/345]  eta: 0:00:38  loss: 0.7458 (0.7484)  time: 0.1877  data: 0.0001  max mem: 14938
[10:58:59.792646] Test:  [150/345]  eta: 0:00:36  loss: 0.7431 (0.7483)  time: 0.1881  data: 0.0001  max mem: 14938
[10:59:01.678360] Test:  [160/345]  eta: 0:00:34  loss: 0.7558 (0.7493)  time: 0.1884  data: 0.0001  max mem: 14938
[10:59:03.568634] Test:  [170/345]  eta: 0:00:32  loss: 0.7612 (0.7496)  time: 0.1887  data: 0.0001  max mem: 14938
[10:59:05.464477] Test:  [180/345]  eta: 0:00:30  loss: 0.7489 (0.7499)  time: 0.1893  data: 0.0001  max mem: 14938
[10:59:07.361014] Test:  [190/345]  eta: 0:00:29  loss: 0.7480 (0.7501)  time: 0.1896  data: 0.0001  max mem: 14938
[10:59:09.261319] Test:  [200/345]  eta: 0:00:27  loss: 0.7539 (0.7503)  time: 0.1898  data: 0.0001  max mem: 14938
[10:59:11.166109] Test:  [210/345]  eta: 0:00:25  loss: 0.7455 (0.7498)  time: 0.1902  data: 0.0001  max mem: 14938
[10:59:13.072855] Test:  [220/345]  eta: 0:00:23  loss: 0.7408 (0.7495)  time: 0.1905  data: 0.0001  max mem: 14938
[10:59:14.984332] Test:  [230/345]  eta: 0:00:21  loss: 0.7464 (0.7494)  time: 0.1909  data: 0.0001  max mem: 14938
[10:59:16.898425] Test:  [240/345]  eta: 0:00:19  loss: 0.7495 (0.7494)  time: 0.1912  data: 0.0001  max mem: 14938
[10:59:18.818880] Test:  [250/345]  eta: 0:00:17  loss: 0.7492 (0.7493)  time: 0.1917  data: 0.0001  max mem: 14938
[10:59:20.741608] Test:  [260/345]  eta: 0:00:16  loss: 0.7524 (0.7500)  time: 0.1921  data: 0.0001  max mem: 14938
[10:59:22.668350] Test:  [270/345]  eta: 0:00:14  loss: 0.7514 (0.7499)  time: 0.1924  data: 0.0001  max mem: 14938
[10:59:24.597178] Test:  [280/345]  eta: 0:00:12  loss: 0.7440 (0.7498)  time: 0.1927  data: 0.0001  max mem: 14938
[10:59:26.530831] Test:  [290/345]  eta: 0:00:10  loss: 0.7467 (0.7499)  time: 0.1931  data: 0.0001  max mem: 14938
[10:59:28.467006] Test:  [300/345]  eta: 0:00:08  loss: 0.7470 (0.7498)  time: 0.1934  data: 0.0001  max mem: 14938
[10:59:30.406902] Test:  [310/345]  eta: 0:00:06  loss: 0.7439 (0.7495)  time: 0.1938  data: 0.0001  max mem: 14938
[10:59:32.349455] Test:  [320/345]  eta: 0:00:04  loss: 0.7463 (0.7495)  time: 0.1941  data: 0.0001  max mem: 14938
[10:59:34.292741] Test:  [330/345]  eta: 0:00:02  loss: 0.7476 (0.7495)  time: 0.1942  data: 0.0001  max mem: 14938
[10:59:36.241995] Test:  [340/345]  eta: 0:00:00  loss: 0.7437 (0.7493)  time: 0.1946  data: 0.0001  max mem: 14938
[10:59:37.022966] Test:  [344/345]  eta: 0:00:00  loss: 0.7437 (0.7493)  time: 0.1948  data: 0.0001  max mem: 14938
[10:59:37.083177] Test: Total time: 0:01:05 (0.1899 s / it)
[10:59:47.447180] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8321 (0.8321)  time: 0.3158  data: 0.1367  max mem: 14938
[10:59:49.260775] Test:  [10/57]  eta: 0:00:09  loss: 0.8611 (0.8805)  time: 0.1935  data: 0.0125  max mem: 14938
[10:59:51.081707] Test:  [20/57]  eta: 0:00:06  loss: 0.8698 (0.8712)  time: 0.1817  data: 0.0001  max mem: 14938
[10:59:52.906220] Test:  [30/57]  eta: 0:00:05  loss: 0.7764 (0.8314)  time: 0.1822  data: 0.0001  max mem: 14938
[10:59:54.733217] Test:  [40/57]  eta: 0:00:03  loss: 0.7507 (0.8105)  time: 0.1825  data: 0.0001  max mem: 14938
[10:59:56.567744] Test:  [50/57]  eta: 0:00:01  loss: 0.7474 (0.8051)  time: 0.1830  data: 0.0001  max mem: 14938
[10:59:57.558186] Test:  [56/57]  eta: 0:00:00  loss: 0.7759 (0.8105)  time: 0.1778  data: 0.0001  max mem: 14938
[10:59:57.615160] Test: Total time: 0:00:10 (0.1839 s / it)
[10:59:59.410098] Dice score of the network on the train images: 0.790042, val images: 0.811360
[10:59:59.414501] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:00:00.292981] Epoch: [19]  [  0/345]  eta: 0:05:02  lr: 0.000119  loss: 0.7778 (0.7778)  time: 0.8775  data: 0.1384  max mem: 14938
[11:00:15.173443] Epoch: [19]  [ 20/345]  eta: 0:04:03  lr: 0.000119  loss: 0.7622 (0.7713)  time: 0.7440  data: 0.0001  max mem: 14938
[11:00:30.097617] Epoch: [19]  [ 40/345]  eta: 0:03:48  lr: 0.000119  loss: 0.7742 (0.7741)  time: 0.7462  data: 0.0001  max mem: 14938
[11:00:45.049711] Epoch: [19]  [ 60/345]  eta: 0:03:33  lr: 0.000120  loss: 0.7742 (0.7746)  time: 0.7476  data: 0.0001  max mem: 14938
[11:01:00.032304] Epoch: [19]  [ 80/345]  eta: 0:03:18  lr: 0.000120  loss: 0.7702 (0.7737)  time: 0.7491  data: 0.0001  max mem: 14938
[11:01:15.031172] Epoch: [19]  [100/345]  eta: 0:03:03  lr: 0.000121  loss: 0.7697 (0.7736)  time: 0.7499  data: 0.0001  max mem: 14938
[11:01:30.048397] Epoch: [19]  [120/345]  eta: 0:02:48  lr: 0.000121  loss: 0.7655 (0.7728)  time: 0.7508  data: 0.0001  max mem: 14938
[11:01:45.066601] Epoch: [19]  [140/345]  eta: 0:02:33  lr: 0.000121  loss: 0.7758 (0.7727)  time: 0.7509  data: 0.0001  max mem: 14938
[11:02:00.083753] Epoch: [19]  [160/345]  eta: 0:02:18  lr: 0.000122  loss: 0.7737 (0.7730)  time: 0.7508  data: 0.0001  max mem: 14938
[11:02:15.094783] Epoch: [19]  [180/345]  eta: 0:02:03  lr: 0.000122  loss: 0.7875 (0.7748)  time: 0.7505  data: 0.0001  max mem: 14938
[11:02:30.106337] Epoch: [19]  [200/345]  eta: 0:01:48  lr: 0.000122  loss: 0.7782 (0.7756)  time: 0.7505  data: 0.0001  max mem: 14938
[11:02:45.106255] Epoch: [19]  [220/345]  eta: 0:01:33  lr: 0.000123  loss: 0.7715 (0.7752)  time: 0.7499  data: 0.0001  max mem: 14938
[11:03:00.089529] Epoch: [19]  [240/345]  eta: 0:01:18  lr: 0.000123  loss: 0.7791 (0.7757)  time: 0.7491  data: 0.0001  max mem: 14938
[11:03:15.077762] Epoch: [19]  [260/345]  eta: 0:01:03  lr: 0.000123  loss: 0.7672 (0.7755)  time: 0.7494  data: 0.0001  max mem: 14938
[11:03:30.060801] Epoch: [19]  [280/345]  eta: 0:00:48  lr: 0.000124  loss: 0.7706 (0.7751)  time: 0.7491  data: 0.0001  max mem: 14938
[11:03:45.040529] Epoch: [19]  [300/345]  eta: 0:00:33  lr: 0.000124  loss: 0.7756 (0.7755)  time: 0.7489  data: 0.0001  max mem: 14938
[11:04:00.030142] Epoch: [19]  [320/345]  eta: 0:00:18  lr: 0.000125  loss: 0.7721 (0.7757)  time: 0.7494  data: 0.0001  max mem: 14938

[11:04:15.023782] Epoch: [19]  [340/345]  eta: 0:00:03  lr: 0.000125  loss: 0.7960 (0.7768)  time: 0.7496  data: 0.0001  max mem: 14938
[11:04:18.022133] Epoch: [19]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.8015 (0.7772)  time: 0.7496  data: 0.0001  max mem: 14938
[11:04:18.080288] Epoch: [19] Total time: 0:04:18 (0.7498 s / it)
[11:04:18.080698] Averaged stats: lr: 0.000125  loss: 0.8015 (0.7772)
[11:04:18.409755] Test:  [  0/345]  eta: 0:01:51  loss: 0.7823 (0.7823)  time: 0.3229  data: 0.1412  max mem: 14938
[11:04:20.244931] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7866 (0.7826)  time: 0.1961  data: 0.0129  max mem: 14938
[11:04:22.081637] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7861 (0.7832)  time: 0.1835  data: 0.0001  max mem: 14938
[11:04:23.922176] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7742 (0.7797)  time: 0.1838  data: 0.0001  max mem: 14938
[11:04:25.767169] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7759 (0.7812)  time: 0.1842  data: 0.0001  max mem: 14938
[11:04:27.616063] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7719 (0.7791)  time: 0.1846  data: 0.0001  max mem: 14938
[11:04:29.468386] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7729 (0.7790)  time: 0.1850  data: 0.0001  max mem: 14938
[11:04:31.322177] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7776 (0.7777)  time: 0.1853  data: 0.0001  max mem: 14938
[11:04:33.180448] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7736 (0.7781)  time: 0.1855  data: 0.0001  max mem: 14938
[11:04:35.042027] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7799 (0.7780)  time: 0.1859  data: 0.0001  max mem: 14938
[11:04:36.907510] Test:  [100/345]  eta: 0:00:45  loss: 0.7785 (0.7777)  time: 0.1863  data: 0.0001  max mem: 14938
[11:04:38.775987] Test:  [110/345]  eta: 0:00:43  loss: 0.7713 (0.7769)  time: 0.1866  data: 0.0001  max mem: 14938
[11:04:40.647695] Test:  [120/345]  eta: 0:00:41  loss: 0.7692 (0.7767)  time: 0.1870  data: 0.0001  max mem: 14938
[11:04:42.524075] Test:  [130/345]  eta: 0:00:40  loss: 0.7723 (0.7762)  time: 0.1874  data: 0.0001  max mem: 14938
[11:04:44.403968] Test:  [140/345]  eta: 0:00:38  loss: 0.7864 (0.7770)  time: 0.1878  data: 0.0001  max mem: 14938
[11:04:46.285948] Test:  [150/345]  eta: 0:00:36  loss: 0.7858 (0.7772)  time: 0.1880  data: 0.0001  max mem: 14938
[11:04:48.172017] Test:  [160/345]  eta: 0:00:34  loss: 0.7851 (0.7776)  time: 0.1883  data: 0.0001  max mem: 14938
[11:04:50.061374] Test:  [170/345]  eta: 0:00:32  loss: 0.7771 (0.7776)  time: 0.1887  data: 0.0001  max mem: 14938
[11:04:51.954953] Test:  [180/345]  eta: 0:00:30  loss: 0.7721 (0.7773)  time: 0.1891  data: 0.0001  max mem: 14938
[11:04:53.854569] Test:  [190/345]  eta: 0:00:29  loss: 0.7742 (0.7772)  time: 0.1896  data: 0.0001  max mem: 14938
[11:04:55.756485] Test:  [200/345]  eta: 0:00:27  loss: 0.7824 (0.7777)  time: 0.1900  data: 0.0001  max mem: 14938
[11:04:57.659764] Test:  [210/345]  eta: 0:00:25  loss: 0.7703 (0.7773)  time: 0.1902  data: 0.0001  max mem: 14938
[11:04:59.567688] Test:  [220/345]  eta: 0:00:23  loss: 0.7836 (0.7778)  time: 0.1905  data: 0.0001  max mem: 14938
[11:05:01.479569] Test:  [230/345]  eta: 0:00:21  loss: 0.7885 (0.7779)  time: 0.1909  data: 0.0001  max mem: 14938
[11:05:03.394790] Test:  [240/345]  eta: 0:00:19  loss: 0.7784 (0.7781)  time: 0.1913  data: 0.0001  max mem: 14938
[11:05:05.313008] Test:  [250/345]  eta: 0:00:17  loss: 0.7795 (0.7783)  time: 0.1916  data: 0.0001  max mem: 14938
[11:05:07.234950] Test:  [260/345]  eta: 0:00:16  loss: 0.7783 (0.7781)  time: 0.1920  data: 0.0001  max mem: 14938
[11:05:09.160480] Test:  [270/345]  eta: 0:00:14  loss: 0.7766 (0.7783)  time: 0.1923  data: 0.0001  max mem: 14938
[11:05:11.088681] Test:  [280/345]  eta: 0:00:12  loss: 0.7892 (0.7791)  time: 0.1926  data: 0.0001  max mem: 14938
[11:05:13.022592] Test:  [290/345]  eta: 0:00:10  loss: 0.7862 (0.7791)  time: 0.1931  data: 0.0001  max mem: 14938
[11:05:14.958537] Test:  [300/345]  eta: 0:00:08  loss: 0.7778 (0.7794)  time: 0.1934  data: 0.0001  max mem: 14938
[11:05:16.896354] Test:  [310/345]  eta: 0:00:06  loss: 0.7786 (0.7794)  time: 0.1936  data: 0.0001  max mem: 14938
[11:05:18.838392] Test:  [320/345]  eta: 0:00:04  loss: 0.7714 (0.7792)  time: 0.1939  data: 0.0001  max mem: 14938
[11:05:20.784097] Test:  [330/345]  eta: 0:00:02  loss: 0.7623 (0.7788)  time: 0.1943  data: 0.0001  max mem: 14938
[11:05:22.733080] Test:  [340/345]  eta: 0:00:00  loss: 0.7777 (0.7789)  time: 0.1947  data: 0.0001  max mem: 14938
[11:05:23.513798] Test:  [344/345]  eta: 0:00:00  loss: 0.7800 (0.7789)  time: 0.1948  data: 0.0001  max mem: 14938
[11:05:23.573592] Test: Total time: 0:01:05 (0.1898 s / it)
[11:05:34.062348] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8920 (0.8920)  time: 0.3205  data: 0.1405  max mem: 14938
[11:05:35.878427] Test:  [10/57]  eta: 0:00:09  loss: 0.9087 (0.9085)  time: 0.1942  data: 0.0128  max mem: 14938
[11:05:37.699924] Test:  [20/57]  eta: 0:00:06  loss: 0.9174 (0.8938)  time: 0.1818  data: 0.0001  max mem: 14938
[11:05:39.523686] Test:  [30/57]  eta: 0:00:05  loss: 0.7805 (0.8537)  time: 0.1822  data: 0.0001  max mem: 14938
[11:05:41.352450] Test:  [40/57]  eta: 0:00:03  loss: 0.7652 (0.8323)  time: 0.1826  data: 0.0001  max mem: 14938
[11:05:43.186370] Test:  [50/57]  eta: 0:00:01  loss: 0.7682 (0.8251)  time: 0.1831  data: 0.0001  max mem: 14938
[11:05:44.176941] Test:  [56/57]  eta: 0:00:00  loss: 0.8040 (0.8303)  time: 0.1778  data: 0.0001  max mem: 14938
[11:05:44.232904] Test: Total time: 0:00:10 (0.1841 s / it)
[11:05:45.991184] Dice score of the network on the train images: 0.770645, val images: 0.777013
[11:05:45.995328] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:05:46.879886] Epoch: [20]  [  0/345]  eta: 0:05:04  lr: 0.000125  loss: 0.7844 (0.7844)  time: 0.8836  data: 0.1418  max mem: 14938
[11:06:01.781540] Epoch: [20]  [ 20/345]  eta: 0:04:04  lr: 0.000125  loss: 0.7768 (0.7803)  time: 0.7450  data: 0.0001  max mem: 14938
[11:06:16.719536] Epoch: [20]  [ 40/345]  eta: 0:03:48  lr: 0.000125  loss: 0.7767 (0.7814)  time: 0.7468  data: 0.0001  max mem: 14938
[11:06:31.670143] Epoch: [20]  [ 60/345]  eta: 0:03:33  lr: 0.000125  loss: 0.7702 (0.7789)  time: 0.7475  data: 0.0001  max mem: 14938
[11:06:46.651308] Epoch: [20]  [ 80/345]  eta: 0:03:18  lr: 0.000125  loss: 0.7889 (0.7816)  time: 0.7490  data: 0.0001  max mem: 14938
[11:07:01.655911] Epoch: [20]  [100/345]  eta: 0:03:03  lr: 0.000125  loss: 0.7745 (0.7809)  time: 0.7502  data: 0.0001  max mem: 14938
[11:07:16.678620] Epoch: [20]  [120/345]  eta: 0:02:48  lr: 0.000125  loss: 0.7747 (0.7802)  time: 0.7511  data: 0.0001  max mem: 14938
[11:07:31.688936] Epoch: [20]  [140/345]  eta: 0:02:33  lr: 0.000125  loss: 0.7730 (0.7800)  time: 0.7505  data: 0.0001  max mem: 14938
[11:07:46.680739] Epoch: [20]  [160/345]  eta: 0:02:18  lr: 0.000125  loss: 0.7726 (0.7793)  time: 0.7495  data: 0.0001  max mem: 14938
[11:08:01.652360] Epoch: [20]  [180/345]  eta: 0:02:03  lr: 0.000125  loss: 0.7684 (0.7786)  time: 0.7485  data: 0.0001  max mem: 14938
[11:08:16.619093] Epoch: [20]  [200/345]  eta: 0:01:48  lr: 0.000125  loss: 0.7694 (0.7776)  time: 0.7483  data: 0.0001  max mem: 14938
[11:08:31.586168] Epoch: [20]  [220/345]  eta: 0:01:33  lr: 0.000125  loss: 0.7740 (0.7773)  time: 0.7483  data: 0.0001  max mem: 14938
[11:08:46.543796] Epoch: [20]  [240/345]  eta: 0:01:18  lr: 0.000125  loss: 0.7738 (0.7771)  time: 0.7478  data: 0.0001  max mem: 14938
[11:09:01.497065] Epoch: [20]  [260/345]  eta: 0:01:03  lr: 0.000125  loss: 0.7694 (0.7765)  time: 0.7476  data: 0.0001  max mem: 14938
[11:09:16.440467] Epoch: [20]  [280/345]  eta: 0:00:48  lr: 0.000125  loss: 0.7635 (0.7755)  time: 0.7471  data: 0.0001  max mem: 14938

[11:09:31.390897] Epoch: [20]  [300/345]  eta: 0:00:33  lr: 0.000125  loss: 0.7674 (0.7751)  time: 0.7475  data: 0.0001  max mem: 14938
[11:09:46.339353] Epoch: [20]  [320/345]  eta: 0:00:18  lr: 0.000125  loss: 0.7638 (0.7745)  time: 0.7474  data: 0.0001  max mem: 14938
[11:10:01.290793] Epoch: [20]  [340/345]  eta: 0:00:03  lr: 0.000125  loss: 0.7717 (0.7743)  time: 0.7475  data: 0.0001  max mem: 14938
[11:10:04.282018] Epoch: [20]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.7712 (0.7743)  time: 0.7475  data: 0.0001  max mem: 14938
[11:10:04.346185] Epoch: [20] Total time: 0:04:18 (0.7488 s / it)
[11:10:04.346646] Averaged stats: lr: 0.000125  loss: 0.7712 (0.7743)
[11:10:04.681960] Test:  [  0/345]  eta: 0:01:54  loss: 0.7444 (0.7444)  time: 0.3311  data: 0.1497  max mem: 14938
[11:10:06.516385] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7351 (0.7342)  time: 0.1968  data: 0.0137  max mem: 14938
[11:10:08.353953] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7297 (0.7300)  time: 0.1835  data: 0.0001  max mem: 14938
[11:10:10.196196] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7295 (0.7326)  time: 0.1839  data: 0.0001  max mem: 14938
[11:10:12.039918] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7292 (0.7323)  time: 0.1842  data: 0.0001  max mem: 14938
[11:10:13.889279] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7299 (0.7325)  time: 0.1846  data: 0.0001  max mem: 14938
[11:10:15.739886] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7340 (0.7344)  time: 0.1849  data: 0.0001  max mem: 14938
[11:10:17.594925] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7344 (0.7342)  time: 0.1852  data: 0.0001  max mem: 14938
[11:10:19.452739] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7311 (0.7334)  time: 0.1856  data: 0.0001  max mem: 14938
[11:10:21.315285] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7282 (0.7341)  time: 0.1860  data: 0.0001  max mem: 14938
[11:10:23.182109] Test:  [100/345]  eta: 0:00:45  loss: 0.7282 (0.7340)  time: 0.1864  data: 0.0001  max mem: 14938
[11:10:25.050319] Test:  [110/345]  eta: 0:00:43  loss: 0.7295 (0.7339)  time: 0.1867  data: 0.0001  max mem: 14938
[11:10:26.924614] Test:  [120/345]  eta: 0:00:41  loss: 0.7309 (0.7339)  time: 0.1871  data: 0.0001  max mem: 14938
[11:10:28.801905] Test:  [130/345]  eta: 0:00:40  loss: 0.7311 (0.7339)  time: 0.1875  data: 0.0001  max mem: 14938
[11:10:30.680507] Test:  [140/345]  eta: 0:00:38  loss: 0.7317 (0.7341)  time: 0.1877  data: 0.0001  max mem: 14938
[11:10:32.564988] Test:  [150/345]  eta: 0:00:36  loss: 0.7397 (0.7346)  time: 0.1881  data: 0.0001  max mem: 14938
[11:10:34.452004] Test:  [160/345]  eta: 0:00:34  loss: 0.7363 (0.7343)  time: 0.1885  data: 0.0001  max mem: 14938
[11:10:36.342079] Test:  [170/345]  eta: 0:00:32  loss: 0.7266 (0.7338)  time: 0.1888  data: 0.0001  max mem: 14938
[11:10:38.238023] Test:  [180/345]  eta: 0:00:30  loss: 0.7276 (0.7336)  time: 0.1893  data: 0.0001  max mem: 14938
[11:10:40.134770] Test:  [190/345]  eta: 0:00:29  loss: 0.7276 (0.7334)  time: 0.1896  data: 0.0001  max mem: 14938
[11:10:42.035009] Test:  [200/345]  eta: 0:00:27  loss: 0.7285 (0.7332)  time: 0.1898  data: 0.0001  max mem: 14938
[11:10:43.937625] Test:  [210/345]  eta: 0:00:25  loss: 0.7324 (0.7338)  time: 0.1901  data: 0.0001  max mem: 14938
[11:10:45.846592] Test:  [220/345]  eta: 0:00:23  loss: 0.7322 (0.7336)  time: 0.1905  data: 0.0001  max mem: 14938
[11:10:47.757173] Test:  [230/345]  eta: 0:00:21  loss: 0.7310 (0.7337)  time: 0.1909  data: 0.0001  max mem: 14938
[11:10:49.671706] Test:  [240/345]  eta: 0:00:19  loss: 0.7345 (0.7339)  time: 0.1912  data: 0.0001  max mem: 14938
[11:10:51.589811] Test:  [250/345]  eta: 0:00:17  loss: 0.7291 (0.7341)  time: 0.1916  data: 0.0001  max mem: 14938
[11:10:53.512078] Test:  [260/345]  eta: 0:00:16  loss: 0.7304 (0.7340)  time: 0.1920  data: 0.0001  max mem: 14938
[11:10:55.438200] Test:  [270/345]  eta: 0:00:14  loss: 0.7329 (0.7343)  time: 0.1924  data: 0.0001  max mem: 14938
[11:10:57.366789] Test:  [280/345]  eta: 0:00:12  loss: 0.7382 (0.7346)  time: 0.1927  data: 0.0001  max mem: 14938
[11:10:59.299259] Test:  [290/345]  eta: 0:00:10  loss: 0.7371 (0.7348)  time: 0.1930  data: 0.0001  max mem: 14938
[11:11:01.236187] Test:  [300/345]  eta: 0:00:08  loss: 0.7318 (0.7346)  time: 0.1934  data: 0.0001  max mem: 14938
[11:11:03.174606] Test:  [310/345]  eta: 0:00:06  loss: 0.7254 (0.7345)  time: 0.1937  data: 0.0001  max mem: 14938
[11:11:05.117705] Test:  [320/345]  eta: 0:00:04  loss: 0.7365 (0.7347)  time: 0.1940  data: 0.0001  max mem: 14938
[11:11:07.063021] Test:  [330/345]  eta: 0:00:02  loss: 0.7393 (0.7348)  time: 0.1944  data: 0.0001  max mem: 14938
[11:11:09.009865] Test:  [340/345]  eta: 0:00:00  loss: 0.7386 (0.7351)  time: 0.1946  data: 0.0001  max mem: 14938
[11:11:09.791058] Test:  [344/345]  eta: 0:00:00  loss: 0.7386 (0.7352)  time: 0.1947  data: 0.0001  max mem: 14938
[11:11:09.850724] Test: Total time: 0:01:05 (0.1899 s / it)
[11:11:20.285665] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8329 (0.8329)  time: 0.3161  data: 0.1360  max mem: 14938
[11:11:22.100988] Test:  [10/57]  eta: 0:00:09  loss: 0.8658 (0.8751)  time: 0.1937  data: 0.0124  max mem: 14938
[11:11:23.920849] Test:  [20/57]  eta: 0:00:06  loss: 0.8888 (0.8646)  time: 0.1817  data: 0.0001  max mem: 14938
[11:11:25.744882] Test:  [30/57]  eta: 0:00:05  loss: 0.7670 (0.8278)  time: 0.1821  data: 0.0001  max mem: 14938
[11:11:27.572114] Test:  [40/57]  eta: 0:00:03  loss: 0.7432 (0.8078)  time: 0.1825  data: 0.0001  max mem: 14938
[11:11:29.406553] Test:  [50/57]  eta: 0:00:01  loss: 0.7352 (0.7999)  time: 0.1830  data: 0.0001  max mem: 14938
[11:11:30.394840] Test:  [56/57]  eta: 0:00:00  loss: 0.7642 (0.8052)  time: 0.1776  data: 0.0001  max mem: 14938
[11:11:30.452656] Test: Total time: 0:00:10 (0.1839 s / it)
[11:11:32.236521] Dice score of the network on the train images: 0.785793, val images: 0.817993
[11:11:32.236755] saving best_dice_model_0 @ epoch 20
[11:11:33.307412] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:11:34.190196] Epoch: [21]  [  0/345]  eta: 0:05:04  lr: 0.000125  loss: 0.7701 (0.7701)  time: 0.8816  data: 0.1420  max mem: 14938
[11:11:49.048641] Epoch: [21]  [ 20/345]  eta: 0:04:03  lr: 0.000125  loss: 0.7591 (0.7589)  time: 0.7429  data: 0.0001  max mem: 14938
[11:12:03.970198] Epoch: [21]  [ 40/345]  eta: 0:03:48  lr: 0.000125  loss: 0.7679 (0.7653)  time: 0.7460  data: 0.0001  max mem: 14938
[11:12:18.908518] Epoch: [21]  [ 60/345]  eta: 0:03:33  lr: 0.000125  loss: 0.7831 (0.7719)  time: 0.7469  data: 0.0001  max mem: 14938
[11:12:33.870395] Epoch: [21]  [ 80/345]  eta: 0:03:18  lr: 0.000124  loss: 0.7915 (0.7769)  time: 0.7480  data: 0.0001  max mem: 14938
[11:12:48.860650] Epoch: [21]  [100/345]  eta: 0:03:03  lr: 0.000124  loss: 0.7891 (0.7792)  time: 0.7495  data: 0.0001  max mem: 14938
[11:13:03.863853] Epoch: [21]  [120/345]  eta: 0:02:48  lr: 0.000124  loss: 0.7728 (0.7779)  time: 0.7501  data: 0.0001  max mem: 14938
[11:13:18.869468] Epoch: [21]  [140/345]  eta: 0:02:33  lr: 0.000124  loss: 0.7643 (0.7762)  time: 0.7502  data: 0.0001  max mem: 14938
[11:13:33.855739] Epoch: [21]  [160/345]  eta: 0:02:18  lr: 0.000124  loss: 0.7685 (0.7755)  time: 0.7493  data: 0.0001  max mem: 14938
[11:13:48.833325] Epoch: [21]  [180/345]  eta: 0:02:03  lr: 0.000124  loss: 0.7821 (0.7763)  time: 0.7488  data: 0.0001  max mem: 14938
[11:14:03.803735] Epoch: [21]  [200/345]  eta: 0:01:48  lr: 0.000124  loss: 0.7739 (0.7764)  time: 0.7485  data: 0.0001  max mem: 14938
[11:14:18.772692] Epoch: [21]  [220/345]  eta: 0:01:33  lr: 0.000124  loss: 0.7759 (0.7766)  time: 0.7484  data: 0.0001  max mem: 14938

[11:14:33.731714] Epoch: [21]  [240/345]  eta: 0:01:18  lr: 0.000124  loss: 0.7794 (0.7771)  time: 0.7479  data: 0.0001  max mem: 14938
[11:14:48.692913] Epoch: [21]  [260/345]  eta: 0:01:03  lr: 0.000124  loss: 0.7714 (0.7771)  time: 0.7480  data: 0.0001  max mem: 14938
[11:15:03.661026] Epoch: [21]  [280/345]  eta: 0:00:48  lr: 0.000124  loss: 0.7653 (0.7767)  time: 0.7484  data: 0.0001  max mem: 14938
[11:15:18.637816] Epoch: [21]  [300/345]  eta: 0:00:33  lr: 0.000124  loss: 0.7757 (0.7765)  time: 0.7488  data: 0.0001  max mem: 14938
[11:15:33.614155] Epoch: [21]  [320/345]  eta: 0:00:18  lr: 0.000124  loss: 0.7634 (0.7760)  time: 0.7488  data: 0.0001  max mem: 14938
[11:15:48.580543] Epoch: [21]  [340/345]  eta: 0:00:03  lr: 0.000124  loss: 0.7731 (0.7758)  time: 0.7483  data: 0.0001  max mem: 14938
[11:15:51.574036] Epoch: [21]  [344/345]  eta: 0:00:00  lr: 0.000124  loss: 0.7735 (0.7758)  time: 0.7484  data: 0.0001  max mem: 14938
[11:15:51.639085] Epoch: [21] Total time: 0:04:18 (0.7488 s / it)
[11:15:51.639404] Averaged stats: lr: 0.000124  loss: 0.7735 (0.7758)
[11:15:51.975127] Test:  [  0/345]  eta: 0:01:54  loss: 0.7158 (0.7158)  time: 0.3314  data: 0.1501  max mem: 14938
[11:15:53.809514] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7323 (0.7366)  time: 0.1968  data: 0.0137  max mem: 14938
[11:15:55.646664] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7343 (0.7366)  time: 0.1835  data: 0.0001  max mem: 14938
[11:15:57.487369] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7351 (0.7385)  time: 0.1838  data: 0.0001  max mem: 14938
[11:15:59.331197] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7438 (0.7396)  time: 0.1842  data: 0.0001  max mem: 14938
[11:16:01.181482] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7376 (0.7400)  time: 0.1847  data: 0.0001  max mem: 14938
[11:16:03.034946] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7366 (0.7392)  time: 0.1851  data: 0.0001  max mem: 14938
[11:16:04.888572] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7344 (0.7387)  time: 0.1853  data: 0.0001  max mem: 14938
[11:16:06.747035] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7395 (0.7391)  time: 0.1856  data: 0.0001  max mem: 14938
[11:16:08.608794] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7400 (0.7390)  time: 0.1860  data: 0.0001  max mem: 14938
[11:16:10.475459] Test:  [100/345]  eta: 0:00:45  loss: 0.7373 (0.7386)  time: 0.1864  data: 0.0001  max mem: 14938
[11:16:12.343412] Test:  [110/345]  eta: 0:00:43  loss: 0.7384 (0.7395)  time: 0.1867  data: 0.0001  max mem: 14938
[11:16:14.217087] Test:  [120/345]  eta: 0:00:41  loss: 0.7446 (0.7400)  time: 0.1870  data: 0.0001  max mem: 14938
[11:16:16.094864] Test:  [130/345]  eta: 0:00:40  loss: 0.7392 (0.7400)  time: 0.1875  data: 0.0001  max mem: 14938
[11:16:17.975478] Test:  [140/345]  eta: 0:00:38  loss: 0.7400 (0.7401)  time: 0.1879  data: 0.0001  max mem: 14938
[11:16:19.858311] Test:  [150/345]  eta: 0:00:36  loss: 0.7418 (0.7404)  time: 0.1881  data: 0.0001  max mem: 14938
[11:16:21.743618] Test:  [160/345]  eta: 0:00:34  loss: 0.7396 (0.7404)  time: 0.1884  data: 0.0001  max mem: 14938
[11:16:23.633179] Test:  [170/345]  eta: 0:00:32  loss: 0.7359 (0.7401)  time: 0.1887  data: 0.0001  max mem: 14938
[11:16:25.529546] Test:  [180/345]  eta: 0:00:30  loss: 0.7261 (0.7395)  time: 0.1892  data: 0.0001  max mem: 14938
[11:16:27.430344] Test:  [190/345]  eta: 0:00:29  loss: 0.7296 (0.7393)  time: 0.1898  data: 0.0001  max mem: 14938
[11:16:29.331544] Test:  [200/345]  eta: 0:00:27  loss: 0.7358 (0.7394)  time: 0.1901  data: 0.0001  max mem: 14938
[11:16:31.234155] Test:  [210/345]  eta: 0:00:25  loss: 0.7387 (0.7394)  time: 0.1901  data: 0.0001  max mem: 14938
[11:16:33.142114] Test:  [220/345]  eta: 0:00:23  loss: 0.7346 (0.7391)  time: 0.1904  data: 0.0001  max mem: 14938
[11:16:35.055185] Test:  [230/345]  eta: 0:00:21  loss: 0.7346 (0.7391)  time: 0.1910  data: 0.0001  max mem: 14938
[11:16:36.970939] Test:  [240/345]  eta: 0:00:19  loss: 0.7370 (0.7390)  time: 0.1914  data: 0.0001  max mem: 14938
[11:16:38.889536] Test:  [250/345]  eta: 0:00:17  loss: 0.7392 (0.7391)  time: 0.1917  data: 0.0001  max mem: 14938
[11:16:40.812065] Test:  [260/345]  eta: 0:00:16  loss: 0.7377 (0.7390)  time: 0.1920  data: 0.0001  max mem: 14938
[11:16:42.737731] Test:  [270/345]  eta: 0:00:14  loss: 0.7377 (0.7395)  time: 0.1924  data: 0.0001  max mem: 14938
[11:16:44.666720] Test:  [280/345]  eta: 0:00:12  loss: 0.7435 (0.7396)  time: 0.1927  data: 0.0001  max mem: 14938
[11:16:46.597889] Test:  [290/345]  eta: 0:00:10  loss: 0.7397 (0.7393)  time: 0.1930  data: 0.0001  max mem: 14938
[11:16:48.533145] Test:  [300/345]  eta: 0:00:08  loss: 0.7351 (0.7392)  time: 0.1933  data: 0.0001  max mem: 14938
[11:16:50.471110] Test:  [310/345]  eta: 0:00:06  loss: 0.7403 (0.7396)  time: 0.1936  data: 0.0001  max mem: 14938
[11:16:52.414149] Test:  [320/345]  eta: 0:00:04  loss: 0.7363 (0.7394)  time: 0.1940  data: 0.0001  max mem: 14938
[11:16:54.358944] Test:  [330/345]  eta: 0:00:02  loss: 0.7295 (0.7393)  time: 0.1943  data: 0.0001  max mem: 14938
[11:16:56.306950] Test:  [340/345]  eta: 0:00:00  loss: 0.7313 (0.7391)  time: 0.1946  data: 0.0001  max mem: 14938
[11:16:57.087986] Test:  [344/345]  eta: 0:00:00  loss: 0.7343 (0.7393)  time: 0.1948  data: 0.0001  max mem: 14938
[11:16:57.148039] Test: Total time: 0:01:05 (0.1899 s / it)
[11:17:07.526448] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8133 (0.8133)  time: 0.3165  data: 0.1371  max mem: 14938
[11:17:09.341466] Test:  [10/57]  eta: 0:00:09  loss: 0.8820 (0.8736)  time: 0.1937  data: 0.0125  max mem: 14938
[11:17:11.161376] Test:  [20/57]  eta: 0:00:06  loss: 0.8837 (0.8691)  time: 0.1817  data: 0.0001  max mem: 14938
[11:17:12.986057] Test:  [30/57]  eta: 0:00:05  loss: 0.7736 (0.8331)  time: 0.1822  data: 0.0001  max mem: 14938
[11:17:14.814953] Test:  [40/57]  eta: 0:00:03  loss: 0.7586 (0.8137)  time: 0.1826  data: 0.0001  max mem: 14938
[11:17:16.648584] Test:  [50/57]  eta: 0:00:01  loss: 0.7437 (0.8065)  time: 0.1831  data: 0.0001  max mem: 14938
[11:17:17.637182] Test:  [56/57]  eta: 0:00:00  loss: 0.7708 (0.8128)  time: 0.1777  data: 0.0001  max mem: 14938
[11:17:17.696788] Test: Total time: 0:00:10 (0.1840 s / it)
[11:17:19.489445] Dice score of the network on the train images: 0.797883, val images: 0.815726
[11:17:19.489680] saving best_prec_model_0 @ epoch 21
[11:17:20.597194] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:17:21.478309] Epoch: [22]  [  0/345]  eta: 0:05:03  lr: 0.000124  loss: 0.7551 (0.7551)  time: 0.8798  data: 0.1392  max mem: 14938
[11:17:36.357768] Epoch: [22]  [ 20/345]  eta: 0:04:03  lr: 0.000124  loss: 0.7625 (0.7650)  time: 0.7439  data: 0.0001  max mem: 14938
[11:17:51.414339] Epoch: [22]  [ 40/345]  eta: 0:03:49  lr: 0.000123  loss: 0.7615 (0.7629)  time: 0.7528  data: 0.0001  max mem: 14938
[11:18:06.368987] Epoch: [22]  [ 60/345]  eta: 0:03:33  lr: 0.000123  loss: 0.7647 (0.7633)  time: 0.7477  data: 0.0001  max mem: 14938
[11:18:21.350700] Epoch: [22]  [ 80/345]  eta: 0:03:18  lr: 0.000123  loss: 0.7618 (0.7636)  time: 0.7490  data: 0.0001  max mem: 14938
[11:18:36.362055] Epoch: [22]  [100/345]  eta: 0:03:03  lr: 0.000123  loss: 0.7640 (0.7641)  time: 0.7505  data: 0.0001  max mem: 14938
[11:18:51.382597] Epoch: [22]  [120/345]  eta: 0:02:48  lr: 0.000123  loss: 0.7575 (0.7626)  time: 0.7510  data: 0.0001  max mem: 14938
[11:19:06.400562] Epoch: [22]  [140/345]  eta: 0:02:33  lr: 0.000123  loss: 0.7677 (0.7640)  time: 0.7509  data: 0.0001  max mem: 14938
[11:19:21.417801] Epoch: [22]  [160/345]  eta: 0:02:18  lr: 0.000123  loss: 0.7666 (0.7645)  time: 0.7508  data: 0.0001  max mem: 14938
[11:19:36.425798] Epoch: [22]  [180/345]  eta: 0:02:03  lr: 0.000123  loss: 0.7601 (0.7642)  time: 0.7503  data: 0.0001  max mem: 14938
[11:19:51.423644] Epoch: [22]  [200/345]  eta: 0:01:48  lr: 0.000123  loss: 0.7713 (0.7650)  time: 0.7498  data: 0.0001  max mem: 14938
[11:20:06.420889] Epoch: [22]  [220/345]  eta: 0:01:33  lr: 0.000123  loss: 0.7631 (0.7645)  time: 0.7498  data: 0.0001  max mem: 14938
[11:20:21.409335] Epoch: [22]  [240/345]  eta: 0:01:18  lr: 0.000123  loss: 0.7719 (0.7649)  time: 0.7494  data: 0.0001  max mem: 14938
[11:20:36.396233] Epoch: [22]  [260/345]  eta: 0:01:03  lr: 0.000122  loss: 0.7660 (0.7653)  time: 0.7493  data: 0.0001  max mem: 14938
[11:20:51.462981] Epoch: [22]  [280/345]  eta: 0:00:48  lr: 0.000122  loss: 0.7562 (0.7647)  time: 0.7533  data: 0.0001  max mem: 14938
[11:21:06.444787] Epoch: [22]  [300/345]  eta: 0:00:33  lr: 0.000122  loss: 0.7610 (0.7646)  time: 0.7490  data: 0.0001  max mem: 14938
[11:21:21.410979] Epoch: [22]  [320/345]  eta: 0:00:18  lr: 0.000122  loss: 0.7624 (0.7646)  time: 0.7483  data: 0.0001  max mem: 14938
[11:21:36.384254] Epoch: [22]  [340/345]  eta: 0:00:03  lr: 0.000122  loss: 0.7560 (0.7642)  time: 0.7486  data: 0.0001  max mem: 14938
[11:21:39.378772] Epoch: [22]  [344/345]  eta: 0:00:00  lr: 0.000122  loss: 0.7558 (0.7640)  time: 0.7487  data: 0.0001  max mem: 14938
[11:21:39.439267] Epoch: [22] Total time: 0:04:18 (0.7503 s / it)
[11:21:39.439573] Averaged stats: lr: 0.000122  loss: 0.7558 (0.7640)
[11:21:39.776198] Test:  [  0/345]  eta: 0:01:54  loss: 0.7262 (0.7262)  time: 0.3324  data: 0.1512  max mem: 14938
[11:21:41.611553] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7277 (0.7262)  time: 0.1970  data: 0.0138  max mem: 14938
[11:21:43.449784] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7282 (0.7257)  time: 0.1836  data: 0.0001  max mem: 14938
[11:21:45.290864] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7299 (0.7273)  time: 0.1839  data: 0.0001  max mem: 14938
[11:21:47.134737] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7299 (0.7284)  time: 0.1842  data: 0.0001  max mem: 14938
[11:21:48.983932] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7281 (0.7282)  time: 0.1846  data: 0.0001  max mem: 14938
[11:21:50.836979] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7294 (0.7286)  time: 0.1851  data: 0.0001  max mem: 14938
[11:21:52.691863] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7298 (0.7289)  time: 0.1853  data: 0.0001  max mem: 14938
[11:21:54.550185] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7312 (0.7292)  time: 0.1856  data: 0.0001  max mem: 14938
[11:21:56.414590] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7312 (0.7292)  time: 0.1861  data: 0.0001  max mem: 14938
[11:21:58.281642] Test:  [100/345]  eta: 0:00:45  loss: 0.7312 (0.7298)  time: 0.1865  data: 0.0001  max mem: 14938
[11:22:00.150528] Test:  [110/345]  eta: 0:00:43  loss: 0.7343 (0.7299)  time: 0.1867  data: 0.0001  max mem: 14938
[11:22:02.024155] Test:  [120/345]  eta: 0:00:41  loss: 0.7327 (0.7301)  time: 0.1871  data: 0.0001  max mem: 14938
[11:22:03.900200] Test:  [130/345]  eta: 0:00:40  loss: 0.7331 (0.7306)  time: 0.1874  data: 0.0001  max mem: 14938
[11:22:05.778867] Test:  [140/345]  eta: 0:00:38  loss: 0.7331 (0.7308)  time: 0.1877  data: 0.0001  max mem: 14938
[11:22:07.662626] Test:  [150/345]  eta: 0:00:36  loss: 0.7214 (0.7301)  time: 0.1881  data: 0.0001  max mem: 14938
[11:22:09.547313] Test:  [160/345]  eta: 0:00:34  loss: 0.7214 (0.7304)  time: 0.1884  data: 0.0001  max mem: 14938
[11:22:11.437373] Test:  [170/345]  eta: 0:00:32  loss: 0.7232 (0.7302)  time: 0.1887  data: 0.0001  max mem: 14938
[11:22:13.331597] Test:  [180/345]  eta: 0:00:30  loss: 0.7287 (0.7302)  time: 0.1892  data: 0.0001  max mem: 14938
[11:22:15.229268] Test:  [190/345]  eta: 0:00:29  loss: 0.7323 (0.7305)  time: 0.1895  data: 0.0001  max mem: 14938
[11:22:17.130004] Test:  [200/345]  eta: 0:00:27  loss: 0.7304 (0.7305)  time: 0.1899  data: 0.0001  max mem: 14938
[11:22:19.036544] Test:  [210/345]  eta: 0:00:25  loss: 0.7313 (0.7304)  time: 0.1903  data: 0.0001  max mem: 14938
[11:22:20.945171] Test:  [220/345]  eta: 0:00:23  loss: 0.7336 (0.7306)  time: 0.1907  data: 0.0001  max mem: 14938
[11:22:22.856290] Test:  [230/345]  eta: 0:00:21  loss: 0.7312 (0.7304)  time: 0.1909  data: 0.0001  max mem: 14938
[11:22:24.772198] Test:  [240/345]  eta: 0:00:19  loss: 0.7259 (0.7305)  time: 0.1913  data: 0.0001  max mem: 14938
[11:22:26.692240] Test:  [250/345]  eta: 0:00:17  loss: 0.7439 (0.7310)  time: 0.1917  data: 0.0001  max mem: 14938
[11:22:28.614317] Test:  [260/345]  eta: 0:00:16  loss: 0.7344 (0.7310)  time: 0.1921  data: 0.0001  max mem: 14938
[11:22:30.540143] Test:  [270/345]  eta: 0:00:14  loss: 0.7309 (0.7312)  time: 0.1923  data: 0.0001  max mem: 14938
[11:22:32.469831] Test:  [280/345]  eta: 0:00:12  loss: 0.7338 (0.7312)  time: 0.1927  data: 0.0001  max mem: 14938
[11:22:34.402451] Test:  [290/345]  eta: 0:00:10  loss: 0.7342 (0.7314)  time: 0.1931  data: 0.0001  max mem: 14938
[11:22:36.338232] Test:  [300/345]  eta: 0:00:08  loss: 0.7268 (0.7314)  time: 0.1934  data: 0.0001  max mem: 14938
[11:22:38.277101] Test:  [310/345]  eta: 0:00:06  loss: 0.7280 (0.7315)  time: 0.1937  data: 0.0001  max mem: 14938
[11:22:40.220038] Test:  [320/345]  eta: 0:00:04  loss: 0.7322 (0.7316)  time: 0.1940  data: 0.0001  max mem: 14938
[11:22:42.165062] Test:  [330/345]  eta: 0:00:02  loss: 0.7404 (0.7319)  time: 0.1943  data: 0.0001  max mem: 14938
[11:22:44.115661] Test:  [340/345]  eta: 0:00:00  loss: 0.7424 (0.7322)  time: 0.1947  data: 0.0001  max mem: 14938
[11:22:44.897247] Test:  [344/345]  eta: 0:00:00  loss: 0.7424 (0.7323)  time: 0.1949  data: 0.0001  max mem: 14938
[11:22:44.951966] Test: Total time: 0:01:05 (0.1899 s / it)
[11:22:55.305331] Test:  [ 0/57]  eta: 0:00:17  loss: 0.8350 (0.8350)  time: 0.3142  data: 0.1346  max mem: 14938
[11:22:57.121790] Test:  [10/57]  eta: 0:00:09  loss: 0.8868 (0.8803)  time: 0.1936  data: 0.0123  max mem: 14938
[11:22:58.941758] Test:  [20/57]  eta: 0:00:06  loss: 0.8868 (0.8706)  time: 0.1818  data: 0.0001  max mem: 14938
[11:23:00.766496] Test:  [30/57]  eta: 0:00:05  loss: 0.7691 (0.8342)  time: 0.1822  data: 0.0001  max mem: 14938
[11:23:02.595406] Test:  [40/57]  eta: 0:00:03  loss: 0.7591 (0.8151)  time: 0.1826  data: 0.0001  max mem: 14938
[11:23:04.430842] Test:  [50/57]  eta: 0:00:01  loss: 0.7455 (0.8072)  time: 0.1831  data: 0.0001  max mem: 14938
[11:23:05.419600] Test:  [56/57]  eta: 0:00:00  loss: 0.7671 (0.8126)  time: 0.1777  data: 0.0001  max mem: 14938
[11:23:05.480661] Test: Total time: 0:00:10 (0.1840 s / it)
[11:23:07.263993] Dice score of the network on the train images: 0.809117, val images: 0.812611
[11:23:07.264199] saving best_prec_model_0 @ epoch 22
[11:23:08.334356] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:23:09.219919] Epoch: [23]  [  0/345]  eta: 0:05:05  lr: 0.000122  loss: 0.7427 (0.7427)  time: 0.8843  data: 0.1421  max mem: 14938
[11:23:24.079719] Epoch: [23]  [ 20/345]  eta: 0:04:03  lr: 0.000122  loss: 0.7570 (0.7568)  time: 0.7429  data: 0.0001  max mem: 14938
[11:23:39.001269] Epoch: [23]  [ 40/345]  eta: 0:03:48  lr: 0.000122  loss: 0.7859 (0.7713)  time: 0.7460  data: 0.0001  max mem: 14938
[11:23:53.958061] Epoch: [23]  [ 60/345]  eta: 0:03:33  lr: 0.000122  loss: 0.7736 (0.7726)  time: 0.7478  data: 0.0001  max mem: 14938
[11:24:08.945454] Epoch: [23]  [ 80/345]  eta: 0:03:18  lr: 0.000121  loss: 0.7641 (0.7704)  time: 0.7493  data: 0.0001  max mem: 14938
[11:24:23.950339] Epoch: [23]  [100/345]  eta: 0:03:03  lr: 0.000121  loss: 0.7588 (0.7679)  time: 0.7502  data: 0.0001  max mem: 14938
[11:24:38.968450] Epoch: [23]  [120/345]  eta: 0:02:48  lr: 0.000121  loss: 0.7671 (0.7682)  time: 0.7509  data: 0.0001  max mem: 14938
[11:24:53.972188] Epoch: [23]  [140/345]  eta: 0:02:33  lr: 0.000121  loss: 0.7857 (0.7706)  time: 0.7501  data: 0.0001  max mem: 14938
[11:25:08.966969] Epoch: [23]  [160/345]  eta: 0:02:18  lr: 0.000121  loss: 0.7812 (0.7720)  time: 0.7497  data: 0.0001  max mem: 14938
[11:25:23.957672] Epoch: [23]  [180/345]  eta: 0:02:03  lr: 0.000121  loss: 0.7656 (0.7709)  time: 0.7495  data: 0.0001  max mem: 14938
[11:25:38.937914] Epoch: [23]  [200/345]  eta: 0:01:48  lr: 0.000121  loss: 0.7754 (0.7708)  time: 0.7490  data: 0.0001  max mem: 14938
[11:25:53.909449] Epoch: [23]  [220/345]  eta: 0:01:33  lr: 0.000121  loss: 0.7680 (0.7705)  time: 0.7485  data: 0.0001  max mem: 14938
[11:26:08.887586] Epoch: [23]  [240/345]  eta: 0:01:18  lr: 0.000120  loss: 0.7620 (0.7700)  time: 0.7489  data: 0.0001  max mem: 14938
[11:26:23.850506] Epoch: [23]  [260/345]  eta: 0:01:03  lr: 0.000120  loss: 0.7589 (0.7691)  time: 0.7481  data: 0.0001  max mem: 14938
[11:26:38.831596] Epoch: [23]  [280/345]  eta: 0:00:48  lr: 0.000120  loss: 0.7534 (0.7681)  time: 0.7490  data: 0.0001  max mem: 14938
[11:26:53.813132] Epoch: [23]  [300/345]  eta: 0:00:33  lr: 0.000120  loss: 0.7514 (0.7671)  time: 0.7490  data: 0.0001  max mem: 14938
[11:27:08.790947] Epoch: [23]  [320/345]  eta: 0:00:18  lr: 0.000120  loss: 0.7542 (0.7667)  time: 0.7488  data: 0.0001  max mem: 14938
[11:27:23.853618] Epoch: [23]  [340/345]  eta: 0:00:03  lr: 0.000120  loss: 0.7604 (0.7663)  time: 0.7531  data: 0.0001  max mem: 14938
[11:27:26.852303] Epoch: [23]  [344/345]  eta: 0:00:00  lr: 0.000120  loss: 0.7604 (0.7662)  time: 0.7532  data: 0.0001  max mem: 14938
[11:27:26.914998] Epoch: [23] Total time: 0:04:18 (0.7495 s / it)
[11:27:26.915259] Averaged stats: lr: 0.000120  loss: 0.7604 (0.7662)
[11:27:27.248892] Test:  [  0/345]  eta: 0:01:52  loss: 0.7398 (0.7398)  time: 0.3274  data: 0.1476  max mem: 14938
[11:27:29.084950] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7398 (0.7391)  time: 0.1966  data: 0.0135  max mem: 14938
[11:27:30.923601] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7367 (0.7370)  time: 0.1837  data: 0.0001  max mem: 14938
[11:27:32.764798] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7301 (0.7344)  time: 0.1839  data: 0.0001  max mem: 14938
[11:27:34.609108] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7315 (0.7348)  time: 0.1842  data: 0.0001  max mem: 14938
[11:27:36.458812] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7342 (0.7351)  time: 0.1846  data: 0.0001  max mem: 14938
[11:27:38.312010] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7361 (0.7360)  time: 0.1851  data: 0.0001  max mem: 14938
[11:27:40.166732] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7361 (0.7345)  time: 0.1853  data: 0.0001  max mem: 14938
[11:27:42.024607] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7310 (0.7345)  time: 0.1856  data: 0.0001  max mem: 14938
[11:27:43.888767] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7360 (0.7346)  time: 0.1860  data: 0.0001  max mem: 14938
[11:27:45.755306] Test:  [100/345]  eta: 0:00:45  loss: 0.7360 (0.7348)  time: 0.1865  data: 0.0001  max mem: 14938
[11:27:47.623989] Test:  [110/345]  eta: 0:00:43  loss: 0.7361 (0.7353)  time: 0.1867  data: 0.0001  max mem: 14938
[11:27:49.497796] Test:  [120/345]  eta: 0:00:41  loss: 0.7286 (0.7348)  time: 0.1871  data: 0.0001  max mem: 14938
[11:27:51.374814] Test:  [130/345]  eta: 0:00:40  loss: 0.7280 (0.7346)  time: 0.1875  data: 0.0001  max mem: 14938
[11:27:53.255452] Test:  [140/345]  eta: 0:00:38  loss: 0.7316 (0.7343)  time: 0.1878  data: 0.0001  max mem: 14938
[11:27:55.139585] Test:  [150/345]  eta: 0:00:36  loss: 0.7287 (0.7338)  time: 0.1882  data: 0.0001  max mem: 14938
[11:27:57.026771] Test:  [160/345]  eta: 0:00:34  loss: 0.7306 (0.7340)  time: 0.1885  data: 0.0001  max mem: 14938
[11:27:58.916193] Test:  [170/345]  eta: 0:00:32  loss: 0.7307 (0.7340)  time: 0.1888  data: 0.0001  max mem: 14938
[11:28:00.812800] Test:  [180/345]  eta: 0:00:30  loss: 0.7280 (0.7339)  time: 0.1892  data: 0.0001  max mem: 14938
[11:28:02.711140] Test:  [190/345]  eta: 0:00:29  loss: 0.7258 (0.7338)  time: 0.1897  data: 0.0001  max mem: 14938
[11:28:04.614455] Test:  [200/345]  eta: 0:00:27  loss: 0.7336 (0.7338)  time: 0.1900  data: 0.0001  max mem: 14938
[11:28:06.518013] Test:  [210/345]  eta: 0:00:25  loss: 0.7276 (0.7336)  time: 0.1903  data: 0.0001  max mem: 14938
[11:28:08.427553] Test:  [220/345]  eta: 0:00:23  loss: 0.7289 (0.7336)  time: 0.1906  data: 0.0001  max mem: 14938
[11:28:10.340517] Test:  [230/345]  eta: 0:00:21  loss: 0.7319 (0.7336)  time: 0.1911  data: 0.0001  max mem: 14938
[11:28:12.256192] Test:  [240/345]  eta: 0:00:19  loss: 0.7245 (0.7333)  time: 0.1914  data: 0.0001  max mem: 14938
[11:28:14.175770] Test:  [250/345]  eta: 0:00:17  loss: 0.7302 (0.7333)  time: 0.1917  data: 0.0001  max mem: 14938
[11:28:16.097862] Test:  [260/345]  eta: 0:00:16  loss: 0.7358 (0.7337)  time: 0.1920  data: 0.0001  max mem: 14938
[11:28:18.024923] Test:  [270/345]  eta: 0:00:14  loss: 0.7357 (0.7335)  time: 0.1924  data: 0.0001  max mem: 14938
[11:28:19.957627] Test:  [280/345]  eta: 0:00:12  loss: 0.7250 (0.7333)  time: 0.1929  data: 0.0001  max mem: 14938
[11:28:21.891757] Test:  [290/345]  eta: 0:00:10  loss: 0.7269 (0.7332)  time: 0.1933  data: 0.0001  max mem: 14938
[11:28:23.827829] Test:  [300/345]  eta: 0:00:08  loss: 0.7343 (0.7333)  time: 0.1935  data: 0.0001  max mem: 14938
[11:28:25.767692] Test:  [310/345]  eta: 0:00:06  loss: 0.7327 (0.7332)  time: 0.1937  data: 0.0001  max mem: 14938
[11:28:27.712017] Test:  [320/345]  eta: 0:00:04  loss: 0.7296 (0.7332)  time: 0.1942  data: 0.0001  max mem: 14938
[11:28:29.659900] Test:  [330/345]  eta: 0:00:02  loss: 0.7255 (0.7331)  time: 0.1946  data: 0.0001  max mem: 14938
[11:28:31.609740] Test:  [340/345]  eta: 0:00:00  loss: 0.7282 (0.7329)  time: 0.1948  data: 0.0001  max mem: 14938
[11:28:32.391121] Test:  [344/345]  eta: 0:00:00  loss: 0.7305 (0.7330)  time: 0.1949  data: 0.0001  max mem: 14938
[11:28:32.447183] Test: Total time: 0:01:05 (0.1899 s / it)
[11:28:42.825011] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8438 (0.8438)  time: 0.3163  data: 0.1367  max mem: 14938
[11:28:44.640307] Test:  [10/57]  eta: 0:00:09  loss: 0.8846 (0.8799)  time: 0.1937  data: 0.0125  max mem: 14938
[11:28:46.462869] Test:  [20/57]  eta: 0:00:06  loss: 0.8889 (0.8713)  time: 0.1818  data: 0.0001  max mem: 14938
[11:28:48.287625] Test:  [30/57]  eta: 0:00:05  loss: 0.7577 (0.8267)  time: 0.1823  data: 0.0001  max mem: 14938
[11:28:50.114777] Test:  [40/57]  eta: 0:00:03  loss: 0.7364 (0.8033)  time: 0.1825  data: 0.0001  max mem: 14938
[11:28:51.949873] Test:  [50/57]  eta: 0:00:01  loss: 0.7236 (0.7944)  time: 0.1831  data: 0.0001  max mem: 14938
[11:28:52.937876] Test:  [56/57]  eta: 0:00:00  loss: 0.7641 (0.8009)  time: 0.1776  data: 0.0001  max mem: 14938
[11:28:52.997475] Test: Total time: 0:00:10 (0.1840 s / it)
[11:28:54.818983] Dice score of the network on the train images: 0.779492, val images: 0.818183
[11:28:54.819238] saving best_dice_model_0 @ epoch 23
[11:28:55.893618] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:28:56.781730] Epoch: [24]  [  0/345]  eta: 0:05:05  lr: 0.000120  loss: 0.7428 (0.7428)  time: 0.8869  data: 0.1445  max mem: 14938
[11:29:11.663944] Epoch: [24]  [ 20/345]  eta: 0:04:04  lr: 0.000119  loss: 0.7582 (0.7587)  time: 0.7441  data: 0.0001  max mem: 14938
[11:29:26.596275] Epoch: [24]  [ 40/345]  eta: 0:03:48  lr: 0.000119  loss: 0.7545 (0.7598)  time: 0.7466  data: 0.0001  max mem: 14938
[11:29:41.548918] Epoch: [24]  [ 60/345]  eta: 0:03:33  lr: 0.000119  loss: 0.7507 (0.7591)  time: 0.7476  data: 0.0001  max mem: 14938
[11:29:56.534726] Epoch: [24]  [ 80/345]  eta: 0:03:18  lr: 0.000119  loss: 0.7702 (0.7617)  time: 0.7492  data: 0.0001  max mem: 14938
[11:30:11.534205] Epoch: [24]  [100/345]  eta: 0:03:03  lr: 0.000119  loss: 0.7913 (0.7666)  time: 0.7499  data: 0.0001  max mem: 14938
[11:30:26.535125] Epoch: [24]  [120/345]  eta: 0:02:48  lr: 0.000119  loss: 0.7656 (0.7667)  time: 0.7500  data: 0.0001  max mem: 14938
[11:30:41.540860] Epoch: [24]  [140/345]  eta: 0:02:33  lr: 0.000118  loss: 0.7637 (0.7665)  time: 0.7502  data: 0.0001  max mem: 14938
[11:30:56.549903] Epoch: [24]  [160/345]  eta: 0:02:18  lr: 0.000118  loss: 0.7563 (0.7653)  time: 0.7504  data: 0.0001  max mem: 14938
[11:31:11.547871] Epoch: [24]  [180/345]  eta: 0:02:03  lr: 0.000118  loss: 0.7585 (0.7650)  time: 0.7499  data: 0.0001  max mem: 14938
[11:31:26.538008] Epoch: [24]  [200/345]  eta: 0:01:48  lr: 0.000118  loss: 0.7523 (0.7637)  time: 0.7495  data: 0.0001  max mem: 14938
[11:31:41.515613] Epoch: [24]  [220/345]  eta: 0:01:33  lr: 0.000118  loss: 0.7500 (0.7626)  time: 0.7488  data: 0.0001  max mem: 14938
[11:31:56.491737] Epoch: [24]  [240/345]  eta: 0:01:18  lr: 0.000118  loss: 0.7489 (0.7616)  time: 0.7488  data: 0.0001  max mem: 14938
[11:32:11.454984] Epoch: [24]  [260/345]  eta: 0:01:03  lr: 0.000117  loss: 0.7466 (0.7608)  time: 0.7481  data: 0.0001  max mem: 14938
[11:32:26.416547] Epoch: [24]  [280/345]  eta: 0:00:48  lr: 0.000117  loss: 0.7483 (0.7601)  time: 0.7480  data: 0.0001  max mem: 14938
[11:32:41.390045] Epoch: [24]  [300/345]  eta: 0:00:33  lr: 0.000117  loss: 0.7470 (0.7593)  time: 0.7486  data: 0.0001  max mem: 14938
[11:32:56.369742] Epoch: [24]  [320/345]  eta: 0:00:18  lr: 0.000117  loss: 0.7478 (0.7588)  time: 0.7489  data: 0.0001  max mem: 14938
[11:33:11.333512] Epoch: [24]  [340/345]  eta: 0:00:03  lr: 0.000117  loss: 0.7615 (0.7587)  time: 0.7481  data: 0.0001  max mem: 14938
[11:33:14.327017] Epoch: [24]  [344/345]  eta: 0:00:00  lr: 0.000117  loss: 0.7615 (0.7587)  time: 0.7481  data: 0.0001  max mem: 14938
[11:33:14.392757] Epoch: [24] Total time: 0:04:18 (0.7493 s / it)
[11:33:14.393271] Averaged stats: lr: 0.000117  loss: 0.7615 (0.7587)
[11:33:14.726667] Test:  [  0/345]  eta: 0:01:53  loss: 0.7428 (0.7428)  time: 0.3286  data: 0.1471  max mem: 14938
[11:33:16.562918] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7417 (0.7377)  time: 0.1967  data: 0.0134  max mem: 14938
[11:33:18.400858] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7410 (0.7408)  time: 0.1836  data: 0.0001  max mem: 14938
[11:33:20.241760] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7345 (0.7380)  time: 0.1839  data: 0.0001  max mem: 14938
[11:33:22.086344] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7385 (0.7400)  time: 0.1842  data: 0.0001  max mem: 14938
[11:33:23.936780] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7402 (0.7396)  time: 0.1847  data: 0.0001  max mem: 14938
[11:33:25.789353] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7318 (0.7381)  time: 0.1851  data: 0.0001  max mem: 14938
[11:33:27.645422] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7318 (0.7382)  time: 0.1854  data: 0.0001  max mem: 14938
[11:33:29.504038] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7354 (0.7371)  time: 0.1857  data: 0.0001  max mem: 14938
[11:33:31.367600] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7381 (0.7377)  time: 0.1861  data: 0.0001  max mem: 14938
[11:33:33.235359] Test:  [100/345]  eta: 0:00:45  loss: 0.7381 (0.7376)  time: 0.1865  data: 0.0001  max mem: 14938
[11:33:35.104598] Test:  [110/345]  eta: 0:00:43  loss: 0.7365 (0.7384)  time: 0.1868  data: 0.0001  max mem: 14938
[11:33:36.979617] Test:  [120/345]  eta: 0:00:41  loss: 0.7365 (0.7383)  time: 0.1872  data: 0.0001  max mem: 14938
[11:33:38.856749] Test:  [130/345]  eta: 0:00:40  loss: 0.7320 (0.7378)  time: 0.1876  data: 0.0001  max mem: 14938
[11:33:40.737137] Test:  [140/345]  eta: 0:00:38  loss: 0.7320 (0.7372)  time: 0.1878  data: 0.0001  max mem: 14938
[11:33:42.619929] Test:  [150/345]  eta: 0:00:36  loss: 0.7306 (0.7372)  time: 0.1881  data: 0.0001  max mem: 14938
[11:33:44.507567] Test:  [160/345]  eta: 0:00:34  loss: 0.7390 (0.7375)  time: 0.1885  data: 0.0001  max mem: 14938
[11:33:46.397299] Test:  [170/345]  eta: 0:00:32  loss: 0.7379 (0.7373)  time: 0.1888  data: 0.0001  max mem: 14938
[11:33:48.292163] Test:  [180/345]  eta: 0:00:30  loss: 0.7287 (0.7371)  time: 0.1892  data: 0.0001  max mem: 14938
[11:33:50.191557] Test:  [190/345]  eta: 0:00:29  loss: 0.7373 (0.7372)  time: 0.1897  data: 0.0001  max mem: 14938
[11:33:52.094224] Test:  [200/345]  eta: 0:00:27  loss: 0.7358 (0.7369)  time: 0.1901  data: 0.0001  max mem: 14938
[11:33:53.997364] Test:  [210/345]  eta: 0:00:25  loss: 0.7358 (0.7369)  time: 0.1902  data: 0.0001  max mem: 14938
[11:33:55.906695] Test:  [220/345]  eta: 0:00:23  loss: 0.7354 (0.7368)  time: 0.1906  data: 0.0001  max mem: 14938
[11:33:57.819879] Test:  [230/345]  eta: 0:00:21  loss: 0.7333 (0.7365)  time: 0.1911  data: 0.0001  max mem: 14938
[11:33:59.737904] Test:  [240/345]  eta: 0:00:19  loss: 0.7332 (0.7365)  time: 0.1915  data: 0.0001  max mem: 14938
[11:34:01.658168] Test:  [250/345]  eta: 0:00:17  loss: 0.7332 (0.7365)  time: 0.1919  data: 0.0001  max mem: 14938
[11:34:03.581357] Test:  [260/345]  eta: 0:00:16  loss: 0.7335 (0.7364)  time: 0.1921  data: 0.0001  max mem: 14938
[11:34:05.506875] Test:  [270/345]  eta: 0:00:14  loss: 0.7362 (0.7367)  time: 0.1924  data: 0.0001  max mem: 14938
[11:34:07.437532] Test:  [280/345]  eta: 0:00:12  loss: 0.7419 (0.7368)  time: 0.1928  data: 0.0001  max mem: 14938
[11:34:09.371273] Test:  [290/345]  eta: 0:00:10  loss: 0.7336 (0.7368)  time: 0.1932  data: 0.0001  max mem: 14938
[11:34:11.307956] Test:  [300/345]  eta: 0:00:08  loss: 0.7236 (0.7365)  time: 0.1935  data: 0.0001  max mem: 14938
[11:34:13.249096] Test:  [310/345]  eta: 0:00:06  loss: 0.7289 (0.7365)  time: 0.1938  data: 0.0001  max mem: 14938
[11:34:15.192309] Test:  [320/345]  eta: 0:00:04  loss: 0.7272 (0.7363)  time: 0.1942  data: 0.0001  max mem: 14938
[11:34:17.138215] Test:  [330/345]  eta: 0:00:02  loss: 0.7337 (0.7366)  time: 0.1944  data: 0.0001  max mem: 14938
[11:34:19.089173] Test:  [340/345]  eta: 0:00:00  loss: 0.7471 (0.7369)  time: 0.1948  data: 0.0001  max mem: 14938
[11:34:19.871348] Test:  [344/345]  eta: 0:00:00  loss: 0.7438 (0.7368)  time: 0.1950  data: 0.0001  max mem: 14938
[11:34:19.931776] Test: Total time: 0:01:05 (0.1900 s / it)
[11:34:30.237858] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8361 (0.8361)  time: 0.3200  data: 0.1403  max mem: 14938
[11:34:32.053733] Test:  [10/57]  eta: 0:00:09  loss: 0.8577 (0.8622)  time: 0.1941  data: 0.0128  max mem: 14938
[11:34:33.875264] Test:  [20/57]  eta: 0:00:06  loss: 0.8577 (0.8518)  time: 0.1818  data: 0.0001  max mem: 14938
[11:34:35.699035] Test:  [30/57]  eta: 0:00:05  loss: 0.7638 (0.8200)  time: 0.1822  data: 0.0001  max mem: 14938
[11:34:37.527330] Test:  [40/57]  eta: 0:00:03  loss: 0.7529 (0.8042)  time: 0.1825  data: 0.0001  max mem: 14938
[11:34:39.361801] Test:  [50/57]  eta: 0:00:01  loss: 0.7444 (0.7976)  time: 0.1831  data: 0.0001  max mem: 14938
[11:34:40.350473] Test:  [56/57]  eta: 0:00:00  loss: 0.7729 (0.8021)  time: 0.1777  data: 0.0001  max mem: 14938
[11:34:40.406542] Test: Total time: 0:00:10 (0.1840 s / it)
[11:34:42.147066] Dice score of the network on the train images: 0.788824, val images: 0.809440
[11:34:42.151656] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:34:43.033468] Epoch: [25]  [  0/345]  eta: 0:05:03  lr: 0.000117  loss: 0.7509 (0.7509)  time: 0.8809  data: 0.1415  max mem: 14938
[11:34:57.916633] Epoch: [25]  [ 20/345]  eta: 0:04:03  lr: 0.000116  loss: 0.7549 (0.7575)  time: 0.7441  data: 0.0001  max mem: 14938
[11:35:12.850934] Epoch: [25]  [ 40/345]  eta: 0:03:48  lr: 0.000116  loss: 0.7509 (0.7548)  time: 0.7467  data: 0.0001  max mem: 14938
[11:35:27.800127] Epoch: [25]  [ 60/345]  eta: 0:03:33  lr: 0.000116  loss: 0.7543 (0.7544)  time: 0.7474  data: 0.0001  max mem: 14938
[11:35:42.774142] Epoch: [25]  [ 80/345]  eta: 0:03:18  lr: 0.000116  loss: 0.7504 (0.7542)  time: 0.7487  data: 0.0001  max mem: 14938

[11:35:57.761821] Epoch: [25]  [100/345]  eta: 0:03:03  lr: 0.000116  loss: 0.7491 (0.7542)  time: 0.7493  data: 0.0001  max mem: 14938
[11:36:12.780401] Epoch: [25]  [120/345]  eta: 0:02:48  lr: 0.000115  loss: 0.7598 (0.7549)  time: 0.7509  data: 0.0001  max mem: 14938

[11:36:27.783966] Epoch: [25]  [140/345]  eta: 0:02:33  lr: 0.000115  loss: 0.7596 (0.7554)  time: 0.7501  data: 0.0001  max mem: 14938
[11:36:42.770610] Epoch: [25]  [160/345]  eta: 0:02:18  lr: 0.000115  loss: 0.7654 (0.7574)  time: 0.7493  data: 0.0001  max mem: 14938
[11:36:57.747772] Epoch: [25]  [180/345]  eta: 0:02:03  lr: 0.000115  loss: 0.7634 (0.7584)  time: 0.7488  data: 0.0001  max mem: 14938
[11:37:12.721712] Epoch: [25]  [200/345]  eta: 0:01:48  lr: 0.000115  loss: 0.7445 (0.7570)  time: 0.7487  data: 0.0001  max mem: 14938
[11:37:27.698090] Epoch: [25]  [220/345]  eta: 0:01:33  lr: 0.000114  loss: 0.7527 (0.7567)  time: 0.7488  data: 0.0001  max mem: 14938
[11:37:42.677065] Epoch: [25]  [240/345]  eta: 0:01:18  lr: 0.000114  loss: 0.7438 (0.7561)  time: 0.7489  data: 0.0001  max mem: 14938
[11:37:57.644044] Epoch: [25]  [260/345]  eta: 0:01:03  lr: 0.000114  loss: 0.7501 (0.7562)  time: 0.7483  data: 0.0001  max mem: 14938
[11:38:12.608821] Epoch: [25]  [280/345]  eta: 0:00:48  lr: 0.000114  loss: 0.7449 (0.7557)  time: 0.7482  data: 0.0001  max mem: 14938
[11:38:27.559970] Epoch: [25]  [300/345]  eta: 0:00:33  lr: 0.000114  loss: 0.7377 (0.7549)  time: 0.7475  data: 0.0001  max mem: 14938
[11:38:42.517639] Epoch: [25]  [320/345]  eta: 0:00:18  lr: 0.000113  loss: 0.7504 (0.7549)  time: 0.7478  data: 0.0001  max mem: 14938
[11:38:57.471865] Epoch: [25]  [340/345]  eta: 0:00:03  lr: 0.000113  loss: 0.7483 (0.7546)  time: 0.7477  data: 0.0001  max mem: 14938
[11:39:00.461119] Epoch: [25]  [344/345]  eta: 0:00:00  lr: 0.000113  loss: 0.7528 (0.7546)  time: 0.7477  data: 0.0001  max mem: 14938
[11:39:00.503589] Epoch: [25] Total time: 0:04:18 (0.7488 s / it)
[11:39:00.503879] Averaged stats: lr: 0.000113  loss: 0.7528 (0.7546)
[11:39:00.834480] Test:  [  0/345]  eta: 0:01:52  loss: 0.6842 (0.6842)  time: 0.3268  data: 0.1451  max mem: 14938
[11:39:02.671695] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7235 (0.7234)  time: 0.1967  data: 0.0132  max mem: 14938
[11:39:04.511519] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7217 (0.7218)  time: 0.1838  data: 0.0001  max mem: 14938
[11:39:06.353119] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7175 (0.7203)  time: 0.1840  data: 0.0001  max mem: 14938
[11:39:08.199356] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7192 (0.7212)  time: 0.1843  data: 0.0001  max mem: 14938
[11:39:10.050126] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7211 (0.7199)  time: 0.1848  data: 0.0001  max mem: 14938
[11:39:11.904143] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7133 (0.7202)  time: 0.1852  data: 0.0001  max mem: 14938
[11:39:13.761049] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7198 (0.7206)  time: 0.1855  data: 0.0001  max mem: 14938
[11:39:15.620291] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7199 (0.7204)  time: 0.1858  data: 0.0001  max mem: 14938
[11:39:17.484392] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7203 (0.7210)  time: 0.1861  data: 0.0001  max mem: 14938
[11:39:19.351572] Test:  [100/345]  eta: 0:00:45  loss: 0.7232 (0.7210)  time: 0.1865  data: 0.0001  max mem: 14938
[11:39:21.222586] Test:  [110/345]  eta: 0:00:43  loss: 0.7244 (0.7217)  time: 0.1869  data: 0.0001  max mem: 14938
[11:39:23.097723] Test:  [120/345]  eta: 0:00:41  loss: 0.7297 (0.7221)  time: 0.1872  data: 0.0001  max mem: 14938
[11:39:24.974321] Test:  [130/345]  eta: 0:00:40  loss: 0.7182 (0.7218)  time: 0.1875  data: 0.0001  max mem: 14938
[11:39:26.856276] Test:  [140/345]  eta: 0:00:38  loss: 0.7187 (0.7221)  time: 0.1879  data: 0.0001  max mem: 14938
[11:39:28.739422] Test:  [150/345]  eta: 0:00:36  loss: 0.7187 (0.7219)  time: 0.1882  data: 0.0001  max mem: 14938
[11:39:30.626742] Test:  [160/345]  eta: 0:00:34  loss: 0.7207 (0.7220)  time: 0.1885  data: 0.0001  max mem: 14938
[11:39:32.516541] Test:  [170/345]  eta: 0:00:32  loss: 0.7233 (0.7221)  time: 0.1888  data: 0.0001  max mem: 14938
[11:39:34.412541] Test:  [180/345]  eta: 0:00:30  loss: 0.7233 (0.7222)  time: 0.1892  data: 0.0001  max mem: 14938
[11:39:36.310251] Test:  [190/345]  eta: 0:00:29  loss: 0.7260 (0.7223)  time: 0.1896  data: 0.0001  max mem: 14938
[11:39:38.211558] Test:  [200/345]  eta: 0:00:27  loss: 0.7267 (0.7227)  time: 0.1899  data: 0.0001  max mem: 14938
[11:39:40.116745] Test:  [210/345]  eta: 0:00:25  loss: 0.7178 (0.7223)  time: 0.1903  data: 0.0001  max mem: 14938
[11:39:42.025820] Test:  [220/345]  eta: 0:00:23  loss: 0.7117 (0.7223)  time: 0.1907  data: 0.0001  max mem: 14938
[11:39:43.937504] Test:  [230/345]  eta: 0:00:21  loss: 0.7249 (0.7227)  time: 0.1910  data: 0.0001  max mem: 14938
[11:39:45.852057] Test:  [240/345]  eta: 0:00:19  loss: 0.7287 (0.7228)  time: 0.1913  data: 0.0001  max mem: 14938
[11:39:47.773688] Test:  [250/345]  eta: 0:00:17  loss: 0.7251 (0.7229)  time: 0.1918  data: 0.0001  max mem: 14938
[11:39:49.697820] Test:  [260/345]  eta: 0:00:16  loss: 0.7225 (0.7231)  time: 0.1922  data: 0.0001  max mem: 14938
[11:39:51.625050] Test:  [270/345]  eta: 0:00:14  loss: 0.7196 (0.7228)  time: 0.1925  data: 0.0001  max mem: 14938
[11:39:53.555147] Test:  [280/345]  eta: 0:00:12  loss: 0.7170 (0.7228)  time: 0.1928  data: 0.0001  max mem: 14938
[11:39:55.488455] Test:  [290/345]  eta: 0:00:10  loss: 0.7205 (0.7227)  time: 0.1931  data: 0.0001  max mem: 14938
[11:39:57.424231] Test:  [300/345]  eta: 0:00:08  loss: 0.7184 (0.7225)  time: 0.1934  data: 0.0001  max mem: 14938
[11:39:59.363988] Test:  [310/345]  eta: 0:00:06  loss: 0.7146 (0.7223)  time: 0.1937  data: 0.0001  max mem: 14938
[11:40:01.307111] Test:  [320/345]  eta: 0:00:04  loss: 0.7149 (0.7222)  time: 0.1941  data: 0.0001  max mem: 14938
[11:40:03.255924] Test:  [330/345]  eta: 0:00:02  loss: 0.7210 (0.7224)  time: 0.1945  data: 0.0001  max mem: 14938
[11:40:05.206760] Test:  [340/345]  eta: 0:00:00  loss: 0.7277 (0.7226)  time: 0.1949  data: 0.0001  max mem: 14938
[11:40:05.987953] Test:  [344/345]  eta: 0:00:00  loss: 0.7277 (0.7226)  time: 0.1950  data: 0.0001  max mem: 14938

[11:40:06.045990] Test: Total time: 0:01:05 (0.1900 s / it)
[11:40:16.610337] Test:  [ 0/57]  eta: 0:00:17  loss: 0.8126 (0.8126)  time: 0.3152  data: 0.1358  max mem: 14938
[11:40:18.425866] Test:  [10/57]  eta: 0:00:09  loss: 0.8489 (0.8610)  time: 0.1936  data: 0.0124  max mem: 14938
[11:40:20.246915] Test:  [20/57]  eta: 0:00:06  loss: 0.8541 (0.8548)  time: 0.1818  data: 0.0001  max mem: 14938
[11:40:22.070246] Test:  [30/57]  eta: 0:00:05  loss: 0.7490 (0.8171)  time: 0.1822  data: 0.0001  max mem: 14938
[11:40:23.899754] Test:  [40/57]  eta: 0:00:03  loss: 0.7376 (0.7981)  time: 0.1826  data: 0.0001  max mem: 14938
[11:40:25.734316] Test:  [50/57]  eta: 0:00:01  loss: 0.7368 (0.7914)  time: 0.1832  data: 0.0001  max mem: 14938
[11:40:26.723218] Test:  [56/57]  eta: 0:00:00  loss: 0.7549 (0.7969)  time: 0.1777  data: 0.0001  max mem: 14938
[11:40:26.783688] Test: Total time: 0:00:10 (0.1840 s / it)
[11:40:28.543119] Dice score of the network on the train images: 0.795592, val images: 0.821893
[11:40:28.543366] saving best_dice_model_0 @ epoch 25
[11:40:29.619968] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:40:30.503465] Epoch: [26]  [  0/345]  eta: 0:05:04  lr: 0.000113  loss: 0.7280 (0.7280)  time: 0.8823  data: 0.1408  max mem: 14938
[11:40:45.385508] Epoch: [26]  [ 20/345]  eta: 0:04:03  lr: 0.000113  loss: 0.7519 (0.7500)  time: 0.7441  data: 0.0001  max mem: 14938
[11:41:00.312565] Epoch: [26]  [ 40/345]  eta: 0:03:48  lr: 0.000113  loss: 0.7473 (0.7484)  time: 0.7463  data: 0.0001  max mem: 14938
[11:41:15.275761] Epoch: [26]  [ 60/345]  eta: 0:03:33  lr: 0.000112  loss: 0.7458 (0.7491)  time: 0.7481  data: 0.0001  max mem: 14938
[11:41:30.264854] Epoch: [26]  [ 80/345]  eta: 0:03:18  lr: 0.000112  loss: 0.7382 (0.7470)  time: 0.7494  data: 0.0001  max mem: 14938
[11:41:45.279970] Epoch: [26]  [100/345]  eta: 0:03:03  lr: 0.000112  loss: 0.7397 (0.7459)  time: 0.7507  data: 0.0001  max mem: 14938
[11:42:00.325791] Epoch: [26]  [120/345]  eta: 0:02:48  lr: 0.000112  loss: 0.7481 (0.7463)  time: 0.7523  data: 0.0001  max mem: 14938
[11:42:15.345578] Epoch: [26]  [140/345]  eta: 0:02:33  lr: 0.000111  loss: 0.7363 (0.7452)  time: 0.7509  data: 0.0001  max mem: 14938
[11:42:30.353577] Epoch: [26]  [160/345]  eta: 0:02:18  lr: 0.000111  loss: 0.7427 (0.7453)  time: 0.7504  data: 0.0001  max mem: 14938
[11:42:45.341896] Epoch: [26]  [180/345]  eta: 0:02:03  lr: 0.000111  loss: 0.7485 (0.7455)  time: 0.7494  data: 0.0001  max mem: 14938
[11:43:00.325652] Epoch: [26]  [200/345]  eta: 0:01:48  lr: 0.000111  loss: 0.7553 (0.7471)  time: 0.7491  data: 0.0001  max mem: 14938
[11:43:15.313821] Epoch: [26]  [220/345]  eta: 0:01:33  lr: 0.000110  loss: 0.7485 (0.7475)  time: 0.7494  data: 0.0001  max mem: 14938
[11:43:30.317465] Epoch: [26]  [240/345]  eta: 0:01:18  lr: 0.000110  loss: 0.7483 (0.7476)  time: 0.7501  data: 0.0001  max mem: 14938
[11:43:45.308728] Epoch: [26]  [260/345]  eta: 0:01:03  lr: 0.000110  loss: 0.7460 (0.7477)  time: 0.7495  data: 0.0001  max mem: 14938
[11:44:00.301135] Epoch: [26]  [280/345]  eta: 0:00:48  lr: 0.000110  loss: 0.7565 (0.7487)  time: 0.7496  data: 0.0001  max mem: 14938
[11:44:15.289330] Epoch: [26]  [300/345]  eta: 0:00:33  lr: 0.000110  loss: 0.7652 (0.7500)  time: 0.7494  data: 0.0001  max mem: 14938
[11:44:30.269377] Epoch: [26]  [320/345]  eta: 0:00:18  lr: 0.000109  loss: 0.7515 (0.7501)  time: 0.7490  data: 0.0001  max mem: 14938
[11:44:45.344302] Epoch: [26]  [340/345]  eta: 0:00:03  lr: 0.000109  loss: 0.7445 (0.7498)  time: 0.7537  data: 0.0001  max mem: 14938
[11:44:48.343182] Epoch: [26]  [344/345]  eta: 0:00:00  lr: 0.000109  loss: 0.7445 (0.7496)  time: 0.7537  data: 0.0001  max mem: 14938
[11:44:48.408985] Epoch: [26] Total time: 0:04:18 (0.7501 s / it)
[11:44:48.409475] Averaged stats: lr: 0.000109  loss: 0.7445 (0.7496)
[11:44:48.746578] Test:  [  0/345]  eta: 0:01:54  loss: 0.7170 (0.7170)  time: 0.3326  data: 0.1516  max mem: 14938
[11:44:50.581989] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7164 (0.7214)  time: 0.1970  data: 0.0138  max mem: 14938
[11:44:52.420790] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7157 (0.7204)  time: 0.1836  data: 0.0001  max mem: 14938
[11:44:54.263697] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7157 (0.7191)  time: 0.1840  data: 0.0001  max mem: 14938
[11:44:56.111185] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7128 (0.7172)  time: 0.1845  data: 0.0001  max mem: 14938
[11:44:57.959556] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7171 (0.7182)  time: 0.1847  data: 0.0001  max mem: 14938
[11:44:59.814570] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7212 (0.7181)  time: 0.1851  data: 0.0001  max mem: 14938
[11:45:01.671401] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7212 (0.7183)  time: 0.1855  data: 0.0001  max mem: 14938
[11:45:03.530317] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7198 (0.7184)  time: 0.1857  data: 0.0001  max mem: 14938
[11:45:05.392639] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7151 (0.7180)  time: 0.1860  data: 0.0001  max mem: 14938
[11:45:07.257941] Test:  [100/345]  eta: 0:00:45  loss: 0.7206 (0.7187)  time: 0.1863  data: 0.0001  max mem: 14938
[11:45:09.128515] Test:  [110/345]  eta: 0:00:43  loss: 0.7239 (0.7189)  time: 0.1867  data: 0.0001  max mem: 14938
[11:45:11.003233] Test:  [120/345]  eta: 0:00:41  loss: 0.7211 (0.7187)  time: 0.1872  data: 0.0001  max mem: 14938
[11:45:12.879761] Test:  [130/345]  eta: 0:00:40  loss: 0.7199 (0.7192)  time: 0.1875  data: 0.0001  max mem: 14938
[11:45:14.760815] Test:  [140/345]  eta: 0:00:38  loss: 0.7199 (0.7189)  time: 0.1878  data: 0.0001  max mem: 14938
[11:45:16.644207] Test:  [150/345]  eta: 0:00:36  loss: 0.7182 (0.7193)  time: 0.1882  data: 0.0001  max mem: 14938
[11:45:18.530745] Test:  [160/345]  eta: 0:00:34  loss: 0.7106 (0.7186)  time: 0.1884  data: 0.0001  max mem: 14938
[11:45:20.420493] Test:  [170/345]  eta: 0:00:32  loss: 0.7103 (0.7183)  time: 0.1888  data: 0.0001  max mem: 14938
[11:45:22.315547] Test:  [180/345]  eta: 0:00:30  loss: 0.7153 (0.7183)  time: 0.1892  data: 0.0001  max mem: 14938
[11:45:24.215077] Test:  [190/345]  eta: 0:00:29  loss: 0.7153 (0.7183)  time: 0.1897  data: 0.0001  max mem: 14938
[11:45:26.116681] Test:  [200/345]  eta: 0:00:27  loss: 0.7140 (0.7182)  time: 0.1900  data: 0.0001  max mem: 14938
[11:45:28.019458] Test:  [210/345]  eta: 0:00:25  loss: 0.7130 (0.7184)  time: 0.1902  data: 0.0001  max mem: 14938
[11:45:29.929277] Test:  [220/345]  eta: 0:00:23  loss: 0.7128 (0.7184)  time: 0.1906  data: 0.0001  max mem: 14938
[11:45:31.844390] Test:  [230/345]  eta: 0:00:21  loss: 0.7153 (0.7183)  time: 0.1912  data: 0.0001  max mem: 14938
[11:45:33.760804] Test:  [240/345]  eta: 0:00:19  loss: 0.7154 (0.7183)  time: 0.1915  data: 0.0001  max mem: 14938
[11:45:35.681077] Test:  [250/345]  eta: 0:00:17  loss: 0.7130 (0.7183)  time: 0.1918  data: 0.0001  max mem: 14938
[11:45:37.604685] Test:  [260/345]  eta: 0:00:16  loss: 0.7130 (0.7183)  time: 0.1921  data: 0.0001  max mem: 14938
[11:45:39.532061] Test:  [270/345]  eta: 0:00:14  loss: 0.7165 (0.7184)  time: 0.1925  data: 0.0001  max mem: 14938
[11:45:41.464110] Test:  [280/345]  eta: 0:00:12  loss: 0.7165 (0.7184)  time: 0.1929  data: 0.0001  max mem: 14938
[11:45:43.397174] Test:  [290/345]  eta: 0:00:10  loss: 0.7141 (0.7184)  time: 0.1932  data: 0.0001  max mem: 14938
[11:45:45.334447] Test:  [300/345]  eta: 0:00:08  loss: 0.7181 (0.7185)  time: 0.1935  data: 0.0001  max mem: 14938
[11:45:47.275543] Test:  [310/345]  eta: 0:00:06  loss: 0.7199 (0.7187)  time: 0.1939  data: 0.0001  max mem: 14938
[11:45:49.219094] Test:  [320/345]  eta: 0:00:04  loss: 0.7172 (0.7186)  time: 0.1942  data: 0.0001  max mem: 14938
[11:45:51.167684] Test:  [330/345]  eta: 0:00:02  loss: 0.7141 (0.7184)  time: 0.1946  data: 0.0001  max mem: 14938
[11:45:53.119127] Test:  [340/345]  eta: 0:00:00  loss: 0.7106 (0.7183)  time: 0.1949  data: 0.0001  max mem: 14938
[11:45:53.901064] Test:  [344/345]  eta: 0:00:00  loss: 0.7108 (0.7183)  time: 0.1951  data: 0.0001  max mem: 14938
[11:45:53.957574] Test: Total time: 0:01:05 (0.1900 s / it)
[11:46:04.280002] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8440 (0.8440)  time: 0.3175  data: 0.1381  max mem: 14938
[11:46:06.095512] Test:  [10/57]  eta: 0:00:09  loss: 0.8559 (0.8662)  time: 0.1938  data: 0.0126  max mem: 14938
[11:46:07.916375] Test:  [20/57]  eta: 0:00:06  loss: 0.8703 (0.8603)  time: 0.1818  data: 0.0001  max mem: 14938
[11:46:09.741520] Test:  [30/57]  eta: 0:00:05  loss: 0.7486 (0.8195)  time: 0.1822  data: 0.0001  max mem: 14938
[11:46:11.569229] Test:  [40/57]  eta: 0:00:03  loss: 0.7359 (0.7979)  time: 0.1826  data: 0.0001  max mem: 14938
[11:46:13.403879] Test:  [50/57]  eta: 0:00:01  loss: 0.7293 (0.7901)  time: 0.1831  data: 0.0001  max mem: 14938
[11:46:14.393352] Test:  [56/57]  eta: 0:00:00  loss: 0.7391 (0.7952)  time: 0.1778  data: 0.0001  max mem: 14938
[11:46:14.452830] Test: Total time: 0:00:10 (0.1841 s / it)
[11:46:16.160392] Dice score of the network on the train images: 0.804166, val images: 0.822558
[11:46:16.160611] saving best_dice_model_0 @ epoch 26
[11:46:17.256763] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:46:18.143288] Epoch: [27]  [  0/345]  eta: 0:05:05  lr: 0.000109  loss: 0.7610 (0.7610)  time: 0.8852  data: 0.1450  max mem: 14938
[11:46:33.013146] Epoch: [27]  [ 20/345]  eta: 0:04:03  lr: 0.000109  loss: 0.7394 (0.7426)  time: 0.7434  data: 0.0001  max mem: 14938
[11:46:47.952636] Epoch: [27]  [ 40/345]  eta: 0:03:48  lr: 0.000108  loss: 0.7365 (0.7421)  time: 0.7469  data: 0.0001  max mem: 14938
[11:47:02.908623] Epoch: [27]  [ 60/345]  eta: 0:03:33  lr: 0.000108  loss: 0.7415 (0.7423)  time: 0.7477  data: 0.0001  max mem: 14938
[11:47:17.889149] Epoch: [27]  [ 80/345]  eta: 0:03:18  lr: 0.000108  loss: 0.7560 (0.7462)  time: 0.7490  data: 0.0001  max mem: 14938
[11:47:32.894037] Epoch: [27]  [100/345]  eta: 0:03:03  lr: 0.000108  loss: 0.7893 (0.7548)  time: 0.7502  data: 0.0001  max mem: 14938
[11:47:47.922260] Epoch: [27]  [120/345]  eta: 0:02:48  lr: 0.000107  loss: 0.7569 (0.7569)  time: 0.7514  data: 0.0001  max mem: 14938
[11:48:02.950257] Epoch: [27]  [140/345]  eta: 0:02:33  lr: 0.000107  loss: 0.7529 (0.7563)  time: 0.7514  data: 0.0001  max mem: 14938
[11:48:17.970754] Epoch: [27]  [160/345]  eta: 0:02:18  lr: 0.000107  loss: 0.7474 (0.7556)  time: 0.7510  data: 0.0001  max mem: 14938
[11:48:32.974286] Epoch: [27]  [180/345]  eta: 0:02:03  lr: 0.000107  loss: 0.7429 (0.7544)  time: 0.7501  data: 0.0001  max mem: 14938
[11:48:47.983126] Epoch: [27]  [200/345]  eta: 0:01:48  lr: 0.000106  loss: 0.7429 (0.7539)  time: 0.7504  data: 0.0001  max mem: 14938
[11:49:02.978818] Epoch: [27]  [220/345]  eta: 0:01:33  lr: 0.000106  loss: 0.7450 (0.7535)  time: 0.7497  data: 0.0001  max mem: 14938
[11:49:17.979859] Epoch: [27]  [240/345]  eta: 0:01:18  lr: 0.000106  loss: 0.7483 (0.7530)  time: 0.7500  data: 0.0001  max mem: 14938
[11:49:32.970552] Epoch: [27]  [260/345]  eta: 0:01:03  lr: 0.000106  loss: 0.7544 (0.7535)  time: 0.7495  data: 0.0001  max mem: 14938
[11:49:47.936476] Epoch: [27]  [280/345]  eta: 0:00:48  lr: 0.000105  loss: 0.7533 (0.7534)  time: 0.7483  data: 0.0001  max mem: 14938
[11:50:02.930264] Epoch: [27]  [300/345]  eta: 0:00:33  lr: 0.000105  loss: 0.7445 (0.7530)  time: 0.7496  data: 0.0001  max mem: 14938
[11:50:17.924604] Epoch: [27]  [320/345]  eta: 0:00:18  lr: 0.000105  loss: 0.7409 (0.7524)  time: 0.7497  data: 0.0001  max mem: 14938
[11:50:32.907675] Epoch: [27]  [340/345]  eta: 0:00:03  lr: 0.000104  loss: 0.7402 (0.7521)  time: 0.7491  data: 0.0001  max mem: 14938
[11:50:35.903307] Epoch: [27]  [344/345]  eta: 0:00:00  lr: 0.000104  loss: 0.7443 (0.7521)  time: 0.7490  data: 0.0001  max mem: 14938
[11:50:35.969365] Epoch: [27] Total time: 0:04:18 (0.7499 s / it)
[11:50:35.969882] Averaged stats: lr: 0.000104  loss: 0.7443 (0.7521)
[11:50:36.303295] Test:  [  0/345]  eta: 0:01:53  loss: 0.7154 (0.7154)  time: 0.3292  data: 0.1474  max mem: 14938
[11:50:38.140306] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7195 (0.7228)  time: 0.1968  data: 0.0135  max mem: 14938
[11:50:39.977742] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7150 (0.7173)  time: 0.1837  data: 0.0001  max mem: 14938
[11:50:41.819368] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7135 (0.7170)  time: 0.1839  data: 0.0001  max mem: 14938
[11:50:43.665118] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7135 (0.7166)  time: 0.1843  data: 0.0001  max mem: 14938
[11:50:45.515672] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7093 (0.7162)  time: 0.1848  data: 0.0001  max mem: 14938
[11:50:47.368799] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7141 (0.7163)  time: 0.1851  data: 0.0001  max mem: 14938
[11:50:49.224351] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7184 (0.7166)  time: 0.1854  data: 0.0001  max mem: 14938
[11:50:51.085011] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7170 (0.7167)  time: 0.1858  data: 0.0001  max mem: 14938
[11:50:52.949686] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7187 (0.7175)  time: 0.1862  data: 0.0001  max mem: 14938
[11:50:54.818053] Test:  [100/345]  eta: 0:00:45  loss: 0.7201 (0.7180)  time: 0.1866  data: 0.0001  max mem: 14938
[11:50:56.686533] Test:  [110/345]  eta: 0:00:43  loss: 0.7157 (0.7176)  time: 0.1868  data: 0.0001  max mem: 14938
[11:50:58.560301] Test:  [120/345]  eta: 0:00:41  loss: 0.7164 (0.7178)  time: 0.1871  data: 0.0001  max mem: 14938
[11:51:00.437786] Test:  [130/345]  eta: 0:00:40  loss: 0.7164 (0.7178)  time: 0.1875  data: 0.0001  max mem: 14938
[11:51:02.319876] Test:  [140/345]  eta: 0:00:38  loss: 0.7158 (0.7175)  time: 0.1879  data: 0.0001  max mem: 14938
[11:51:04.203093] Test:  [150/345]  eta: 0:00:36  loss: 0.7146 (0.7173)  time: 0.1882  data: 0.0001  max mem: 14938
[11:51:06.090036] Test:  [160/345]  eta: 0:00:34  loss: 0.7094 (0.7172)  time: 0.1885  data: 0.0001  max mem: 14938
[11:51:07.980907] Test:  [170/345]  eta: 0:00:32  loss: 0.7150 (0.7170)  time: 0.1888  data: 0.0001  max mem: 14938
[11:51:09.876904] Test:  [180/345]  eta: 0:00:30  loss: 0.7105 (0.7165)  time: 0.1893  data: 0.0001  max mem: 14938
[11:51:11.774801] Test:  [190/345]  eta: 0:00:29  loss: 0.7098 (0.7163)  time: 0.1896  data: 0.0001  max mem: 14938
[11:51:13.675586] Test:  [200/345]  eta: 0:00:27  loss: 0.7120 (0.7162)  time: 0.1899  data: 0.0001  max mem: 14938
[11:51:15.581055] Test:  [210/345]  eta: 0:00:25  loss: 0.7167 (0.7163)  time: 0.1903  data: 0.0001  max mem: 14938
[11:51:17.490034] Test:  [220/345]  eta: 0:00:23  loss: 0.7182 (0.7165)  time: 0.1906  data: 0.0001  max mem: 14938
[11:51:19.402268] Test:  [230/345]  eta: 0:00:21  loss: 0.7262 (0.7171)  time: 0.1910  data: 0.0001  max mem: 14938
[11:51:21.319058] Test:  [240/345]  eta: 0:00:19  loss: 0.7266 (0.7171)  time: 0.1914  data: 0.0001  max mem: 14938
[11:51:23.238466] Test:  [250/345]  eta: 0:00:17  loss: 0.7171 (0.7171)  time: 0.1918  data: 0.0001  max mem: 14938
[11:51:25.160322] Test:  [260/345]  eta: 0:00:16  loss: 0.7104 (0.7167)  time: 0.1920  data: 0.0001  max mem: 14938
[11:51:27.088354] Test:  [270/345]  eta: 0:00:14  loss: 0.7105 (0.7167)  time: 0.1924  data: 0.0001  max mem: 14938
[11:51:29.019006] Test:  [280/345]  eta: 0:00:12  loss: 0.7134 (0.7167)  time: 0.1929  data: 0.0001  max mem: 14938
[11:51:30.954492] Test:  [290/345]  eta: 0:00:10  loss: 0.7157 (0.7167)  time: 0.1932  data: 0.0001  max mem: 14938
[11:51:32.890315] Test:  [300/345]  eta: 0:00:08  loss: 0.7204 (0.7169)  time: 0.1935  data: 0.0001  max mem: 14938
[11:51:34.831650] Test:  [310/345]  eta: 0:00:06  loss: 0.7204 (0.7171)  time: 0.1938  data: 0.0001  max mem: 14938
[11:51:36.775668] Test:  [320/345]  eta: 0:00:04  loss: 0.7219 (0.7172)  time: 0.1942  data: 0.0001  max mem: 14938
[11:51:38.721341] Test:  [330/345]  eta: 0:00:02  loss: 0.7160 (0.7171)  time: 0.1944  data: 0.0001  max mem: 14938
[11:51:40.670386] Test:  [340/345]  eta: 0:00:00  loss: 0.7109 (0.7171)  time: 0.1947  data: 0.0001  max mem: 14938
[11:51:41.451610] Test:  [344/345]  eta: 0:00:00  loss: 0.7109 (0.7170)  time: 0.1948  data: 0.0001  max mem: 14938
[11:51:41.512230] Test: Total time: 0:01:05 (0.1900 s / it)
[11:51:51.929441] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8328 (0.8328)  time: 0.3171  data: 0.1379  max mem: 14938
[11:51:53.744263] Test:  [10/57]  eta: 0:00:09  loss: 0.8565 (0.8706)  time: 0.1938  data: 0.0126  max mem: 14938
[11:51:55.565728] Test:  [20/57]  eta: 0:00:06  loss: 0.8600 (0.8636)  time: 0.1818  data: 0.0001  max mem: 14938
[11:51:57.388782] Test:  [30/57]  eta: 0:00:05  loss: 0.7537 (0.8243)  time: 0.1822  data: 0.0001  max mem: 14938
[11:51:59.217439] Test:  [40/57]  eta: 0:00:03  loss: 0.7441 (0.8046)  time: 0.1825  data: 0.0001  max mem: 14938
[11:52:01.051036] Test:  [50/57]  eta: 0:00:01  loss: 0.7330 (0.7968)  time: 0.1831  data: 0.0001  max mem: 14938
[11:52:02.040207] Test:  [56/57]  eta: 0:00:00  loss: 0.7558 (0.8016)  time: 0.1777  data: 0.0001  max mem: 14938
[11:52:02.099367] Test: Total time: 0:00:10 (0.1840 s / it)
[11:52:03.854085] Dice score of the network on the train images: 0.809147, val images: 0.819315
[11:52:03.858410] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:52:04.741799] Epoch: [28]  [  0/345]  eta: 0:05:04  lr: 0.000104  loss: 0.7294 (0.7294)  time: 0.8824  data: 0.1423  max mem: 14938
[11:52:19.645560] Epoch: [28]  [ 20/345]  eta: 0:04:04  lr: 0.000104  loss: 0.7463 (0.7467)  time: 0.7451  data: 0.0001  max mem: 14938
[11:52:34.593390] Epoch: [28]  [ 40/345]  eta: 0:03:48  lr: 0.000104  loss: 0.7462 (0.7475)  time: 0.7473  data: 0.0001  max mem: 14938
[11:52:49.551699] Epoch: [28]  [ 60/345]  eta: 0:03:33  lr: 0.000103  loss: 0.7354 (0.7452)  time: 0.7479  data: 0.0001  max mem: 14938
[11:53:04.548403] Epoch: [28]  [ 80/345]  eta: 0:03:18  lr: 0.000103  loss: 0.7450 (0.7456)  time: 0.7498  data: 0.0001  max mem: 14938
[11:53:19.557928] Epoch: [28]  [100/345]  eta: 0:03:03  lr: 0.000103  loss: 0.7462 (0.7461)  time: 0.7504  data: 0.0001  max mem: 14938
[11:53:34.587332] Epoch: [28]  [120/345]  eta: 0:02:48  lr: 0.000103  loss: 0.7443 (0.7458)  time: 0.7514  data: 0.0001  max mem: 14938
[11:53:49.612563] Epoch: [28]  [140/345]  eta: 0:02:33  lr: 0.000102  loss: 0.7419 (0.7455)  time: 0.7512  data: 0.0001  max mem: 14938
[11:54:04.630720] Epoch: [28]  [160/345]  eta: 0:02:18  lr: 0.000102  loss: 0.7353 (0.7448)  time: 0.7509  data: 0.0001  max mem: 14938
[11:54:19.641490] Epoch: [28]  [180/345]  eta: 0:02:03  lr: 0.000102  loss: 0.7473 (0.7454)  time: 0.7505  data: 0.0001  max mem: 14938
[11:54:34.643538] Epoch: [28]  [200/345]  eta: 0:01:48  lr: 0.000101  loss: 0.7429 (0.7452)  time: 0.7501  data: 0.0001  max mem: 14938
[11:54:49.634197] Epoch: [28]  [220/345]  eta: 0:01:33  lr: 0.000101  loss: 0.7388 (0.7446)  time: 0.7495  data: 0.0001  max mem: 14938
[11:55:04.623016] Epoch: [28]  [240/345]  eta: 0:01:18  lr: 0.000101  loss: 0.7390 (0.7443)  time: 0.7494  data: 0.0001  max mem: 14938
[11:55:19.612802] Epoch: [28]  [260/345]  eta: 0:01:03  lr: 0.000101  loss: 0.7408 (0.7440)  time: 0.7494  data: 0.0001  max mem: 14938
[11:55:34.608731] Epoch: [28]  [280/345]  eta: 0:00:48  lr: 0.000100  loss: 0.7397 (0.7438)  time: 0.7497  data: 0.0001  max mem: 14938
[11:55:49.585057] Epoch: [28]  [300/345]  eta: 0:00:33  lr: 0.000100  loss: 0.7347 (0.7433)  time: 0.7488  data: 0.0001  max mem: 14938
[11:56:04.563523] Epoch: [28]  [320/345]  eta: 0:00:18  lr: 0.000100  loss: 0.7419 (0.7433)  time: 0.7489  data: 0.0001  max mem: 14938
[11:56:19.540348] Epoch: [28]  [340/345]  eta: 0:00:03  lr: 0.000099  loss: 0.7373 (0.7432)  time: 0.7488  data: 0.0001  max mem: 14938
[11:56:22.537150] Epoch: [28]  [344/345]  eta: 0:00:00  lr: 0.000099  loss: 0.7347 (0.7431)  time: 0.7490  data: 0.0001  max mem: 14938
[11:56:22.602698] Epoch: [28] Total time: 0:04:18 (0.7500 s / it)
[11:56:22.602861] Averaged stats: lr: 0.000099  loss: 0.7347 (0.7431)
[11:56:22.936713] Test:  [  0/345]  eta: 0:01:53  loss: 0.7177 (0.7177)  time: 0.3294  data: 0.1479  max mem: 14938
[11:56:24.774213] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7106 (0.7142)  time: 0.1969  data: 0.0135  max mem: 14938
[11:56:26.613274] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7147 (0.7161)  time: 0.1838  data: 0.0001  max mem: 14938
[11:56:28.454929] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7162 (0.7171)  time: 0.1840  data: 0.0001  max mem: 14938
[11:56:30.300053] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7133 (0.7168)  time: 0.1843  data: 0.0001  max mem: 14938
[11:56:32.150170] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7113 (0.7151)  time: 0.1847  data: 0.0001  max mem: 14938
[11:56:34.003288] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7023 (0.7126)  time: 0.1851  data: 0.0001  max mem: 14938
[11:56:35.859796] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7048 (0.7128)  time: 0.1854  data: 0.0001  max mem: 14938
[11:56:37.719175] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7117 (0.7123)  time: 0.1857  data: 0.0001  max mem: 14938
[11:56:39.584617] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7055 (0.7116)  time: 0.1862  data: 0.0001  max mem: 14938
[11:56:41.451958] Test:  [100/345]  eta: 0:00:45  loss: 0.7096 (0.7121)  time: 0.1866  data: 0.0001  max mem: 14938
[11:56:43.322073] Test:  [110/345]  eta: 0:00:43  loss: 0.7186 (0.7122)  time: 0.1868  data: 0.0001  max mem: 14938
[11:56:45.195752] Test:  [120/345]  eta: 0:00:41  loss: 0.7151 (0.7125)  time: 0.1871  data: 0.0001  max mem: 14938
[11:56:47.073045] Test:  [130/345]  eta: 0:00:40  loss: 0.7151 (0.7133)  time: 0.1875  data: 0.0001  max mem: 14938
[11:56:48.953531] Test:  [140/345]  eta: 0:00:38  loss: 0.7130 (0.7128)  time: 0.1878  data: 0.0001  max mem: 14938
[11:56:50.838304] Test:  [150/345]  eta: 0:00:36  loss: 0.7054 (0.7126)  time: 0.1882  data: 0.0001  max mem: 14938
[11:56:52.726297] Test:  [160/345]  eta: 0:00:34  loss: 0.7106 (0.7125)  time: 0.1886  data: 0.0001  max mem: 14938
[11:56:54.618222] Test:  [170/345]  eta: 0:00:32  loss: 0.7126 (0.7131)  time: 0.1889  data: 0.0001  max mem: 14938
[11:56:56.513039] Test:  [180/345]  eta: 0:00:30  loss: 0.7126 (0.7131)  time: 0.1893  data: 0.0001  max mem: 14938
[11:56:58.412224] Test:  [190/345]  eta: 0:00:29  loss: 0.7054 (0.7128)  time: 0.1896  data: 0.0001  max mem: 14938
[11:57:00.313417] Test:  [200/345]  eta: 0:00:27  loss: 0.7054 (0.7126)  time: 0.1900  data: 0.0001  max mem: 14938
[11:57:02.218817] Test:  [210/345]  eta: 0:00:25  loss: 0.7095 (0.7127)  time: 0.1903  data: 0.0001  max mem: 14938
[11:57:04.126051] Test:  [220/345]  eta: 0:00:23  loss: 0.7154 (0.7127)  time: 0.1906  data: 0.0001  max mem: 14938
[11:57:06.039582] Test:  [230/345]  eta: 0:00:21  loss: 0.7154 (0.7127)  time: 0.1910  data: 0.0001  max mem: 14938
[11:57:07.957608] Test:  [240/345]  eta: 0:00:19  loss: 0.7116 (0.7127)  time: 0.1915  data: 0.0001  max mem: 14938
[11:57:09.876911] Test:  [250/345]  eta: 0:00:17  loss: 0.7119 (0.7128)  time: 0.1918  data: 0.0001  max mem: 14938
[11:57:11.802028] Test:  [260/345]  eta: 0:00:16  loss: 0.7027 (0.7124)  time: 0.1922  data: 0.0001  max mem: 14938
[11:57:13.730451] Test:  [270/345]  eta: 0:00:14  loss: 0.7024 (0.7121)  time: 0.1926  data: 0.0001  max mem: 14938
[11:57:15.661683] Test:  [280/345]  eta: 0:00:12  loss: 0.7056 (0.7121)  time: 0.1929  data: 0.0001  max mem: 14938
[11:57:17.594802] Test:  [290/345]  eta: 0:00:10  loss: 0.7116 (0.7123)  time: 0.1932  data: 0.0001  max mem: 14938
[11:57:19.533215] Test:  [300/345]  eta: 0:00:08  loss: 0.7078 (0.7121)  time: 0.1935  data: 0.0001  max mem: 14938
[11:57:21.474005] Test:  [310/345]  eta: 0:00:06  loss: 0.7018 (0.7119)  time: 0.1939  data: 0.0001  max mem: 14938
[11:57:23.417417] Test:  [320/345]  eta: 0:00:04  loss: 0.7083 (0.7118)  time: 0.1942  data: 0.0001  max mem: 14938
[11:57:25.363673] Test:  [330/345]  eta: 0:00:02  loss: 0.7134 (0.7119)  time: 0.1944  data: 0.0001  max mem: 14938
[11:57:27.311866] Test:  [340/345]  eta: 0:00:00  loss: 0.7172 (0.7121)  time: 0.1947  data: 0.0001  max mem: 14938
[11:57:28.093470] Test:  [344/345]  eta: 0:00:00  loss: 0.7181 (0.7121)  time: 0.1948  data: 0.0001  max mem: 14938
[11:57:28.153005] Test: Total time: 0:01:05 (0.1900 s / it)
[11:57:38.505307] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8336 (0.8336)  time: 0.3173  data: 0.1374  max mem: 14938
[11:57:40.321553] Test:  [10/57]  eta: 0:00:09  loss: 0.8739 (0.8708)  time: 0.1939  data: 0.0126  max mem: 14938
[11:57:42.140927] Test:  [20/57]  eta: 0:00:06  loss: 0.8791 (0.8641)  time: 0.1817  data: 0.0001  max mem: 14938
[11:57:43.964136] Test:  [30/57]  eta: 0:00:05  loss: 0.7481 (0.8228)  time: 0.1821  data: 0.0001  max mem: 14938
[11:57:45.791130] Test:  [40/57]  eta: 0:00:03  loss: 0.7378 (0.8020)  time: 0.1825  data: 0.0001  max mem: 14938
[11:57:47.626591] Test:  [50/57]  eta: 0:00:01  loss: 0.7345 (0.7942)  time: 0.1831  data: 0.0001  max mem: 14938
[11:57:48.615313] Test:  [56/57]  eta: 0:00:00  loss: 0.7438 (0.7996)  time: 0.1777  data: 0.0001  max mem: 14938
[11:57:48.674376] Test: Total time: 0:00:10 (0.1840 s / it)
[11:57:50.399512] Dice score of the network on the train images: 0.811970, val images: 0.823037
[11:57:50.399745] saving best_dice_model_0 @ epoch 28
[11:57:51.606306] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[11:57:52.493428] Epoch: [29]  [  0/345]  eta: 0:05:05  lr: 0.000099  loss: 0.7350 (0.7350)  time: 0.8860  data: 0.1446  max mem: 14938
[11:58:07.382459] Epoch: [29]  [ 20/345]  eta: 0:04:04  lr: 0.000099  loss: 0.7299 (0.7314)  time: 0.7444  data: 0.0001  max mem: 14938
[11:58:22.336319] Epoch: [29]  [ 40/345]  eta: 0:03:48  lr: 0.000099  loss: 0.7362 (0.7352)  time: 0.7476  data: 0.0001  max mem: 14938
[11:58:37.302960] Epoch: [29]  [ 60/345]  eta: 0:03:33  lr: 0.000098  loss: 0.7331 (0.7355)  time: 0.7483  data: 0.0001  max mem: 14938
[11:58:52.303569] Epoch: [29]  [ 80/345]  eta: 0:03:18  lr: 0.000098  loss: 0.7359 (0.7357)  time: 0.7500  data: 0.0001  max mem: 14938
[11:59:07.322392] Epoch: [29]  [100/345]  eta: 0:03:03  lr: 0.000098  loss: 0.7331 (0.7355)  time: 0.7509  data: 0.0001  max mem: 14938
[11:59:22.350662] Epoch: [29]  [120/345]  eta: 0:02:48  lr: 0.000097  loss: 0.7301 (0.7349)  time: 0.7514  data: 0.0001  max mem: 14938
[11:59:37.376623] Epoch: [29]  [140/345]  eta: 0:02:33  lr: 0.000097  loss: 0.7358 (0.7347)  time: 0.7513  data: 0.0001  max mem: 14938
[11:59:52.397842] Epoch: [29]  [160/345]  eta: 0:02:18  lr: 0.000097  loss: 0.7306 (0.7351)  time: 0.7510  data: 0.0001  max mem: 14938
[12:00:07.409157] Epoch: [29]  [180/345]  eta: 0:02:03  lr: 0.000096  loss: 0.7348 (0.7348)  time: 0.7505  data: 0.0001  max mem: 14938
[12:00:22.420939] Epoch: [29]  [200/345]  eta: 0:01:48  lr: 0.000096  loss: 0.7363 (0.7351)  time: 0.7506  data: 0.0001  max mem: 14938
[12:00:37.420708] Epoch: [29]  [220/345]  eta: 0:01:33  lr: 0.000096  loss: 0.7342 (0.7353)  time: 0.7500  data: 0.0001  max mem: 14938
[12:00:52.417258] Epoch: [29]  [240/345]  eta: 0:01:18  lr: 0.000095  loss: 0.7315 (0.7352)  time: 0.7498  data: 0.0001  max mem: 14938
[12:01:07.413465] Epoch: [29]  [260/345]  eta: 0:01:03  lr: 0.000095  loss: 0.7349 (0.7352)  time: 0.7498  data: 0.0001  max mem: 14938
[12:01:22.400404] Epoch: [29]  [280/345]  eta: 0:00:48  lr: 0.000095  loss: 0.7321 (0.7350)  time: 0.7493  data: 0.0001  max mem: 14938
[12:01:37.387671] Epoch: [29]  [300/345]  eta: 0:00:33  lr: 0.000094  loss: 0.7305 (0.7348)  time: 0.7493  data: 0.0001  max mem: 14938
[12:01:52.358337] Epoch: [29]  [320/345]  eta: 0:00:18  lr: 0.000094  loss: 0.7372 (0.7351)  time: 0.7485  data: 0.0001  max mem: 14938
[12:02:07.316175] Epoch: [29]  [340/345]  eta: 0:00:03  lr: 0.000094  loss: 0.7390 (0.7354)  time: 0.7479  data: 0.0001  max mem: 14938
[12:02:10.310793] Epoch: [29]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.7367 (0.7353)  time: 0.7479  data: 0.0001  max mem: 14938
[12:02:10.374833] Epoch: [29] Total time: 0:04:18 (0.7501 s / it)
[12:02:10.375239] Averaged stats: lr: 0.000094  loss: 0.7367 (0.7353)
[12:02:10.710829] Test:  [  0/345]  eta: 0:01:53  loss: 0.7051 (0.7051)  time: 0.3295  data: 0.1483  max mem: 14938
[12:02:12.548795] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7147 (0.7131)  time: 0.1968  data: 0.0135  max mem: 14938
[12:02:14.387406] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7125 (0.7123)  time: 0.1837  data: 0.0001  max mem: 14938
[12:02:16.229953] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7082 (0.7118)  time: 0.1840  data: 0.0001  max mem: 14938
[12:02:18.074703] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7152 (0.7138)  time: 0.1843  data: 0.0001  max mem: 14938
[12:02:19.925920] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7161 (0.7138)  time: 0.1847  data: 0.0001  max mem: 14938
[12:02:21.778452] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7122 (0.7141)  time: 0.1851  data: 0.0001  max mem: 14938
[12:02:23.634064] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7122 (0.7136)  time: 0.1854  data: 0.0001  max mem: 14938
[12:02:25.492480] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7142 (0.7137)  time: 0.1857  data: 0.0001  max mem: 14938
[12:02:27.355086] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7115 (0.7133)  time: 0.1860  data: 0.0001  max mem: 14938
[12:02:29.222051] Test:  [100/345]  eta: 0:00:45  loss: 0.7135 (0.7135)  time: 0.1864  data: 0.0001  max mem: 14938
[12:02:31.091882] Test:  [110/345]  eta: 0:00:43  loss: 0.7073 (0.7125)  time: 0.1868  data: 0.0001  max mem: 14938
[12:02:32.963725] Test:  [120/345]  eta: 0:00:41  loss: 0.7019 (0.7116)  time: 0.1870  data: 0.0001  max mem: 14938
[12:02:34.841305] Test:  [130/345]  eta: 0:00:40  loss: 0.7050 (0.7118)  time: 0.1874  data: 0.0001  max mem: 14938
[12:02:36.722017] Test:  [140/345]  eta: 0:00:38  loss: 0.7129 (0.7117)  time: 0.1879  data: 0.0001  max mem: 14938
[12:02:38.605538] Test:  [150/345]  eta: 0:00:36  loss: 0.7091 (0.7117)  time: 0.1882  data: 0.0001  max mem: 14938
[12:02:40.491629] Test:  [160/345]  eta: 0:00:34  loss: 0.7065 (0.7116)  time: 0.1884  data: 0.0001  max mem: 14938
[12:02:42.381844] Test:  [170/345]  eta: 0:00:32  loss: 0.7074 (0.7114)  time: 0.1888  data: 0.0001  max mem: 14938
[12:02:44.276501] Test:  [180/345]  eta: 0:00:30  loss: 0.7074 (0.7112)  time: 0.1892  data: 0.0001  max mem: 14938
[12:02:46.176254] Test:  [190/345]  eta: 0:00:29  loss: 0.7121 (0.7114)  time: 0.1897  data: 0.0001  max mem: 14938
[12:02:48.077835] Test:  [200/345]  eta: 0:00:27  loss: 0.7121 (0.7114)  time: 0.1900  data: 0.0001  max mem: 14938
[12:02:49.983295] Test:  [210/345]  eta: 0:00:25  loss: 0.7050 (0.7113)  time: 0.1903  data: 0.0001  max mem: 14938
[12:02:51.893722] Test:  [220/345]  eta: 0:00:23  loss: 0.7076 (0.7113)  time: 0.1907  data: 0.0001  max mem: 14938
[12:02:53.808262] Test:  [230/345]  eta: 0:00:21  loss: 0.7076 (0.7111)  time: 0.1912  data: 0.0001  max mem: 14938
[12:02:55.724656] Test:  [240/345]  eta: 0:00:19  loss: 0.7075 (0.7111)  time: 0.1915  data: 0.0001  max mem: 14938
[12:02:57.645346] Test:  [250/345]  eta: 0:00:17  loss: 0.7095 (0.7112)  time: 0.1918  data: 0.0001  max mem: 14938
[12:02:59.567106] Test:  [260/345]  eta: 0:00:16  loss: 0.7093 (0.7110)  time: 0.1921  data: 0.0001  max mem: 14938
[12:03:01.494427] Test:  [270/345]  eta: 0:00:14  loss: 0.7057 (0.7109)  time: 0.1924  data: 0.0001  max mem: 14938
[12:03:03.425634] Test:  [280/345]  eta: 0:00:12  loss: 0.7048 (0.7108)  time: 0.1929  data: 0.0001  max mem: 14938
[12:03:05.358500] Test:  [290/345]  eta: 0:00:10  loss: 0.7072 (0.7108)  time: 0.1932  data: 0.0001  max mem: 14938
[12:03:07.297656] Test:  [300/345]  eta: 0:00:08  loss: 0.7072 (0.7106)  time: 0.1936  data: 0.0001  max mem: 14938
[12:03:09.240971] Test:  [310/345]  eta: 0:00:06  loss: 0.7062 (0.7106)  time: 0.1941  data: 0.0001  max mem: 14938
[12:03:11.184180] Test:  [320/345]  eta: 0:00:04  loss: 0.7071 (0.7107)  time: 0.1943  data: 0.0001  max mem: 14938
[12:03:13.133204] Test:  [330/345]  eta: 0:00:02  loss: 0.7071 (0.7109)  time: 0.1946  data: 0.0001  max mem: 14938
[12:03:15.081921] Test:  [340/345]  eta: 0:00:00  loss: 0.7069 (0.7108)  time: 0.1948  data: 0.0001  max mem: 14938
[12:03:15.863654] Test:  [344/345]  eta: 0:00:00  loss: 0.7042 (0.7107)  time: 0.1949  data: 0.0001  max mem: 14938
[12:03:15.923770] Test: Total time: 0:01:05 (0.1900 s / it)
[12:03:26.307563] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8074 (0.8074)  time: 0.3180  data: 0.1382  max mem: 14938
[12:03:28.124176] Test:  [10/57]  eta: 0:00:09  loss: 0.8632 (0.8632)  time: 0.1940  data: 0.0126  max mem: 14938
[12:03:29.946060] Test:  [20/57]  eta: 0:00:06  loss: 0.8632 (0.8598)  time: 0.1819  data: 0.0001  max mem: 14938
[12:03:31.771242] Test:  [30/57]  eta: 0:00:05  loss: 0.7546 (0.8201)  time: 0.1823  data: 0.0001  max mem: 14938
[12:03:33.600336] Test:  [40/57]  eta: 0:00:03  loss: 0.7429 (0.8005)  time: 0.1827  data: 0.0001  max mem: 14938
[12:03:35.435293] Test:  [50/57]  eta: 0:00:01  loss: 0.7360 (0.7929)  time: 0.1831  data: 0.0001  max mem: 14938
[12:03:36.424091] Test:  [56/57]  eta: 0:00:00  loss: 0.7520 (0.7994)  time: 0.1777  data: 0.0001  max mem: 14938
[12:03:36.478015] Test: Total time: 0:00:10 (0.1840 s / it)
[12:03:38.222654] Dice score of the network on the train images: 0.808294, val images: 0.818206
[12:03:38.226512] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:03:39.111498] Epoch: [30]  [  0/345]  eta: 0:05:05  lr: 0.000094  loss: 0.7173 (0.7173)  time: 0.8841  data: 0.1422  max mem: 14938
[12:03:53.995128] Epoch: [30]  [ 20/345]  eta: 0:04:04  lr: 0.000093  loss: 0.7280 (0.7295)  time: 0.7441  data: 0.0001  max mem: 14938
[12:04:08.915242] Epoch: [30]  [ 40/345]  eta: 0:03:48  lr: 0.000093  loss: 0.7312 (0.7299)  time: 0.7460  data: 0.0001  max mem: 14938
[12:04:23.869455] Epoch: [30]  [ 60/345]  eta: 0:03:33  lr: 0.000093  loss: 0.7247 (0.7293)  time: 0.7477  data: 0.0001  max mem: 14938
[12:04:38.847633] Epoch: [30]  [ 80/345]  eta: 0:03:18  lr: 0.000092  loss: 0.7237 (0.7289)  time: 0.7489  data: 0.0001  max mem: 14938
[12:04:53.840757] Epoch: [30]  [100/345]  eta: 0:03:03  lr: 0.000092  loss: 0.7277 (0.7286)  time: 0.7496  data: 0.0001  max mem: 14938
[12:05:08.872412] Epoch: [30]  [120/345]  eta: 0:02:48  lr: 0.000092  loss: 0.7325 (0.7288)  time: 0.7515  data: 0.0001  max mem: 14938
[12:05:23.897260] Epoch: [30]  [140/345]  eta: 0:02:33  lr: 0.000091  loss: 0.7365 (0.7299)  time: 0.7512  data: 0.0001  max mem: 14938
[12:05:38.911350] Epoch: [30]  [160/345]  eta: 0:02:18  lr: 0.000091  loss: 0.7331 (0.7302)  time: 0.7507  data: 0.0001  max mem: 14938
[12:05:54.061734] Epoch: [30]  [180/345]  eta: 0:02:03  lr: 0.000091  loss: 0.7379 (0.7309)  time: 0.7575  data: 0.0001  max mem: 14938
[12:06:09.075674] Epoch: [30]  [200/345]  eta: 0:01:48  lr: 0.000090  loss: 0.7446 (0.7321)  time: 0.7506  data: 0.0001  max mem: 14938
[12:06:24.079128] Epoch: [30]  [220/345]  eta: 0:01:33  lr: 0.000090  loss: 0.7313 (0.7322)  time: 0.7501  data: 0.0001  max mem: 14938
[12:06:39.073636] Epoch: [30]  [240/345]  eta: 0:01:18  lr: 0.000090  loss: 0.7274 (0.7322)  time: 0.7497  data: 0.0001  max mem: 14938
[12:06:54.070362] Epoch: [30]  [260/345]  eta: 0:01:03  lr: 0.000089  loss: 0.7316 (0.7324)  time: 0.7498  data: 0.0001  max mem: 14938
[12:07:09.066688] Epoch: [30]  [280/345]  eta: 0:00:48  lr: 0.000089  loss: 0.7314 (0.7326)  time: 0.7498  data: 0.0001  max mem: 14938
[12:07:24.053476] Epoch: [30]  [300/345]  eta: 0:00:33  lr: 0.000089  loss: 0.7317 (0.7325)  time: 0.7493  data: 0.0001  max mem: 14938
[12:07:39.026359] Epoch: [30]  [320/345]  eta: 0:00:18  lr: 0.000088  loss: 0.7288 (0.7322)  time: 0.7486  data: 0.0001  max mem: 14938

[12:07:54.013474] Epoch: [30]  [340/345]  eta: 0:00:03  lr: 0.000088  loss: 0.7321 (0.7323)  time: 0.7493  data: 0.0001  max mem: 14938
[12:07:57.007310] Epoch: [30]  [344/345]  eta: 0:00:00  lr: 0.000088  loss: 0.7300 (0.7322)  time: 0.7491  data: 0.0001  max mem: 14938
[12:07:57.071112] Epoch: [30] Total time: 0:04:18 (0.7503 s / it)
[12:07:57.071416] Averaged stats: lr: 0.000088  loss: 0.7300 (0.7322)
[12:07:57.402937] Test:  [  0/345]  eta: 0:01:52  loss: 0.7288 (0.7288)  time: 0.3262  data: 0.1445  max mem: 14938
[12:07:59.240541] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7232 (0.7175)  time: 0.1966  data: 0.0132  max mem: 14938
[12:08:01.078865] Test:  [ 20/345]  eta: 0:01:01  loss: 0.7077 (0.7120)  time: 0.1837  data: 0.0001  max mem: 14938
[12:08:02.920936] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7042 (0.7091)  time: 0.1840  data: 0.0001  max mem: 14938
[12:08:04.765434] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7020 (0.7073)  time: 0.1843  data: 0.0001  max mem: 14938
[12:08:06.614779] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7006 (0.7070)  time: 0.1846  data: 0.0001  max mem: 14938
[12:08:08.467858] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7006 (0.7076)  time: 0.1851  data: 0.0001  max mem: 14938
[12:08:10.324564] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7036 (0.7071)  time: 0.1854  data: 0.0001  max mem: 14938
[12:08:12.182853] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7043 (0.7064)  time: 0.1857  data: 0.0001  max mem: 14938
[12:08:14.046344] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7081 (0.7072)  time: 0.1860  data: 0.0001  max mem: 14938
[12:08:15.913112] Test:  [100/345]  eta: 0:00:45  loss: 0.7073 (0.7069)  time: 0.1865  data: 0.0001  max mem: 14938
[12:08:17.782325] Test:  [110/345]  eta: 0:00:43  loss: 0.6986 (0.7061)  time: 0.1867  data: 0.0001  max mem: 14938
[12:08:19.656883] Test:  [120/345]  eta: 0:00:41  loss: 0.6986 (0.7058)  time: 0.1871  data: 0.0001  max mem: 14938
[12:08:21.534917] Test:  [130/345]  eta: 0:00:40  loss: 0.7051 (0.7062)  time: 0.1876  data: 0.0001  max mem: 14938
[12:08:23.415214] Test:  [140/345]  eta: 0:00:38  loss: 0.7144 (0.7067)  time: 0.1879  data: 0.0001  max mem: 14938
[12:08:25.299094] Test:  [150/345]  eta: 0:00:36  loss: 0.7086 (0.7067)  time: 0.1882  data: 0.0001  max mem: 14938
[12:08:27.185757] Test:  [160/345]  eta: 0:00:34  loss: 0.7055 (0.7068)  time: 0.1885  data: 0.0001  max mem: 14938
[12:08:29.076088] Test:  [170/345]  eta: 0:00:32  loss: 0.7038 (0.7064)  time: 0.1888  data: 0.0001  max mem: 14938
[12:08:30.973296] Test:  [180/345]  eta: 0:00:30  loss: 0.7006 (0.7063)  time: 0.1893  data: 0.0001  max mem: 14938
[12:08:32.873132] Test:  [190/345]  eta: 0:00:29  loss: 0.7096 (0.7065)  time: 0.1898  data: 0.0001  max mem: 14938
[12:08:34.776302] Test:  [200/345]  eta: 0:00:27  loss: 0.7097 (0.7066)  time: 0.1901  data: 0.0001  max mem: 14938
[12:08:36.680227] Test:  [210/345]  eta: 0:00:25  loss: 0.7040 (0.7067)  time: 0.1903  data: 0.0001  max mem: 14938
[12:08:38.588185] Test:  [220/345]  eta: 0:00:23  loss: 0.7078 (0.7068)  time: 0.1905  data: 0.0001  max mem: 14938
[12:08:40.500773] Test:  [230/345]  eta: 0:00:21  loss: 0.7037 (0.7067)  time: 0.1910  data: 0.0001  max mem: 14938
[12:08:42.419643] Test:  [240/345]  eta: 0:00:19  loss: 0.6986 (0.7064)  time: 0.1915  data: 0.0001  max mem: 14938
[12:08:44.340069] Test:  [250/345]  eta: 0:00:17  loss: 0.7031 (0.7065)  time: 0.1919  data: 0.0001  max mem: 14938
[12:08:46.261508] Test:  [260/345]  eta: 0:00:16  loss: 0.7104 (0.7068)  time: 0.1920  data: 0.0001  max mem: 14938
[12:08:48.187940] Test:  [270/345]  eta: 0:00:14  loss: 0.7152 (0.7070)  time: 0.1923  data: 0.0001  max mem: 14938
[12:08:50.120230] Test:  [280/345]  eta: 0:00:12  loss: 0.7048 (0.7068)  time: 0.1929  data: 0.0001  max mem: 14938
[12:08:52.052592] Test:  [290/345]  eta: 0:00:10  loss: 0.7046 (0.7069)  time: 0.1932  data: 0.0001  max mem: 14938
[12:08:53.990986] Test:  [300/345]  eta: 0:00:08  loss: 0.7098 (0.7070)  time: 0.1935  data: 0.0001  max mem: 14938
[12:08:55.930994] Test:  [310/345]  eta: 0:00:06  loss: 0.7092 (0.7070)  time: 0.1939  data: 0.0001  max mem: 14938
[12:08:57.874114] Test:  [320/345]  eta: 0:00:04  loss: 0.7061 (0.7071)  time: 0.1941  data: 0.0001  max mem: 14938
[12:08:59.821870] Test:  [330/345]  eta: 0:00:02  loss: 0.7044 (0.7071)  time: 0.1945  data: 0.0001  max mem: 14938
[12:09:01.770591] Test:  [340/345]  eta: 0:00:00  loss: 0.7060 (0.7073)  time: 0.1948  data: 0.0001  max mem: 14938
[12:09:02.552281] Test:  [344/345]  eta: 0:00:00  loss: 0.7060 (0.7072)  time: 0.1949  data: 0.0001  max mem: 14938
[12:09:02.589850] Test: Total time: 0:01:05 (0.1899 s / it)
[12:09:12.850500] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8358 (0.8358)  time: 0.3179  data: 0.1380  max mem: 14938
[12:09:14.666642] Test:  [10/57]  eta: 0:00:09  loss: 0.8754 (0.8750)  time: 0.1939  data: 0.0126  max mem: 14938
[12:09:16.487549] Test:  [20/57]  eta: 0:00:06  loss: 0.8803 (0.8728)  time: 0.1818  data: 0.0001  max mem: 14938
[12:09:18.312012] Test:  [30/57]  eta: 0:00:05  loss: 0.7473 (0.8283)  time: 0.1822  data: 0.0001  max mem: 14938
[12:09:20.141403] Test:  [40/57]  eta: 0:00:03  loss: 0.7417 (0.8050)  time: 0.1826  data: 0.0001  max mem: 14938
[12:09:21.976842] Test:  [50/57]  eta: 0:00:01  loss: 0.7327 (0.7965)  time: 0.1832  data: 0.0001  max mem: 14938
[12:09:22.966691] Test:  [56/57]  eta: 0:00:00  loss: 0.7438 (0.8016)  time: 0.1778  data: 0.0001  max mem: 14938
[12:09:23.028043] Test: Total time: 0:00:10 (0.1841 s / it)
[12:09:24.832547] Dice score of the network on the train images: 0.814467, val images: 0.825632
[12:09:24.832779] saving best_dice_model_0 @ epoch 30
[12:09:25.921639] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:09:26.809103] Epoch: [31]  [  0/345]  eta: 0:05:05  lr: 0.000088  loss: 0.7254 (0.7254)  time: 0.8862  data: 0.1445  max mem: 14938
[12:09:41.671830] Epoch: [31]  [ 20/345]  eta: 0:04:03  lr: 0.000088  loss: 0.7269 (0.7304)  time: 0.7431  data: 0.0001  max mem: 14938
[12:09:56.588138] Epoch: [31]  [ 40/345]  eta: 0:03:48  lr: 0.000087  loss: 0.7216 (0.7288)  time: 0.7458  data: 0.0001  max mem: 14938
[12:10:11.533992] Epoch: [31]  [ 60/345]  eta: 0:03:33  lr: 0.000087  loss: 0.7374 (0.7317)  time: 0.7472  data: 0.0001  max mem: 14938
[12:10:26.507876] Epoch: [31]  [ 80/345]  eta: 0:03:18  lr: 0.000087  loss: 0.7333 (0.7322)  time: 0.7486  data: 0.0001  max mem: 14938
[12:10:41.641879] Epoch: [31]  [100/345]  eta: 0:03:03  lr: 0.000086  loss: 0.7270 (0.7321)  time: 0.7567  data: 0.0001  max mem: 14938
[12:10:56.673662] Epoch: [31]  [120/345]  eta: 0:02:48  lr: 0.000086  loss: 0.7254 (0.7313)  time: 0.7515  data: 0.0001  max mem: 14938
[12:11:11.705998] Epoch: [31]  [140/345]  eta: 0:02:33  lr: 0.000085  loss: 0.7328 (0.7313)  time: 0.7516  data: 0.0001  max mem: 14938
[12:11:26.730522] Epoch: [31]  [160/345]  eta: 0:02:18  lr: 0.000085  loss: 0.7309 (0.7312)  time: 0.7512  data: 0.0001  max mem: 14938
[12:11:41.744445] Epoch: [31]  [180/345]  eta: 0:02:03  lr: 0.000085  loss: 0.7545 (0.7339)  time: 0.7506  data: 0.0001  max mem: 14938
[12:11:56.752934] Epoch: [31]  [200/345]  eta: 0:01:48  lr: 0.000084  loss: 0.7409 (0.7354)  time: 0.7504  data: 0.0001  max mem: 14938
[12:12:11.752159] Epoch: [31]  [220/345]  eta: 0:01:33  lr: 0.000084  loss: 0.7396 (0.7358)  time: 0.7499  data: 0.0001  max mem: 14938
[12:12:26.749607] Epoch: [31]  [240/345]  eta: 0:01:18  lr: 0.000084  loss: 0.7309 (0.7355)  time: 0.7498  data: 0.0001  max mem: 14938
[12:12:41.733678] Epoch: [31]  [260/345]  eta: 0:01:03  lr: 0.000083  loss: 0.7331 (0.7356)  time: 0.7492  data: 0.0001  max mem: 14938
[12:12:56.717984] Epoch: [31]  [280/345]  eta: 0:00:48  lr: 0.000083  loss: 0.7302 (0.7354)  time: 0.7492  data: 0.0001  max mem: 14938
[12:13:11.709677] Epoch: [31]  [300/345]  eta: 0:00:33  lr: 0.000083  loss: 0.7360 (0.7355)  time: 0.7495  data: 0.0001  max mem: 14938
[12:13:26.689354] Epoch: [31]  [320/345]  eta: 0:00:18  lr: 0.000082  loss: 0.7302 (0.7352)  time: 0.7489  data: 0.0001  max mem: 14938
[12:13:41.671228] Epoch: [31]  [340/345]  eta: 0:00:03  lr: 0.000082  loss: 0.7308 (0.7350)  time: 0.7490  data: 0.0001  max mem: 14938
[12:13:44.667483] Epoch: [31]  [344/345]  eta: 0:00:00  lr: 0.000082  loss: 0.7271 (0.7350)  time: 0.7491  data: 0.0001  max mem: 14938
[12:13:44.732926] Epoch: [31] Total time: 0:04:18 (0.7502 s / it)
[12:13:44.733342] Averaged stats: lr: 0.000082  loss: 0.7271 (0.7350)
[12:13:45.073840] Test:  [  0/345]  eta: 0:01:55  loss: 0.7181 (0.7181)  time: 0.3362  data: 0.1542  max mem: 14938
[12:13:46.910680] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6981 (0.6998)  time: 0.1975  data: 0.0141  max mem: 14938
[12:13:48.749562] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6987 (0.7019)  time: 0.1837  data: 0.0001  max mem: 14938
[12:13:50.591382] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7075 (0.7032)  time: 0.1840  data: 0.0001  max mem: 14938
[12:13:52.435907] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7016 (0.7037)  time: 0.1843  data: 0.0001  max mem: 14938
[12:13:54.286874] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7018 (0.7040)  time: 0.1847  data: 0.0001  max mem: 14938
[12:13:56.139985] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7014 (0.7033)  time: 0.1852  data: 0.0001  max mem: 14938
[12:13:57.995751] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7014 (0.7041)  time: 0.1854  data: 0.0001  max mem: 14938
[12:13:59.854579] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7091 (0.7042)  time: 0.1857  data: 0.0001  max mem: 14938
[12:14:01.719051] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7044 (0.7042)  time: 0.1861  data: 0.0001  max mem: 14938
[12:14:03.586508] Test:  [100/345]  eta: 0:00:45  loss: 0.7047 (0.7044)  time: 0.1865  data: 0.0001  max mem: 14938
[12:14:05.455973] Test:  [110/345]  eta: 0:00:43  loss: 0.7041 (0.7045)  time: 0.1868  data: 0.0001  max mem: 14938
[12:14:07.330013] Test:  [120/345]  eta: 0:00:41  loss: 0.7016 (0.7041)  time: 0.1871  data: 0.0001  max mem: 14938
[12:14:09.207905] Test:  [130/345]  eta: 0:00:40  loss: 0.6978 (0.7040)  time: 0.1875  data: 0.0001  max mem: 14938
[12:14:11.089238] Test:  [140/345]  eta: 0:00:38  loss: 0.7006 (0.7043)  time: 0.1879  data: 0.0001  max mem: 14938
[12:14:12.972733] Test:  [150/345]  eta: 0:00:36  loss: 0.7090 (0.7044)  time: 0.1882  data: 0.0001  max mem: 14938
[12:14:14.858717] Test:  [160/345]  eta: 0:00:34  loss: 0.7109 (0.7047)  time: 0.1884  data: 0.0001  max mem: 14938
[12:14:16.749775] Test:  [170/345]  eta: 0:00:32  loss: 0.7093 (0.7051)  time: 0.1888  data: 0.0001  max mem: 14938
[12:14:18.645492] Test:  [180/345]  eta: 0:00:30  loss: 0.7096 (0.7054)  time: 0.1893  data: 0.0001  max mem: 14938
[12:14:20.543345] Test:  [190/345]  eta: 0:00:29  loss: 0.7096 (0.7051)  time: 0.1896  data: 0.0001  max mem: 14938
[12:14:22.443192] Test:  [200/345]  eta: 0:00:27  loss: 0.7042 (0.7053)  time: 0.1898  data: 0.0001  max mem: 14938
[12:14:24.347476] Test:  [210/345]  eta: 0:00:25  loss: 0.7058 (0.7052)  time: 0.1902  data: 0.0001  max mem: 14938
[12:14:26.256442] Test:  [220/345]  eta: 0:00:23  loss: 0.7031 (0.7051)  time: 0.1906  data: 0.0001  max mem: 14938
[12:14:28.169951] Test:  [230/345]  eta: 0:00:21  loss: 0.6983 (0.7050)  time: 0.1911  data: 0.0001  max mem: 14938
[12:14:30.087499] Test:  [240/345]  eta: 0:00:19  loss: 0.6985 (0.7049)  time: 0.1915  data: 0.0001  max mem: 14938
[12:14:32.009419] Test:  [250/345]  eta: 0:00:17  loss: 0.7045 (0.7050)  time: 0.1919  data: 0.0001  max mem: 14938
[12:14:33.934271] Test:  [260/345]  eta: 0:00:16  loss: 0.7068 (0.7050)  time: 0.1923  data: 0.0001  max mem: 14938
[12:14:35.861989] Test:  [270/345]  eta: 0:00:14  loss: 0.7062 (0.7052)  time: 0.1926  data: 0.0001  max mem: 14938
[12:14:37.791667] Test:  [280/345]  eta: 0:00:12  loss: 0.7051 (0.7050)  time: 0.1928  data: 0.0001  max mem: 14938
[12:14:39.726132] Test:  [290/345]  eta: 0:00:10  loss: 0.7008 (0.7050)  time: 0.1932  data: 0.0001  max mem: 14938
[12:14:41.662898] Test:  [300/345]  eta: 0:00:08  loss: 0.7048 (0.7051)  time: 0.1935  data: 0.0001  max mem: 14938
[12:14:43.603120] Test:  [310/345]  eta: 0:00:06  loss: 0.6987 (0.7049)  time: 0.1938  data: 0.0001  max mem: 14938
[12:14:45.546123] Test:  [320/345]  eta: 0:00:04  loss: 0.7037 (0.7051)  time: 0.1941  data: 0.0001  max mem: 14938
[12:14:47.491468] Test:  [330/345]  eta: 0:00:02  loss: 0.7058 (0.7051)  time: 0.1944  data: 0.0001  max mem: 14938
[12:14:49.441359] Test:  [340/345]  eta: 0:00:00  loss: 0.7049 (0.7051)  time: 0.1947  data: 0.0001  max mem: 14938
[12:14:50.224237] Test:  [344/345]  eta: 0:00:00  loss: 0.7062 (0.7052)  time: 0.1949  data: 0.0001  max mem: 14938
[12:14:50.284279] Test: Total time: 0:01:05 (0.1900 s / it)
[12:15:00.685939] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8362 (0.8362)  time: 0.3179  data: 0.1382  max mem: 14938
[12:15:02.503186] Test:  [10/57]  eta: 0:00:09  loss: 0.8866 (0.8768)  time: 0.1940  data: 0.0126  max mem: 14938
[12:15:04.323892] Test:  [20/57]  eta: 0:00:06  loss: 0.8866 (0.8706)  time: 0.1818  data: 0.0001  max mem: 14938
[12:15:06.148633] Test:  [30/57]  eta: 0:00:05  loss: 0.7469 (0.8269)  time: 0.1822  data: 0.0001  max mem: 14938
[12:15:07.977675] Test:  [40/57]  eta: 0:00:03  loss: 0.7380 (0.8052)  time: 0.1826  data: 0.0001  max mem: 14938
[12:15:09.811513] Test:  [50/57]  eta: 0:00:01  loss: 0.7326 (0.7973)  time: 0.1831  data: 0.0001  max mem: 14938
[12:15:10.799489] Test:  [56/57]  eta: 0:00:00  loss: 0.7497 (0.8029)  time: 0.1776  data: 0.0001  max mem: 14938
[12:15:10.854715] Test: Total time: 0:00:10 (0.1840 s / it)
[12:15:12.592888] Dice score of the network on the train images: 0.816288, val images: 0.822032
[12:15:12.597955] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:15:13.483129] Epoch: [32]  [  0/345]  eta: 0:05:05  lr: 0.000082  loss: 0.7259 (0.7259)  time: 0.8841  data: 0.1417  max mem: 14938
[12:15:28.380017] Epoch: [32]  [ 20/345]  eta: 0:04:04  lr: 0.000081  loss: 0.7344 (0.7373)  time: 0.7448  data: 0.0001  max mem: 14938
[12:15:43.325896] Epoch: [32]  [ 40/345]  eta: 0:03:48  lr: 0.000081  loss: 0.7396 (0.7396)  time: 0.7472  data: 0.0001  max mem: 14938
[12:15:58.281903] Epoch: [32]  [ 60/345]  eta: 0:03:33  lr: 0.000081  loss: 0.7310 (0.7365)  time: 0.7478  data: 0.0001  max mem: 14938
[12:16:13.254852] Epoch: [32]  [ 80/345]  eta: 0:03:18  lr: 0.000080  loss: 0.7242 (0.7347)  time: 0.7486  data: 0.0001  max mem: 14938
[12:16:28.251533] Epoch: [32]  [100/345]  eta: 0:03:03  lr: 0.000080  loss: 0.7249 (0.7334)  time: 0.7498  data: 0.0001  max mem: 14938
[12:16:43.405112] Epoch: [32]  [120/345]  eta: 0:02:48  lr: 0.000080  loss: 0.7275 (0.7325)  time: 0.7576  data: 0.0001  max mem: 14938
[12:16:58.434523] Epoch: [32]  [140/345]  eta: 0:02:33  lr: 0.000079  loss: 0.7197 (0.7310)  time: 0.7514  data: 0.0001  max mem: 14938
[12:17:13.458306] Epoch: [32]  [160/345]  eta: 0:02:18  lr: 0.000079  loss: 0.7278 (0.7310)  time: 0.7511  data: 0.0001  max mem: 14938
[12:17:28.472932] Epoch: [32]  [180/345]  eta: 0:02:03  lr: 0.000079  loss: 0.7147 (0.7295)  time: 0.7507  data: 0.0001  max mem: 14938
[12:17:43.481742] Epoch: [32]  [200/345]  eta: 0:01:48  lr: 0.000078  loss: 0.7241 (0.7290)  time: 0.7504  data: 0.0001  max mem: 14938
[12:17:58.486835] Epoch: [32]  [220/345]  eta: 0:01:33  lr: 0.000078  loss: 0.7207 (0.7284)  time: 0.7502  data: 0.0001  max mem: 14938
[12:18:13.476933] Epoch: [32]  [240/345]  eta: 0:01:18  lr: 0.000077  loss: 0.7255 (0.7286)  time: 0.7495  data: 0.0001  max mem: 14938
[12:18:28.470611] Epoch: [32]  [260/345]  eta: 0:01:03  lr: 0.000077  loss: 0.7258 (0.7287)  time: 0.7496  data: 0.0001  max mem: 14938
[12:18:43.443317] Epoch: [32]  [280/345]  eta: 0:00:48  lr: 0.000077  loss: 0.7309 (0.7292)  time: 0.7486  data: 0.0001  max mem: 14938
[12:18:58.431892] Epoch: [32]  [300/345]  eta: 0:00:33  lr: 0.000076  loss: 0.7235 (0.7289)  time: 0.7494  data: 0.0001  max mem: 14938
[12:19:13.411944] Epoch: [32]  [320/345]  eta: 0:00:18  lr: 0.000076  loss: 0.7272 (0.7288)  time: 0.7490  data: 0.0001  max mem: 14938
[12:19:28.372819] Epoch: [32]  [340/345]  eta: 0:00:03  lr: 0.000076  loss: 0.7233 (0.7287)  time: 0.7480  data: 0.0001  max mem: 14938
[12:19:31.366189] Epoch: [32]  [344/345]  eta: 0:00:00  lr: 0.000076  loss: 0.7233 (0.7285)  time: 0.7480  data: 0.0001  max mem: 14938
[12:19:31.431275] Epoch: [32] Total time: 0:04:18 (0.7502 s / it)
[12:19:31.431758] Averaged stats: lr: 0.000076  loss: 0.7233 (0.7285)
[12:19:31.764363] Test:  [  0/345]  eta: 0:01:53  loss: 0.6920 (0.6920)  time: 0.3287  data: 0.1477  max mem: 14938
[12:19:33.601550] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6924 (0.6966)  time: 0.1968  data: 0.0135  max mem: 14938
[12:19:35.441696] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6976 (0.7012)  time: 0.1838  data: 0.0001  max mem: 14938
[12:19:37.283305] Test:  [ 30/345]  eta: 0:00:59  loss: 0.7002 (0.7012)  time: 0.1840  data: 0.0001  max mem: 14938
[12:19:39.129666] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6978 (0.7001)  time: 0.1843  data: 0.0001  max mem: 14938
[12:19:40.979317] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6953 (0.6996)  time: 0.1847  data: 0.0001  max mem: 14938
[12:19:42.832726] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6958 (0.6994)  time: 0.1851  data: 0.0001  max mem: 14938
[12:19:44.688958] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7001 (0.7001)  time: 0.1854  data: 0.0001  max mem: 14938
[12:19:46.548617] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7028 (0.7006)  time: 0.1857  data: 0.0001  max mem: 14938
[12:19:48.412981] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7028 (0.7010)  time: 0.1861  data: 0.0001  max mem: 14938
[12:19:50.280799] Test:  [100/345]  eta: 0:00:45  loss: 0.6972 (0.7007)  time: 0.1866  data: 0.0001  max mem: 14938
[12:19:52.151120] Test:  [110/345]  eta: 0:00:43  loss: 0.6982 (0.7007)  time: 0.1869  data: 0.0001  max mem: 14938
[12:19:54.025028] Test:  [120/345]  eta: 0:00:41  loss: 0.6974 (0.7004)  time: 0.1872  data: 0.0001  max mem: 14938
[12:19:55.902608] Test:  [130/345]  eta: 0:00:40  loss: 0.6918 (0.6998)  time: 0.1875  data: 0.0001  max mem: 14938
[12:19:57.784179] Test:  [140/345]  eta: 0:00:38  loss: 0.6948 (0.6999)  time: 0.1879  data: 0.0001  max mem: 14938
[12:19:59.668739] Test:  [150/345]  eta: 0:00:36  loss: 0.7007 (0.6998)  time: 0.1883  data: 0.0001  max mem: 14938
[12:20:01.556408] Test:  [160/345]  eta: 0:00:34  loss: 0.6988 (0.6998)  time: 0.1886  data: 0.0001  max mem: 14938
[12:20:03.446271] Test:  [170/345]  eta: 0:00:32  loss: 0.7007 (0.7000)  time: 0.1888  data: 0.0001  max mem: 14938
[12:20:05.340641] Test:  [180/345]  eta: 0:00:30  loss: 0.6986 (0.6998)  time: 0.1892  data: 0.0001  max mem: 14938
[12:20:07.238925] Test:  [190/345]  eta: 0:00:29  loss: 0.6959 (0.6998)  time: 0.1896  data: 0.0001  max mem: 14938
[12:20:09.140314] Test:  [200/345]  eta: 0:00:27  loss: 0.7006 (0.6998)  time: 0.1899  data: 0.0001  max mem: 14938
[12:20:11.045693] Test:  [210/345]  eta: 0:00:25  loss: 0.6999 (0.6999)  time: 0.1903  data: 0.0001  max mem: 14938
[12:20:12.954667] Test:  [220/345]  eta: 0:00:23  loss: 0.6998 (0.7000)  time: 0.1907  data: 0.0001  max mem: 14938
[12:20:14.866580] Test:  [230/345]  eta: 0:00:21  loss: 0.7038 (0.7002)  time: 0.1910  data: 0.0001  max mem: 14938
[12:20:16.782594] Test:  [240/345]  eta: 0:00:19  loss: 0.7034 (0.7002)  time: 0.1913  data: 0.0001  max mem: 14938
[12:20:18.703350] Test:  [250/345]  eta: 0:00:17  loss: 0.7017 (0.7001)  time: 0.1918  data: 0.0001  max mem: 14938
[12:20:20.627408] Test:  [260/345]  eta: 0:00:16  loss: 0.7040 (0.7002)  time: 0.1922  data: 0.0001  max mem: 14938
[12:20:22.556953] Test:  [270/345]  eta: 0:00:14  loss: 0.7040 (0.7001)  time: 0.1926  data: 0.0001  max mem: 14938
[12:20:24.488838] Test:  [280/345]  eta: 0:00:12  loss: 0.6973 (0.6999)  time: 0.1930  data: 0.0001  max mem: 14938
[12:20:26.423494] Test:  [290/345]  eta: 0:00:10  loss: 0.6973 (0.7001)  time: 0.1933  data: 0.0001  max mem: 14938
[12:20:28.359167] Test:  [300/345]  eta: 0:00:08  loss: 0.6985 (0.7000)  time: 0.1935  data: 0.0001  max mem: 14938
[12:20:30.299854] Test:  [310/345]  eta: 0:00:06  loss: 0.6985 (0.7000)  time: 0.1938  data: 0.0001  max mem: 14938
[12:20:32.241481] Test:  [320/345]  eta: 0:00:04  loss: 0.7004 (0.7000)  time: 0.1941  data: 0.0001  max mem: 14938
[12:20:34.188414] Test:  [330/345]  eta: 0:00:02  loss: 0.7033 (0.7002)  time: 0.1944  data: 0.0001  max mem: 14938
[12:20:36.138081] Test:  [340/345]  eta: 0:00:00  loss: 0.7033 (0.7001)  time: 0.1948  data: 0.0001  max mem: 14938
[12:20:36.919750] Test:  [344/345]  eta: 0:00:00  loss: 0.7014 (0.7002)  time: 0.1949  data: 0.0001  max mem: 14938
[12:20:36.978608] Test: Total time: 0:01:05 (0.1900 s / it)
[12:20:47.328652] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8507 (0.8507)  time: 0.3187  data: 0.1384  max mem: 14938
[12:20:49.145151] Test:  [10/57]  eta: 0:00:09  loss: 0.8721 (0.8776)  time: 0.1940  data: 0.0126  max mem: 14938
[12:20:50.965310] Test:  [20/57]  eta: 0:00:06  loss: 0.8721 (0.8672)  time: 0.1818  data: 0.0001  max mem: 14938
[12:20:52.789000] Test:  [30/57]  eta: 0:00:05  loss: 0.7484 (0.8240)  time: 0.1821  data: 0.0001  max mem: 14938
[12:20:54.616933] Test:  [40/57]  eta: 0:00:03  loss: 0.7397 (0.8016)  time: 0.1825  data: 0.0001  max mem: 14938
[12:20:56.451676] Test:  [50/57]  eta: 0:00:01  loss: 0.7323 (0.7938)  time: 0.1831  data: 0.0001  max mem: 14938
[12:20:57.440249] Test:  [56/57]  eta: 0:00:00  loss: 0.7433 (0.7994)  time: 0.1776  data: 0.0001  max mem: 14938
[12:20:57.498514] Test: Total time: 0:00:10 (0.1840 s / it)
[12:20:59.287104] Dice score of the network on the train images: 0.820390, val images: 0.826599
[12:20:59.287328] saving best_dice_model_0 @ epoch 32
[12:21:00.489769] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:21:01.371382] Epoch: [33]  [  0/345]  eta: 0:05:03  lr: 0.000075  loss: 0.7173 (0.7173)  time: 0.8806  data: 0.1391  max mem: 14938
[12:21:16.233966] Epoch: [33]  [ 20/345]  eta: 0:04:03  lr: 0.000075  loss: 0.7275 (0.7261)  time: 0.7431  data: 0.0001  max mem: 14938
[12:21:31.146628] Epoch: [33]  [ 40/345]  eta: 0:03:48  lr: 0.000075  loss: 0.7197 (0.7240)  time: 0.7456  data: 0.0001  max mem: 14938
[12:21:46.093247] Epoch: [33]  [ 60/345]  eta: 0:03:33  lr: 0.000074  loss: 0.7209 (0.7235)  time: 0.7473  data: 0.0001  max mem: 14938

[12:22:01.055795] Epoch: [33]  [ 80/345]  eta: 0:03:18  lr: 0.000074  loss: 0.7234 (0.7243)  time: 0.7481  data: 0.0001  max mem: 14938
[12:22:16.054610] Epoch: [33]  [100/345]  eta: 0:03:03  lr: 0.000074  loss: 0.7306 (0.7252)  time: 0.7499  data: 0.0001  max mem: 14938

[12:22:31.068926] Epoch: [33]  [120/345]  eta: 0:02:48  lr: 0.000073  loss: 0.7238 (0.7253)  time: 0.7507  data: 0.0001  max mem: 14938
[12:22:46.079960] Epoch: [33]  [140/345]  eta: 0:02:33  lr: 0.000073  loss: 0.7281 (0.7259)  time: 0.7505  data: 0.0001  max mem: 14938

[12:23:01.101874] Epoch: [33]  [160/345]  eta: 0:02:18  lr: 0.000073  loss: 0.7340 (0.7267)  time: 0.7511  data: 0.0001  max mem: 14938
[12:23:16.117425] Epoch: [33]  [180/345]  eta: 0:02:03  lr: 0.000072  loss: 0.7213 (0.7262)  time: 0.7507  data: 0.0001  max mem: 14938
[12:23:31.235700] Epoch: [33]  [200/345]  eta: 0:01:48  lr: 0.000072  loss: 0.7251 (0.7260)  time: 0.7559  data: 0.0001  max mem: 14938
[12:23:46.214667] Epoch: [33]  [220/345]  eta: 0:01:33  lr: 0.000071  loss: 0.7295 (0.7262)  time: 0.7489  data: 0.0001  max mem: 14938
[12:24:01.215568] Epoch: [33]  [240/345]  eta: 0:01:18  lr: 0.000071  loss: 0.7240 (0.7263)  time: 0.7500  data: 0.0001  max mem: 14938
[12:24:16.211317] Epoch: [33]  [260/345]  eta: 0:01:03  lr: 0.000071  loss: 0.7195 (0.7260)  time: 0.7497  data: 0.0001  max mem: 14938

[12:24:31.209612] Epoch: [33]  [280/345]  eta: 0:00:48  lr: 0.000070  loss: 0.7218 (0.7259)  time: 0.7499  data: 0.0001  max mem: 14938
[12:24:46.195022] Epoch: [33]  [300/345]  eta: 0:00:33  lr: 0.000070  loss: 0.7192 (0.7254)  time: 0.7492  data: 0.0001  max mem: 14938
[12:25:01.170900] Epoch: [33]  [320/345]  eta: 0:00:18  lr: 0.000070  loss: 0.7169 (0.7248)  time: 0.7487  data: 0.0001  max mem: 14938
[12:25:16.154927] Epoch: [33]  [340/345]  eta: 0:00:03  lr: 0.000069  loss: 0.7196 (0.7245)  time: 0.7492  data: 0.0001  max mem: 14938
[12:25:19.152838] Epoch: [33]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.7185 (0.7245)  time: 0.7494  data: 0.0001  max mem: 14938
[12:25:19.216591] Epoch: [33] Total time: 0:04:18 (0.7499 s / it)
[12:25:19.217013] Averaged stats: lr: 0.000069  loss: 0.7185 (0.7245)
[12:25:19.553730] Test:  [  0/345]  eta: 0:01:54  loss: 0.6951 (0.6951)  time: 0.3324  data: 0.1510  max mem: 14938
[12:25:21.389882] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6972 (0.7019)  time: 0.1971  data: 0.0138  max mem: 14938
[12:25:23.230301] Test:  [ 20/345]  eta: 0:01:02  loss: 0.7016 (0.7042)  time: 0.1838  data: 0.0001  max mem: 14938
[12:25:25.073474] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6965 (0.7020)  time: 0.1841  data: 0.0001  max mem: 14938
[12:25:26.921042] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6980 (0.7023)  time: 0.1845  data: 0.0001  max mem: 14938
[12:25:28.769878] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7023 (0.7021)  time: 0.1848  data: 0.0001  max mem: 14938
[12:25:30.623900] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6994 (0.7017)  time: 0.1851  data: 0.0001  max mem: 14938
[12:25:32.480661] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6991 (0.7014)  time: 0.1855  data: 0.0001  max mem: 14938
[12:25:34.339883] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6970 (0.7016)  time: 0.1857  data: 0.0001  max mem: 14938
[12:25:36.203314] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6988 (0.7018)  time: 0.1861  data: 0.0001  max mem: 14938
[12:25:38.069348] Test:  [100/345]  eta: 0:00:45  loss: 0.6985 (0.7017)  time: 0.1864  data: 0.0001  max mem: 14938
[12:25:39.939280] Test:  [110/345]  eta: 0:00:43  loss: 0.6992 (0.7020)  time: 0.1867  data: 0.0001  max mem: 14938
[12:25:41.812054] Test:  [120/345]  eta: 0:00:41  loss: 0.6968 (0.7015)  time: 0.1871  data: 0.0001  max mem: 14938
[12:25:43.689633] Test:  [130/345]  eta: 0:00:40  loss: 0.6960 (0.7013)  time: 0.1875  data: 0.0001  max mem: 14938
[12:25:45.570840] Test:  [140/345]  eta: 0:00:38  loss: 0.6965 (0.7010)  time: 0.1879  data: 0.0001  max mem: 14938
[12:25:47.455069] Test:  [150/345]  eta: 0:00:36  loss: 0.7062 (0.7019)  time: 0.1882  data: 0.0001  max mem: 14938
[12:25:49.343282] Test:  [160/345]  eta: 0:00:34  loss: 0.7104 (0.7019)  time: 0.1886  data: 0.0001  max mem: 14938
[12:25:51.235066] Test:  [170/345]  eta: 0:00:32  loss: 0.7004 (0.7019)  time: 0.1889  data: 0.0001  max mem: 14938
[12:25:53.130992] Test:  [180/345]  eta: 0:00:30  loss: 0.7000 (0.7018)  time: 0.1893  data: 0.0001  max mem: 14938
[12:25:55.031436] Test:  [190/345]  eta: 0:00:29  loss: 0.6974 (0.7017)  time: 0.1898  data: 0.0001  max mem: 14938
[12:25:56.934783] Test:  [200/345]  eta: 0:00:27  loss: 0.6991 (0.7019)  time: 0.1901  data: 0.0001  max mem: 14938
[12:25:58.841509] Test:  [210/345]  eta: 0:00:25  loss: 0.7093 (0.7022)  time: 0.1904  data: 0.0001  max mem: 14938
[12:26:00.748724] Test:  [220/345]  eta: 0:00:23  loss: 0.7036 (0.7022)  time: 0.1906  data: 0.0001  max mem: 14938
[12:26:02.662838] Test:  [230/345]  eta: 0:00:21  loss: 0.6951 (0.7019)  time: 0.1910  data: 0.0001  max mem: 14938
[12:26:04.580660] Test:  [240/345]  eta: 0:00:19  loss: 0.6961 (0.7019)  time: 0.1915  data: 0.0001  max mem: 14938
[12:26:06.500611] Test:  [250/345]  eta: 0:00:17  loss: 0.6971 (0.7018)  time: 0.1918  data: 0.0001  max mem: 14938
[12:26:08.425032] Test:  [260/345]  eta: 0:00:16  loss: 0.6961 (0.7019)  time: 0.1922  data: 0.0001  max mem: 14938
[12:26:10.350155] Test:  [270/345]  eta: 0:00:14  loss: 0.7036 (0.7019)  time: 0.1924  data: 0.0001  max mem: 14938
[12:26:12.279758] Test:  [280/345]  eta: 0:00:12  loss: 0.7054 (0.7022)  time: 0.1927  data: 0.0001  max mem: 14938
[12:26:14.213018] Test:  [290/345]  eta: 0:00:10  loss: 0.7054 (0.7021)  time: 0.1931  data: 0.0001  max mem: 14938
[12:26:16.151215] Test:  [300/345]  eta: 0:00:08  loss: 0.6994 (0.7022)  time: 0.1935  data: 0.0001  max mem: 14938
[12:26:18.091076] Test:  [310/345]  eta: 0:00:06  loss: 0.6984 (0.7021)  time: 0.1938  data: 0.0001  max mem: 14938
[12:26:20.034682] Test:  [320/345]  eta: 0:00:04  loss: 0.7015 (0.7022)  time: 0.1941  data: 0.0001  max mem: 14938
[12:26:21.981367] Test:  [330/345]  eta: 0:00:02  loss: 0.7000 (0.7021)  time: 0.1945  data: 0.0001  max mem: 14938
[12:26:23.929696] Test:  [340/345]  eta: 0:00:00  loss: 0.6998 (0.7022)  time: 0.1947  data: 0.0001  max mem: 14938
[12:26:24.712023] Test:  [344/345]  eta: 0:00:00  loss: 0.7012 (0.7021)  time: 0.1949  data: 0.0001  max mem: 14938
[12:26:24.771845] Test: Total time: 0:01:05 (0.1900 s / it)
[12:26:35.199871] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8489 (0.8489)  time: 0.3198  data: 0.1398  max mem: 14938
[12:26:37.016925] Test:  [10/57]  eta: 0:00:09  loss: 0.8573 (0.8685)  time: 0.1942  data: 0.0128  max mem: 14938
[12:26:38.838431] Test:  [20/57]  eta: 0:00:06  loss: 0.8573 (0.8596)  time: 0.1819  data: 0.0001  max mem: 14938
[12:26:40.662660] Test:  [30/57]  eta: 0:00:05  loss: 0.7504 (0.8184)  time: 0.1822  data: 0.0001  max mem: 14938
[12:26:42.490703] Test:  [40/57]  eta: 0:00:03  loss: 0.7349 (0.7982)  time: 0.1826  data: 0.0001  max mem: 14938
[12:26:44.325342] Test:  [50/57]  eta: 0:00:01  loss: 0.7294 (0.7901)  time: 0.1831  data: 0.0001  max mem: 14938
[12:26:45.315175] Test:  [56/57]  eta: 0:00:00  loss: 0.7583 (0.7970)  time: 0.1778  data: 0.0001  max mem: 14938
[12:26:45.372440] Test: Total time: 0:00:10 (0.1841 s / it)
[12:26:47.165195] Dice score of the network on the train images: 0.813176, val images: 0.824460
[12:26:47.169651] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:26:48.053980] Epoch: [34]  [  0/345]  eta: 0:05:04  lr: 0.000069  loss: 0.7143 (0.7143)  time: 0.8832  data: 0.1426  max mem: 14938
[12:27:02.960570] Epoch: [34]  [ 20/345]  eta: 0:04:04  lr: 0.000069  loss: 0.7202 (0.7230)  time: 0.7453  data: 0.0001  max mem: 14938
[12:27:17.917492] Epoch: [34]  [ 40/345]  eta: 0:03:48  lr: 0.000068  loss: 0.7194 (0.7225)  time: 0.7478  data: 0.0001  max mem: 14938
[12:27:32.900285] Epoch: [34]  [ 60/345]  eta: 0:03:33  lr: 0.000068  loss: 0.7157 (0.7208)  time: 0.7491  data: 0.0001  max mem: 14938
[12:27:47.887263] Epoch: [34]  [ 80/345]  eta: 0:03:18  lr: 0.000068  loss: 0.7194 (0.7211)  time: 0.7493  data: 0.0001  max mem: 14938
[12:28:02.892886] Epoch: [34]  [100/345]  eta: 0:03:03  lr: 0.000067  loss: 0.7231 (0.7221)  time: 0.7502  data: 0.0001  max mem: 14938
[12:28:17.917189] Epoch: [34]  [120/345]  eta: 0:02:48  lr: 0.000067  loss: 0.7169 (0.7216)  time: 0.7512  data: 0.0001  max mem: 14938
[12:28:32.940220] Epoch: [34]  [140/345]  eta: 0:02:33  lr: 0.000066  loss: 0.7156 (0.7211)  time: 0.7511  data: 0.0001  max mem: 14938
[12:28:48.080083] Epoch: [34]  [160/345]  eta: 0:02:18  lr: 0.000066  loss: 0.7268 (0.7217)  time: 0.7569  data: 0.0001  max mem: 14938
[12:29:03.084708] Epoch: [34]  [180/345]  eta: 0:02:03  lr: 0.000066  loss: 0.7198 (0.7215)  time: 0.7502  data: 0.0001  max mem: 14938
[12:29:18.080544] Epoch: [34]  [200/345]  eta: 0:01:48  lr: 0.000065  loss: 0.7241 (0.7220)  time: 0.7497  data: 0.0001  max mem: 14938
[12:29:33.081177] Epoch: [34]  [220/345]  eta: 0:01:33  lr: 0.000065  loss: 0.7177 (0.7220)  time: 0.7500  data: 0.0001  max mem: 14938
[12:29:48.088344] Epoch: [34]  [240/345]  eta: 0:01:18  lr: 0.000064  loss: 0.7190 (0.7219)  time: 0.7503  data: 0.0001  max mem: 14938
[12:30:03.083951] Epoch: [34]  [260/345]  eta: 0:01:03  lr: 0.000064  loss: 0.7185 (0.7221)  time: 0.7497  data: 0.0001  max mem: 14938
[12:30:18.075734] Epoch: [34]  [280/345]  eta: 0:00:48  lr: 0.000064  loss: 0.7161 (0.7219)  time: 0.7495  data: 0.0001  max mem: 14938
[12:30:33.064533] Epoch: [34]  [300/345]  eta: 0:00:33  lr: 0.000063  loss: 0.7164 (0.7218)  time: 0.7494  data: 0.0001  max mem: 14938
[12:30:48.044042] Epoch: [34]  [320/345]  eta: 0:00:18  lr: 0.000063  loss: 0.7256 (0.7223)  time: 0.7489  data: 0.0001  max mem: 14938
[12:31:03.032824] Epoch: [34]  [340/345]  eta: 0:00:03  lr: 0.000063  loss: 0.7239 (0.7226)  time: 0.7494  data: 0.0001  max mem: 14938
[12:31:06.030151] Epoch: [34]  [344/345]  eta: 0:00:00  lr: 0.000063  loss: 0.7239 (0.7227)  time: 0.7494  data: 0.0001  max mem: 14938
[12:31:06.092554] Epoch: [34] Total time: 0:04:18 (0.7505 s / it)
[12:31:06.093024] Averaged stats: lr: 0.000063  loss: 0.7239 (0.7227)
[12:31:06.424412] Test:  [  0/345]  eta: 0:01:52  loss: 0.7079 (0.7079)  time: 0.3271  data: 0.1455  max mem: 14938
[12:31:08.262140] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6943 (0.6962)  time: 0.1967  data: 0.0133  max mem: 14938
[12:31:10.099434] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6957 (0.6974)  time: 0.1837  data: 0.0001  max mem: 14938
[12:31:11.940583] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6958 (0.6983)  time: 0.1839  data: 0.0001  max mem: 14938
[12:31:13.787456] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6967 (0.6984)  time: 0.1844  data: 0.0001  max mem: 14938
[12:31:15.636568] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6980 (0.6985)  time: 0.1847  data: 0.0001  max mem: 14938
[12:31:17.490738] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6992 (0.7000)  time: 0.1851  data: 0.0001  max mem: 14938
[12:31:19.347561] Test:  [ 70/345]  eta: 0:00:51  loss: 0.7022 (0.7006)  time: 0.1855  data: 0.0001  max mem: 14938
[12:31:21.207650] Test:  [ 80/345]  eta: 0:00:49  loss: 0.7022 (0.7011)  time: 0.1858  data: 0.0001  max mem: 14938
[12:31:23.071827] Test:  [ 90/345]  eta: 0:00:47  loss: 0.7019 (0.7012)  time: 0.1862  data: 0.0001  max mem: 14938
[12:31:24.939302] Test:  [100/345]  eta: 0:00:45  loss: 0.7019 (0.7012)  time: 0.1865  data: 0.0001  max mem: 14938
[12:31:26.809239] Test:  [110/345]  eta: 0:00:43  loss: 0.7002 (0.7008)  time: 0.1868  data: 0.0001  max mem: 14938
[12:31:28.683751] Test:  [120/345]  eta: 0:00:41  loss: 0.7002 (0.7012)  time: 0.1872  data: 0.0001  max mem: 14938
[12:31:30.561315] Test:  [130/345]  eta: 0:00:40  loss: 0.7025 (0.7010)  time: 0.1875  data: 0.0001  max mem: 14938
[12:31:32.441514] Test:  [140/345]  eta: 0:00:38  loss: 0.6969 (0.7009)  time: 0.1878  data: 0.0001  max mem: 14938
[12:31:34.326578] Test:  [150/345]  eta: 0:00:36  loss: 0.6963 (0.7010)  time: 0.1882  data: 0.0001  max mem: 14938
[12:31:36.212397] Test:  [160/345]  eta: 0:00:34  loss: 0.6940 (0.7002)  time: 0.1885  data: 0.0001  max mem: 14938
[12:31:38.103672] Test:  [170/345]  eta: 0:00:32  loss: 0.6969 (0.7005)  time: 0.1888  data: 0.0001  max mem: 14938
[12:31:40.000135] Test:  [180/345]  eta: 0:00:30  loss: 0.6977 (0.7003)  time: 0.1893  data: 0.0001  max mem: 14938
[12:31:41.902169] Test:  [190/345]  eta: 0:00:29  loss: 0.6963 (0.7004)  time: 0.1899  data: 0.0001  max mem: 14938
[12:31:43.804593] Test:  [200/345]  eta: 0:00:27  loss: 0.6963 (0.7002)  time: 0.1902  data: 0.0001  max mem: 14938
[12:31:45.712235] Test:  [210/345]  eta: 0:00:25  loss: 0.6982 (0.7002)  time: 0.1905  data: 0.0001  max mem: 14938
[12:31:47.621519] Test:  [220/345]  eta: 0:00:23  loss: 0.7012 (0.7001)  time: 0.1908  data: 0.0001  max mem: 14938
[12:31:49.534093] Test:  [230/345]  eta: 0:00:21  loss: 0.6957 (0.7001)  time: 0.1910  data: 0.0001  max mem: 14938
[12:31:51.452004] Test:  [240/345]  eta: 0:00:19  loss: 0.7035 (0.7003)  time: 0.1915  data: 0.0001  max mem: 14938
[12:31:53.373489] Test:  [250/345]  eta: 0:00:17  loss: 0.7006 (0.7001)  time: 0.1919  data: 0.0001  max mem: 14938
[12:31:55.297646] Test:  [260/345]  eta: 0:00:16  loss: 0.6939 (0.7003)  time: 0.1922  data: 0.0001  max mem: 14938
[12:31:57.223852] Test:  [270/345]  eta: 0:00:14  loss: 0.6998 (0.7003)  time: 0.1925  data: 0.0001  max mem: 14938
[12:31:59.152963] Test:  [280/345]  eta: 0:00:12  loss: 0.6933 (0.6999)  time: 0.1927  data: 0.0001  max mem: 14938
[12:32:01.087708] Test:  [290/345]  eta: 0:00:10  loss: 0.6928 (0.6997)  time: 0.1931  data: 0.0001  max mem: 14938
[12:32:03.026634] Test:  [300/345]  eta: 0:00:08  loss: 0.6954 (0.6996)  time: 0.1936  data: 0.0001  max mem: 14938
[12:32:04.967747] Test:  [310/345]  eta: 0:00:06  loss: 0.6925 (0.6996)  time: 0.1940  data: 0.0001  max mem: 14938
[12:32:06.912039] Test:  [320/345]  eta: 0:00:04  loss: 0.6908 (0.6996)  time: 0.1942  data: 0.0001  max mem: 14938
[12:32:08.859416] Test:  [330/345]  eta: 0:00:02  loss: 0.6995 (0.6995)  time: 0.1945  data: 0.0001  max mem: 14938
[12:32:10.808529] Test:  [340/345]  eta: 0:00:00  loss: 0.6995 (0.6995)  time: 0.1948  data: 0.0001  max mem: 14938
[12:32:11.590429] Test:  [344/345]  eta: 0:00:00  loss: 0.6987 (0.6994)  time: 0.1949  data: 0.0001  max mem: 14938
[12:32:11.650309] Test: Total time: 0:01:05 (0.1900 s / it)
[12:32:21.957119] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8471 (0.8471)  time: 0.3226  data: 0.1432  max mem: 14938
[12:32:23.773643] Test:  [10/57]  eta: 0:00:09  loss: 0.8574 (0.8794)  time: 0.1944  data: 0.0131  max mem: 14938
[12:32:25.594769] Test:  [20/57]  eta: 0:00:06  loss: 0.8688 (0.8709)  time: 0.1818  data: 0.0001  max mem: 14938
[12:32:27.420597] Test:  [30/57]  eta: 0:00:05  loss: 0.7518 (0.8278)  time: 0.1823  data: 0.0001  max mem: 14938
[12:32:29.249732] Test:  [40/57]  eta: 0:00:03  loss: 0.7463 (0.8067)  time: 0.1827  data: 0.0001  max mem: 14938
[12:32:31.083917] Test:  [50/57]  eta: 0:00:01  loss: 0.7371 (0.7978)  time: 0.1831  data: 0.0001  max mem: 14938
[12:32:32.073890] Test:  [56/57]  eta: 0:00:00  loss: 0.7537 (0.8039)  time: 0.1777  data: 0.0001  max mem: 14938
[12:32:32.132599] Test: Total time: 0:00:10 (0.1842 s / it)
[12:32:33.933612] Dice score of the network on the train images: 0.822253, val images: 0.820109
[12:32:33.937813] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:32:34.826589] Epoch: [35]  [  0/345]  eta: 0:05:06  lr: 0.000063  loss: 0.7378 (0.7378)  time: 0.8876  data: 0.1436  max mem: 14938
[12:32:49.712456] Epoch: [35]  [ 20/345]  eta: 0:04:04  lr: 0.000062  loss: 0.7141 (0.7165)  time: 0.7442  data: 0.0001  max mem: 14938
[12:33:04.647084] Epoch: [35]  [ 40/345]  eta: 0:03:48  lr: 0.000062  loss: 0.7183 (0.7196)  time: 0.7467  data: 0.0001  max mem: 14938
[12:33:19.620353] Epoch: [35]  [ 60/345]  eta: 0:03:33  lr: 0.000061  loss: 0.7190 (0.7196)  time: 0.7486  data: 0.0001  max mem: 14938
[12:33:34.614181] Epoch: [35]  [ 80/345]  eta: 0:03:18  lr: 0.000061  loss: 0.7210 (0.7204)  time: 0.7496  data: 0.0001  max mem: 14938
[12:33:49.629293] Epoch: [35]  [100/345]  eta: 0:03:03  lr: 0.000061  loss: 0.7175 (0.7204)  time: 0.7507  data: 0.0001  max mem: 14938
[12:34:04.662429] Epoch: [35]  [120/345]  eta: 0:02:48  lr: 0.000060  loss: 0.7193 (0.7207)  time: 0.7516  data: 0.0001  max mem: 14938
[12:34:19.700613] Epoch: [35]  [140/345]  eta: 0:02:33  lr: 0.000060  loss: 0.7243 (0.7217)  time: 0.7519  data: 0.0001  max mem: 14938
[12:34:34.736037] Epoch: [35]  [160/345]  eta: 0:02:18  lr: 0.000059  loss: 0.7244 (0.7220)  time: 0.7517  data: 0.0001  max mem: 14938
[12:34:49.752952] Epoch: [35]  [180/345]  eta: 0:02:03  lr: 0.000059  loss: 0.7238 (0.7222)  time: 0.7508  data: 0.0001  max mem: 14938
[12:35:04.775849] Epoch: [35]  [200/345]  eta: 0:01:48  lr: 0.000059  loss: 0.7188 (0.7220)  time: 0.7511  data: 0.0001  max mem: 14938
[12:35:19.778852] Epoch: [35]  [220/345]  eta: 0:01:33  lr: 0.000058  loss: 0.7205 (0.7219)  time: 0.7501  data: 0.0001  max mem: 14938
[12:35:34.783883] Epoch: [35]  [240/345]  eta: 0:01:18  lr: 0.000058  loss: 0.7204 (0.7221)  time: 0.7502  data: 0.0001  max mem: 14938
[12:35:49.784285] Epoch: [35]  [260/345]  eta: 0:01:03  lr: 0.000058  loss: 0.7190 (0.7222)  time: 0.7500  data: 0.0001  max mem: 14938
[12:36:04.785406] Epoch: [35]  [280/345]  eta: 0:00:48  lr: 0.000057  loss: 0.7163 (0.7220)  time: 0.7500  data: 0.0001  max mem: 14938
[12:36:19.785995] Epoch: [35]  [300/345]  eta: 0:00:33  lr: 0.000057  loss: 0.7139 (0.7218)  time: 0.7500  data: 0.0001  max mem: 14938
[12:36:34.779252] Epoch: [35]  [320/345]  eta: 0:00:18  lr: 0.000056  loss: 0.7174 (0.7215)  time: 0.7496  data: 0.0001  max mem: 14938
[12:36:49.767828] Epoch: [35]  [340/345]  eta: 0:00:03  lr: 0.000056  loss: 0.7220 (0.7215)  time: 0.7494  data: 0.0001  max mem: 14938
[12:36:52.767060] Epoch: [35]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.7153 (0.7214)  time: 0.7494  data: 0.0001  max mem: 14938
[12:36:52.809942] Epoch: [35] Total time: 0:04:18 (0.7504 s / it)
[12:36:52.810227] Averaged stats: lr: 0.000056  loss: 0.7153 (0.7214)
[12:36:53.141800] Test:  [  0/345]  eta: 0:01:52  loss: 0.7159 (0.7159)  time: 0.3274  data: 0.1452  max mem: 14938
[12:36:54.978918] Test:  [ 10/345]  eta: 0:01:05  loss: 0.7044 (0.7038)  time: 0.1967  data: 0.0133  max mem: 14938
[12:36:56.819143] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6988 (0.6975)  time: 0.1838  data: 0.0001  max mem: 14938
[12:36:58.660632] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6916 (0.6958)  time: 0.1840  data: 0.0001  max mem: 14938
[12:37:00.505391] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6927 (0.6948)  time: 0.1843  data: 0.0001  max mem: 14938
[12:37:02.356201] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6932 (0.6942)  time: 0.1847  data: 0.0001  max mem: 14938
[12:37:04.209438] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6932 (0.6939)  time: 0.1852  data: 0.0001  max mem: 14938
[12:37:06.066231] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6913 (0.6935)  time: 0.1855  data: 0.0001  max mem: 14938
[12:37:07.927599] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6913 (0.6943)  time: 0.1859  data: 0.0001  max mem: 14938
[12:37:09.791099] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6957 (0.6940)  time: 0.1862  data: 0.0001  max mem: 14938
[12:37:11.658644] Test:  [100/345]  eta: 0:00:45  loss: 0.6957 (0.6945)  time: 0.1865  data: 0.0001  max mem: 14938
[12:37:13.528087] Test:  [110/345]  eta: 0:00:43  loss: 0.6984 (0.6950)  time: 0.1868  data: 0.0001  max mem: 14938
[12:37:15.402651] Test:  [120/345]  eta: 0:00:41  loss: 0.6984 (0.6949)  time: 0.1872  data: 0.0001  max mem: 14938
[12:37:17.280774] Test:  [130/345]  eta: 0:00:40  loss: 0.6951 (0.6947)  time: 0.1876  data: 0.0001  max mem: 14938
[12:37:19.161642] Test:  [140/345]  eta: 0:00:38  loss: 0.6951 (0.6949)  time: 0.1879  data: 0.0001  max mem: 14938
[12:37:21.046632] Test:  [150/345]  eta: 0:00:36  loss: 0.6899 (0.6948)  time: 0.1882  data: 0.0001  max mem: 14938
[12:37:22.933441] Test:  [160/345]  eta: 0:00:34  loss: 0.6897 (0.6950)  time: 0.1885  data: 0.0001  max mem: 14938
[12:37:24.823466] Test:  [170/345]  eta: 0:00:32  loss: 0.6929 (0.6952)  time: 0.1888  data: 0.0001  max mem: 14938
[12:37:26.719098] Test:  [180/345]  eta: 0:00:30  loss: 0.6891 (0.6949)  time: 0.1892  data: 0.0001  max mem: 14938
[12:37:28.619396] Test:  [190/345]  eta: 0:00:29  loss: 0.6882 (0.6948)  time: 0.1897  data: 0.0001  max mem: 14938
[12:37:30.523444] Test:  [200/345]  eta: 0:00:27  loss: 0.6865 (0.6947)  time: 0.1902  data: 0.0001  max mem: 14938
[12:37:32.431157] Test:  [210/345]  eta: 0:00:25  loss: 0.6892 (0.6948)  time: 0.1905  data: 0.0001  max mem: 14938
[12:37:34.340273] Test:  [220/345]  eta: 0:00:23  loss: 0.6970 (0.6949)  time: 0.1908  data: 0.0001  max mem: 14938
[12:37:36.254205] Test:  [230/345]  eta: 0:00:21  loss: 0.6935 (0.6949)  time: 0.1911  data: 0.0001  max mem: 14938
[12:37:38.171486] Test:  [240/345]  eta: 0:00:19  loss: 0.6928 (0.6946)  time: 0.1915  data: 0.0001  max mem: 14938
[12:37:40.092098] Test:  [250/345]  eta: 0:00:17  loss: 0.6900 (0.6945)  time: 0.1918  data: 0.0001  max mem: 14938
[12:37:42.016359] Test:  [260/345]  eta: 0:00:16  loss: 0.6907 (0.6944)  time: 0.1922  data: 0.0001  max mem: 14938
[12:37:43.942321] Test:  [270/345]  eta: 0:00:14  loss: 0.6889 (0.6943)  time: 0.1925  data: 0.0001  max mem: 14938
[12:37:45.873586] Test:  [280/345]  eta: 0:00:12  loss: 0.6876 (0.6942)  time: 0.1928  data: 0.0001  max mem: 14938
[12:37:47.807644] Test:  [290/345]  eta: 0:00:10  loss: 0.6882 (0.6941)  time: 0.1932  data: 0.0001  max mem: 14938
[12:37:49.746168] Test:  [300/345]  eta: 0:00:08  loss: 0.6932 (0.6943)  time: 0.1936  data: 0.0001  max mem: 14938
[12:37:51.685289] Test:  [310/345]  eta: 0:00:06  loss: 0.6971 (0.6945)  time: 0.1938  data: 0.0001  max mem: 14938
[12:37:53.629937] Test:  [320/345]  eta: 0:00:04  loss: 0.6970 (0.6945)  time: 0.1941  data: 0.0001  max mem: 14938
[12:37:55.577422] Test:  [330/345]  eta: 0:00:02  loss: 0.6926 (0.6945)  time: 0.1946  data: 0.0001  max mem: 14938
[12:37:57.527329] Test:  [340/345]  eta: 0:00:00  loss: 0.6943 (0.6945)  time: 0.1948  data: 0.0001  max mem: 14938
[12:37:58.309530] Test:  [344/345]  eta: 0:00:00  loss: 0.6939 (0.6945)  time: 0.1950  data: 0.0001  max mem: 14938
[12:37:58.366373] Test: Total time: 0:01:05 (0.1900 s / it)
[12:38:08.745507] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8374 (0.8374)  time: 0.3190  data: 0.1392  max mem: 14938
[12:38:10.560995] Test:  [10/57]  eta: 0:00:09  loss: 0.8641 (0.8757)  time: 0.1940  data: 0.0127  max mem: 14938
[12:38:12.382327] Test:  [20/57]  eta: 0:00:06  loss: 0.8772 (0.8677)  time: 0.1818  data: 0.0001  max mem: 14938
[12:38:14.209362] Test:  [30/57]  eta: 0:00:05  loss: 0.7437 (0.8245)  time: 0.1824  data: 0.0001  max mem: 14938
[12:38:16.038898] Test:  [40/57]  eta: 0:00:03  loss: 0.7362 (0.8041)  time: 0.1827  data: 0.0001  max mem: 14938
[12:38:17.874753] Test:  [50/57]  eta: 0:00:01  loss: 0.7313 (0.7964)  time: 0.1832  data: 0.0001  max mem: 14938
[12:38:18.865422] Test:  [56/57]  eta: 0:00:00  loss: 0.7461 (0.8018)  time: 0.1779  data: 0.0001  max mem: 14938
[12:38:18.921713] Test: Total time: 0:00:10 (0.1841 s / it)
[12:38:20.715868] Dice score of the network on the train images: 0.830839, val images: 0.819486
[12:38:20.720012] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:38:21.606708] Epoch: [36]  [  0/345]  eta: 0:05:05  lr: 0.000056  loss: 0.7076 (0.7076)  time: 0.8856  data: 0.1422  max mem: 14938
[12:38:36.509183] Epoch: [36]  [ 20/345]  eta: 0:04:04  lr: 0.000056  loss: 0.7195 (0.7197)  time: 0.7451  data: 0.0001  max mem: 14938
[12:38:51.457349] Epoch: [36]  [ 40/345]  eta: 0:03:48  lr: 0.000055  loss: 0.7145 (0.7182)  time: 0.7474  data: 0.0001  max mem: 14938
[12:39:06.438697] Epoch: [36]  [ 60/345]  eta: 0:03:33  lr: 0.000055  loss: 0.7178 (0.7193)  time: 0.7490  data: 0.0001  max mem: 14938
[12:39:21.442949] Epoch: [36]  [ 80/345]  eta: 0:03:18  lr: 0.000054  loss: 0.7201 (0.7188)  time: 0.7502  data: 0.0001  max mem: 14938
[12:39:36.479068] Epoch: [36]  [100/345]  eta: 0:03:03  lr: 0.000054  loss: 0.7163 (0.7188)  time: 0.7518  data: 0.0001  max mem: 14938
[12:39:51.530976] Epoch: [36]  [120/345]  eta: 0:02:48  lr: 0.000054  loss: 0.7187 (0.7193)  time: 0.7525  data: 0.0001  max mem: 14938
[12:40:06.587469] Epoch: [36]  [140/345]  eta: 0:02:33  lr: 0.000053  loss: 0.7158 (0.7189)  time: 0.7528  data: 0.0001  max mem: 14938
[12:40:21.632425] Epoch: [36]  [160/345]  eta: 0:02:18  lr: 0.000053  loss: 0.7197 (0.7190)  time: 0.7522  data: 0.0001  max mem: 14938
[12:40:36.635315] Epoch: [36]  [180/345]  eta: 0:02:03  lr: 0.000053  loss: 0.7227 (0.7197)  time: 0.7501  data: 0.0001  max mem: 14938
[12:40:51.629644] Epoch: [36]  [200/345]  eta: 0:01:48  lr: 0.000052  loss: 0.7177 (0.7197)  time: 0.7497  data: 0.0001  max mem: 14938
[12:41:06.624323] Epoch: [36]  [220/345]  eta: 0:01:33  lr: 0.000052  loss: 0.7156 (0.7195)  time: 0.7497  data: 0.0001  max mem: 14938
[12:41:21.616929] Epoch: [36]  [240/345]  eta: 0:01:18  lr: 0.000051  loss: 0.7194 (0.7195)  time: 0.7496  data: 0.0001  max mem: 14938
[12:41:36.601746] Epoch: [36]  [260/345]  eta: 0:01:03  lr: 0.000051  loss: 0.7157 (0.7191)  time: 0.7492  data: 0.0001  max mem: 14938
[12:41:51.578066] Epoch: [36]  [280/345]  eta: 0:00:48  lr: 0.000051  loss: 0.7142 (0.7189)  time: 0.7488  data: 0.0001  max mem: 14938
[12:42:06.554788] Epoch: [36]  [300/345]  eta: 0:00:33  lr: 0.000050  loss: 0.7174 (0.7188)  time: 0.7488  data: 0.0001  max mem: 14938
[12:42:21.554580] Epoch: [36]  [320/345]  eta: 0:00:18  lr: 0.000050  loss: 0.7169 (0.7189)  time: 0.7499  data: 0.0001  max mem: 14938
[12:42:36.556709] Epoch: [36]  [340/345]  eta: 0:00:03  lr: 0.000050  loss: 0.7240 (0.7191)  time: 0.7501  data: 0.0001  max mem: 14938
[12:42:39.556901] Epoch: [36]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.7240 (0.7192)  time: 0.7500  data: 0.0001  max mem: 14938
[12:42:39.621439] Epoch: [36] Total time: 0:04:18 (0.7504 s / it)
[12:42:39.621902] Averaged stats: lr: 0.000050  loss: 0.7240 (0.7192)
[12:42:39.955425] Test:  [  0/345]  eta: 0:01:53  loss: 0.6795 (0.6795)  time: 0.3298  data: 0.1483  max mem: 14938
[12:42:41.793106] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6947 (0.6948)  time: 0.1970  data: 0.0135  max mem: 14938
[12:42:43.633336] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6934 (0.6940)  time: 0.1838  data: 0.0001  max mem: 14938
[12:42:45.477018] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6916 (0.6940)  time: 0.1841  data: 0.0001  max mem: 14938
[12:42:47.322827] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6895 (0.6932)  time: 0.1844  data: 0.0001  max mem: 14938
[12:42:49.173140] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6950 (0.6945)  time: 0.1848  data: 0.0001  max mem: 14938
[12:42:51.028349] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6915 (0.6937)  time: 0.1852  data: 0.0001  max mem: 14938
[12:42:52.884829] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6888 (0.6929)  time: 0.1855  data: 0.0001  max mem: 14938
[12:42:54.745119] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6891 (0.6925)  time: 0.1858  data: 0.0001  max mem: 14938
[12:42:56.608958] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6916 (0.6934)  time: 0.1861  data: 0.0001  max mem: 14938
[12:42:58.476129] Test:  [100/345]  eta: 0:00:45  loss: 0.6978 (0.6934)  time: 0.1865  data: 0.0001  max mem: 14938
[12:43:00.347595] Test:  [110/345]  eta: 0:00:43  loss: 0.6931 (0.6935)  time: 0.1869  data: 0.0001  max mem: 14938
[12:43:02.223207] Test:  [120/345]  eta: 0:00:42  loss: 0.6974 (0.6941)  time: 0.1873  data: 0.0001  max mem: 14938
[12:43:04.100369] Test:  [130/345]  eta: 0:00:40  loss: 0.6981 (0.6943)  time: 0.1876  data: 0.0001  max mem: 14938
[12:43:05.982173] Test:  [140/345]  eta: 0:00:38  loss: 0.6972 (0.6943)  time: 0.1879  data: 0.0001  max mem: 14938
[12:43:07.867175] Test:  [150/345]  eta: 0:00:36  loss: 0.6923 (0.6941)  time: 0.1883  data: 0.0001  max mem: 14938
[12:43:09.754952] Test:  [160/345]  eta: 0:00:34  loss: 0.6966 (0.6944)  time: 0.1886  data: 0.0001  max mem: 14938
[12:43:11.647296] Test:  [170/345]  eta: 0:00:32  loss: 0.6980 (0.6946)  time: 0.1889  data: 0.0001  max mem: 14938
[12:43:13.547017] Test:  [180/345]  eta: 0:00:30  loss: 0.6952 (0.6948)  time: 0.1895  data: 0.0001  max mem: 14938
[12:43:15.447748] Test:  [190/345]  eta: 0:00:29  loss: 0.6952 (0.6947)  time: 0.1900  data: 0.0001  max mem: 14938
[12:43:17.351043] Test:  [200/345]  eta: 0:00:27  loss: 0.6927 (0.6945)  time: 0.1901  data: 0.0001  max mem: 14938
[12:43:19.257826] Test:  [210/345]  eta: 0:00:25  loss: 0.6909 (0.6944)  time: 0.1904  data: 0.0001  max mem: 14938
[12:43:21.168766] Test:  [220/345]  eta: 0:00:23  loss: 0.6909 (0.6944)  time: 0.1908  data: 0.0001  max mem: 14938
[12:43:23.084916] Test:  [230/345]  eta: 0:00:21  loss: 0.6916 (0.6942)  time: 0.1913  data: 0.0001  max mem: 14938
[12:43:25.001871] Test:  [240/345]  eta: 0:00:19  loss: 0.6887 (0.6941)  time: 0.1916  data: 0.0001  max mem: 14938
[12:43:26.922706] Test:  [250/345]  eta: 0:00:17  loss: 0.6922 (0.6940)  time: 0.1918  data: 0.0001  max mem: 14938
[12:43:28.846781] Test:  [260/345]  eta: 0:00:16  loss: 0.6929 (0.6940)  time: 0.1922  data: 0.0001  max mem: 14938
[12:43:30.773793] Test:  [270/345]  eta: 0:00:14  loss: 0.6942 (0.6942)  time: 0.1925  data: 0.0001  max mem: 14938
[12:43:32.703995] Test:  [280/345]  eta: 0:00:12  loss: 0.6928 (0.6941)  time: 0.1928  data: 0.0001  max mem: 14938
[12:43:34.638550] Test:  [290/345]  eta: 0:00:10  loss: 0.6938 (0.6944)  time: 0.1932  data: 0.0001  max mem: 14938
[12:43:36.577953] Test:  [300/345]  eta: 0:00:08  loss: 0.6938 (0.6941)  time: 0.1936  data: 0.0001  max mem: 14938
[12:43:38.518665] Test:  [310/345]  eta: 0:00:06  loss: 0.6909 (0.6941)  time: 0.1940  data: 0.0001  max mem: 14938
[12:43:40.460901] Test:  [320/345]  eta: 0:00:04  loss: 0.7003 (0.6945)  time: 0.1941  data: 0.0001  max mem: 14938
[12:43:42.406748] Test:  [330/345]  eta: 0:00:02  loss: 0.7036 (0.6947)  time: 0.1944  data: 0.0001  max mem: 14938
[12:43:44.356072] Test:  [340/345]  eta: 0:00:00  loss: 0.6995 (0.6946)  time: 0.1947  data: 0.0001  max mem: 14938
[12:43:45.137873] Test:  [344/345]  eta: 0:00:00  loss: 0.6913 (0.6946)  time: 0.1949  data: 0.0001  max mem: 14938
[12:43:45.197483] Test: Total time: 0:01:05 (0.1901 s / it)
[12:43:55.521171] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8351 (0.8351)  time: 0.3181  data: 0.1384  max mem: 14938
[12:43:57.337907] Test:  [10/57]  eta: 0:00:09  loss: 0.8829 (0.8867)  time: 0.1940  data: 0.0126  max mem: 14938
[12:43:59.159207] Test:  [20/57]  eta: 0:00:06  loss: 0.8836 (0.8725)  time: 0.1818  data: 0.0001  max mem: 14938
[12:44:00.984292] Test:  [30/57]  eta: 0:00:05  loss: 0.7629 (0.8307)  time: 0.1823  data: 0.0001  max mem: 14938
[12:44:02.813407] Test:  [40/57]  eta: 0:00:03  loss: 0.7470 (0.8105)  time: 0.1827  data: 0.0001  max mem: 14938
[12:44:04.650478] Test:  [50/57]  eta: 0:00:01  loss: 0.7345 (0.8019)  time: 0.1833  data: 0.0001  max mem: 14938
[12:44:05.639747] Test:  [56/57]  eta: 0:00:00  loss: 0.7576 (0.8062)  time: 0.1779  data: 0.0001  max mem: 14938
[12:44:05.695972] Test: Total time: 0:00:10 (0.1841 s / it)
[12:44:07.456907] Dice score of the network on the train images: 0.835222, val images: 0.816313
[12:44:07.457139] saving best_prec_model_0 @ epoch 36
[12:44:08.602275] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:44:09.482454] Epoch: [37]  [  0/345]  eta: 0:05:03  lr: 0.000050  loss: 0.7243 (0.7243)  time: 0.8790  data: 0.1384  max mem: 14938
[12:44:24.357454] Epoch: [37]  [ 20/345]  eta: 0:04:03  lr: 0.000049  loss: 0.7106 (0.7144)  time: 0.7437  data: 0.0001  max mem: 14938
[12:44:39.284829] Epoch: [37]  [ 40/345]  eta: 0:03:48  lr: 0.000049  loss: 0.7096 (0.7136)  time: 0.7463  data: 0.0001  max mem: 14938
[12:44:54.270842] Epoch: [37]  [ 60/345]  eta: 0:03:33  lr: 0.000048  loss: 0.7159 (0.7153)  time: 0.7493  data: 0.0001  max mem: 14938
[12:45:09.284456] Epoch: [37]  [ 80/345]  eta: 0:03:18  lr: 0.000048  loss: 0.7187 (0.7166)  time: 0.7506  data: 0.0001  max mem: 14938
[12:45:24.302920] Epoch: [37]  [100/345]  eta: 0:03:03  lr: 0.000048  loss: 0.7123 (0.7161)  time: 0.7509  data: 0.0001  max mem: 14938
[12:45:39.347553] Epoch: [37]  [120/345]  eta: 0:02:48  lr: 0.000047  loss: 0.7095 (0.7162)  time: 0.7522  data: 0.0001  max mem: 14938
[12:45:54.390704] Epoch: [37]  [140/345]  eta: 0:02:33  lr: 0.000047  loss: 0.7140 (0.7166)  time: 0.7521  data: 0.0001  max mem: 14938
[12:46:09.421460] Epoch: [37]  [160/345]  eta: 0:02:18  lr: 0.000047  loss: 0.7162 (0.7168)  time: 0.7515  data: 0.0001  max mem: 14938
[12:46:24.455806] Epoch: [37]  [180/345]  eta: 0:02:03  lr: 0.000046  loss: 0.7162 (0.7172)  time: 0.7517  data: 0.0001  max mem: 14938
[12:46:39.450353] Epoch: [37]  [200/345]  eta: 0:01:48  lr: 0.000046  loss: 0.7220 (0.7180)  time: 0.7497  data: 0.0001  max mem: 14938
[12:46:54.442354] Epoch: [37]  [220/345]  eta: 0:01:33  lr: 0.000045  loss: 0.7162 (0.7183)  time: 0.7496  data: 0.0001  max mem: 14938
[12:47:09.464199] Epoch: [37]  [240/345]  eta: 0:01:18  lr: 0.000045  loss: 0.7225 (0.7187)  time: 0.7510  data: 0.0001  max mem: 14938
[12:47:24.452676] Epoch: [37]  [260/345]  eta: 0:01:03  lr: 0.000045  loss: 0.7234 (0.7190)  time: 0.7494  data: 0.0001  max mem: 14938
[12:47:39.452830] Epoch: [37]  [280/345]  eta: 0:00:48  lr: 0.000044  loss: 0.7157 (0.7189)  time: 0.7500  data: 0.0001  max mem: 14938
[12:47:54.453318] Epoch: [37]  [300/345]  eta: 0:00:33  lr: 0.000044  loss: 0.7101 (0.7185)  time: 0.7500  data: 0.0001  max mem: 14938
[12:48:09.447786] Epoch: [37]  [320/345]  eta: 0:00:18  lr: 0.000044  loss: 0.7106 (0.7182)  time: 0.7497  data: 0.0001  max mem: 14938
[12:48:24.436961] Epoch: [37]  [340/345]  eta: 0:00:03  lr: 0.000043  loss: 0.7218 (0.7183)  time: 0.7494  data: 0.0001  max mem: 14938
[12:48:27.436984] Epoch: [37]  [344/345]  eta: 0:00:00  lr: 0.000043  loss: 0.7220 (0.7184)  time: 0.7496  data: 0.0001  max mem: 14938
[12:48:27.500513] Epoch: [37] Total time: 0:04:18 (0.7504 s / it)
[12:48:27.501042] Averaged stats: lr: 0.000043  loss: 0.7220 (0.7184)
[12:48:27.831725] Test:  [  0/345]  eta: 0:01:52  loss: 0.7074 (0.7074)  time: 0.3259  data: 0.1445  max mem: 14938
[12:48:29.669024] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6912 (0.6953)  time: 0.1966  data: 0.0132  max mem: 14938
[12:48:31.509558] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6903 (0.6933)  time: 0.1838  data: 0.0001  max mem: 14938
[12:48:33.352686] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6902 (0.6928)  time: 0.1841  data: 0.0001  max mem: 14938
[12:48:35.199246] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6927 (0.6939)  time: 0.1844  data: 0.0001  max mem: 14938
[12:48:37.050433] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6948 (0.6939)  time: 0.1848  data: 0.0001  max mem: 14938
[12:48:38.906033] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6847 (0.6927)  time: 0.1853  data: 0.0001  max mem: 14938
[12:48:40.763488] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6829 (0.6915)  time: 0.1856  data: 0.0001  max mem: 14938
[12:48:42.624295] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6833 (0.6908)  time: 0.1859  data: 0.0001  max mem: 14938
[12:48:44.488994] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6865 (0.6908)  time: 0.1862  data: 0.0001  max mem: 14938
[12:48:46.356391] Test:  [100/345]  eta: 0:00:45  loss: 0.6886 (0.6907)  time: 0.1866  data: 0.0001  max mem: 14938
[12:48:48.226917] Test:  [110/345]  eta: 0:00:43  loss: 0.6953 (0.6912)  time: 0.1868  data: 0.0001  max mem: 14938
[12:48:50.102304] Test:  [120/345]  eta: 0:00:42  loss: 0.6967 (0.6914)  time: 0.1872  data: 0.0001  max mem: 14938
[12:48:51.980351] Test:  [130/345]  eta: 0:00:40  loss: 0.6939 (0.6917)  time: 0.1876  data: 0.0001  max mem: 14938
[12:48:53.862052] Test:  [140/345]  eta: 0:00:38  loss: 0.6905 (0.6917)  time: 0.1879  data: 0.0001  max mem: 14938
[12:48:55.747201] Test:  [150/345]  eta: 0:00:36  loss: 0.6905 (0.6919)  time: 0.1883  data: 0.0001  max mem: 14938
[12:48:57.634932] Test:  [160/345]  eta: 0:00:34  loss: 0.6929 (0.6920)  time: 0.1886  data: 0.0001  max mem: 14938
[12:48:59.526527] Test:  [170/345]  eta: 0:00:32  loss: 0.6891 (0.6916)  time: 0.1889  data: 0.0001  max mem: 14938
[12:49:01.423752] Test:  [180/345]  eta: 0:00:30  loss: 0.6884 (0.6917)  time: 0.1894  data: 0.0001  max mem: 14938
[12:49:03.325350] Test:  [190/345]  eta: 0:00:29  loss: 0.6906 (0.6919)  time: 0.1899  data: 0.0001  max mem: 14938
[12:49:05.228303] Test:  [200/345]  eta: 0:00:27  loss: 0.6916 (0.6919)  time: 0.1902  data: 0.0001  max mem: 14938
[12:49:07.135430] Test:  [210/345]  eta: 0:00:25  loss: 0.6916 (0.6920)  time: 0.1905  data: 0.0001  max mem: 14938
[12:49:09.045447] Test:  [220/345]  eta: 0:00:23  loss: 0.6903 (0.6920)  time: 0.1908  data: 0.0001  max mem: 14938
[12:49:10.959143] Test:  [230/345]  eta: 0:00:21  loss: 0.6875 (0.6919)  time: 0.1911  data: 0.0001  max mem: 14938
[12:49:12.876441] Test:  [240/345]  eta: 0:00:19  loss: 0.6902 (0.6919)  time: 0.1915  data: 0.0001  max mem: 14938
[12:49:14.798532] Test:  [250/345]  eta: 0:00:17  loss: 0.6920 (0.6919)  time: 0.1919  data: 0.0001  max mem: 14938
[12:49:16.723598] Test:  [260/345]  eta: 0:00:16  loss: 0.6916 (0.6919)  time: 0.1923  data: 0.0001  max mem: 14938
[12:49:18.650843] Test:  [270/345]  eta: 0:00:14  loss: 0.6888 (0.6918)  time: 0.1926  data: 0.0001  max mem: 14938
[12:49:20.582282] Test:  [280/345]  eta: 0:00:12  loss: 0.6885 (0.6918)  time: 0.1929  data: 0.0001  max mem: 14938
[12:49:22.516711] Test:  [290/345]  eta: 0:00:10  loss: 0.6892 (0.6920)  time: 0.1932  data: 0.0001  max mem: 14938
[12:49:24.454525] Test:  [300/345]  eta: 0:00:08  loss: 0.6901 (0.6919)  time: 0.1936  data: 0.0001  max mem: 14938
[12:49:26.395518] Test:  [310/345]  eta: 0:00:06  loss: 0.6901 (0.6918)  time: 0.1939  data: 0.0001  max mem: 14938
[12:49:28.341687] Test:  [320/345]  eta: 0:00:04  loss: 0.6894 (0.6917)  time: 0.1943  data: 0.0001  max mem: 14938
[12:49:30.291536] Test:  [330/345]  eta: 0:00:02  loss: 0.6913 (0.6919)  time: 0.1947  data: 0.0001  max mem: 14938
[12:49:32.245022] Test:  [340/345]  eta: 0:00:00  loss: 0.6954 (0.6922)  time: 0.1951  data: 0.0001  max mem: 14938
[12:49:33.027229] Test:  [344/345]  eta: 0:00:00  loss: 0.6959 (0.6923)  time: 0.1952  data: 0.0001  max mem: 14938
[12:49:33.082934] Test: Total time: 0:01:05 (0.1901 s / it)
[12:49:43.500932] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8449 (0.8449)  time: 0.3225  data: 0.1433  max mem: 14938
[12:49:45.316278] Test:  [10/57]  eta: 0:00:09  loss: 0.8883 (0.8882)  time: 0.1943  data: 0.0131  max mem: 14938
[12:49:47.139418] Test:  [20/57]  eta: 0:00:06  loss: 0.8893 (0.8810)  time: 0.1819  data: 0.0001  max mem: 14938
[12:49:48.966522] Test:  [30/57]  eta: 0:00:05  loss: 0.7586 (0.8360)  time: 0.1825  data: 0.0001  max mem: 14938
[12:49:50.795914] Test:  [40/57]  eta: 0:00:03  loss: 0.7489 (0.8144)  time: 0.1828  data: 0.0001  max mem: 14938
[12:49:52.631159] Test:  [50/57]  eta: 0:00:01  loss: 0.7434 (0.8069)  time: 0.1832  data: 0.0001  max mem: 14938
[12:49:53.621287] Test:  [56/57]  eta: 0:00:00  loss: 0.7551 (0.8112)  time: 0.1778  data: 0.0001  max mem: 14938
[12:49:53.676276] Test: Total time: 0:00:10 (0.1842 s / it)
[12:49:55.406588] Dice score of the network on the train images: 0.839986, val images: 0.814463
[12:49:55.406809] saving best_prec_model_0 @ epoch 37
[12:49:56.465872] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:49:57.357259] Epoch: [38]  [  0/345]  eta: 0:05:07  lr: 0.000043  loss: 0.7105 (0.7105)  time: 0.8903  data: 0.1472  max mem: 14938
[12:50:12.255577] Epoch: [38]  [ 20/345]  eta: 0:04:04  lr: 0.000043  loss: 0.7158 (0.7130)  time: 0.7449  data: 0.0001  max mem: 14938
[12:50:27.206493] Epoch: [38]  [ 40/345]  eta: 0:03:48  lr: 0.000042  loss: 0.7172 (0.7156)  time: 0.7475  data: 0.0001  max mem: 14938
[12:50:42.181659] Epoch: [38]  [ 60/345]  eta: 0:03:33  lr: 0.000042  loss: 0.7191 (0.7162)  time: 0.7487  data: 0.0001  max mem: 14938
[12:50:57.179780] Epoch: [38]  [ 80/345]  eta: 0:03:18  lr: 0.000042  loss: 0.7104 (0.7158)  time: 0.7499  data: 0.0001  max mem: 14938
[12:51:12.207730] Epoch: [38]  [100/345]  eta: 0:03:03  lr: 0.000041  loss: 0.7139 (0.7154)  time: 0.7514  data: 0.0001  max mem: 14938
[12:51:27.384720] Epoch: [38]  [120/345]  eta: 0:02:49  lr: 0.000041  loss: 0.7157 (0.7157)  time: 0.7588  data: 0.0001  max mem: 14938
[12:51:42.400873] Epoch: [38]  [140/345]  eta: 0:02:34  lr: 0.000041  loss: 0.7168 (0.7159)  time: 0.7508  data: 0.0001  max mem: 14938
[12:51:57.411779] Epoch: [38]  [160/345]  eta: 0:02:18  lr: 0.000040  loss: 0.7093 (0.7155)  time: 0.7505  data: 0.0001  max mem: 14938
[12:52:12.419170] Epoch: [38]  [180/345]  eta: 0:02:03  lr: 0.000040  loss: 0.7119 (0.7151)  time: 0.7503  data: 0.0001  max mem: 14938
[12:52:27.419558] Epoch: [38]  [200/345]  eta: 0:01:48  lr: 0.000040  loss: 0.7156 (0.7154)  time: 0.7500  data: 0.0001  max mem: 14938
[12:52:42.415711] Epoch: [38]  [220/345]  eta: 0:01:33  lr: 0.000039  loss: 0.7137 (0.7156)  time: 0.7498  data: 0.0001  max mem: 14938
[12:52:57.408100] Epoch: [38]  [240/345]  eta: 0:01:18  lr: 0.000039  loss: 0.7134 (0.7156)  time: 0.7496  data: 0.0001  max mem: 14938
[12:53:12.393967] Epoch: [38]  [260/345]  eta: 0:01:03  lr: 0.000039  loss: 0.7108 (0.7155)  time: 0.7493  data: 0.0001  max mem: 14938
[12:53:27.380561] Epoch: [38]  [280/345]  eta: 0:00:48  lr: 0.000038  loss: 0.7178 (0.7157)  time: 0.7493  data: 0.0001  max mem: 14938
[12:53:42.374114] Epoch: [38]  [300/345]  eta: 0:00:33  lr: 0.000038  loss: 0.7149 (0.7157)  time: 0.7496  data: 0.0001  max mem: 14938
[12:53:57.364765] Epoch: [38]  [320/345]  eta: 0:00:18  lr: 0.000038  loss: 0.7141 (0.7158)  time: 0.7495  data: 0.0001  max mem: 14938
[12:54:12.361465] Epoch: [38]  [340/345]  eta: 0:00:03  lr: 0.000037  loss: 0.7190 (0.7160)  time: 0.7498  data: 0.0001  max mem: 14938
[12:54:15.365556] Epoch: [38]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 0.7170 (0.7159)  time: 0.7503  data: 0.0001  max mem: 14938
[12:54:15.428817] Epoch: [38] Total time: 0:04:18 (0.7506 s / it)
[12:54:15.429119] Averaged stats: lr: 0.000037  loss: 0.7170 (0.7159)
[12:54:15.758993] Test:  [  0/345]  eta: 0:01:52  loss: 0.6721 (0.6721)  time: 0.3253  data: 0.1438  max mem: 14938
[12:54:17.596262] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6932 (0.6941)  time: 0.1965  data: 0.0131  max mem: 14938
[12:54:19.435540] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6917 (0.6921)  time: 0.1838  data: 0.0001  max mem: 14938
[12:54:21.278097] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6872 (0.6912)  time: 0.1840  data: 0.0001  max mem: 14938
[12:54:23.124755] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6895 (0.6916)  time: 0.1844  data: 0.0001  max mem: 14938
[12:54:24.975188] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6903 (0.6918)  time: 0.1848  data: 0.0001  max mem: 14938
[12:54:26.829746] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6916 (0.6917)  time: 0.1852  data: 0.0001  max mem: 14938
[12:54:28.686261] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6904 (0.6915)  time: 0.1855  data: 0.0001  max mem: 14938
[12:54:30.546386] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6887 (0.6910)  time: 0.1858  data: 0.0001  max mem: 14938
[12:54:32.409168] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6909 (0.6910)  time: 0.1861  data: 0.0001  max mem: 14938
[12:54:34.277481] Test:  [100/345]  eta: 0:00:45  loss: 0.6946 (0.6917)  time: 0.1865  data: 0.0001  max mem: 14938
[12:54:36.146595] Test:  [110/345]  eta: 0:00:43  loss: 0.6946 (0.6916)  time: 0.1868  data: 0.0001  max mem: 14938
[12:54:38.021568] Test:  [120/345]  eta: 0:00:41  loss: 0.6902 (0.6916)  time: 0.1872  data: 0.0001  max mem: 14938
[12:54:39.900190] Test:  [130/345]  eta: 0:00:40  loss: 0.6864 (0.6910)  time: 0.1876  data: 0.0001  max mem: 14938
[12:54:41.782043] Test:  [140/345]  eta: 0:00:38  loss: 0.6869 (0.6908)  time: 0.1880  data: 0.0001  max mem: 14938
[12:54:43.668464] Test:  [150/345]  eta: 0:00:36  loss: 0.6876 (0.6909)  time: 0.1884  data: 0.0001  max mem: 14938
[12:54:45.554891] Test:  [160/345]  eta: 0:00:34  loss: 0.6872 (0.6906)  time: 0.1886  data: 0.0001  max mem: 14938
[12:54:47.446387] Test:  [170/345]  eta: 0:00:32  loss: 0.6884 (0.6909)  time: 0.1888  data: 0.0001  max mem: 14938
[12:54:49.341563] Test:  [180/345]  eta: 0:00:30  loss: 0.6856 (0.6903)  time: 0.1893  data: 0.0001  max mem: 14938
[12:54:51.241240] Test:  [190/345]  eta: 0:00:29  loss: 0.6820 (0.6902)  time: 0.1897  data: 0.0001  max mem: 14938
[12:54:53.143321] Test:  [200/345]  eta: 0:00:27  loss: 0.6899 (0.6903)  time: 0.1900  data: 0.0001  max mem: 14938
[12:54:55.048395] Test:  [210/345]  eta: 0:00:25  loss: 0.6902 (0.6903)  time: 0.1903  data: 0.0001  max mem: 14938
[12:54:56.958175] Test:  [220/345]  eta: 0:00:23  loss: 0.6883 (0.6903)  time: 0.1907  data: 0.0001  max mem: 14938
[12:54:58.870892] Test:  [230/345]  eta: 0:00:21  loss: 0.6885 (0.6905)  time: 0.1911  data: 0.0001  max mem: 14938
[12:55:00.787527] Test:  [240/345]  eta: 0:00:19  loss: 0.6889 (0.6904)  time: 0.1914  data: 0.0001  max mem: 14938
[12:55:02.708557] Test:  [250/345]  eta: 0:00:17  loss: 0.6849 (0.6902)  time: 0.1918  data: 0.0001  max mem: 14938
[12:55:04.632566] Test:  [260/345]  eta: 0:00:16  loss: 0.6840 (0.6902)  time: 0.1922  data: 0.0001  max mem: 14938
[12:55:06.558535] Test:  [270/345]  eta: 0:00:14  loss: 0.6888 (0.6903)  time: 0.1924  data: 0.0001  max mem: 14938
[12:55:08.491401] Test:  [280/345]  eta: 0:00:12  loss: 0.6890 (0.6901)  time: 0.1929  data: 0.0001  max mem: 14938
[12:55:10.426927] Test:  [290/345]  eta: 0:00:10  loss: 0.6881 (0.6901)  time: 0.1934  data: 0.0001  max mem: 14938
[12:55:12.363867] Test:  [300/345]  eta: 0:00:08  loss: 0.6875 (0.6901)  time: 0.1936  data: 0.0001  max mem: 14938
[12:55:14.304939] Test:  [310/345]  eta: 0:00:06  loss: 0.6818 (0.6899)  time: 0.1938  data: 0.0001  max mem: 14938
[12:55:16.249060] Test:  [320/345]  eta: 0:00:04  loss: 0.6846 (0.6900)  time: 0.1942  data: 0.0001  max mem: 14938
[12:55:18.195885] Test:  [330/345]  eta: 0:00:02  loss: 0.6846 (0.6898)  time: 0.1945  data: 0.0001  max mem: 14938
[12:55:20.145677] Test:  [340/345]  eta: 0:00:00  loss: 0.6835 (0.6898)  time: 0.1948  data: 0.0001  max mem: 14938
[12:55:20.928194] Test:  [344/345]  eta: 0:00:00  loss: 0.6835 (0.6897)  time: 0.1950  data: 0.0001  max mem: 14938
[12:55:20.988257] Test: Total time: 0:01:05 (0.1900 s / it)
[12:55:31.427404] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8422 (0.8422)  time: 0.3175  data: 0.1381  max mem: 14938
[12:55:33.242688] Test:  [10/57]  eta: 0:00:09  loss: 0.8618 (0.8793)  time: 0.1938  data: 0.0126  max mem: 14938
[12:55:35.066422] Test:  [20/57]  eta: 0:00:06  loss: 0.8693 (0.8727)  time: 0.1819  data: 0.0001  max mem: 14938
[12:55:36.892718] Test:  [30/57]  eta: 0:00:05  loss: 0.7497 (0.8285)  time: 0.1824  data: 0.0001  max mem: 14938
[12:55:38.722579] Test:  [40/57]  eta: 0:00:03  loss: 0.7432 (0.8071)  time: 0.1828  data: 0.0001  max mem: 14938
[12:55:40.558560] Test:  [50/57]  eta: 0:00:01  loss: 0.7423 (0.7994)  time: 0.1832  data: 0.0001  max mem: 14938
[12:55:41.549338] Test:  [56/57]  eta: 0:00:00  loss: 0.7477 (0.8042)  time: 0.1779  data: 0.0001  max mem: 14938
[12:55:41.605810] Test: Total time: 0:00:10 (0.1841 s / it)
[12:55:43.346005] Dice score of the network on the train images: 0.832593, val images: 0.818145
[12:55:43.350506] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:55:44.236849] Epoch: [39]  [  0/345]  eta: 0:05:05  lr: 0.000037  loss: 0.7183 (0.7183)  time: 0.8853  data: 0.1425  max mem: 14938
[12:55:59.146758] Epoch: [39]  [ 20/345]  eta: 0:04:04  lr: 0.000037  loss: 0.7082 (0.7087)  time: 0.7454  data: 0.0001  max mem: 14938
[12:56:14.104579] Epoch: [39]  [ 40/345]  eta: 0:03:48  lr: 0.000036  loss: 0.7162 (0.7126)  time: 0.7479  data: 0.0001  max mem: 14938
[12:56:29.083542] Epoch: [39]  [ 60/345]  eta: 0:03:33  lr: 0.000036  loss: 0.7095 (0.7132)  time: 0.7489  data: 0.0001  max mem: 14938
[12:56:44.075898] Epoch: [39]  [ 80/345]  eta: 0:03:18  lr: 0.000036  loss: 0.7066 (0.7131)  time: 0.7496  data: 0.0001  max mem: 14938
[12:56:59.077355] Epoch: [39]  [100/345]  eta: 0:03:03  lr: 0.000035  loss: 0.7179 (0.7145)  time: 0.7500  data: 0.0001  max mem: 14938
[12:57:14.225126] Epoch: [39]  [120/345]  eta: 0:02:48  lr: 0.000035  loss: 0.7134 (0.7145)  time: 0.7573  data: 0.0001  max mem: 14938
[12:57:29.265542] Epoch: [39]  [140/345]  eta: 0:02:33  lr: 0.000035  loss: 0.7074 (0.7137)  time: 0.7520  data: 0.0001  max mem: 14938
[12:57:44.285677] Epoch: [39]  [160/345]  eta: 0:02:18  lr: 0.000034  loss: 0.7062 (0.7134)  time: 0.7510  data: 0.0001  max mem: 14938
[12:57:59.307349] Epoch: [39]  [180/345]  eta: 0:02:03  lr: 0.000034  loss: 0.7067 (0.7131)  time: 0.7510  data: 0.0001  max mem: 14938
[12:58:14.314616] Epoch: [39]  [200/345]  eta: 0:01:48  lr: 0.000034  loss: 0.7140 (0.7133)  time: 0.7503  data: 0.0001  max mem: 14938
[12:58:29.327839] Epoch: [39]  [220/345]  eta: 0:01:33  lr: 0.000033  loss: 0.7130 (0.7136)  time: 0.7506  data: 0.0001  max mem: 14938
[12:58:44.342068] Epoch: [39]  [240/345]  eta: 0:01:18  lr: 0.000033  loss: 0.7106 (0.7135)  time: 0.7507  data: 0.0001  max mem: 14938
[12:58:59.349936] Epoch: [39]  [260/345]  eta: 0:01:03  lr: 0.000033  loss: 0.7163 (0.7135)  time: 0.7503  data: 0.0001  max mem: 14938
[12:59:14.360859] Epoch: [39]  [280/345]  eta: 0:00:48  lr: 0.000032  loss: 0.7051 (0.7132)  time: 0.7505  data: 0.0001  max mem: 14938
[12:59:29.365512] Epoch: [39]  [300/345]  eta: 0:00:33  lr: 0.000032  loss: 0.7090 (0.7131)  time: 0.7502  data: 0.0001  max mem: 14938
[12:59:44.363781] Epoch: [39]  [320/345]  eta: 0:00:18  lr: 0.000032  loss: 0.7114 (0.7130)  time: 0.7499  data: 0.0001  max mem: 14938
[12:59:59.349850] Epoch: [39]  [340/345]  eta: 0:00:03  lr: 0.000031  loss: 0.7178 (0.7132)  time: 0.7493  data: 0.0001  max mem: 14938
[13:00:02.347677] Epoch: [39]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 0.7178 (0.7132)  time: 0.7491  data: 0.0001  max mem: 14938
[13:00:02.411624] Epoch: [39] Total time: 0:04:19 (0.7509 s / it)
[13:00:02.412042] Averaged stats: lr: 0.000031  loss: 0.7178 (0.7132)
[13:00:02.744035] Test:  [  0/345]  eta: 0:01:53  loss: 0.6844 (0.6844)  time: 0.3285  data: 0.1468  max mem: 14938
[13:00:04.580685] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6842 (0.6851)  time: 0.1968  data: 0.0134  max mem: 14938
[13:00:06.419705] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6842 (0.6874)  time: 0.1837  data: 0.0001  max mem: 14938
[13:00:08.262977] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6855 (0.6863)  time: 0.1841  data: 0.0001  max mem: 14938
[13:00:10.109969] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6819 (0.6855)  time: 0.1844  data: 0.0001  max mem: 14938
[13:00:11.961235] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6825 (0.6865)  time: 0.1848  data: 0.0001  max mem: 14938
[13:00:13.814930] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6890 (0.6877)  time: 0.1852  data: 0.0001  max mem: 14938
[13:00:15.671098] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6874 (0.6883)  time: 0.1854  data: 0.0001  max mem: 14938
[13:00:17.532174] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6854 (0.6881)  time: 0.1858  data: 0.0001  max mem: 14938
[13:00:19.395722] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6872 (0.6880)  time: 0.1862  data: 0.0001  max mem: 14938
[13:00:21.263865] Test:  [100/345]  eta: 0:00:45  loss: 0.6886 (0.6881)  time: 0.1865  data: 0.0001  max mem: 14938
[13:00:23.133031] Test:  [110/345]  eta: 0:00:43  loss: 0.6827 (0.6877)  time: 0.1868  data: 0.0001  max mem: 14938
[13:00:25.007257] Test:  [120/345]  eta: 0:00:41  loss: 0.6847 (0.6886)  time: 0.1871  data: 0.0001  max mem: 14938
[13:00:26.887427] Test:  [130/345]  eta: 0:00:40  loss: 0.6893 (0.6891)  time: 0.1877  data: 0.0001  max mem: 14938
[13:00:28.768207] Test:  [140/345]  eta: 0:00:38  loss: 0.6887 (0.6893)  time: 0.1880  data: 0.0001  max mem: 14938
[13:00:30.652752] Test:  [150/345]  eta: 0:00:36  loss: 0.6854 (0.6889)  time: 0.1882  data: 0.0001  max mem: 14938
[13:00:32.542024] Test:  [160/345]  eta: 0:00:34  loss: 0.6842 (0.6889)  time: 0.1886  data: 0.0001  max mem: 14938
[13:00:34.432512] Test:  [170/345]  eta: 0:00:32  loss: 0.6840 (0.6888)  time: 0.1889  data: 0.0001  max mem: 14938
[13:00:36.328695] Test:  [180/345]  eta: 0:00:30  loss: 0.6895 (0.6891)  time: 0.1893  data: 0.0001  max mem: 14938
[13:00:38.228550] Test:  [190/345]  eta: 0:00:29  loss: 0.6905 (0.6892)  time: 0.1897  data: 0.0001  max mem: 14938
[13:00:40.130970] Test:  [200/345]  eta: 0:00:27  loss: 0.6869 (0.6891)  time: 0.1901  data: 0.0001  max mem: 14938
[13:00:42.037580] Test:  [210/345]  eta: 0:00:25  loss: 0.6877 (0.6895)  time: 0.1904  data: 0.0001  max mem: 14938
[13:00:43.948448] Test:  [220/345]  eta: 0:00:23  loss: 0.6877 (0.6895)  time: 0.1908  data: 0.0001  max mem: 14938
[13:00:45.862312] Test:  [230/345]  eta: 0:00:21  loss: 0.6835 (0.6893)  time: 0.1912  data: 0.0001  max mem: 14938
[13:00:47.779035] Test:  [240/345]  eta: 0:00:19  loss: 0.6832 (0.6892)  time: 0.1915  data: 0.0001  max mem: 14938
[13:00:49.698835] Test:  [250/345]  eta: 0:00:17  loss: 0.6933 (0.6895)  time: 0.1918  data: 0.0001  max mem: 14938
[13:00:51.621554] Test:  [260/345]  eta: 0:00:16  loss: 0.6964 (0.6898)  time: 0.1921  data: 0.0001  max mem: 14938
[13:00:53.547262] Test:  [270/345]  eta: 0:00:14  loss: 0.6923 (0.6898)  time: 0.1924  data: 0.0001  max mem: 14938
[13:00:55.480160] Test:  [280/345]  eta: 0:00:12  loss: 0.6900 (0.6898)  time: 0.1929  data: 0.0001  max mem: 14938
[13:00:57.413378] Test:  [290/345]  eta: 0:00:10  loss: 0.6900 (0.6899)  time: 0.1933  data: 0.0001  max mem: 14938
[13:00:59.348861] Test:  [300/345]  eta: 0:00:08  loss: 0.6850 (0.6897)  time: 0.1934  data: 0.0001  max mem: 14938
[13:01:01.289508] Test:  [310/345]  eta: 0:00:06  loss: 0.6825 (0.6897)  time: 0.1938  data: 0.0001  max mem: 14938
[13:01:03.232125] Test:  [320/345]  eta: 0:00:04  loss: 0.6917 (0.6897)  time: 0.1941  data: 0.0001  max mem: 14938
[13:01:05.178560] Test:  [330/345]  eta: 0:00:02  loss: 0.6896 (0.6895)  time: 0.1944  data: 0.0001  max mem: 14938
[13:01:07.127684] Test:  [340/345]  eta: 0:00:00  loss: 0.6872 (0.6895)  time: 0.1947  data: 0.0001  max mem: 14938
[13:01:07.910149] Test:  [344/345]  eta: 0:00:00  loss: 0.6860 (0.6894)  time: 0.1949  data: 0.0001  max mem: 14938
[13:01:07.969971] Test: Total time: 0:01:05 (0.1900 s / it)
[13:01:18.354799] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8360 (0.8360)  time: 0.3179  data: 0.1384  max mem: 14938
[13:01:20.172380] Test:  [10/57]  eta: 0:00:09  loss: 0.8735 (0.8776)  time: 0.1941  data: 0.0126  max mem: 14938
[13:01:21.995269] Test:  [20/57]  eta: 0:00:06  loss: 0.8735 (0.8691)  time: 0.1820  data: 0.0001  max mem: 14938
[13:01:23.820897] Test:  [30/57]  eta: 0:00:05  loss: 0.7526 (0.8261)  time: 0.1824  data: 0.0001  max mem: 14938
[13:01:25.650513] Test:  [40/57]  eta: 0:00:03  loss: 0.7392 (0.8049)  time: 0.1827  data: 0.0001  max mem: 14938
[13:01:27.484874] Test:  [50/57]  eta: 0:00:01  loss: 0.7319 (0.7959)  time: 0.1831  data: 0.0001  max mem: 14938
[13:01:28.475096] Test:  [56/57]  eta: 0:00:00  loss: 0.7578 (0.8013)  time: 0.1777  data: 0.0001  max mem: 14938
[13:01:28.534586] Test: Total time: 0:00:10 (0.1842 s / it)
[13:01:30.263978] Dice score of the network on the train images: 0.827538, val images: 0.823710
[13:01:30.268216] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:01:31.150630] Epoch: [40]  [  0/345]  eta: 0:05:04  lr: 0.000031  loss: 0.7308 (0.7308)  time: 0.8813  data: 0.1390  max mem: 14938
[13:01:46.030341] Epoch: [40]  [ 20/345]  eta: 0:04:03  lr: 0.000031  loss: 0.7093 (0.7112)  time: 0.7439  data: 0.0001  max mem: 14938
[13:02:00.972472] Epoch: [40]  [ 40/345]  eta: 0:03:48  lr: 0.000031  loss: 0.7128 (0.7127)  time: 0.7471  data: 0.0001  max mem: 14938
[13:02:15.947472] Epoch: [40]  [ 60/345]  eta: 0:03:33  lr: 0.000030  loss: 0.7131 (0.7133)  time: 0.7487  data: 0.0001  max mem: 14938
[13:02:30.948695] Epoch: [40]  [ 80/345]  eta: 0:03:18  lr: 0.000030  loss: 0.7138 (0.7132)  time: 0.7500  data: 0.0001  max mem: 14938
[13:02:45.960868] Epoch: [40]  [100/345]  eta: 0:03:03  lr: 0.000030  loss: 0.7077 (0.7130)  time: 0.7506  data: 0.0001  max mem: 14938
[13:03:01.118313] Epoch: [40]  [120/345]  eta: 0:02:48  lr: 0.000029  loss: 0.7137 (0.7129)  time: 0.7578  data: 0.0001  max mem: 14938
[13:03:16.143772] Epoch: [40]  [140/345]  eta: 0:02:33  lr: 0.000029  loss: 0.7087 (0.7132)  time: 0.7512  data: 0.0001  max mem: 14938
[13:03:31.165540] Epoch: [40]  [160/345]  eta: 0:02:18  lr: 0.000029  loss: 0.7115 (0.7128)  time: 0.7510  data: 0.0001  max mem: 14938
[13:03:46.192526] Epoch: [40]  [180/345]  eta: 0:02:03  lr: 0.000028  loss: 0.7073 (0.7124)  time: 0.7513  data: 0.0001  max mem: 14938
[13:04:01.213427] Epoch: [40]  [200/345]  eta: 0:01:48  lr: 0.000028  loss: 0.7050 (0.7118)  time: 0.7510  data: 0.0001  max mem: 14938
[13:04:16.220120] Epoch: [40]  [220/345]  eta: 0:01:33  lr: 0.000028  loss: 0.7069 (0.7118)  time: 0.7503  data: 0.0001  max mem: 14938
[13:04:31.220656] Epoch: [40]  [240/345]  eta: 0:01:18  lr: 0.000027  loss: 0.7091 (0.7115)  time: 0.7500  data: 0.0001  max mem: 14938
[13:04:46.225408] Epoch: [40]  [260/345]  eta: 0:01:03  lr: 0.000027  loss: 0.7092 (0.7115)  time: 0.7502  data: 0.0001  max mem: 14938
[13:05:01.217072] Epoch: [40]  [280/345]  eta: 0:00:48  lr: 0.000027  loss: 0.7021 (0.7110)  time: 0.7495  data: 0.0001  max mem: 14938
[13:05:16.194089] Epoch: [40]  [300/345]  eta: 0:00:33  lr: 0.000026  loss: 0.7019 (0.7107)  time: 0.7488  data: 0.0001  max mem: 14938
[13:05:31.185152] Epoch: [40]  [320/345]  eta: 0:00:18  lr: 0.000026  loss: 0.7138 (0.7109)  time: 0.7495  data: 0.0001  max mem: 14938
[13:05:46.165917] Epoch: [40]  [340/345]  eta: 0:00:03  lr: 0.000026  loss: 0.7089 (0.7110)  time: 0.7490  data: 0.0001  max mem: 14938
[13:05:49.166719] Epoch: [40]  [344/345]  eta: 0:00:00  lr: 0.000026  loss: 0.7104 (0.7110)  time: 0.7492  data: 0.0001  max mem: 14938
[13:05:49.230699] Epoch: [40] Total time: 0:04:18 (0.7506 s / it)
[13:05:49.231158] Averaged stats: lr: 0.000026  loss: 0.7104 (0.7110)
[13:05:49.563069] Test:  [  0/345]  eta: 0:01:52  loss: 0.6777 (0.6777)  time: 0.3273  data: 0.1460  max mem: 14938
[13:05:51.400684] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6879 (0.6894)  time: 0.1967  data: 0.0133  max mem: 14938
[13:05:53.241025] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6881 (0.6886)  time: 0.1838  data: 0.0001  max mem: 14938
[13:05:55.083420] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6844 (0.6857)  time: 0.1841  data: 0.0001  max mem: 14938
[13:05:56.930530] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6778 (0.6844)  time: 0.1844  data: 0.0001  max mem: 14938
[13:05:58.781031] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6841 (0.6851)  time: 0.1848  data: 0.0001  max mem: 14938
[13:06:00.634859] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6857 (0.6850)  time: 0.1852  data: 0.0001  max mem: 14938
[13:06:02.490773] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6834 (0.6853)  time: 0.1854  data: 0.0001  max mem: 14938
[13:06:04.349955] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6828 (0.6851)  time: 0.1857  data: 0.0001  max mem: 14938
[13:06:06.212797] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6809 (0.6845)  time: 0.1860  data: 0.0001  max mem: 14938
[13:06:08.079327] Test:  [100/345]  eta: 0:00:45  loss: 0.6867 (0.6850)  time: 0.1864  data: 0.0001  max mem: 14938
[13:06:09.950174] Test:  [110/345]  eta: 0:00:43  loss: 0.6841 (0.6848)  time: 0.1868  data: 0.0001  max mem: 14938
[13:06:11.824033] Test:  [120/345]  eta: 0:00:41  loss: 0.6806 (0.6845)  time: 0.1872  data: 0.0001  max mem: 14938
[13:06:13.701770] Test:  [130/345]  eta: 0:00:40  loss: 0.6786 (0.6842)  time: 0.1875  data: 0.0001  max mem: 14938
[13:06:15.583080] Test:  [140/345]  eta: 0:00:38  loss: 0.6842 (0.6842)  time: 0.1879  data: 0.0001  max mem: 14938
[13:06:17.468232] Test:  [150/345]  eta: 0:00:36  loss: 0.6874 (0.6846)  time: 0.1883  data: 0.0001  max mem: 14938
[13:06:19.354862] Test:  [160/345]  eta: 0:00:34  loss: 0.6872 (0.6846)  time: 0.1885  data: 0.0001  max mem: 14938
[13:06:21.245794] Test:  [170/345]  eta: 0:00:32  loss: 0.6824 (0.6846)  time: 0.1888  data: 0.0001  max mem: 14938
[13:06:23.141747] Test:  [180/345]  eta: 0:00:30  loss: 0.6800 (0.6847)  time: 0.1893  data: 0.0001  max mem: 14938
[13:06:25.042396] Test:  [190/345]  eta: 0:00:29  loss: 0.6833 (0.6846)  time: 0.1898  data: 0.0001  max mem: 14938
[13:06:26.945886] Test:  [200/345]  eta: 0:00:27  loss: 0.6836 (0.6850)  time: 0.1902  data: 0.0001  max mem: 14938
[13:06:28.851233] Test:  [210/345]  eta: 0:00:25  loss: 0.6878 (0.6852)  time: 0.1904  data: 0.0001  max mem: 14938
[13:06:30.760454] Test:  [220/345]  eta: 0:00:23  loss: 0.6873 (0.6851)  time: 0.1907  data: 0.0001  max mem: 14938
[13:06:32.675476] Test:  [230/345]  eta: 0:00:21  loss: 0.6833 (0.6853)  time: 0.1912  data: 0.0001  max mem: 14938
[13:06:34.593874] Test:  [240/345]  eta: 0:00:19  loss: 0.6869 (0.6854)  time: 0.1916  data: 0.0001  max mem: 14938
[13:06:36.514591] Test:  [250/345]  eta: 0:00:17  loss: 0.6862 (0.6855)  time: 0.1919  data: 0.0001  max mem: 14938
[13:06:38.437880] Test:  [260/345]  eta: 0:00:16  loss: 0.6818 (0.6855)  time: 0.1921  data: 0.0001  max mem: 14938
[13:06:40.366038] Test:  [270/345]  eta: 0:00:14  loss: 0.6797 (0.6854)  time: 0.1925  data: 0.0001  max mem: 14938
[13:06:42.297056] Test:  [280/345]  eta: 0:00:12  loss: 0.6833 (0.6854)  time: 0.1929  data: 0.0001  max mem: 14938
[13:06:44.230575] Test:  [290/345]  eta: 0:00:10  loss: 0.6868 (0.6855)  time: 0.1932  data: 0.0001  max mem: 14938
[13:06:46.168402] Test:  [300/345]  eta: 0:00:08  loss: 0.6870 (0.6855)  time: 0.1935  data: 0.0001  max mem: 14938
[13:06:48.107931] Test:  [310/345]  eta: 0:00:06  loss: 0.6870 (0.6856)  time: 0.1938  data: 0.0001  max mem: 14938
[13:06:50.051773] Test:  [320/345]  eta: 0:00:04  loss: 0.6910 (0.6859)  time: 0.1941  data: 0.0001  max mem: 14938
[13:06:51.998630] Test:  [330/345]  eta: 0:00:02  loss: 0.6879 (0.6859)  time: 0.1945  data: 0.0001  max mem: 14938
[13:06:53.947742] Test:  [340/345]  eta: 0:00:00  loss: 0.6885 (0.6860)  time: 0.1947  data: 0.0001  max mem: 14938
[13:06:54.728741] Test:  [344/345]  eta: 0:00:00  loss: 0.6896 (0.6860)  time: 0.1949  data: 0.0001  max mem: 14938
[13:06:54.789616] Test: Total time: 0:01:05 (0.1900 s / it)
[13:07:05.183716] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8466 (0.8466)  time: 0.3180  data: 0.1385  max mem: 14938
[13:07:06.998277] Test:  [10/57]  eta: 0:00:09  loss: 0.8741 (0.8847)  time: 0.1938  data: 0.0126  max mem: 14938
[13:07:08.818112] Test:  [20/57]  eta: 0:00:06  loss: 0.8806 (0.8763)  time: 0.1817  data: 0.0001  max mem: 14938
[13:07:10.643217] Test:  [30/57]  eta: 0:00:05  loss: 0.7585 (0.8318)  time: 0.1822  data: 0.0001  max mem: 14938
[13:07:12.471715] Test:  [40/57]  eta: 0:00:03  loss: 0.7423 (0.8103)  time: 0.1826  data: 0.0001  max mem: 14938
[13:07:14.307636] Test:  [50/57]  eta: 0:00:01  loss: 0.7338 (0.8020)  time: 0.1831  data: 0.0001  max mem: 14938
[13:07:15.297398] Test:  [56/57]  eta: 0:00:00  loss: 0.7550 (0.8070)  time: 0.1778  data: 0.0001  max mem: 14938
[13:07:15.357364] Test: Total time: 0:00:10 (0.1841 s / it)
[13:07:17.108337] Dice score of the network on the train images: 0.839331, val images: 0.821304
[13:07:17.112361] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:07:17.996851] Epoch: [41]  [  0/345]  eta: 0:05:04  lr: 0.000026  loss: 0.7000 (0.7000)  time: 0.8836  data: 0.1415  max mem: 14938
[13:07:32.897614] Epoch: [41]  [ 20/345]  eta: 0:04:04  lr: 0.000025  loss: 0.7009 (0.7040)  time: 0.7450  data: 0.0001  max mem: 14938
[13:07:47.840747] Epoch: [41]  [ 40/345]  eta: 0:03:48  lr: 0.000025  loss: 0.7095 (0.7080)  time: 0.7471  data: 0.0001  max mem: 14938
[13:08:02.796922] Epoch: [41]  [ 60/345]  eta: 0:03:33  lr: 0.000025  loss: 0.7076 (0.7088)  time: 0.7478  data: 0.0001  max mem: 14938
[13:08:17.786085] Epoch: [41]  [ 80/345]  eta: 0:03:18  lr: 0.000025  loss: 0.7070 (0.7093)  time: 0.7494  data: 0.0001  max mem: 14938

[13:08:32.800229] Epoch: [41]  [100/345]  eta: 0:03:03  lr: 0.000024  loss: 0.7099 (0.7098)  time: 0.7507  data: 0.0001  max mem: 14938
[13:08:47.828835] Epoch: [41]  [120/345]  eta: 0:02:48  lr: 0.000024  loss: 0.7035 (0.7092)  time: 0.7514  data: 0.0001  max mem: 14938
[13:09:02.859591] Epoch: [41]  [140/345]  eta: 0:02:33  lr: 0.000024  loss: 0.7051 (0.7093)  time: 0.7515  data: 0.0001  max mem: 14938
[13:09:17.889201] Epoch: [41]  [160/345]  eta: 0:02:18  lr: 0.000023  loss: 0.7092 (0.7093)  time: 0.7514  data: 0.0001  max mem: 14938
[13:09:32.922591] Epoch: [41]  [180/345]  eta: 0:02:03  lr: 0.000023  loss: 0.7051 (0.7090)  time: 0.7516  data: 0.0001  max mem: 14938
[13:09:47.946327] Epoch: [41]  [200/345]  eta: 0:01:48  lr: 0.000023  loss: 0.7088 (0.7091)  time: 0.7511  data: 0.0001  max mem: 14938
[13:10:02.962422] Epoch: [41]  [220/345]  eta: 0:01:33  lr: 0.000022  loss: 0.7078 (0.7091)  time: 0.7508  data: 0.0001  max mem: 14938
[13:10:17.971996] Epoch: [41]  [240/345]  eta: 0:01:18  lr: 0.000022  loss: 0.7107 (0.7092)  time: 0.7504  data: 0.0001  max mem: 14938
[13:10:32.977026] Epoch: [41]  [260/345]  eta: 0:01:03  lr: 0.000022  loss: 0.7155 (0.7097)  time: 0.7502  data: 0.0001  max mem: 14938
[13:10:47.976543] Epoch: [41]  [280/345]  eta: 0:00:48  lr: 0.000022  loss: 0.7116 (0.7098)  time: 0.7499  data: 0.0001  max mem: 14938
[13:11:02.973264] Epoch: [41]  [300/345]  eta: 0:00:33  lr: 0.000021  loss: 0.7081 (0.7100)  time: 0.7498  data: 0.0001  max mem: 14938
[13:11:17.961023] Epoch: [41]  [320/345]  eta: 0:00:18  lr: 0.000021  loss: 0.7042 (0.7099)  time: 0.7494  data: 0.0001  max mem: 14938
[13:11:32.956822] Epoch: [41]  [340/345]  eta: 0:00:03  lr: 0.000021  loss: 0.7080 (0.7100)  time: 0.7498  data: 0.0001  max mem: 14938
[13:11:35.956181] Epoch: [41]  [344/345]  eta: 0:00:00  lr: 0.000021  loss: 0.7104 (0.7100)  time: 0.7498  data: 0.0001  max mem: 14938
[13:11:36.020434] Epoch: [41] Total time: 0:04:18 (0.7505 s / it)
[13:11:36.020741] Averaged stats: lr: 0.000021  loss: 0.7104 (0.7100)
[13:11:36.351442] Test:  [  0/345]  eta: 0:01:52  loss: 0.6857 (0.6857)  time: 0.3262  data: 0.1448  max mem: 14938
[13:11:38.187003] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6926 (0.6894)  time: 0.1965  data: 0.0132  max mem: 14938
[13:11:40.027409] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6931 (0.6913)  time: 0.1837  data: 0.0001  max mem: 14938
[13:11:41.871540] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6866 (0.6901)  time: 0.1842  data: 0.0001  max mem: 14938
[13:11:43.718478] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6810 (0.6888)  time: 0.1845  data: 0.0001  max mem: 14938
[13:11:45.568462] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6806 (0.6868)  time: 0.1848  data: 0.0001  max mem: 14938
[13:11:47.423328] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6806 (0.6862)  time: 0.1852  data: 0.0001  max mem: 14938
[13:11:49.279761] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6846 (0.6866)  time: 0.1855  data: 0.0001  max mem: 14938
[13:11:51.139733] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6862 (0.6863)  time: 0.1858  data: 0.0001  max mem: 14938
[13:11:53.003080] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6821 (0.6858)  time: 0.1861  data: 0.0001  max mem: 14938
[13:11:54.871768] Test:  [100/345]  eta: 0:00:45  loss: 0.6821 (0.6861)  time: 0.1866  data: 0.0001  max mem: 14938
[13:11:56.741304] Test:  [110/345]  eta: 0:00:43  loss: 0.6855 (0.6865)  time: 0.1869  data: 0.0001  max mem: 14938
[13:11:58.615867] Test:  [120/345]  eta: 0:00:41  loss: 0.6850 (0.6864)  time: 0.1872  data: 0.0001  max mem: 14938
[13:12:00.494802] Test:  [130/345]  eta: 0:00:40  loss: 0.6816 (0.6866)  time: 0.1876  data: 0.0001  max mem: 14938
[13:12:02.376297] Test:  [140/345]  eta: 0:00:38  loss: 0.6854 (0.6867)  time: 0.1880  data: 0.0001  max mem: 14938
[13:12:04.261588] Test:  [150/345]  eta: 0:00:36  loss: 0.6871 (0.6866)  time: 0.1883  data: 0.0001  max mem: 14938
[13:12:06.148837] Test:  [160/345]  eta: 0:00:34  loss: 0.6837 (0.6864)  time: 0.1886  data: 0.0001  max mem: 14938
[13:12:08.041352] Test:  [170/345]  eta: 0:00:32  loss: 0.6833 (0.6862)  time: 0.1889  data: 0.0001  max mem: 14938
[13:12:09.937287] Test:  [180/345]  eta: 0:00:30  loss: 0.6836 (0.6863)  time: 0.1894  data: 0.0001  max mem: 14938
[13:12:11.835929] Test:  [190/345]  eta: 0:00:29  loss: 0.6858 (0.6864)  time: 0.1897  data: 0.0001  max mem: 14938
[13:12:13.736907] Test:  [200/345]  eta: 0:00:27  loss: 0.6865 (0.6865)  time: 0.1899  data: 0.0001  max mem: 14938
[13:12:15.642292] Test:  [210/345]  eta: 0:00:25  loss: 0.6822 (0.6862)  time: 0.1903  data: 0.0001  max mem: 14938
[13:12:17.553498] Test:  [220/345]  eta: 0:00:23  loss: 0.6817 (0.6863)  time: 0.1908  data: 0.0001  max mem: 14938
[13:12:19.465345] Test:  [230/345]  eta: 0:00:21  loss: 0.6848 (0.6862)  time: 0.1911  data: 0.0001  max mem: 14938
[13:12:21.381785] Test:  [240/345]  eta: 0:00:19  loss: 0.6849 (0.6863)  time: 0.1914  data: 0.0001  max mem: 14938
[13:12:23.301801] Test:  [250/345]  eta: 0:00:17  loss: 0.6849 (0.6864)  time: 0.1918  data: 0.0001  max mem: 14938
[13:12:25.224602] Test:  [260/345]  eta: 0:00:16  loss: 0.6803 (0.6862)  time: 0.1921  data: 0.0001  max mem: 14938
[13:12:27.150951] Test:  [270/345]  eta: 0:00:14  loss: 0.6795 (0.6863)  time: 0.1924  data: 0.0001  max mem: 14938
[13:12:29.081416] Test:  [280/345]  eta: 0:00:12  loss: 0.6817 (0.6863)  time: 0.1928  data: 0.0001  max mem: 14938
[13:12:31.014757] Test:  [290/345]  eta: 0:00:10  loss: 0.6850 (0.6863)  time: 0.1931  data: 0.0001  max mem: 14938
[13:12:32.953185] Test:  [300/345]  eta: 0:00:08  loss: 0.6841 (0.6863)  time: 0.1935  data: 0.0001  max mem: 14938
[13:12:34.893884] Test:  [310/345]  eta: 0:00:06  loss: 0.6866 (0.6865)  time: 0.1939  data: 0.0001  max mem: 14938
[13:12:36.838096] Test:  [320/345]  eta: 0:00:04  loss: 0.6820 (0.6863)  time: 0.1942  data: 0.0001  max mem: 14938
[13:12:38.785464] Test:  [330/345]  eta: 0:00:02  loss: 0.6861 (0.6865)  time: 0.1945  data: 0.0001  max mem: 14938
[13:12:40.735534] Test:  [340/345]  eta: 0:00:00  loss: 0.6893 (0.6865)  time: 0.1948  data: 0.0001  max mem: 14938
[13:12:41.517458] Test:  [344/345]  eta: 0:00:00  loss: 0.6879 (0.6866)  time: 0.1950  data: 0.0001  max mem: 14938
[13:12:41.577523] Test: Total time: 0:01:05 (0.1900 s / it)
[13:12:51.884201] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8363 (0.8363)  time: 0.3176  data: 0.1384  max mem: 14938
[13:12:53.701064] Test:  [10/57]  eta: 0:00:09  loss: 0.8698 (0.8784)  time: 0.1940  data: 0.0126  max mem: 14938
[13:12:55.522997] Test:  [20/57]  eta: 0:00:06  loss: 0.8698 (0.8688)  time: 0.1819  data: 0.0001  max mem: 14938
[13:12:57.349106] Test:  [30/57]  eta: 0:00:05  loss: 0.7494 (0.8267)  time: 0.1823  data: 0.0001  max mem: 14938
[13:12:59.179504] Test:  [40/57]  eta: 0:00:03  loss: 0.7440 (0.8067)  time: 0.1828  data: 0.0001  max mem: 14938
[13:13:01.014613] Test:  [50/57]  eta: 0:00:01  loss: 0.7352 (0.7989)  time: 0.1832  data: 0.0001  max mem: 14938
[13:13:02.003979] Test:  [56/57]  eta: 0:00:00  loss: 0.7536 (0.8040)  time: 0.1778  data: 0.0001  max mem: 14938
[13:13:02.059801] Test: Total time: 0:00:10 (0.1841 s / it)
[13:13:03.787322] Dice score of the network on the train images: 0.835536, val images: 0.817650
[13:13:03.791360] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:13:04.672716] Epoch: [42]  [  0/345]  eta: 0:05:03  lr: 0.000021  loss: 0.7018 (0.7018)  time: 0.8802  data: 0.1377  max mem: 14938
[13:13:19.569817] Epoch: [42]  [ 20/345]  eta: 0:04:04  lr: 0.000020  loss: 0.7060 (0.7066)  time: 0.7448  data: 0.0001  max mem: 14938
[13:13:34.504284] Epoch: [42]  [ 40/345]  eta: 0:03:48  lr: 0.000020  loss: 0.7085 (0.7077)  time: 0.7467  data: 0.0001  max mem: 14938
[13:13:49.461427] Epoch: [42]  [ 60/345]  eta: 0:03:33  lr: 0.000020  loss: 0.7067 (0.7079)  time: 0.7478  data: 0.0001  max mem: 14938
[13:14:04.448674] Epoch: [42]  [ 80/345]  eta: 0:03:18  lr: 0.000020  loss: 0.7136 (0.7095)  time: 0.7493  data: 0.0001  max mem: 14938
[13:14:19.466488] Epoch: [42]  [100/345]  eta: 0:03:03  lr: 0.000019  loss: 0.7089 (0.7103)  time: 0.7508  data: 0.0001  max mem: 14938
[13:14:34.481558] Epoch: [42]  [120/345]  eta: 0:02:48  lr: 0.000019  loss: 0.7104 (0.7105)  time: 0.7507  data: 0.0001  max mem: 14938
[13:14:49.505753] Epoch: [42]  [140/345]  eta: 0:02:33  lr: 0.000019  loss: 0.7075 (0.7101)  time: 0.7512  data: 0.0001  max mem: 14938
[13:15:04.519594] Epoch: [42]  [160/345]  eta: 0:02:18  lr: 0.000018  loss: 0.7072 (0.7098)  time: 0.7506  data: 0.0001  max mem: 14938
[13:15:19.537906] Epoch: [42]  [180/345]  eta: 0:02:03  lr: 0.000018  loss: 0.7041 (0.7092)  time: 0.7509  data: 0.0001  max mem: 14938
[13:15:34.559191] Epoch: [42]  [200/345]  eta: 0:01:48  lr: 0.000018  loss: 0.7116 (0.7097)  time: 0.7510  data: 0.0001  max mem: 14938
[13:15:49.572747] Epoch: [42]  [220/345]  eta: 0:01:33  lr: 0.000018  loss: 0.7072 (0.7095)  time: 0.7506  data: 0.0001  max mem: 14938
[13:16:04.588418] Epoch: [42]  [240/345]  eta: 0:01:18  lr: 0.000017  loss: 0.7077 (0.7097)  time: 0.7507  data: 0.0001  max mem: 14938
[13:16:19.592787] Epoch: [42]  [260/345]  eta: 0:01:03  lr: 0.000017  loss: 0.7097 (0.7098)  time: 0.7502  data: 0.0001  max mem: 14938
[13:16:34.608760] Epoch: [42]  [280/345]  eta: 0:00:48  lr: 0.000017  loss: 0.7035 (0.7094)  time: 0.7507  data: 0.0001  max mem: 14938
[13:16:49.610768] Epoch: [42]  [300/345]  eta: 0:00:33  lr: 0.000017  loss: 0.7090 (0.7096)  time: 0.7500  data: 0.0001  max mem: 14938
[13:17:04.611846] Epoch: [42]  [320/345]  eta: 0:00:18  lr: 0.000016  loss: 0.7037 (0.7097)  time: 0.7500  data: 0.0001  max mem: 14938
[13:17:19.618627] Epoch: [42]  [340/345]  eta: 0:00:03  lr: 0.000016  loss: 0.7045 (0.7095)  time: 0.7503  data: 0.0001  max mem: 14938
[13:17:22.618495] Epoch: [42]  [344/345]  eta: 0:00:00  lr: 0.000016  loss: 0.7056 (0.7096)  time: 0.7501  data: 0.0001  max mem: 14938
[13:17:22.683681] Epoch: [42] Total time: 0:04:18 (0.7504 s / it)
[13:17:22.683840] Averaged stats: lr: 0.000016  loss: 0.7056 (0.7096)
[13:17:23.022207] Test:  [  0/345]  eta: 0:01:55  loss: 0.7099 (0.7099)  time: 0.3341  data: 0.1524  max mem: 14938
[13:17:24.859945] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6878 (0.6885)  time: 0.1974  data: 0.0139  max mem: 14938
[13:17:26.699198] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6829 (0.6852)  time: 0.1838  data: 0.0001  max mem: 14938
[13:17:28.544309] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6829 (0.6848)  time: 0.1842  data: 0.0001  max mem: 14938
[13:17:30.391538] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6829 (0.6850)  time: 0.1846  data: 0.0001  max mem: 14938
[13:17:32.240790] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6867 (0.6859)  time: 0.1848  data: 0.0001  max mem: 14938
[13:17:34.095462] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6869 (0.6856)  time: 0.1851  data: 0.0001  max mem: 14938
[13:17:35.952196] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6812 (0.6854)  time: 0.1855  data: 0.0001  max mem: 14938
[13:17:37.812385] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6812 (0.6846)  time: 0.1858  data: 0.0001  max mem: 14938
[13:17:39.676104] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6812 (0.6844)  time: 0.1861  data: 0.0001  max mem: 14938
[13:17:41.541016] Test:  [100/345]  eta: 0:00:45  loss: 0.6812 (0.6843)  time: 0.1864  data: 0.0001  max mem: 14938
[13:17:43.409896] Test:  [110/345]  eta: 0:00:43  loss: 0.6812 (0.6849)  time: 0.1866  data: 0.0001  max mem: 14938
[13:17:45.284191] Test:  [120/345]  eta: 0:00:42  loss: 0.6842 (0.6848)  time: 0.1871  data: 0.0001  max mem: 14938
[13:17:47.160975] Test:  [130/345]  eta: 0:00:40  loss: 0.6868 (0.6851)  time: 0.1875  data: 0.0001  max mem: 14938
[13:17:49.041665] Test:  [140/345]  eta: 0:00:38  loss: 0.6868 (0.6851)  time: 0.1878  data: 0.0001  max mem: 14938
[13:17:50.925759] Test:  [150/345]  eta: 0:00:36  loss: 0.6833 (0.6847)  time: 0.1882  data: 0.0001  max mem: 14938
[13:17:52.814750] Test:  [160/345]  eta: 0:00:34  loss: 0.6790 (0.6845)  time: 0.1886  data: 0.0001  max mem: 14938
[13:17:54.705301] Test:  [170/345]  eta: 0:00:32  loss: 0.6796 (0.6847)  time: 0.1889  data: 0.0001  max mem: 14938
[13:17:56.600780] Test:  [180/345]  eta: 0:00:30  loss: 0.6890 (0.6848)  time: 0.1893  data: 0.0001  max mem: 14938
[13:17:58.499375] Test:  [190/345]  eta: 0:00:29  loss: 0.6890 (0.6851)  time: 0.1897  data: 0.0001  max mem: 14938
[13:18:00.402554] Test:  [200/345]  eta: 0:00:27  loss: 0.6845 (0.6851)  time: 0.1900  data: 0.0001  max mem: 14938
[13:18:02.307761] Test:  [210/345]  eta: 0:00:25  loss: 0.6827 (0.6852)  time: 0.1904  data: 0.0001  max mem: 14938
[13:18:04.216266] Test:  [220/345]  eta: 0:00:23  loss: 0.6867 (0.6853)  time: 0.1906  data: 0.0001  max mem: 14938
[13:18:06.128794] Test:  [230/345]  eta: 0:00:21  loss: 0.6866 (0.6854)  time: 0.1910  data: 0.0001  max mem: 14938
[13:18:08.048236] Test:  [240/345]  eta: 0:00:19  loss: 0.6808 (0.6853)  time: 0.1915  data: 0.0001  max mem: 14938
[13:18:09.968894] Test:  [250/345]  eta: 0:00:17  loss: 0.6850 (0.6855)  time: 0.1920  data: 0.0001  max mem: 14938
[13:18:11.893132] Test:  [260/345]  eta: 0:00:16  loss: 0.6858 (0.6852)  time: 0.1922  data: 0.0001  max mem: 14938
[13:18:13.819875] Test:  [270/345]  eta: 0:00:14  loss: 0.6806 (0.6851)  time: 0.1925  data: 0.0001  max mem: 14938
[13:18:15.749740] Test:  [280/345]  eta: 0:00:12  loss: 0.6872 (0.6853)  time: 0.1928  data: 0.0001  max mem: 14938
[13:18:17.682947] Test:  [290/345]  eta: 0:00:10  loss: 0.6847 (0.6853)  time: 0.1931  data: 0.0001  max mem: 14938
[13:18:19.620049] Test:  [300/345]  eta: 0:00:08  loss: 0.6796 (0.6851)  time: 0.1935  data: 0.0001  max mem: 14938
[13:18:21.562064] Test:  [310/345]  eta: 0:00:06  loss: 0.6796 (0.6851)  time: 0.1939  data: 0.0001  max mem: 14938
[13:18:23.507102] Test:  [320/345]  eta: 0:00:04  loss: 0.6797 (0.6850)  time: 0.1943  data: 0.0001  max mem: 14938
[13:18:25.454160] Test:  [330/345]  eta: 0:00:02  loss: 0.6804 (0.6850)  time: 0.1946  data: 0.0001  max mem: 14938
[13:18:27.404983] Test:  [340/345]  eta: 0:00:00  loss: 0.6862 (0.6851)  time: 0.1948  data: 0.0001  max mem: 14938
[13:18:28.187162] Test:  [344/345]  eta: 0:00:00  loss: 0.6857 (0.6851)  time: 0.1950  data: 0.0001  max mem: 14938
[13:18:28.246543] Test: Total time: 0:01:05 (0.1900 s / it)
[13:18:38.616245] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8673 (0.8673)  time: 0.3172  data: 0.1378  max mem: 14938
[13:18:40.432003] Test:  [10/57]  eta: 0:00:09  loss: 0.8807 (0.8857)  time: 0.1938  data: 0.0126  max mem: 14938
[13:18:42.253866] Test:  [20/57]  eta: 0:00:06  loss: 0.8807 (0.8761)  time: 0.1818  data: 0.0001  max mem: 14938
[13:18:44.079916] Test:  [30/57]  eta: 0:00:05  loss: 0.7638 (0.8325)  time: 0.1823  data: 0.0001  max mem: 14938
[13:18:45.909677] Test:  [40/57]  eta: 0:00:03  loss: 0.7451 (0.8115)  time: 0.1827  data: 0.0001  max mem: 14938
[13:18:47.746331] Test:  [50/57]  eta: 0:00:01  loss: 0.7366 (0.8029)  time: 0.1833  data: 0.0001  max mem: 14938
[13:18:48.735957] Test:  [56/57]  eta: 0:00:00  loss: 0.7575 (0.8078)  time: 0.1779  data: 0.0001  max mem: 14938
[13:18:48.791134] Test: Total time: 0:00:10 (0.1841 s / it)
[13:18:50.542381] Dice score of the network on the train images: 0.838579, val images: 0.820358
[13:18:50.547152] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:18:51.427224] Epoch: [43]  [  0/345]  eta: 0:05:03  lr: 0.000016  loss: 0.7047 (0.7047)  time: 0.8792  data: 0.1369  max mem: 14938
[13:19:06.331140] Epoch: [43]  [ 20/345]  eta: 0:04:04  lr: 0.000016  loss: 0.7069 (0.7082)  time: 0.7451  data: 0.0001  max mem: 14938
[13:19:21.287393] Epoch: [43]  [ 40/345]  eta: 0:03:48  lr: 0.000016  loss: 0.7081 (0.7079)  time: 0.7478  data: 0.0001  max mem: 14938
[13:19:36.272998] Epoch: [43]  [ 60/345]  eta: 0:03:33  lr: 0.000015  loss: 0.7094 (0.7086)  time: 0.7492  data: 0.0001  max mem: 14938
[13:19:51.272375] Epoch: [43]  [ 80/345]  eta: 0:03:18  lr: 0.000015  loss: 0.7077 (0.7085)  time: 0.7499  data: 0.0001  max mem: 14938
[13:20:06.298341] Epoch: [43]  [100/345]  eta: 0:03:03  lr: 0.000015  loss: 0.7069 (0.7087)  time: 0.7513  data: 0.0001  max mem: 14938
[13:20:21.339139] Epoch: [43]  [120/345]  eta: 0:02:48  lr: 0.000015  loss: 0.7079 (0.7087)  time: 0.7520  data: 0.0001  max mem: 14938
[13:20:36.379312] Epoch: [43]  [140/345]  eta: 0:02:33  lr: 0.000014  loss: 0.7026 (0.7082)  time: 0.7520  data: 0.0001  max mem: 14938
[13:20:51.417638] Epoch: [43]  [160/345]  eta: 0:02:18  lr: 0.000014  loss: 0.7085 (0.7085)  time: 0.7519  data: 0.0001  max mem: 14938
[13:21:06.446221] Epoch: [43]  [180/345]  eta: 0:02:03  lr: 0.000014  loss: 0.7072 (0.7086)  time: 0.7514  data: 0.0001  max mem: 14938
[13:21:21.469944] Epoch: [43]  [200/345]  eta: 0:01:48  lr: 0.000014  loss: 0.7051 (0.7083)  time: 0.7511  data: 0.0001  max mem: 14938
[13:21:36.481691] Epoch: [43]  [220/345]  eta: 0:01:33  lr: 0.000013  loss: 0.7079 (0.7083)  time: 0.7505  data: 0.0001  max mem: 14938
[13:21:51.487069] Epoch: [43]  [240/345]  eta: 0:01:18  lr: 0.000013  loss: 0.7043 (0.7082)  time: 0.7502  data: 0.0001  max mem: 14938
[13:22:06.489992] Epoch: [43]  [260/345]  eta: 0:01:03  lr: 0.000013  loss: 0.7012 (0.7080)  time: 0.7501  data: 0.0001  max mem: 14938
[13:22:21.583913] Epoch: [43]  [280/345]  eta: 0:00:48  lr: 0.000013  loss: 0.7099 (0.7081)  time: 0.7547  data: 0.0001  max mem: 14938
[13:22:36.591024] Epoch: [43]  [300/345]  eta: 0:00:33  lr: 0.000012  loss: 0.7077 (0.7083)  time: 0.7503  data: 0.0001  max mem: 14938
[13:22:51.593043] Epoch: [43]  [320/345]  eta: 0:00:18  lr: 0.000012  loss: 0.7060 (0.7084)  time: 0.7501  data: 0.0001  max mem: 14938
[13:23:06.581550] Epoch: [43]  [340/345]  eta: 0:00:03  lr: 0.000012  loss: 0.7063 (0.7082)  time: 0.7494  data: 0.0001  max mem: 14938
[13:23:09.580967] Epoch: [43]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 0.7080 (0.7082)  time: 0.7494  data: 0.0001  max mem: 14938
[13:23:09.641501] Epoch: [43] Total time: 0:04:19 (0.7510 s / it)
[13:23:09.641860] Averaged stats: lr: 0.000012  loss: 0.7080 (0.7082)
[13:23:09.976221] Test:  [  0/345]  eta: 0:01:53  loss: 0.6717 (0.6717)  time: 0.3303  data: 0.1484  max mem: 14938
[13:23:11.812548] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6799 (0.6814)  time: 0.1969  data: 0.0136  max mem: 14938
[13:23:13.651297] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6823 (0.6843)  time: 0.1837  data: 0.0001  max mem: 14938
[13:23:15.495505] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6809 (0.6824)  time: 0.1841  data: 0.0001  max mem: 14938
[13:23:17.340939] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6809 (0.6826)  time: 0.1844  data: 0.0001  max mem: 14938
[13:23:19.192423] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6797 (0.6820)  time: 0.1848  data: 0.0001  max mem: 14938
[13:23:21.046266] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6782 (0.6822)  time: 0.1852  data: 0.0001  max mem: 14938
[13:23:22.902545] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6803 (0.6823)  time: 0.1855  data: 0.0001  max mem: 14938
[13:23:24.761890] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6823 (0.6822)  time: 0.1857  data: 0.0001  max mem: 14938
[13:23:26.625984] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6811 (0.6820)  time: 0.1861  data: 0.0001  max mem: 14938
[13:23:28.493668] Test:  [100/345]  eta: 0:00:45  loss: 0.6839 (0.6826)  time: 0.1865  data: 0.0001  max mem: 14938
[13:23:30.363070] Test:  [110/345]  eta: 0:00:43  loss: 0.6861 (0.6831)  time: 0.1868  data: 0.0001  max mem: 14938
[13:23:32.237553] Test:  [120/345]  eta: 0:00:41  loss: 0.6857 (0.6832)  time: 0.1871  data: 0.0001  max mem: 14938
[13:23:34.113537] Test:  [130/345]  eta: 0:00:40  loss: 0.6846 (0.6832)  time: 0.1875  data: 0.0001  max mem: 14938
[13:23:35.993196] Test:  [140/345]  eta: 0:00:38  loss: 0.6817 (0.6831)  time: 0.1877  data: 0.0001  max mem: 14938
[13:23:37.877611] Test:  [150/345]  eta: 0:00:36  loss: 0.6831 (0.6835)  time: 0.1882  data: 0.0001  max mem: 14938
[13:23:39.765793] Test:  [160/345]  eta: 0:00:34  loss: 0.6831 (0.6832)  time: 0.1886  data: 0.0001  max mem: 14938
[13:23:41.656493] Test:  [170/345]  eta: 0:00:32  loss: 0.6853 (0.6836)  time: 0.1889  data: 0.0001  max mem: 14938
[13:23:43.552882] Test:  [180/345]  eta: 0:00:30  loss: 0.6879 (0.6836)  time: 0.1893  data: 0.0001  max mem: 14938
[13:23:45.452842] Test:  [190/345]  eta: 0:00:29  loss: 0.6785 (0.6834)  time: 0.1898  data: 0.0001  max mem: 14938
[13:23:47.356263] Test:  [200/345]  eta: 0:00:27  loss: 0.6785 (0.6834)  time: 0.1901  data: 0.0001  max mem: 14938
[13:23:49.261839] Test:  [210/345]  eta: 0:00:25  loss: 0.6814 (0.6833)  time: 0.1904  data: 0.0001  max mem: 14938
[13:23:51.173231] Test:  [220/345]  eta: 0:00:23  loss: 0.6799 (0.6832)  time: 0.1908  data: 0.0001  max mem: 14938
[13:23:53.086823] Test:  [230/345]  eta: 0:00:21  loss: 0.6763 (0.6831)  time: 0.1912  data: 0.0001  max mem: 14938
[13:23:55.004315] Test:  [240/345]  eta: 0:00:19  loss: 0.6746 (0.6830)  time: 0.1915  data: 0.0001  max mem: 14938
[13:23:56.925454] Test:  [250/345]  eta: 0:00:17  loss: 0.6761 (0.6831)  time: 0.1919  data: 0.0001  max mem: 14938
[13:23:58.850562] Test:  [260/345]  eta: 0:00:16  loss: 0.6846 (0.6832)  time: 0.1923  data: 0.0001  max mem: 14938
[13:24:00.777308] Test:  [270/345]  eta: 0:00:14  loss: 0.6816 (0.6830)  time: 0.1925  data: 0.0001  max mem: 14938
[13:24:02.709418] Test:  [280/345]  eta: 0:00:12  loss: 0.6838 (0.6831)  time: 0.1929  data: 0.0001  max mem: 14938
[13:24:04.644719] Test:  [290/345]  eta: 0:00:10  loss: 0.6838 (0.6831)  time: 0.1933  data: 0.0001  max mem: 14938
[13:24:06.581437] Test:  [300/345]  eta: 0:00:08  loss: 0.6802 (0.6831)  time: 0.1936  data: 0.0001  max mem: 14938
[13:24:08.522548] Test:  [310/345]  eta: 0:00:06  loss: 0.6802 (0.6832)  time: 0.1938  data: 0.0001  max mem: 14938
[13:24:10.466838] Test:  [320/345]  eta: 0:00:04  loss: 0.6814 (0.6832)  time: 0.1942  data: 0.0001  max mem: 14938
[13:24:12.412807] Test:  [330/345]  eta: 0:00:02  loss: 0.6833 (0.6832)  time: 0.1945  data: 0.0001  max mem: 14938
[13:24:14.363149] Test:  [340/345]  eta: 0:00:00  loss: 0.6818 (0.6832)  time: 0.1948  data: 0.0001  max mem: 14938
[13:24:15.145026] Test:  [344/345]  eta: 0:00:00  loss: 0.6811 (0.6831)  time: 0.1950  data: 0.0001  max mem: 14938
[13:24:15.205340] Test: Total time: 0:01:05 (0.1900 s / it)
[13:24:25.597419] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8649 (0.8649)  time: 0.3167  data: 0.1375  max mem: 14938
[13:24:27.413363] Test:  [10/57]  eta: 0:00:09  loss: 0.8772 (0.8872)  time: 0.1938  data: 0.0126  max mem: 14938
[13:24:29.234448] Test:  [20/57]  eta: 0:00:06  loss: 0.8825 (0.8781)  time: 0.1818  data: 0.0001  max mem: 14938
[13:24:31.058455] Test:  [30/57]  eta: 0:00:05  loss: 0.7634 (0.8333)  time: 0.1822  data: 0.0001  max mem: 14938
[13:24:32.888624] Test:  [40/57]  eta: 0:00:03  loss: 0.7437 (0.8118)  time: 0.1827  data: 0.0001  max mem: 14938
[13:24:34.722858] Test:  [50/57]  eta: 0:00:01  loss: 0.7352 (0.8033)  time: 0.1832  data: 0.0001  max mem: 14938
[13:24:35.712458] Test:  [56/57]  eta: 0:00:00  loss: 0.7543 (0.8081)  time: 0.1778  data: 0.0001  max mem: 14938
[13:24:35.772470] Test: Total time: 0:00:10 (0.1841 s / it)
[13:24:37.505844] Dice score of the network on the train images: 0.839951, val images: 0.821235
[13:24:37.509933] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:24:38.392384] Epoch: [44]  [  0/345]  eta: 0:05:04  lr: 0.000012  loss: 0.6928 (0.6928)  time: 0.8814  data: 0.1381  max mem: 14938
[13:24:53.292077] Epoch: [44]  [ 20/345]  eta: 0:04:04  lr: 0.000012  loss: 0.7081 (0.7069)  time: 0.7449  data: 0.0001  max mem: 14938
[13:25:08.243024] Epoch: [44]  [ 40/345]  eta: 0:03:48  lr: 0.000011  loss: 0.7026 (0.7060)  time: 0.7475  data: 0.0001  max mem: 14938
[13:25:23.225759] Epoch: [44]  [ 60/345]  eta: 0:03:33  lr: 0.000011  loss: 0.7036 (0.7056)  time: 0.7491  data: 0.0001  max mem: 14938
[13:25:38.234061] Epoch: [44]  [ 80/345]  eta: 0:03:18  lr: 0.000011  loss: 0.7037 (0.7048)  time: 0.7504  data: 0.0001  max mem: 14938
[13:25:53.270734] Epoch: [44]  [100/345]  eta: 0:03:03  lr: 0.000011  loss: 0.7065 (0.7054)  time: 0.7518  data: 0.0001  max mem: 14938
[13:26:08.292166] Epoch: [44]  [120/345]  eta: 0:02:48  lr: 0.000011  loss: 0.7005 (0.7050)  time: 0.7510  data: 0.0001  max mem: 14938
[13:26:23.322766] Epoch: [44]  [140/345]  eta: 0:02:33  lr: 0.000010  loss: 0.7013 (0.7048)  time: 0.7515  data: 0.0001  max mem: 14938
[13:26:38.372805] Epoch: [44]  [160/345]  eta: 0:02:18  lr: 0.000010  loss: 0.7062 (0.7054)  time: 0.7525  data: 0.0001  max mem: 14938
[13:26:53.419227] Epoch: [44]  [180/345]  eta: 0:02:03  lr: 0.000010  loss: 0.7122 (0.7064)  time: 0.7523  data: 0.0001  max mem: 14938
[13:27:08.553860] Epoch: [44]  [200/345]  eta: 0:01:48  lr: 0.000010  loss: 0.7047 (0.7063)  time: 0.7567  data: 0.0001  max mem: 14938
[13:27:23.559965] Epoch: [44]  [220/345]  eta: 0:01:33  lr: 0.000010  loss: 0.7050 (0.7064)  time: 0.7503  data: 0.0001  max mem: 14938
[13:27:38.568271] Epoch: [44]  [240/345]  eta: 0:01:18  lr: 0.000009  loss: 0.7064 (0.7066)  time: 0.7504  data: 0.0001  max mem: 14938
[13:27:53.592923] Epoch: [44]  [260/345]  eta: 0:01:03  lr: 0.000009  loss: 0.7119 (0.7070)  time: 0.7512  data: 0.0001  max mem: 14938
[13:28:08.607223] Epoch: [44]  [280/345]  eta: 0:00:48  lr: 0.000009  loss: 0.7050 (0.7070)  time: 0.7507  data: 0.0001  max mem: 14938
[13:28:23.614228] Epoch: [44]  [300/345]  eta: 0:00:33  lr: 0.000009  loss: 0.7066 (0.7070)  time: 0.7503  data: 0.0001  max mem: 14938
[13:28:38.617550] Epoch: [44]  [320/345]  eta: 0:00:18  lr: 0.000009  loss: 0.7054 (0.7071)  time: 0.7501  data: 0.0001  max mem: 14938
[13:28:53.619610] Epoch: [44]  [340/345]  eta: 0:00:03  lr: 0.000008  loss: 0.7058 (0.7071)  time: 0.7501  data: 0.0001  max mem: 14938
[13:28:56.617789] Epoch: [44]  [344/345]  eta: 0:00:00  lr: 0.000008  loss: 0.7067 (0.7071)  time: 0.7500  data: 0.0001  max mem: 14938
[13:28:56.681111] Epoch: [44] Total time: 0:04:19 (0.7512 s / it)
[13:28:56.681435] Averaged stats: lr: 0.000008  loss: 0.7067 (0.7071)
[13:28:57.013568] Test:  [  0/345]  eta: 0:01:53  loss: 0.6955 (0.6955)  time: 0.3277  data: 0.1462  max mem: 14938
[13:28:58.850035] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6852 (0.6870)  time: 0.1967  data: 0.0133  max mem: 14938
[13:29:00.689806] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6809 (0.6844)  time: 0.1837  data: 0.0001  max mem: 14938
[13:29:02.533887] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6809 (0.6870)  time: 0.1841  data: 0.0001  max mem: 14938
[13:29:04.379683] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6858 (0.6862)  time: 0.1844  data: 0.0001  max mem: 14938
[13:29:06.230131] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6855 (0.6857)  time: 0.1848  data: 0.0001  max mem: 14938
[13:29:08.084231] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6781 (0.6847)  time: 0.1852  data: 0.0001  max mem: 14938
[13:29:09.942544] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6810 (0.6845)  time: 0.1856  data: 0.0001  max mem: 14938
[13:29:11.802065] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6846 (0.6856)  time: 0.1858  data: 0.0001  max mem: 14938
[13:29:13.665856] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6820 (0.6852)  time: 0.1861  data: 0.0001  max mem: 14938
[13:29:15.533769] Test:  [100/345]  eta: 0:00:45  loss: 0.6789 (0.6849)  time: 0.1865  data: 0.0001  max mem: 14938
[13:29:17.403205] Test:  [110/345]  eta: 0:00:43  loss: 0.6789 (0.6846)  time: 0.1868  data: 0.0001  max mem: 14938
[13:29:19.278483] Test:  [120/345]  eta: 0:00:41  loss: 0.6764 (0.6841)  time: 0.1872  data: 0.0001  max mem: 14938
[13:29:21.157320] Test:  [130/345]  eta: 0:00:40  loss: 0.6806 (0.6841)  time: 0.1876  data: 0.0001  max mem: 14938
[13:29:23.039192] Test:  [140/345]  eta: 0:00:38  loss: 0.6813 (0.6839)  time: 0.1880  data: 0.0001  max mem: 14938
[13:29:24.923910] Test:  [150/345]  eta: 0:00:36  loss: 0.6824 (0.6838)  time: 0.1883  data: 0.0001  max mem: 14938
[13:29:26.811858] Test:  [160/345]  eta: 0:00:34  loss: 0.6823 (0.6837)  time: 0.1886  data: 0.0001  max mem: 14938
[13:29:28.703985] Test:  [170/345]  eta: 0:00:32  loss: 0.6823 (0.6836)  time: 0.1889  data: 0.0001  max mem: 14938
[13:29:30.602649] Test:  [180/345]  eta: 0:00:30  loss: 0.6841 (0.6837)  time: 0.1895  data: 0.0001  max mem: 14938
[13:29:32.503910] Test:  [190/345]  eta: 0:00:29  loss: 0.6844 (0.6841)  time: 0.1899  data: 0.0001  max mem: 14938
[13:29:34.406221] Test:  [200/345]  eta: 0:00:27  loss: 0.6845 (0.6839)  time: 0.1901  data: 0.0001  max mem: 14938
[13:29:36.311740] Test:  [210/345]  eta: 0:00:25  loss: 0.6812 (0.6838)  time: 0.1903  data: 0.0001  max mem: 14938
[13:29:38.219854] Test:  [220/345]  eta: 0:00:23  loss: 0.6808 (0.6838)  time: 0.1906  data: 0.0001  max mem: 14938
[13:29:40.133013] Test:  [230/345]  eta: 0:00:21  loss: 0.6808 (0.6838)  time: 0.1910  data: 0.0001  max mem: 14938
[13:29:42.049338] Test:  [240/345]  eta: 0:00:19  loss: 0.6777 (0.6834)  time: 0.1914  data: 0.0001  max mem: 14938
[13:29:43.970422] Test:  [250/345]  eta: 0:00:17  loss: 0.6740 (0.6832)  time: 0.1918  data: 0.0001  max mem: 14938
[13:29:45.892824] Test:  [260/345]  eta: 0:00:16  loss: 0.6797 (0.6832)  time: 0.1921  data: 0.0001  max mem: 14938
[13:29:47.822049] Test:  [270/345]  eta: 0:00:14  loss: 0.6802 (0.6831)  time: 0.1925  data: 0.0001  max mem: 14938
[13:29:49.751864] Test:  [280/345]  eta: 0:00:12  loss: 0.6798 (0.6831)  time: 0.1929  data: 0.0001  max mem: 14938
[13:29:51.684680] Test:  [290/345]  eta: 0:00:10  loss: 0.6798 (0.6829)  time: 0.1931  data: 0.0001  max mem: 14938
[13:29:53.623784] Test:  [300/345]  eta: 0:00:08  loss: 0.6797 (0.6829)  time: 0.1935  data: 0.0001  max mem: 14938
[13:29:55.563554] Test:  [310/345]  eta: 0:00:06  loss: 0.6813 (0.6829)  time: 0.1939  data: 0.0001  max mem: 14938
[13:29:57.507529] Test:  [320/345]  eta: 0:00:04  loss: 0.6834 (0.6831)  time: 0.1941  data: 0.0001  max mem: 14938
[13:29:59.454143] Test:  [330/345]  eta: 0:00:02  loss: 0.6830 (0.6830)  time: 0.1945  data: 0.0001  max mem: 14938
[13:30:01.403344] Test:  [340/345]  eta: 0:00:00  loss: 0.6785 (0.6828)  time: 0.1947  data: 0.0001  max mem: 14938
[13:30:02.183682] Test:  [344/345]  eta: 0:00:00  loss: 0.6780 (0.6827)  time: 0.1949  data: 0.0001  max mem: 14938
[13:30:02.243066] Test: Total time: 0:01:05 (0.1900 s / it)
[13:30:12.538697] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8512 (0.8512)  time: 0.3171  data: 0.1369  max mem: 14938
[13:30:14.355894] Test:  [10/57]  eta: 0:00:09  loss: 0.8820 (0.8857)  time: 0.1940  data: 0.0125  max mem: 14938
[13:30:16.177301] Test:  [20/57]  eta: 0:00:06  loss: 0.8820 (0.8768)  time: 0.1819  data: 0.0001  max mem: 14938
[13:30:18.003022] Test:  [30/57]  eta: 0:00:05  loss: 0.7535 (0.8326)  time: 0.1823  data: 0.0001  max mem: 14938
[13:30:19.833401] Test:  [40/57]  eta: 0:00:03  loss: 0.7460 (0.8117)  time: 0.1828  data: 0.0001  max mem: 14938
[13:30:21.669138] Test:  [50/57]  eta: 0:00:01  loss: 0.7356 (0.8035)  time: 0.1833  data: 0.0001  max mem: 14938
[13:30:22.658883] Test:  [56/57]  eta: 0:00:00  loss: 0.7532 (0.8083)  time: 0.1778  data: 0.0001  max mem: 14938
[13:30:22.717484] Test: Total time: 0:00:10 (0.1841 s / it)
[13:30:24.451722] Dice score of the network on the train images: 0.842005, val images: 0.818350
[13:30:24.456596] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:30:25.342057] Epoch: [45]  [  0/345]  eta: 0:05:05  lr: 0.000008  loss: 0.7099 (0.7099)  time: 0.8843  data: 0.1416  max mem: 14938
[13:30:40.242553] Epoch: [45]  [ 20/345]  eta: 0:04:04  lr: 0.000008  loss: 0.7015 (0.7050)  time: 0.7450  data: 0.0001  max mem: 14938
[13:30:55.179852] Epoch: [45]  [ 40/345]  eta: 0:03:48  lr: 0.000008  loss: 0.7075 (0.7061)  time: 0.7468  data: 0.0001  max mem: 14938
[13:31:10.143307] Epoch: [45]  [ 60/345]  eta: 0:03:33  lr: 0.000008  loss: 0.7043 (0.7058)  time: 0.7481  data: 0.0001  max mem: 14938
[13:31:25.124439] Epoch: [45]  [ 80/345]  eta: 0:03:18  lr: 0.000008  loss: 0.7051 (0.7058)  time: 0.7490  data: 0.0001  max mem: 14938
[13:31:40.123607] Epoch: [45]  [100/345]  eta: 0:03:03  lr: 0.000007  loss: 0.7084 (0.7064)  time: 0.7499  data: 0.0001  max mem: 14938
[13:31:55.138284] Epoch: [45]  [120/345]  eta: 0:02:48  lr: 0.000007  loss: 0.7073 (0.7066)  time: 0.7507  data: 0.0001  max mem: 14938
[13:32:10.154676] Epoch: [45]  [140/345]  eta: 0:02:33  lr: 0.000007  loss: 0.7037 (0.7064)  time: 0.7508  data: 0.0001  max mem: 14938
[13:32:25.176585] Epoch: [45]  [160/345]  eta: 0:02:18  lr: 0.000007  loss: 0.7033 (0.7061)  time: 0.7510  data: 0.0001  max mem: 14938
[13:32:40.195280] Epoch: [45]  [180/345]  eta: 0:02:03  lr: 0.000007  loss: 0.7079 (0.7063)  time: 0.7509  data: 0.0001  max mem: 14938
[13:32:55.200103] Epoch: [45]  [200/345]  eta: 0:01:48  lr: 0.000007  loss: 0.7018 (0.7064)  time: 0.7502  data: 0.0001  max mem: 14938
[13:33:10.210771] Epoch: [45]  [220/345]  eta: 0:01:33  lr: 0.000006  loss: 0.7129 (0.7066)  time: 0.7505  data: 0.0001  max mem: 14938
[13:33:25.236162] Epoch: [45]  [240/345]  eta: 0:01:18  lr: 0.000006  loss: 0.7032 (0.7067)  time: 0.7512  data: 0.0001  max mem: 14938
[13:33:40.249901] Epoch: [45]  [260/345]  eta: 0:01:03  lr: 0.000006  loss: 0.7030 (0.7066)  time: 0.7506  data: 0.0001  max mem: 14938
[13:33:55.229355] Epoch: [45]  [280/345]  eta: 0:00:48  lr: 0.000006  loss: 0.7040 (0.7067)  time: 0.7489  data: 0.0001  max mem: 14938
[13:34:10.213293] Epoch: [45]  [300/345]  eta: 0:00:33  lr: 0.000006  loss: 0.6991 (0.7063)  time: 0.7491  data: 0.0001  max mem: 14938
[13:34:25.194424] Epoch: [45]  [320/345]  eta: 0:00:18  lr: 0.000006  loss: 0.7042 (0.7063)  time: 0.7490  data: 0.0001  max mem: 14938
[13:34:40.176743] Epoch: [45]  [340/345]  eta: 0:00:03  lr: 0.000005  loss: 0.7038 (0.7062)  time: 0.7491  data: 0.0001  max mem: 14938
[13:34:43.173573] Epoch: [45]  [344/345]  eta: 0:00:00  lr: 0.000005  loss: 0.7040 (0.7062)  time: 0.7492  data: 0.0001  max mem: 14938
[13:34:43.238094] Epoch: [45] Total time: 0:04:18 (0.7501 s / it)
[13:34:43.238608] Averaged stats: lr: 0.000005  loss: 0.7040 (0.7062)
[13:34:43.569767] Test:  [  0/345]  eta: 0:01:53  loss: 0.6604 (0.6604)  time: 0.3277  data: 0.1458  max mem: 14938
[13:34:45.405055] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6747 (0.6791)  time: 0.1966  data: 0.0133  max mem: 14938
[13:34:47.245551] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6771 (0.6814)  time: 0.1837  data: 0.0001  max mem: 14938
[13:34:49.088413] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6771 (0.6796)  time: 0.1841  data: 0.0001  max mem: 14938
[13:34:50.933228] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6827 (0.6821)  time: 0.1843  data: 0.0001  max mem: 14938
[13:34:52.784046] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6879 (0.6831)  time: 0.1847  data: 0.0001  max mem: 14938
[13:34:54.638653] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6813 (0.6823)  time: 0.1852  data: 0.0001  max mem: 14938
[13:34:56.494970] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6781 (0.6822)  time: 0.1855  data: 0.0001  max mem: 14938
[13:34:58.355559] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6818 (0.6827)  time: 0.1858  data: 0.0001  max mem: 14938
[13:35:00.220112] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6836 (0.6825)  time: 0.1862  data: 0.0001  max mem: 14938
[13:35:02.086455] Test:  [100/345]  eta: 0:00:45  loss: 0.6836 (0.6827)  time: 0.1865  data: 0.0001  max mem: 14938
[13:35:03.956109] Test:  [110/345]  eta: 0:00:43  loss: 0.6798 (0.6827)  time: 0.1867  data: 0.0001  max mem: 14938
[13:35:05.831662] Test:  [120/345]  eta: 0:00:41  loss: 0.6788 (0.6826)  time: 0.1872  data: 0.0001  max mem: 14938
[13:35:07.709281] Test:  [130/345]  eta: 0:00:40  loss: 0.6767 (0.6822)  time: 0.1876  data: 0.0001  max mem: 14938
[13:35:09.590728] Test:  [140/345]  eta: 0:00:38  loss: 0.6748 (0.6821)  time: 0.1879  data: 0.0001  max mem: 14938
[13:35:11.476387] Test:  [150/345]  eta: 0:00:36  loss: 0.6810 (0.6822)  time: 0.1883  data: 0.0001  max mem: 14938
[13:35:13.364730] Test:  [160/345]  eta: 0:00:34  loss: 0.6787 (0.6819)  time: 0.1886  data: 0.0001  max mem: 14938
[13:35:15.257019] Test:  [170/345]  eta: 0:00:32  loss: 0.6743 (0.6818)  time: 0.1890  data: 0.0001  max mem: 14938
[13:35:17.153330] Test:  [180/345]  eta: 0:00:30  loss: 0.6825 (0.6821)  time: 0.1894  data: 0.0001  max mem: 14938
[13:35:19.053125] Test:  [190/345]  eta: 0:00:29  loss: 0.6828 (0.6822)  time: 0.1898  data: 0.0001  max mem: 14938
[13:35:20.954923] Test:  [200/345]  eta: 0:00:27  loss: 0.6817 (0.6822)  time: 0.1900  data: 0.0001  max mem: 14938
[13:35:22.860928] Test:  [210/345]  eta: 0:00:25  loss: 0.6821 (0.6823)  time: 0.1903  data: 0.0001  max mem: 14938
[13:35:24.769117] Test:  [220/345]  eta: 0:00:23  loss: 0.6805 (0.6823)  time: 0.1907  data: 0.0001  max mem: 14938
[13:35:26.683519] Test:  [230/345]  eta: 0:00:21  loss: 0.6765 (0.6822)  time: 0.1911  data: 0.0001  max mem: 14938
[13:35:28.601070] Test:  [240/345]  eta: 0:00:19  loss: 0.6751 (0.6818)  time: 0.1915  data: 0.0001  max mem: 14938
[13:35:30.524468] Test:  [250/345]  eta: 0:00:17  loss: 0.6751 (0.6819)  time: 0.1920  data: 0.0001  max mem: 14938
[13:35:32.447942] Test:  [260/345]  eta: 0:00:16  loss: 0.6799 (0.6818)  time: 0.1923  data: 0.0001  max mem: 14938
[13:35:34.379664] Test:  [270/345]  eta: 0:00:14  loss: 0.6777 (0.6816)  time: 0.1927  data: 0.0001  max mem: 14938
[13:35:36.311937] Test:  [280/345]  eta: 0:00:12  loss: 0.6796 (0.6818)  time: 0.1931  data: 0.0001  max mem: 14938
[13:35:38.248495] Test:  [290/345]  eta: 0:00:10  loss: 0.6814 (0.6817)  time: 0.1934  data: 0.0001  max mem: 14938
[13:35:40.189488] Test:  [300/345]  eta: 0:00:08  loss: 0.6825 (0.6820)  time: 0.1938  data: 0.0001  max mem: 14938
[13:35:42.130927] Test:  [310/345]  eta: 0:00:06  loss: 0.6860 (0.6821)  time: 0.1941  data: 0.0001  max mem: 14938
[13:35:44.074629] Test:  [320/345]  eta: 0:00:04  loss: 0.6832 (0.6823)  time: 0.1942  data: 0.0001  max mem: 14938
[13:35:46.022904] Test:  [330/345]  eta: 0:00:02  loss: 0.6815 (0.6822)  time: 0.1945  data: 0.0001  max mem: 14938
[13:35:47.973051] Test:  [340/345]  eta: 0:00:00  loss: 0.6746 (0.6821)  time: 0.1949  data: 0.0001  max mem: 14938
[13:35:48.754548] Test:  [344/345]  eta: 0:00:00  loss: 0.6782 (0.6820)  time: 0.1950  data: 0.0001  max mem: 14938
[13:35:48.812995] Test: Total time: 0:01:05 (0.1901 s / it)
[13:35:59.251300] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8527 (0.8527)  time: 0.3186  data: 0.1387  max mem: 14938
[13:36:01.067061] Test:  [10/57]  eta: 0:00:09  loss: 0.8839 (0.8874)  time: 0.1940  data: 0.0127  max mem: 14938
[13:36:02.887998] Test:  [20/57]  eta: 0:00:06  loss: 0.8839 (0.8782)  time: 0.1818  data: 0.0001  max mem: 14938
[13:36:04.712653] Test:  [30/57]  eta: 0:00:05  loss: 0.7574 (0.8337)  time: 0.1822  data: 0.0001  max mem: 14938
[13:36:06.541191] Test:  [40/57]  eta: 0:00:03  loss: 0.7465 (0.8124)  time: 0.1826  data: 0.0001  max mem: 14938
[13:36:08.375959] Test:  [50/57]  eta: 0:00:01  loss: 0.7358 (0.8040)  time: 0.1831  data: 0.0001  max mem: 14938
[13:36:09.365474] Test:  [56/57]  eta: 0:00:00  loss: 0.7544 (0.8088)  time: 0.1778  data: 0.0001  max mem: 14938
[13:36:09.423013] Test: Total time: 0:00:10 (0.1841 s / it)
[13:36:11.207806] Dice score of the network on the train images: 0.841412, val images: 0.819433
[13:36:11.212022] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:36:12.096205] Epoch: [46]  [  0/345]  eta: 0:05:04  lr: 0.000005  loss: 0.7020 (0.7020)  time: 0.8831  data: 0.1419  max mem: 14938
[13:36:26.993652] Epoch: [46]  [ 20/345]  eta: 0:04:04  lr: 0.000005  loss: 0.7033 (0.7061)  time: 0.7448  data: 0.0001  max mem: 14938
[13:36:41.949214] Epoch: [46]  [ 40/345]  eta: 0:03:48  lr: 0.000005  loss: 0.7082 (0.7059)  time: 0.7477  data: 0.0001  max mem: 14938
[13:36:56.930595] Epoch: [46]  [ 60/345]  eta: 0:03:33  lr: 0.000005  loss: 0.7004 (0.7049)  time: 0.7490  data: 0.0001  max mem: 14938
[13:37:11.931251] Epoch: [46]  [ 80/345]  eta: 0:03:18  lr: 0.000005  loss: 0.7097 (0.7063)  time: 0.7500  data: 0.0001  max mem: 14938
[13:37:26.961928] Epoch: [46]  [100/345]  eta: 0:03:03  lr: 0.000005  loss: 0.7011 (0.7059)  time: 0.7515  data: 0.0001  max mem: 14938
[13:37:42.002339] Epoch: [46]  [120/345]  eta: 0:02:48  lr: 0.000005  loss: 0.7002 (0.7060)  time: 0.7520  data: 0.0001  max mem: 14938
[13:37:57.173055] Epoch: [46]  [140/345]  eta: 0:02:34  lr: 0.000004  loss: 0.7035 (0.7058)  time: 0.7585  data: 0.0001  max mem: 14938
[13:38:12.221914] Epoch: [46]  [160/345]  eta: 0:02:19  lr: 0.000004  loss: 0.7110 (0.7063)  time: 0.7524  data: 0.0001  max mem: 14938
[13:38:27.253315] Epoch: [46]  [180/345]  eta: 0:02:04  lr: 0.000004  loss: 0.7044 (0.7061)  time: 0.7515  data: 0.0001  max mem: 14938
[13:38:42.285082] Epoch: [46]  [200/345]  eta: 0:01:48  lr: 0.000004  loss: 0.7004 (0.7062)  time: 0.7515  data: 0.0001  max mem: 14938
[13:38:57.298912] Epoch: [46]  [220/345]  eta: 0:01:33  lr: 0.000004  loss: 0.7046 (0.7062)  time: 0.7506  data: 0.0001  max mem: 14938
[13:39:12.304425] Epoch: [46]  [240/345]  eta: 0:01:18  lr: 0.000004  loss: 0.7118 (0.7065)  time: 0.7502  data: 0.0001  max mem: 14938
[13:39:27.316315] Epoch: [46]  [260/345]  eta: 0:01:03  lr: 0.000004  loss: 0.7025 (0.7060)  time: 0.7506  data: 0.0001  max mem: 14938
[13:39:42.321762] Epoch: [46]  [280/345]  eta: 0:00:48  lr: 0.000003  loss: 0.6999 (0.7057)  time: 0.7502  data: 0.0001  max mem: 14938
[13:39:57.331993] Epoch: [46]  [300/345]  eta: 0:00:33  lr: 0.000003  loss: 0.7057 (0.7057)  time: 0.7505  data: 0.0001  max mem: 14938
[13:40:12.331750] Epoch: [46]  [320/345]  eta: 0:00:18  lr: 0.000003  loss: 0.7037 (0.7057)  time: 0.7499  data: 0.0001  max mem: 14938
[13:40:27.322407] Epoch: [46]  [340/345]  eta: 0:00:03  lr: 0.000003  loss: 0.7077 (0.7057)  time: 0.7495  data: 0.0001  max mem: 14938
[13:40:30.325061] Epoch: [46]  [344/345]  eta: 0:00:00  lr: 0.000003  loss: 0.7081 (0.7059)  time: 0.7497  data: 0.0001  max mem: 14938
[13:40:30.390385] Epoch: [46] Total time: 0:04:19 (0.7512 s / it)
[13:40:30.390631] Averaged stats: lr: 0.000003  loss: 0.7081 (0.7059)
[13:40:30.722004] Test:  [  0/345]  eta: 0:01:52  loss: 0.6769 (0.6769)  time: 0.3273  data: 0.1456  max mem: 14938
[13:40:32.560182] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6785 (0.6816)  time: 0.1968  data: 0.0133  max mem: 14938
[13:40:34.400916] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6789 (0.6815)  time: 0.1839  data: 0.0001  max mem: 14938
[13:40:36.244846] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6798 (0.6804)  time: 0.1842  data: 0.0001  max mem: 14938
[13:40:38.091643] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6784 (0.6807)  time: 0.1845  data: 0.0001  max mem: 14938
[13:40:39.942244] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6788 (0.6812)  time: 0.1848  data: 0.0001  max mem: 14938
[13:40:41.797223] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6786 (0.6811)  time: 0.1852  data: 0.0001  max mem: 14938
[13:40:43.654188] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6793 (0.6812)  time: 0.1855  data: 0.0001  max mem: 14938
[13:40:45.516485] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6806 (0.6813)  time: 0.1859  data: 0.0001  max mem: 14938
[13:40:47.382609] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6766 (0.6809)  time: 0.1864  data: 0.0001  max mem: 14938
[13:40:49.249954] Test:  [100/345]  eta: 0:00:45  loss: 0.6766 (0.6808)  time: 0.1866  data: 0.0001  max mem: 14938
[13:40:51.120406] Test:  [110/345]  eta: 0:00:43  loss: 0.6798 (0.6810)  time: 0.1868  data: 0.0001  max mem: 14938
[13:40:52.996693] Test:  [120/345]  eta: 0:00:42  loss: 0.6798 (0.6807)  time: 0.1873  data: 0.0001  max mem: 14938
[13:40:54.876577] Test:  [130/345]  eta: 0:00:40  loss: 0.6708 (0.6802)  time: 0.1878  data: 0.0001  max mem: 14938
[13:40:56.759104] Test:  [140/345]  eta: 0:00:38  loss: 0.6776 (0.6809)  time: 0.1881  data: 0.0001  max mem: 14938
[13:40:58.645398] Test:  [150/345]  eta: 0:00:36  loss: 0.6836 (0.6810)  time: 0.1884  data: 0.0001  max mem: 14938
[13:41:00.534126] Test:  [160/345]  eta: 0:00:34  loss: 0.6803 (0.6807)  time: 0.1887  data: 0.0001  max mem: 14938
[13:41:02.426940] Test:  [170/345]  eta: 0:00:32  loss: 0.6773 (0.6808)  time: 0.1890  data: 0.0001  max mem: 14938
[13:41:04.326280] Test:  [180/345]  eta: 0:00:30  loss: 0.6775 (0.6810)  time: 0.1896  data: 0.0001  max mem: 14938
[13:41:06.228445] Test:  [190/345]  eta: 0:00:29  loss: 0.6829 (0.6812)  time: 0.1900  data: 0.0001  max mem: 14938
[13:41:08.130739] Test:  [200/345]  eta: 0:00:27  loss: 0.6833 (0.6815)  time: 0.1902  data: 0.0001  max mem: 14938
[13:41:10.038287] Test:  [210/345]  eta: 0:00:25  loss: 0.6833 (0.6815)  time: 0.1904  data: 0.0001  max mem: 14938
[13:41:11.947970] Test:  [220/345]  eta: 0:00:23  loss: 0.6825 (0.6817)  time: 0.1908  data: 0.0001  max mem: 14938
[13:41:13.861526] Test:  [230/345]  eta: 0:00:21  loss: 0.6822 (0.6815)  time: 0.1911  data: 0.0001  max mem: 14938
[13:41:15.780631] Test:  [240/345]  eta: 0:00:19  loss: 0.6754 (0.6816)  time: 0.1916  data: 0.0001  max mem: 14938
[13:41:17.702495] Test:  [250/345]  eta: 0:00:17  loss: 0.6827 (0.6816)  time: 0.1920  data: 0.0001  max mem: 14938
[13:41:19.627880] Test:  [260/345]  eta: 0:00:16  loss: 0.6821 (0.6814)  time: 0.1923  data: 0.0001  max mem: 14938
[13:41:21.555348] Test:  [270/345]  eta: 0:00:14  loss: 0.6791 (0.6815)  time: 0.1926  data: 0.0001  max mem: 14938
[13:41:23.486304] Test:  [280/345]  eta: 0:00:12  loss: 0.6791 (0.6815)  time: 0.1929  data: 0.0001  max mem: 14938
[13:41:25.421549] Test:  [290/345]  eta: 0:00:10  loss: 0.6785 (0.6815)  time: 0.1933  data: 0.0001  max mem: 14938
[13:41:27.358831] Test:  [300/345]  eta: 0:00:08  loss: 0.6825 (0.6818)  time: 0.1936  data: 0.0001  max mem: 14938
[13:41:29.300910] Test:  [310/345]  eta: 0:00:06  loss: 0.6800 (0.6818)  time: 0.1939  data: 0.0001  max mem: 14938
[13:41:31.245408] Test:  [320/345]  eta: 0:00:04  loss: 0.6799 (0.6818)  time: 0.1943  data: 0.0001  max mem: 14938
[13:41:33.192801] Test:  [330/345]  eta: 0:00:02  loss: 0.6819 (0.6819)  time: 0.1945  data: 0.0001  max mem: 14938
[13:41:35.142902] Test:  [340/345]  eta: 0:00:00  loss: 0.6830 (0.6820)  time: 0.1948  data: 0.0001  max mem: 14938
[13:41:35.924868] Test:  [344/345]  eta: 0:00:00  loss: 0.6830 (0.6821)  time: 0.1950  data: 0.0001  max mem: 14938
[13:41:35.983693] Test: Total time: 0:01:05 (0.1901 s / it)
[13:41:46.318957] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8487 (0.8487)  time: 0.3194  data: 0.1396  max mem: 14938
[13:41:48.135387] Test:  [10/57]  eta: 0:00:09  loss: 0.8795 (0.8847)  time: 0.1941  data: 0.0128  max mem: 14938
[13:41:49.957061] Test:  [20/57]  eta: 0:00:06  loss: 0.8795 (0.8752)  time: 0.1818  data: 0.0001  max mem: 14938
[13:41:51.784300] Test:  [30/57]  eta: 0:00:05  loss: 0.7582 (0.8312)  time: 0.1824  data: 0.0001  max mem: 14938
[13:41:53.616184] Test:  [40/57]  eta: 0:00:03  loss: 0.7453 (0.8101)  time: 0.1829  data: 0.0001  max mem: 14938
[13:41:55.451534] Test:  [50/57]  eta: 0:00:01  loss: 0.7333 (0.8018)  time: 0.1833  data: 0.0001  max mem: 14938
[13:41:56.440660] Test:  [56/57]  eta: 0:00:00  loss: 0.7552 (0.8067)  time: 0.1778  data: 0.0001  max mem: 14938
[13:41:56.496128] Test: Total time: 0:00:10 (0.1842 s / it)
[13:41:58.223823] Dice score of the network on the train images: 0.839579, val images: 0.820321
[13:41:58.227874] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:41:59.113605] Epoch: [47]  [  0/345]  eta: 0:05:05  lr: 0.000003  loss: 0.7120 (0.7120)  time: 0.8847  data: 0.1426  max mem: 14938
[13:42:14.023791] Epoch: [47]  [ 20/345]  eta: 0:04:04  lr: 0.000003  loss: 0.7003 (0.7020)  time: 0.7455  data: 0.0001  max mem: 14938
[13:42:28.983939] Epoch: [47]  [ 40/345]  eta: 0:03:48  lr: 0.000003  loss: 0.7029 (0.7034)  time: 0.7480  data: 0.0001  max mem: 14938
[13:42:43.967173] Epoch: [47]  [ 60/345]  eta: 0:03:33  lr: 0.000003  loss: 0.7067 (0.7039)  time: 0.7491  data: 0.0001  max mem: 14938
[13:42:58.978859] Epoch: [47]  [ 80/345]  eta: 0:03:18  lr: 0.000003  loss: 0.7083 (0.7051)  time: 0.7505  data: 0.0001  max mem: 14938
[13:43:14.011287] Epoch: [47]  [100/345]  eta: 0:03:03  lr: 0.000003  loss: 0.7053 (0.7050)  time: 0.7516  data: 0.0001  max mem: 14938
[13:43:29.057614] Epoch: [47]  [120/345]  eta: 0:02:48  lr: 0.000002  loss: 0.7081 (0.7054)  time: 0.7523  data: 0.0001  max mem: 14938
[13:43:44.225150] Epoch: [47]  [140/345]  eta: 0:02:34  lr: 0.000002  loss: 0.7028 (0.7056)  time: 0.7583  data: 0.0001  max mem: 14938
[13:43:59.265724] Epoch: [47]  [160/345]  eta: 0:02:19  lr: 0.000002  loss: 0.7078 (0.7054)  time: 0.7520  data: 0.0001  max mem: 14938
[13:44:14.313565] Epoch: [47]  [180/345]  eta: 0:02:04  lr: 0.000002  loss: 0.7074 (0.7060)  time: 0.7523  data: 0.0001  max mem: 14938
[13:44:29.339150] Epoch: [47]  [200/345]  eta: 0:01:49  lr: 0.000002  loss: 0.7039 (0.7060)  time: 0.7512  data: 0.0001  max mem: 14938
[13:44:44.363682] Epoch: [47]  [220/345]  eta: 0:01:33  lr: 0.000002  loss: 0.7041 (0.7057)  time: 0.7512  data: 0.0001  max mem: 14938
[13:44:59.379536] Epoch: [47]  [240/345]  eta: 0:01:18  lr: 0.000002  loss: 0.6982 (0.7055)  time: 0.7507  data: 0.0001  max mem: 14938
[13:45:14.392816] Epoch: [47]  [260/345]  eta: 0:01:03  lr: 0.000002  loss: 0.7067 (0.7057)  time: 0.7506  data: 0.0001  max mem: 14938
[13:45:29.414478] Epoch: [47]  [280/345]  eta: 0:00:48  lr: 0.000002  loss: 0.7073 (0.7058)  time: 0.7510  data: 0.0001  max mem: 14938
[13:45:44.407001] Epoch: [47]  [300/345]  eta: 0:00:33  lr: 0.000002  loss: 0.7041 (0.7057)  time: 0.7496  data: 0.0001  max mem: 14938
[13:45:59.420552] Epoch: [47]  [320/345]  eta: 0:00:18  lr: 0.000001  loss: 0.7052 (0.7057)  time: 0.7506  data: 0.0001  max mem: 14938
[13:46:14.419933] Epoch: [47]  [340/345]  eta: 0:00:03  lr: 0.000001  loss: 0.7038 (0.7056)  time: 0.7499  data: 0.0001  max mem: 14938
[13:46:17.421857] Epoch: [47]  [344/345]  eta: 0:00:00  lr: 0.000001  loss: 0.7038 (0.7056)  time: 0.7500  data: 0.0001  max mem: 14938
[13:46:17.487136] Epoch: [47] Total time: 0:04:19 (0.7515 s / it)
[13:46:17.487537] Averaged stats: lr: 0.000001  loss: 0.7038 (0.7056)
[13:46:17.821698] Test:  [  0/345]  eta: 0:01:53  loss: 0.6640 (0.6640)  time: 0.3287  data: 0.1466  max mem: 14938
[13:46:19.659253] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6796 (0.6795)  time: 0.1969  data: 0.0134  max mem: 14938
[13:46:21.500277] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6796 (0.6792)  time: 0.1839  data: 0.0001  max mem: 14938
[13:46:23.343990] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6730 (0.6772)  time: 0.1842  data: 0.0001  max mem: 14938
[13:46:25.190278] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6750 (0.6796)  time: 0.1844  data: 0.0001  max mem: 14938
[13:46:27.042812] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6820 (0.6799)  time: 0.1849  data: 0.0001  max mem: 14938
[13:46:28.896593] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6793 (0.6801)  time: 0.1853  data: 0.0001  max mem: 14938
[13:46:30.753899] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6760 (0.6798)  time: 0.1855  data: 0.0001  max mem: 14938
[13:46:32.614104] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6773 (0.6802)  time: 0.1858  data: 0.0001  max mem: 14938
[13:46:34.479840] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6868 (0.6809)  time: 0.1862  data: 0.0001  max mem: 14938
[13:46:36.347245] Test:  [100/345]  eta: 0:00:45  loss: 0.6887 (0.6813)  time: 0.1866  data: 0.0001  max mem: 14938
[13:46:38.218296] Test:  [110/345]  eta: 0:00:43  loss: 0.6785 (0.6809)  time: 0.1869  data: 0.0001  max mem: 14938
[13:46:40.092387] Test:  [120/345]  eta: 0:00:42  loss: 0.6817 (0.6818)  time: 0.1872  data: 0.0001  max mem: 14938
[13:46:41.970960] Test:  [130/345]  eta: 0:00:40  loss: 0.6819 (0.6820)  time: 0.1876  data: 0.0001  max mem: 14938
[13:46:43.853774] Test:  [140/345]  eta: 0:00:38  loss: 0.6820 (0.6823)  time: 0.1880  data: 0.0001  max mem: 14938
[13:46:45.738243] Test:  [150/345]  eta: 0:00:36  loss: 0.6820 (0.6820)  time: 0.1883  data: 0.0001  max mem: 14938
[13:46:47.626693] Test:  [160/345]  eta: 0:00:34  loss: 0.6811 (0.6822)  time: 0.1886  data: 0.0001  max mem: 14938
[13:46:49.518512] Test:  [170/345]  eta: 0:00:32  loss: 0.6861 (0.6829)  time: 0.1890  data: 0.0001  max mem: 14938
[13:46:51.414770] Test:  [180/345]  eta: 0:00:30  loss: 0.6861 (0.6829)  time: 0.1894  data: 0.0001  max mem: 14938
[13:46:53.316159] Test:  [190/345]  eta: 0:00:29  loss: 0.6797 (0.6830)  time: 0.1898  data: 0.0001  max mem: 14938
[13:46:55.217509] Test:  [200/345]  eta: 0:00:27  loss: 0.6791 (0.6827)  time: 0.1901  data: 0.0001  max mem: 14938
[13:46:57.123390] Test:  [210/345]  eta: 0:00:25  loss: 0.6811 (0.6827)  time: 0.1903  data: 0.0001  max mem: 14938
[13:46:59.032460] Test:  [220/345]  eta: 0:00:23  loss: 0.6811 (0.6826)  time: 0.1907  data: 0.0001  max mem: 14938
[13:47:00.945511] Test:  [230/345]  eta: 0:00:21  loss: 0.6779 (0.6826)  time: 0.1911  data: 0.0001  max mem: 14938
[13:47:02.862163] Test:  [240/345]  eta: 0:00:19  loss: 0.6778 (0.6824)  time: 0.1914  data: 0.0001  max mem: 14938
[13:47:04.782130] Test:  [250/345]  eta: 0:00:17  loss: 0.6736 (0.6822)  time: 0.1918  data: 0.0001  max mem: 14938
[13:47:06.705696] Test:  [260/345]  eta: 0:00:16  loss: 0.6765 (0.6822)  time: 0.1921  data: 0.0001  max mem: 14938
[13:47:08.633169] Test:  [270/345]  eta: 0:00:14  loss: 0.6791 (0.6821)  time: 0.1925  data: 0.0001  max mem: 14938
[13:47:10.564494] Test:  [280/345]  eta: 0:00:12  loss: 0.6791 (0.6820)  time: 0.1929  data: 0.0001  max mem: 14938
[13:47:12.499368] Test:  [290/345]  eta: 0:00:10  loss: 0.6812 (0.6820)  time: 0.1933  data: 0.0001  max mem: 14938
[13:47:14.438660] Test:  [300/345]  eta: 0:00:08  loss: 0.6742 (0.6819)  time: 0.1937  data: 0.0001  max mem: 14938
[13:47:16.381213] Test:  [310/345]  eta: 0:00:06  loss: 0.6765 (0.6818)  time: 0.1940  data: 0.0001  max mem: 14938
[13:47:18.326366] Test:  [320/345]  eta: 0:00:04  loss: 0.6781 (0.6817)  time: 0.1943  data: 0.0001  max mem: 14938
[13:47:20.274287] Test:  [330/345]  eta: 0:00:02  loss: 0.6804 (0.6819)  time: 0.1946  data: 0.0001  max mem: 14938
[13:47:22.223597] Test:  [340/345]  eta: 0:00:00  loss: 0.6815 (0.6818)  time: 0.1948  data: 0.0001  max mem: 14938
[13:47:23.005333] Test:  [344/345]  eta: 0:00:00  loss: 0.6815 (0.6819)  time: 0.1949  data: 0.0001  max mem: 14938
[13:47:23.065243] Test: Total time: 0:01:05 (0.1901 s / it)
[13:47:33.528864] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8537 (0.8537)  time: 0.3191  data: 0.1399  max mem: 14938
[13:47:35.343752] Test:  [10/57]  eta: 0:00:09  loss: 0.8823 (0.8882)  time: 0.1939  data: 0.0128  max mem: 14938
[13:47:37.164848] Test:  [20/57]  eta: 0:00:06  loss: 0.8823 (0.8787)  time: 0.1817  data: 0.0001  max mem: 14938
[13:47:38.990648] Test:  [30/57]  eta: 0:00:05  loss: 0.7579 (0.8341)  time: 0.1823  data: 0.0001  max mem: 14938
[13:47:40.819937] Test:  [40/57]  eta: 0:00:03  loss: 0.7463 (0.8127)  time: 0.1827  data: 0.0001  max mem: 14938
[13:47:42.654476] Test:  [50/57]  eta: 0:00:01  loss: 0.7355 (0.8042)  time: 0.1831  data: 0.0001  max mem: 14938
[13:47:43.644316] Test:  [56/57]  eta: 0:00:00  loss: 0.7547 (0.8091)  time: 0.1778  data: 0.0001  max mem: 14938
[13:47:43.698915] Test: Total time: 0:00:10 (0.1840 s / it)
[13:47:45.481229] Dice score of the network on the train images: 0.842014, val images: 0.819227
[13:47:45.485409] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:47:46.371771] Epoch: [48]  [  0/345]  eta: 0:05:05  lr: 0.000001  loss: 0.7029 (0.7029)  time: 0.8852  data: 0.1405  max mem: 14938
[13:48:01.280037] Epoch: [48]  [ 20/345]  eta: 0:04:04  lr: 0.000001  loss: 0.7014 (0.7024)  time: 0.7454  data: 0.0001  max mem: 14938
[13:48:16.239846] Epoch: [48]  [ 40/345]  eta: 0:03:48  lr: 0.000001  loss: 0.7027 (0.7027)  time: 0.7479  data: 0.0001  max mem: 14938
[13:48:31.232533] Epoch: [48]  [ 60/345]  eta: 0:03:33  lr: 0.000001  loss: 0.7006 (0.7025)  time: 0.7496  data: 0.0001  max mem: 14938
[13:48:46.242307] Epoch: [48]  [ 80/345]  eta: 0:03:18  lr: 0.000001  loss: 0.7065 (0.7042)  time: 0.7504  data: 0.0001  max mem: 14938
[13:49:01.263110] Epoch: [48]  [100/345]  eta: 0:03:03  lr: 0.000001  loss: 0.7074 (0.7044)  time: 0.7510  data: 0.0001  max mem: 14938
[13:49:16.313129] Epoch: [48]  [120/345]  eta: 0:02:48  lr: 0.000001  loss: 0.7045 (0.7045)  time: 0.7525  data: 0.0001  max mem: 14938
[13:49:31.357521] Epoch: [48]  [140/345]  eta: 0:02:33  lr: 0.000001  loss: 0.7029 (0.7046)  time: 0.7522  data: 0.0001  max mem: 14938
[13:49:46.405234] Epoch: [48]  [160/345]  eta: 0:02:18  lr: 0.000001  loss: 0.7053 (0.7048)  time: 0.7523  data: 0.0001  max mem: 14938
[13:50:01.434714] Epoch: [48]  [180/345]  eta: 0:02:03  lr: 0.000001  loss: 0.7074 (0.7050)  time: 0.7514  data: 0.0001  max mem: 14938
[13:50:16.472647] Epoch: [48]  [200/345]  eta: 0:01:48  lr: 0.000001  loss: 0.7037 (0.7052)  time: 0.7518  data: 0.0001  max mem: 14938
[13:50:31.493576] Epoch: [48]  [220/345]  eta: 0:01:33  lr: 0.000001  loss: 0.7026 (0.7052)  time: 0.7510  data: 0.0001  max mem: 14938
[13:50:46.525103] Epoch: [48]  [240/345]  eta: 0:01:18  lr: 0.000001  loss: 0.7075 (0.7054)  time: 0.7515  data: 0.0001  max mem: 14938
[13:51:01.532483] Epoch: [48]  [260/345]  eta: 0:01:03  lr: 0.000001  loss: 0.6983 (0.7051)  time: 0.7503  data: 0.0001  max mem: 14938
[13:51:16.624685] Epoch: [48]  [280/345]  eta: 0:00:48  lr: 0.000000  loss: 0.7065 (0.7053)  time: 0.7546  data: 0.0001  max mem: 14938
[13:51:31.622349] Epoch: [48]  [300/345]  eta: 0:00:33  lr: 0.000000  loss: 0.7125 (0.7056)  time: 0.7498  data: 0.0001  max mem: 14938
[13:51:46.629000] Epoch: [48]  [320/345]  eta: 0:00:18  lr: 0.000000  loss: 0.7010 (0.7054)  time: 0.7503  data: 0.0001  max mem: 14938
[13:52:01.628225] Epoch: [48]  [340/345]  eta: 0:00:03  lr: 0.000000  loss: 0.7009 (0.7054)  time: 0.7499  data: 0.0001  max mem: 14938
[13:52:04.628378] Epoch: [48]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.7009 (0.7054)  time: 0.7499  data: 0.0001  max mem: 14938
[13:52:04.689772] Epoch: [48] Total time: 0:04:19 (0.7513 s / it)
[13:52:04.690030] Averaged stats: lr: 0.000000  loss: 0.7009 (0.7054)
[13:52:05.021987] Test:  [  0/345]  eta: 0:01:52  loss: 0.6776 (0.6776)  time: 0.3275  data: 0.1459  max mem: 14938
[13:52:06.857999] Test:  [ 10/345]  eta: 0:01:05  loss: 0.6852 (0.6881)  time: 0.1966  data: 0.0133  max mem: 14938
[13:52:08.697588] Test:  [ 20/345]  eta: 0:01:01  loss: 0.6810 (0.6842)  time: 0.1837  data: 0.0001  max mem: 14938
[13:52:10.540983] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6810 (0.6843)  time: 0.1841  data: 0.0001  max mem: 14938
[13:52:12.386648] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6830 (0.6839)  time: 0.1844  data: 0.0001  max mem: 14938
[13:52:14.236632] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6793 (0.6830)  time: 0.1847  data: 0.0001  max mem: 14938
[13:52:16.092702] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6769 (0.6825)  time: 0.1853  data: 0.0001  max mem: 14938
[13:52:17.949031] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6754 (0.6821)  time: 0.1856  data: 0.0001  max mem: 14938
[13:52:19.808548] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6781 (0.6816)  time: 0.1857  data: 0.0001  max mem: 14938
[13:52:21.672758] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6778 (0.6817)  time: 0.1861  data: 0.0001  max mem: 14938
[13:52:23.539695] Test:  [100/345]  eta: 0:00:45  loss: 0.6784 (0.6819)  time: 0.1865  data: 0.0001  max mem: 14938
[13:52:25.411001] Test:  [110/345]  eta: 0:00:43  loss: 0.6784 (0.6819)  time: 0.1869  data: 0.0001  max mem: 14938
[13:52:27.284400] Test:  [120/345]  eta: 0:00:41  loss: 0.6785 (0.6817)  time: 0.1872  data: 0.0001  max mem: 14938
[13:52:29.162931] Test:  [130/345]  eta: 0:00:40  loss: 0.6788 (0.6818)  time: 0.1875  data: 0.0001  max mem: 14938
[13:52:31.044159] Test:  [140/345]  eta: 0:00:38  loss: 0.6846 (0.6819)  time: 0.1879  data: 0.0001  max mem: 14938
[13:52:32.930062] Test:  [150/345]  eta: 0:00:36  loss: 0.6803 (0.6818)  time: 0.1883  data: 0.0001  max mem: 14938
[13:52:34.817452] Test:  [160/345]  eta: 0:00:34  loss: 0.6837 (0.6822)  time: 0.1886  data: 0.0001  max mem: 14938
[13:52:36.708507] Test:  [170/345]  eta: 0:00:32  loss: 0.6834 (0.6820)  time: 0.1889  data: 0.0001  max mem: 14938
[13:52:38.604433] Test:  [180/345]  eta: 0:00:30  loss: 0.6766 (0.6822)  time: 0.1893  data: 0.0001  max mem: 14938
[13:52:40.503728] Test:  [190/345]  eta: 0:00:29  loss: 0.6821 (0.6822)  time: 0.1897  data: 0.0001  max mem: 14938
[13:52:42.405667] Test:  [200/345]  eta: 0:00:27  loss: 0.6794 (0.6819)  time: 0.1900  data: 0.0001  max mem: 14938
[13:52:44.311243] Test:  [210/345]  eta: 0:00:25  loss: 0.6794 (0.6820)  time: 0.1903  data: 0.0001  max mem: 14938
[13:52:46.221443] Test:  [220/345]  eta: 0:00:23  loss: 0.6812 (0.6819)  time: 0.1907  data: 0.0001  max mem: 14938
[13:52:48.134055] Test:  [230/345]  eta: 0:00:21  loss: 0.6801 (0.6818)  time: 0.1911  data: 0.0001  max mem: 14938
[13:52:50.052787] Test:  [240/345]  eta: 0:00:19  loss: 0.6811 (0.6819)  time: 0.1915  data: 0.0001  max mem: 14938
[13:52:51.974964] Test:  [250/345]  eta: 0:00:17  loss: 0.6779 (0.6818)  time: 0.1920  data: 0.0001  max mem: 14938
[13:52:53.899352] Test:  [260/345]  eta: 0:00:16  loss: 0.6777 (0.6817)  time: 0.1923  data: 0.0001  max mem: 14938
[13:52:55.830264] Test:  [270/345]  eta: 0:00:14  loss: 0.6777 (0.6817)  time: 0.1927  data: 0.0001  max mem: 14938
[13:52:57.762499] Test:  [280/345]  eta: 0:00:12  loss: 0.6830 (0.6819)  time: 0.1931  data: 0.0001  max mem: 14938
[13:52:59.696818] Test:  [290/345]  eta: 0:00:10  loss: 0.6825 (0.6819)  time: 0.1933  data: 0.0001  max mem: 14938
[13:53:01.635694] Test:  [300/345]  eta: 0:00:08  loss: 0.6815 (0.6819)  time: 0.1936  data: 0.0001  max mem: 14938
[13:53:03.577334] Test:  [310/345]  eta: 0:00:06  loss: 0.6811 (0.6819)  time: 0.1940  data: 0.0001  max mem: 14938
[13:53:05.521526] Test:  [320/345]  eta: 0:00:04  loss: 0.6844 (0.6820)  time: 0.1942  data: 0.0001  max mem: 14938
[13:53:07.468509] Test:  [330/345]  eta: 0:00:02  loss: 0.6825 (0.6820)  time: 0.1945  data: 0.0001  max mem: 14938
[13:53:09.418595] Test:  [340/345]  eta: 0:00:00  loss: 0.6802 (0.6819)  time: 0.1948  data: 0.0001  max mem: 14938
[13:53:10.200684] Test:  [344/345]  eta: 0:00:00  loss: 0.6772 (0.6819)  time: 0.1950  data: 0.0001  max mem: 14938
[13:53:10.258239] Test: Total time: 0:01:05 (0.1900 s / it)
[13:53:20.693331] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8527 (0.8527)  time: 0.3159  data: 0.1363  max mem: 14938
[13:53:22.511326] Test:  [10/57]  eta: 0:00:09  loss: 0.8813 (0.8871)  time: 0.1939  data: 0.0124  max mem: 14938
[13:53:24.333024] Test:  [20/57]  eta: 0:00:06  loss: 0.8813 (0.8778)  time: 0.1819  data: 0.0001  max mem: 14938
[13:53:26.159325] Test:  [30/57]  eta: 0:00:05  loss: 0.7571 (0.8332)  time: 0.1823  data: 0.0001  max mem: 14938
[13:53:27.988549] Test:  [40/57]  eta: 0:00:03  loss: 0.7458 (0.8118)  time: 0.1827  data: 0.0001  max mem: 14938
[13:53:29.824150] Test:  [50/57]  eta: 0:00:01  loss: 0.7347 (0.8034)  time: 0.1832  data: 0.0001  max mem: 14938
[13:53:30.814353] Test:  [56/57]  eta: 0:00:00  loss: 0.7547 (0.8083)  time: 0.1778  data: 0.0001  max mem: 14938
[13:53:30.874831] Test: Total time: 0:00:10 (0.1842 s / it)
[13:53:32.612029] Dice score of the network on the train images: 0.841305, val images: 0.819833
[13:53:32.616183] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:53:33.500501] Epoch: [49]  [  0/345]  eta: 0:05:04  lr: 0.000000  loss: 0.7214 (0.7214)  time: 0.8833  data: 0.1407  max mem: 14938
[13:53:48.412124] Epoch: [49]  [ 20/345]  eta: 0:04:04  lr: 0.000000  loss: 0.7066 (0.7084)  time: 0.7455  data: 0.0001  max mem: 14938
[13:54:03.395377] Epoch: [49]  [ 40/345]  eta: 0:03:48  lr: 0.000000  loss: 0.7052 (0.7089)  time: 0.7491  data: 0.0001  max mem: 14938
[13:54:18.373594] Epoch: [49]  [ 60/345]  eta: 0:03:33  lr: 0.000000  loss: 0.7050 (0.7078)  time: 0.7489  data: 0.0001  max mem: 14938
[13:54:33.358342] Epoch: [49]  [ 80/345]  eta: 0:03:18  lr: 0.000000  loss: 0.7049 (0.7067)  time: 0.7492  data: 0.0001  max mem: 14938
[13:54:48.361352] Epoch: [49]  [100/345]  eta: 0:03:03  lr: 0.000000  loss: 0.7049 (0.7064)  time: 0.7501  data: 0.0001  max mem: 14938
[13:55:03.401587] Epoch: [49]  [120/345]  eta: 0:02:48  lr: 0.000000  loss: 0.7005 (0.7056)  time: 0.7520  data: 0.0001  max mem: 14938
[13:55:18.440770] Epoch: [49]  [140/345]  eta: 0:02:33  lr: 0.000000  loss: 0.7055 (0.7055)  time: 0.7519  data: 0.0001  max mem: 14938
[13:55:33.492181] Epoch: [49]  [160/345]  eta: 0:02:18  lr: 0.000000  loss: 0.7036 (0.7055)  time: 0.7525  data: 0.0001  max mem: 14938
[13:55:48.528584] Epoch: [49]  [180/345]  eta: 0:02:03  lr: 0.000000  loss: 0.7051 (0.7056)  time: 0.7518  data: 0.0001  max mem: 14938
[13:56:03.560900] Epoch: [49]  [200/345]  eta: 0:01:48  lr: 0.000000  loss: 0.6995 (0.7053)  time: 0.7516  data: 0.0001  max mem: 14938
[13:56:18.589826] Epoch: [49]  [220/345]  eta: 0:01:33  lr: 0.000000  loss: 0.7016 (0.7051)  time: 0.7514  data: 0.0001  max mem: 14938
[13:56:33.608859] Epoch: [49]  [240/345]  eta: 0:01:18  lr: 0.000000  loss: 0.7034 (0.7051)  time: 0.7509  data: 0.0001  max mem: 14938
[13:56:48.625081] Epoch: [49]  [260/345]  eta: 0:01:03  lr: 0.000000  loss: 0.7012 (0.7051)  time: 0.7508  data: 0.0001  max mem: 14938
[13:57:03.645517] Epoch: [49]  [280/345]  eta: 0:00:48  lr: 0.000000  loss: 0.7021 (0.7050)  time: 0.7510  data: 0.0001  max mem: 14938
[13:57:18.648905] Epoch: [49]  [300/345]  eta: 0:00:33  lr: 0.000000  loss: 0.7022 (0.7050)  time: 0.7501  data: 0.0001  max mem: 14938
[13:57:33.646275] Epoch: [49]  [320/345]  eta: 0:00:18  lr: 0.000000  loss: 0.7051 (0.7051)  time: 0.7498  data: 0.0001  max mem: 14938
[13:57:48.637680] Epoch: [49]  [340/345]  eta: 0:00:03  lr: 0.000000  loss: 0.7042 (0.7053)  time: 0.7495  data: 0.0001  max mem: 14938
[13:57:51.636551] Epoch: [49]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.7042 (0.7052)  time: 0.7496  data: 0.0001  max mem: 14938
[13:57:51.697058] Epoch: [49] Total time: 0:04:19 (0.7510 s / it)
[13:57:51.697545] Averaged stats: lr: 0.000000  loss: 0.7042 (0.7052)
[13:57:52.031132] Test:  [  0/345]  eta: 0:01:53  loss: 0.6842 (0.6842)  time: 0.3300  data: 0.1485  max mem: 14938
[13:57:53.869777] Test:  [ 10/345]  eta: 0:01:06  loss: 0.6766 (0.6779)  time: 0.1971  data: 0.0136  max mem: 14938
[13:57:55.709446] Test:  [ 20/345]  eta: 0:01:02  loss: 0.6766 (0.6801)  time: 0.1838  data: 0.0001  max mem: 14938
[13:57:57.552486] Test:  [ 30/345]  eta: 0:00:59  loss: 0.6829 (0.6815)  time: 0.1841  data: 0.0001  max mem: 14938
[13:57:59.398708] Test:  [ 40/345]  eta: 0:00:57  loss: 0.6841 (0.6819)  time: 0.1844  data: 0.0001  max mem: 14938
[13:58:01.249383] Test:  [ 50/345]  eta: 0:00:55  loss: 0.6835 (0.6811)  time: 0.1848  data: 0.0001  max mem: 14938
[13:58:03.104050] Test:  [ 60/345]  eta: 0:00:53  loss: 0.6778 (0.6808)  time: 0.1852  data: 0.0001  max mem: 14938
[13:58:04.961302] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6759 (0.6802)  time: 0.1855  data: 0.0001  max mem: 14938
[13:58:06.821203] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6793 (0.6807)  time: 0.1858  data: 0.0001  max mem: 14938
[13:58:08.687168] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6813 (0.6810)  time: 0.1862  data: 0.0001  max mem: 14938
[13:58:10.554237] Test:  [100/345]  eta: 0:00:45  loss: 0.6799 (0.6812)  time: 0.1866  data: 0.0001  max mem: 14938
[13:58:12.424436] Test:  [110/345]  eta: 0:00:43  loss: 0.6819 (0.6814)  time: 0.1868  data: 0.0001  max mem: 14938
[13:58:14.299306] Test:  [120/345]  eta: 0:00:42  loss: 0.6739 (0.6805)  time: 0.1872  data: 0.0001  max mem: 14938
[13:58:16.177848] Test:  [130/345]  eta: 0:00:40  loss: 0.6739 (0.6805)  time: 0.1876  data: 0.0001  max mem: 14938
[13:58:18.058652] Test:  [140/345]  eta: 0:00:38  loss: 0.6776 (0.6806)  time: 0.1879  data: 0.0001  max mem: 14938
[13:58:19.941929] Test:  [150/345]  eta: 0:00:36  loss: 0.6840 (0.6807)  time: 0.1882  data: 0.0001  max mem: 14938
[13:58:21.829442] Test:  [160/345]  eta: 0:00:34  loss: 0.6840 (0.6807)  time: 0.1885  data: 0.0001  max mem: 14938
[13:58:23.721088] Test:  [170/345]  eta: 0:00:32  loss: 0.6800 (0.6808)  time: 0.1889  data: 0.0001  max mem: 14938
[13:58:25.618451] Test:  [180/345]  eta: 0:00:30  loss: 0.6817 (0.6809)  time: 0.1894  data: 0.0001  max mem: 14938
[13:58:27.518339] Test:  [190/345]  eta: 0:00:29  loss: 0.6822 (0.6811)  time: 0.1898  data: 0.0001  max mem: 14938
[13:58:29.421837] Test:  [200/345]  eta: 0:00:27  loss: 0.6820 (0.6811)  time: 0.1901  data: 0.0001  max mem: 14938
[13:58:31.327507] Test:  [210/345]  eta: 0:00:25  loss: 0.6812 (0.6813)  time: 0.1904  data: 0.0001  max mem: 14938
[13:58:33.236427] Test:  [220/345]  eta: 0:00:23  loss: 0.6818 (0.6812)  time: 0.1907  data: 0.0001  max mem: 14938
[13:58:35.150436] Test:  [230/345]  eta: 0:00:21  loss: 0.6822 (0.6816)  time: 0.1911  data: 0.0001  max mem: 14938
[13:58:37.066844] Test:  [240/345]  eta: 0:00:19  loss: 0.6830 (0.6816)  time: 0.1915  data: 0.0001  max mem: 14938
[13:58:38.988738] Test:  [250/345]  eta: 0:00:17  loss: 0.6834 (0.6817)  time: 0.1919  data: 0.0001  max mem: 14938
[13:58:40.912950] Test:  [260/345]  eta: 0:00:16  loss: 0.6845 (0.6818)  time: 0.1923  data: 0.0001  max mem: 14938
[13:58:42.840041] Test:  [270/345]  eta: 0:00:14  loss: 0.6814 (0.6817)  time: 0.1925  data: 0.0001  max mem: 14938
[13:58:44.773805] Test:  [280/345]  eta: 0:00:12  loss: 0.6782 (0.6817)  time: 0.1930  data: 0.0001  max mem: 14938
[13:58:46.708088] Test:  [290/345]  eta: 0:00:10  loss: 0.6778 (0.6815)  time: 0.1933  data: 0.0001  max mem: 14938
[13:58:48.644907] Test:  [300/345]  eta: 0:00:08  loss: 0.6791 (0.6816)  time: 0.1935  data: 0.0001  max mem: 14938
[13:58:50.584500] Test:  [310/345]  eta: 0:00:06  loss: 0.6833 (0.6816)  time: 0.1938  data: 0.0001  max mem: 14938
[13:58:52.528426] Test:  [320/345]  eta: 0:00:04  loss: 0.6760 (0.6814)  time: 0.1941  data: 0.0001  max mem: 14938
[13:58:54.475868] Test:  [330/345]  eta: 0:00:02  loss: 0.6799 (0.6816)  time: 0.1945  data: 0.0001  max mem: 14938
[13:58:56.428671] Test:  [340/345]  eta: 0:00:00  loss: 0.6839 (0.6817)  time: 0.1950  data: 0.0001  max mem: 14938
[13:58:57.210319] Test:  [344/345]  eta: 0:00:00  loss: 0.6815 (0.6816)  time: 0.1951  data: 0.0001  max mem: 14938
[13:58:57.269942] Test: Total time: 0:01:05 (0.1901 s / it)
[13:59:07.640273] Test:  [ 0/57]  eta: 0:00:18  loss: 0.8519 (0.8519)  time: 0.3189  data: 0.1396  max mem: 14938
[13:59:09.456760] Test:  [10/57]  eta: 0:00:09  loss: 0.8808 (0.8865)  time: 0.1941  data: 0.0128  max mem: 14938
[13:59:11.277088] Test:  [20/57]  eta: 0:00:06  loss: 0.8808 (0.8773)  time: 0.1818  data: 0.0001  max mem: 14938
[13:59:13.102098] Test:  [30/57]  eta: 0:00:05  loss: 0.7574 (0.8328)  time: 0.1822  data: 0.0001  max mem: 14938
[13:59:14.931458] Test:  [40/57]  eta: 0:00:03  loss: 0.7454 (0.8114)  time: 0.1827  data: 0.0001  max mem: 14938
[13:59:16.766216] Test:  [50/57]  eta: 0:00:01  loss: 0.7344 (0.8030)  time: 0.1832  data: 0.0001  max mem: 14938
[13:59:17.755729] Test:  [56/57]  eta: 0:00:00  loss: 0.7547 (0.8079)  time: 0.1778  data: 0.0001  max mem: 14938
[13:59:17.815550] Test: Total time: 0:00:10 (0.1841 s / it)
[13:59:19.573955] Dice score of the network on the train images: 0.840836, val images: 0.819946
[13:59:19.575354] Training time 4:49:23
[13:59:21.460580] Load pre-trained checkpoint from: /root/seg_framework/MS-Mamba/output_dir/mslesseg/checkpoints_0/checkpoint-best_dice_model_0.pth
[13:59:21.482386] <All keys matched successfully>
[13:59:22.053567] Test:  [  0/246]  eta: 0:02:03    time: 0.5017  data: 0.1641  max mem: 14938
[13:59:24.736825] Test:  [ 10/246]  eta: 0:01:08    time: 0.2895  data: 0.0150  max mem: 14938
[13:59:30.967366] ---------------------------------
[13:59:30.967586] Patient 1:
[13:59:30.967670]       precision: 0.46226415038108826
[13:59:30.967739]       recall: 0.5483871102333069
[13:59:30.967801]       dice_score: 0.5016561150550842
[13:59:30.970816] Test:  [ 20/246]  eta: 0:01:41    time: 0.4458  data: 0.0001  max mem: 14938
[13:59:33.650593] Test:  [ 30/246]  eta: 0:01:24    time: 0.4456  data: 0.0001  max mem: 14938
[13:59:39.828665] ---------------------------------
[13:59:39.828889] Patient 2:
[13:59:39.828967]       precision: 0.5499514937400818
[13:59:39.829032]       recall: 0.5724381804466248
[13:59:39.829093]       dice_score: 0.5609695911407471
[13:59:39.835657] Test:  [ 40/246]  eta: 0:01:31    time: 0.4432  data: 0.0001  max mem: 14938
[13:59:42.514835] Test:  [ 50/246]  eta: 0:01:20    time: 0.4432  data: 0.0001  max mem: 14938
[13:59:45.376459] Test:  [ 60/246]  eta: 0:01:12    time: 0.2770  data: 0.0001  max mem: 14938
[13:59:48.985439] ---------------------------------
[13:59:48.985656] Patient 3:
[13:59:48.985738]       precision: 0.36601561307907104
[13:59:48.985807]       recall: 0.5139879584312439
[13:59:48.985866]       dice_score: 0.42756104469299316
[13:59:51.384112] Test:  [ 70/246]  eta: 0:01:13    time: 0.4434  data: 0.0001  max mem: 14938
[13:59:54.245695] Test:  [ 80/246]  eta: 0:01:06    time: 0.4434  data: 0.0001  max mem: 14938
[13:59:57.869468] ---------------------------------
[13:59:57.869680] Patient 4:
[13:59:57.869762]       precision: 0.5817232131958008
[13:59:57.869830]       recall: 0.5623422265052795
[13:59:57.869896]       dice_score: 0.5718685984611511
[14:00:00.261859] Test:  [ 90/246]  eta: 0:01:06    time: 0.4438  data: 0.0001  max mem: 14938
[14:00:03.122422] Test:  [100/246]  eta: 0:01:00    time: 0.4438  data: 0.0001  max mem: 14938
[14:00:06.949645] ---------------------------------
[14:00:06.949864] Patient 5:
[14:00:06.949945]       precision: 0.38930976390838623
[14:00:06.950013]       recall: 0.5074054002761841
[14:00:06.950075]       dice_score: 0.4405810832977295
[14:00:09.056667] Test:  [110/246]  eta: 0:00:58    time: 0.4397  data: 0.0001  max mem: 14938
[14:00:11.919351] Test:  [120/246]  eta: 0:00:52    time: 0.4398  data: 0.0001  max mem: 14938
[14:00:15.825610] ---------------------------------
[14:00:15.825832] Patient 6:
[14:00:15.825910]       precision: 0.38487255573272705
[14:00:15.825976]       recall: 0.5052111744880676
[14:00:15.826037]       dice_score: 0.436907023191452
[14:00:17.933897] Test:  [130/246]  eta: 0:00:49    time: 0.4438  data: 0.0001  max mem: 14938
[14:00:20.795137] Test:  [140/246]  eta: 0:00:44    time: 0.4437  data: 0.0001  max mem: 14938
[14:00:24.990909] ---------------------------------
[14:00:24.991118] Patient 7:
[14:00:24.991195]       precision: 0.8102118968963623
[14:00:24.991271]       recall: 0.7545257210731506
[14:00:25.021640]       dice_score: 0.781377911567688
[14:00:26.843754] Test:  [150/246]  eta: 0:00:41    time: 0.4454  data: 0.0001  max mem: 14938
[14:00:29.704880] Test:  [160/246]  eta: 0:00:36    time: 0.4454  data: 0.0001  max mem: 14938
[14:00:33.900205] ---------------------------------
[14:00:33.900526] Patient 8:
[14:00:33.900602]       precision: 0.8888484835624695
[14:00:33.900667]       recall: 0.5609744787216187
[14:00:33.900728]       dice_score: 0.687837541103363
[14:00:35.722232] Test:  [170/246]  eta: 0:00:32    time: 0.4439  data: 0.0001  max mem: 14938
[14:00:38.586754] Test:  [180/246]  eta: 0:00:28    time: 0.4440  data: 0.0001  max mem: 14938
[14:00:42.894554] ---------------------------------
[14:00:42.894771] Patient 9:
[14:00:42.894851]       precision: 0.7309382557868958
[14:00:42.894916]       recall: 0.8078441023826599
[14:00:42.894978]       dice_score: 0.7674693465232849
[14:00:44.719547] Test:  [190/246]  eta: 0:00:24    time: 0.4498  data: 0.0001  max mem: 14938
[14:00:47.577694] Test:  [200/246]  eta: 0:00:19    time: 0.4495  data: 0.0001  max mem: 14938
[14:00:52.042064] ---------------------------------
[14:00:52.042291] Patient 10:
[14:00:52.042370]       precision: 0.7396626472473145
[14:00:52.042434]       recall: 0.7960658073425293
[14:00:52.042494]       dice_score: 0.7668284773826599
[14:00:53.585387] Test:  [210/246]  eta: 0:00:15    time: 0.4432  data: 0.0001  max mem: 14938
[14:00:56.443489] Test:  [220/246]  eta: 0:00:11    time: 0.4432  data: 0.0001  max mem: 14938
[14:01:00.896571] ---------------------------------
[14:01:00.896789] Patient 11:
[14:01:00.896867]       precision: 0.8767351508140564
[14:01:00.896931]       recall: 0.7684180736541748
[14:01:00.896992]       dice_score: 0.819010853767395
[14:01:02.435850] Test:  [230/246]  eta: 0:00:06    time: 0.4425  data: 0.0001  max mem: 14938
[14:01:05.292524] Test:  [240/246]  eta: 0:00:02    time: 0.4424  data: 0.0001  max mem: 14938
[14:01:09.811166] ---------------------------------
[14:01:09.811393] Patient 12:
[14:01:09.811474]       precision: 0.6638855934143066
[14:01:09.811539]       recall: 0.7533814311027527
[14:01:09.811599]       dice_score: 0.7058078050613403
[14:01:09.811974] Test:  [245/246]  eta: 0:00:00    time: 0.4402  data: 0.0001  max mem: 14938
[14:01:09.866880] Test: Total time: 0:01:48 (0.4403 s / it)
[14:01:09.867074] ================================
[14:01:09.867134] Averaged over all patients:
[14:01:09.867408]       precision: 0.6204 ± 0.1842
[14:01:09.867556]       recall: 0.6376 ± 0.1196
[14:01:09.867679]       dice_score: 0.6223 ± 0.1424
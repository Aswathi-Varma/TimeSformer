Not using distributed mode
[12:53:56.041870] job dir: /root/seg_framework/MS-Mamba/run_scripts
[12:53:56.042016] Namespace(accum_iter=1,
model='SegFormer3D',
in_channels=1,
lr=None,
blr=0.001,
min_lr=0,
dist_on_itp=False,
warmup_epochs=20,
device='cuda:0',
seed=42,
layer_decay=0.75,
clip_grad=None,
num_workers=8,
pin_mem=True,
resume='',
mask_mode='concatenate to image',
world_size=1,
embed_dim=1,
local_rank=-1,
dist_url='env://',
nb_classes=2,
data_dir='/root/MSLesSeg24/data',
datalist=None,
preprocess=False,
dim=2,
distributed=False)
[12:53:56.042906] Starting for fold 0
[12:53:56.232496] Elements in data_dir_paths: 11052
[12:53:56.266711] Elements in data_dir_paths: 1803
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/fold_0/val_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[34m[1mwandb[39m[22m: [33mWARNING[39m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir="...")` before `wandb.init`
[34m[1mwandb[39m[22m: [33mWARNING[39m Found log directory outside of given root_logdir, dropping given root_logdir for event file in /root/seg_framework/MS-Mamba/output_dir/mslesseg/val_ft
[12:53:58.269857] number of params: 59620439
[12:53:58.270100] model: Vivim2D(
  (encoder): mamba_block(
    (downsample_layers): SegformerEncoder(
      (patch_embeddings): ModuleList(
        (0): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))
          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        )
        (1): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        )
        (2): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(128, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        )
        (3): SegformerOverlapPatchEmbeddings(
          (proj): Conv2d(320, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
      (block): ModuleList(
        (0): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): Identity()
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.003703703870996833)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=64, out_features=64, bias=True)
                (key): Linear(in_features=64, out_features=64, bias=True)
                (value): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(64, 64, kernel_size=(8, 8), stride=(8, 8))
                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=64, out_features=64, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.007407407741993666)
            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=256, out_features=64, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.011111111380159855)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.014814815483987331)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.018518518656492233)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=128, out_features=128, bias=True)
                (key): Linear(in_features=128, out_features=128, bias=True)
                (value): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(128, 128, kernel_size=(4, 4), stride=(4, 4))
                (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=128, out_features=128, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.02222222276031971)
            (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=512, out_features=128, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (2): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.025925926864147186)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.029629630967974663)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03333333507180214)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (3): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.03703703731298447)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (4): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04074074327945709)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (5): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.04444444552063942)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (6): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.048148151487112045)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (7): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.051851850003004074)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (8): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0555555559694767)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (9): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.05925925821065903)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (10): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06296296417713165)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (11): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.06666667014360428)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (12): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07037036865949631)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (13): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07407407462596893)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (14): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.07777778059244156)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (15): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08148147910833359)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (16): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08518518507480621)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (17): SegformerLayer(
            (layer_norm_1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=320, out_features=320, bias=True)
                (key): Linear(in_features=320, out_features=320, bias=True)
                (value): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
                (sr): Conv2d(320, 320, kernel_size=(2, 2), stride=(2, 2))
                (layer_norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=320, out_features=320, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.08888889104127884)
            (layer_norm_2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1280)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=1280, out_features=320, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (3): ModuleList(
          (0): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.09259259700775146)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (1): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.0962962955236435)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
          (2): SegformerLayer(
            (layer_norm_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (attention): SegformerAttention(
              (self): SegformerEfficientSelfAttention(
                (query): Linear(in_features=512, out_features=512, bias=True)
                (key): Linear(in_features=512, out_features=512, bias=True)
                (value): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
              (output): SegformerSelfOutput(
                (dense): Linear(in_features=512, out_features=512, bias=True)
                (dropout): Dropout(p=0.0, inplace=False)
              )
            )
            (drop_path): SegformerDropPath(p=0.10000000149011612)
            (layer_norm_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): SegformerMixFFN(
              (dense1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): SegformerDWConv(
                (dwconv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048)
              )
              (intermediate_act_fn): GELUActivation()
              (dense2): Linear(in_features=2048, out_features=512, bias=True)
              (dropout): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (layer_norm): ModuleList(
        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
        (3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
    )
    (stages): ModuleList(
      (0): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=64, out_features=256, bias=False)
              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (act): SiLU()
              (x_proj): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_b): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_b): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_b): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_s): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_s): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_s): Linear(in_features=4, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=64, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=256, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=64, out_features=256, bias=False)
              (conv1d): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (act): SiLU()
              (x_proj): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_b): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_b): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_b): Linear(in_features=4, out_features=128, bias=True)
              (conv1d_s): Conv1d(128, 128, kernel_size=(4,), stride=(1,), padding=(3,), groups=128)
              (x_proj_s): Linear(in_features=128, out_features=36, bias=False)
              (dt_proj_s): Linear(in_features=4, out_features=128, bias=True)
              (out_proj): Linear(in_features=128, out_features=64, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=64, out_features=256, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=256)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=256, out_features=64, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (1): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=128, out_features=512, bias=False)
              (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (act): SiLU()
              (x_proj): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_b): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_b): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_b): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_s): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_s): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_s): Linear(in_features=8, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=128, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=128, out_features=512, bias=False)
              (conv1d): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (act): SiLU()
              (x_proj): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_b): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_b): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_b): Linear(in_features=8, out_features=256, bias=True)
              (conv1d_s): Conv1d(256, 256, kernel_size=(4,), stride=(1,), padding=(3,), groups=256)
              (x_proj_s): Linear(in_features=256, out_features=40, bias=False)
              (dt_proj_s): Linear(in_features=8, out_features=256, bias=True)
              (out_proj): Linear(in_features=256, out_features=128, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=128, out_features=512, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=512)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=512, out_features=128, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (2): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=320, out_features=1280, bias=False)
              (conv1d): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (act): SiLU()
              (x_proj): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_b): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_b): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_b): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_s): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_s): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_s): Linear(in_features=20, out_features=640, bias=True)
              (out_proj): Linear(in_features=640, out_features=320, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(1280, 1280, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=320, out_features=1280, bias=False)
              (conv1d): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (act): SiLU()
              (x_proj): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_b): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_b): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_b): Linear(in_features=20, out_features=640, bias=True)
              (conv1d_s): Conv1d(640, 640, kernel_size=(4,), stride=(1,), padding=(3,), groups=640)
              (x_proj_s): Linear(in_features=640, out_features=52, bias=False)
              (dt_proj_s): Linear(in_features=20, out_features=640, bias=True)
              (out_proj): Linear(in_features=640, out_features=320, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=320, out_features=1280, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(1280, 1280, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=1280)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1280, out_features=320, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
      (3): Sequential(
        (0): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=512, out_features=2048, bias=False)
              (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (act): SiLU()
              (x_proj): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_b): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_b): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_b): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_s): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_s): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_s): Linear(in_features=32, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=512, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
        (1): Sequential(
          (0): MambaLayer(
            (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mamba): Mamba(
              (in_proj): Linear(in_features=512, out_features=2048, bias=False)
              (conv1d): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (act): SiLU()
              (x_proj): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_b): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_b): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_b): Linear(in_features=32, out_features=1024, bias=True)
              (conv1d_s): Conv1d(1024, 1024, kernel_size=(4,), stride=(1,), padding=(3,), groups=1024)
              (x_proj_s): Linear(in_features=1024, out_features=64, bias=False)
              (dt_proj_s): Linear(in_features=32, out_features=1024, bias=True)
              (out_proj): Linear(in_features=1024, out_features=512, bias=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (dwconv): DWConv(
                (dwconv): Conv3d(2048, 2048, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), groups=2048)
              )
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
          )
        )
      )
    )
  )
  (decoder): SegformerDecodeHead(
    (linear_c): ModuleList(
      (0): SegformerMLP(
        (proj): Linear(in_features=64, out_features=768, bias=True)
      )
      (1): SegformerMLP(
        (proj): Linear(in_features=128, out_features=768, bias=True)
      )
      (2): SegformerMLP(
        (proj): Linear(in_features=320, out_features=768, bias=True)
      )
      (3): SegformerMLP(
        (proj): Linear(in_features=512, out_features=768, bias=True)
      )
    )
    (linear_fuse): Conv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (batch_norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (activation): ReLU()
    (dropout): Dropout(p=0.1, inplace=False)
    (classifier): Conv2d(768, 150, kernel_size=(1, 1), stride=(1, 1))
  )
  (out): Conv2d(768, 1, kernel_size=(1, 1), stride=(1, 1))
)
[12:53:58.273129] base lr: 1.00e-03
[12:53:58.273190] actual lr: 1.25e-04
[12:53:58.273245] accumulate grad iterations: 1
[12:53:58.273296] effective batch size: 32
[12:53:58.274720] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.000125
    maximize: False
    weight_decay: 0.01
)
[12:53:58.276813] Start training for 50 epochs
[12:53:58.276904] Number of samples in train dataloader:  345
[12:53:58.278607] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
/root/anaconda3/envs/vivim/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.
  warnings.warn(warning.format(ret))
[12:54:08.291555] Epoch: [0]  [  0/345]  eta: 0:57:34  lr: 0.000000  loss: 1.7515 (1.7515)  time: 10.0119  data: 0.4884  max mem: 15824
[12:54:20.300441] Epoch: [0]  [ 20/345]  eta: 0:05:40  lr: 0.000000  loss: 1.7539 (1.7551)  time: 0.6004  data: 0.0001  max mem: 15824
[12:54:32.313081] Epoch: [0]  [ 40/345]  eta: 0:04:13  lr: 0.000001  loss: 1.7350 (1.7464)  time: 0.6006  data: 0.0001  max mem: 15824
[12:54:44.394725] Epoch: [0]  [ 60/345]  eta: 0:03:35  lr: 0.000001  loss: 1.7284 (1.7421)  time: 0.6040  data: 0.0001  max mem: 15824
[12:54:56.542495] Epoch: [0]  [ 80/345]  eta: 0:03:10  lr: 0.000001  loss: 1.7253 (1.7384)  time: 0.6073  data: 0.0001  max mem: 15824
[12:55:08.869011] Epoch: [0]  [100/345]  eta: 0:02:51  lr: 0.000002  loss: 1.7088 (1.7327)  time: 0.6163  data: 0.0001  max mem: 15824
[12:55:21.100848] Epoch: [0]  [120/345]  eta: 0:02:33  lr: 0.000002  loss: 1.6910 (1.7256)  time: 0.6115  data: 0.0001  max mem: 15824
[12:55:33.397965] Epoch: [0]  [140/345]  eta: 0:02:18  lr: 0.000003  loss: 1.6640 (1.7173)  time: 0.6148  data: 0.0001  max mem: 15824
[12:55:45.717015] Epoch: [0]  [160/345]  eta: 0:02:03  lr: 0.000003  loss: 1.6347 (1.7075)  time: 0.6159  data: 0.0001  max mem: 15824

[12:55:58.071018] Epoch: [0]  [180/345]  eta: 0:01:49  lr: 0.000003  loss: 1.6049 (1.6961)  time: 0.6177  data: 0.0001  max mem: 15824
[12:56:10.450573] Epoch: [0]  [200/345]  eta: 0:01:35  lr: 0.000004  loss: 1.5569 (1.6824)  time: 0.6189  data: 0.0001  max mem: 15824
[12:56:22.846882] Epoch: [0]  [220/345]  eta: 0:01:21  lr: 0.000004  loss: 1.5029 (1.6664)  time: 0.6198  data: 0.0001  max mem: 15824
[12:56:35.221234] Epoch: [0]  [240/345]  eta: 0:01:08  lr: 0.000004  loss: 1.4345 (1.6476)  time: 0.6187  data: 0.0001  max mem: 15824
[12:56:47.577542] Epoch: [0]  [260/345]  eta: 0:00:55  lr: 0.000005  loss: 1.3631 (1.6261)  time: 0.6178  data: 0.0001  max mem: 15824
[12:56:59.956766] Epoch: [0]  [280/345]  eta: 0:00:42  lr: 0.000005  loss: 1.2998 (1.6028)  time: 0.6189  data: 0.0001  max mem: 15824
[12:57:12.347620] Epoch: [0]  [300/345]  eta: 0:00:29  lr: 0.000005  loss: 1.2449 (1.5790)  time: 0.6195  data: 0.0001  max mem: 15824
[12:57:24.716572] Epoch: [0]  [320/345]  eta: 0:00:16  lr: 0.000006  loss: 1.2013 (1.5557)  time: 0.6184  data: 0.0001  max mem: 15824
[12:57:37.067014] Epoch: [0]  [340/345]  eta: 0:00:03  lr: 0.000006  loss: 1.1660 (1.5328)  time: 0.6175  data: 0.0001  max mem: 15824
[12:57:39.538428] Epoch: [0]  [344/345]  eta: 0:00:00  lr: 0.000006  loss: 1.1616 (1.5284)  time: 0.6175  data: 0.0001  max mem: 15824
[12:57:39.604970] Epoch: [0] Total time: 0:03:41 (0.6415 s / it)
[12:57:39.605437] Averaged stats: lr: 0.000006  loss: 1.1616 (1.5284)
[12:57:40.177715] Test:  [  0/345]  eta: 0:03:15  loss: 1.1551 (1.1551)  time: 0.5672  data: 0.3847  max mem: 15824
[12:57:41.969319] Test:  [ 10/345]  eta: 0:01:11  loss: 1.1545 (1.1536)  time: 0.2144  data: 0.0350  max mem: 15824
[12:57:43.768561] Test:  [ 20/345]  eta: 0:01:04  loss: 1.1546 (1.1541)  time: 0.1795  data: 0.0001  max mem: 15824
[12:57:45.573173] Test:  [ 30/345]  eta: 0:01:00  loss: 1.1550 (1.1546)  time: 0.1801  data: 0.0001  max mem: 15824
[12:57:47.374144] Test:  [ 40/345]  eta: 0:00:57  loss: 1.1554 (1.1546)  time: 0.1802  data: 0.0001  max mem: 15824
[12:57:49.178537] Test:  [ 50/345]  eta: 0:00:55  loss: 1.1544 (1.1545)  time: 0.1802  data: 0.0001  max mem: 15824
[12:57:50.989187] Test:  [ 60/345]  eta: 0:00:53  loss: 1.1544 (1.1544)  time: 0.1807  data: 0.0001  max mem: 15824
[12:57:52.803437] Test:  [ 70/345]  eta: 0:00:51  loss: 1.1528 (1.1543)  time: 0.1812  data: 0.0001  max mem: 15824
[12:57:54.622328] Test:  [ 80/345]  eta: 0:00:49  loss: 1.1525 (1.1542)  time: 0.1816  data: 0.0001  max mem: 15824
[12:57:56.443953] Test:  [ 90/345]  eta: 0:00:47  loss: 1.1532 (1.1541)  time: 0.1820  data: 0.0001  max mem: 15824
[12:57:58.271141] Test:  [100/345]  eta: 0:00:45  loss: 1.1539 (1.1542)  time: 0.1824  data: 0.0001  max mem: 15824
[12:58:00.098123] Test:  [110/345]  eta: 0:00:43  loss: 1.1539 (1.1542)  time: 0.1826  data: 0.0001  max mem: 15824
[12:58:01.928554] Test:  [120/345]  eta: 0:00:41  loss: 1.1545 (1.1543)  time: 0.1828  data: 0.0001  max mem: 15824
[12:58:03.763046] Test:  [130/345]  eta: 0:00:39  loss: 1.1540 (1.1542)  time: 0.1832  data: 0.0001  max mem: 15824
[12:58:05.602758] Test:  [140/345]  eta: 0:00:37  loss: 1.1533 (1.1542)  time: 0.1836  data: 0.0001  max mem: 15824
[12:58:07.443669] Test:  [150/345]  eta: 0:00:35  loss: 1.1531 (1.1541)  time: 0.1840  data: 0.0001  max mem: 15824
[12:58:09.287882] Test:  [160/345]  eta: 0:00:34  loss: 1.1516 (1.1540)  time: 0.1842  data: 0.0001  max mem: 15824
[12:58:11.135620] Test:  [170/345]  eta: 0:00:32  loss: 1.1527 (1.1540)  time: 0.1845  data: 0.0001  max mem: 15824
[12:58:12.987038] Test:  [180/345]  eta: 0:00:30  loss: 1.1532 (1.1540)  time: 0.1849  data: 0.0001  max mem: 15824
[12:58:14.841446] Test:  [190/345]  eta: 0:00:28  loss: 1.1530 (1.1540)  time: 0.1852  data: 0.0001  max mem: 15824
[12:58:16.700193] Test:  [200/345]  eta: 0:00:26  loss: 1.1529 (1.1539)  time: 0.1856  data: 0.0001  max mem: 15824
[12:58:18.961420] Test:  [210/345]  eta: 0:00:25  loss: 1.1531 (1.1539)  time: 0.2059  data: 0.0001  max mem: 15824
[12:58:20.839695] Test:  [220/345]  eta: 0:00:23  loss: 1.1532 (1.1539)  time: 0.2069  data: 0.0001  max mem: 15824
[12:58:22.865028] Test:  [230/345]  eta: 0:00:21  loss: 1.1535 (1.1539)  time: 0.1951  data: 0.0001  max mem: 15824
[12:58:24.738253] Test:  [240/345]  eta: 0:00:19  loss: 1.1531 (1.1538)  time: 0.1949  data: 0.0001  max mem: 15824
[12:58:26.806341] Test:  [250/345]  eta: 0:00:17  loss: 1.1530 (1.1538)  time: 0.1970  data: 0.0001  max mem: 15824
[12:58:28.876202] Test:  [260/345]  eta: 0:00:16  loss: 1.1542 (1.1538)  time: 0.2068  data: 0.0001  max mem: 15824
[12:58:30.916860] Test:  [270/345]  eta: 0:00:14  loss: 1.1532 (1.1538)  time: 0.2055  data: 0.0001  max mem: 15824
[12:58:32.845886] Test:  [280/345]  eta: 0:00:12  loss: 1.1537 (1.1539)  time: 0.1984  data: 0.0001  max mem: 15824
[12:58:34.936870] Test:  [290/345]  eta: 0:00:10  loss: 1.1538 (1.1539)  time: 0.2009  data: 0.0001  max mem: 15824
[12:58:37.104286] Test:  [300/345]  eta: 0:00:08  loss: 1.1540 (1.1539)  time: 0.2129  data: 0.0001  max mem: 15824
[12:58:39.194662] Test:  [310/345]  eta: 0:00:06  loss: 1.1549 (1.1540)  time: 0.2128  data: 0.0001  max mem: 15824
[12:58:41.261455] Test:  [320/345]  eta: 0:00:04  loss: 1.1553 (1.1540)  time: 0.2078  data: 0.0001  max mem: 15824
[12:58:43.363898] Test:  [330/345]  eta: 0:00:02  loss: 1.1544 (1.1540)  time: 0.2084  data: 0.0001  max mem: 15824
[12:58:45.311296] Test:  [340/345]  eta: 0:00:00  loss: 1.1538 (1.1541)  time: 0.2024  data: 0.0001  max mem: 15824
[12:58:46.362857] Test:  [344/345]  eta: 0:00:00  loss: 1.1540 (1.1541)  time: 0.2154  data: 0.0001  max mem: 15824
[12:58:46.437972] Test: Total time: 0:01:06 (0.1937 s / it)
[12:58:57.248540] Test:  [ 0/57]  eta: 0:00:31  loss: 1.1689 (1.1689)  time: 0.5579  data: 0.3757  max mem: 15824
[12:58:59.021902] Test:  [10/57]  eta: 0:00:09  loss: 1.1605 (1.1601)  time: 0.2119  data: 0.0342  max mem: 15824
[12:59:00.799311] Test:  [20/57]  eta: 0:00:07  loss: 1.1605 (1.1579)  time: 0.1775  data: 0.0001  max mem: 15824
[12:59:02.580280] Test:  [30/57]  eta: 0:00:05  loss: 1.1440 (1.1510)  time: 0.1779  data: 0.0001  max mem: 15824
[12:59:04.365717] Test:  [40/57]  eta: 0:00:03  loss: 1.1335 (1.1465)  time: 0.1783  data: 0.0001  max mem: 15824
[12:59:06.153660] Test:  [50/57]  eta: 0:00:01  loss: 1.1411 (1.1452)  time: 0.1786  data: 0.0001  max mem: 15824
[12:59:07.919145] Test:  [56/57]  eta: 0:00:00  loss: 1.1426 (1.1456)  time: 0.2133  data: 0.0000  max mem: 15824
[12:59:07.997868] Test: Total time: 0:00:11 (0.1984 s / it)
[12:59:09.748613] Dice score of the network on the train images: 0.000000, val images: 0.000000
[12:59:09.748824] saving best_dice_model_0 @ epoch 0
[12:59:10.473999] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[12:59:11.546346] Epoch: [1]  [  0/345]  eta: 0:06:09  lr: 0.000006  loss: 1.1476 (1.1476)  time: 1.0713  data: 0.4211  max mem: 15824
[12:59:23.831912] Epoch: [1]  [ 20/345]  eta: 0:03:26  lr: 0.000007  loss: 1.1294 (1.1303)  time: 0.6142  data: 0.0001  max mem: 15824
[12:59:36.136506] Epoch: [1]  [ 40/345]  eta: 0:03:10  lr: 0.000007  loss: 1.1066 (1.1192)  time: 0.6152  data: 0.0001  max mem: 15824
[12:59:48.591453] Epoch: [1]  [ 60/345]  eta: 0:02:58  lr: 0.000007  loss: 1.0897 (1.1097)  time: 0.6227  data: 0.0001  max mem: 15824
[13:00:00.939025] Epoch: [1]  [ 80/345]  eta: 0:02:45  lr: 0.000008  loss: 1.0741 (1.1012)  time: 0.6173  data: 0.0001  max mem: 15824
[13:00:13.301567] Epoch: [1]  [100/345]  eta: 0:02:32  lr: 0.000008  loss: 1.0618 (1.0932)  time: 0.6181  data: 0.0001  max mem: 15824
[13:00:25.646842] Epoch: [1]  [120/345]  eta: 0:02:19  lr: 0.000008  loss: 1.0472 (1.0861)  time: 0.6172  data: 0.0001  max mem: 15824
[13:00:38.031367] Epoch: [1]  [140/345]  eta: 0:02:07  lr: 0.000009  loss: 1.0338 (1.0789)  time: 0.6192  data: 0.0001  max mem: 15824

[13:00:50.415810] Epoch: [1]  [160/345]  eta: 0:01:54  lr: 0.000009  loss: 1.0163 (1.0714)  time: 0.6192  data: 0.0001  max mem: 15824
[13:01:02.771923] Epoch: [1]  [180/345]  eta: 0:01:42  lr: 0.000010  loss: 1.0105 (1.0643)  time: 0.6178  data: 0.0001  max mem: 15824
[13:01:15.137473] Epoch: [1]  [200/345]  eta: 0:01:29  lr: 0.000010  loss: 0.9967 (1.0574)  time: 0.6182  data: 0.0001  max mem: 15824
[13:01:27.509932] Epoch: [1]  [220/345]  eta: 0:01:17  lr: 0.000010  loss: 0.9832 (1.0511)  time: 0.6186  data: 0.0001  max mem: 15824
[13:01:39.868993] Epoch: [1]  [240/345]  eta: 0:01:05  lr: 0.000011  loss: 0.9799 (1.0455)  time: 0.6179  data: 0.0001  max mem: 15824
[13:01:52.225184] Epoch: [1]  [260/345]  eta: 0:00:52  lr: 0.000011  loss: 0.9699 (1.0398)  time: 0.6178  data: 0.0001  max mem: 15824
[13:02:04.577608] Epoch: [1]  [280/345]  eta: 0:00:40  lr: 0.000011  loss: 0.9648 (1.0342)  time: 0.6176  data: 0.0001  max mem: 15824
[13:02:16.928957] Epoch: [1]  [300/345]  eta: 0:00:27  lr: 0.000012  loss: 0.9598 (1.0296)  time: 0.6175  data: 0.0001  max mem: 15824
[13:02:29.279148] Epoch: [1]  [320/345]  eta: 0:00:15  lr: 0.000012  loss: 0.9409 (1.0242)  time: 0.6175  data: 0.0001  max mem: 15824
[13:02:41.613495] Epoch: [1]  [340/345]  eta: 0:00:03  lr: 0.000012  loss: 0.9405 (1.0194)  time: 0.6167  data: 0.0001  max mem: 15824
[13:02:44.079680] Epoch: [1]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 0.9424 (1.0186)  time: 0.6167  data: 0.0001  max mem: 15824
[13:02:44.150321] Epoch: [1] Total time: 0:03:33 (0.6194 s / it)
[13:02:44.150976] Averaged stats: lr: 0.000012  loss: 0.9424 (1.0186)
[13:02:44.755398] Test:  [  0/345]  eta: 0:03:26  loss: 0.9474 (0.9474)  time: 0.5988  data: 0.4153  max mem: 15824
[13:02:46.548713] Test:  [ 10/345]  eta: 0:01:12  loss: 0.9163 (0.9205)  time: 0.2174  data: 0.0379  max mem: 15824
[13:02:48.346062] Test:  [ 20/345]  eta: 0:01:04  loss: 0.9284 (0.9325)  time: 0.1795  data: 0.0001  max mem: 15824
[13:02:50.144038] Test:  [ 30/345]  eta: 0:01:00  loss: 0.9256 (0.9302)  time: 0.1797  data: 0.0001  max mem: 15824
[13:02:51.945183] Test:  [ 40/345]  eta: 0:00:57  loss: 0.9208 (0.9314)  time: 0.1799  data: 0.0001  max mem: 15824
[13:02:53.753793] Test:  [ 50/345]  eta: 0:00:55  loss: 0.9340 (0.9330)  time: 0.1804  data: 0.0001  max mem: 15824
[13:02:55.558725] Test:  [ 60/345]  eta: 0:00:53  loss: 0.9364 (0.9323)  time: 0.1806  data: 0.0001  max mem: 15824
[13:02:57.370822] Test:  [ 70/345]  eta: 0:00:51  loss: 0.9208 (0.9309)  time: 0.1808  data: 0.0001  max mem: 15824
[13:02:59.185846] Test:  [ 80/345]  eta: 0:00:49  loss: 0.9189 (0.9300)  time: 0.1813  data: 0.0001  max mem: 15824
[13:03:01.003428] Test:  [ 90/345]  eta: 0:00:47  loss: 0.9333 (0.9298)  time: 0.1816  data: 0.0001  max mem: 15824
[13:03:02.828059] Test:  [100/345]  eta: 0:00:45  loss: 0.9213 (0.9289)  time: 0.1820  data: 0.0001  max mem: 15824
[13:03:04.652594] Test:  [110/345]  eta: 0:00:43  loss: 0.9213 (0.9288)  time: 0.1824  data: 0.0001  max mem: 15824
[13:03:06.482920] Test:  [120/345]  eta: 0:00:41  loss: 0.9301 (0.9290)  time: 0.1827  data: 0.0001  max mem: 15824
[13:03:08.314528] Test:  [130/345]  eta: 0:00:39  loss: 0.9205 (0.9278)  time: 0.1830  data: 0.0001  max mem: 15824
[13:03:10.149527] Test:  [140/345]  eta: 0:00:37  loss: 0.9205 (0.9281)  time: 0.1833  data: 0.0001  max mem: 15824
[13:03:11.987674] Test:  [150/345]  eta: 0:00:35  loss: 0.9325 (0.9289)  time: 0.1836  data: 0.0001  max mem: 15824
[13:03:13.830411] Test:  [160/345]  eta: 0:00:34  loss: 0.9335 (0.9284)  time: 0.1840  data: 0.0001  max mem: 15824
[13:03:15.674562] Test:  [170/345]  eta: 0:00:32  loss: 0.9216 (0.9279)  time: 0.1843  data: 0.0001  max mem: 15824
[13:03:17.523236] Test:  [180/345]  eta: 0:00:30  loss: 0.9250 (0.9281)  time: 0.1846  data: 0.0001  max mem: 15824
[13:03:19.376197] Test:  [190/345]  eta: 0:00:28  loss: 0.9208 (0.9276)  time: 0.1850  data: 0.0001  max mem: 15824
[13:03:21.233805] Test:  [200/345]  eta: 0:00:26  loss: 0.9318 (0.9284)  time: 0.1855  data: 0.0001  max mem: 15824
[13:03:23.093399] Test:  [210/345]  eta: 0:00:24  loss: 0.9385 (0.9285)  time: 0.1858  data: 0.0001  max mem: 15824
[13:03:25.325743] Test:  [220/345]  eta: 0:00:23  loss: 0.9302 (0.9284)  time: 0.2045  data: 0.0001  max mem: 15824
[13:03:27.189040] Test:  [230/345]  eta: 0:00:21  loss: 0.9132 (0.9277)  time: 0.2047  data: 0.0001  max mem: 15824
[13:03:29.241681] Test:  [240/345]  eta: 0:00:19  loss: 0.9124 (0.9277)  time: 0.1957  data: 0.0001  max mem: 15824
[13:03:31.128504] Test:  [250/345]  eta: 0:00:17  loss: 0.9261 (0.9278)  time: 0.1969  data: 0.0001  max mem: 15824
[13:03:33.153787] Test:  [260/345]  eta: 0:00:15  loss: 0.9321 (0.9283)  time: 0.1955  data: 0.0001  max mem: 15824
[13:03:35.065546] Test:  [270/345]  eta: 0:00:14  loss: 0.9448 (0.9286)  time: 0.1968  data: 0.0001  max mem: 15824
[13:03:37.099347] Test:  [280/345]  eta: 0:00:12  loss: 0.9338 (0.9284)  time: 0.1972  data: 0.0001  max mem: 15824
[13:03:39.013826] Test:  [290/345]  eta: 0:00:10  loss: 0.9204 (0.9283)  time: 0.1973  data: 0.0001  max mem: 15824
[13:03:41.103699] Test:  [300/345]  eta: 0:00:08  loss: 0.9197 (0.9284)  time: 0.2002  data: 0.0001  max mem: 15824
[13:03:43.008765] Test:  [310/345]  eta: 0:00:06  loss: 0.9355 (0.9286)  time: 0.1997  data: 0.0001  max mem: 15824
[13:03:45.176973] Test:  [320/345]  eta: 0:00:04  loss: 0.9212 (0.9282)  time: 0.2036  data: 0.0001  max mem: 15824
[13:03:47.075288] Test:  [330/345]  eta: 0:00:02  loss: 0.9212 (0.9282)  time: 0.2033  data: 0.0001  max mem: 15824
[13:03:49.242744] Test:  [340/345]  eta: 0:00:00  loss: 0.9377 (0.9286)  time: 0.2032  data: 0.0001  max mem: 15824
[13:03:50.002079] Test:  [344/345]  eta: 0:00:00  loss: 0.9341 (0.9286)  time: 0.2032  data: 0.0001  max mem: 15824
[13:03:50.066380] Test: Total time: 0:01:05 (0.1910 s / it)
[13:04:00.620961] Test:  [ 0/57]  eta: 0:00:30  loss: 0.9982 (0.9982)  time: 0.5354  data: 0.3554  max mem: 15824
[13:04:02.386213] Test:  [10/57]  eta: 0:00:09  loss: 0.9593 (0.9729)  time: 0.2091  data: 0.0324  max mem: 15824
[13:04:04.161854] Test:  [20/57]  eta: 0:00:07  loss: 0.9661 (0.9673)  time: 0.1770  data: 0.0001  max mem: 15824
[13:04:05.939921] Test:  [30/57]  eta: 0:00:05  loss: 0.8971 (0.9125)  time: 0.1776  data: 0.0001  max mem: 15824
[13:04:07.722152] Test:  [40/57]  eta: 0:00:03  loss: 0.7672 (0.8753)  time: 0.1780  data: 0.0001  max mem: 15824
[13:04:09.505471] Test:  [50/57]  eta: 0:00:01  loss: 0.7718 (0.8669)  time: 0.1782  data: 0.0001  max mem: 15824
[13:04:10.477624] Test:  [56/57]  eta: 0:00:00  loss: 0.8665 (0.8746)  time: 0.1734  data: 0.0000  max mem: 15824
[13:04:10.543898] Test: Total time: 0:00:10 (0.1835 s / it)
[13:04:12.293788] Dice score of the network on the train images: 0.413709, val images: 0.525104
[13:04:12.294013] saving best_prec_model_0 @ epoch 1
[13:04:13.006572] saving best_rec_model_0 @ epoch 1
[13:04:13.688107] saving best_dice_model_0 @ epoch 1
[13:04:15.074857] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:04:16.116698] Epoch: [2]  [  0/345]  eta: 0:05:58  lr: 0.000013  loss: 0.9240 (0.9240)  time: 1.0406  data: 0.4197  max mem: 15824
[13:04:28.389160] Epoch: [2]  [ 20/345]  eta: 0:03:26  lr: 0.000013  loss: 0.9148 (0.9179)  time: 0.6136  data: 0.0001  max mem: 15824

[13:04:40.713456] Epoch: [2]  [ 40/345]  eta: 0:03:10  lr: 0.000013  loss: 0.9184 (0.9183)  time: 0.6162  data: 0.0001  max mem: 15824
[13:04:53.062524] Epoch: [2]  [ 60/345]  eta: 0:02:57  lr: 0.000014  loss: 0.9143 (0.9170)  time: 0.6174  data: 0.0001  max mem: 15824
[13:05:05.458004] Epoch: [2]  [ 80/345]  eta: 0:02:44  lr: 0.000014  loss: 0.9165 (0.9159)  time: 0.6197  data: 0.0001  max mem: 15824
[13:05:17.873710] Epoch: [2]  [100/345]  eta: 0:02:32  lr: 0.000014  loss: 0.8992 (0.9121)  time: 0.6207  data: 0.0001  max mem: 15824
[13:05:30.295761] Epoch: [2]  [120/345]  eta: 0:02:19  lr: 0.000015  loss: 0.8817 (0.9082)  time: 0.6211  data: 0.0001  max mem: 15824
[13:05:42.703689] Epoch: [2]  [140/345]  eta: 0:02:07  lr: 0.000015  loss: 0.8787 (0.9045)  time: 0.6204  data: 0.0001  max mem: 15824
[13:05:55.104438] Epoch: [2]  [160/345]  eta: 0:01:54  lr: 0.000015  loss: 0.8665 (0.9001)  time: 0.6200  data: 0.0001  max mem: 15824
[13:06:07.524718] Epoch: [2]  [180/345]  eta: 0:01:42  lr: 0.000016  loss: 0.8565 (0.8957)  time: 0.6210  data: 0.0001  max mem: 15824
[13:06:19.912907] Epoch: [2]  [200/345]  eta: 0:01:30  lr: 0.000016  loss: 0.8544 (0.8914)  time: 0.6194  data: 0.0001  max mem: 15824
[13:06:32.319779] Epoch: [2]  [220/345]  eta: 0:01:17  lr: 0.000016  loss: 0.8354 (0.8866)  time: 0.6202  data: 0.0001  max mem: 15824
[13:06:44.731741] Epoch: [2]  [240/345]  eta: 0:01:05  lr: 0.000017  loss: 0.8313 (0.8821)  time: 0.6206  data: 0.0001  max mem: 15824
[13:06:57.148623] Epoch: [2]  [260/345]  eta: 0:00:52  lr: 0.000017  loss: 0.8184 (0.8774)  time: 0.6208  data: 0.0001  max mem: 15824
[13:07:09.541320] Epoch: [2]  [280/345]  eta: 0:00:40  lr: 0.000018  loss: 0.8146 (0.8732)  time: 0.6196  data: 0.0001  max mem: 15824
[13:07:21.950599] Epoch: [2]  [300/345]  eta: 0:00:27  lr: 0.000018  loss: 0.8087 (0.8693)  time: 0.6204  data: 0.0001  max mem: 15824
[13:07:34.353349] Epoch: [2]  [320/345]  eta: 0:00:15  lr: 0.000018  loss: 0.7897 (0.8648)  time: 0.6201  data: 0.0001  max mem: 15824
[13:07:46.744180] Epoch: [2]  [340/345]  eta: 0:00:03  lr: 0.000019  loss: 0.7853 (0.8602)  time: 0.6195  data: 0.0001  max mem: 15824
[13:07:49.223669] Epoch: [2]  [344/345]  eta: 0:00:00  lr: 0.000019  loss: 0.7853 (0.8592)  time: 0.6193  data: 0.0001  max mem: 15824
[13:07:49.298982] Epoch: [2] Total time: 0:03:34 (0.6209 s / it)
[13:07:49.299330] Averaged stats: lr: 0.000019  loss: 0.7853 (0.8592)
[13:07:49.870489] Test:  [  0/345]  eta: 0:03:15  loss: 0.8558 (0.8558)  time: 0.5656  data: 0.3835  max mem: 15824
[13:07:51.662931] Test:  [ 10/345]  eta: 0:01:11  loss: 0.8496 (0.8315)  time: 0.2143  data: 0.0350  max mem: 15824
[13:07:53.455951] Test:  [ 20/345]  eta: 0:01:04  loss: 0.8228 (0.8221)  time: 0.1792  data: 0.0001  max mem: 15824
[13:07:55.249881] Test:  [ 30/345]  eta: 0:01:00  loss: 0.8043 (0.8185)  time: 0.1793  data: 0.0001  max mem: 15824
[13:07:57.050568] Test:  [ 40/345]  eta: 0:00:57  loss: 0.7859 (0.8118)  time: 0.1797  data: 0.0001  max mem: 15824
[13:07:58.853080] Test:  [ 50/345]  eta: 0:00:55  loss: 0.7824 (0.8062)  time: 0.1801  data: 0.0001  max mem: 15824
[13:08:00.655895] Test:  [ 60/345]  eta: 0:00:53  loss: 0.7897 (0.8066)  time: 0.1802  data: 0.0001  max mem: 15824
[13:08:02.463025] Test:  [ 70/345]  eta: 0:00:50  loss: 0.8004 (0.8062)  time: 0.1804  data: 0.0001  max mem: 15824
[13:08:04.275115] Test:  [ 80/345]  eta: 0:00:48  loss: 0.8004 (0.8066)  time: 0.1809  data: 0.0001  max mem: 15824
[13:08:06.092065] Test:  [ 90/345]  eta: 0:00:47  loss: 0.8169 (0.8063)  time: 0.1814  data: 0.0001  max mem: 15824
[13:08:07.911165] Test:  [100/345]  eta: 0:00:45  loss: 0.8136 (0.8072)  time: 0.1817  data: 0.0001  max mem: 15824
[13:08:09.735443] Test:  [110/345]  eta: 0:00:43  loss: 0.8056 (0.8080)  time: 0.1821  data: 0.0001  max mem: 15824
[13:08:11.561995] Test:  [120/345]  eta: 0:00:41  loss: 0.7937 (0.8049)  time: 0.1825  data: 0.0001  max mem: 15824
[13:08:13.391999] Test:  [130/345]  eta: 0:00:39  loss: 0.7844 (0.8057)  time: 0.1828  data: 0.0001  max mem: 15824
[13:08:15.224590] Test:  [140/345]  eta: 0:00:37  loss: 0.8185 (0.8065)  time: 0.1831  data: 0.0001  max mem: 15824
[13:08:17.060736] Test:  [150/345]  eta: 0:00:35  loss: 0.8145 (0.8071)  time: 0.1834  data: 0.0001  max mem: 15824
[13:08:18.901495] Test:  [160/345]  eta: 0:00:33  loss: 0.8069 (0.8075)  time: 0.1838  data: 0.0001  max mem: 15824
[13:08:20.745705] Test:  [170/345]  eta: 0:00:32  loss: 0.8166 (0.8078)  time: 0.1842  data: 0.0001  max mem: 15824
[13:08:22.593995] Test:  [180/345]  eta: 0:00:30  loss: 0.8013 (0.8066)  time: 0.1846  data: 0.0001  max mem: 15824
[13:08:24.444260] Test:  [190/345]  eta: 0:00:28  loss: 0.7886 (0.8068)  time: 0.1849  data: 0.0001  max mem: 15824
[13:08:26.297980] Test:  [200/345]  eta: 0:00:26  loss: 0.7906 (0.8063)  time: 0.1851  data: 0.0001  max mem: 15824
[13:08:28.158699] Test:  [210/345]  eta: 0:00:24  loss: 0.7906 (0.8063)  time: 0.1857  data: 0.0001  max mem: 15824
[13:08:30.018514] Test:  [220/345]  eta: 0:00:23  loss: 0.7956 (0.8052)  time: 0.1860  data: 0.0001  max mem: 15824
[13:08:31.880877] Test:  [230/345]  eta: 0:00:21  loss: 0.8014 (0.8055)  time: 0.1860  data: 0.0001  max mem: 15824
[13:08:33.751593] Test:  [240/345]  eta: 0:00:19  loss: 0.8046 (0.8051)  time: 0.1866  data: 0.0001  max mem: 15824
[13:08:35.622039] Test:  [250/345]  eta: 0:00:17  loss: 0.7950 (0.8048)  time: 0.1870  data: 0.0001  max mem: 15824
[13:08:37.497282] Test:  [260/345]  eta: 0:00:15  loss: 0.8168 (0.8059)  time: 0.1872  data: 0.0001  max mem: 15824
[13:08:39.373663] Test:  [270/345]  eta: 0:00:13  loss: 0.8111 (0.8050)  time: 0.1875  data: 0.0001  max mem: 15824
[13:08:41.255640] Test:  [280/345]  eta: 0:00:12  loss: 0.7966 (0.8052)  time: 0.1879  data: 0.0001  max mem: 15824
[13:08:43.140929] Test:  [290/345]  eta: 0:00:10  loss: 0.8124 (0.8061)  time: 0.1883  data: 0.0001  max mem: 15824
[13:08:45.030147] Test:  [300/345]  eta: 0:00:08  loss: 0.8008 (0.8056)  time: 0.1887  data: 0.0001  max mem: 15824
[13:08:46.922490] Test:  [310/345]  eta: 0:00:06  loss: 0.7850 (0.8054)  time: 0.1890  data: 0.0001  max mem: 15824
[13:08:48.819241] Test:  [320/345]  eta: 0:00:04  loss: 0.7937 (0.8051)  time: 0.1894  data: 0.0001  max mem: 15824
[13:08:50.721170] Test:  [330/345]  eta: 0:00:02  loss: 0.8085 (0.8058)  time: 0.1899  data: 0.0001  max mem: 15824
[13:08:52.621942] Test:  [340/345]  eta: 0:00:00  loss: 0.8094 (0.8057)  time: 0.1901  data: 0.0001  max mem: 15824
[13:08:53.383578] Test:  [344/345]  eta: 0:00:00  loss: 0.8094 (0.8058)  time: 0.1901  data: 0.0001  max mem: 15824
[13:08:53.456059] Test: Total time: 0:01:04 (0.1859 s / it)
[13:09:03.866464] Test:  [ 0/57]  eta: 0:00:30  loss: 0.8937 (0.8937)  time: 0.5311  data: 0.3508  max mem: 15824
[13:09:05.638132] Test:  [10/57]  eta: 0:00:09  loss: 0.8491 (0.8629)  time: 0.2092  data: 0.0320  max mem: 15824
[13:09:07.414317] Test:  [20/57]  eta: 0:00:07  loss: 0.8144 (0.8497)  time: 0.1773  data: 0.0001  max mem: 15824
[13:09:09.195071] Test:  [30/57]  eta: 0:00:05  loss: 0.7938 (0.7804)  time: 0.1778  data: 0.0001  max mem: 15824
[13:09:10.979717] Test:  [40/57]  eta: 0:00:03  loss: 0.6023 (0.7353)  time: 0.1782  data: 0.0001  max mem: 15824
[13:09:12.763798] Test:  [50/57]  eta: 0:00:01  loss: 0.6396 (0.7237)  time: 0.1784  data: 0.0001  max mem: 15824
[13:09:13.738157] Test:  [56/57]  eta: 0:00:00  loss: 0.7296 (0.7318)  time: 0.1736  data: 0.0001  max mem: 15824
[13:09:13.815604] Test: Total time: 0:00:10 (0.1839 s / it)
[13:09:15.531097] Dice score of the network on the train images: 0.539333, val images: 0.661012
[13:09:15.531329] saving best_prec_model_0 @ epoch 2
[13:09:16.581053] saving best_rec_model_0 @ epoch 2
[13:09:17.880186] saving best_dice_model_0 @ epoch 2
[13:09:19.050508] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:09:20.085939] Epoch: [3]  [  0/345]  eta: 0:05:56  lr: 0.000019  loss: 0.7458 (0.7458)  time: 1.0342  data: 0.4134  max mem: 15824
[13:09:32.412904] Epoch: [3]  [ 20/345]  eta: 0:03:26  lr: 0.000019  loss: 0.7634 (0.7688)  time: 0.6163  data: 0.0001  max mem: 15824
[13:09:44.732188] Epoch: [3]  [ 40/345]  eta: 0:03:11  lr: 0.000019  loss: 0.7602 (0.7649)  time: 0.6159  data: 0.0001  max mem: 15824
[13:09:57.080794] Epoch: [3]  [ 60/345]  eta: 0:02:57  lr: 0.000020  loss: 0.7370 (0.7591)  time: 0.6174  data: 0.0001  max mem: 15824
[13:10:09.478020] Epoch: [3]  [ 80/345]  eta: 0:02:44  lr: 0.000020  loss: 0.7492 (0.7574)  time: 0.6198  data: 0.0001  max mem: 15824
[13:10:21.875111] Epoch: [3]  [100/345]  eta: 0:02:32  lr: 0.000021  loss: 0.7525 (0.7559)  time: 0.6198  data: 0.0001  max mem: 15824
[13:10:34.291768] Epoch: [3]  [120/345]  eta: 0:02:19  lr: 0.000021  loss: 0.7220 (0.7505)  time: 0.6208  data: 0.0001  max mem: 15824
[13:10:46.713871] Epoch: [3]  [140/345]  eta: 0:02:07  lr: 0.000021  loss: 0.7056 (0.7449)  time: 0.6211  data: 0.0001  max mem: 15824
[13:10:59.129369] Epoch: [3]  [160/345]  eta: 0:01:54  lr: 0.000022  loss: 0.6906 (0.7387)  time: 0.6207  data: 0.0001  max mem: 15824
[13:11:11.545969] Epoch: [3]  [180/345]  eta: 0:01:42  lr: 0.000022  loss: 0.6897 (0.7335)  time: 0.6208  data: 0.0001  max mem: 15824
[13:11:23.956370] Epoch: [3]  [200/345]  eta: 0:01:30  lr: 0.000022  loss: 0.6786 (0.7285)  time: 0.6205  data: 0.0001  max mem: 15824
[13:11:36.374446] Epoch: [3]  [220/345]  eta: 0:01:17  lr: 0.000023  loss: 0.6758 (0.7244)  time: 0.6209  data: 0.0001  max mem: 15824
[13:11:48.789150] Epoch: [3]  [240/345]  eta: 0:01:05  lr: 0.000023  loss: 0.6824 (0.7209)  time: 0.6207  data: 0.0001  max mem: 15824
[13:12:01.188197] Epoch: [3]  [260/345]  eta: 0:00:52  lr: 0.000023  loss: 0.6655 (0.7164)  time: 0.6199  data: 0.0001  max mem: 15824
[13:12:13.599608] Epoch: [3]  [280/345]  eta: 0:00:40  lr: 0.000024  loss: 0.6538 (0.7129)  time: 0.6205  data: 0.0001  max mem: 15824
[13:12:26.012312] Epoch: [3]  [300/345]  eta: 0:00:27  lr: 0.000024  loss: 0.6394 (0.7082)  time: 0.6206  data: 0.0001  max mem: 15824
[13:12:38.412132] Epoch: [3]  [320/345]  eta: 0:00:15  lr: 0.000025  loss: 0.6369 (0.7037)  time: 0.6199  data: 0.0001  max mem: 15824
[13:12:50.803243] Epoch: [3]  [340/345]  eta: 0:00:03  lr: 0.000025  loss: 0.6233 (0.6989)  time: 0.6195  data: 0.0001  max mem: 15824
[13:12:53.282572] Epoch: [3]  [344/345]  eta: 0:00:00  lr: 0.000025  loss: 0.6233 (0.6981)  time: 0.6195  data: 0.0001  max mem: 15824
[13:12:53.351843] Epoch: [3] Total time: 0:03:34 (0.6212 s / it)
[13:12:53.352163] Averaged stats: lr: 0.000025  loss: 0.6233 (0.6981)
[13:12:53.953946] Test:  [  0/345]  eta: 0:03:25  loss: 0.6240 (0.6240)  time: 0.5964  data: 0.4149  max mem: 15824
[13:12:55.743167] Test:  [ 10/345]  eta: 0:01:12  loss: 0.5772 (0.5800)  time: 0.2168  data: 0.0378  max mem: 15824
[13:12:57.532533] Test:  [ 20/345]  eta: 0:01:04  loss: 0.5850 (0.5870)  time: 0.1789  data: 0.0001  max mem: 15824
[13:12:59.328976] Test:  [ 30/345]  eta: 0:01:00  loss: 0.5905 (0.5844)  time: 0.1792  data: 0.0001  max mem: 15824
[13:13:01.130293] Test:  [ 40/345]  eta: 0:00:57  loss: 0.5943 (0.5871)  time: 0.1798  data: 0.0001  max mem: 15824
[13:13:02.930758] Test:  [ 50/345]  eta: 0:00:55  loss: 0.5943 (0.5877)  time: 0.1800  data: 0.0001  max mem: 15824
[13:13:04.735767] Test:  [ 60/345]  eta: 0:00:53  loss: 0.5838 (0.5877)  time: 0.1802  data: 0.0001  max mem: 15824
[13:13:06.541450] Test:  [ 70/345]  eta: 0:00:51  loss: 0.6061 (0.5931)  time: 0.1805  data: 0.0001  max mem: 15824
[13:13:08.355336] Test:  [ 80/345]  eta: 0:00:49  loss: 0.6189 (0.5930)  time: 0.1809  data: 0.0001  max mem: 15824
[13:13:10.172092] Test:  [ 90/345]  eta: 0:00:47  loss: 0.6074 (0.5951)  time: 0.1815  data: 0.0001  max mem: 15824
[13:13:11.991218] Test:  [100/345]  eta: 0:00:45  loss: 0.5976 (0.5946)  time: 0.1817  data: 0.0001  max mem: 15824
[13:13:13.814587] Test:  [110/345]  eta: 0:00:43  loss: 0.5896 (0.5944)  time: 0.1821  data: 0.0001  max mem: 15824
[13:13:15.640435] Test:  [120/345]  eta: 0:00:41  loss: 0.5912 (0.5935)  time: 0.1824  data: 0.0001  max mem: 15824
[13:13:17.469253] Test:  [130/345]  eta: 0:00:39  loss: 0.5867 (0.5926)  time: 0.1827  data: 0.0001  max mem: 15824
[13:13:19.300802] Test:  [140/345]  eta: 0:00:37  loss: 0.5688 (0.5904)  time: 0.1830  data: 0.0001  max mem: 15824
[13:13:21.138320] Test:  [150/345]  eta: 0:00:35  loss: 0.5829 (0.5936)  time: 0.1834  data: 0.0001  max mem: 15824
[13:13:22.979575] Test:  [160/345]  eta: 0:00:34  loss: 0.5993 (0.5935)  time: 0.1839  data: 0.0001  max mem: 15824
[13:13:24.825717] Test:  [170/345]  eta: 0:00:32  loss: 0.5837 (0.5942)  time: 0.1843  data: 0.0001  max mem: 15824
[13:13:26.672256] Test:  [180/345]  eta: 0:00:30  loss: 0.5886 (0.5942)  time: 0.1846  data: 0.0001  max mem: 15824
[13:13:28.524089] Test:  [190/345]  eta: 0:00:28  loss: 0.5911 (0.5948)  time: 0.1849  data: 0.0001  max mem: 15824
[13:13:30.379063] Test:  [200/345]  eta: 0:00:26  loss: 0.5909 (0.5940)  time: 0.1853  data: 0.0001  max mem: 15824
[13:13:32.235777] Test:  [210/345]  eta: 0:00:24  loss: 0.5850 (0.5942)  time: 0.1855  data: 0.0001  max mem: 15824
[13:13:34.096144] Test:  [220/345]  eta: 0:00:23  loss: 0.5735 (0.5928)  time: 0.1858  data: 0.0001  max mem: 15824
[13:13:35.960846] Test:  [230/345]  eta: 0:00:21  loss: 0.5786 (0.5934)  time: 0.1862  data: 0.0001  max mem: 15824
[13:13:37.829668] Test:  [240/345]  eta: 0:00:19  loss: 0.5895 (0.5930)  time: 0.1866  data: 0.0001  max mem: 15824
[13:13:39.698234] Test:  [250/345]  eta: 0:00:17  loss: 0.5763 (0.5928)  time: 0.1868  data: 0.0001  max mem: 15824
[13:13:41.572152] Test:  [260/345]  eta: 0:00:15  loss: 0.5763 (0.5927)  time: 0.1871  data: 0.0001  max mem: 15824
[13:13:43.448044] Test:  [270/345]  eta: 0:00:13  loss: 0.5882 (0.5923)  time: 0.1874  data: 0.0001  max mem: 15824
[13:13:45.330359] Test:  [280/345]  eta: 0:00:12  loss: 0.6009 (0.5931)  time: 0.1878  data: 0.0001  max mem: 15824
[13:13:47.212932] Test:  [290/345]  eta: 0:00:10  loss: 0.5810 (0.5923)  time: 0.1882  data: 0.0001  max mem: 15824
[13:13:49.102353] Test:  [300/345]  eta: 0:00:08  loss: 0.5841 (0.5922)  time: 0.1885  data: 0.0001  max mem: 15824
[13:13:50.992368] Test:  [310/345]  eta: 0:00:06  loss: 0.5877 (0.5921)  time: 0.1889  data: 0.0001  max mem: 15824
[13:13:52.888445] Test:  [320/345]  eta: 0:00:04  loss: 0.5854 (0.5920)  time: 0.1892  data: 0.0001  max mem: 15824
[13:13:54.785526] Test:  [330/345]  eta: 0:00:02  loss: 0.5870 (0.5919)  time: 0.1896  data: 0.0001  max mem: 15824
[13:13:56.683271] Test:  [340/345]  eta: 0:00:00  loss: 0.5872 (0.5921)  time: 0.1897  data: 0.0001  max mem: 15824
[13:13:57.442805] Test:  [344/345]  eta: 0:00:00  loss: 0.5974 (0.5922)  time: 0.1898  data: 0.0001  max mem: 15824
[13:13:57.501181] Test: Total time: 0:01:04 (0.1859 s / it)
[13:14:07.952196] Test:  [ 0/57]  eta: 0:00:31  loss: 0.6731 (0.6731)  time: 0.5476  data: 0.3679  max mem: 15824
[13:14:09.721041] Test:  [10/57]  eta: 0:00:09  loss: 0.6265 (0.6576)  time: 0.2105  data: 0.0335  max mem: 15824
[13:14:11.497563] Test:  [20/57]  eta: 0:00:07  loss: 0.5935 (0.6159)  time: 0.1772  data: 0.0001  max mem: 15824
[13:14:13.277616] Test:  [30/57]  eta: 0:00:05  loss: 0.5170 (0.5558)  time: 0.1778  data: 0.0001  max mem: 15824
[13:14:15.064482] Test:  [40/57]  eta: 0:00:03  loss: 0.3978 (0.5196)  time: 0.1783  data: 0.0001  max mem: 15824
[13:14:16.851344] Test:  [50/57]  eta: 0:00:01  loss: 0.4141 (0.5072)  time: 0.1786  data: 0.0001  max mem: 15824
[13:14:17.822312] Test:  [56/57]  eta: 0:00:00  loss: 0.4978 (0.5158)  time: 0.1734  data: 0.0000  max mem: 15824
[13:14:17.892883] Test: Total time: 0:00:10 (0.1840 s / it)
[13:14:19.614837] Dice score of the network on the train images: 0.615095, val images: 0.720636
[13:14:19.615048] saving best_prec_model_0 @ epoch 3
[13:14:20.707465] saving best_dice_model_0 @ epoch 3
[13:14:22.426217] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:14:23.418368] Epoch: [4]  [  0/345]  eta: 0:05:41  lr: 0.000025  loss: 0.6189 (0.6189)  time: 0.9911  data: 0.3678  max mem: 15824
[13:14:35.725747] Epoch: [4]  [ 20/345]  eta: 0:03:25  lr: 0.000025  loss: 0.5961 (0.6047)  time: 0.6153  data: 0.0001  max mem: 15824
[13:14:48.066402] Epoch: [4]  [ 40/345]  eta: 0:03:10  lr: 0.000026  loss: 0.5860 (0.5997)  time: 0.6170  data: 0.0001  max mem: 15824
[13:15:00.421608] Epoch: [4]  [ 60/345]  eta: 0:02:57  lr: 0.000026  loss: 0.5976 (0.6008)  time: 0.6177  data: 0.0001  max mem: 15824
[13:15:12.791567] Epoch: [4]  [ 80/345]  eta: 0:02:44  lr: 0.000026  loss: 0.5859 (0.5974)  time: 0.6184  data: 0.0001  max mem: 15824
[13:15:25.192282] Epoch: [4]  [100/345]  eta: 0:02:32  lr: 0.000027  loss: 0.5816 (0.5955)  time: 0.6200  data: 0.0001  max mem: 15824
[13:15:37.610127] Epoch: [4]  [120/345]  eta: 0:02:19  lr: 0.000027  loss: 0.5661 (0.5920)  time: 0.6209  data: 0.0001  max mem: 15824
[13:15:50.044523] Epoch: [4]  [140/345]  eta: 0:02:07  lr: 0.000028  loss: 0.5872 (0.5913)  time: 0.6217  data: 0.0001  max mem: 15824
[13:16:02.476688] Epoch: [4]  [160/345]  eta: 0:01:54  lr: 0.000028  loss: 0.5576 (0.5862)  time: 0.6216  data: 0.0001  max mem: 15824
[13:16:14.898882] Epoch: [4]  [180/345]  eta: 0:01:42  lr: 0.000028  loss: 0.5423 (0.5823)  time: 0.6211  data: 0.0001  max mem: 15824
[13:16:27.318934] Epoch: [4]  [200/345]  eta: 0:01:30  lr: 0.000029  loss: 0.5249 (0.5774)  time: 0.6210  data: 0.0001  max mem: 15824
[13:16:39.732886] Epoch: [4]  [220/345]  eta: 0:01:17  lr: 0.000029  loss: 0.5339 (0.5743)  time: 0.6206  data: 0.0001  max mem: 15824
[13:16:52.131587] Epoch: [4]  [240/345]  eta: 0:01:05  lr: 0.000029  loss: 0.5481 (0.5717)  time: 0.6199  data: 0.0001  max mem: 15824
[13:17:04.553241] Epoch: [4]  [260/345]  eta: 0:00:52  lr: 0.000030  loss: 0.5172 (0.5678)  time: 0.6210  data: 0.0001  max mem: 15824
[13:17:16.978819] Epoch: [4]  [280/345]  eta: 0:00:40  lr: 0.000030  loss: 0.5278 (0.5652)  time: 0.6212  data: 0.0001  max mem: 15824
[13:17:29.376470] Epoch: [4]  [300/345]  eta: 0:00:27  lr: 0.000030  loss: 0.5180 (0.5619)  time: 0.6198  data: 0.0001  max mem: 15824
[13:17:41.799119] Epoch: [4]  [320/345]  eta: 0:00:15  lr: 0.000031  loss: 0.5050 (0.5583)  time: 0.6211  data: 0.0001  max mem: 15824
[13:17:54.186465] Epoch: [4]  [340/345]  eta: 0:00:03  lr: 0.000031  loss: 0.5152 (0.5557)  time: 0.6193  data: 0.0001  max mem: 15824
[13:17:56.656311] Epoch: [4]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 0.5152 (0.5548)  time: 0.6185  data: 0.0001  max mem: 15824
[13:17:56.731957] Epoch: [4] Total time: 0:03:34 (0.6212 s / it)
[13:17:56.732179] Averaged stats: lr: 0.000031  loss: 0.5152 (0.5548)
[13:17:57.301752] Test:  [  0/345]  eta: 0:03:14  loss: 0.5980 (0.5980)  time: 0.5646  data: 0.3835  max mem: 15824
[13:17:59.088497] Test:  [ 10/345]  eta: 0:01:11  loss: 0.5101 (0.5130)  time: 0.2137  data: 0.0349  max mem: 15824
[13:18:00.880779] Test:  [ 20/345]  eta: 0:01:04  loss: 0.5101 (0.5239)  time: 0.1789  data: 0.0001  max mem: 15824
[13:18:02.673635] Test:  [ 30/345]  eta: 0:01:00  loss: 0.5168 (0.5209)  time: 0.1792  data: 0.0001  max mem: 15824
[13:18:04.470525] Test:  [ 40/345]  eta: 0:00:57  loss: 0.5237 (0.5250)  time: 0.1794  data: 0.0001  max mem: 15824
[13:18:06.271319] Test:  [ 50/345]  eta: 0:00:55  loss: 0.5248 (0.5227)  time: 0.1798  data: 0.0001  max mem: 15824
[13:18:08.075714] Test:  [ 60/345]  eta: 0:00:52  loss: 0.5180 (0.5221)  time: 0.1802  data: 0.0001  max mem: 15824
[13:18:09.881572] Test:  [ 70/345]  eta: 0:00:50  loss: 0.5286 (0.5237)  time: 0.1804  data: 0.0001  max mem: 15824
[13:18:11.694095] Test:  [ 80/345]  eta: 0:00:48  loss: 0.5269 (0.5242)  time: 0.1809  data: 0.0001  max mem: 15824
[13:18:13.509647] Test:  [ 90/345]  eta: 0:00:46  loss: 0.5285 (0.5263)  time: 0.1813  data: 0.0001  max mem: 15824
[13:18:15.329122] Test:  [100/345]  eta: 0:00:45  loss: 0.5380 (0.5266)  time: 0.1817  data: 0.0001  max mem: 15824
[13:18:17.151258] Test:  [110/345]  eta: 0:00:43  loss: 0.5146 (0.5257)  time: 0.1820  data: 0.0001  max mem: 15824
[13:18:18.976541] Test:  [120/345]  eta: 0:00:41  loss: 0.5146 (0.5271)  time: 0.1823  data: 0.0001  max mem: 15824
[13:18:20.807995] Test:  [130/345]  eta: 0:00:39  loss: 0.5262 (0.5266)  time: 0.1828  data: 0.0001  max mem: 15824
[13:18:22.639718] Test:  [140/345]  eta: 0:00:37  loss: 0.5185 (0.5270)  time: 0.1831  data: 0.0001  max mem: 15824
[13:18:24.474866] Test:  [150/345]  eta: 0:00:35  loss: 0.5331 (0.5280)  time: 0.1833  data: 0.0001  max mem: 15824
[13:18:26.315980] Test:  [160/345]  eta: 0:00:33  loss: 0.5097 (0.5268)  time: 0.1838  data: 0.0001  max mem: 15824
[13:18:28.160056] Test:  [170/345]  eta: 0:00:32  loss: 0.5078 (0.5260)  time: 0.1842  data: 0.0001  max mem: 15824
[13:18:30.006011] Test:  [180/345]  eta: 0:00:30  loss: 0.5017 (0.5251)  time: 0.1844  data: 0.0001  max mem: 15824
[13:18:31.855635] Test:  [190/345]  eta: 0:00:28  loss: 0.5309 (0.5255)  time: 0.1847  data: 0.0001  max mem: 15824
[13:18:33.708424] Test:  [200/345]  eta: 0:00:26  loss: 0.5418 (0.5273)  time: 0.1851  data: 0.0001  max mem: 15824
[13:18:35.565365] Test:  [210/345]  eta: 0:00:24  loss: 0.5382 (0.5274)  time: 0.1854  data: 0.0001  max mem: 15824
[13:18:37.426904] Test:  [220/345]  eta: 0:00:23  loss: 0.5140 (0.5271)  time: 0.1859  data: 0.0001  max mem: 15824
[13:18:39.288856] Test:  [230/345]  eta: 0:00:21  loss: 0.5184 (0.5271)  time: 0.1861  data: 0.0001  max mem: 15824
[13:18:41.153908] Test:  [240/345]  eta: 0:00:19  loss: 0.5184 (0.5266)  time: 0.1863  data: 0.0001  max mem: 15824
[13:18:43.023446] Test:  [250/345]  eta: 0:00:17  loss: 0.5227 (0.5269)  time: 0.1867  data: 0.0001  max mem: 15824
[13:18:44.897468] Test:  [260/345]  eta: 0:00:15  loss: 0.5256 (0.5270)  time: 0.1871  data: 0.0001  max mem: 15824
[13:18:46.775339] Test:  [270/345]  eta: 0:00:13  loss: 0.5343 (0.5275)  time: 0.1875  data: 0.0001  max mem: 15824
[13:18:48.658000] Test:  [280/345]  eta: 0:00:12  loss: 0.5395 (0.5277)  time: 0.1880  data: 0.0001  max mem: 15824
[13:18:50.544438] Test:  [290/345]  eta: 0:00:10  loss: 0.5259 (0.5277)  time: 0.1884  data: 0.0001  max mem: 15824
[13:18:52.434594] Test:  [300/345]  eta: 0:00:08  loss: 0.5314 (0.5280)  time: 0.1888  data: 0.0001  max mem: 15824
[13:18:54.328023] Test:  [310/345]  eta: 0:00:06  loss: 0.5504 (0.5291)  time: 0.1891  data: 0.0001  max mem: 15824
[13:18:56.222403] Test:  [320/345]  eta: 0:00:04  loss: 0.5517 (0.5293)  time: 0.1893  data: 0.0001  max mem: 15824
[13:18:58.121782] Test:  [330/345]  eta: 0:00:02  loss: 0.5407 (0.5292)  time: 0.1896  data: 0.0001  max mem: 15824
[13:19:00.020932] Test:  [340/345]  eta: 0:00:00  loss: 0.5407 (0.5297)  time: 0.1899  data: 0.0001  max mem: 15824
[13:19:00.782720] Test:  [344/345]  eta: 0:00:00  loss: 0.5418 (0.5298)  time: 0.1899  data: 0.0001  max mem: 15824
[13:19:00.852790] Test: Total time: 0:01:04 (0.1858 s / it)
[13:19:11.215948] Test:  [ 0/57]  eta: 0:00:33  loss: 0.6286 (0.6286)  time: 0.5877  data: 0.4067  max mem: 15824
[13:19:12.984905] Test:  [10/57]  eta: 0:00:10  loss: 0.5681 (0.5836)  time: 0.2142  data: 0.0371  max mem: 15824
[13:19:14.761769] Test:  [20/57]  eta: 0:00:07  loss: 0.5427 (0.5618)  time: 0.1772  data: 0.0001  max mem: 15824
[13:19:16.543917] Test:  [30/57]  eta: 0:00:05  loss: 0.4854 (0.5141)  time: 0.1779  data: 0.0001  max mem: 15824
[13:19:18.331042] Test:  [40/57]  eta: 0:00:03  loss: 0.3805 (0.4862)  time: 0.1784  data: 0.0001  max mem: 15824
[13:19:20.117661] Test:  [50/57]  eta: 0:00:01  loss: 0.3969 (0.4754)  time: 0.1786  data: 0.0001  max mem: 15824
[13:19:21.088333] Test:  [56/57]  eta: 0:00:00  loss: 0.4634 (0.4789)  time: 0.1735  data: 0.0000  max mem: 15824
[13:19:21.163003] Test: Total time: 0:00:10 (0.1848 s / it)
[13:19:22.869965] Dice score of the network on the train images: 0.636817, val images: 0.720724
[13:19:22.870177] saving best_dice_model_0 @ epoch 4
[13:19:24.506449] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:19:25.521161] Epoch: [5]  [  0/345]  eta: 0:05:49  lr: 0.000031  loss: 0.5101 (0.5101)  time: 1.0136  data: 0.3907  max mem: 15824
[13:19:37.843108] Epoch: [5]  [ 20/345]  eta: 0:03:26  lr: 0.000032  loss: 0.4995 (0.5003)  time: 0.6160  data: 0.0001  max mem: 15824
[13:19:50.155806] Epoch: [5]  [ 40/345]  eta: 0:03:10  lr: 0.000032  loss: 0.4789 (0.4884)  time: 0.6156  data: 0.0001  max mem: 15824
[13:20:02.496876] Epoch: [5]  [ 60/345]  eta: 0:02:57  lr: 0.000032  loss: 0.4809 (0.4896)  time: 0.6170  data: 0.0001  max mem: 15824
[13:20:14.873877] Epoch: [5]  [ 80/345]  eta: 0:02:44  lr: 0.000033  loss: 0.4693 (0.4859)  time: 0.6188  data: 0.0001  max mem: 15824
[13:20:27.293823] Epoch: [5]  [100/345]  eta: 0:02:32  lr: 0.000033  loss: 0.4865 (0.4855)  time: 0.6209  data: 0.0001  max mem: 15824
[13:20:39.730508] Epoch: [5]  [120/345]  eta: 0:02:19  lr: 0.000033  loss: 0.4749 (0.4836)  time: 0.6218  data: 0.0001  max mem: 15824
[13:20:52.164462] Epoch: [5]  [140/345]  eta: 0:02:07  lr: 0.000034  loss: 0.4727 (0.4830)  time: 0.6216  data: 0.0001  max mem: 15824
[13:21:04.594048] Epoch: [5]  [160/345]  eta: 0:01:54  lr: 0.000034  loss: 0.4683 (0.4818)  time: 0.6214  data: 0.0001  max mem: 15824
[13:21:17.028838] Epoch: [5]  [180/345]  eta: 0:01:42  lr: 0.000035  loss: 0.4606 (0.4796)  time: 0.6217  data: 0.0001  max mem: 15824
[13:21:29.460110] Epoch: [5]  [200/345]  eta: 0:01:30  lr: 0.000035  loss: 0.4748 (0.4786)  time: 0.6215  data: 0.0001  max mem: 15824
[13:21:41.885356] Epoch: [5]  [220/345]  eta: 0:01:17  lr: 0.000035  loss: 0.4484 (0.4763)  time: 0.6212  data: 0.0001  max mem: 15824
[13:21:54.307670] Epoch: [5]  [240/345]  eta: 0:01:05  lr: 0.000036  loss: 0.4524 (0.4747)  time: 0.6211  data: 0.0001  max mem: 15824
[13:22:06.736302] Epoch: [5]  [260/345]  eta: 0:00:52  lr: 0.000036  loss: 0.4224 (0.4718)  time: 0.6214  data: 0.0001  max mem: 15824
[13:22:19.171045] Epoch: [5]  [280/345]  eta: 0:00:40  lr: 0.000036  loss: 0.4446 (0.4705)  time: 0.6217  data: 0.0001  max mem: 15824
[13:22:31.596718] Epoch: [5]  [300/345]  eta: 0:00:27  lr: 0.000037  loss: 0.4318 (0.4682)  time: 0.6212  data: 0.0001  max mem: 15824
[13:22:43.995079] Epoch: [5]  [320/345]  eta: 0:00:15  lr: 0.000037  loss: 0.4288 (0.4661)  time: 0.6199  data: 0.0001  max mem: 15824
[13:22:56.398379] Epoch: [5]  [340/345]  eta: 0:00:03  lr: 0.000037  loss: 0.4311 (0.4644)  time: 0.6201  data: 0.0001  max mem: 15824
[13:22:58.882766] Epoch: [5]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 0.4294 (0.4640)  time: 0.6202  data: 0.0001  max mem: 15824
[13:22:58.960077] Epoch: [5] Total time: 0:03:34 (0.6216 s / it)
[13:22:58.960392] Averaged stats: lr: 0.000037  loss: 0.4294 (0.4640)
[13:22:59.545470] Test:  [  0/345]  eta: 0:03:20  loss: 0.4049 (0.4049)  time: 0.5804  data: 0.3952  max mem: 15824
[13:23:01.335276] Test:  [ 10/345]  eta: 0:01:12  loss: 0.4248 (0.4163)  time: 0.2154  data: 0.0360  max mem: 15824
[13:23:03.130204] Test:  [ 20/345]  eta: 0:01:04  loss: 0.4248 (0.4195)  time: 0.1792  data: 0.0001  max mem: 15824
[13:23:04.930879] Test:  [ 30/345]  eta: 0:01:00  loss: 0.4106 (0.4169)  time: 0.1797  data: 0.0001  max mem: 15824
[13:23:06.730814] Test:  [ 40/345]  eta: 0:00:57  loss: 0.4142 (0.4194)  time: 0.1800  data: 0.0001  max mem: 15824
[13:23:08.532587] Test:  [ 50/345]  eta: 0:00:55  loss: 0.4267 (0.4232)  time: 0.1800  data: 0.0001  max mem: 15824
[13:23:10.336052] Test:  [ 60/345]  eta: 0:00:53  loss: 0.4219 (0.4221)  time: 0.1802  data: 0.0001  max mem: 15824
[13:23:12.144784] Test:  [ 70/345]  eta: 0:00:51  loss: 0.4149 (0.4223)  time: 0.1805  data: 0.0001  max mem: 15824
[13:23:13.957835] Test:  [ 80/345]  eta: 0:00:49  loss: 0.4264 (0.4249)  time: 0.1810  data: 0.0001  max mem: 15824
[13:23:15.775561] Test:  [ 90/345]  eta: 0:00:47  loss: 0.4126 (0.4237)  time: 0.1815  data: 0.0001  max mem: 15824
[13:23:17.596485] Test:  [100/345]  eta: 0:00:45  loss: 0.4153 (0.4240)  time: 0.1818  data: 0.0001  max mem: 15824
[13:23:19.418886] Test:  [110/345]  eta: 0:00:43  loss: 0.4367 (0.4249)  time: 0.1820  data: 0.0001  max mem: 15824
[13:23:21.250012] Test:  [120/345]  eta: 0:00:41  loss: 0.4367 (0.4253)  time: 0.1826  data: 0.0001  max mem: 15824
[13:23:23.080773] Test:  [130/345]  eta: 0:00:39  loss: 0.4180 (0.4243)  time: 0.1830  data: 0.0001  max mem: 15824
[13:23:24.916217] Test:  [140/345]  eta: 0:00:37  loss: 0.4130 (0.4242)  time: 0.1832  data: 0.0001  max mem: 15824
[13:23:26.754993] Test:  [150/345]  eta: 0:00:35  loss: 0.4133 (0.4236)  time: 0.1836  data: 0.0001  max mem: 15824
[13:23:28.596748] Test:  [160/345]  eta: 0:00:34  loss: 0.4357 (0.4247)  time: 0.1840  data: 0.0001  max mem: 15824
[13:23:30.441385] Test:  [170/345]  eta: 0:00:32  loss: 0.4370 (0.4248)  time: 0.1843  data: 0.0001  max mem: 15824
[13:23:32.291357] Test:  [180/345]  eta: 0:00:30  loss: 0.4284 (0.4242)  time: 0.1847  data: 0.0001  max mem: 15824
[13:23:34.142093] Test:  [190/345]  eta: 0:00:28  loss: 0.4126 (0.4241)  time: 0.1850  data: 0.0001  max mem: 15824
[13:23:35.999283] Test:  [200/345]  eta: 0:00:26  loss: 0.4103 (0.4232)  time: 0.1853  data: 0.0001  max mem: 15824
[13:23:37.858460] Test:  [210/345]  eta: 0:00:24  loss: 0.4092 (0.4222)  time: 0.1858  data: 0.0001  max mem: 15824
[13:23:39.722003] Test:  [220/345]  eta: 0:00:23  loss: 0.4125 (0.4222)  time: 0.1861  data: 0.0001  max mem: 15824
[13:23:41.586894] Test:  [230/345]  eta: 0:00:21  loss: 0.4197 (0.4225)  time: 0.1864  data: 0.0001  max mem: 15824
[13:23:43.455855] Test:  [240/345]  eta: 0:00:19  loss: 0.4240 (0.4227)  time: 0.1866  data: 0.0001  max mem: 15824
[13:23:45.325480] Test:  [250/345]  eta: 0:00:17  loss: 0.4194 (0.4229)  time: 0.1869  data: 0.0001  max mem: 15824
[13:23:47.200357] Test:  [260/345]  eta: 0:00:15  loss: 0.4265 (0.4231)  time: 0.1872  data: 0.0001  max mem: 15824
[13:23:49.077731] Test:  [270/345]  eta: 0:00:13  loss: 0.4265 (0.4230)  time: 0.1876  data: 0.0001  max mem: 15824
[13:23:50.960178] Test:  [280/345]  eta: 0:00:12  loss: 0.4153 (0.4230)  time: 0.1879  data: 0.0001  max mem: 15824
[13:23:52.844068] Test:  [290/345]  eta: 0:00:10  loss: 0.4003 (0.4223)  time: 0.1883  data: 0.0001  max mem: 15824
[13:23:54.733554] Test:  [300/345]  eta: 0:00:08  loss: 0.4088 (0.4228)  time: 0.1886  data: 0.0001  max mem: 15824
[13:23:56.626839] Test:  [310/345]  eta: 0:00:06  loss: 0.4231 (0.4227)  time: 0.1891  data: 0.0001  max mem: 15824
[13:23:58.524232] Test:  [320/345]  eta: 0:00:04  loss: 0.4155 (0.4227)  time: 0.1895  data: 0.0001  max mem: 15824
[13:24:00.422790] Test:  [330/345]  eta: 0:00:02  loss: 0.4236 (0.4226)  time: 0.1897  data: 0.0001  max mem: 15824
[13:24:02.322855] Test:  [340/345]  eta: 0:00:00  loss: 0.4035 (0.4221)  time: 0.1899  data: 0.0001  max mem: 15824
[13:24:03.083748] Test:  [344/345]  eta: 0:00:00  loss: 0.4035 (0.4223)  time: 0.1899  data: 0.0001  max mem: 15824
[13:24:03.154538] Test: Total time: 0:01:04 (0.1861 s / it)
[13:24:13.577020] Test:  [ 0/57]  eta: 0:00:31  loss: 0.5544 (0.5544)  time: 0.5502  data: 0.3697  max mem: 15824
[13:24:15.346844] Test:  [10/57]  eta: 0:00:09  loss: 0.4984 (0.5127)  time: 0.2108  data: 0.0337  max mem: 15824
[13:24:17.123021] Test:  [20/57]  eta: 0:00:07  loss: 0.4629 (0.4743)  time: 0.1772  data: 0.0001  max mem: 15824
[13:24:18.905927] Test:  [30/57]  eta: 0:00:05  loss: 0.3870 (0.4310)  time: 0.1779  data: 0.0001  max mem: 15824
[13:24:20.695049] Test:  [40/57]  eta: 0:00:03  loss: 0.3344 (0.4070)  time: 0.1785  data: 0.0001  max mem: 15824
[13:24:22.482776] Test:  [50/57]  eta: 0:00:01  loss: 0.3344 (0.3996)  time: 0.1788  data: 0.0001  max mem: 15824
[13:24:23.456064] Test:  [56/57]  eta: 0:00:00  loss: 0.3831 (0.4080)  time: 0.1738  data: 0.0001  max mem: 15824
[13:24:23.520611] Test: Total time: 0:00:10 (0.1841 s / it)
[13:24:25.197514] Dice score of the network on the train images: 0.690383, val images: 0.732290
[13:24:25.197718] saving best_prec_model_0 @ epoch 5
[13:24:26.752326] saving best_dice_model_0 @ epoch 5
[13:24:27.930780] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:24:28.979356] Epoch: [6]  [  0/345]  eta: 0:06:01  lr: 0.000038  loss: 0.4069 (0.4069)  time: 1.0472  data: 0.4242  max mem: 15824
[13:24:41.301095] Epoch: [6]  [ 20/345]  eta: 0:03:26  lr: 0.000038  loss: 0.4082 (0.4143)  time: 0.6160  data: 0.0001  max mem: 15824
[13:24:53.664954] Epoch: [6]  [ 40/345]  eta: 0:03:11  lr: 0.000038  loss: 0.4007 (0.4131)  time: 0.6181  data: 0.0001  max mem: 15824
[13:25:06.046763] Epoch: [6]  [ 60/345]  eta: 0:02:58  lr: 0.000039  loss: 0.4169 (0.4160)  time: 0.6190  data: 0.0001  max mem: 15824
[13:25:18.444989] Epoch: [6]  [ 80/345]  eta: 0:02:45  lr: 0.000039  loss: 0.4105 (0.4159)  time: 0.6199  data: 0.0001  max mem: 15824
[13:25:30.869658] Epoch: [6]  [100/345]  eta: 0:02:32  lr: 0.000039  loss: 0.4236 (0.4172)  time: 0.6212  data: 0.0001  max mem: 15824
[13:25:43.324390] Epoch: [6]  [120/345]  eta: 0:02:20  lr: 0.000040  loss: 0.4308 (0.4196)  time: 0.6227  data: 0.0001  max mem: 15824
[13:25:55.771904] Epoch: [6]  [140/345]  eta: 0:02:07  lr: 0.000040  loss: 0.4017 (0.4183)  time: 0.6223  data: 0.0001  max mem: 15824
[13:26:08.210943] Epoch: [6]  [160/345]  eta: 0:01:55  lr: 0.000040  loss: 0.4183 (0.4178)  time: 0.6219  data: 0.0001  max mem: 15824
[13:26:20.643844] Epoch: [6]  [180/345]  eta: 0:01:42  lr: 0.000041  loss: 0.4126 (0.4179)  time: 0.6216  data: 0.0001  max mem: 15824
[13:26:33.074375] Epoch: [6]  [200/345]  eta: 0:01:30  lr: 0.000041  loss: 0.3915 (0.4163)  time: 0.6215  data: 0.0001  max mem: 15824
[13:26:45.487142] Epoch: [6]  [220/345]  eta: 0:01:17  lr: 0.000041  loss: 0.3927 (0.4144)  time: 0.6206  data: 0.0001  max mem: 15824
[13:26:57.893280] Epoch: [6]  [240/345]  eta: 0:01:05  lr: 0.000042  loss: 0.3895 (0.4128)  time: 0.6203  data: 0.0001  max mem: 15824
[13:27:10.303699] Epoch: [6]  [260/345]  eta: 0:00:52  lr: 0.000042  loss: 0.3943 (0.4109)  time: 0.6205  data: 0.0001  max mem: 15824
[13:27:22.719179] Epoch: [6]  [280/345]  eta: 0:00:40  lr: 0.000043  loss: 0.3915 (0.4096)  time: 0.6207  data: 0.0001  max mem: 15824
[13:27:35.136164] Epoch: [6]  [300/345]  eta: 0:00:27  lr: 0.000043  loss: 0.3789 (0.4084)  time: 0.6208  data: 0.0001  max mem: 15824
[13:27:47.529133] Epoch: [6]  [320/345]  eta: 0:00:15  lr: 0.000043  loss: 0.3976 (0.4078)  time: 0.6196  data: 0.0001  max mem: 15824
[13:27:59.928575] Epoch: [6]  [340/345]  eta: 0:00:03  lr: 0.000044  loss: 0.3970 (0.4068)  time: 0.6199  data: 0.0001  max mem: 15824
[13:28:02.407955] Epoch: [6]  [344/345]  eta: 0:00:00  lr: 0.000044  loss: 0.4056 (0.4069)  time: 0.6198  data: 0.0001  max mem: 15824
[13:28:02.476527] Epoch: [6] Total time: 0:03:34 (0.6219 s / it)
[13:28:02.477422] Averaged stats: lr: 0.000044  loss: 0.4056 (0.4069)
[13:28:03.075686] Test:  [  0/345]  eta: 0:03:24  loss: 0.3666 (0.3666)  time: 0.5930  data: 0.4113  max mem: 15824
[13:28:04.867401] Test:  [ 10/345]  eta: 0:01:12  loss: 0.3666 (0.3640)  time: 0.2167  data: 0.0375  max mem: 15824
[13:28:06.661694] Test:  [ 20/345]  eta: 0:01:04  loss: 0.3795 (0.3774)  time: 0.1792  data: 0.0001  max mem: 15824
[13:28:08.458567] Test:  [ 30/345]  eta: 0:01:00  loss: 0.3882 (0.3832)  time: 0.1795  data: 0.0001  max mem: 15824
[13:28:10.256267] Test:  [ 40/345]  eta: 0:00:57  loss: 0.3930 (0.3891)  time: 0.1797  data: 0.0001  max mem: 15824
[13:28:12.055215] Test:  [ 50/345]  eta: 0:00:55  loss: 0.4064 (0.3934)  time: 0.1798  data: 0.0001  max mem: 15824
[13:28:13.858217] Test:  [ 60/345]  eta: 0:00:53  loss: 0.4042 (0.3917)  time: 0.1800  data: 0.0001  max mem: 15824
[13:28:15.664823] Test:  [ 70/345]  eta: 0:00:51  loss: 0.3676 (0.3884)  time: 0.1804  data: 0.0001  max mem: 15824
[13:28:17.476524] Test:  [ 80/345]  eta: 0:00:49  loss: 0.3805 (0.3874)  time: 0.1809  data: 0.0001  max mem: 15824
[13:28:19.292957] Test:  [ 90/345]  eta: 0:00:47  loss: 0.3834 (0.3897)  time: 0.1814  data: 0.0001  max mem: 15824
[13:28:21.111890] Test:  [100/345]  eta: 0:00:45  loss: 0.3882 (0.3879)  time: 0.1817  data: 0.0001  max mem: 15824
[13:28:22.934310] Test:  [110/345]  eta: 0:00:43  loss: 0.3882 (0.3884)  time: 0.1820  data: 0.0001  max mem: 15824
[13:28:24.759218] Test:  [120/345]  eta: 0:00:41  loss: 0.3891 (0.3872)  time: 0.1823  data: 0.0001  max mem: 15824
[13:28:26.589325] Test:  [130/345]  eta: 0:00:39  loss: 0.3766 (0.3868)  time: 0.1827  data: 0.0001  max mem: 15824
[13:28:28.420759] Test:  [140/345]  eta: 0:00:37  loss: 0.3740 (0.3860)  time: 0.1830  data: 0.0001  max mem: 15824
[13:28:30.257447] Test:  [150/345]  eta: 0:00:35  loss: 0.3901 (0.3871)  time: 0.1833  data: 0.0001  max mem: 15824
[13:28:32.095386] Test:  [160/345]  eta: 0:00:34  loss: 0.3987 (0.3866)  time: 0.1837  data: 0.0001  max mem: 15824
[13:28:33.937845] Test:  [170/345]  eta: 0:00:32  loss: 0.3652 (0.3864)  time: 0.1840  data: 0.0001  max mem: 15824
[13:28:35.785449] Test:  [180/345]  eta: 0:00:30  loss: 0.3905 (0.3869)  time: 0.1844  data: 0.0001  max mem: 15824
[13:28:37.636172] Test:  [190/345]  eta: 0:00:28  loss: 0.3813 (0.3863)  time: 0.1849  data: 0.0001  max mem: 15824
[13:28:39.488995] Test:  [200/345]  eta: 0:00:26  loss: 0.3642 (0.3858)  time: 0.1851  data: 0.0001  max mem: 15824
[13:28:41.344909] Test:  [210/345]  eta: 0:00:24  loss: 0.3630 (0.3853)  time: 0.1854  data: 0.0001  max mem: 15824
[13:28:43.205612] Test:  [220/345]  eta: 0:00:23  loss: 0.3630 (0.3858)  time: 0.1858  data: 0.0001  max mem: 15824
[13:28:45.069899] Test:  [230/345]  eta: 0:00:21  loss: 0.3692 (0.3850)  time: 0.1862  data: 0.0001  max mem: 15824
[13:28:46.938065] Test:  [240/345]  eta: 0:00:19  loss: 0.3715 (0.3849)  time: 0.1866  data: 0.0001  max mem: 15824
[13:28:48.809007] Test:  [250/345]  eta: 0:00:17  loss: 0.3825 (0.3846)  time: 0.1869  data: 0.0001  max mem: 15824
[13:28:50.683985] Test:  [260/345]  eta: 0:00:15  loss: 0.3839 (0.3849)  time: 0.1872  data: 0.0001  max mem: 15824
[13:28:52.560000] Test:  [270/345]  eta: 0:00:13  loss: 0.3886 (0.3853)  time: 0.1875  data: 0.0001  max mem: 15824
[13:28:54.440765] Test:  [280/345]  eta: 0:00:12  loss: 0.3972 (0.3860)  time: 0.1878  data: 0.0001  max mem: 15824
[13:28:56.324978] Test:  [290/345]  eta: 0:00:10  loss: 0.4003 (0.3864)  time: 0.1882  data: 0.0001  max mem: 15824
[13:28:58.213616] Test:  [300/345]  eta: 0:00:08  loss: 0.4003 (0.3868)  time: 0.1886  data: 0.0001  max mem: 15824
[13:29:00.106482] Test:  [310/345]  eta: 0:00:06  loss: 0.3757 (0.3870)  time: 0.1890  data: 0.0001  max mem: 15824
[13:29:02.000881] Test:  [320/345]  eta: 0:00:04  loss: 0.3848 (0.3873)  time: 0.1893  data: 0.0001  max mem: 15824
[13:29:03.897416] Test:  [330/345]  eta: 0:00:02  loss: 0.3893 (0.3869)  time: 0.1895  data: 0.0001  max mem: 15824
[13:29:05.796784] Test:  [340/345]  eta: 0:00:00  loss: 0.3783 (0.3870)  time: 0.1897  data: 0.0001  max mem: 15824
[13:29:06.556316] Test:  [344/345]  eta: 0:00:00  loss: 0.3775 (0.3869)  time: 0.1898  data: 0.0001  max mem: 15824
[13:29:06.634957] Test: Total time: 0:01:04 (0.1860 s / it)
[13:29:17.053266] Test:  [ 0/57]  eta: 0:00:31  loss: 0.5326 (0.5326)  time: 0.5484  data: 0.3689  max mem: 15824
[13:29:18.825026] Test:  [10/57]  eta: 0:00:09  loss: 0.5108 (0.5151)  time: 0.2108  data: 0.0336  max mem: 15824
[13:29:20.603796] Test:  [20/57]  eta: 0:00:07  loss: 0.4677 (0.4788)  time: 0.1775  data: 0.0001  max mem: 15824
[13:29:22.384795] Test:  [30/57]  eta: 0:00:05  loss: 0.3619 (0.4325)  time: 0.1779  data: 0.0001  max mem: 15824
[13:29:24.170064] Test:  [40/57]  eta: 0:00:03  loss: 0.3472 (0.4121)  time: 0.1783  data: 0.0001  max mem: 15824
[13:29:25.957721] Test:  [50/57]  eta: 0:00:01  loss: 0.3496 (0.4115)  time: 0.1786  data: 0.0001  max mem: 15824
[13:29:26.930416] Test:  [56/57]  eta: 0:00:00  loss: 0.3874 (0.4244)  time: 0.1736  data: 0.0000  max mem: 15824
[13:29:26.995430] Test: Total time: 0:00:10 (0.1841 s / it)
[13:29:28.689331] Dice score of the network on the train images: 0.735111, val images: 0.725018
[13:29:28.689530] saving best_prec_model_0 @ epoch 6
[13:29:29.755501] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:29:30.750895] Epoch: [7]  [  0/345]  eta: 0:05:43  lr: 0.000044  loss: 0.3992 (0.3992)  time: 0.9942  data: 0.3695  max mem: 15824
[13:29:43.093811] Epoch: [7]  [ 20/345]  eta: 0:03:26  lr: 0.000044  loss: 0.3967 (0.3931)  time: 0.6171  data: 0.0001  max mem: 15824
[13:29:55.454379] Epoch: [7]  [ 40/345]  eta: 0:03:11  lr: 0.000044  loss: 0.3653 (0.3802)  time: 0.6180  data: 0.0001  max mem: 15824
[13:30:07.837257] Epoch: [7]  [ 60/345]  eta: 0:02:57  lr: 0.000045  loss: 0.3779 (0.3796)  time: 0.6191  data: 0.0001  max mem: 15824
[13:30:20.239877] Epoch: [7]  [ 80/345]  eta: 0:02:45  lr: 0.000045  loss: 0.3725 (0.3770)  time: 0.6201  data: 0.0001  max mem: 15824
[13:30:32.673115] Epoch: [7]  [100/345]  eta: 0:02:32  lr: 0.000046  loss: 0.3694 (0.3771)  time: 0.6216  data: 0.0001  max mem: 15824

[13:30:45.106402] Epoch: [7]  [120/345]  eta: 0:02:20  lr: 0.000046  loss: 0.3463 (0.3748)  time: 0.6216  data: 0.0001  max mem: 15824
[13:30:57.529282] Epoch: [7]  [140/345]  eta: 0:02:07  lr: 0.000046  loss: 0.3635 (0.3737)  time: 0.6211  data: 0.0001  max mem: 15824
[13:31:09.971305] Epoch: [7]  [160/345]  eta: 0:01:55  lr: 0.000047  loss: 0.3715 (0.3738)  time: 0.6221  data: 0.0001  max mem: 15824
[13:31:22.416853] Epoch: [7]  [180/345]  eta: 0:01:42  lr: 0.000047  loss: 0.3674 (0.3739)  time: 0.6222  data: 0.0001  max mem: 15824
[13:31:34.867093] Epoch: [7]  [200/345]  eta: 0:01:30  lr: 0.000047  loss: 0.3260 (0.3706)  time: 0.6225  data: 0.0001  max mem: 15824
[13:31:47.291554] Epoch: [7]  [220/345]  eta: 0:01:17  lr: 0.000048  loss: 0.3843 (0.3716)  time: 0.6212  data: 0.0001  max mem: 15824
[13:31:59.684125] Epoch: [7]  [240/345]  eta: 0:01:05  lr: 0.000048  loss: 0.3671 (0.3712)  time: 0.6195  data: 0.0001  max mem: 15824
[13:32:12.079650] Epoch: [7]  [260/345]  eta: 0:00:52  lr: 0.000048  loss: 0.3675 (0.3712)  time: 0.6197  data: 0.0001  max mem: 15824
[13:32:24.456257] Epoch: [7]  [280/345]  eta: 0:00:40  lr: 0.000049  loss: 0.3750 (0.3712)  time: 0.6188  data: 0.0001  max mem: 15824
[13:32:36.842505] Epoch: [7]  [300/345]  eta: 0:00:27  lr: 0.000049  loss: 0.3529 (0.3702)  time: 0.6193  data: 0.0001  max mem: 15824
[13:32:49.215648] Epoch: [7]  [320/345]  eta: 0:00:15  lr: 0.000050  loss: 0.3578 (0.3695)  time: 0.6186  data: 0.0001  max mem: 15824
[13:33:01.580634] Epoch: [7]  [340/345]  eta: 0:00:03  lr: 0.000050  loss: 0.3616 (0.3687)  time: 0.6182  data: 0.0001  max mem: 15824
[13:33:04.053675] Epoch: [7]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.3647 (0.3689)  time: 0.6181  data: 0.0001  max mem: 15824
[13:33:04.131729] Epoch: [7] Total time: 0:03:34 (0.6214 s / it)
[13:33:04.131945] Averaged stats: lr: 0.000050  loss: 0.3647 (0.3689)
[13:33:04.707194] Test:  [  0/345]  eta: 0:03:16  loss: 0.3371 (0.3371)  time: 0.5695  data: 0.3862  max mem: 15824
[13:33:06.496940] Test:  [ 10/345]  eta: 0:01:11  loss: 0.3454 (0.3425)  time: 0.2144  data: 0.0352  max mem: 15824
[13:33:08.291527] Test:  [ 20/345]  eta: 0:01:04  loss: 0.3328 (0.3379)  time: 0.1791  data: 0.0001  max mem: 15824
[13:33:10.092619] Test:  [ 30/345]  eta: 0:01:00  loss: 0.3328 (0.3407)  time: 0.1797  data: 0.0001  max mem: 15824
[13:33:11.894177] Test:  [ 40/345]  eta: 0:00:57  loss: 0.3473 (0.3416)  time: 0.1801  data: 0.0001  max mem: 15824
[13:33:13.696027] Test:  [ 50/345]  eta: 0:00:55  loss: 0.3499 (0.3433)  time: 0.1801  data: 0.0001  max mem: 15824
[13:33:15.499416] Test:  [ 60/345]  eta: 0:00:53  loss: 0.3456 (0.3434)  time: 0.1802  data: 0.0001  max mem: 15824
[13:33:17.308370] Test:  [ 70/345]  eta: 0:00:50  loss: 0.3441 (0.3452)  time: 0.1806  data: 0.0001  max mem: 15824
[13:33:19.121131] Test:  [ 80/345]  eta: 0:00:49  loss: 0.3444 (0.3445)  time: 0.1810  data: 0.0001  max mem: 15824
[13:33:20.937591] Test:  [ 90/345]  eta: 0:00:47  loss: 0.3263 (0.3430)  time: 0.1814  data: 0.0001  max mem: 15824
[13:33:22.756242] Test:  [100/345]  eta: 0:00:45  loss: 0.3210 (0.3419)  time: 0.1817  data: 0.0001  max mem: 15824
[13:33:24.579792] Test:  [110/345]  eta: 0:00:43  loss: 0.3425 (0.3422)  time: 0.1821  data: 0.0001  max mem: 15824
[13:33:26.407007] Test:  [120/345]  eta: 0:00:41  loss: 0.3460 (0.3426)  time: 0.1825  data: 0.0001  max mem: 15824
[13:33:28.238611] Test:  [130/345]  eta: 0:00:39  loss: 0.3402 (0.3407)  time: 0.1829  data: 0.0001  max mem: 15824
[13:33:30.072894] Test:  [140/345]  eta: 0:00:37  loss: 0.3219 (0.3390)  time: 0.1832  data: 0.0001  max mem: 15824
[13:33:31.912341] Test:  [150/345]  eta: 0:00:35  loss: 0.3240 (0.3384)  time: 0.1836  data: 0.0001  max mem: 15824
[13:33:33.753282] Test:  [160/345]  eta: 0:00:34  loss: 0.3320 (0.3392)  time: 0.1840  data: 0.0001  max mem: 15824
[13:33:35.597140] Test:  [170/345]  eta: 0:00:32  loss: 0.3405 (0.3395)  time: 0.1842  data: 0.0001  max mem: 15824
[13:33:37.443998] Test:  [180/345]  eta: 0:00:30  loss: 0.3329 (0.3385)  time: 0.1845  data: 0.0001  max mem: 15824
[13:33:39.294040] Test:  [190/345]  eta: 0:00:28  loss: 0.3367 (0.3392)  time: 0.1848  data: 0.0001  max mem: 15824
[13:33:41.146226] Test:  [200/345]  eta: 0:00:26  loss: 0.3549 (0.3395)  time: 0.1850  data: 0.0001  max mem: 15824
[13:33:43.004823] Test:  [210/345]  eta: 0:00:24  loss: 0.3325 (0.3394)  time: 0.1855  data: 0.0001  max mem: 15824
[13:33:44.864750] Test:  [220/345]  eta: 0:00:23  loss: 0.3489 (0.3401)  time: 0.1859  data: 0.0001  max mem: 15824
[13:33:46.729775] Test:  [230/345]  eta: 0:00:21  loss: 0.3571 (0.3404)  time: 0.1862  data: 0.0001  max mem: 15824
[13:33:48.596791] Test:  [240/345]  eta: 0:00:19  loss: 0.3452 (0.3407)  time: 0.1865  data: 0.0001  max mem: 15824
[13:33:50.468584] Test:  [250/345]  eta: 0:00:17  loss: 0.3452 (0.3407)  time: 0.1869  data: 0.0001  max mem: 15824
[13:33:52.342498] Test:  [260/345]  eta: 0:00:15  loss: 0.3463 (0.3409)  time: 0.1872  data: 0.0001  max mem: 15824
[13:33:54.221603] Test:  [270/345]  eta: 0:00:13  loss: 0.3425 (0.3409)  time: 0.1876  data: 0.0001  max mem: 15824
[13:33:56.103407] Test:  [280/345]  eta: 0:00:12  loss: 0.3523 (0.3416)  time: 0.1880  data: 0.0001  max mem: 15824
[13:33:57.988823] Test:  [290/345]  eta: 0:00:10  loss: 0.3548 (0.3417)  time: 0.1883  data: 0.0001  max mem: 15824
[13:33:59.875741] Test:  [300/345]  eta: 0:00:08  loss: 0.3411 (0.3418)  time: 0.1886  data: 0.0001  max mem: 15824
[13:34:01.769029] Test:  [310/345]  eta: 0:00:06  loss: 0.3372 (0.3420)  time: 0.1889  data: 0.0001  max mem: 15824
[13:34:03.664261] Test:  [320/345]  eta: 0:00:04  loss: 0.3369 (0.3422)  time: 0.1894  data: 0.0001  max mem: 15824
[13:34:05.564511] Test:  [330/345]  eta: 0:00:02  loss: 0.3335 (0.3420)  time: 0.1897  data: 0.0001  max mem: 15824
[13:34:07.464390] Test:  [340/345]  eta: 0:00:00  loss: 0.3330 (0.3424)  time: 0.1899  data: 0.0001  max mem: 15824
[13:34:08.226029] Test:  [344/345]  eta: 0:00:00  loss: 0.3409 (0.3427)  time: 0.1900  data: 0.0001  max mem: 15824
[13:34:08.291514] Test: Total time: 0:01:04 (0.1860 s / it)
[13:34:18.631325] Test:  [ 0/57]  eta: 0:00:33  loss: 0.4525 (0.4525)  time: 0.5790  data: 0.3993  max mem: 15824
[13:34:20.401941] Test:  [10/57]  eta: 0:00:10  loss: 0.4525 (0.4582)  time: 0.2135  data: 0.0364  max mem: 15824
[13:34:22.177347] Test:  [20/57]  eta: 0:00:07  loss: 0.4253 (0.4293)  time: 0.1772  data: 0.0001  max mem: 15824
[13:34:23.960390] Test:  [30/57]  eta: 0:00:05  loss: 0.3474 (0.3865)  time: 0.1779  data: 0.0001  max mem: 15824
[13:34:25.745563] Test:  [40/57]  eta: 0:00:03  loss: 0.2851 (0.3624)  time: 0.1783  data: 0.0001  max mem: 15824
[13:34:27.532162] Test:  [50/57]  eta: 0:00:01  loss: 0.2851 (0.3585)  time: 0.1785  data: 0.0001  max mem: 15824
[13:34:28.504514] Test:  [56/57]  eta: 0:00:00  loss: 0.3423 (0.3728)  time: 0.1736  data: 0.0001  max mem: 15824
[13:34:28.575912] Test: Total time: 0:00:10 (0.1846 s / it)
[13:34:30.297576] Dice score of the network on the train images: 0.723388, val images: 0.745293
[13:34:30.297810] saving best_dice_model_0 @ epoch 7
[13:34:31.492787] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:34:32.511737] Epoch: [8]  [  0/345]  eta: 0:05:51  lr: 0.000050  loss: 0.3250 (0.3250)  time: 1.0178  data: 0.3956  max mem: 15824
[13:34:44.837487] Epoch: [8]  [ 20/345]  eta: 0:03:26  lr: 0.000050  loss: 0.3374 (0.3425)  time: 0.6162  data: 0.0001  max mem: 15824
[13:34:57.187698] Epoch: [8]  [ 40/345]  eta: 0:03:11  lr: 0.000051  loss: 0.3358 (0.3424)  time: 0.6175  data: 0.0001  max mem: 15824
[13:35:09.561015] Epoch: [8]  [ 60/345]  eta: 0:02:57  lr: 0.000051  loss: 0.3360 (0.3455)  time: 0.6186  data: 0.0001  max mem: 15824
[13:35:21.938935] Epoch: [8]  [ 80/345]  eta: 0:02:45  lr: 0.000051  loss: 0.3399 (0.3431)  time: 0.6188  data: 0.0001  max mem: 15824
[13:35:34.349456] Epoch: [8]  [100/345]  eta: 0:02:32  lr: 0.000052  loss: 0.3217 (0.3414)  time: 0.6205  data: 0.0001  max mem: 15824
[13:35:46.776618] Epoch: [8]  [120/345]  eta: 0:02:19  lr: 0.000052  loss: 0.3481 (0.3415)  time: 0.6213  data: 0.0001  max mem: 15824
[13:35:59.206639] Epoch: [8]  [140/345]  eta: 0:02:07  lr: 0.000053  loss: 0.3270 (0.3402)  time: 0.6215  data: 0.0001  max mem: 15824
[13:36:11.642242] Epoch: [8]  [160/345]  eta: 0:01:55  lr: 0.000053  loss: 0.3386 (0.3399)  time: 0.6217  data: 0.0001  max mem: 15824
[13:36:24.067514] Epoch: [8]  [180/345]  eta: 0:01:42  lr: 0.000053  loss: 0.3503 (0.3410)  time: 0.6212  data: 0.0001  max mem: 15824
[13:36:36.492640] Epoch: [8]  [200/345]  eta: 0:01:30  lr: 0.000054  loss: 0.3419 (0.3404)  time: 0.6212  data: 0.0001  max mem: 15824
[13:36:48.895185] Epoch: [8]  [220/345]  eta: 0:01:17  lr: 0.000054  loss: 0.3069 (0.3392)  time: 0.6201  data: 0.0001  max mem: 15824
[13:37:01.285940] Epoch: [8]  [240/345]  eta: 0:01:05  lr: 0.000054  loss: 0.3240 (0.3391)  time: 0.6195  data: 0.0001  max mem: 15824
[13:37:13.707366] Epoch: [8]  [260/345]  eta: 0:00:52  lr: 0.000055  loss: 0.3270 (0.3393)  time: 0.6210  data: 0.0001  max mem: 15824
[13:37:26.119944] Epoch: [8]  [280/345]  eta: 0:00:40  lr: 0.000055  loss: 0.3325 (0.3396)  time: 0.6206  data: 0.0001  max mem: 15824
[13:37:38.510484] Epoch: [8]  [300/345]  eta: 0:00:27  lr: 0.000055  loss: 0.3295 (0.3396)  time: 0.6195  data: 0.0001  max mem: 15824
[13:37:50.888907] Epoch: [8]  [320/345]  eta: 0:00:15  lr: 0.000056  loss: 0.3376 (0.3392)  time: 0.6189  data: 0.0001  max mem: 15824
[13:38:03.262311] Epoch: [8]  [340/345]  eta: 0:00:03  lr: 0.000056  loss: 0.3387 (0.3395)  time: 0.6186  data: 0.0001  max mem: 15824
[13:38:05.732813] Epoch: [8]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.3457 (0.3395)  time: 0.6183  data: 0.0001  max mem: 15824
[13:38:05.815227] Epoch: [8] Total time: 0:03:34 (0.6212 s / it)
[13:38:05.815789] Averaged stats: lr: 0.000056  loss: 0.3457 (0.3395)
[13:38:06.380863] Test:  [  0/345]  eta: 0:03:13  loss: 0.3454 (0.3454)  time: 0.5599  data: 0.3763  max mem: 15824
[13:38:08.172149] Test:  [ 10/345]  eta: 0:01:11  loss: 0.2948 (0.3117)  time: 0.2137  data: 0.0343  max mem: 15824
[13:38:09.964219] Test:  [ 20/345]  eta: 0:01:04  loss: 0.2972 (0.3073)  time: 0.1791  data: 0.0001  max mem: 15824
[13:38:11.756185] Test:  [ 30/345]  eta: 0:01:00  loss: 0.3079 (0.3082)  time: 0.1791  data: 0.0001  max mem: 15824
[13:38:13.556773] Test:  [ 40/345]  eta: 0:00:57  loss: 0.3131 (0.3096)  time: 0.1796  data: 0.0001  max mem: 15824
[13:38:15.357998] Test:  [ 50/345]  eta: 0:00:55  loss: 0.3138 (0.3129)  time: 0.1800  data: 0.0001  max mem: 15824
[13:38:17.160051] Test:  [ 60/345]  eta: 0:00:52  loss: 0.3152 (0.3126)  time: 0.1801  data: 0.0001  max mem: 15824
[13:38:18.965544] Test:  [ 70/345]  eta: 0:00:50  loss: 0.3134 (0.3126)  time: 0.1803  data: 0.0001  max mem: 15824
[13:38:20.777059] Test:  [ 80/345]  eta: 0:00:48  loss: 0.3049 (0.3130)  time: 0.1808  data: 0.0001  max mem: 15824
[13:38:22.590768] Test:  [ 90/345]  eta: 0:00:46  loss: 0.2960 (0.3114)  time: 0.1812  data: 0.0001  max mem: 15824
[13:38:24.407542] Test:  [100/345]  eta: 0:00:45  loss: 0.2977 (0.3117)  time: 0.1815  data: 0.0001  max mem: 15824
[13:38:26.227202] Test:  [110/345]  eta: 0:00:43  loss: 0.3041 (0.3126)  time: 0.1818  data: 0.0001  max mem: 15824
[13:38:28.051543] Test:  [120/345]  eta: 0:00:41  loss: 0.3116 (0.3128)  time: 0.1821  data: 0.0001  max mem: 15824
[13:38:29.880345] Test:  [130/345]  eta: 0:00:39  loss: 0.3169 (0.3133)  time: 0.1826  data: 0.0001  max mem: 15824
[13:38:31.711096] Test:  [140/345]  eta: 0:00:37  loss: 0.3141 (0.3141)  time: 0.1829  data: 0.0001  max mem: 15824
[13:38:33.545058] Test:  [150/345]  eta: 0:00:35  loss: 0.3052 (0.3140)  time: 0.1832  data: 0.0001  max mem: 15824
[13:38:35.382526] Test:  [160/345]  eta: 0:00:33  loss: 0.3006 (0.3142)  time: 0.1835  data: 0.0001  max mem: 15824
[13:38:37.223625] Test:  [170/345]  eta: 0:00:32  loss: 0.3136 (0.3142)  time: 0.1839  data: 0.0001  max mem: 15824
[13:38:39.069671] Test:  [180/345]  eta: 0:00:30  loss: 0.3246 (0.3150)  time: 0.1843  data: 0.0001  max mem: 15824
[13:38:40.918674] Test:  [190/345]  eta: 0:00:28  loss: 0.3128 (0.3145)  time: 0.1847  data: 0.0001  max mem: 15824
[13:38:42.770684] Test:  [200/345]  eta: 0:00:26  loss: 0.2995 (0.3138)  time: 0.1850  data: 0.0001  max mem: 15824
[13:38:44.624673] Test:  [210/345]  eta: 0:00:24  loss: 0.3105 (0.3148)  time: 0.1852  data: 0.0001  max mem: 15824
[13:38:46.483318] Test:  [220/345]  eta: 0:00:22  loss: 0.3239 (0.3145)  time: 0.1856  data: 0.0001  max mem: 15824
[13:38:48.346093] Test:  [230/345]  eta: 0:00:21  loss: 0.2998 (0.3141)  time: 0.1860  data: 0.0001  max mem: 15824
[13:38:50.209809] Test:  [240/345]  eta: 0:00:19  loss: 0.2997 (0.3135)  time: 0.1863  data: 0.0001  max mem: 15824
[13:38:52.078245] Test:  [250/345]  eta: 0:00:17  loss: 0.3094 (0.3133)  time: 0.1865  data: 0.0001  max mem: 15824
[13:38:53.950567] Test:  [260/345]  eta: 0:00:15  loss: 0.3108 (0.3129)  time: 0.1870  data: 0.0001  max mem: 15824
[13:38:55.826520] Test:  [270/345]  eta: 0:00:13  loss: 0.3092 (0.3129)  time: 0.1874  data: 0.0001  max mem: 15824
[13:38:57.708751] Test:  [280/345]  eta: 0:00:11  loss: 0.3092 (0.3131)  time: 0.1878  data: 0.0001  max mem: 15824
[13:38:59.595937] Test:  [290/345]  eta: 0:00:10  loss: 0.3178 (0.3131)  time: 0.1884  data: 0.0001  max mem: 15824
[13:39:01.484619] Test:  [300/345]  eta: 0:00:08  loss: 0.3197 (0.3132)  time: 0.1887  data: 0.0001  max mem: 15824
[13:39:03.374772] Test:  [310/345]  eta: 0:00:06  loss: 0.3193 (0.3131)  time: 0.1889  data: 0.0001  max mem: 15824
[13:39:05.267776] Test:  [320/345]  eta: 0:00:04  loss: 0.3213 (0.3137)  time: 0.1891  data: 0.0001  max mem: 15824
[13:39:07.162052] Test:  [330/345]  eta: 0:00:02  loss: 0.3113 (0.3135)  time: 0.1893  data: 0.0001  max mem: 15824
[13:39:09.059467] Test:  [340/345]  eta: 0:00:00  loss: 0.3102 (0.3136)  time: 0.1895  data: 0.0001  max mem: 15824
[13:39:09.819505] Test:  [344/345]  eta: 0:00:00  loss: 0.3102 (0.3136)  time: 0.1896  data: 0.0001  max mem: 15824
[13:39:09.897379] Test: Total time: 0:01:04 (0.1857 s / it)
[13:39:20.344383] Test:  [ 0/57]  eta: 0:00:32  loss: 0.4717 (0.4717)  time: 0.5765  data: 0.3968  max mem: 15824
[13:39:22.119147] Test:  [10/57]  eta: 0:00:10  loss: 0.4580 (0.4641)  time: 0.2137  data: 0.0362  max mem: 15824
[13:39:23.891264] Test:  [20/57]  eta: 0:00:07  loss: 0.4310 (0.4368)  time: 0.1773  data: 0.0001  max mem: 15824
[13:39:25.670938] Test:  [30/57]  eta: 0:00:05  loss: 0.3121 (0.3897)  time: 0.1775  data: 0.0001  max mem: 15824
[13:39:27.457877] Test:  [40/57]  eta: 0:00:03  loss: 0.2891 (0.3641)  time: 0.1783  data: 0.0001  max mem: 15824
[13:39:29.248138] Test:  [50/57]  eta: 0:00:01  loss: 0.2980 (0.3606)  time: 0.1788  data: 0.0001  max mem: 15824
[13:39:30.220801] Test:  [56/57]  eta: 0:00:00  loss: 0.3378 (0.3721)  time: 0.1738  data: 0.0000  max mem: 15824
[13:39:30.284563] Test: Total time: 0:00:10 (0.1845 s / it)
[13:39:32.024400] Dice score of the network on the train images: 0.752015, val images: 0.753272
[13:39:32.024638] saving best_dice_model_0 @ epoch 8
[13:39:33.055396] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:39:34.065844] Epoch: [9]  [  0/345]  eta: 0:05:48  lr: 0.000056  loss: 0.3351 (0.3351)  time: 1.0094  data: 0.3869  max mem: 15824
[13:39:46.390772] Epoch: [9]  [ 20/345]  eta: 0:03:26  lr: 0.000057  loss: 0.3241 (0.3286)  time: 0.6162  data: 0.0001  max mem: 15824
[13:39:58.751014] Epoch: [9]  [ 40/345]  eta: 0:03:11  lr: 0.000057  loss: 0.3310 (0.3281)  time: 0.6180  data: 0.0001  max mem: 15824
[13:40:11.123760] Epoch: [9]  [ 60/345]  eta: 0:02:57  lr: 0.000057  loss: 0.3346 (0.3323)  time: 0.6186  data: 0.0001  max mem: 15824
[13:40:23.522084] Epoch: [9]  [ 80/345]  eta: 0:02:45  lr: 0.000058  loss: 0.3280 (0.3299)  time: 0.6199  data: 0.0001  max mem: 15824
[13:40:35.940002] Epoch: [9]  [100/345]  eta: 0:02:32  lr: 0.000058  loss: 0.3135 (0.3263)  time: 0.6208  data: 0.0001  max mem: 15824
[13:40:48.365805] Epoch: [9]  [120/345]  eta: 0:02:20  lr: 0.000058  loss: 0.3099 (0.3248)  time: 0.6212  data: 0.0001  max mem: 15824
[13:41:00.789342] Epoch: [9]  [140/345]  eta: 0:02:07  lr: 0.000059  loss: 0.3116 (0.3224)  time: 0.6211  data: 0.0001  max mem: 15824
[13:41:13.194949] Epoch: [9]  [160/345]  eta: 0:01:55  lr: 0.000059  loss: 0.3308 (0.3243)  time: 0.6202  data: 0.0001  max mem: 15824
[13:41:25.610723] Epoch: [9]  [180/345]  eta: 0:01:42  lr: 0.000060  loss: 0.3276 (0.3240)  time: 0.6207  data: 0.0001  max mem: 15824
[13:41:38.053032] Epoch: [9]  [200/345]  eta: 0:01:30  lr: 0.000060  loss: 0.2929 (0.3219)  time: 0.6221  data: 0.0001  max mem: 15824
[13:41:50.486951] Epoch: [9]  [220/345]  eta: 0:01:17  lr: 0.000060  loss: 0.3124 (0.3215)  time: 0.6216  data: 0.0001  max mem: 15824
[13:42:02.910759] Epoch: [9]  [240/345]  eta: 0:01:05  lr: 0.000061  loss: 0.3067 (0.3204)  time: 0.6211  data: 0.0001  max mem: 15824
[13:42:15.316800] Epoch: [9]  [260/345]  eta: 0:00:52  lr: 0.000061  loss: 0.3076 (0.3204)  time: 0.6203  data: 0.0001  max mem: 15824
[13:42:27.729175] Epoch: [9]  [280/345]  eta: 0:00:40  lr: 0.000061  loss: 0.3125 (0.3206)  time: 0.6206  data: 0.0001  max mem: 15824
[13:42:40.143400] Epoch: [9]  [300/345]  eta: 0:00:27  lr: 0.000062  loss: 0.2991 (0.3199)  time: 0.6207  data: 0.0001  max mem: 15824
[13:42:52.547534] Epoch: [9]  [320/345]  eta: 0:00:15  lr: 0.000062  loss: 0.3034 (0.3194)  time: 0.6202  data: 0.0001  max mem: 15824
[13:43:04.929926] Epoch: [9]  [340/345]  eta: 0:00:03  lr: 0.000062  loss: 0.3159 (0.3193)  time: 0.6191  data: 0.0001  max mem: 15824
[13:43:07.406881] Epoch: [9]  [344/345]  eta: 0:00:00  lr: 0.000062  loss: 0.3237 (0.3195)  time: 0.6188  data: 0.0001  max mem: 15824
[13:43:07.474370] Epoch: [9] Total time: 0:03:34 (0.6215 s / it)
[13:43:07.474601] Averaged stats: lr: 0.000062  loss: 0.3237 (0.3195)
[13:43:08.053817] Test:  [  0/345]  eta: 0:03:17  loss: 0.3171 (0.3171)  time: 0.5734  data: 0.3915  max mem: 15824
[13:43:09.839081] Test:  [ 10/345]  eta: 0:01:11  loss: 0.3087 (0.3161)  time: 0.2143  data: 0.0357  max mem: 15824
[13:43:11.633570] Test:  [ 20/345]  eta: 0:01:04  loss: 0.3110 (0.3188)  time: 0.1789  data: 0.0001  max mem: 15824
[13:43:13.427350] Test:  [ 30/345]  eta: 0:01:00  loss: 0.3037 (0.3139)  time: 0.1794  data: 0.0001  max mem: 15824
[13:43:15.224315] Test:  [ 40/345]  eta: 0:00:57  loss: 0.2991 (0.3102)  time: 0.1795  data: 0.0001  max mem: 15824
[13:43:17.025482] Test:  [ 50/345]  eta: 0:00:55  loss: 0.2933 (0.3090)  time: 0.1798  data: 0.0001  max mem: 15824
[13:43:18.827572] Test:  [ 60/345]  eta: 0:00:52  loss: 0.3064 (0.3113)  time: 0.1801  data: 0.0001  max mem: 15824
[13:43:20.636641] Test:  [ 70/345]  eta: 0:00:50  loss: 0.3064 (0.3119)  time: 0.1805  data: 0.0001  max mem: 15824
[13:43:22.447280] Test:  [ 80/345]  eta: 0:00:48  loss: 0.3027 (0.3132)  time: 0.1809  data: 0.0001  max mem: 15824
[13:43:24.264306] Test:  [ 90/345]  eta: 0:00:47  loss: 0.3001 (0.3121)  time: 0.1813  data: 0.0001  max mem: 15824
[13:43:26.085088] Test:  [100/345]  eta: 0:00:45  loss: 0.3001 (0.3116)  time: 0.1818  data: 0.0001  max mem: 15824
[13:43:27.907364] Test:  [110/345]  eta: 0:00:43  loss: 0.3095 (0.3109)  time: 0.1821  data: 0.0001  max mem: 15824
[13:43:29.733650] Test:  [120/345]  eta: 0:00:41  loss: 0.3036 (0.3101)  time: 0.1824  data: 0.0001  max mem: 15824
[13:43:31.563516] Test:  [130/345]  eta: 0:00:39  loss: 0.3017 (0.3088)  time: 0.1827  data: 0.0001  max mem: 15824
[13:43:33.395298] Test:  [140/345]  eta: 0:00:37  loss: 0.2864 (0.3079)  time: 0.1830  data: 0.0001  max mem: 15824
[13:43:35.231021] Test:  [150/345]  eta: 0:00:35  loss: 0.2905 (0.3073)  time: 0.1833  data: 0.0001  max mem: 15824
[13:43:37.070798] Test:  [160/345]  eta: 0:00:33  loss: 0.3032 (0.3076)  time: 0.1837  data: 0.0001  max mem: 15824
[13:43:38.917509] Test:  [170/345]  eta: 0:00:32  loss: 0.3012 (0.3070)  time: 0.1843  data: 0.0001  max mem: 15824
[13:43:40.764221] Test:  [180/345]  eta: 0:00:30  loss: 0.2915 (0.3062)  time: 0.1846  data: 0.0001  max mem: 15824
[13:43:42.615638] Test:  [190/345]  eta: 0:00:28  loss: 0.2916 (0.3054)  time: 0.1848  data: 0.0001  max mem: 15824
[13:43:44.470456] Test:  [200/345]  eta: 0:00:26  loss: 0.2968 (0.3058)  time: 0.1852  data: 0.0001  max mem: 15824
[13:43:46.326649] Test:  [210/345]  eta: 0:00:24  loss: 0.2954 (0.3050)  time: 0.1855  data: 0.0001  max mem: 15824
[13:43:48.185843] Test:  [220/345]  eta: 0:00:23  loss: 0.2954 (0.3055)  time: 0.1857  data: 0.0001  max mem: 15824
[13:43:50.049389] Test:  [230/345]  eta: 0:00:21  loss: 0.3272 (0.3063)  time: 0.1861  data: 0.0001  max mem: 15824
[13:43:51.917619] Test:  [240/345]  eta: 0:00:19  loss: 0.3200 (0.3063)  time: 0.1865  data: 0.0001  max mem: 15824
[13:43:53.790407] Test:  [250/345]  eta: 0:00:17  loss: 0.3044 (0.3063)  time: 0.1870  data: 0.0001  max mem: 15824
[13:43:55.664216] Test:  [260/345]  eta: 0:00:15  loss: 0.3089 (0.3069)  time: 0.1873  data: 0.0001  max mem: 15824
[13:43:57.543431] Test:  [270/345]  eta: 0:00:13  loss: 0.3145 (0.3073)  time: 0.1876  data: 0.0001  max mem: 15824
[13:43:59.423008] Test:  [280/345]  eta: 0:00:12  loss: 0.3245 (0.3079)  time: 0.1879  data: 0.0001  max mem: 15824
[13:44:01.308140] Test:  [290/345]  eta: 0:00:10  loss: 0.3155 (0.3080)  time: 0.1882  data: 0.0001  max mem: 15824
[13:44:03.196074] Test:  [300/345]  eta: 0:00:08  loss: 0.3102 (0.3074)  time: 0.1886  data: 0.0001  max mem: 15824
[13:44:05.088105] Test:  [310/345]  eta: 0:00:06  loss: 0.2973 (0.3072)  time: 0.1889  data: 0.0001  max mem: 15824
[13:44:06.983226] Test:  [320/345]  eta: 0:00:04  loss: 0.2973 (0.3067)  time: 0.1893  data: 0.0001  max mem: 15824
[13:44:08.883725] Test:  [330/345]  eta: 0:00:02  loss: 0.2987 (0.3067)  time: 0.1897  data: 0.0001  max mem: 15824
[13:44:10.782963] Test:  [340/345]  eta: 0:00:00  loss: 0.2881 (0.3060)  time: 0.1899  data: 0.0001  max mem: 15824
[13:44:11.544239] Test:  [344/345]  eta: 0:00:00  loss: 0.2853 (0.3058)  time: 0.1900  data: 0.0001  max mem: 15824
[13:44:11.618198] Test: Total time: 0:01:04 (0.1859 s / it)
[13:44:22.066890] Test:  [ 0/57]  eta: 0:00:32  loss: 0.5136 (0.5136)  time: 0.5633  data: 0.3817  max mem: 15824
[13:44:23.837881] Test:  [10/57]  eta: 0:00:09  loss: 0.4439 (0.4582)  time: 0.2121  data: 0.0348  max mem: 15824
[13:44:25.614075] Test:  [20/57]  eta: 0:00:07  loss: 0.4267 (0.4409)  time: 0.1773  data: 0.0001  max mem: 15824
[13:44:27.392148] Test:  [30/57]  eta: 0:00:05  loss: 0.3409 (0.3925)  time: 0.1776  data: 0.0001  max mem: 15824
[13:44:29.175755] Test:  [40/57]  eta: 0:00:03  loss: 0.2820 (0.3662)  time: 0.1780  data: 0.0001  max mem: 15824
[13:44:30.964858] Test:  [50/57]  eta: 0:00:01  loss: 0.2928 (0.3672)  time: 0.1786  data: 0.0001  max mem: 15824
[13:44:31.936738] Test:  [56/57]  eta: 0:00:00  loss: 0.3531 (0.3800)  time: 0.1736  data: 0.0000  max mem: 15824
[13:44:32.009631] Test: Total time: 0:00:10 (0.1843 s / it)
[13:44:33.720336] Dice score of the network on the train images: 0.737646, val images: 0.748770
[13:44:33.723950] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:44:34.706535] Epoch: [10]  [  0/345]  eta: 0:05:38  lr: 0.000063  loss: 0.3064 (0.3064)  time: 0.9817  data: 0.3575  max mem: 15824
[13:44:47.146229] Epoch: [10]  [ 20/345]  eta: 0:03:27  lr: 0.000063  loss: 0.3173 (0.3138)  time: 0.6219  data: 0.0001  max mem: 15824
[13:44:59.500750] Epoch: [10]  [ 40/345]  eta: 0:03:11  lr: 0.000063  loss: 0.2969 (0.3103)  time: 0.6177  data: 0.0001  max mem: 15824
[13:45:11.888953] Epoch: [10]  [ 60/345]  eta: 0:02:58  lr: 0.000064  loss: 0.2935 (0.3074)  time: 0.6194  data: 0.0001  max mem: 15824
[13:45:24.289383] Epoch: [10]  [ 80/345]  eta: 0:02:45  lr: 0.000064  loss: 0.3037 (0.3073)  time: 0.6200  data: 0.0001  max mem: 15824
[13:45:36.695472] Epoch: [10]  [100/345]  eta: 0:02:32  lr: 0.000064  loss: 0.3018 (0.3058)  time: 0.6203  data: 0.0001  max mem: 15824
[13:45:49.131267] Epoch: [10]  [120/345]  eta: 0:02:20  lr: 0.000065  loss: 0.2979 (0.3042)  time: 0.6217  data: 0.0001  max mem: 15824
[13:46:01.561010] Epoch: [10]  [140/345]  eta: 0:02:07  lr: 0.000065  loss: 0.2882 (0.3027)  time: 0.6214  data: 0.0001  max mem: 15824
[13:46:14.001839] Epoch: [10]  [160/345]  eta: 0:01:55  lr: 0.000065  loss: 0.2866 (0.3016)  time: 0.6220  data: 0.0001  max mem: 15824
[13:46:26.389262] Epoch: [10]  [180/345]  eta: 0:01:42  lr: 0.000066  loss: 0.2754 (0.3011)  time: 0.6193  data: 0.0001  max mem: 15824
[13:46:38.805063] Epoch: [10]  [200/345]  eta: 0:01:30  lr: 0.000066  loss: 0.3200 (0.3035)  time: 0.6207  data: 0.0001  max mem: 15824
[13:46:51.231329] Epoch: [10]  [220/345]  eta: 0:01:17  lr: 0.000066  loss: 0.2852 (0.3022)  time: 0.6213  data: 0.0001  max mem: 15824
[13:47:03.673302] Epoch: [10]  [240/345]  eta: 0:01:05  lr: 0.000067  loss: 0.2975 (0.3018)  time: 0.6221  data: 0.0001  max mem: 15824
[13:47:16.070174] Epoch: [10]  [260/345]  eta: 0:00:52  lr: 0.000067  loss: 0.2948 (0.3014)  time: 0.6198  data: 0.0001  max mem: 15824
[13:47:28.462471] Epoch: [10]  [280/345]  eta: 0:00:40  lr: 0.000068  loss: 0.2976 (0.3011)  time: 0.6196  data: 0.0001  max mem: 15824
[13:47:40.838870] Epoch: [10]  [300/345]  eta: 0:00:27  lr: 0.000068  loss: 0.2900 (0.3005)  time: 0.6188  data: 0.0001  max mem: 15824
[13:47:53.238190] Epoch: [10]  [320/345]  eta: 0:00:15  lr: 0.000068  loss: 0.2962 (0.3001)  time: 0.6199  data: 0.0001  max mem: 15824
[13:48:05.625853] Epoch: [10]  [340/345]  eta: 0:00:03  lr: 0.000069  loss: 0.2838 (0.2992)  time: 0.6193  data: 0.0001  max mem: 15824
[13:48:08.096112] Epoch: [10]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.2960 (0.2993)  time: 0.6190  data: 0.0001  max mem: 15824
[13:48:08.173082] Epoch: [10] Total time: 0:03:34 (0.6216 s / it)
[13:48:08.173441] Averaged stats: lr: 0.000069  loss: 0.2960 (0.2993)
[13:48:08.821498] Test:  [  0/345]  eta: 0:03:41  loss: 0.2545 (0.2545)  time: 0.6429  data: 0.4607  max mem: 15824
[13:48:10.612298] Test:  [ 10/345]  eta: 0:01:14  loss: 0.2824 (0.2882)  time: 0.2212  data: 0.0420  max mem: 15824
[13:48:12.403865] Test:  [ 20/345]  eta: 0:01:05  loss: 0.2824 (0.2883)  time: 0.1790  data: 0.0001  max mem: 15824
[13:48:14.202545] Test:  [ 30/345]  eta: 0:01:01  loss: 0.2726 (0.2834)  time: 0.1795  data: 0.0001  max mem: 15824
[13:48:16.003364] Test:  [ 40/345]  eta: 0:00:58  loss: 0.2726 (0.2841)  time: 0.1799  data: 0.0001  max mem: 15824
[13:48:17.805107] Test:  [ 50/345]  eta: 0:00:55  loss: 0.2779 (0.2825)  time: 0.1801  data: 0.0001  max mem: 15824
[13:48:19.607759] Test:  [ 60/345]  eta: 0:00:53  loss: 0.2693 (0.2801)  time: 0.1802  data: 0.0001  max mem: 15824
[13:48:21.413873] Test:  [ 70/345]  eta: 0:00:51  loss: 0.2683 (0.2792)  time: 0.1804  data: 0.0001  max mem: 15824
[13:48:23.227705] Test:  [ 80/345]  eta: 0:00:49  loss: 0.2683 (0.2785)  time: 0.1809  data: 0.0001  max mem: 15824
[13:48:25.041915] Test:  [ 90/345]  eta: 0:00:47  loss: 0.2685 (0.2796)  time: 0.1813  data: 0.0001  max mem: 15824
[13:48:26.861441] Test:  [100/345]  eta: 0:00:45  loss: 0.2729 (0.2793)  time: 0.1816  data: 0.0001  max mem: 15824
[13:48:28.683763] Test:  [110/345]  eta: 0:00:43  loss: 0.2761 (0.2803)  time: 0.1820  data: 0.0001  max mem: 15824
[13:48:30.508753] Test:  [120/345]  eta: 0:00:41  loss: 0.2911 (0.2812)  time: 0.1823  data: 0.0001  max mem: 15824
[13:48:32.341640] Test:  [130/345]  eta: 0:00:39  loss: 0.2794 (0.2800)  time: 0.1828  data: 0.0001  max mem: 15824
[13:48:34.174123] Test:  [140/345]  eta: 0:00:37  loss: 0.2794 (0.2809)  time: 0.1832  data: 0.0001  max mem: 15824
[13:48:36.011312] Test:  [150/345]  eta: 0:00:35  loss: 0.2893 (0.2812)  time: 0.1834  data: 0.0001  max mem: 15824
[13:48:37.850958] Test:  [160/345]  eta: 0:00:34  loss: 0.2712 (0.2807)  time: 0.1838  data: 0.0001  max mem: 15824
[13:48:39.695589] Test:  [170/345]  eta: 0:00:32  loss: 0.2818 (0.2815)  time: 0.1842  data: 0.0001  max mem: 15824
[13:48:41.543406] Test:  [180/345]  eta: 0:00:30  loss: 0.2833 (0.2816)  time: 0.1846  data: 0.0001  max mem: 15824
[13:48:43.393745] Test:  [190/345]  eta: 0:00:28  loss: 0.2780 (0.2819)  time: 0.1848  data: 0.0001  max mem: 15824
[13:48:45.250684] Test:  [200/345]  eta: 0:00:26  loss: 0.2774 (0.2819)  time: 0.1853  data: 0.0001  max mem: 15824
[13:48:47.108144] Test:  [210/345]  eta: 0:00:24  loss: 0.2831 (0.2821)  time: 0.1856  data: 0.0001  max mem: 15824
[13:48:48.968330] Test:  [220/345]  eta: 0:00:23  loss: 0.2836 (0.2823)  time: 0.1858  data: 0.0001  max mem: 15824
[13:48:50.832503] Test:  [230/345]  eta: 0:00:21  loss: 0.2827 (0.2824)  time: 0.1862  data: 0.0001  max mem: 15824
[13:48:52.700658] Test:  [240/345]  eta: 0:00:19  loss: 0.2827 (0.2828)  time: 0.1866  data: 0.0001  max mem: 15824
[13:48:54.573506] Test:  [250/345]  eta: 0:00:17  loss: 0.2725 (0.2821)  time: 0.1870  data: 0.0001  max mem: 15824
[13:48:56.450701] Test:  [260/345]  eta: 0:00:15  loss: 0.2725 (0.2820)  time: 0.1874  data: 0.0001  max mem: 15824
[13:48:58.329589] Test:  [270/345]  eta: 0:00:13  loss: 0.2725 (0.2818)  time: 0.1877  data: 0.0001  max mem: 15824
[13:49:00.211330] Test:  [280/345]  eta: 0:00:12  loss: 0.2738 (0.2821)  time: 0.1880  data: 0.0001  max mem: 15824
[13:49:02.095774] Test:  [290/345]  eta: 0:00:10  loss: 0.2796 (0.2818)  time: 0.1882  data: 0.0001  max mem: 15824
[13:49:03.984491] Test:  [300/345]  eta: 0:00:08  loss: 0.2796 (0.2819)  time: 0.1886  data: 0.0001  max mem: 15824
[13:49:05.877606] Test:  [310/345]  eta: 0:00:06  loss: 0.2680 (0.2818)  time: 0.1890  data: 0.0001  max mem: 15824
[13:49:07.775134] Test:  [320/345]  eta: 0:00:04  loss: 0.2874 (0.2821)  time: 0.1895  data: 0.0001  max mem: 15824
[13:49:09.676338] Test:  [330/345]  eta: 0:00:02  loss: 0.2934 (0.2823)  time: 0.1899  data: 0.0001  max mem: 15824
[13:49:11.576436] Test:  [340/345]  eta: 0:00:00  loss: 0.2739 (0.2823)  time: 0.1900  data: 0.0001  max mem: 15824
[13:49:12.337674] Test:  [344/345]  eta: 0:00:00  loss: 0.2706 (0.2821)  time: 0.1900  data: 0.0001  max mem: 15824
[13:49:12.415615] Test: Total time: 0:01:04 (0.1862 s / it)
[13:49:22.883815] Test:  [ 0/57]  eta: 0:00:31  loss: 0.5056 (0.5056)  time: 0.5474  data: 0.3673  max mem: 15824
[13:49:24.655878] Test:  [10/57]  eta: 0:00:09  loss: 0.4588 (0.4729)  time: 0.2108  data: 0.0335  max mem: 15824
[13:49:26.434439] Test:  [20/57]  eta: 0:00:07  loss: 0.4256 (0.4432)  time: 0.1775  data: 0.0001  max mem: 15824
[13:49:28.215549] Test:  [30/57]  eta: 0:00:05  loss: 0.3499 (0.4020)  time: 0.1779  data: 0.0001  max mem: 15824
[13:49:30.001728] Test:  [40/57]  eta: 0:00:03  loss: 0.3259 (0.3862)  time: 0.1783  data: 0.0001  max mem: 15824
[13:49:31.788355] Test:  [50/57]  eta: 0:00:01  loss: 0.3470 (0.3906)  time: 0.1786  data: 0.0001  max mem: 15824
[13:49:32.760287] Test:  [56/57]  eta: 0:00:00  loss: 0.3810 (0.4091)  time: 0.1735  data: 0.0000  max mem: 15824
[13:49:32.834923] Test: Total time: 0:00:10 (0.1842 s / it)
[13:49:34.574852] Dice score of the network on the train images: 0.773230, val images: 0.724935
[13:49:34.578989] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:49:35.573392] Epoch: [11]  [  0/345]  eta: 0:05:42  lr: 0.000069  loss: 0.3295 (0.3295)  time: 0.9933  data: 0.3707  max mem: 15824
[13:49:47.896734] Epoch: [11]  [ 20/345]  eta: 0:03:26  lr: 0.000069  loss: 0.2748 (0.2762)  time: 0.6161  data: 0.0001  max mem: 15824
[13:50:00.249069] Epoch: [11]  [ 40/345]  eta: 0:03:10  lr: 0.000069  loss: 0.2858 (0.2816)  time: 0.6176  data: 0.0001  max mem: 15824
[13:50:12.637477] Epoch: [11]  [ 60/345]  eta: 0:02:57  lr: 0.000070  loss: 0.2763 (0.2794)  time: 0.6194  data: 0.0001  max mem: 15824
[13:50:25.038466] Epoch: [11]  [ 80/345]  eta: 0:02:45  lr: 0.000070  loss: 0.2801 (0.2810)  time: 0.6200  data: 0.0001  max mem: 15824
[13:50:37.427088] Epoch: [11]  [100/345]  eta: 0:02:32  lr: 0.000071  loss: 0.2735 (0.2813)  time: 0.6194  data: 0.0001  max mem: 15824
[13:50:49.828638] Epoch: [11]  [120/345]  eta: 0:02:19  lr: 0.000071  loss: 0.2937 (0.2828)  time: 0.6200  data: 0.0001  max mem: 15824
[13:51:02.235691] Epoch: [11]  [140/345]  eta: 0:02:07  lr: 0.000071  loss: 0.2768 (0.2823)  time: 0.6203  data: 0.0001  max mem: 15824
[13:51:14.660522] Epoch: [11]  [160/345]  eta: 0:01:54  lr: 0.000072  loss: 0.2796 (0.2831)  time: 0.6212  data: 0.0001  max mem: 15824
[13:51:27.074859] Epoch: [11]  [180/345]  eta: 0:01:42  lr: 0.000072  loss: 0.2774 (0.2835)  time: 0.6207  data: 0.0001  max mem: 15824
[13:51:39.470244] Epoch: [11]  [200/345]  eta: 0:01:30  lr: 0.000072  loss: 0.2893 (0.2847)  time: 0.6197  data: 0.0001  max mem: 15824
[13:51:51.908803] Epoch: [11]  [220/345]  eta: 0:01:17  lr: 0.000073  loss: 0.2809 (0.2845)  time: 0.6219  data: 0.0001  max mem: 15824
[13:52:04.341917] Epoch: [11]  [240/345]  eta: 0:01:05  lr: 0.000073  loss: 0.2735 (0.2849)  time: 0.6216  data: 0.0001  max mem: 15824
[13:52:16.763002] Epoch: [11]  [260/345]  eta: 0:00:52  lr: 0.000073  loss: 0.2902 (0.2854)  time: 0.6210  data: 0.0001  max mem: 15824
[13:52:29.192740] Epoch: [11]  [280/345]  eta: 0:00:40  lr: 0.000074  loss: 0.2950 (0.2865)  time: 0.6214  data: 0.0001  max mem: 15824
[13:52:41.621425] Epoch: [11]  [300/345]  eta: 0:00:27  lr: 0.000074  loss: 0.2803 (0.2861)  time: 0.6214  data: 0.0001  max mem: 15824
[13:52:54.032185] Epoch: [11]  [320/345]  eta: 0:00:15  lr: 0.000075  loss: 0.2755 (0.2861)  time: 0.6205  data: 0.0001  max mem: 15824
[13:53:06.441789] Epoch: [11]  [340/345]  eta: 0:00:03  lr: 0.000075  loss: 0.2766 (0.2860)  time: 0.6204  data: 0.0001  max mem: 15824
[13:53:08.924407] Epoch: [11]  [344/345]  eta: 0:00:00  lr: 0.000075  loss: 0.2823 (0.2861)  time: 0.6203  data: 0.0001  max mem: 15824
[13:53:08.997215] Epoch: [11] Total time: 0:03:34 (0.6215 s / it)
[13:53:08.997698] Averaged stats: lr: 0.000075  loss: 0.2823 (0.2861)
[13:53:09.587081] Test:  [  0/345]  eta: 0:03:21  loss: 0.3015 (0.3015)  time: 0.5842  data: 0.4013  max mem: 15824
[13:53:11.380417] Test:  [ 10/345]  eta: 0:01:12  loss: 0.2650 (0.2741)  time: 0.2161  data: 0.0366  max mem: 15824
[13:53:13.169888] Test:  [ 20/345]  eta: 0:01:04  loss: 0.2643 (0.2691)  time: 0.1791  data: 0.0001  max mem: 15824
[13:53:14.966465] Test:  [ 30/345]  eta: 0:01:00  loss: 0.2643 (0.2726)  time: 0.1792  data: 0.0001  max mem: 15824
[13:53:16.766499] Test:  [ 40/345]  eta: 0:00:57  loss: 0.2618 (0.2729)  time: 0.1798  data: 0.0001  max mem: 15824
[13:53:18.568301] Test:  [ 50/345]  eta: 0:00:55  loss: 0.2701 (0.2736)  time: 0.1800  data: 0.0001  max mem: 15824
[13:53:20.373217] Test:  [ 60/345]  eta: 0:00:53  loss: 0.2740 (0.2735)  time: 0.1803  data: 0.0001  max mem: 15824
[13:53:22.180223] Test:  [ 70/345]  eta: 0:00:51  loss: 0.2715 (0.2753)  time: 0.1805  data: 0.0001  max mem: 15824
[13:53:23.992880] Test:  [ 80/345]  eta: 0:00:49  loss: 0.2715 (0.2752)  time: 0.1809  data: 0.0001  max mem: 15824
[13:53:25.810254] Test:  [ 90/345]  eta: 0:00:47  loss: 0.2650 (0.2737)  time: 0.1814  data: 0.0001  max mem: 15824
[13:53:27.630693] Test:  [100/345]  eta: 0:00:45  loss: 0.2606 (0.2727)  time: 0.1818  data: 0.0001  max mem: 15824
[13:53:29.452160] Test:  [110/345]  eta: 0:00:43  loss: 0.2729 (0.2731)  time: 0.1820  data: 0.0001  max mem: 15824
[13:53:31.275874] Test:  [120/345]  eta: 0:00:41  loss: 0.2797 (0.2740)  time: 0.1822  data: 0.0001  max mem: 15824
[13:53:33.106365] Test:  [130/345]  eta: 0:00:39  loss: 0.2760 (0.2740)  time: 0.1826  data: 0.0001  max mem: 15824
[13:53:34.937875] Test:  [140/345]  eta: 0:00:37  loss: 0.2806 (0.2749)  time: 0.1830  data: 0.0001  max mem: 15824
[13:53:36.774519] Test:  [150/345]  eta: 0:00:35  loss: 0.2756 (0.2744)  time: 0.1833  data: 0.0001  max mem: 15824
[13:53:38.614340] Test:  [160/345]  eta: 0:00:34  loss: 0.2564 (0.2732)  time: 0.1838  data: 0.0001  max mem: 15824
[13:53:40.458621] Test:  [170/345]  eta: 0:00:32  loss: 0.2658 (0.2731)  time: 0.1841  data: 0.0001  max mem: 15824
[13:53:42.305308] Test:  [180/345]  eta: 0:00:30  loss: 0.2722 (0.2731)  time: 0.1845  data: 0.0001  max mem: 15824
[13:53:44.155362] Test:  [190/345]  eta: 0:00:28  loss: 0.2598 (0.2726)  time: 0.1848  data: 0.0001  max mem: 15824
[13:53:46.009946] Test:  [200/345]  eta: 0:00:26  loss: 0.2575 (0.2719)  time: 0.1852  data: 0.0001  max mem: 15824
[13:53:47.867558] Test:  [210/345]  eta: 0:00:24  loss: 0.2600 (0.2715)  time: 0.1855  data: 0.0001  max mem: 15824
[13:53:49.728702] Test:  [220/345]  eta: 0:00:23  loss: 0.2759 (0.2722)  time: 0.1859  data: 0.0001  max mem: 15824
[13:53:51.592279] Test:  [230/345]  eta: 0:00:21  loss: 0.2874 (0.2722)  time: 0.1862  data: 0.0001  max mem: 15824
[13:53:53.460742] Test:  [240/345]  eta: 0:00:19  loss: 0.2694 (0.2721)  time: 0.1865  data: 0.0001  max mem: 15824
[13:53:55.333037] Test:  [250/345]  eta: 0:00:17  loss: 0.2667 (0.2719)  time: 0.1870  data: 0.0001  max mem: 15824
[13:53:57.207723] Test:  [260/345]  eta: 0:00:15  loss: 0.2595 (0.2715)  time: 0.1873  data: 0.0001  max mem: 15824
[13:53:59.086575] Test:  [270/345]  eta: 0:00:13  loss: 0.2692 (0.2715)  time: 0.1876  data: 0.0001  max mem: 15824
[13:54:00.968503] Test:  [280/345]  eta: 0:00:12  loss: 0.2692 (0.2713)  time: 0.1880  data: 0.0001  max mem: 15824
[13:54:02.853026] Test:  [290/345]  eta: 0:00:10  loss: 0.2591 (0.2710)  time: 0.1883  data: 0.0001  max mem: 15824
[13:54:04.742428] Test:  [300/345]  eta: 0:00:08  loss: 0.2604 (0.2711)  time: 0.1886  data: 0.0001  max mem: 15824
[13:54:06.633804] Test:  [310/345]  eta: 0:00:06  loss: 0.2742 (0.2713)  time: 0.1890  data: 0.0001  max mem: 15824
[13:54:08.528708] Test:  [320/345]  eta: 0:00:04  loss: 0.2742 (0.2714)  time: 0.1892  data: 0.0001  max mem: 15824
[13:54:10.428018] Test:  [330/345]  eta: 0:00:02  loss: 0.2812 (0.2717)  time: 0.1896  data: 0.0001  max mem: 15824
[13:54:12.328383] Test:  [340/345]  eta: 0:00:00  loss: 0.2713 (0.2718)  time: 0.1899  data: 0.0001  max mem: 15824
[13:54:13.089323] Test:  [344/345]  eta: 0:00:00  loss: 0.2710 (0.2716)  time: 0.1900  data: 0.0001  max mem: 15824
[13:54:13.158332] Test: Total time: 0:01:04 (0.1860 s / it)
[13:54:23.536361] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4346 (0.4346)  time: 0.5503  data: 0.3702  max mem: 15824
[13:54:25.304904] Test:  [10/57]  eta: 0:00:09  loss: 0.4346 (0.4580)  time: 0.2107  data: 0.0337  max mem: 15824
[13:54:27.081032] Test:  [20/57]  eta: 0:00:07  loss: 0.3992 (0.4284)  time: 0.1772  data: 0.0001  max mem: 15824
[13:54:28.860951] Test:  [30/57]  eta: 0:00:05  loss: 0.2901 (0.3733)  time: 0.1777  data: 0.0001  max mem: 15824
[13:54:30.645813] Test:  [40/57]  eta: 0:00:03  loss: 0.2395 (0.3406)  time: 0.1782  data: 0.0001  max mem: 15824
[13:54:32.431701] Test:  [50/57]  eta: 0:00:01  loss: 0.2470 (0.3381)  time: 0.1785  data: 0.0001  max mem: 15824
[13:54:33.402426] Test:  [56/57]  eta: 0:00:00  loss: 0.3066 (0.3539)  time: 0.1734  data: 0.0001  max mem: 15824
[13:54:33.469949] Test: Total time: 0:00:10 (0.1839 s / it)
[13:54:35.193424] Dice score of the network on the train images: 0.759182, val images: 0.779863
[13:54:35.193649] saving best_rec_model_0 @ epoch 11
[13:54:36.348541] saving best_dice_model_0 @ epoch 11
[13:54:37.345684] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:54:38.342997] Epoch: [12]  [  0/345]  eta: 0:05:43  lr: 0.000075  loss: 0.3118 (0.3118)  time: 0.9962  data: 0.3725  max mem: 15824
[13:54:50.658140] Epoch: [12]  [ 20/345]  eta: 0:03:25  lr: 0.000075  loss: 0.2728 (0.2791)  time: 0.6157  data: 0.0001  max mem: 15824
[13:55:03.016939] Epoch: [12]  [ 40/345]  eta: 0:03:10  lr: 0.000076  loss: 0.2839 (0.2811)  time: 0.6179  data: 0.0001  max mem: 15824
[13:55:15.396483] Epoch: [12]  [ 60/345]  eta: 0:02:57  lr: 0.000076  loss: 0.2618 (0.2766)  time: 0.6189  data: 0.0001  max mem: 15824
[13:55:27.794762] Epoch: [12]  [ 80/345]  eta: 0:02:45  lr: 0.000076  loss: 0.2662 (0.2744)  time: 0.6199  data: 0.0001  max mem: 15824
[13:55:40.197878] Epoch: [12]  [100/345]  eta: 0:02:32  lr: 0.000077  loss: 0.2682 (0.2737)  time: 0.6201  data: 0.0001  max mem: 15824
[13:55:52.623477] Epoch: [12]  [120/345]  eta: 0:02:19  lr: 0.000077  loss: 0.2683 (0.2740)  time: 0.6212  data: 0.0001  max mem: 15824
[13:56:05.069987] Epoch: [12]  [140/345]  eta: 0:02:07  lr: 0.000078  loss: 0.2558 (0.2732)  time: 0.6223  data: 0.0001  max mem: 15824
[13:56:17.517933] Epoch: [12]  [160/345]  eta: 0:01:55  lr: 0.000078  loss: 0.2670 (0.2726)  time: 0.6223  data: 0.0001  max mem: 15824
[13:56:29.954894] Epoch: [12]  [180/345]  eta: 0:01:42  lr: 0.000078  loss: 0.2633 (0.2725)  time: 0.6218  data: 0.0001  max mem: 15824
[13:56:42.378441] Epoch: [12]  [200/345]  eta: 0:01:30  lr: 0.000079  loss: 0.2699 (0.2726)  time: 0.6211  data: 0.0001  max mem: 15824
[13:56:54.799439] Epoch: [12]  [220/345]  eta: 0:01:17  lr: 0.000079  loss: 0.2620 (0.2721)  time: 0.6210  data: 0.0001  max mem: 15824
[13:57:07.225438] Epoch: [12]  [240/345]  eta: 0:01:05  lr: 0.000079  loss: 0.2816 (0.2727)  time: 0.6213  data: 0.0001  max mem: 15824
[13:57:19.644607] Epoch: [12]  [260/345]  eta: 0:00:52  lr: 0.000080  loss: 0.2600 (0.2727)  time: 0.6209  data: 0.0001  max mem: 15824
[13:57:32.052942] Epoch: [12]  [280/345]  eta: 0:00:40  lr: 0.000080  loss: 0.2756 (0.2725)  time: 0.6204  data: 0.0001  max mem: 15824
[13:57:44.457736] Epoch: [12]  [300/345]  eta: 0:00:27  lr: 0.000080  loss: 0.2749 (0.2731)  time: 0.6202  data: 0.0001  max mem: 15824
[13:57:56.874495] Epoch: [12]  [320/345]  eta: 0:00:15  lr: 0.000081  loss: 0.2656 (0.2733)  time: 0.6208  data: 0.0001  max mem: 15824
[13:58:09.254642] Epoch: [12]  [340/345]  eta: 0:00:03  lr: 0.000081  loss: 0.2763 (0.2734)  time: 0.6190  data: 0.0001  max mem: 15824
[13:58:11.726898] Epoch: [12]  [344/345]  eta: 0:00:00  lr: 0.000081  loss: 0.2862 (0.2738)  time: 0.6185  data: 0.0001  max mem: 15824
[13:58:11.806555] Epoch: [12] Total time: 0:03:34 (0.6216 s / it)
[13:58:11.806795] Averaged stats: lr: 0.000081  loss: 0.2862 (0.2738)
[13:58:12.411550] Test:  [  0/345]  eta: 0:03:26  loss: 0.2715 (0.2715)  time: 0.5997  data: 0.4192  max mem: 15824
[13:58:14.200369] Test:  [ 10/345]  eta: 0:01:12  loss: 0.2715 (0.2714)  time: 0.2171  data: 0.0382  max mem: 15824
[13:58:15.989790] Test:  [ 20/345]  eta: 0:01:04  loss: 0.2536 (0.2656)  time: 0.1788  data: 0.0001  max mem: 15824
[13:58:17.785175] Test:  [ 30/345]  eta: 0:01:00  loss: 0.2528 (0.2617)  time: 0.1792  data: 0.0001  max mem: 15824
[13:58:19.586532] Test:  [ 40/345]  eta: 0:00:57  loss: 0.2532 (0.2604)  time: 0.1798  data: 0.0001  max mem: 15824
[13:58:21.389319] Test:  [ 50/345]  eta: 0:00:55  loss: 0.2546 (0.2624)  time: 0.1801  data: 0.0001  max mem: 15824
[13:58:23.191792] Test:  [ 60/345]  eta: 0:00:53  loss: 0.2622 (0.2616)  time: 0.1802  data: 0.0001  max mem: 15824
[13:58:24.995850] Test:  [ 70/345]  eta: 0:00:51  loss: 0.2622 (0.2623)  time: 0.1803  data: 0.0001  max mem: 15824
[13:58:26.806355] Test:  [ 80/345]  eta: 0:00:49  loss: 0.2609 (0.2624)  time: 0.1807  data: 0.0001  max mem: 15824
[13:58:28.620719] Test:  [ 90/345]  eta: 0:00:47  loss: 0.2563 (0.2615)  time: 0.1812  data: 0.0001  max mem: 15824
[13:58:30.439352] Test:  [100/345]  eta: 0:00:45  loss: 0.2563 (0.2619)  time: 0.1816  data: 0.0001  max mem: 15824
[13:58:32.261625] Test:  [110/345]  eta: 0:00:43  loss: 0.2775 (0.2634)  time: 0.1820  data: 0.0001  max mem: 15824
[13:58:34.087163] Test:  [120/345]  eta: 0:00:41  loss: 0.2780 (0.2648)  time: 0.1823  data: 0.0001  max mem: 15824
[13:58:35.915882] Test:  [130/345]  eta: 0:00:39  loss: 0.2551 (0.2635)  time: 0.1826  data: 0.0001  max mem: 15824
[13:58:37.747491] Test:  [140/345]  eta: 0:00:37  loss: 0.2674 (0.2648)  time: 0.1830  data: 0.0001  max mem: 15824
[13:58:39.585021] Test:  [150/345]  eta: 0:00:35  loss: 0.2740 (0.2653)  time: 0.1834  data: 0.0001  max mem: 15824
[13:58:41.424514] Test:  [160/345]  eta: 0:00:34  loss: 0.2667 (0.2649)  time: 0.1838  data: 0.0001  max mem: 15824
[13:58:43.271500] Test:  [170/345]  eta: 0:00:32  loss: 0.2607 (0.2654)  time: 0.1843  data: 0.0001  max mem: 15824
[13:58:45.115474] Test:  [180/345]  eta: 0:00:30  loss: 0.2545 (0.2647)  time: 0.1845  data: 0.0001  max mem: 15824
[13:58:46.965666] Test:  [190/345]  eta: 0:00:28  loss: 0.2492 (0.2639)  time: 0.1846  data: 0.0001  max mem: 15824
[13:58:48.817719] Test:  [200/345]  eta: 0:00:26  loss: 0.2529 (0.2642)  time: 0.1851  data: 0.0001  max mem: 15824
[13:58:50.673020] Test:  [210/345]  eta: 0:00:24  loss: 0.2620 (0.2640)  time: 0.1853  data: 0.0001  max mem: 15824
[13:58:52.531276] Test:  [220/345]  eta: 0:00:23  loss: 0.2620 (0.2640)  time: 0.1856  data: 0.0001  max mem: 15824
[13:58:54.395563] Test:  [230/345]  eta: 0:00:21  loss: 0.2629 (0.2640)  time: 0.1861  data: 0.0001  max mem: 15824
[13:58:56.262884] Test:  [240/345]  eta: 0:00:19  loss: 0.2743 (0.2646)  time: 0.1865  data: 0.0001  max mem: 15824
[13:58:58.133585] Test:  [250/345]  eta: 0:00:17  loss: 0.2742 (0.2646)  time: 0.1868  data: 0.0001  max mem: 15824
[13:59:00.007833] Test:  [260/345]  eta: 0:00:15  loss: 0.2666 (0.2650)  time: 0.1872  data: 0.0001  max mem: 15824
[13:59:01.884544] Test:  [270/345]  eta: 0:00:13  loss: 0.2693 (0.2650)  time: 0.1875  data: 0.0001  max mem: 15824
[13:59:03.766516] Test:  [280/345]  eta: 0:00:12  loss: 0.2577 (0.2646)  time: 0.1879  data: 0.0001  max mem: 15824
[13:59:05.650374] Test:  [290/345]  eta: 0:00:10  loss: 0.2578 (0.2648)  time: 0.1882  data: 0.0001  max mem: 15824
[13:59:07.538245] Test:  [300/345]  eta: 0:00:08  loss: 0.2786 (0.2651)  time: 0.1885  data: 0.0001  max mem: 15824
[13:59:09.429478] Test:  [310/345]  eta: 0:00:06  loss: 0.2664 (0.2650)  time: 0.1889  data: 0.0001  max mem: 15824
[13:59:11.321620] Test:  [320/345]  eta: 0:00:04  loss: 0.2567 (0.2647)  time: 0.1891  data: 0.0001  max mem: 15824
[13:59:13.219371] Test:  [330/345]  eta: 0:00:02  loss: 0.2650 (0.2652)  time: 0.1894  data: 0.0001  max mem: 15824
[13:59:15.118908] Test:  [340/345]  eta: 0:00:00  loss: 0.2692 (0.2650)  time: 0.1898  data: 0.0001  max mem: 15824
[13:59:15.879762] Test:  [344/345]  eta: 0:00:00  loss: 0.2739 (0.2651)  time: 0.1899  data: 0.0001  max mem: 15824
[13:59:15.948073] Test: Total time: 0:01:04 (0.1859 s / it)
[13:59:26.355164] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4750 (0.4750)  time: 0.5354  data: 0.3534  max mem: 15824
[13:59:28.125805] Test:  [10/57]  eta: 0:00:09  loss: 0.4563 (0.4655)  time: 0.2095  data: 0.0322  max mem: 15824
[13:59:29.902382] Test:  [20/57]  eta: 0:00:07  loss: 0.4295 (0.4467)  time: 0.1773  data: 0.0001  max mem: 15824
[13:59:31.681615] Test:  [30/57]  eta: 0:00:05  loss: 0.3253 (0.4008)  time: 0.1777  data: 0.0001  max mem: 15824
[13:59:33.467534] Test:  [40/57]  eta: 0:00:03  loss: 0.3143 (0.3790)  time: 0.1782  data: 0.0001  max mem: 15824
[13:59:35.255643] Test:  [50/57]  eta: 0:00:01  loss: 0.3202 (0.3773)  time: 0.1786  data: 0.0001  max mem: 15824
[13:59:36.226576] Test:  [56/57]  eta: 0:00:00  loss: 0.3517 (0.3885)  time: 0.1735  data: 0.0000  max mem: 15824
[13:59:36.299123] Test: Total time: 0:00:10 (0.1839 s / it)
[13:59:38.023294] Dice score of the network on the train images: 0.789142, val images: 0.761252
[13:59:38.023515] saving best_prec_model_0 @ epoch 12
[13:59:39.135590] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[13:59:40.128326] Epoch: [13]  [  0/345]  eta: 0:05:42  lr: 0.000081  loss: 0.2248 (0.2248)  time: 0.9915  data: 0.3657  max mem: 15824
[13:59:52.450422] Epoch: [13]  [ 20/345]  eta: 0:03:26  lr: 0.000082  loss: 0.2683 (0.2650)  time: 0.6160  data: 0.0001  max mem: 15824
[14:00:04.784483] Epoch: [13]  [ 40/345]  eta: 0:03:10  lr: 0.000082  loss: 0.2523 (0.2595)  time: 0.6167  data: 0.0001  max mem: 15824
[14:00:17.132093] Epoch: [13]  [ 60/345]  eta: 0:02:57  lr: 0.000082  loss: 0.2612 (0.2652)  time: 0.6173  data: 0.0001  max mem: 15824
[14:00:29.490670] Epoch: [13]  [ 80/345]  eta: 0:02:44  lr: 0.000083  loss: 0.2653 (0.2667)  time: 0.6179  data: 0.0001  max mem: 15824
[14:00:41.862214] Epoch: [13]  [100/345]  eta: 0:02:32  lr: 0.000083  loss: 0.2633 (0.2680)  time: 0.6185  data: 0.0001  max mem: 15824
[14:00:54.269707] Epoch: [13]  [120/345]  eta: 0:02:19  lr: 0.000083  loss: 0.2544 (0.2665)  time: 0.6203  data: 0.0001  max mem: 15824
[14:01:06.687355] Epoch: [13]  [140/345]  eta: 0:02:07  lr: 0.000084  loss: 0.2794 (0.2681)  time: 0.6208  data: 0.0001  max mem: 15824
[14:01:19.120086] Epoch: [13]  [160/345]  eta: 0:01:54  lr: 0.000084  loss: 0.2550 (0.2669)  time: 0.6216  data: 0.0001  max mem: 15824
[14:01:31.520507] Epoch: [13]  [180/345]  eta: 0:01:42  lr: 0.000085  loss: 0.2552 (0.2663)  time: 0.6200  data: 0.0001  max mem: 15824
[14:01:43.961609] Epoch: [13]  [200/345]  eta: 0:01:30  lr: 0.000085  loss: 0.2574 (0.2659)  time: 0.6220  data: 0.0001  max mem: 15824
[14:01:56.389432] Epoch: [13]  [220/345]  eta: 0:01:17  lr: 0.000085  loss: 0.2597 (0.2655)  time: 0.6213  data: 0.0001  max mem: 15824
[14:02:08.809126] Epoch: [13]  [240/345]  eta: 0:01:05  lr: 0.000086  loss: 0.2600 (0.2656)  time: 0.6209  data: 0.0001  max mem: 15824
[14:02:21.229698] Epoch: [13]  [260/345]  eta: 0:00:52  lr: 0.000086  loss: 0.2699 (0.2660)  time: 0.6210  data: 0.0001  max mem: 15824
[14:02:33.652078] Epoch: [13]  [280/345]  eta: 0:00:40  lr: 0.000086  loss: 0.2637 (0.2659)  time: 0.6211  data: 0.0001  max mem: 15824
[14:02:46.073259] Epoch: [13]  [300/345]  eta: 0:00:27  lr: 0.000087  loss: 0.2586 (0.2657)  time: 0.6210  data: 0.0001  max mem: 15824
[14:02:58.482554] Epoch: [13]  [320/345]  eta: 0:00:15  lr: 0.000087  loss: 0.2557 (0.2652)  time: 0.6204  data: 0.0001  max mem: 15824
[14:03:10.888861] Epoch: [13]  [340/345]  eta: 0:00:03  lr: 0.000087  loss: 0.2413 (0.2642)  time: 0.6203  data: 0.0001  max mem: 15824
[14:03:13.366446] Epoch: [13]  [344/345]  eta: 0:00:00  lr: 0.000087  loss: 0.2413 (0.2638)  time: 0.6200  data: 0.0001  max mem: 15824
[14:03:13.431592] Epoch: [13] Total time: 0:03:34 (0.6211 s / it)
[14:03:13.431815] Averaged stats: lr: 0.000087  loss: 0.2413 (0.2638)
[14:03:14.066007] Test:  [  0/345]  eta: 0:03:36  loss: 0.2596 (0.2596)  time: 0.6289  data: 0.4477  max mem: 15824
[14:03:15.853227] Test:  [ 10/345]  eta: 0:01:13  loss: 0.2772 (0.2752)  time: 0.2196  data: 0.0408  max mem: 15824
[14:03:17.646424] Test:  [ 20/345]  eta: 0:01:05  loss: 0.2546 (0.2601)  time: 0.1789  data: 0.0001  max mem: 15824
[14:03:19.440452] Test:  [ 30/345]  eta: 0:01:00  loss: 0.2357 (0.2518)  time: 0.1793  data: 0.0001  max mem: 15824
[14:03:21.238064] Test:  [ 40/345]  eta: 0:00:58  loss: 0.2356 (0.2488)  time: 0.1795  data: 0.0001  max mem: 15824
[14:03:23.039259] Test:  [ 50/345]  eta: 0:00:55  loss: 0.2362 (0.2472)  time: 0.1799  data: 0.0001  max mem: 15824
[14:03:24.842418] Test:  [ 60/345]  eta: 0:00:53  loss: 0.2362 (0.2478)  time: 0.1802  data: 0.0001  max mem: 15824
[14:03:26.652660] Test:  [ 70/345]  eta: 0:00:51  loss: 0.2359 (0.2459)  time: 0.1806  data: 0.0001  max mem: 15824
[14:03:28.464577] Test:  [ 80/345]  eta: 0:00:49  loss: 0.2339 (0.2454)  time: 0.1810  data: 0.0001  max mem: 15824
[14:03:30.281228] Test:  [ 90/345]  eta: 0:00:47  loss: 0.2388 (0.2461)  time: 0.1814  data: 0.0001  max mem: 15824
[14:03:32.098869] Test:  [100/345]  eta: 0:00:45  loss: 0.2262 (0.2444)  time: 0.1817  data: 0.0001  max mem: 15824
[14:03:33.919042] Test:  [110/345]  eta: 0:00:43  loss: 0.2310 (0.2444)  time: 0.1818  data: 0.0001  max mem: 15824
[14:03:35.743359] Test:  [120/345]  eta: 0:00:41  loss: 0.2445 (0.2450)  time: 0.1822  data: 0.0001  max mem: 15824
[14:03:37.572975] Test:  [130/345]  eta: 0:00:39  loss: 0.2482 (0.2451)  time: 0.1826  data: 0.0001  max mem: 15824
[14:03:39.403888] Test:  [140/345]  eta: 0:00:37  loss: 0.2375 (0.2444)  time: 0.1830  data: 0.0001  max mem: 15824
[14:03:41.239055] Test:  [150/345]  eta: 0:00:35  loss: 0.2310 (0.2439)  time: 0.1832  data: 0.0001  max mem: 15824
[14:03:43.078905] Test:  [160/345]  eta: 0:00:34  loss: 0.2343 (0.2433)  time: 0.1837  data: 0.0001  max mem: 15824
[14:03:44.921963] Test:  [170/345]  eta: 0:00:32  loss: 0.2357 (0.2434)  time: 0.1841  data: 0.0001  max mem: 15824
[14:03:46.768248] Test:  [180/345]  eta: 0:00:30  loss: 0.2389 (0.2429)  time: 0.1844  data: 0.0001  max mem: 15824
[14:03:48.616633] Test:  [190/345]  eta: 0:00:28  loss: 0.2351 (0.2423)  time: 0.1847  data: 0.0001  max mem: 15824
[14:03:50.469776] Test:  [200/345]  eta: 0:00:26  loss: 0.2321 (0.2421)  time: 0.1850  data: 0.0001  max mem: 15824
[14:03:52.325175] Test:  [210/345]  eta: 0:00:24  loss: 0.2335 (0.2423)  time: 0.1854  data: 0.0001  max mem: 15824
[14:03:54.185713] Test:  [220/345]  eta: 0:00:23  loss: 0.2362 (0.2422)  time: 0.1857  data: 0.0001  max mem: 15824
[14:03:56.048478] Test:  [230/345]  eta: 0:00:21  loss: 0.2419 (0.2425)  time: 0.1861  data: 0.0001  max mem: 15824
[14:03:57.914595] Test:  [240/345]  eta: 0:00:19  loss: 0.2547 (0.2430)  time: 0.1864  data: 0.0001  max mem: 15824
[14:03:59.786290] Test:  [250/345]  eta: 0:00:17  loss: 0.2506 (0.2434)  time: 0.1868  data: 0.0001  max mem: 15824
[14:04:01.657477] Test:  [260/345]  eta: 0:00:15  loss: 0.2483 (0.2434)  time: 0.1871  data: 0.0001  max mem: 15824
[14:04:03.533810] Test:  [270/345]  eta: 0:00:13  loss: 0.2371 (0.2431)  time: 0.1873  data: 0.0001  max mem: 15824
[14:04:05.413976] Test:  [280/345]  eta: 0:00:12  loss: 0.2371 (0.2432)  time: 0.1878  data: 0.0001  max mem: 15824
[14:04:07.299537] Test:  [290/345]  eta: 0:00:10  loss: 0.2482 (0.2431)  time: 0.1882  data: 0.0001  max mem: 15824
[14:04:09.187621] Test:  [300/345]  eta: 0:00:08  loss: 0.2387 (0.2432)  time: 0.1886  data: 0.0001  max mem: 15824
[14:04:11.078757] Test:  [310/345]  eta: 0:00:06  loss: 0.2473 (0.2437)  time: 0.1889  data: 0.0001  max mem: 15824
[14:04:12.971848] Test:  [320/345]  eta: 0:00:04  loss: 0.2313 (0.2432)  time: 0.1892  data: 0.0001  max mem: 15824
[14:04:14.869828] Test:  [330/345]  eta: 0:00:02  loss: 0.2250 (0.2430)  time: 0.1895  data: 0.0001  max mem: 15824
[14:04:16.768189] Test:  [340/345]  eta: 0:00:00  loss: 0.2301 (0.2426)  time: 0.1898  data: 0.0001  max mem: 15824
[14:04:17.528989] Test:  [344/345]  eta: 0:00:00  loss: 0.2304 (0.2426)  time: 0.1898  data: 0.0001  max mem: 15824
[14:04:17.605010] Test: Total time: 0:01:04 (0.1860 s / it)
[14:04:28.003181] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4873 (0.4873)  time: 0.5491  data: 0.3684  max mem: 15824
[14:04:29.774961] Test:  [10/57]  eta: 0:00:09  loss: 0.4356 (0.4613)  time: 0.2109  data: 0.0336  max mem: 15824
[14:04:31.552850] Test:  [20/57]  eta: 0:00:07  loss: 0.4119 (0.4376)  time: 0.1774  data: 0.0001  max mem: 15824
[14:04:33.337600] Test:  [30/57]  eta: 0:00:05  loss: 0.3251 (0.3898)  time: 0.1781  data: 0.0001  max mem: 15824
[14:04:35.123262] Test:  [40/57]  eta: 0:00:03  loss: 0.2961 (0.3673)  time: 0.1785  data: 0.0001  max mem: 15824
[14:04:36.908560] Test:  [50/57]  eta: 0:00:01  loss: 0.3095 (0.3666)  time: 0.1785  data: 0.0001  max mem: 15824
[14:04:37.882231] Test:  [56/57]  eta: 0:00:00  loss: 0.3545 (0.3808)  time: 0.1737  data: 0.0001  max mem: 15824
[14:04:37.953012] Test: Total time: 0:00:10 (0.1842 s / it)
[14:04:39.661463] Dice score of the network on the train images: 0.789913, val images: 0.763817
[14:04:39.665576] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:04:40.662981] Epoch: [14]  [  0/345]  eta: 0:05:43  lr: 0.000087  loss: 0.2336 (0.2336)  time: 0.9965  data: 0.3722  max mem: 15824
[14:04:52.966612] Epoch: [14]  [ 20/345]  eta: 0:03:25  lr: 0.000088  loss: 0.2386 (0.2439)  time: 0.6151  data: 0.0001  max mem: 15824
[14:05:05.441117] Epoch: [14]  [ 40/345]  eta: 0:03:11  lr: 0.000088  loss: 0.2427 (0.2452)  time: 0.6237  data: 0.0001  max mem: 15824
[14:05:17.821047] Epoch: [14]  [ 60/345]  eta: 0:02:58  lr: 0.000089  loss: 0.2492 (0.2483)  time: 0.6190  data: 0.0001  max mem: 15824
[14:05:30.214309] Epoch: [14]  [ 80/345]  eta: 0:02:45  lr: 0.000089  loss: 0.2552 (0.2490)  time: 0.6196  data: 0.0001  max mem: 15824
[14:05:42.617230] Epoch: [14]  [100/345]  eta: 0:02:32  lr: 0.000089  loss: 0.2559 (0.2505)  time: 0.6201  data: 0.0001  max mem: 15824
[14:05:55.025646] Epoch: [14]  [120/345]  eta: 0:02:20  lr: 0.000090  loss: 0.2550 (0.2511)  time: 0.6204  data: 0.0001  max mem: 15824
[14:06:07.446496] Epoch: [14]  [140/345]  eta: 0:02:07  lr: 0.000090  loss: 0.2513 (0.2520)  time: 0.6210  data: 0.0001  max mem: 15824
[14:06:19.870511] Epoch: [14]  [160/345]  eta: 0:01:55  lr: 0.000090  loss: 0.2564 (0.2533)  time: 0.6212  data: 0.0001  max mem: 15824
[14:06:32.285497] Epoch: [14]  [180/345]  eta: 0:01:42  lr: 0.000091  loss: 0.2340 (0.2528)  time: 0.6207  data: 0.0001  max mem: 15824
[14:06:44.696087] Epoch: [14]  [200/345]  eta: 0:01:30  lr: 0.000091  loss: 0.2475 (0.2524)  time: 0.6205  data: 0.0001  max mem: 15824
[14:06:57.099302] Epoch: [14]  [220/345]  eta: 0:01:17  lr: 0.000091  loss: 0.2525 (0.2532)  time: 0.6201  data: 0.0001  max mem: 15824
[14:07:09.524074] Epoch: [14]  [240/345]  eta: 0:01:05  lr: 0.000092  loss: 0.2589 (0.2538)  time: 0.6212  data: 0.0001  max mem: 15824
[14:07:21.916390] Epoch: [14]  [260/345]  eta: 0:00:52  lr: 0.000092  loss: 0.2582 (0.2543)  time: 0.6196  data: 0.0001  max mem: 15824
[14:07:34.418146] Epoch: [14]  [280/345]  eta: 0:00:40  lr: 0.000093  loss: 0.2495 (0.2543)  time: 0.6250  data: 0.0001  max mem: 15824
[14:07:46.788682] Epoch: [14]  [300/345]  eta: 0:00:27  lr: 0.000093  loss: 0.2486 (0.2539)  time: 0.6185  data: 0.0001  max mem: 15824
[14:07:59.192913] Epoch: [14]  [320/345]  eta: 0:00:15  lr: 0.000093  loss: 0.2409 (0.2535)  time: 0.6202  data: 0.0001  max mem: 15824
[14:08:11.589163] Epoch: [14]  [340/345]  eta: 0:00:03  lr: 0.000094  loss: 0.2578 (0.2536)  time: 0.6198  data: 0.0001  max mem: 15824
[14:08:14.070270] Epoch: [14]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.2502 (0.2536)  time: 0.6200  data: 0.0001  max mem: 15824
[14:08:14.141450] Epoch: [14] Total time: 0:03:34 (0.6217 s / it)
[14:08:14.141847] Averaged stats: lr: 0.000094  loss: 0.2502 (0.2536)
[14:08:14.726354] Test:  [  0/345]  eta: 0:03:19  loss: 0.2510 (0.2510)  time: 0.5777  data: 0.3948  max mem: 15824
[14:08:16.514481] Test:  [ 10/345]  eta: 0:01:12  loss: 0.2447 (0.2464)  time: 0.2150  data: 0.0360  max mem: 15824
[14:08:18.308108] Test:  [ 20/345]  eta: 0:01:04  loss: 0.2455 (0.2497)  time: 0.1790  data: 0.0001  max mem: 15824
[14:08:20.104387] Test:  [ 30/345]  eta: 0:01:00  loss: 0.2466 (0.2453)  time: 0.1794  data: 0.0001  max mem: 15824
[14:08:21.905208] Test:  [ 40/345]  eta: 0:00:57  loss: 0.2300 (0.2416)  time: 0.1798  data: 0.0001  max mem: 15824
[14:08:23.710824] Test:  [ 50/345]  eta: 0:00:55  loss: 0.2398 (0.2439)  time: 0.1803  data: 0.0001  max mem: 15824
[14:08:25.516202] Test:  [ 60/345]  eta: 0:00:53  loss: 0.2384 (0.2407)  time: 0.1805  data: 0.0001  max mem: 15824
[14:08:27.323356] Test:  [ 70/345]  eta: 0:00:51  loss: 0.2322 (0.2409)  time: 0.1806  data: 0.0001  max mem: 15824
[14:08:29.134923] Test:  [ 80/345]  eta: 0:00:49  loss: 0.2262 (0.2389)  time: 0.1809  data: 0.0001  max mem: 15824
[14:08:30.948154] Test:  [ 90/345]  eta: 0:00:47  loss: 0.2208 (0.2377)  time: 0.1812  data: 0.0001  max mem: 15824
[14:08:32.766133] Test:  [100/345]  eta: 0:00:45  loss: 0.2241 (0.2391)  time: 0.1815  data: 0.0001  max mem: 15824
[14:08:34.593659] Test:  [110/345]  eta: 0:00:43  loss: 0.2262 (0.2393)  time: 0.1822  data: 0.0001  max mem: 15824
[14:08:36.420726] Test:  [120/345]  eta: 0:00:41  loss: 0.2473 (0.2400)  time: 0.1827  data: 0.0001  max mem: 15824
[14:08:38.253088] Test:  [130/345]  eta: 0:00:39  loss: 0.2455 (0.2399)  time: 0.1829  data: 0.0001  max mem: 15824
[14:08:40.085820] Test:  [140/345]  eta: 0:00:37  loss: 0.2414 (0.2412)  time: 0.1832  data: 0.0001  max mem: 15824
[14:08:41.922473] Test:  [150/345]  eta: 0:00:35  loss: 0.2457 (0.2407)  time: 0.1834  data: 0.0001  max mem: 15824
[14:08:43.764778] Test:  [160/345]  eta: 0:00:34  loss: 0.2360 (0.2404)  time: 0.1839  data: 0.0001  max mem: 15824
[14:08:45.612777] Test:  [170/345]  eta: 0:00:32  loss: 0.2367 (0.2409)  time: 0.1844  data: 0.0001  max mem: 15824
[14:08:47.463693] Test:  [180/345]  eta: 0:00:30  loss: 0.2410 (0.2409)  time: 0.1849  data: 0.0001  max mem: 15824
[14:08:49.314784] Test:  [190/345]  eta: 0:00:28  loss: 0.2381 (0.2409)  time: 0.1850  data: 0.0001  max mem: 15824
[14:08:51.166239] Test:  [200/345]  eta: 0:00:26  loss: 0.2381 (0.2415)  time: 0.1851  data: 0.0001  max mem: 15824
[14:08:53.023277] Test:  [210/345]  eta: 0:00:24  loss: 0.2426 (0.2412)  time: 0.1854  data: 0.0001  max mem: 15824
[14:08:54.883658] Test:  [220/345]  eta: 0:00:23  loss: 0.2376 (0.2413)  time: 0.1858  data: 0.0001  max mem: 15824
[14:08:56.748760] Test:  [230/345]  eta: 0:00:21  loss: 0.2376 (0.2412)  time: 0.1862  data: 0.0001  max mem: 15824
[14:08:58.617840] Test:  [240/345]  eta: 0:00:19  loss: 0.2347 (0.2409)  time: 0.1866  data: 0.0001  max mem: 15824
[14:09:00.492896] Test:  [250/345]  eta: 0:00:17  loss: 0.2338 (0.2407)  time: 0.1871  data: 0.0001  max mem: 15824
[14:09:02.366916] Test:  [260/345]  eta: 0:00:15  loss: 0.2357 (0.2408)  time: 0.1874  data: 0.0001  max mem: 15824
[14:09:04.244884] Test:  [270/345]  eta: 0:00:13  loss: 0.2293 (0.2404)  time: 0.1875  data: 0.0001  max mem: 15824
[14:09:06.126252] Test:  [280/345]  eta: 0:00:12  loss: 0.2297 (0.2406)  time: 0.1879  data: 0.0001  max mem: 15824
[14:09:08.012141] Test:  [290/345]  eta: 0:00:10  loss: 0.2371 (0.2407)  time: 0.1883  data: 0.0001  max mem: 15824
[14:09:09.902069] Test:  [300/345]  eta: 0:00:08  loss: 0.2371 (0.2409)  time: 0.1887  data: 0.0001  max mem: 15824
[14:09:11.794044] Test:  [310/345]  eta: 0:00:06  loss: 0.2338 (0.2408)  time: 0.1890  data: 0.0001  max mem: 15824
[14:09:13.692329] Test:  [320/345]  eta: 0:00:04  loss: 0.2411 (0.2410)  time: 0.1895  data: 0.0001  max mem: 15824
[14:09:15.593384] Test:  [330/345]  eta: 0:00:02  loss: 0.2491 (0.2413)  time: 0.1899  data: 0.0001  max mem: 15824
[14:09:17.492311] Test:  [340/345]  eta: 0:00:00  loss: 0.2473 (0.2413)  time: 0.1899  data: 0.0001  max mem: 15824
[14:09:18.254159] Test:  [344/345]  eta: 0:00:00  loss: 0.2329 (0.2412)  time: 0.1900  data: 0.0001  max mem: 15824
[14:09:18.328469] Test: Total time: 0:01:04 (0.1860 s / it)
[14:09:28.790745] Test:  [ 0/57]  eta: 0:00:33  loss: 0.4964 (0.4964)  time: 0.5932  data: 0.4131  max mem: 15824
[14:09:30.561718] Test:  [10/57]  eta: 0:00:10  loss: 0.4799 (0.4803)  time: 0.2149  data: 0.0376  max mem: 15824
[14:09:32.338246] Test:  [20/57]  eta: 0:00:07  loss: 0.4389 (0.4588)  time: 0.1773  data: 0.0001  max mem: 15824
[14:09:34.115785] Test:  [30/57]  eta: 0:00:05  loss: 0.3342 (0.4021)  time: 0.1776  data: 0.0001  max mem: 15824
[14:09:35.899564] Test:  [40/57]  eta: 0:00:03  loss: 0.2890 (0.3789)  time: 0.1780  data: 0.0001  max mem: 15824
[14:09:37.684982] Test:  [50/57]  eta: 0:00:01  loss: 0.3304 (0.3868)  time: 0.1784  data: 0.0001  max mem: 15824
[14:09:38.656769] Test:  [56/57]  eta: 0:00:00  loss: 0.3763 (0.4066)  time: 0.1735  data: 0.0000  max mem: 15824
[14:09:38.732907] Test: Total time: 0:00:10 (0.1848 s / it)
[14:09:40.449006] Dice score of the network on the train images: 0.802190, val images: 0.749025
[14:09:40.453077] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:09:41.438321] Epoch: [15]  [  0/345]  eta: 0:05:39  lr: 0.000094  loss: 0.2338 (0.2338)  time: 0.9842  data: 0.3584  max mem: 15824
[14:09:53.784393] Epoch: [15]  [ 20/345]  eta: 0:03:26  lr: 0.000094  loss: 0.2383 (0.2423)  time: 0.6173  data: 0.0001  max mem: 15824
[14:10:06.149626] Epoch: [15]  [ 40/345]  eta: 0:03:11  lr: 0.000094  loss: 0.2459 (0.2505)  time: 0.6182  data: 0.0001  max mem: 15824
[14:10:18.545890] Epoch: [15]  [ 60/345]  eta: 0:02:57  lr: 0.000095  loss: 0.2449 (0.2517)  time: 0.6198  data: 0.0001  max mem: 15824
[14:10:30.946568] Epoch: [15]  [ 80/345]  eta: 0:02:45  lr: 0.000095  loss: 0.2510 (0.2515)  time: 0.6200  data: 0.0001  max mem: 15824
[14:10:43.341609] Epoch: [15]  [100/345]  eta: 0:02:32  lr: 0.000096  loss: 0.2431 (0.2507)  time: 0.6197  data: 0.0001  max mem: 15824
[14:10:55.766044] Epoch: [15]  [120/345]  eta: 0:02:20  lr: 0.000096  loss: 0.2614 (0.2527)  time: 0.6212  data: 0.0001  max mem: 15824
[14:11:08.185408] Epoch: [15]  [140/345]  eta: 0:02:07  lr: 0.000096  loss: 0.2347 (0.2521)  time: 0.6209  data: 0.0001  max mem: 15824
[14:11:20.604672] Epoch: [15]  [160/345]  eta: 0:01:55  lr: 0.000097  loss: 0.2532 (0.2529)  time: 0.6209  data: 0.0001  max mem: 15824
[14:11:33.153180] Epoch: [15]  [180/345]  eta: 0:01:42  lr: 0.000097  loss: 0.2542 (0.2525)  time: 0.6274  data: 0.0001  max mem: 15824
[14:11:45.566428] Epoch: [15]  [200/345]  eta: 0:01:30  lr: 0.000097  loss: 0.2448 (0.2526)  time: 0.6206  data: 0.0001  max mem: 15824
[14:11:57.980115] Epoch: [15]  [220/345]  eta: 0:01:17  lr: 0.000098  loss: 0.2383 (0.2513)  time: 0.6206  data: 0.0001  max mem: 15824
[14:12:10.410611] Epoch: [15]  [240/345]  eta: 0:01:05  lr: 0.000098  loss: 0.2343 (0.2498)  time: 0.6215  data: 0.0001  max mem: 15824
[14:12:22.820462] Epoch: [15]  [260/345]  eta: 0:00:52  lr: 0.000098  loss: 0.2479 (0.2499)  time: 0.6204  data: 0.0001  max mem: 15824
[14:12:35.225502] Epoch: [15]  [280/345]  eta: 0:00:40  lr: 0.000099  loss: 0.2351 (0.2494)  time: 0.6202  data: 0.0001  max mem: 15824
[14:12:47.612732] Epoch: [15]  [300/345]  eta: 0:00:27  lr: 0.000099  loss: 0.2456 (0.2494)  time: 0.6193  data: 0.0001  max mem: 15824
[14:12:59.995715] Epoch: [15]  [320/345]  eta: 0:00:15  lr: 0.000100  loss: 0.2495 (0.2496)  time: 0.6191  data: 0.0001  max mem: 15824
[14:13:12.350348] Epoch: [15]  [340/345]  eta: 0:00:03  lr: 0.000100  loss: 0.2448 (0.2492)  time: 0.6177  data: 0.0001  max mem: 15824
[14:13:14.816245] Epoch: [15]  [344/345]  eta: 0:00:00  lr: 0.000100  loss: 0.2430 (0.2489)  time: 0.6173  data: 0.0001  max mem: 15824
[14:13:14.889057] Epoch: [15] Total time: 0:03:34 (0.6216 s / it)
[14:13:14.889419] Averaged stats: lr: 0.000100  loss: 0.2430 (0.2489)
[14:13:15.469451] Test:  [  0/345]  eta: 0:03:18  loss: 0.2570 (0.2570)  time: 0.5745  data: 0.3929  max mem: 15824
[14:13:17.256367] Test:  [ 10/345]  eta: 0:01:11  loss: 0.2210 (0.2274)  time: 0.2146  data: 0.0358  max mem: 15824
[14:13:19.050525] Test:  [ 20/345]  eta: 0:01:04  loss: 0.2361 (0.2388)  time: 0.1790  data: 0.0001  max mem: 15824
[14:13:20.846862] Test:  [ 30/345]  eta: 0:01:00  loss: 0.2492 (0.2443)  time: 0.1795  data: 0.0001  max mem: 15824
[14:13:22.644609] Test:  [ 40/345]  eta: 0:00:57  loss: 0.2469 (0.2439)  time: 0.1796  data: 0.0001  max mem: 15824
[14:13:24.444690] Test:  [ 50/345]  eta: 0:00:55  loss: 0.2449 (0.2446)  time: 0.1798  data: 0.0001  max mem: 15824
[14:13:26.250139] Test:  [ 60/345]  eta: 0:00:53  loss: 0.2397 (0.2442)  time: 0.1802  data: 0.0001  max mem: 15824
[14:13:28.057960] Test:  [ 70/345]  eta: 0:00:50  loss: 0.2397 (0.2430)  time: 0.1806  data: 0.0001  max mem: 15824
[14:13:29.869022] Test:  [ 80/345]  eta: 0:00:48  loss: 0.2375 (0.2415)  time: 0.1809  data: 0.0001  max mem: 15824
[14:13:31.684351] Test:  [ 90/345]  eta: 0:00:47  loss: 0.2262 (0.2410)  time: 0.1813  data: 0.0001  max mem: 15824
[14:13:33.503706] Test:  [100/345]  eta: 0:00:45  loss: 0.2507 (0.2429)  time: 0.1817  data: 0.0001  max mem: 15824
[14:13:35.326755] Test:  [110/345]  eta: 0:00:43  loss: 0.2445 (0.2418)  time: 0.1821  data: 0.0001  max mem: 15824
[14:13:37.154571] Test:  [120/345]  eta: 0:00:41  loss: 0.2314 (0.2426)  time: 0.1825  data: 0.0001  max mem: 15824
[14:13:38.982572] Test:  [130/345]  eta: 0:00:39  loss: 0.2323 (0.2419)  time: 0.1827  data: 0.0001  max mem: 15824
[14:13:40.815614] Test:  [140/345]  eta: 0:00:37  loss: 0.2378 (0.2421)  time: 0.1830  data: 0.0001  max mem: 15824
[14:13:42.649953] Test:  [150/345]  eta: 0:00:35  loss: 0.2378 (0.2412)  time: 0.1833  data: 0.0001  max mem: 15824
[14:13:44.489769] Test:  [160/345]  eta: 0:00:33  loss: 0.2221 (0.2410)  time: 0.1836  data: 0.0001  max mem: 15824
[14:13:46.332027] Test:  [170/345]  eta: 0:00:32  loss: 0.2296 (0.2408)  time: 0.1840  data: 0.0001  max mem: 15824
[14:13:48.179474] Test:  [180/345]  eta: 0:00:30  loss: 0.2418 (0.2413)  time: 0.1844  data: 0.0001  max mem: 15824
[14:13:50.028336] Test:  [190/345]  eta: 0:00:28  loss: 0.2343 (0.2412)  time: 0.1848  data: 0.0001  max mem: 15824
[14:13:51.880651] Test:  [200/345]  eta: 0:00:26  loss: 0.2332 (0.2412)  time: 0.1850  data: 0.0001  max mem: 15824
[14:13:53.737952] Test:  [210/345]  eta: 0:00:24  loss: 0.2301 (0.2406)  time: 0.1854  data: 0.0001  max mem: 15824
[14:13:55.598529] Test:  [220/345]  eta: 0:00:23  loss: 0.2319 (0.2414)  time: 0.1858  data: 0.0001  max mem: 15824
[14:13:57.461128] Test:  [230/345]  eta: 0:00:21  loss: 0.2462 (0.2413)  time: 0.1861  data: 0.0001  max mem: 15824
[14:13:59.326885] Test:  [240/345]  eta: 0:00:19  loss: 0.2350 (0.2408)  time: 0.1864  data: 0.0001  max mem: 15824
[14:14:01.197379] Test:  [250/345]  eta: 0:00:17  loss: 0.2335 (0.2404)  time: 0.1867  data: 0.0001  max mem: 15824
[14:14:03.070557] Test:  [260/345]  eta: 0:00:15  loss: 0.2326 (0.2400)  time: 0.1871  data: 0.0001  max mem: 15824
[14:14:04.947633] Test:  [270/345]  eta: 0:00:13  loss: 0.2359 (0.2407)  time: 0.1875  data: 0.0001  max mem: 15824
[14:14:06.827147] Test:  [280/345]  eta: 0:00:12  loss: 0.2457 (0.2407)  time: 0.1878  data: 0.0001  max mem: 15824
[14:14:08.713920] Test:  [290/345]  eta: 0:00:10  loss: 0.2238 (0.2400)  time: 0.1883  data: 0.0001  max mem: 15824
[14:14:10.601880] Test:  [300/345]  eta: 0:00:08  loss: 0.2214 (0.2396)  time: 0.1887  data: 0.0001  max mem: 15824
[14:14:12.492968] Test:  [310/345]  eta: 0:00:06  loss: 0.2284 (0.2395)  time: 0.1889  data: 0.0001  max mem: 15824
[14:14:14.388374] Test:  [320/345]  eta: 0:00:04  loss: 0.2412 (0.2396)  time: 0.1892  data: 0.0001  max mem: 15824
[14:14:16.287362] Test:  [330/345]  eta: 0:00:02  loss: 0.2471 (0.2401)  time: 0.1896  data: 0.0001  max mem: 15824
[14:14:18.186623] Test:  [340/345]  eta: 0:00:00  loss: 0.2471 (0.2401)  time: 0.1899  data: 0.0001  max mem: 15824
[14:14:18.947130] Test:  [344/345]  eta: 0:00:00  loss: 0.2471 (0.2400)  time: 0.1899  data: 0.0001  max mem: 15824
[14:14:19.018282] Test: Total time: 0:01:04 (0.1859 s / it)
[14:14:29.527798] Test:  [ 0/57]  eta: 0:00:33  loss: 0.4089 (0.4089)  time: 0.5940  data: 0.4133  max mem: 15824
[14:14:31.301299] Test:  [10/57]  eta: 0:00:10  loss: 0.4089 (0.4297)  time: 0.2151  data: 0.0377  max mem: 15824
[14:14:33.074293] Test:  [20/57]  eta: 0:00:07  loss: 0.3924 (0.4014)  time: 0.1772  data: 0.0001  max mem: 15824
[14:14:34.855459] Test:  [30/57]  eta: 0:00:05  loss: 0.3118 (0.3563)  time: 0.1776  data: 0.0001  max mem: 15824
[14:14:36.638276] Test:  [40/57]  eta: 0:00:03  loss: 0.2452 (0.3300)  time: 0.1781  data: 0.0001  max mem: 15824
[14:14:38.423324] Test:  [50/57]  eta: 0:00:01  loss: 0.2607 (0.3269)  time: 0.1783  data: 0.0001  max mem: 15824
[14:14:39.395336] Test:  [56/57]  eta: 0:00:00  loss: 0.3016 (0.3390)  time: 0.1734  data: 0.0000  max mem: 15824
[14:14:39.467526] Test: Total time: 0:00:10 (0.1848 s / it)
[14:14:41.191835] Dice score of the network on the train images: 0.767003, val images: 0.782883
[14:14:41.192053] saving best_rec_model_0 @ epoch 15
[14:14:42.291813] saving best_dice_model_0 @ epoch 15
[14:14:43.409704] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:14:44.403832] Epoch: [16]  [  0/345]  eta: 0:05:42  lr: 0.000100  loss: 0.2526 (0.2526)  time: 0.9929  data: 0.3664  max mem: 15824
[14:14:56.714344] Epoch: [16]  [ 20/345]  eta: 0:03:25  lr: 0.000100  loss: 0.2236 (0.2321)  time: 0.6155  data: 0.0001  max mem: 15824
[14:15:09.052013] Epoch: [16]  [ 40/345]  eta: 0:03:10  lr: 0.000101  loss: 0.2306 (0.2323)  time: 0.6168  data: 0.0001  max mem: 15824
[14:15:21.429989] Epoch: [16]  [ 60/345]  eta: 0:02:57  lr: 0.000101  loss: 0.2358 (0.2369)  time: 0.6189  data: 0.0001  max mem: 15824
[14:15:33.802721] Epoch: [16]  [ 80/345]  eta: 0:02:44  lr: 0.000101  loss: 0.2529 (0.2415)  time: 0.6186  data: 0.0001  max mem: 15824
[14:15:46.216166] Epoch: [16]  [100/345]  eta: 0:02:32  lr: 0.000102  loss: 0.2468 (0.2421)  time: 0.6206  data: 0.0001  max mem: 15824
[14:15:58.612290] Epoch: [16]  [120/345]  eta: 0:02:19  lr: 0.000102  loss: 0.2373 (0.2422)  time: 0.6198  data: 0.0001  max mem: 15824
[14:16:11.013877] Epoch: [16]  [140/345]  eta: 0:02:07  lr: 0.000103  loss: 0.2338 (0.2413)  time: 0.6200  data: 0.0001  max mem: 15824
[14:16:23.407131] Epoch: [16]  [160/345]  eta: 0:01:54  lr: 0.000103  loss: 0.2325 (0.2408)  time: 0.6196  data: 0.0001  max mem: 15824
[14:16:35.821966] Epoch: [16]  [180/345]  eta: 0:01:42  lr: 0.000103  loss: 0.2324 (0.2402)  time: 0.6207  data: 0.0001  max mem: 15824
[14:16:48.213941] Epoch: [16]  [200/345]  eta: 0:01:30  lr: 0.000104  loss: 0.2456 (0.2407)  time: 0.6196  data: 0.0001  max mem: 15824
[14:17:00.624954] Epoch: [16]  [220/345]  eta: 0:01:17  lr: 0.000104  loss: 0.2339 (0.2402)  time: 0.6205  data: 0.0001  max mem: 15824
[14:17:13.027825] Epoch: [16]  [240/345]  eta: 0:01:05  lr: 0.000104  loss: 0.2315 (0.2395)  time: 0.6201  data: 0.0001  max mem: 15824
[14:17:25.428151] Epoch: [16]  [260/345]  eta: 0:00:52  lr: 0.000105  loss: 0.2279 (0.2389)  time: 0.6200  data: 0.0001  max mem: 15824
[14:17:37.816438] Epoch: [16]  [280/345]  eta: 0:00:40  lr: 0.000105  loss: 0.2161 (0.2380)  time: 0.6194  data: 0.0001  max mem: 15824
[14:17:50.193694] Epoch: [16]  [300/345]  eta: 0:00:27  lr: 0.000105  loss: 0.2473 (0.2380)  time: 0.6188  data: 0.0001  max mem: 15824
[14:18:02.569472] Epoch: [16]  [320/345]  eta: 0:00:15  lr: 0.000106  loss: 0.2313 (0.2378)  time: 0.6187  data: 0.0001  max mem: 15824
[14:18:14.933436] Epoch: [16]  [340/345]  eta: 0:00:03  lr: 0.000106  loss: 0.2196 (0.2370)  time: 0.6182  data: 0.0001  max mem: 15824
[14:18:17.405143] Epoch: [16]  [344/345]  eta: 0:00:00  lr: 0.000106  loss: 0.2248 (0.2373)  time: 0.6179  data: 0.0001  max mem: 15824
[14:18:17.479667] Epoch: [16] Total time: 0:03:34 (0.6205 s / it)
[14:18:17.479884] Averaged stats: lr: 0.000106  loss: 0.2248 (0.2373)
[14:18:18.129603] Test:  [  0/345]  eta: 0:03:42  loss: 0.2719 (0.2719)  time: 0.6446  data: 0.4636  max mem: 15824
[14:18:19.914993] Test:  [ 10/345]  eta: 0:01:13  loss: 0.2265 (0.2312)  time: 0.2208  data: 0.0422  max mem: 15824
[14:18:21.708707] Test:  [ 20/345]  eta: 0:01:05  loss: 0.2262 (0.2267)  time: 0.1789  data: 0.0001  max mem: 15824
[14:18:23.503917] Test:  [ 30/345]  eta: 0:01:01  loss: 0.2228 (0.2271)  time: 0.1794  data: 0.0001  max mem: 15824
[14:18:25.300703] Test:  [ 40/345]  eta: 0:00:58  loss: 0.2108 (0.2242)  time: 0.1795  data: 0.0001  max mem: 15824
[14:18:27.103306] Test:  [ 50/345]  eta: 0:00:55  loss: 0.2129 (0.2233)  time: 0.1799  data: 0.0001  max mem: 15824
[14:18:28.913848] Test:  [ 60/345]  eta: 0:00:53  loss: 0.2129 (0.2231)  time: 0.1805  data: 0.0001  max mem: 15824
[14:18:30.722156] Test:  [ 70/345]  eta: 0:00:51  loss: 0.2205 (0.2242)  time: 0.1808  data: 0.0001  max mem: 15824
[14:18:32.533159] Test:  [ 80/345]  eta: 0:00:49  loss: 0.2248 (0.2247)  time: 0.1809  data: 0.0001  max mem: 15824
[14:18:34.348320] Test:  [ 90/345]  eta: 0:00:47  loss: 0.2209 (0.2246)  time: 0.1812  data: 0.0001  max mem: 15824
[14:18:36.166442] Test:  [100/345]  eta: 0:00:45  loss: 0.2220 (0.2250)  time: 0.1816  data: 0.0001  max mem: 15824
[14:18:37.990066] Test:  [110/345]  eta: 0:00:43  loss: 0.2168 (0.2242)  time: 0.1820  data: 0.0001  max mem: 15824
[14:18:39.815465] Test:  [120/345]  eta: 0:00:41  loss: 0.2148 (0.2248)  time: 0.1824  data: 0.0001  max mem: 15824
[14:18:41.642977] Test:  [130/345]  eta: 0:00:39  loss: 0.2155 (0.2243)  time: 0.1826  data: 0.0001  max mem: 15824
[14:18:43.475969] Test:  [140/345]  eta: 0:00:37  loss: 0.2201 (0.2242)  time: 0.1830  data: 0.0001  max mem: 15824
[14:18:45.310899] Test:  [150/345]  eta: 0:00:35  loss: 0.2224 (0.2242)  time: 0.1833  data: 0.0001  max mem: 15824
[14:18:47.150537] Test:  [160/345]  eta: 0:00:34  loss: 0.2217 (0.2236)  time: 0.1837  data: 0.0001  max mem: 15824
[14:18:48.994545] Test:  [170/345]  eta: 0:00:32  loss: 0.2118 (0.2240)  time: 0.1841  data: 0.0001  max mem: 15824
[14:18:50.841341] Test:  [180/345]  eta: 0:00:30  loss: 0.2108 (0.2233)  time: 0.1845  data: 0.0001  max mem: 15824
[14:18:52.692097] Test:  [190/345]  eta: 0:00:28  loss: 0.2108 (0.2227)  time: 0.1848  data: 0.0001  max mem: 15824
[14:18:54.544182] Test:  [200/345]  eta: 0:00:26  loss: 0.2101 (0.2222)  time: 0.1851  data: 0.0001  max mem: 15824
[14:18:56.401314] Test:  [210/345]  eta: 0:00:24  loss: 0.2091 (0.2224)  time: 0.1854  data: 0.0001  max mem: 15824
[14:18:58.261277] Test:  [220/345]  eta: 0:00:23  loss: 0.2252 (0.2226)  time: 0.1858  data: 0.0001  max mem: 15824
[14:19:00.125506] Test:  [230/345]  eta: 0:00:21  loss: 0.2255 (0.2227)  time: 0.1861  data: 0.0001  max mem: 15824
[14:19:01.996216] Test:  [240/345]  eta: 0:00:19  loss: 0.2232 (0.2227)  time: 0.1867  data: 0.0001  max mem: 15824
[14:19:03.866875] Test:  [250/345]  eta: 0:00:17  loss: 0.2149 (0.2225)  time: 0.1870  data: 0.0001  max mem: 15824
[14:19:05.740325] Test:  [260/345]  eta: 0:00:15  loss: 0.2148 (0.2226)  time: 0.1871  data: 0.0001  max mem: 15824
[14:19:07.619077] Test:  [270/345]  eta: 0:00:13  loss: 0.2239 (0.2227)  time: 0.1875  data: 0.0001  max mem: 15824
[14:19:09.499972] Test:  [280/345]  eta: 0:00:12  loss: 0.2239 (0.2226)  time: 0.1879  data: 0.0001  max mem: 15824
[14:19:11.384778] Test:  [290/345]  eta: 0:00:10  loss: 0.2113 (0.2224)  time: 0.1882  data: 0.0001  max mem: 15824
[14:19:13.274347] Test:  [300/345]  eta: 0:00:08  loss: 0.2210 (0.2224)  time: 0.1887  data: 0.0001  max mem: 15824
[14:19:15.168061] Test:  [310/345]  eta: 0:00:06  loss: 0.2213 (0.2224)  time: 0.1891  data: 0.0001  max mem: 15824
[14:19:17.063016] Test:  [320/345]  eta: 0:00:04  loss: 0.2145 (0.2225)  time: 0.1894  data: 0.0001  max mem: 15824
[14:19:18.959068] Test:  [330/345]  eta: 0:00:02  loss: 0.2212 (0.2228)  time: 0.1895  data: 0.0001  max mem: 15824
[14:19:20.858958] Test:  [340/345]  eta: 0:00:00  loss: 0.2171 (0.2227)  time: 0.1897  data: 0.0001  max mem: 15824
[14:19:21.619789] Test:  [344/345]  eta: 0:00:00  loss: 0.2171 (0.2226)  time: 0.1899  data: 0.0001  max mem: 15824
[14:19:21.689434] Test: Total time: 0:01:04 (0.1861 s / it)
[14:19:32.199220] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4472 (0.4472)  time: 0.5573  data: 0.3768  max mem: 15824
[14:19:33.971789] Test:  [10/57]  eta: 0:00:09  loss: 0.4468 (0.4592)  time: 0.2117  data: 0.0344  max mem: 15824
[14:19:35.750986] Test:  [20/57]  eta: 0:00:07  loss: 0.4260 (0.4317)  time: 0.1775  data: 0.0001  max mem: 15824
[14:19:37.531750] Test:  [30/57]  eta: 0:00:05  loss: 0.2888 (0.3802)  time: 0.1779  data: 0.0001  max mem: 15824
[14:19:39.315889] Test:  [40/57]  eta: 0:00:03  loss: 0.2756 (0.3598)  time: 0.1782  data: 0.0001  max mem: 15824
[14:19:41.101621] Test:  [50/57]  eta: 0:00:01  loss: 0.3277 (0.3651)  time: 0.1784  data: 0.0001  max mem: 15824
[14:19:42.074181] Test:  [56/57]  eta: 0:00:00  loss: 0.3510 (0.3825)  time: 0.1735  data: 0.0000  max mem: 15824
[14:19:42.133492] Test: Total time: 0:00:10 (0.1841 s / it)
[14:19:43.869087] Dice score of the network on the train images: 0.809278, val images: 0.757731
[14:19:43.869333] saving best_prec_model_0 @ epoch 16
[14:19:45.059531] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:19:46.067571] Epoch: [17]  [  0/345]  eta: 0:05:47  lr: 0.000106  loss: 0.1961 (0.1961)  time: 1.0069  data: 0.3796  max mem: 15824
[14:19:58.356814] Epoch: [17]  [ 20/345]  eta: 0:03:25  lr: 0.000107  loss: 0.2109 (0.2211)  time: 0.6144  data: 0.0001  max mem: 15824
[14:20:10.690172] Epoch: [17]  [ 40/345]  eta: 0:03:10  lr: 0.000107  loss: 0.2368 (0.2295)  time: 0.6166  data: 0.0001  max mem: 15824
[14:20:23.075133] Epoch: [17]  [ 60/345]  eta: 0:02:57  lr: 0.000107  loss: 0.2216 (0.2286)  time: 0.6192  data: 0.0001  max mem: 15824
[14:20:35.466351] Epoch: [17]  [ 80/345]  eta: 0:02:44  lr: 0.000108  loss: 0.2413 (0.2315)  time: 0.6195  data: 0.0001  max mem: 15824
[14:20:47.850721] Epoch: [17]  [100/345]  eta: 0:02:32  lr: 0.000108  loss: 0.2120 (0.2292)  time: 0.6192  data: 0.0001  max mem: 15824
[14:21:00.235869] Epoch: [17]  [120/345]  eta: 0:02:19  lr: 0.000108  loss: 0.2286 (0.2289)  time: 0.6192  data: 0.0001  max mem: 15824
[14:21:12.646233] Epoch: [17]  [140/345]  eta: 0:02:07  lr: 0.000109  loss: 0.2276 (0.2290)  time: 0.6205  data: 0.0001  max mem: 15824
[14:21:25.051947] Epoch: [17]  [160/345]  eta: 0:01:54  lr: 0.000109  loss: 0.2244 (0.2290)  time: 0.6202  data: 0.0001  max mem: 15824
[14:21:37.450133] Epoch: [17]  [180/345]  eta: 0:01:42  lr: 0.000110  loss: 0.2124 (0.2282)  time: 0.6199  data: 0.0001  max mem: 15824
[14:21:49.846109] Epoch: [17]  [200/345]  eta: 0:01:30  lr: 0.000110  loss: 0.2187 (0.2287)  time: 0.6198  data: 0.0001  max mem: 15824
[14:22:02.260302] Epoch: [17]  [220/345]  eta: 0:01:17  lr: 0.000110  loss: 0.2250 (0.2290)  time: 0.6207  data: 0.0001  max mem: 15824
[14:22:14.663201] Epoch: [17]  [240/345]  eta: 0:01:05  lr: 0.000111  loss: 0.2458 (0.2303)  time: 0.6201  data: 0.0001  max mem: 15824
[14:22:27.074287] Epoch: [17]  [260/345]  eta: 0:00:52  lr: 0.000111  loss: 0.2380 (0.2313)  time: 0.6205  data: 0.0001  max mem: 15824
[14:22:39.483746] Epoch: [17]  [280/345]  eta: 0:00:40  lr: 0.000111  loss: 0.2223 (0.2304)  time: 0.6204  data: 0.0001  max mem: 15824
[14:22:51.878360] Epoch: [17]  [300/345]  eta: 0:00:27  lr: 0.000112  loss: 0.2142 (0.2299)  time: 0.6197  data: 0.0001  max mem: 15824
[14:23:04.273597] Epoch: [17]  [320/345]  eta: 0:00:15  lr: 0.000112  loss: 0.2306 (0.2299)  time: 0.6197  data: 0.0001  max mem: 15824
[14:23:16.658981] Epoch: [17]  [340/345]  eta: 0:00:03  lr: 0.000112  loss: 0.2260 (0.2298)  time: 0.6192  data: 0.0001  max mem: 15824
[14:23:19.131705] Epoch: [17]  [344/345]  eta: 0:00:00  lr: 0.000112  loss: 0.2302 (0.2300)  time: 0.6189  data: 0.0001  max mem: 15824
[14:23:19.201947] Epoch: [17] Total time: 0:03:34 (0.6207 s / it)
[14:23:19.202339] Averaged stats: lr: 0.000112  loss: 0.2302 (0.2300)
[14:23:19.771554] Test:  [  0/345]  eta: 0:03:14  loss: 0.1860 (0.1860)  time: 0.5645  data: 0.3814  max mem: 15824
[14:23:21.560306] Test:  [ 10/345]  eta: 0:01:11  loss: 0.2013 (0.2044)  time: 0.2138  data: 0.0348  max mem: 15824
[14:23:23.355659] Test:  [ 20/345]  eta: 0:01:04  loss: 0.2102 (0.2125)  time: 0.1791  data: 0.0001  max mem: 15824
[14:23:25.150025] Test:  [ 30/345]  eta: 0:01:00  loss: 0.2102 (0.2110)  time: 0.1794  data: 0.0001  max mem: 15824
[14:23:26.949220] Test:  [ 40/345]  eta: 0:00:57  loss: 0.2182 (0.2181)  time: 0.1796  data: 0.0001  max mem: 15824
[14:23:28.751537] Test:  [ 50/345]  eta: 0:00:55  loss: 0.2194 (0.2178)  time: 0.1800  data: 0.0001  max mem: 15824
[14:23:30.559705] Test:  [ 60/345]  eta: 0:00:53  loss: 0.2246 (0.2185)  time: 0.1805  data: 0.0001  max mem: 15824
[14:23:32.366973] Test:  [ 70/345]  eta: 0:00:50  loss: 0.2099 (0.2181)  time: 0.1807  data: 0.0001  max mem: 15824
[14:23:34.180760] Test:  [ 80/345]  eta: 0:00:48  loss: 0.2098 (0.2174)  time: 0.1810  data: 0.0001  max mem: 15824
[14:23:35.997417] Test:  [ 90/345]  eta: 0:00:47  loss: 0.2134 (0.2166)  time: 0.1815  data: 0.0001  max mem: 15824
[14:23:37.816066] Test:  [100/345]  eta: 0:00:45  loss: 0.2159 (0.2163)  time: 0.1817  data: 0.0001  max mem: 15824
[14:23:39.638390] Test:  [110/345]  eta: 0:00:43  loss: 0.2099 (0.2164)  time: 0.1820  data: 0.0001  max mem: 15824
[14:23:41.464574] Test:  [120/345]  eta: 0:00:41  loss: 0.2003 (0.2145)  time: 0.1824  data: 0.0001  max mem: 15824
[14:23:43.293306] Test:  [130/345]  eta: 0:00:39  loss: 0.2001 (0.2140)  time: 0.1827  data: 0.0001  max mem: 15824
[14:23:45.124670] Test:  [140/345]  eta: 0:00:37  loss: 0.2119 (0.2145)  time: 0.1829  data: 0.0001  max mem: 15824
[14:23:46.961300] Test:  [150/345]  eta: 0:00:35  loss: 0.2175 (0.2150)  time: 0.1833  data: 0.0001  max mem: 15824
[14:23:48.802204] Test:  [160/345]  eta: 0:00:33  loss: 0.2139 (0.2152)  time: 0.1838  data: 0.0001  max mem: 15824
[14:23:50.645033] Test:  [170/345]  eta: 0:00:32  loss: 0.2158 (0.2156)  time: 0.1841  data: 0.0001  max mem: 15824
[14:23:52.493845] Test:  [180/345]  eta: 0:00:30  loss: 0.2158 (0.2153)  time: 0.1845  data: 0.0001  max mem: 15824
[14:23:54.346137] Test:  [190/345]  eta: 0:00:28  loss: 0.2138 (0.2159)  time: 0.1850  data: 0.0001  max mem: 15824
[14:23:56.202240] Test:  [200/345]  eta: 0:00:26  loss: 0.2209 (0.2160)  time: 0.1854  data: 0.0001  max mem: 15824
[14:23:58.060506] Test:  [210/345]  eta: 0:00:24  loss: 0.2183 (0.2156)  time: 0.1857  data: 0.0001  max mem: 15824
[14:23:59.920666] Test:  [220/345]  eta: 0:00:23  loss: 0.2080 (0.2156)  time: 0.1859  data: 0.0001  max mem: 15824
[14:24:01.785059] Test:  [230/345]  eta: 0:00:21  loss: 0.2131 (0.2155)  time: 0.1862  data: 0.0001  max mem: 15824
[14:24:03.654148] Test:  [240/345]  eta: 0:00:19  loss: 0.2246 (0.2159)  time: 0.1866  data: 0.0001  max mem: 15824
[14:24:05.525619] Test:  [250/345]  eta: 0:00:17  loss: 0.2156 (0.2158)  time: 0.1870  data: 0.0001  max mem: 15824
[14:24:07.400455] Test:  [260/345]  eta: 0:00:15  loss: 0.2130 (0.2157)  time: 0.1872  data: 0.0001  max mem: 15824
[14:24:09.279617] Test:  [270/345]  eta: 0:00:13  loss: 0.2130 (0.2155)  time: 0.1876  data: 0.0001  max mem: 15824
[14:24:11.164912] Test:  [280/345]  eta: 0:00:12  loss: 0.2172 (0.2157)  time: 0.1882  data: 0.0001  max mem: 15824
[14:24:13.051318] Test:  [290/345]  eta: 0:00:10  loss: 0.2170 (0.2155)  time: 0.1885  data: 0.0001  max mem: 15824
[14:24:14.942386] Test:  [300/345]  eta: 0:00:08  loss: 0.2203 (0.2160)  time: 0.1888  data: 0.0001  max mem: 15824
[14:24:16.833367] Test:  [310/345]  eta: 0:00:06  loss: 0.2019 (0.2154)  time: 0.1890  data: 0.0001  max mem: 15824
[14:24:18.730941] Test:  [320/345]  eta: 0:00:04  loss: 0.2019 (0.2152)  time: 0.1894  data: 0.0001  max mem: 15824
[14:24:20.630225] Test:  [330/345]  eta: 0:00:02  loss: 0.2075 (0.2151)  time: 0.1898  data: 0.0001  max mem: 15824
[14:24:22.530177] Test:  [340/345]  eta: 0:00:00  loss: 0.2163 (0.2150)  time: 0.1899  data: 0.0001  max mem: 15824
[14:24:23.291246] Test:  [344/345]  eta: 0:00:00  loss: 0.2163 (0.2150)  time: 0.1900  data: 0.0001  max mem: 15824
[14:24:23.357342] Test: Total time: 0:01:04 (0.1859 s / it)
[14:24:33.765741] Test:  [ 0/57]  eta: 0:00:32  loss: 0.4884 (0.4884)  time: 0.5641  data: 0.3842  max mem: 15824
[14:24:35.537818] Test:  [10/57]  eta: 0:00:09  loss: 0.4434 (0.4666)  time: 0.2123  data: 0.0350  max mem: 15824
[14:24:37.315419] Test:  [20/57]  eta: 0:00:07  loss: 0.4183 (0.4382)  time: 0.1774  data: 0.0001  max mem: 15824
[14:24:39.098577] Test:  [30/57]  eta: 0:00:05  loss: 0.3028 (0.3889)  time: 0.1780  data: 0.0001  max mem: 15824
[14:24:40.884965] Test:  [40/57]  eta: 0:00:03  loss: 0.2930 (0.3704)  time: 0.1784  data: 0.0001  max mem: 15824
[14:24:42.671453] Test:  [50/57]  eta: 0:00:01  loss: 0.3243 (0.3762)  time: 0.1786  data: 0.0001  max mem: 15824
[14:24:43.646845] Test:  [56/57]  eta: 0:00:00  loss: 0.3665 (0.3959)  time: 0.1738  data: 0.0001  max mem: 15824
[14:24:43.721804] Test: Total time: 0:00:10 (0.1846 s / it)
[14:24:45.479108] Dice score of the network on the train images: 0.810806, val images: 0.744633
[14:24:45.482690] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:24:46.483207] Epoch: [18]  [  0/345]  eta: 0:05:44  lr: 0.000113  loss: 0.2002 (0.2002)  time: 0.9994  data: 0.3784  max mem: 15824
[14:24:58.792066] Epoch: [18]  [ 20/345]  eta: 0:03:25  lr: 0.000113  loss: 0.2242 (0.2236)  time: 0.6154  data: 0.0001  max mem: 15824
[14:25:11.151283] Epoch: [18]  [ 40/345]  eta: 0:03:10  lr: 0.000113  loss: 0.2264 (0.2232)  time: 0.6179  data: 0.0001  max mem: 15824
[14:25:23.543301] Epoch: [18]  [ 60/345]  eta: 0:02:57  lr: 0.000114  loss: 0.2146 (0.2235)  time: 0.6196  data: 0.0001  max mem: 15824
[14:25:35.935748] Epoch: [18]  [ 80/345]  eta: 0:02:45  lr: 0.000114  loss: 0.2254 (0.2251)  time: 0.6196  data: 0.0001  max mem: 15824
[14:25:48.348650] Epoch: [18]  [100/345]  eta: 0:02:32  lr: 0.000114  loss: 0.2197 (0.2253)  time: 0.6206  data: 0.0001  max mem: 15824
[14:26:00.768790] Epoch: [18]  [120/345]  eta: 0:02:19  lr: 0.000115  loss: 0.2284 (0.2256)  time: 0.6210  data: 0.0001  max mem: 15824
[14:26:13.185093] Epoch: [18]  [140/345]  eta: 0:02:07  lr: 0.000115  loss: 0.2275 (0.2262)  time: 0.6208  data: 0.0001  max mem: 15824

[14:26:25.598568] Epoch: [18]  [160/345]  eta: 0:01:55  lr: 0.000115  loss: 0.2249 (0.2255)  time: 0.6206  data: 0.0001  max mem: 15824
[14:26:38.027416] Epoch: [18]  [180/345]  eta: 0:01:42  lr: 0.000116  loss: 0.2203 (0.2250)  time: 0.6214  data: 0.0001  max mem: 15824
[14:26:50.564460] Epoch: [18]  [200/345]  eta: 0:01:30  lr: 0.000116  loss: 0.2126 (0.2243)  time: 0.6268  data: 0.0001  max mem: 15824
[14:27:02.973432] Epoch: [18]  [220/345]  eta: 0:01:17  lr: 0.000116  loss: 0.2136 (0.2233)  time: 0.6204  data: 0.0001  max mem: 15824
[14:27:15.363676] Epoch: [18]  [240/345]  eta: 0:01:05  lr: 0.000117  loss: 0.2168 (0.2231)  time: 0.6195  data: 0.0001  max mem: 15824
[14:27:27.774971] Epoch: [18]  [260/345]  eta: 0:00:52  lr: 0.000117  loss: 0.2145 (0.2235)  time: 0.6205  data: 0.0001  max mem: 15824
[14:27:40.170133] Epoch: [18]  [280/345]  eta: 0:00:40  lr: 0.000118  loss: 0.2132 (0.2230)  time: 0.6197  data: 0.0001  max mem: 15824
[14:27:52.564360] Epoch: [18]  [300/345]  eta: 0:00:27  lr: 0.000118  loss: 0.2278 (0.2234)  time: 0.6197  data: 0.0001  max mem: 15824
[14:28:04.979991] Epoch: [18]  [320/345]  eta: 0:00:15  lr: 0.000118  loss: 0.2402 (0.2247)  time: 0.6207  data: 0.0001  max mem: 15824
[14:28:17.375926] Epoch: [18]  [340/345]  eta: 0:00:03  lr: 0.000119  loss: 0.2177 (0.2246)  time: 0.6198  data: 0.0001  max mem: 15824
[14:28:19.852664] Epoch: [18]  [344/345]  eta: 0:00:00  lr: 0.000119  loss: 0.2081 (0.2244)  time: 0.6195  data: 0.0001  max mem: 15824
[14:28:19.918146] Epoch: [18] Total time: 0:03:34 (0.6216 s / it)
[14:28:19.918495] Averaged stats: lr: 0.000119  loss: 0.2081 (0.2244)
[14:28:20.496589] Test:  [  0/345]  eta: 0:03:17  loss: 0.1934 (0.1934)  time: 0.5729  data: 0.3904  max mem: 15824
[14:28:22.287192] Test:  [ 10/345]  eta: 0:01:11  loss: 0.2074 (0.2131)  time: 0.2148  data: 0.0356  max mem: 15824
[14:28:24.080894] Test:  [ 20/345]  eta: 0:01:04  loss: 0.2109 (0.2113)  time: 0.1791  data: 0.0001  max mem: 15824
[14:28:25.880379] Test:  [ 30/345]  eta: 0:01:00  loss: 0.2103 (0.2101)  time: 0.1796  data: 0.0001  max mem: 15824
[14:28:27.681097] Test:  [ 40/345]  eta: 0:00:57  loss: 0.2129 (0.2141)  time: 0.1799  data: 0.0001  max mem: 15824
[14:28:29.482245] Test:  [ 50/345]  eta: 0:00:55  loss: 0.2126 (0.2130)  time: 0.1800  data: 0.0001  max mem: 15824
[14:28:31.287204] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1992 (0.2110)  time: 0.1802  data: 0.0001  max mem: 15824
[14:28:33.100017] Test:  [ 70/345]  eta: 0:00:51  loss: 0.2041 (0.2112)  time: 0.1808  data: 0.0001  max mem: 15824
[14:28:34.912331] Test:  [ 80/345]  eta: 0:00:49  loss: 0.2035 (0.2114)  time: 0.1812  data: 0.0001  max mem: 15824
[14:28:36.729946] Test:  [ 90/345]  eta: 0:00:47  loss: 0.2025 (0.2107)  time: 0.1814  data: 0.0001  max mem: 15824
[14:28:38.548743] Test:  [100/345]  eta: 0:00:45  loss: 0.1933 (0.2101)  time: 0.1818  data: 0.0001  max mem: 15824
[14:28:40.374217] Test:  [110/345]  eta: 0:00:43  loss: 0.2017 (0.2099)  time: 0.1822  data: 0.0001  max mem: 15824
[14:28:42.201316] Test:  [120/345]  eta: 0:00:41  loss: 0.2086 (0.2100)  time: 0.1826  data: 0.0001  max mem: 15824
[14:28:44.030540] Test:  [130/345]  eta: 0:00:39  loss: 0.2083 (0.2116)  time: 0.1828  data: 0.0001  max mem: 15824
[14:28:45.863345] Test:  [140/345]  eta: 0:00:37  loss: 0.2083 (0.2119)  time: 0.1830  data: 0.0001  max mem: 15824
[14:28:47.699484] Test:  [150/345]  eta: 0:00:35  loss: 0.2088 (0.2121)  time: 0.1834  data: 0.0001  max mem: 15824
[14:28:49.541301] Test:  [160/345]  eta: 0:00:34  loss: 0.2147 (0.2122)  time: 0.1838  data: 0.0001  max mem: 15824
[14:28:51.386153] Test:  [170/345]  eta: 0:00:32  loss: 0.2094 (0.2118)  time: 0.1843  data: 0.0001  max mem: 15824
[14:28:53.235044] Test:  [180/345]  eta: 0:00:30  loss: 0.1984 (0.2109)  time: 0.1846  data: 0.0001  max mem: 15824
[14:28:55.086060] Test:  [190/345]  eta: 0:00:28  loss: 0.1963 (0.2108)  time: 0.1849  data: 0.0001  max mem: 15824
[14:28:56.942989] Test:  [200/345]  eta: 0:00:26  loss: 0.2077 (0.2110)  time: 0.1853  data: 0.0001  max mem: 15824
[14:28:58.800456] Test:  [210/345]  eta: 0:00:24  loss: 0.2173 (0.2116)  time: 0.1857  data: 0.0001  max mem: 15824
[14:29:00.663277] Test:  [220/345]  eta: 0:00:23  loss: 0.2037 (0.2114)  time: 0.1859  data: 0.0001  max mem: 15824
[14:29:02.528382] Test:  [230/345]  eta: 0:00:21  loss: 0.2013 (0.2111)  time: 0.1863  data: 0.0001  max mem: 15824
[14:29:04.398082] Test:  [240/345]  eta: 0:00:19  loss: 0.1931 (0.2111)  time: 0.1867  data: 0.0001  max mem: 15824
[14:29:06.271591] Test:  [250/345]  eta: 0:00:17  loss: 0.2053 (0.2110)  time: 0.1871  data: 0.0001  max mem: 15824
[14:29:08.147942] Test:  [260/345]  eta: 0:00:15  loss: 0.2043 (0.2111)  time: 0.1874  data: 0.0001  max mem: 15824
[14:29:10.028726] Test:  [270/345]  eta: 0:00:13  loss: 0.2043 (0.2111)  time: 0.1878  data: 0.0001  max mem: 15824
[14:29:11.911330] Test:  [280/345]  eta: 0:00:12  loss: 0.2147 (0.2111)  time: 0.1881  data: 0.0001  max mem: 15824
[14:29:13.796955] Test:  [290/345]  eta: 0:00:10  loss: 0.1996 (0.2107)  time: 0.1883  data: 0.0001  max mem: 15824
[14:29:15.687900] Test:  [300/345]  eta: 0:00:08  loss: 0.1996 (0.2105)  time: 0.1888  data: 0.0001  max mem: 15824
[14:29:17.581508] Test:  [310/345]  eta: 0:00:06  loss: 0.1924 (0.2102)  time: 0.1892  data: 0.0001  max mem: 15824
[14:29:19.478970] Test:  [320/345]  eta: 0:00:04  loss: 0.1999 (0.2100)  time: 0.1895  data: 0.0001  max mem: 15824
[14:29:21.381300] Test:  [330/345]  eta: 0:00:02  loss: 0.2093 (0.2104)  time: 0.1899  data: 0.0001  max mem: 15824
[14:29:23.281326] Test:  [340/345]  eta: 0:00:00  loss: 0.2269 (0.2107)  time: 0.1901  data: 0.0001  max mem: 15824
[14:29:24.042786] Test:  [344/345]  eta: 0:00:00  loss: 0.2226 (0.2106)  time: 0.1900  data: 0.0001  max mem: 15824
[14:29:24.117369] Test: Total time: 0:01:04 (0.1861 s / it)
[14:29:34.481491] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4753 (0.4753)  time: 0.5600  data: 0.3799  max mem: 15824
[14:29:36.254352] Test:  [10/57]  eta: 0:00:09  loss: 0.4572 (0.4570)  time: 0.2120  data: 0.0346  max mem: 15824
[14:29:38.032877] Test:  [20/57]  eta: 0:00:07  loss: 0.4442 (0.4341)  time: 0.1775  data: 0.0001  max mem: 15824
[14:29:39.814861] Test:  [30/57]  eta: 0:00:05  loss: 0.3429 (0.3870)  time: 0.1780  data: 0.0001  max mem: 15824
[14:29:41.601501] Test:  [40/57]  eta: 0:00:03  loss: 0.2817 (0.3675)  time: 0.1784  data: 0.0001  max mem: 15824
[14:29:43.387747] Test:  [50/57]  eta: 0:00:01  loss: 0.3393 (0.3681)  time: 0.1786  data: 0.0001  max mem: 15824
[14:29:44.358448] Test:  [56/57]  eta: 0:00:00  loss: 0.3516 (0.3783)  time: 0.1735  data: 0.0000  max mem: 15824
[14:29:44.429116] Test: Total time: 0:00:10 (0.1844 s / it)
[14:29:46.160837] Dice score of the network on the train images: 0.815028, val images: 0.768002
[14:29:46.164506] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:29:47.180034] Epoch: [19]  [  0/345]  eta: 0:05:50  lr: 0.000119  loss: 0.2445 (0.2445)  time: 1.0147  data: 0.3871  max mem: 15824
[14:29:59.498208] Epoch: [19]  [ 20/345]  eta: 0:03:26  lr: 0.000119  loss: 0.2298 (0.2359)  time: 0.6159  data: 0.0001  max mem: 15824
[14:30:11.827151] Epoch: [19]  [ 40/345]  eta: 0:03:10  lr: 0.000119  loss: 0.2134 (0.2262)  time: 0.6164  data: 0.0001  max mem: 15824
[14:30:24.214966] Epoch: [19]  [ 60/345]  eta: 0:02:57  lr: 0.000120  loss: 0.2106 (0.2217)  time: 0.6193  data: 0.0001  max mem: 15824
[14:30:36.608142] Epoch: [19]  [ 80/345]  eta: 0:02:45  lr: 0.000120  loss: 0.1973 (0.2164)  time: 0.6196  data: 0.0001  max mem: 15824
[14:30:49.005569] Epoch: [19]  [100/345]  eta: 0:02:32  lr: 0.000121  loss: 0.2063 (0.2154)  time: 0.6198  data: 0.0001  max mem: 15824
[14:31:01.404028] Epoch: [19]  [120/345]  eta: 0:02:19  lr: 0.000121  loss: 0.2122 (0.2163)  time: 0.6199  data: 0.0001  max mem: 15824
[14:31:13.830954] Epoch: [19]  [140/345]  eta: 0:02:07  lr: 0.000121  loss: 0.2210 (0.2170)  time: 0.6213  data: 0.0001  max mem: 15824
[14:31:26.255008] Epoch: [19]  [160/345]  eta: 0:01:55  lr: 0.000122  loss: 0.2092 (0.2161)  time: 0.6212  data: 0.0001  max mem: 15824
[14:31:38.661006] Epoch: [19]  [180/345]  eta: 0:01:42  lr: 0.000122  loss: 0.2208 (0.2171)  time: 0.6203  data: 0.0001  max mem: 15824
[14:31:51.075035] Epoch: [19]  [200/345]  eta: 0:01:30  lr: 0.000122  loss: 0.2180 (0.2177)  time: 0.6207  data: 0.0001  max mem: 15824
[14:32:03.485511] Epoch: [19]  [220/345]  eta: 0:01:17  lr: 0.000123  loss: 0.2191 (0.2176)  time: 0.6205  data: 0.0001  max mem: 15824
[14:32:15.900164] Epoch: [19]  [240/345]  eta: 0:01:05  lr: 0.000123  loss: 0.2107 (0.2175)  time: 0.6207  data: 0.0001  max mem: 15824
[14:32:28.298526] Epoch: [19]  [260/345]  eta: 0:00:52  lr: 0.000123  loss: 0.2154 (0.2178)  time: 0.6199  data: 0.0001  max mem: 15824
[14:32:40.688975] Epoch: [19]  [280/345]  eta: 0:00:40  lr: 0.000124  loss: 0.2170 (0.2185)  time: 0.6195  data: 0.0001  max mem: 15824
[14:32:53.086073] Epoch: [19]  [300/345]  eta: 0:00:27  lr: 0.000124  loss: 0.2097 (0.2181)  time: 0.6198  data: 0.0001  max mem: 15824
[14:33:05.484376] Epoch: [19]  [320/345]  eta: 0:00:15  lr: 0.000125  loss: 0.2085 (0.2183)  time: 0.6199  data: 0.0001  max mem: 15824
[14:33:17.873344] Epoch: [19]  [340/345]  eta: 0:00:03  lr: 0.000125  loss: 0.2182 (0.2184)  time: 0.6194  data: 0.0001  max mem: 15824
[14:33:20.354314] Epoch: [19]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.2182 (0.2186)  time: 0.6194  data: 0.0001  max mem: 15824
[14:33:20.426176] Epoch: [19] Total time: 0:03:34 (0.6210 s / it)
[14:33:20.426374] Averaged stats: lr: 0.000125  loss: 0.2182 (0.2186)
[14:33:21.012414] Test:  [  0/345]  eta: 0:03:20  loss: 0.2275 (0.2275)  time: 0.5797  data: 0.3978  max mem: 15824
[14:33:22.802216] Test:  [ 10/345]  eta: 0:01:12  loss: 0.2114 (0.2185)  time: 0.2153  data: 0.0362  max mem: 15824
[14:33:24.597643] Test:  [ 20/345]  eta: 0:01:04  loss: 0.2090 (0.2197)  time: 0.1792  data: 0.0001  max mem: 15824
[14:33:26.394782] Test:  [ 30/345]  eta: 0:01:00  loss: 0.2090 (0.2143)  time: 0.1796  data: 0.0001  max mem: 15824
[14:33:28.193924] Test:  [ 40/345]  eta: 0:00:57  loss: 0.2078 (0.2132)  time: 0.1797  data: 0.0001  max mem: 15824
[14:33:29.997188] Test:  [ 50/345]  eta: 0:00:55  loss: 0.2090 (0.2130)  time: 0.1801  data: 0.0001  max mem: 15824
[14:33:31.805283] Test:  [ 60/345]  eta: 0:00:53  loss: 0.2057 (0.2103)  time: 0.1805  data: 0.0001  max mem: 15824
[14:33:33.612448] Test:  [ 70/345]  eta: 0:00:51  loss: 0.2018 (0.2087)  time: 0.1807  data: 0.0001  max mem: 15824
[14:33:35.427425] Test:  [ 80/345]  eta: 0:00:49  loss: 0.2061 (0.2088)  time: 0.1810  data: 0.0001  max mem: 15824
[14:33:37.245123] Test:  [ 90/345]  eta: 0:00:47  loss: 0.2121 (0.2098)  time: 0.1816  data: 0.0001  max mem: 15824
[14:33:39.065442] Test:  [100/345]  eta: 0:00:45  loss: 0.2079 (0.2095)  time: 0.1818  data: 0.0001  max mem: 15824
[14:33:40.887581] Test:  [110/345]  eta: 0:00:43  loss: 0.2079 (0.2100)  time: 0.1821  data: 0.0001  max mem: 15824
[14:33:42.714478] Test:  [120/345]  eta: 0:00:41  loss: 0.2120 (0.2099)  time: 0.1824  data: 0.0001  max mem: 15824
[14:33:44.544839] Test:  [130/345]  eta: 0:00:39  loss: 0.2098 (0.2090)  time: 0.1828  data: 0.0001  max mem: 15824
[14:33:46.379813] Test:  [140/345]  eta: 0:00:37  loss: 0.2082 (0.2088)  time: 0.1832  data: 0.0001  max mem: 15824
[14:33:48.215591] Test:  [150/345]  eta: 0:00:35  loss: 0.2191 (0.2102)  time: 0.1835  data: 0.0001  max mem: 15824
[14:33:50.055324] Test:  [160/345]  eta: 0:00:34  loss: 0.1993 (0.2094)  time: 0.1837  data: 0.0001  max mem: 15824
[14:33:51.900119] Test:  [170/345]  eta: 0:00:32  loss: 0.1939 (0.2085)  time: 0.1842  data: 0.0001  max mem: 15824
[14:33:53.749025] Test:  [180/345]  eta: 0:00:30  loss: 0.1983 (0.2087)  time: 0.1846  data: 0.0001  max mem: 15824
[14:33:55.601949] Test:  [190/345]  eta: 0:00:28  loss: 0.2085 (0.2085)  time: 0.1850  data: 0.0001  max mem: 15824
[14:33:57.459326] Test:  [200/345]  eta: 0:00:26  loss: 0.2039 (0.2082)  time: 0.1855  data: 0.0001  max mem: 15824
[14:33:59.318455] Test:  [210/345]  eta: 0:00:24  loss: 0.2080 (0.2080)  time: 0.1858  data: 0.0001  max mem: 15824
[14:34:01.180121] Test:  [220/345]  eta: 0:00:23  loss: 0.2091 (0.2087)  time: 0.1860  data: 0.0001  max mem: 15824
[14:34:03.047033] Test:  [230/345]  eta: 0:00:21  loss: 0.2117 (0.2093)  time: 0.1864  data: 0.0001  max mem: 15824
[14:34:04.913828] Test:  [240/345]  eta: 0:00:19  loss: 0.2117 (0.2096)  time: 0.1866  data: 0.0001  max mem: 15824
[14:34:06.784972] Test:  [250/345]  eta: 0:00:17  loss: 0.2055 (0.2097)  time: 0.1868  data: 0.0001  max mem: 15824
[14:34:08.658325] Test:  [260/345]  eta: 0:00:15  loss: 0.1975 (0.2095)  time: 0.1872  data: 0.0001  max mem: 15824
[14:34:10.536084] Test:  [270/345]  eta: 0:00:13  loss: 0.1951 (0.2092)  time: 0.1875  data: 0.0001  max mem: 15824
[14:34:12.420887] Test:  [280/345]  eta: 0:00:12  loss: 0.2044 (0.2094)  time: 0.1881  data: 0.0001  max mem: 15824
[14:34:14.305155] Test:  [290/345]  eta: 0:00:10  loss: 0.2034 (0.2090)  time: 0.1884  data: 0.0001  max mem: 15824
[14:34:16.197403] Test:  [300/345]  eta: 0:00:08  loss: 0.1961 (0.2086)  time: 0.1888  data: 0.0001  max mem: 15824
[14:34:18.091148] Test:  [310/345]  eta: 0:00:06  loss: 0.2065 (0.2084)  time: 0.1892  data: 0.0001  max mem: 15824
[14:34:19.986334] Test:  [320/345]  eta: 0:00:04  loss: 0.2092 (0.2088)  time: 0.1894  data: 0.0001  max mem: 15824
[14:34:21.884785] Test:  [330/345]  eta: 0:00:02  loss: 0.2100 (0.2088)  time: 0.1896  data: 0.0001  max mem: 15824
[14:34:23.783748] Test:  [340/345]  eta: 0:00:00  loss: 0.2075 (0.2086)  time: 0.1898  data: 0.0001  max mem: 15824
[14:34:24.545207] Test:  [344/345]  eta: 0:00:00  loss: 0.2075 (0.2085)  time: 0.1899  data: 0.0001  max mem: 15824
[14:34:24.620745] Test: Total time: 0:01:04 (0.1861 s / it)
[14:34:35.113293] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4907 (0.4907)  time: 0.5554  data: 0.3753  max mem: 15824
[14:34:36.885415] Test:  [10/57]  eta: 0:00:09  loss: 0.4621 (0.4620)  time: 0.2115  data: 0.0342  max mem: 15824
[14:34:38.664291] Test:  [20/57]  eta: 0:00:07  loss: 0.4189 (0.4379)  time: 0.1775  data: 0.0001  max mem: 15824
[14:34:40.443821] Test:  [30/57]  eta: 0:00:05  loss: 0.3148 (0.3838)  time: 0.1779  data: 0.0001  max mem: 15824
[14:34:42.229034] Test:  [40/57]  eta: 0:00:03  loss: 0.2584 (0.3592)  time: 0.1782  data: 0.0001  max mem: 15824
[14:34:44.013199] Test:  [50/57]  eta: 0:00:01  loss: 0.3063 (0.3621)  time: 0.1784  data: 0.0001  max mem: 15824
[14:34:44.984863] Test:  [56/57]  eta: 0:00:00  loss: 0.3407 (0.3810)  time: 0.1735  data: 0.0000  max mem: 15824
[14:34:45.067345] Test: Total time: 0:00:10 (0.1844 s / it)
[14:34:46.794968] Dice score of the network on the train images: 0.814617, val images: 0.769356
[14:34:46.798594] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:34:47.814977] Epoch: [20]  [  0/345]  eta: 0:05:50  lr: 0.000125  loss: 0.2114 (0.2114)  time: 1.0154  data: 0.3912  max mem: 15824
[14:35:00.166677] Epoch: [20]  [ 20/345]  eta: 0:03:26  lr: 0.000125  loss: 0.2083 (0.2056)  time: 0.6175  data: 0.0001  max mem: 15824
[14:35:12.521482] Epoch: [20]  [ 40/345]  eta: 0:03:11  lr: 0.000125  loss: 0.2034 (0.2083)  time: 0.6177  data: 0.0001  max mem: 15824
[14:35:24.918384] Epoch: [20]  [ 60/345]  eta: 0:02:58  lr: 0.000125  loss: 0.2084 (0.2097)  time: 0.6198  data: 0.0001  max mem: 15824
[14:35:37.323164] Epoch: [20]  [ 80/345]  eta: 0:02:45  lr: 0.000125  loss: 0.2002 (0.2077)  time: 0.6202  data: 0.0001  max mem: 15824
[14:35:49.727483] Epoch: [20]  [100/345]  eta: 0:02:32  lr: 0.000125  loss: 0.2075 (0.2073)  time: 0.6202  data: 0.0001  max mem: 15824
[14:36:02.128295] Epoch: [20]  [120/345]  eta: 0:02:20  lr: 0.000125  loss: 0.1999 (0.2070)  time: 0.6200  data: 0.0001  max mem: 15824
[14:36:14.550150] Epoch: [20]  [140/345]  eta: 0:02:07  lr: 0.000125  loss: 0.2164 (0.2085)  time: 0.6210  data: 0.0001  max mem: 15824
[14:36:26.978163] Epoch: [20]  [160/345]  eta: 0:01:55  lr: 0.000125  loss: 0.2119 (0.2095)  time: 0.6213  data: 0.0001  max mem: 15824
[14:36:39.390868] Epoch: [20]  [180/345]  eta: 0:01:42  lr: 0.000125  loss: 0.2145 (0.2099)  time: 0.6206  data: 0.0001  max mem: 15824
[14:36:51.816745] Epoch: [20]  [200/345]  eta: 0:01:30  lr: 0.000125  loss: 0.2121 (0.2096)  time: 0.6212  data: 0.0001  max mem: 15824
[14:37:04.229717] Epoch: [20]  [220/345]  eta: 0:01:17  lr: 0.000125  loss: 0.1970 (0.2091)  time: 0.6206  data: 0.0001  max mem: 15824
[14:37:16.661120] Epoch: [20]  [240/345]  eta: 0:01:05  lr: 0.000125  loss: 0.2157 (0.2099)  time: 0.6215  data: 0.0001  max mem: 15824
[14:37:29.074264] Epoch: [20]  [260/345]  eta: 0:00:52  lr: 0.000125  loss: 0.2075 (0.2102)  time: 0.6206  data: 0.0001  max mem: 15824
[14:37:41.466601] Epoch: [20]  [280/345]  eta: 0:00:40  lr: 0.000125  loss: 0.2214 (0.2115)  time: 0.6196  data: 0.0001  max mem: 15824
[14:37:53.865672] Epoch: [20]  [300/345]  eta: 0:00:27  lr: 0.000125  loss: 0.2307 (0.2127)  time: 0.6199  data: 0.0001  max mem: 15824
[14:38:06.264258] Epoch: [20]  [320/345]  eta: 0:00:15  lr: 0.000125  loss: 0.2146 (0.2134)  time: 0.6199  data: 0.0001  max mem: 15824
[14:38:18.657836] Epoch: [20]  [340/345]  eta: 0:00:03  lr: 0.000125  loss: 0.2293 (0.2144)  time: 0.6196  data: 0.0001  max mem: 15824
[14:38:21.131355] Epoch: [20]  [344/345]  eta: 0:00:00  lr: 0.000125  loss: 0.2293 (0.2146)  time: 0.6191  data: 0.0001  max mem: 15824
[14:38:21.206764] Epoch: [20] Total time: 0:03:34 (0.6215 s / it)
[14:38:21.206996] Averaged stats: lr: 0.000125  loss: 0.2293 (0.2146)
[14:38:21.798168] Test:  [  0/345]  eta: 0:03:22  loss: 0.1908 (0.1908)  time: 0.5859  data: 0.4035  max mem: 15824
[14:38:23.587772] Test:  [ 10/345]  eta: 0:01:12  loss: 0.1959 (0.2036)  time: 0.2159  data: 0.0368  max mem: 15824
[14:38:25.382187] Test:  [ 20/345]  eta: 0:01:04  loss: 0.2067 (0.2083)  time: 0.1791  data: 0.0001  max mem: 15824
[14:38:27.182094] Test:  [ 30/345]  eta: 0:01:00  loss: 0.2034 (0.2065)  time: 0.1797  data: 0.0001  max mem: 15824
[14:38:28.983557] Test:  [ 40/345]  eta: 0:00:57  loss: 0.2030 (0.2054)  time: 0.1800  data: 0.0001  max mem: 15824
[14:38:30.787271] Test:  [ 50/345]  eta: 0:00:55  loss: 0.2030 (0.2054)  time: 0.1802  data: 0.0001  max mem: 15824
[14:38:32.590691] Test:  [ 60/345]  eta: 0:00:53  loss: 0.2005 (0.2033)  time: 0.1803  data: 0.0001  max mem: 15824
[14:38:34.399107] Test:  [ 70/345]  eta: 0:00:51  loss: 0.2006 (0.2050)  time: 0.1805  data: 0.0001  max mem: 15824
[14:38:36.212489] Test:  [ 80/345]  eta: 0:00:49  loss: 0.2105 (0.2057)  time: 0.1810  data: 0.0001  max mem: 15824
[14:38:38.030598] Test:  [ 90/345]  eta: 0:00:47  loss: 0.2088 (0.2055)  time: 0.1815  data: 0.0001  max mem: 15824
[14:38:39.849633] Test:  [100/345]  eta: 0:00:45  loss: 0.2088 (0.2062)  time: 0.1818  data: 0.0001  max mem: 15824
[14:38:41.671206] Test:  [110/345]  eta: 0:00:43  loss: 0.2093 (0.2070)  time: 0.1820  data: 0.0001  max mem: 15824
[14:38:43.498064] Test:  [120/345]  eta: 0:00:41  loss: 0.2021 (0.2069)  time: 0.1824  data: 0.0001  max mem: 15824
[14:38:45.327190] Test:  [130/345]  eta: 0:00:39  loss: 0.1994 (0.2065)  time: 0.1827  data: 0.0001  max mem: 15824
[14:38:47.159401] Test:  [140/345]  eta: 0:00:37  loss: 0.1949 (0.2057)  time: 0.1830  data: 0.0001  max mem: 15824
[14:38:48.995675] Test:  [150/345]  eta: 0:00:35  loss: 0.2082 (0.2064)  time: 0.1834  data: 0.0001  max mem: 15824
[14:38:50.833478] Test:  [160/345]  eta: 0:00:34  loss: 0.2144 (0.2066)  time: 0.1836  data: 0.0001  max mem: 15824
[14:38:52.679002] Test:  [170/345]  eta: 0:00:32  loss: 0.1965 (0.2063)  time: 0.1841  data: 0.0001  max mem: 15824
[14:38:54.525475] Test:  [180/345]  eta: 0:00:30  loss: 0.1870 (0.2056)  time: 0.1845  data: 0.0001  max mem: 15824
[14:38:56.376328] Test:  [190/345]  eta: 0:00:28  loss: 0.1960 (0.2055)  time: 0.1848  data: 0.0001  max mem: 15824
[14:38:58.228725] Test:  [200/345]  eta: 0:00:26  loss: 0.2079 (0.2056)  time: 0.1851  data: 0.0001  max mem: 15824
[14:39:00.088530] Test:  [210/345]  eta: 0:00:24  loss: 0.2161 (0.2061)  time: 0.1856  data: 0.0001  max mem: 15824
[14:39:01.951496] Test:  [220/345]  eta: 0:00:23  loss: 0.2161 (0.2060)  time: 0.1861  data: 0.0001  max mem: 15824
[14:39:03.815201] Test:  [230/345]  eta: 0:00:21  loss: 0.2022 (0.2060)  time: 0.1863  data: 0.0001  max mem: 15824
[14:39:05.682934] Test:  [240/345]  eta: 0:00:19  loss: 0.2022 (0.2061)  time: 0.1865  data: 0.0001  max mem: 15824
[14:39:07.554168] Test:  [250/345]  eta: 0:00:17  loss: 0.1922 (0.2058)  time: 0.1869  data: 0.0001  max mem: 15824
[14:39:09.428332] Test:  [260/345]  eta: 0:00:15  loss: 0.2047 (0.2058)  time: 0.1872  data: 0.0001  max mem: 15824
[14:39:11.306825] Test:  [270/345]  eta: 0:00:13  loss: 0.2037 (0.2055)  time: 0.1876  data: 0.0001  max mem: 15824
[14:39:13.188943] Test:  [280/345]  eta: 0:00:12  loss: 0.1978 (0.2051)  time: 0.1880  data: 0.0001  max mem: 15824
[14:39:15.074494] Test:  [290/345]  eta: 0:00:10  loss: 0.1947 (0.2052)  time: 0.1883  data: 0.0001  max mem: 15824
[14:39:16.965590] Test:  [300/345]  eta: 0:00:08  loss: 0.1965 (0.2050)  time: 0.1888  data: 0.0001  max mem: 15824
[14:39:18.857527] Test:  [310/345]  eta: 0:00:06  loss: 0.1965 (0.2052)  time: 0.1891  data: 0.0001  max mem: 15824
[14:39:20.754633] Test:  [320/345]  eta: 0:00:04  loss: 0.2045 (0.2053)  time: 0.1894  data: 0.0001  max mem: 15824
[14:39:22.654092] Test:  [330/345]  eta: 0:00:02  loss: 0.2055 (0.2058)  time: 0.1898  data: 0.0001  max mem: 15824
[14:39:24.556662] Test:  [340/345]  eta: 0:00:00  loss: 0.2052 (0.2057)  time: 0.1900  data: 0.0001  max mem: 15824
[14:39:25.316760] Test:  [344/345]  eta: 0:00:00  loss: 0.2005 (0.2057)  time: 0.1901  data: 0.0001  max mem: 15824
[14:39:25.386695] Test: Total time: 0:01:04 (0.1860 s / it)
[14:39:35.841265] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4463 (0.4463)  time: 0.5357  data: 0.3556  max mem: 15824
[14:39:37.610613] Test:  [10/57]  eta: 0:00:09  loss: 0.4441 (0.4384)  time: 0.2095  data: 0.0324  max mem: 15824
[14:39:39.385755] Test:  [20/57]  eta: 0:00:07  loss: 0.4161 (0.4194)  time: 0.1771  data: 0.0001  max mem: 15824
[14:39:41.164602] Test:  [30/57]  eta: 0:00:05  loss: 0.3215 (0.3698)  time: 0.1776  data: 0.0001  max mem: 15824
[14:39:42.949485] Test:  [40/57]  eta: 0:00:03  loss: 0.2709 (0.3472)  time: 0.1781  data: 0.0001  max mem: 15824
[14:39:44.734294] Test:  [50/57]  eta: 0:00:01  loss: 0.2938 (0.3494)  time: 0.1784  data: 0.0001  max mem: 15824
[14:39:45.708102] Test:  [56/57]  eta: 0:00:00  loss: 0.3329 (0.3597)  time: 0.1736  data: 0.0001  max mem: 15824
[14:39:45.777856] Test: Total time: 0:00:10 (0.1837 s / it)
[14:39:47.487327] Dice score of the network on the train images: 0.808681, val images: 0.782135
[14:39:47.491355] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:39:48.490782] Epoch: [21]  [  0/345]  eta: 0:05:44  lr: 0.000125  loss: 0.1876 (0.1876)  time: 0.9982  data: 0.3716  max mem: 15824
[14:40:00.829974] Epoch: [21]  [ 20/345]  eta: 0:03:26  lr: 0.000125  loss: 0.2130 (0.2126)  time: 0.6169  data: 0.0001  max mem: 15824
[14:40:13.188639] Epoch: [21]  [ 40/345]  eta: 0:03:11  lr: 0.000125  loss: 0.1967 (0.2088)  time: 0.6179  data: 0.0001  max mem: 15824
[14:40:25.592645] Epoch: [21]  [ 60/345]  eta: 0:02:57  lr: 0.000125  loss: 0.2018 (0.2072)  time: 0.6202  data: 0.0001  max mem: 15824
[14:40:37.997393] Epoch: [21]  [ 80/345]  eta: 0:02:45  lr: 0.000124  loss: 0.1962 (0.2061)  time: 0.6202  data: 0.0001  max mem: 15824
[14:40:50.410013] Epoch: [21]  [100/345]  eta: 0:02:32  lr: 0.000124  loss: 0.1980 (0.2059)  time: 0.6206  data: 0.0001  max mem: 15824
[14:41:02.810257] Epoch: [21]  [120/345]  eta: 0:02:20  lr: 0.000124  loss: 0.2122 (0.2073)  time: 0.6200  data: 0.0001  max mem: 15824
[14:41:15.232928] Epoch: [21]  [140/345]  eta: 0:02:07  lr: 0.000124  loss: 0.2127 (0.2094)  time: 0.6211  data: 0.0001  max mem: 15824
[14:41:27.663292] Epoch: [21]  [160/345]  eta: 0:01:55  lr: 0.000124  loss: 0.2162 (0.2101)  time: 0.6215  data: 0.0001  max mem: 15824
[14:41:40.091219] Epoch: [21]  [180/345]  eta: 0:01:42  lr: 0.000124  loss: 0.2034 (0.2097)  time: 0.6213  data: 0.0001  max mem: 15824
[14:41:52.532625] Epoch: [21]  [200/345]  eta: 0:01:30  lr: 0.000124  loss: 0.2161 (0.2103)  time: 0.6220  data: 0.0001  max mem: 15824
[14:42:04.961981] Epoch: [21]  [220/345]  eta: 0:01:17  lr: 0.000124  loss: 0.2095 (0.2103)  time: 0.6214  data: 0.0001  max mem: 15824
[14:42:17.504705] Epoch: [21]  [240/345]  eta: 0:01:05  lr: 0.000124  loss: 0.1936 (0.2098)  time: 0.6271  data: 0.0001  max mem: 15824
[14:42:29.920066] Epoch: [21]  [260/345]  eta: 0:00:52  lr: 0.000124  loss: 0.2045 (0.2094)  time: 0.6207  data: 0.0001  max mem: 15824
[14:42:42.336185] Epoch: [21]  [280/345]  eta: 0:00:40  lr: 0.000124  loss: 0.2021 (0.2088)  time: 0.6208  data: 0.0001  max mem: 15824

[14:42:54.752484] Epoch: [21]  [300/345]  eta: 0:00:27  lr: 0.000124  loss: 0.2044 (0.2091)  time: 0.6208  data: 0.0001  max mem: 15824
[14:43:07.168597] Epoch: [21]  [320/345]  eta: 0:00:15  lr: 0.000124  loss: 0.2082 (0.2095)  time: 0.6208  data: 0.0001  max mem: 15824
[14:43:19.539046] Epoch: [21]  [340/345]  eta: 0:00:03  lr: 0.000124  loss: 0.2179 (0.2102)  time: 0.6185  data: 0.0001  max mem: 15824
[14:43:22.012237] Epoch: [21]  [344/345]  eta: 0:00:00  lr: 0.000124  loss: 0.2179 (0.2103)  time: 0.6183  data: 0.0001  max mem: 15824
[14:43:22.094954] Epoch: [21] Total time: 0:03:34 (0.6220 s / it)
[14:43:22.095901] Averaged stats: lr: 0.000124  loss: 0.2179 (0.2103)
[14:43:22.679244] Test:  [  0/345]  eta: 0:03:18  loss: 0.1880 (0.1880)  time: 0.5767  data: 0.3902  max mem: 15824
[14:43:24.467693] Test:  [ 10/345]  eta: 0:01:12  loss: 0.1887 (0.2001)  time: 0.2149  data: 0.0355  max mem: 15824
[14:43:26.263905] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1868 (0.1959)  time: 0.1792  data: 0.0001  max mem: 15824
[14:43:28.060916] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1932 (0.1978)  time: 0.1796  data: 0.0001  max mem: 15824
[14:43:29.862126] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1968 (0.1975)  time: 0.1798  data: 0.0001  max mem: 15824
[14:43:31.666866] Test:  [ 50/345]  eta: 0:00:55  loss: 0.2055 (0.1988)  time: 0.1802  data: 0.0001  max mem: 15824
[14:43:33.470422] Test:  [ 60/345]  eta: 0:00:53  loss: 0.2093 (0.2007)  time: 0.1803  data: 0.0001  max mem: 15824
[14:43:35.275724] Test:  [ 70/345]  eta: 0:00:51  loss: 0.2043 (0.2004)  time: 0.1804  data: 0.0001  max mem: 15824
[14:43:37.089866] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1917 (0.1994)  time: 0.1809  data: 0.0001  max mem: 15824
[14:43:38.906054] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1899 (0.1997)  time: 0.1815  data: 0.0001  max mem: 15824
[14:43:40.724654] Test:  [100/345]  eta: 0:00:45  loss: 0.1951 (0.1988)  time: 0.1817  data: 0.0001  max mem: 15824
[14:43:42.547454] Test:  [110/345]  eta: 0:00:43  loss: 0.2015 (0.2000)  time: 0.1820  data: 0.0001  max mem: 15824
[14:43:44.375888] Test:  [120/345]  eta: 0:00:41  loss: 0.2060 (0.1998)  time: 0.1825  data: 0.0001  max mem: 15824
[14:43:46.210520] Test:  [130/345]  eta: 0:00:39  loss: 0.1950 (0.2001)  time: 0.1831  data: 0.0001  max mem: 15824
[14:43:48.046411] Test:  [140/345]  eta: 0:00:37  loss: 0.2129 (0.2013)  time: 0.1835  data: 0.0001  max mem: 15824
[14:43:49.882628] Test:  [150/345]  eta: 0:00:35  loss: 0.2084 (0.2019)  time: 0.1835  data: 0.0001  max mem: 15824
[14:43:51.724171] Test:  [160/345]  eta: 0:00:34  loss: 0.2044 (0.2023)  time: 0.1838  data: 0.0001  max mem: 15824
[14:43:53.568004] Test:  [170/345]  eta: 0:00:32  loss: 0.2094 (0.2029)  time: 0.1842  data: 0.0001  max mem: 15824
[14:43:55.416796] Test:  [180/345]  eta: 0:00:30  loss: 0.2066 (0.2030)  time: 0.1846  data: 0.0001  max mem: 15824
[14:43:57.267136] Test:  [190/345]  eta: 0:00:28  loss: 0.2057 (0.2035)  time: 0.1849  data: 0.0001  max mem: 15824
[14:43:59.120168] Test:  [200/345]  eta: 0:00:26  loss: 0.2060 (0.2039)  time: 0.1851  data: 0.0001  max mem: 15824
[14:44:00.977018] Test:  [210/345]  eta: 0:00:24  loss: 0.2060 (0.2039)  time: 0.1854  data: 0.0001  max mem: 15824
[14:44:02.836745] Test:  [220/345]  eta: 0:00:23  loss: 0.2014 (0.2038)  time: 0.1858  data: 0.0001  max mem: 15824
[14:44:04.699824] Test:  [230/345]  eta: 0:00:21  loss: 0.2014 (0.2044)  time: 0.1861  data: 0.0001  max mem: 15824
[14:44:06.572656] Test:  [240/345]  eta: 0:00:19  loss: 0.2126 (0.2048)  time: 0.1867  data: 0.0001  max mem: 15824
[14:44:08.449130] Test:  [250/345]  eta: 0:00:17  loss: 0.2109 (0.2048)  time: 0.1874  data: 0.0001  max mem: 15824
[14:44:10.326188] Test:  [260/345]  eta: 0:00:15  loss: 0.2010 (0.2044)  time: 0.1876  data: 0.0001  max mem: 15824
[14:44:12.205455] Test:  [270/345]  eta: 0:00:13  loss: 0.1959 (0.2041)  time: 0.1877  data: 0.0001  max mem: 15824
[14:44:14.087777] Test:  [280/345]  eta: 0:00:12  loss: 0.1959 (0.2039)  time: 0.1880  data: 0.0001  max mem: 15824
[14:44:15.971433] Test:  [290/345]  eta: 0:00:10  loss: 0.2028 (0.2042)  time: 0.1882  data: 0.0001  max mem: 15824
[14:44:17.864479] Test:  [300/345]  eta: 0:00:08  loss: 0.2028 (0.2043)  time: 0.1888  data: 0.0001  max mem: 15824
[14:44:19.754919] Test:  [310/345]  eta: 0:00:06  loss: 0.1953 (0.2043)  time: 0.1891  data: 0.0001  max mem: 15824
[14:44:21.649907] Test:  [320/345]  eta: 0:00:04  loss: 0.1989 (0.2042)  time: 0.1892  data: 0.0001  max mem: 15824
[14:44:23.549678] Test:  [330/345]  eta: 0:00:02  loss: 0.2075 (0.2044)  time: 0.1897  data: 0.0001  max mem: 15824
[14:44:25.449559] Test:  [340/345]  eta: 0:00:00  loss: 0.2092 (0.2045)  time: 0.1899  data: 0.0001  max mem: 15824
[14:44:26.211491] Test:  [344/345]  eta: 0:00:00  loss: 0.2029 (0.2044)  time: 0.1901  data: 0.0001  max mem: 15824
[14:44:26.270094] Test: Total time: 0:01:04 (0.1860 s / it)
[14:44:36.731972] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4249 (0.4249)  time: 0.5523  data: 0.3718  max mem: 15824
[14:44:38.506396] Test:  [10/57]  eta: 0:00:09  loss: 0.4249 (0.4421)  time: 0.2114  data: 0.0339  max mem: 15824
[14:44:40.290376] Test:  [20/57]  eta: 0:00:07  loss: 0.4176 (0.4188)  time: 0.1778  data: 0.0001  max mem: 15824
[14:44:42.072914] Test:  [30/57]  eta: 0:00:05  loss: 0.3339 (0.3729)  time: 0.1783  data: 0.0001  max mem: 15824
[14:44:43.857123] Test:  [40/57]  eta: 0:00:03  loss: 0.2731 (0.3529)  time: 0.1783  data: 0.0001  max mem: 15824
[14:44:45.641861] Test:  [50/57]  eta: 0:00:01  loss: 0.3063 (0.3560)  time: 0.1784  data: 0.0001  max mem: 15824
[14:44:46.616126] Test:  [56/57]  eta: 0:00:00  loss: 0.3539 (0.3706)  time: 0.1736  data: 0.0000  max mem: 15824
[14:44:46.691348] Test: Total time: 0:00:10 (0.1844 s / it)
[14:44:48.437661] Dice score of the network on the train images: 0.811892, val images: 0.759748
[14:44:48.441781] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:44:49.425252] Epoch: [22]  [  0/345]  eta: 0:05:38  lr: 0.000124  loss: 0.1960 (0.1960)  time: 0.9823  data: 0.3585  max mem: 15824
[14:45:01.740168] Epoch: [22]  [ 20/345]  eta: 0:03:25  lr: 0.000124  loss: 0.2083 (0.2118)  time: 0.6157  data: 0.0001  max mem: 15824
[14:45:14.082859] Epoch: [22]  [ 40/345]  eta: 0:03:10  lr: 0.000123  loss: 0.2221 (0.2150)  time: 0.6171  data: 0.0001  max mem: 15824
[14:45:26.455753] Epoch: [22]  [ 60/345]  eta: 0:02:57  lr: 0.000123  loss: 0.1952 (0.2096)  time: 0.6186  data: 0.0001  max mem: 15824
[14:45:38.840050] Epoch: [22]  [ 80/345]  eta: 0:02:44  lr: 0.000123  loss: 0.1831 (0.2062)  time: 0.6192  data: 0.0001  max mem: 15824
[14:45:51.250274] Epoch: [22]  [100/345]  eta: 0:02:32  lr: 0.000123  loss: 0.1858 (0.2050)  time: 0.6205  data: 0.0001  max mem: 15824
[14:46:03.653342] Epoch: [22]  [120/345]  eta: 0:02:19  lr: 0.000123  loss: 0.2023 (0.2063)  time: 0.6201  data: 0.0001  max mem: 15824
[14:46:16.049205] Epoch: [22]  [140/345]  eta: 0:02:07  lr: 0.000123  loss: 0.1997 (0.2069)  time: 0.6198  data: 0.0001  max mem: 15824
[14:46:28.443302] Epoch: [22]  [160/345]  eta: 0:01:54  lr: 0.000123  loss: 0.2071 (0.2070)  time: 0.6197  data: 0.0001  max mem: 15824
[14:46:40.837003] Epoch: [22]  [180/345]  eta: 0:01:42  lr: 0.000123  loss: 0.2019 (0.2072)  time: 0.6196  data: 0.0001  max mem: 15824
[14:46:53.230657] Epoch: [22]  [200/345]  eta: 0:01:30  lr: 0.000123  loss: 0.2059 (0.2077)  time: 0.6196  data: 0.0001  max mem: 15824
[14:47:05.649965] Epoch: [22]  [220/345]  eta: 0:01:17  lr: 0.000123  loss: 0.1962 (0.2075)  time: 0.6209  data: 0.0001  max mem: 15824
[14:47:18.042885] Epoch: [22]  [240/345]  eta: 0:01:05  lr: 0.000123  loss: 0.1916 (0.2067)  time: 0.6196  data: 0.0001  max mem: 15824
[14:47:30.434355] Epoch: [22]  [260/345]  eta: 0:00:52  lr: 0.000122  loss: 0.2090 (0.2068)  time: 0.6195  data: 0.0001  max mem: 15824
[14:47:42.814978] Epoch: [22]  [280/345]  eta: 0:00:40  lr: 0.000122  loss: 0.2073 (0.2068)  time: 0.6190  data: 0.0001  max mem: 15824
[14:47:55.206567] Epoch: [22]  [300/345]  eta: 0:00:27  lr: 0.000122  loss: 0.1944 (0.2067)  time: 0.6195  data: 0.0001  max mem: 15824
[14:48:07.587852] Epoch: [22]  [320/345]  eta: 0:00:15  lr: 0.000122  loss: 0.1947 (0.2062)  time: 0.6190  data: 0.0001  max mem: 15824
[14:48:19.962198] Epoch: [22]  [340/345]  eta: 0:00:03  lr: 0.000122  loss: 0.1939 (0.2056)  time: 0.6187  data: 0.0001  max mem: 15824
[14:48:22.435726] Epoch: [22]  [344/345]  eta: 0:00:00  lr: 0.000122  loss: 0.1939 (0.2055)  time: 0.6184  data: 0.0001  max mem: 15824
[14:48:22.514030] Epoch: [22] Total time: 0:03:34 (0.6205 s / it)
[14:48:22.514264] Averaged stats: lr: 0.000122  loss: 0.1939 (0.2055)
[14:48:23.183944] Test:  [  0/345]  eta: 0:03:49  loss: 0.1430 (0.1430)  time: 0.6643  data: 0.4814  max mem: 15824
[14:48:24.972188] Test:  [ 10/345]  eta: 0:01:14  loss: 0.1961 (0.1993)  time: 0.2229  data: 0.0438  max mem: 15824
[14:48:26.768012] Test:  [ 20/345]  eta: 0:01:05  loss: 0.1921 (0.1975)  time: 0.1791  data: 0.0001  max mem: 15824
[14:48:28.569113] Test:  [ 30/345]  eta: 0:01:01  loss: 0.1900 (0.1969)  time: 0.1798  data: 0.0001  max mem: 15824
[14:48:30.370175] Test:  [ 40/345]  eta: 0:00:58  loss: 0.1935 (0.1980)  time: 0.1800  data: 0.0001  max mem: 15824
[14:48:32.171352] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1817 (0.1962)  time: 0.1800  data: 0.0001  max mem: 15824
[14:48:33.973960] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1751 (0.1946)  time: 0.1801  data: 0.0001  max mem: 15824
[14:48:35.785106] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1751 (0.1933)  time: 0.1806  data: 0.0001  max mem: 15824
[14:48:37.597587] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1818 (0.1927)  time: 0.1811  data: 0.0001  max mem: 15824
[14:48:39.415108] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1924 (0.1929)  time: 0.1814  data: 0.0001  max mem: 15824
[14:48:41.234715] Test:  [100/345]  eta: 0:00:45  loss: 0.1825 (0.1916)  time: 0.1818  data: 0.0001  max mem: 15824
[14:48:43.056430] Test:  [110/345]  eta: 0:00:43  loss: 0.1809 (0.1910)  time: 0.1820  data: 0.0001  max mem: 15824
[14:48:44.882700] Test:  [120/345]  eta: 0:00:41  loss: 0.1811 (0.1902)  time: 0.1823  data: 0.0001  max mem: 15824
[14:48:46.711513] Test:  [130/345]  eta: 0:00:39  loss: 0.1828 (0.1902)  time: 0.1827  data: 0.0001  max mem: 15824
[14:48:48.543179] Test:  [140/345]  eta: 0:00:37  loss: 0.1968 (0.1913)  time: 0.1830  data: 0.0001  max mem: 15824
[14:48:50.381185] Test:  [150/345]  eta: 0:00:35  loss: 0.1968 (0.1912)  time: 0.1834  data: 0.0001  max mem: 15824
[14:48:52.224304] Test:  [160/345]  eta: 0:00:34  loss: 0.1943 (0.1917)  time: 0.1840  data: 0.0001  max mem: 15824
[14:48:54.069590] Test:  [170/345]  eta: 0:00:32  loss: 0.2000 (0.1923)  time: 0.1844  data: 0.0001  max mem: 15824
[14:48:55.916494] Test:  [180/345]  eta: 0:00:30  loss: 0.1904 (0.1925)  time: 0.1845  data: 0.0001  max mem: 15824
[14:48:57.766337] Test:  [190/345]  eta: 0:00:28  loss: 0.1904 (0.1921)  time: 0.1848  data: 0.0001  max mem: 15824
[14:48:59.622171] Test:  [200/345]  eta: 0:00:26  loss: 0.1898 (0.1919)  time: 0.1852  data: 0.0001  max mem: 15824
[14:49:01.478158] Test:  [210/345]  eta: 0:00:24  loss: 0.1898 (0.1922)  time: 0.1855  data: 0.0001  max mem: 15824
[14:49:03.338227] Test:  [220/345]  eta: 0:00:23  loss: 0.1916 (0.1925)  time: 0.1857  data: 0.0001  max mem: 15824
[14:49:05.204775] Test:  [230/345]  eta: 0:00:21  loss: 0.1864 (0.1925)  time: 0.1863  data: 0.0001  max mem: 15824
[14:49:07.072652] Test:  [240/345]  eta: 0:00:19  loss: 0.1877 (0.1927)  time: 0.1867  data: 0.0001  max mem: 15824
[14:49:08.946491] Test:  [250/345]  eta: 0:00:17  loss: 0.1874 (0.1920)  time: 0.1870  data: 0.0001  max mem: 15824
[14:49:10.822568] Test:  [260/345]  eta: 0:00:15  loss: 0.1810 (0.1921)  time: 0.1874  data: 0.0001  max mem: 15824
[14:49:12.701863] Test:  [270/345]  eta: 0:00:13  loss: 0.1810 (0.1917)  time: 0.1877  data: 0.0001  max mem: 15824
[14:49:14.587221] Test:  [280/345]  eta: 0:00:12  loss: 0.1810 (0.1920)  time: 0.1882  data: 0.0001  max mem: 15824
[14:49:16.473045] Test:  [290/345]  eta: 0:00:10  loss: 0.1960 (0.1927)  time: 0.1885  data: 0.0001  max mem: 15824
[14:49:18.361337] Test:  [300/345]  eta: 0:00:08  loss: 0.1957 (0.1924)  time: 0.1886  data: 0.0001  max mem: 15824
[14:49:20.251932] Test:  [310/345]  eta: 0:00:06  loss: 0.1859 (0.1926)  time: 0.1889  data: 0.0001  max mem: 15824
[14:49:22.150543] Test:  [320/345]  eta: 0:00:04  loss: 0.1995 (0.1929)  time: 0.1894  data: 0.0001  max mem: 15824
[14:49:24.052016] Test:  [330/345]  eta: 0:00:02  loss: 0.1932 (0.1926)  time: 0.1899  data: 0.0001  max mem: 15824
[14:49:25.952704] Test:  [340/345]  eta: 0:00:00  loss: 0.1916 (0.1929)  time: 0.1901  data: 0.0001  max mem: 15824
[14:49:26.713244] Test:  [344/345]  eta: 0:00:00  loss: 0.1916 (0.1928)  time: 0.1900  data: 0.0001  max mem: 15824
[14:49:26.784585] Test: Total time: 0:01:04 (0.1863 s / it)
[14:49:37.239053] Test:  [ 0/57]  eta: 0:00:30  loss: 0.5057 (0.5057)  time: 0.5355  data: 0.3550  max mem: 15824
[14:49:39.012509] Test:  [10/57]  eta: 0:00:09  loss: 0.4676 (0.4853)  time: 0.2098  data: 0.0324  max mem: 15824
[14:49:40.789128] Test:  [20/57]  eta: 0:00:07  loss: 0.4676 (0.4664)  time: 0.1774  data: 0.0001  max mem: 15824
[14:49:42.571320] Test:  [30/57]  eta: 0:00:05  loss: 0.3391 (0.4047)  time: 0.1779  data: 0.0001  max mem: 15824
[14:49:44.356900] Test:  [40/57]  eta: 0:00:03  loss: 0.2713 (0.3787)  time: 0.1783  data: 0.0001  max mem: 15824
[14:49:46.143289] Test:  [50/57]  eta: 0:00:01  loss: 0.3097 (0.3839)  time: 0.1785  data: 0.0001  max mem: 15824
[14:49:47.116613] Test:  [56/57]  eta: 0:00:00  loss: 0.3788 (0.4030)  time: 0.1736  data: 0.0000  max mem: 15824
[14:49:47.179158] Test: Total time: 0:00:10 (0.1838 s / it)
[14:49:48.901287] Dice score of the network on the train images: 0.830385, val images: 0.756118
[14:49:48.901512] saving best_prec_model_0 @ epoch 22
[14:49:49.957022] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:49:50.961385] Epoch: [23]  [  0/345]  eta: 0:05:46  lr: 0.000122  loss: 0.2209 (0.2209)  time: 1.0035  data: 0.3788  max mem: 15824

[14:50:03.287693] Epoch: [23]  [ 20/345]  eta: 0:03:26  lr: 0.000122  loss: 0.1980 (0.1986)  time: 0.6163  data: 0.0001  max mem: 15824
[14:50:15.661134] Epoch: [23]  [ 40/345]  eta: 0:03:11  lr: 0.000122  loss: 0.2018 (0.2010)  time: 0.6186  data: 0.0001  max mem: 15824
[14:50:28.181193] Epoch: [23]  [ 60/345]  eta: 0:02:58  lr: 0.000122  loss: 0.2071 (0.2055)  time: 0.6259  data: 0.0001  max mem: 15824
[14:50:40.562065] Epoch: [23]  [ 80/345]  eta: 0:02:45  lr: 0.000121  loss: 0.2027 (0.2046)  time: 0.6190  data: 0.0001  max mem: 15824
[14:50:52.977443] Epoch: [23]  [100/345]  eta: 0:02:32  lr: 0.000121  loss: 0.2092 (0.2053)  time: 0.6207  data: 0.0001  max mem: 15824
[14:51:05.401760] Epoch: [23]  [120/345]  eta: 0:02:20  lr: 0.000121  loss: 0.1935 (0.2050)  time: 0.6212  data: 0.0001  max mem: 15824
[14:51:17.836187] Epoch: [23]  [140/345]  eta: 0:02:07  lr: 0.000121  loss: 0.1983 (0.2050)  time: 0.6217  data: 0.0001  max mem: 15824
[14:51:30.257507] Epoch: [23]  [160/345]  eta: 0:01:55  lr: 0.000121  loss: 0.2031 (0.2045)  time: 0.6210  data: 0.0001  max mem: 15824
[14:51:42.667232] Epoch: [23]  [180/345]  eta: 0:01:42  lr: 0.000121  loss: 0.1959 (0.2039)  time: 0.6204  data: 0.0001  max mem: 15824
[14:51:55.090552] Epoch: [23]  [200/345]  eta: 0:01:30  lr: 0.000121  loss: 0.2023 (0.2042)  time: 0.6211  data: 0.0001  max mem: 15824
[14:52:07.505546] Epoch: [23]  [220/345]  eta: 0:01:17  lr: 0.000121  loss: 0.2000 (0.2038)  time: 0.6207  data: 0.0001  max mem: 15824
[14:52:19.892690] Epoch: [23]  [240/345]  eta: 0:01:05  lr: 0.000120  loss: 0.1906 (0.2025)  time: 0.6193  data: 0.0001  max mem: 15824
[14:52:32.306354] Epoch: [23]  [260/345]  eta: 0:00:52  lr: 0.000120  loss: 0.1971 (0.2026)  time: 0.6206  data: 0.0001  max mem: 15824
[14:52:44.719477] Epoch: [23]  [280/345]  eta: 0:00:40  lr: 0.000120  loss: 0.1986 (0.2027)  time: 0.6206  data: 0.0001  max mem: 15824
[14:52:57.115732] Epoch: [23]  [300/345]  eta: 0:00:27  lr: 0.000120  loss: 0.2004 (0.2025)  time: 0.6198  data: 0.0001  max mem: 15824
[14:53:09.513597] Epoch: [23]  [320/345]  eta: 0:00:15  lr: 0.000120  loss: 0.2007 (0.2026)  time: 0.6199  data: 0.0001  max mem: 15824
[14:53:21.886066] Epoch: [23]  [340/345]  eta: 0:00:03  lr: 0.000120  loss: 0.1949 (0.2024)  time: 0.6186  data: 0.0001  max mem: 15824
[14:53:24.365359] Epoch: [23]  [344/345]  eta: 0:00:00  lr: 0.000120  loss: 0.2005 (0.2024)  time: 0.6185  data: 0.0001  max mem: 15824
[14:53:24.433854] Epoch: [23] Total time: 0:03:34 (0.6217 s / it)
[14:53:24.434218] Averaged stats: lr: 0.000120  loss: 0.2005 (0.2024)
[14:53:25.081342] Test:  [  0/345]  eta: 0:03:41  loss: 0.1604 (0.1604)  time: 0.6414  data: 0.4583  max mem: 15824
[14:53:26.869453] Test:  [ 10/345]  eta: 0:01:13  loss: 0.1835 (0.1872)  time: 0.2208  data: 0.0417  max mem: 15824
[14:53:28.661619] Test:  [ 20/345]  eta: 0:01:05  loss: 0.1762 (0.1822)  time: 0.1789  data: 0.0001  max mem: 15824
[14:53:30.452739] Test:  [ 30/345]  eta: 0:01:01  loss: 0.1762 (0.1836)  time: 0.1791  data: 0.0001  max mem: 15824
[14:53:32.251046] Test:  [ 40/345]  eta: 0:00:58  loss: 0.1895 (0.1854)  time: 0.1794  data: 0.0001  max mem: 15824
[14:53:34.053797] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1902 (0.1865)  time: 0.1800  data: 0.0001  max mem: 15824
[14:53:35.855227] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1901 (0.1858)  time: 0.1801  data: 0.0001  max mem: 15824
[14:53:37.658824] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1860 (0.1860)  time: 0.1802  data: 0.0001  max mem: 15824
[14:53:39.472052] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1860 (0.1862)  time: 0.1808  data: 0.0001  max mem: 15824
[14:53:41.287141] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1817 (0.1861)  time: 0.1814  data: 0.0001  max mem: 15824
[14:53:43.104728] Test:  [100/345]  eta: 0:00:45  loss: 0.1859 (0.1859)  time: 0.1816  data: 0.0001  max mem: 15824
[14:53:44.930975] Test:  [110/345]  eta: 0:00:43  loss: 0.1902 (0.1858)  time: 0.1821  data: 0.0001  max mem: 15824
[14:53:46.755092] Test:  [120/345]  eta: 0:00:41  loss: 0.1931 (0.1869)  time: 0.1825  data: 0.0001  max mem: 15824
[14:53:48.582371] Test:  [130/345]  eta: 0:00:39  loss: 0.1931 (0.1871)  time: 0.1825  data: 0.0001  max mem: 15824
[14:53:50.414878] Test:  [140/345]  eta: 0:00:37  loss: 0.1872 (0.1869)  time: 0.1829  data: 0.0001  max mem: 15824
[14:53:52.250079] Test:  [150/345]  eta: 0:00:35  loss: 0.1872 (0.1871)  time: 0.1833  data: 0.0001  max mem: 15824
[14:53:54.088815] Test:  [160/345]  eta: 0:00:34  loss: 0.1840 (0.1871)  time: 0.1836  data: 0.0001  max mem: 15824
[14:53:55.933091] Test:  [170/345]  eta: 0:00:32  loss: 0.1915 (0.1876)  time: 0.1841  data: 0.0001  max mem: 15824
[14:53:57.779483] Test:  [180/345]  eta: 0:00:30  loss: 0.1915 (0.1875)  time: 0.1845  data: 0.0001  max mem: 15824
[14:53:59.628963] Test:  [190/345]  eta: 0:00:28  loss: 0.1907 (0.1877)  time: 0.1847  data: 0.0001  max mem: 15824
[14:54:01.483776] Test:  [200/345]  eta: 0:00:26  loss: 0.1907 (0.1880)  time: 0.1852  data: 0.0001  max mem: 15824
[14:54:03.342952] Test:  [210/345]  eta: 0:00:24  loss: 0.1932 (0.1888)  time: 0.1856  data: 0.0001  max mem: 15824
[14:54:05.206091] Test:  [220/345]  eta: 0:00:23  loss: 0.1932 (0.1892)  time: 0.1861  data: 0.0001  max mem: 15824
[14:54:07.069949] Test:  [230/345]  eta: 0:00:21  loss: 0.1817 (0.1894)  time: 0.1863  data: 0.0001  max mem: 15824
[14:54:08.937738] Test:  [240/345]  eta: 0:00:19  loss: 0.1817 (0.1890)  time: 0.1865  data: 0.0001  max mem: 15824
[14:54:10.810730] Test:  [250/345]  eta: 0:00:17  loss: 0.1789 (0.1889)  time: 0.1870  data: 0.0001  max mem: 15824
[14:54:12.683302] Test:  [260/345]  eta: 0:00:15  loss: 0.1752 (0.1886)  time: 0.1872  data: 0.0001  max mem: 15824
[14:54:14.557996] Test:  [270/345]  eta: 0:00:13  loss: 0.1816 (0.1887)  time: 0.1873  data: 0.0001  max mem: 15824
[14:54:16.440065] Test:  [280/345]  eta: 0:00:12  loss: 0.1949 (0.1892)  time: 0.1878  data: 0.0001  max mem: 15824
[14:54:18.324137] Test:  [290/345]  eta: 0:00:10  loss: 0.1908 (0.1894)  time: 0.1882  data: 0.0001  max mem: 15824
[14:54:20.214726] Test:  [300/345]  eta: 0:00:08  loss: 0.1870 (0.1893)  time: 0.1887  data: 0.0001  max mem: 15824
[14:54:22.104756] Test:  [310/345]  eta: 0:00:06  loss: 0.1741 (0.1889)  time: 0.1890  data: 0.0001  max mem: 15824
[14:54:23.998195] Test:  [320/345]  eta: 0:00:04  loss: 0.1762 (0.1887)  time: 0.1891  data: 0.0001  max mem: 15824
[14:54:25.894550] Test:  [330/345]  eta: 0:00:02  loss: 0.1889 (0.1889)  time: 0.1894  data: 0.0001  max mem: 15824
[14:54:27.794732] Test:  [340/345]  eta: 0:00:00  loss: 0.1907 (0.1889)  time: 0.1898  data: 0.0001  max mem: 15824
[14:54:28.555693] Test:  [344/345]  eta: 0:00:00  loss: 0.1907 (0.1890)  time: 0.1899  data: 0.0001  max mem: 15824
[14:54:28.620844] Test: Total time: 0:01:04 (0.1860 s / it)
[14:54:39.060008] Test:  [ 0/57]  eta: 0:00:32  loss: 0.4890 (0.4890)  time: 0.5764  data: 0.3956  max mem: 15824
[14:54:40.828965] Test:  [10/57]  eta: 0:00:10  loss: 0.4599 (0.4682)  time: 0.2131  data: 0.0360  max mem: 15824
[14:54:42.606432] Test:  [20/57]  eta: 0:00:07  loss: 0.4251 (0.4409)  time: 0.1772  data: 0.0001  max mem: 15824
[14:54:44.389354] Test:  [30/57]  eta: 0:00:05  loss: 0.2981 (0.3883)  time: 0.1780  data: 0.0001  max mem: 15824
[14:54:46.175089] Test:  [40/57]  eta: 0:00:03  loss: 0.2887 (0.3704)  time: 0.1784  data: 0.0001  max mem: 15824
[14:54:47.961642] Test:  [50/57]  eta: 0:00:01  loss: 0.3228 (0.3752)  time: 0.1786  data: 0.0001  max mem: 15824
[14:54:48.932732] Test:  [56/57]  eta: 0:00:00  loss: 0.4111 (0.3919)  time: 0.1735  data: 0.0000  max mem: 15824
[14:54:49.000234] Test: Total time: 0:00:10 (0.1845 s / it)
[14:54:50.736157] Dice score of the network on the train images: 0.834472, val images: 0.754426
[14:54:50.736386] saving best_prec_model_0 @ epoch 23
[14:54:51.823999] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:54:52.834429] Epoch: [24]  [  0/345]  eta: 0:05:48  lr: 0.000120  loss: 0.1642 (0.1642)  time: 1.0093  data: 0.3866  max mem: 15824
[14:55:05.137814] Epoch: [24]  [ 20/345]  eta: 0:03:26  lr: 0.000119  loss: 0.1914 (0.1944)  time: 0.6151  data: 0.0001  max mem: 15824
[14:55:17.501730] Epoch: [24]  [ 40/345]  eta: 0:03:10  lr: 0.000119  loss: 0.1845 (0.1936)  time: 0.6182  data: 0.0001  max mem: 15824
[14:55:29.898506] Epoch: [24]  [ 60/345]  eta: 0:02:57  lr: 0.000119  loss: 0.1785 (0.1920)  time: 0.6198  data: 0.0001  max mem: 15824
[14:55:42.304052] Epoch: [24]  [ 80/345]  eta: 0:02:45  lr: 0.000119  loss: 0.1859 (0.1924)  time: 0.6202  data: 0.0001  max mem: 15824
[14:55:54.703870] Epoch: [24]  [100/345]  eta: 0:02:32  lr: 0.000119  loss: 0.1820 (0.1915)  time: 0.6199  data: 0.0001  max mem: 15824
[14:56:07.131480] Epoch: [24]  [120/345]  eta: 0:02:20  lr: 0.000119  loss: 0.1951 (0.1923)  time: 0.6213  data: 0.0001  max mem: 15824
[14:56:19.557749] Epoch: [24]  [140/345]  eta: 0:02:07  lr: 0.000118  loss: 0.1805 (0.1915)  time: 0.6213  data: 0.0001  max mem: 15824
[14:56:31.983382] Epoch: [24]  [160/345]  eta: 0:01:55  lr: 0.000118  loss: 0.1939 (0.1918)  time: 0.6212  data: 0.0001  max mem: 15824
[14:56:44.402872] Epoch: [24]  [180/345]  eta: 0:01:42  lr: 0.000118  loss: 0.1999 (0.1934)  time: 0.6209  data: 0.0001  max mem: 15824
[14:56:56.824973] Epoch: [24]  [200/345]  eta: 0:01:30  lr: 0.000118  loss: 0.1919 (0.1939)  time: 0.6211  data: 0.0001  max mem: 15824
[14:57:09.241548] Epoch: [24]  [220/345]  eta: 0:01:17  lr: 0.000118  loss: 0.1910 (0.1934)  time: 0.6208  data: 0.0001  max mem: 15824
[14:57:21.648202] Epoch: [24]  [240/345]  eta: 0:01:05  lr: 0.000118  loss: 0.1919 (0.1935)  time: 0.6203  data: 0.0001  max mem: 15824
[14:57:34.043320] Epoch: [24]  [260/345]  eta: 0:00:52  lr: 0.000117  loss: 0.1921 (0.1935)  time: 0.6197  data: 0.0001  max mem: 15824
[14:57:46.438263] Epoch: [24]  [280/345]  eta: 0:00:40  lr: 0.000117  loss: 0.1914 (0.1935)  time: 0.6197  data: 0.0001  max mem: 15824
[14:57:58.840227] Epoch: [24]  [300/345]  eta: 0:00:27  lr: 0.000117  loss: 0.1892 (0.1939)  time: 0.6200  data: 0.0001  max mem: 15824
[14:58:11.236735] Epoch: [24]  [320/345]  eta: 0:00:15  lr: 0.000117  loss: 0.1916 (0.1941)  time: 0.6198  data: 0.0001  max mem: 15824
[14:58:23.629844] Epoch: [24]  [340/345]  eta: 0:00:03  lr: 0.000117  loss: 0.1873 (0.1942)  time: 0.6196  data: 0.0001  max mem: 15824
[14:58:26.110743] Epoch: [24]  [344/345]  eta: 0:00:00  lr: 0.000117  loss: 0.1897 (0.1942)  time: 0.6199  data: 0.0001  max mem: 15824
[14:58:26.186859] Epoch: [24] Total time: 0:03:34 (0.6213 s / it)
[14:58:26.187070] Averaged stats: lr: 0.000117  loss: 0.1897 (0.1942)
[14:58:26.775133] Test:  [  0/345]  eta: 0:03:21  loss: 0.1722 (0.1722)  time: 0.5827  data: 0.3991  max mem: 15824
[14:58:28.566114] Test:  [ 10/345]  eta: 0:01:12  loss: 0.1724 (0.1752)  time: 0.2157  data: 0.0364  max mem: 15824
[14:58:30.356526] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1788 (0.1818)  time: 0.1790  data: 0.0001  max mem: 15824
[14:58:32.154235] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1950 (0.1861)  time: 0.1793  data: 0.0001  max mem: 15824
[14:58:33.954582] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1919 (0.1897)  time: 0.1798  data: 0.0001  max mem: 15824
[14:58:35.755839] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1873 (0.1892)  time: 0.1800  data: 0.0001  max mem: 15824
[14:58:37.558213] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1850 (0.1887)  time: 0.1801  data: 0.0001  max mem: 15824
[14:58:39.365877] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1821 (0.1865)  time: 0.1804  data: 0.0001  max mem: 15824
[14:58:41.179000] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1830 (0.1866)  time: 0.1810  data: 0.0001  max mem: 15824
[14:58:42.995364] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1833 (0.1867)  time: 0.1814  data: 0.0001  max mem: 15824
[14:58:44.813965] Test:  [100/345]  eta: 0:00:45  loss: 0.1751 (0.1859)  time: 0.1817  data: 0.0001  max mem: 15824
[14:58:46.636635] Test:  [110/345]  eta: 0:00:43  loss: 0.1677 (0.1850)  time: 0.1820  data: 0.0001  max mem: 15824
[14:58:48.462036] Test:  [120/345]  eta: 0:00:41  loss: 0.1764 (0.1847)  time: 0.1823  data: 0.0001  max mem: 15824
[14:58:50.289942] Test:  [130/345]  eta: 0:00:39  loss: 0.1740 (0.1841)  time: 0.1826  data: 0.0001  max mem: 15824
[14:58:52.121611] Test:  [140/345]  eta: 0:00:37  loss: 0.1668 (0.1836)  time: 0.1829  data: 0.0001  max mem: 15824
[14:58:53.957797] Test:  [150/345]  eta: 0:00:35  loss: 0.1771 (0.1840)  time: 0.1833  data: 0.0001  max mem: 15824
[14:58:55.797840] Test:  [160/345]  eta: 0:00:34  loss: 0.1936 (0.1843)  time: 0.1837  data: 0.0001  max mem: 15824
[14:58:57.640451] Test:  [170/345]  eta: 0:00:32  loss: 0.1885 (0.1844)  time: 0.1841  data: 0.0001  max mem: 15824
[14:58:59.488711] Test:  [180/345]  eta: 0:00:30  loss: 0.1803 (0.1840)  time: 0.1845  data: 0.0001  max mem: 15824
[14:59:01.340171] Test:  [190/345]  eta: 0:00:28  loss: 0.1803 (0.1842)  time: 0.1849  data: 0.0001  max mem: 15824
[14:59:03.192559] Test:  [200/345]  eta: 0:00:26  loss: 0.1860 (0.1846)  time: 0.1851  data: 0.0001  max mem: 15824
[14:59:05.048326] Test:  [210/345]  eta: 0:00:24  loss: 0.1874 (0.1851)  time: 0.1854  data: 0.0001  max mem: 15824
[14:59:06.908191] Test:  [220/345]  eta: 0:00:23  loss: 0.1861 (0.1851)  time: 0.1857  data: 0.0001  max mem: 15824
[14:59:08.771307] Test:  [230/345]  eta: 0:00:21  loss: 0.1801 (0.1850)  time: 0.1861  data: 0.0001  max mem: 15824
[14:59:10.638665] Test:  [240/345]  eta: 0:00:19  loss: 0.1818 (0.1853)  time: 0.1865  data: 0.0001  max mem: 15824
[14:59:12.507172] Test:  [250/345]  eta: 0:00:17  loss: 0.1731 (0.1847)  time: 0.1867  data: 0.0001  max mem: 15824
[14:59:14.380194] Test:  [260/345]  eta: 0:00:15  loss: 0.1799 (0.1853)  time: 0.1870  data: 0.0001  max mem: 15824
[14:59:16.256097] Test:  [270/345]  eta: 0:00:13  loss: 0.1834 (0.1852)  time: 0.1874  data: 0.0001  max mem: 15824
[14:59:18.136307] Test:  [280/345]  eta: 0:00:12  loss: 0.1772 (0.1852)  time: 0.1877  data: 0.0001  max mem: 15824
[14:59:20.019813] Test:  [290/345]  eta: 0:00:10  loss: 0.1724 (0.1848)  time: 0.1881  data: 0.0001  max mem: 15824
[14:59:21.907818] Test:  [300/345]  eta: 0:00:08  loss: 0.1744 (0.1846)  time: 0.1885  data: 0.0001  max mem: 15824
[14:59:23.798445] Test:  [310/345]  eta: 0:00:06  loss: 0.1802 (0.1849)  time: 0.1889  data: 0.0001  max mem: 15824
[14:59:25.693488] Test:  [320/345]  eta: 0:00:04  loss: 0.1895 (0.1853)  time: 0.1892  data: 0.0001  max mem: 15824
[14:59:27.590282] Test:  [330/345]  eta: 0:00:02  loss: 0.1753 (0.1848)  time: 0.1895  data: 0.0001  max mem: 15824
[14:59:29.489045] Test:  [340/345]  eta: 0:00:00  loss: 0.1701 (0.1849)  time: 0.1897  data: 0.0001  max mem: 15824
[14:59:30.249306] Test:  [344/345]  eta: 0:00:00  loss: 0.1743 (0.1848)  time: 0.1898  data: 0.0001  max mem: 15824
[14:59:30.314351] Test: Total time: 0:01:04 (0.1859 s / it)
[14:59:40.855027] Test:  [ 0/57]  eta: 0:00:32  loss: 0.4606 (0.4606)  time: 0.5676  data: 0.3870  max mem: 15824
[14:59:42.628451] Test:  [10/57]  eta: 0:00:09  loss: 0.4425 (0.4515)  time: 0.2127  data: 0.0353  max mem: 15824
[14:59:44.406304] Test:  [20/57]  eta: 0:00:07  loss: 0.4306 (0.4405)  time: 0.1775  data: 0.0001  max mem: 15824
[14:59:46.186651] Test:  [30/57]  eta: 0:00:05  loss: 0.3183 (0.3874)  time: 0.1778  data: 0.0001  max mem: 15824
[14:59:47.970862] Test:  [40/57]  eta: 0:00:03  loss: 0.2765 (0.3683)  time: 0.1782  data: 0.0001  max mem: 15824
[14:59:49.758348] Test:  [50/57]  eta: 0:00:01  loss: 0.3229 (0.3681)  time: 0.1785  data: 0.0001  max mem: 15824
[14:59:50.728950] Test:  [56/57]  eta: 0:00:00  loss: 0.3688 (0.3787)  time: 0.1735  data: 0.0001  max mem: 15824
[14:59:50.793176] Test: Total time: 0:00:10 (0.1843 s / it)
[14:59:52.522410] Dice score of the network on the train images: 0.825251, val images: 0.773094
[14:59:52.526582] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[14:59:53.523692] Epoch: [25]  [  0/345]  eta: 0:05:43  lr: 0.000117  loss: 0.1692 (0.1692)  time: 0.9960  data: 0.3743  max mem: 15824
[15:00:05.870158] Epoch: [25]  [ 20/345]  eta: 0:03:26  lr: 0.000116  loss: 0.1831 (0.1832)  time: 0.6173  data: 0.0001  max mem: 15824
[15:00:18.232051] Epoch: [25]  [ 40/345]  eta: 0:03:11  lr: 0.000116  loss: 0.1778 (0.1827)  time: 0.6181  data: 0.0001  max mem: 15824
[15:00:30.624790] Epoch: [25]  [ 60/345]  eta: 0:02:57  lr: 0.000116  loss: 0.1853 (0.1849)  time: 0.6196  data: 0.0001  max mem: 15824
[15:00:43.026448] Epoch: [25]  [ 80/345]  eta: 0:02:45  lr: 0.000116  loss: 0.1884 (0.1856)  time: 0.6200  data: 0.0001  max mem: 15824
[15:00:55.442180] Epoch: [25]  [100/345]  eta: 0:02:32  lr: 0.000116  loss: 0.1766 (0.1862)  time: 0.6207  data: 0.0001  max mem: 15824
[15:01:07.869785] Epoch: [25]  [120/345]  eta: 0:02:20  lr: 0.000115  loss: 0.1804 (0.1862)  time: 0.6213  data: 0.0001  max mem: 15824
[15:01:20.290473] Epoch: [25]  [140/345]  eta: 0:02:07  lr: 0.000115  loss: 0.1904 (0.1870)  time: 0.6210  data: 0.0001  max mem: 15824
[15:01:32.708064] Epoch: [25]  [160/345]  eta: 0:01:55  lr: 0.000115  loss: 0.1893 (0.1873)  time: 0.6208  data: 0.0001  max mem: 15824
[15:01:45.127976] Epoch: [25]  [180/345]  eta: 0:01:42  lr: 0.000115  loss: 0.1896 (0.1882)  time: 0.6209  data: 0.0001  max mem: 15824
[15:01:57.545718] Epoch: [25]  [200/345]  eta: 0:01:30  lr: 0.000115  loss: 0.1904 (0.1888)  time: 0.6208  data: 0.0001  max mem: 15824
[15:02:09.975142] Epoch: [25]  [220/345]  eta: 0:01:17  lr: 0.000114  loss: 0.1812 (0.1889)  time: 0.6214  data: 0.0001  max mem: 15824
[15:02:22.394921] Epoch: [25]  [240/345]  eta: 0:01:05  lr: 0.000114  loss: 0.1854 (0.1886)  time: 0.6209  data: 0.0001  max mem: 15824
[15:02:34.786432] Epoch: [25]  [260/345]  eta: 0:00:52  lr: 0.000114  loss: 0.1835 (0.1887)  time: 0.6195  data: 0.0001  max mem: 15824
[15:02:47.177543] Epoch: [25]  [280/345]  eta: 0:00:40  lr: 0.000114  loss: 0.1819 (0.1885)  time: 0.6195  data: 0.0001  max mem: 15824
[15:02:59.557523] Epoch: [25]  [300/345]  eta: 0:00:27  lr: 0.000114  loss: 0.1785 (0.1885)  time: 0.6189  data: 0.0001  max mem: 15824
[15:03:11.950621] Epoch: [25]  [320/345]  eta: 0:00:15  lr: 0.000113  loss: 0.1945 (0.1890)  time: 0.6196  data: 0.0001  max mem: 15824
[15:03:24.328440] Epoch: [25]  [340/345]  eta: 0:00:03  lr: 0.000113  loss: 0.1782 (0.1889)  time: 0.6188  data: 0.0001  max mem: 15824
[15:03:26.806376] Epoch: [25]  [344/345]  eta: 0:00:00  lr: 0.000113  loss: 0.1811 (0.1890)  time: 0.6187  data: 0.0001  max mem: 15824
[15:03:26.876620] Epoch: [25] Total time: 0:03:34 (0.6213 s / it)
[15:03:26.877172] Averaged stats: lr: 0.000113  loss: 0.1811 (0.1890)
[15:03:27.476871] Test:  [  0/345]  eta: 0:03:24  loss: 0.1602 (0.1602)  time: 0.5941  data: 0.4123  max mem: 15824
[15:03:29.267028] Test:  [ 10/345]  eta: 0:01:12  loss: 0.1631 (0.1689)  time: 0.2167  data: 0.0376  max mem: 15824
[15:03:31.057124] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1656 (0.1723)  time: 0.1789  data: 0.0001  max mem: 15824
[15:03:32.856190] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1676 (0.1733)  time: 0.1794  data: 0.0001  max mem: 15824
[15:03:34.655726] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1697 (0.1731)  time: 0.1799  data: 0.0001  max mem: 15824
[15:03:36.458281] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1690 (0.1744)  time: 0.1800  data: 0.0001  max mem: 15824
[15:03:38.261451] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1733 (0.1751)  time: 0.1802  data: 0.0001  max mem: 15824
[15:03:40.067437] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1741 (0.1763)  time: 0.1804  data: 0.0001  max mem: 15824
[15:03:41.879296] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1722 (0.1757)  time: 0.1808  data: 0.0001  max mem: 15824
[15:03:43.692344] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1651 (0.1748)  time: 0.1812  data: 0.0001  max mem: 15824
[15:03:45.509771] Test:  [100/345]  eta: 0:00:45  loss: 0.1717 (0.1763)  time: 0.1815  data: 0.0001  max mem: 15824
[15:03:47.330920] Test:  [110/345]  eta: 0:00:43  loss: 0.1767 (0.1765)  time: 0.1819  data: 0.0001  max mem: 15824
[15:03:49.155046] Test:  [120/345]  eta: 0:00:41  loss: 0.1820 (0.1774)  time: 0.1822  data: 0.0001  max mem: 15824
[15:03:50.985081] Test:  [130/345]  eta: 0:00:39  loss: 0.1764 (0.1772)  time: 0.1826  data: 0.0001  max mem: 15824
[15:03:52.818609] Test:  [140/345]  eta: 0:00:37  loss: 0.1702 (0.1764)  time: 0.1831  data: 0.0001  max mem: 15824
[15:03:54.656363] Test:  [150/345]  eta: 0:00:35  loss: 0.1684 (0.1760)  time: 0.1835  data: 0.0001  max mem: 15824
[15:03:56.496609] Test:  [160/345]  eta: 0:00:34  loss: 0.1660 (0.1758)  time: 0.1838  data: 0.0001  max mem: 15824
[15:03:58.339407] Test:  [170/345]  eta: 0:00:32  loss: 0.1683 (0.1762)  time: 0.1841  data: 0.0001  max mem: 15824
[15:04:00.184603] Test:  [180/345]  eta: 0:00:30  loss: 0.1862 (0.1769)  time: 0.1843  data: 0.0001  max mem: 15824
[15:04:02.036787] Test:  [190/345]  eta: 0:00:28  loss: 0.1855 (0.1772)  time: 0.1848  data: 0.0001  max mem: 15824
[15:04:03.893828] Test:  [200/345]  eta: 0:00:26  loss: 0.1823 (0.1776)  time: 0.1854  data: 0.0001  max mem: 15824
[15:04:05.751084] Test:  [210/345]  eta: 0:00:24  loss: 0.1780 (0.1778)  time: 0.1857  data: 0.0001  max mem: 15824
[15:04:07.613915] Test:  [220/345]  eta: 0:00:23  loss: 0.1763 (0.1775)  time: 0.1859  data: 0.0001  max mem: 15824
[15:04:09.479177] Test:  [230/345]  eta: 0:00:21  loss: 0.1796 (0.1787)  time: 0.1863  data: 0.0001  max mem: 15824
[15:04:11.349361] Test:  [240/345]  eta: 0:00:19  loss: 0.1821 (0.1785)  time: 0.1867  data: 0.0001  max mem: 15824
[15:04:13.220074] Test:  [250/345]  eta: 0:00:17  loss: 0.1710 (0.1783)  time: 0.1870  data: 0.0001  max mem: 15824
[15:04:15.095555] Test:  [260/345]  eta: 0:00:15  loss: 0.1710 (0.1782)  time: 0.1872  data: 0.0001  max mem: 15824
[15:04:16.973296] Test:  [270/345]  eta: 0:00:13  loss: 0.1713 (0.1783)  time: 0.1876  data: 0.0001  max mem: 15824
[15:04:18.856789] Test:  [280/345]  eta: 0:00:12  loss: 0.1885 (0.1786)  time: 0.1880  data: 0.0001  max mem: 15824
[15:04:20.742402] Test:  [290/345]  eta: 0:00:10  loss: 0.1770 (0.1785)  time: 0.1884  data: 0.0001  max mem: 15824
[15:04:22.631874] Test:  [300/345]  eta: 0:00:08  loss: 0.1730 (0.1785)  time: 0.1887  data: 0.0001  max mem: 15824
[15:04:24.528173] Test:  [310/345]  eta: 0:00:06  loss: 0.1792 (0.1787)  time: 0.1892  data: 0.0001  max mem: 15824
[15:04:26.422278] Test:  [320/345]  eta: 0:00:04  loss: 0.1853 (0.1791)  time: 0.1895  data: 0.0001  max mem: 15824
[15:04:28.319889] Test:  [330/345]  eta: 0:00:02  loss: 0.1792 (0.1790)  time: 0.1895  data: 0.0001  max mem: 15824
[15:04:30.219732] Test:  [340/345]  eta: 0:00:00  loss: 0.1613 (0.1788)  time: 0.1898  data: 0.0001  max mem: 15824
[15:04:30.980511] Test:  [344/345]  eta: 0:00:00  loss: 0.1613 (0.1790)  time: 0.1899  data: 0.0001  max mem: 15824
[15:04:31.055549] Test: Total time: 0:01:04 (0.1860 s / it)
[15:04:41.549606] Test:  [ 0/57]  eta: 0:00:33  loss: 0.4785 (0.4785)  time: 0.5797  data: 0.3992  max mem: 15824
[15:04:43.322386] Test:  [10/57]  eta: 0:00:10  loss: 0.4390 (0.4528)  time: 0.2138  data: 0.0364  max mem: 15824
[15:04:45.097814] Test:  [20/57]  eta: 0:00:07  loss: 0.4059 (0.4245)  time: 0.1773  data: 0.0001  max mem: 15824
[15:04:46.877564] Test:  [30/57]  eta: 0:00:05  loss: 0.2990 (0.3700)  time: 0.1777  data: 0.0001  max mem: 15824
[15:04:48.662549] Test:  [40/57]  eta: 0:00:03  loss: 0.2627 (0.3470)  time: 0.1782  data: 0.0001  max mem: 15824
[15:04:50.447929] Test:  [50/57]  eta: 0:00:01  loss: 0.2924 (0.3467)  time: 0.1785  data: 0.0001  max mem: 15824
[15:04:51.421398] Test:  [56/57]  eta: 0:00:00  loss: 0.3262 (0.3585)  time: 0.1736  data: 0.0000  max mem: 15824
[15:04:51.489463] Test: Total time: 0:00:10 (0.1846 s / it)
[15:04:53.237026] Dice score of the network on the train images: 0.824979, val images: 0.784817
[15:04:53.237250] saving best_dice_model_0 @ epoch 25
[15:04:54.326462] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:04:55.385904] Epoch: [26]  [  0/345]  eta: 0:06:05  lr: 0.000113  loss: 0.1664 (0.1664)  time: 1.0582  data: 0.4367  max mem: 15824
[15:05:07.724721] Epoch: [26]  [ 20/345]  eta: 0:03:27  lr: 0.000113  loss: 0.1887 (0.1922)  time: 0.6169  data: 0.0001  max mem: 15824
[15:05:20.085645] Epoch: [26]  [ 40/345]  eta: 0:03:11  lr: 0.000113  loss: 0.1849 (0.1878)  time: 0.6180  data: 0.0001  max mem: 15824
[15:05:32.471391] Epoch: [26]  [ 60/345]  eta: 0:02:58  lr: 0.000112  loss: 0.1790 (0.1858)  time: 0.6192  data: 0.0001  max mem: 15824
[15:05:44.855561] Epoch: [26]  [ 80/345]  eta: 0:02:45  lr: 0.000112  loss: 0.1922 (0.1878)  time: 0.6192  data: 0.0001  max mem: 15824
[15:05:57.270405] Epoch: [26]  [100/345]  eta: 0:02:32  lr: 0.000112  loss: 0.1697 (0.1859)  time: 0.6207  data: 0.0001  max mem: 15824
[15:06:09.682710] Epoch: [26]  [120/345]  eta: 0:02:20  lr: 0.000112  loss: 0.1792 (0.1859)  time: 0.6206  data: 0.0001  max mem: 15824
[15:06:22.103712] Epoch: [26]  [140/345]  eta: 0:02:07  lr: 0.000111  loss: 0.1921 (0.1863)  time: 0.6210  data: 0.0001  max mem: 15824
[15:06:34.527814] Epoch: [26]  [160/345]  eta: 0:01:55  lr: 0.000111  loss: 0.1735 (0.1853)  time: 0.6212  data: 0.0001  max mem: 15824
[15:06:46.943165] Epoch: [26]  [180/345]  eta: 0:01:42  lr: 0.000111  loss: 0.1812 (0.1853)  time: 0.6207  data: 0.0001  max mem: 15824
[15:06:59.367848] Epoch: [26]  [200/345]  eta: 0:01:30  lr: 0.000111  loss: 0.1921 (0.1854)  time: 0.6212  data: 0.0001  max mem: 15824
[15:07:11.775388] Epoch: [26]  [220/345]  eta: 0:01:17  lr: 0.000110  loss: 0.1782 (0.1848)  time: 0.6203  data: 0.0001  max mem: 15824
[15:07:24.169690] Epoch: [26]  [240/345]  eta: 0:01:05  lr: 0.000110  loss: 0.1769 (0.1845)  time: 0.6197  data: 0.0001  max mem: 15824
[15:07:36.564859] Epoch: [26]  [260/345]  eta: 0:00:52  lr: 0.000110  loss: 0.1749 (0.1843)  time: 0.6197  data: 0.0001  max mem: 15824
[15:07:48.960515] Epoch: [26]  [280/345]  eta: 0:00:40  lr: 0.000110  loss: 0.1815 (0.1844)  time: 0.6197  data: 0.0001  max mem: 15824
[15:08:01.337381] Epoch: [26]  [300/345]  eta: 0:00:27  lr: 0.000110  loss: 0.1827 (0.1845)  time: 0.6188  data: 0.0001  max mem: 15824
[15:08:13.715933] Epoch: [26]  [320/345]  eta: 0:00:15  lr: 0.000109  loss: 0.1903 (0.1851)  time: 0.6189  data: 0.0001  max mem: 15824
[15:08:26.075267] Epoch: [26]  [340/345]  eta: 0:00:03  lr: 0.000109  loss: 0.1778 (0.1852)  time: 0.6179  data: 0.0001  max mem: 15824
[15:08:28.543956] Epoch: [26]  [344/345]  eta: 0:00:00  lr: 0.000109  loss: 0.1850 (0.1855)  time: 0.6176  data: 0.0001  max mem: 15824
[15:08:28.622728] Epoch: [26] Total time: 0:03:34 (0.6211 s / it)
[15:08:28.623087] Averaged stats: lr: 0.000109  loss: 0.1850 (0.1855)
[15:08:29.216452] Test:  [  0/345]  eta: 0:03:22  loss: 0.1394 (0.1394)  time: 0.5877  data: 0.4053  max mem: 15824
[15:08:31.003665] Test:  [ 10/345]  eta: 0:01:12  loss: 0.1838 (0.1829)  time: 0.2158  data: 0.0369  max mem: 15824
[15:08:32.795182] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1826 (0.1804)  time: 0.1789  data: 0.0001  max mem: 15824
[15:08:34.590486] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1738 (0.1800)  time: 0.1793  data: 0.0001  max mem: 15824
[15:08:36.387954] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1802 (0.1802)  time: 0.1796  data: 0.0001  max mem: 15824
[15:08:38.188105] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1802 (0.1821)  time: 0.1798  data: 0.0001  max mem: 15824
[15:08:39.994649] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1853 (0.1842)  time: 0.1803  data: 0.0001  max mem: 15824
[15:08:41.803618] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1908 (0.1865)  time: 0.1807  data: 0.0001  max mem: 15824
[15:08:43.618244] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1786 (0.1850)  time: 0.1811  data: 0.0001  max mem: 15824
[15:08:45.437615] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1749 (0.1852)  time: 0.1816  data: 0.0001  max mem: 15824
[15:08:47.260573] Test:  [100/345]  eta: 0:00:45  loss: 0.1841 (0.1847)  time: 0.1820  data: 0.0001  max mem: 15824
[15:08:49.082924] Test:  [110/345]  eta: 0:00:43  loss: 0.1743 (0.1841)  time: 0.1822  data: 0.0001  max mem: 15824
[15:08:50.910497] Test:  [120/345]  eta: 0:00:41  loss: 0.1776 (0.1841)  time: 0.1824  data: 0.0001  max mem: 15824
[15:08:52.740860] Test:  [130/345]  eta: 0:00:39  loss: 0.1907 (0.1847)  time: 0.1828  data: 0.0001  max mem: 15824
[15:08:54.578047] Test:  [140/345]  eta: 0:00:37  loss: 0.1809 (0.1845)  time: 0.1833  data: 0.0001  max mem: 15824
[15:08:56.415388] Test:  [150/345]  eta: 0:00:35  loss: 0.1759 (0.1842)  time: 0.1837  data: 0.0001  max mem: 15824
[15:08:58.255418] Test:  [160/345]  eta: 0:00:34  loss: 0.1705 (0.1836)  time: 0.1838  data: 0.0001  max mem: 15824
[15:09:00.098732] Test:  [170/345]  eta: 0:00:32  loss: 0.1721 (0.1834)  time: 0.1841  data: 0.0001  max mem: 15824
[15:09:01.945056] Test:  [180/345]  eta: 0:00:30  loss: 0.1778 (0.1830)  time: 0.1844  data: 0.0001  max mem: 15824
[15:09:03.796651] Test:  [190/345]  eta: 0:00:28  loss: 0.1766 (0.1830)  time: 0.1848  data: 0.0001  max mem: 15824
[15:09:05.653624] Test:  [200/345]  eta: 0:00:26  loss: 0.1819 (0.1832)  time: 0.1854  data: 0.0001  max mem: 15824
[15:09:07.511470] Test:  [210/345]  eta: 0:00:24  loss: 0.1814 (0.1832)  time: 0.1857  data: 0.0001  max mem: 15824
[15:09:09.377599] Test:  [220/345]  eta: 0:00:23  loss: 0.1849 (0.1834)  time: 0.1861  data: 0.0001  max mem: 15824
[15:09:11.242378] Test:  [230/345]  eta: 0:00:21  loss: 0.1809 (0.1831)  time: 0.1865  data: 0.0001  max mem: 15824
[15:09:13.111612] Test:  [240/345]  eta: 0:00:19  loss: 0.1751 (0.1833)  time: 0.1866  data: 0.0001  max mem: 15824
[15:09:14.984009] Test:  [250/345]  eta: 0:00:17  loss: 0.1789 (0.1833)  time: 0.1870  data: 0.0001  max mem: 15824
[15:09:16.859234] Test:  [260/345]  eta: 0:00:15  loss: 0.1810 (0.1834)  time: 0.1873  data: 0.0001  max mem: 15824
[15:09:18.737607] Test:  [270/345]  eta: 0:00:13  loss: 0.1810 (0.1833)  time: 0.1876  data: 0.0001  max mem: 15824
[15:09:20.619760] Test:  [280/345]  eta: 0:00:12  loss: 0.1765 (0.1833)  time: 0.1880  data: 0.0001  max mem: 15824
[15:09:22.503336] Test:  [290/345]  eta: 0:00:10  loss: 0.1795 (0.1836)  time: 0.1882  data: 0.0001  max mem: 15824
[15:09:24.393996] Test:  [300/345]  eta: 0:00:08  loss: 0.1832 (0.1835)  time: 0.1887  data: 0.0001  max mem: 15824
[15:09:26.291141] Test:  [310/345]  eta: 0:00:06  loss: 0.1754 (0.1834)  time: 0.1893  data: 0.0001  max mem: 15824
[15:09:28.191893] Test:  [320/345]  eta: 0:00:04  loss: 0.1890 (0.1836)  time: 0.1898  data: 0.0001  max mem: 15824
[15:09:30.092973] Test:  [330/345]  eta: 0:00:02  loss: 0.1979 (0.1838)  time: 0.1900  data: 0.0001  max mem: 15824
[15:09:31.992318] Test:  [340/345]  eta: 0:00:00  loss: 0.1818 (0.1840)  time: 0.1900  data: 0.0001  max mem: 15824
[15:09:32.753080] Test:  [344/345]  eta: 0:00:00  loss: 0.1827 (0.1841)  time: 0.1900  data: 0.0001  max mem: 15824
[15:09:32.820087] Test: Total time: 0:01:04 (0.1861 s / it)
[15:09:43.387151] Test:  [ 0/57]  eta: 0:00:33  loss: 0.4583 (0.4583)  time: 0.5861  data: 0.4035  max mem: 15824
[15:09:45.161110] Test:  [10/57]  eta: 0:00:10  loss: 0.4583 (0.4589)  time: 0.2145  data: 0.0368  max mem: 15824
[15:09:46.937785] Test:  [20/57]  eta: 0:00:07  loss: 0.4559 (0.4441)  time: 0.1775  data: 0.0001  max mem: 15824
[15:09:48.720756] Test:  [30/57]  eta: 0:00:05  loss: 0.3099 (0.3835)  time: 0.1779  data: 0.0001  max mem: 15824
[15:09:50.508754] Test:  [40/57]  eta: 0:00:03  loss: 0.2604 (0.3562)  time: 0.1785  data: 0.0001  max mem: 15824
[15:09:52.295232] Test:  [50/57]  eta: 0:00:01  loss: 0.2987 (0.3581)  time: 0.1787  data: 0.0001  max mem: 15824
[15:09:53.269464] Test:  [56/57]  eta: 0:00:00  loss: 0.3230 (0.3762)  time: 0.1738  data: 0.0001  max mem: 15824
[15:09:53.336912] Test: Total time: 0:00:10 (0.1849 s / it)
[15:09:55.071949] Dice score of the network on the train images: 0.826185, val images: 0.777692
[15:09:55.076036] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:09:56.061602] Epoch: [27]  [  0/345]  eta: 0:05:39  lr: 0.000109  loss: 0.1921 (0.1921)  time: 0.9845  data: 0.3574  max mem: 15824
[15:10:08.412960] Epoch: [27]  [ 20/345]  eta: 0:03:26  lr: 0.000109  loss: 0.1827 (0.1854)  time: 0.6175  data: 0.0001  max mem: 15824
[15:10:20.794193] Epoch: [27]  [ 40/345]  eta: 0:03:11  lr: 0.000108  loss: 0.1736 (0.1821)  time: 0.6190  data: 0.0001  max mem: 15824
[15:10:33.192815] Epoch: [27]  [ 60/345]  eta: 0:02:58  lr: 0.000108  loss: 0.1832 (0.1836)  time: 0.6199  data: 0.0001  max mem: 15824
[15:10:45.594566] Epoch: [27]  [ 80/345]  eta: 0:02:45  lr: 0.000108  loss: 0.1797 (0.1824)  time: 0.6200  data: 0.0001  max mem: 15824
[15:10:58.015275] Epoch: [27]  [100/345]  eta: 0:02:32  lr: 0.000108  loss: 0.1739 (0.1816)  time: 0.6210  data: 0.0001  max mem: 15824
[15:11:10.436024] Epoch: [27]  [120/345]  eta: 0:02:20  lr: 0.000107  loss: 0.1854 (0.1835)  time: 0.6210  data: 0.0001  max mem: 15824
[15:11:22.835974] Epoch: [27]  [140/345]  eta: 0:02:07  lr: 0.000107  loss: 0.1719 (0.1831)  time: 0.6200  data: 0.0001  max mem: 15824
[15:11:35.232724] Epoch: [27]  [160/345]  eta: 0:01:55  lr: 0.000107  loss: 0.1770 (0.1829)  time: 0.6198  data: 0.0001  max mem: 15824
[15:11:47.632603] Epoch: [27]  [180/345]  eta: 0:01:42  lr: 0.000107  loss: 0.1949 (0.1846)  time: 0.6199  data: 0.0001  max mem: 15824
[15:12:00.019038] Epoch: [27]  [200/345]  eta: 0:01:30  lr: 0.000106  loss: 0.1909 (0.1855)  time: 0.6193  data: 0.0001  max mem: 15824
[15:12:12.416912] Epoch: [27]  [220/345]  eta: 0:01:17  lr: 0.000106  loss: 0.1859 (0.1857)  time: 0.6199  data: 0.0001  max mem: 15824
[15:12:24.796814] Epoch: [27]  [240/345]  eta: 0:01:05  lr: 0.000106  loss: 0.1821 (0.1855)  time: 0.6190  data: 0.0001  max mem: 15824
[15:12:37.193747] Epoch: [27]  [260/345]  eta: 0:00:52  lr: 0.000106  loss: 0.1843 (0.1855)  time: 0.6198  data: 0.0001  max mem: 15824
[15:12:49.586304] Epoch: [27]  [280/345]  eta: 0:00:40  lr: 0.000105  loss: 0.1769 (0.1851)  time: 0.6196  data: 0.0001  max mem: 15824
[15:13:01.988330] Epoch: [27]  [300/345]  eta: 0:00:27  lr: 0.000105  loss: 0.1743 (0.1848)  time: 0.6201  data: 0.0001  max mem: 15824
[15:13:14.380710] Epoch: [27]  [320/345]  eta: 0:00:15  lr: 0.000105  loss: 0.1848 (0.1849)  time: 0.6196  data: 0.0001  max mem: 15824
[15:13:26.773090] Epoch: [27]  [340/345]  eta: 0:00:03  lr: 0.000104  loss: 0.1838 (0.1846)  time: 0.6196  data: 0.0001  max mem: 15824
[15:13:29.249138] Epoch: [27]  [344/345]  eta: 0:00:00  lr: 0.000104  loss: 0.1849 (0.1847)  time: 0.6193  data: 0.0001  max mem: 15824
[15:13:29.320488] Epoch: [27] Total time: 0:03:34 (0.6210 s / it)
[15:13:29.320806] Averaged stats: lr: 0.000104  loss: 0.1849 (0.1847)
[15:13:29.894296] Test:  [  0/345]  eta: 0:03:15  loss: 0.1537 (0.1537)  time: 0.5679  data: 0.3845  max mem: 15824
[15:13:31.681608] Test:  [ 10/345]  eta: 0:01:11  loss: 0.1796 (0.1758)  time: 0.2140  data: 0.0350  max mem: 15824
[15:13:33.474419] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1781 (0.1770)  time: 0.1789  data: 0.0001  max mem: 15824
[15:13:35.269459] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1741 (0.1770)  time: 0.1793  data: 0.0001  max mem: 15824
[15:13:37.068091] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1694 (0.1738)  time: 0.1796  data: 0.0001  max mem: 15824
[15:13:38.868159] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1694 (0.1746)  time: 0.1799  data: 0.0001  max mem: 15824
[15:13:40.672511] Test:  [ 60/345]  eta: 0:00:52  loss: 0.1658 (0.1726)  time: 0.1802  data: 0.0001  max mem: 15824
[15:13:42.482204] Test:  [ 70/345]  eta: 0:00:50  loss: 0.1687 (0.1735)  time: 0.1806  data: 0.0001  max mem: 15824
[15:13:44.291243] Test:  [ 80/345]  eta: 0:00:48  loss: 0.1672 (0.1726)  time: 0.1808  data: 0.0001  max mem: 15824
[15:13:46.107285] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1597 (0.1732)  time: 0.1812  data: 0.0001  max mem: 15824
[15:13:47.926621] Test:  [100/345]  eta: 0:00:45  loss: 0.1642 (0.1732)  time: 0.1817  data: 0.0001  max mem: 15824
[15:13:49.747776] Test:  [110/345]  eta: 0:00:43  loss: 0.1654 (0.1725)  time: 0.1820  data: 0.0001  max mem: 15824
[15:13:51.572895] Test:  [120/345]  eta: 0:00:41  loss: 0.1735 (0.1733)  time: 0.1823  data: 0.0001  max mem: 15824
[15:13:53.403774] Test:  [130/345]  eta: 0:00:39  loss: 0.1677 (0.1720)  time: 0.1827  data: 0.0001  max mem: 15824
[15:13:55.235106] Test:  [140/345]  eta: 0:00:37  loss: 0.1677 (0.1726)  time: 0.1830  data: 0.0001  max mem: 15824
[15:13:57.071914] Test:  [150/345]  eta: 0:00:35  loss: 0.1715 (0.1724)  time: 0.1833  data: 0.0001  max mem: 15824
[15:13:58.912309] Test:  [160/345]  eta: 0:00:33  loss: 0.1710 (0.1722)  time: 0.1838  data: 0.0001  max mem: 15824
[15:14:00.756000] Test:  [170/345]  eta: 0:00:32  loss: 0.1752 (0.1721)  time: 0.1841  data: 0.0001  max mem: 15824
[15:14:02.603397] Test:  [180/345]  eta: 0:00:30  loss: 0.1729 (0.1723)  time: 0.1845  data: 0.0001  max mem: 15824
[15:14:04.453891] Test:  [190/345]  eta: 0:00:28  loss: 0.1786 (0.1732)  time: 0.1848  data: 0.0001  max mem: 15824
[15:14:06.307048] Test:  [200/345]  eta: 0:00:26  loss: 0.1796 (0.1733)  time: 0.1851  data: 0.0001  max mem: 15824
[15:14:08.167161] Test:  [210/345]  eta: 0:00:24  loss: 0.1796 (0.1736)  time: 0.1856  data: 0.0001  max mem: 15824
[15:14:10.027225] Test:  [220/345]  eta: 0:00:23  loss: 0.1732 (0.1735)  time: 0.1859  data: 0.0001  max mem: 15824
[15:14:11.892060] Test:  [230/345]  eta: 0:00:21  loss: 0.1712 (0.1734)  time: 0.1862  data: 0.0001  max mem: 15824
[15:14:13.758480] Test:  [240/345]  eta: 0:00:19  loss: 0.1721 (0.1735)  time: 0.1865  data: 0.0001  max mem: 15824
[15:14:15.629781] Test:  [250/345]  eta: 0:00:17  loss: 0.1726 (0.1736)  time: 0.1868  data: 0.0001  max mem: 15824
[15:14:17.503806] Test:  [260/345]  eta: 0:00:15  loss: 0.1687 (0.1734)  time: 0.1872  data: 0.0001  max mem: 15824
[15:14:19.381178] Test:  [270/345]  eta: 0:00:13  loss: 0.1687 (0.1735)  time: 0.1875  data: 0.0001  max mem: 15824
[15:14:21.264037] Test:  [280/345]  eta: 0:00:12  loss: 0.1715 (0.1738)  time: 0.1880  data: 0.0001  max mem: 15824
[15:14:23.150649] Test:  [290/345]  eta: 0:00:10  loss: 0.1699 (0.1738)  time: 0.1884  data: 0.0001  max mem: 15824
[15:14:25.037816] Test:  [300/345]  eta: 0:00:08  loss: 0.1786 (0.1741)  time: 0.1886  data: 0.0001  max mem: 15824
[15:14:26.929997] Test:  [310/345]  eta: 0:00:06  loss: 0.1786 (0.1740)  time: 0.1889  data: 0.0001  max mem: 15824
[15:14:28.824524] Test:  [320/345]  eta: 0:00:04  loss: 0.1707 (0.1741)  time: 0.1893  data: 0.0001  max mem: 15824
[15:14:30.723962] Test:  [330/345]  eta: 0:00:02  loss: 0.1664 (0.1739)  time: 0.1896  data: 0.0001  max mem: 15824
[15:14:32.623916] Test:  [340/345]  eta: 0:00:00  loss: 0.1696 (0.1739)  time: 0.1899  data: 0.0001  max mem: 15824
[15:14:33.384493] Test:  [344/345]  eta: 0:00:00  loss: 0.1696 (0.1740)  time: 0.1899  data: 0.0001  max mem: 15824
[15:14:33.448506] Test: Total time: 0:01:04 (0.1859 s / it)
[15:14:43.956337] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4597 (0.4597)  time: 0.5352  data: 0.3542  max mem: 15824
[15:14:45.731944] Test:  [10/57]  eta: 0:00:09  loss: 0.4597 (0.4706)  time: 0.2100  data: 0.0323  max mem: 15824
[15:14:47.511006] Test:  [20/57]  eta: 0:00:07  loss: 0.4416 (0.4463)  time: 0.1777  data: 0.0001  max mem: 15824
[15:14:49.290455] Test:  [30/57]  eta: 0:00:05  loss: 0.2859 (0.3894)  time: 0.1779  data: 0.0001  max mem: 15824
[15:14:51.074772] Test:  [40/57]  eta: 0:00:03  loss: 0.2712 (0.3633)  time: 0.1781  data: 0.0001  max mem: 15824
[15:14:52.859496] Test:  [50/57]  eta: 0:00:01  loss: 0.3047 (0.3643)  time: 0.1784  data: 0.0001  max mem: 15824
[15:14:53.831993] Test:  [56/57]  eta: 0:00:00  loss: 0.3622 (0.3805)  time: 0.1735  data: 0.0000  max mem: 15824
[15:14:53.897523] Test: Total time: 0:00:10 (0.1838 s / it)
[15:14:55.693420] Dice score of the network on the train images: 0.841276, val images: 0.772819
[15:14:55.697501] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:14:56.703145] Epoch: [28]  [  0/345]  eta: 0:05:46  lr: 0.000104  loss: 0.1871 (0.1871)  time: 1.0044  data: 0.3804  max mem: 15824
[15:15:09.049554] Epoch: [28]  [ 20/345]  eta: 0:03:26  lr: 0.000104  loss: 0.1716 (0.1755)  time: 0.6173  data: 0.0001  max mem: 15824
[15:15:21.404867] Epoch: [28]  [ 40/345]  eta: 0:03:11  lr: 0.000104  loss: 0.1819 (0.1808)  time: 0.6177  data: 0.0001  max mem: 15824
[15:15:33.792747] Epoch: [28]  [ 60/345]  eta: 0:02:57  lr: 0.000103  loss: 0.1649 (0.1793)  time: 0.6193  data: 0.0001  max mem: 15824
[15:15:46.196724] Epoch: [28]  [ 80/345]  eta: 0:02:45  lr: 0.000103  loss: 0.1726 (0.1782)  time: 0.6201  data: 0.0001  max mem: 15824
[15:15:58.615777] Epoch: [28]  [100/345]  eta: 0:02:32  lr: 0.000103  loss: 0.1761 (0.1794)  time: 0.6209  data: 0.0001  max mem: 15824
[15:16:11.042419] Epoch: [28]  [120/345]  eta: 0:02:20  lr: 0.000103  loss: 0.1776 (0.1801)  time: 0.6213  data: 0.0001  max mem: 15824
[15:16:23.435692] Epoch: [28]  [140/345]  eta: 0:02:07  lr: 0.000102  loss: 0.1688 (0.1788)  time: 0.6196  data: 0.0001  max mem: 15824
[15:16:35.847548] Epoch: [28]  [160/345]  eta: 0:01:55  lr: 0.000102  loss: 0.1727 (0.1786)  time: 0.6205  data: 0.0001  max mem: 15824
[15:16:48.245095] Epoch: [28]  [180/345]  eta: 0:01:42  lr: 0.000102  loss: 0.1665 (0.1777)  time: 0.6198  data: 0.0001  max mem: 15824
[15:17:00.622186] Epoch: [28]  [200/345]  eta: 0:01:30  lr: 0.000101  loss: 0.1723 (0.1775)  time: 0.6188  data: 0.0001  max mem: 15824
[15:17:12.992941] Epoch: [28]  [220/345]  eta: 0:01:17  lr: 0.000101  loss: 0.1671 (0.1771)  time: 0.6185  data: 0.0001  max mem: 15824
[15:17:25.369923] Epoch: [28]  [240/345]  eta: 0:01:05  lr: 0.000101  loss: 0.1697 (0.1774)  time: 0.6188  data: 0.0001  max mem: 15824
[15:17:37.739600] Epoch: [28]  [260/345]  eta: 0:00:52  lr: 0.000101  loss: 0.1769 (0.1778)  time: 0.6184  data: 0.0001  max mem: 15824
[15:17:50.120237] Epoch: [28]  [280/345]  eta: 0:00:40  lr: 0.000100  loss: 0.1680 (0.1776)  time: 0.6190  data: 0.0001  max mem: 15824
[15:18:02.487699] Epoch: [28]  [300/345]  eta: 0:00:27  lr: 0.000100  loss: 0.1755 (0.1776)  time: 0.6183  data: 0.0001  max mem: 15824
[15:18:14.850067] Epoch: [28]  [320/345]  eta: 0:00:15  lr: 0.000100  loss: 0.1718 (0.1777)  time: 0.6181  data: 0.0001  max mem: 15824
[15:18:27.214983] Epoch: [28]  [340/345]  eta: 0:00:03  lr: 0.000099  loss: 0.1841 (0.1779)  time: 0.6182  data: 0.0001  max mem: 15824
[15:18:29.683766] Epoch: [28]  [344/345]  eta: 0:00:00  lr: 0.000099  loss: 0.1674 (0.1781)  time: 0.6181  data: 0.0001  max mem: 15824
[15:18:29.759997] Epoch: [28] Total time: 0:03:34 (0.6205 s / it)
[15:18:29.760124] Averaged stats: lr: 0.000099  loss: 0.1674 (0.1781)
[15:18:30.331381] Test:  [  0/345]  eta: 0:03:15  loss: 0.1534 (0.1534)  time: 0.5676  data: 0.3859  max mem: 15824
[15:18:32.120286] Test:  [ 10/345]  eta: 0:01:11  loss: 0.1708 (0.1669)  time: 0.2141  data: 0.0352  max mem: 15824
[15:18:33.911756] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1519 (0.1567)  time: 0.1789  data: 0.0001  max mem: 15824
[15:18:35.705340] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1504 (0.1610)  time: 0.1792  data: 0.0001  max mem: 15824
[15:18:37.505004] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1560 (0.1600)  time: 0.1796  data: 0.0001  max mem: 15824
[15:18:39.306725] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1532 (0.1590)  time: 0.1800  data: 0.0001  max mem: 15824
[15:18:41.109120] Test:  [ 60/345]  eta: 0:00:52  loss: 0.1578 (0.1609)  time: 0.1801  data: 0.0001  max mem: 15824
[15:18:42.916285] Test:  [ 70/345]  eta: 0:00:50  loss: 0.1662 (0.1645)  time: 0.1804  data: 0.0001  max mem: 15824
[15:18:44.728839] Test:  [ 80/345]  eta: 0:00:48  loss: 0.1728 (0.1651)  time: 0.1809  data: 0.0001  max mem: 15824
[15:18:46.544548] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1728 (0.1660)  time: 0.1814  data: 0.0001  max mem: 15824
[15:18:48.364985] Test:  [100/345]  eta: 0:00:45  loss: 0.1746 (0.1667)  time: 0.1817  data: 0.0001  max mem: 15824
[15:18:50.186718] Test:  [110/345]  eta: 0:00:43  loss: 0.1649 (0.1659)  time: 0.1821  data: 0.0001  max mem: 15824
[15:18:52.011044] Test:  [120/345]  eta: 0:00:41  loss: 0.1628 (0.1659)  time: 0.1822  data: 0.0001  max mem: 15824
[15:18:53.840020] Test:  [130/345]  eta: 0:00:39  loss: 0.1657 (0.1661)  time: 0.1826  data: 0.0001  max mem: 15824
[15:18:55.671653] Test:  [140/345]  eta: 0:00:37  loss: 0.1635 (0.1656)  time: 0.1830  data: 0.0001  max mem: 15824
[15:18:57.508034] Test:  [150/345]  eta: 0:00:35  loss: 0.1589 (0.1660)  time: 0.1833  data: 0.0001  max mem: 15824
[15:18:59.347924] Test:  [160/345]  eta: 0:00:33  loss: 0.1589 (0.1655)  time: 0.1838  data: 0.0001  max mem: 15824
[15:19:01.190517] Test:  [170/345]  eta: 0:00:32  loss: 0.1602 (0.1659)  time: 0.1841  data: 0.0001  max mem: 15824
[15:19:03.036308] Test:  [180/345]  eta: 0:00:30  loss: 0.1655 (0.1661)  time: 0.1844  data: 0.0001  max mem: 15824
[15:19:04.884667] Test:  [190/345]  eta: 0:00:28  loss: 0.1627 (0.1662)  time: 0.1847  data: 0.0001  max mem: 15824
[15:19:06.737697] Test:  [200/345]  eta: 0:00:26  loss: 0.1620 (0.1662)  time: 0.1850  data: 0.0001  max mem: 15824
[15:19:08.594763] Test:  [210/345]  eta: 0:00:24  loss: 0.1526 (0.1657)  time: 0.1854  data: 0.0001  max mem: 15824
[15:19:10.454255] Test:  [220/345]  eta: 0:00:23  loss: 0.1585 (0.1656)  time: 0.1858  data: 0.0001  max mem: 15824
[15:19:12.317109] Test:  [230/345]  eta: 0:00:21  loss: 0.1647 (0.1658)  time: 0.1861  data: 0.0001  max mem: 15824
[15:19:14.185478] Test:  [240/345]  eta: 0:00:19  loss: 0.1654 (0.1663)  time: 0.1865  data: 0.0001  max mem: 15824
[15:19:16.056759] Test:  [250/345]  eta: 0:00:17  loss: 0.1840 (0.1671)  time: 0.1869  data: 0.0001  max mem: 15824
[15:19:17.930867] Test:  [260/345]  eta: 0:00:15  loss: 0.1766 (0.1672)  time: 0.1872  data: 0.0001  max mem: 15824
[15:19:19.806701] Test:  [270/345]  eta: 0:00:13  loss: 0.1718 (0.1674)  time: 0.1874  data: 0.0001  max mem: 15824
[15:19:21.687465] Test:  [280/345]  eta: 0:00:12  loss: 0.1718 (0.1677)  time: 0.1878  data: 0.0001  max mem: 15824
[15:19:23.568892] Test:  [290/345]  eta: 0:00:10  loss: 0.1692 (0.1679)  time: 0.1881  data: 0.0001  max mem: 15824
[15:19:25.457262] Test:  [300/345]  eta: 0:00:08  loss: 0.1692 (0.1681)  time: 0.1884  data: 0.0001  max mem: 15824
[15:19:27.353079] Test:  [310/345]  eta: 0:00:06  loss: 0.1592 (0.1678)  time: 0.1892  data: 0.0001  max mem: 15824
[15:19:29.247977] Test:  [320/345]  eta: 0:00:04  loss: 0.1581 (0.1679)  time: 0.1895  data: 0.0001  max mem: 15824
[15:19:31.147335] Test:  [330/345]  eta: 0:00:02  loss: 0.1631 (0.1677)  time: 0.1897  data: 0.0001  max mem: 15824
[15:19:33.045458] Test:  [340/345]  eta: 0:00:00  loss: 0.1569 (0.1674)  time: 0.1898  data: 0.0001  max mem: 15824
[15:19:33.806392] Test:  [344/345]  eta: 0:00:00  loss: 0.1466 (0.1671)  time: 0.1899  data: 0.0001  max mem: 15824
[15:19:33.875887] Test: Total time: 0:01:04 (0.1858 s / it)
[15:19:44.290936] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4408 (0.4408)  time: 0.5379  data: 0.3569  max mem: 15824
[15:19:46.060626] Test:  [10/57]  eta: 0:00:09  loss: 0.4391 (0.4463)  time: 0.2097  data: 0.0325  max mem: 15824
[15:19:47.838045] Test:  [20/57]  eta: 0:00:07  loss: 0.4242 (0.4247)  time: 0.1773  data: 0.0001  max mem: 15824
[15:19:49.617768] Test:  [30/57]  eta: 0:00:05  loss: 0.2884 (0.3699)  time: 0.1778  data: 0.0001  max mem: 15824
[15:19:51.404111] Test:  [40/57]  eta: 0:00:03  loss: 0.2502 (0.3447)  time: 0.1782  data: 0.0001  max mem: 15824
[15:19:53.189632] Test:  [50/57]  eta: 0:00:01  loss: 0.2887 (0.3460)  time: 0.1785  data: 0.0001  max mem: 15824
[15:19:54.160419] Test:  [56/57]  eta: 0:00:00  loss: 0.3474 (0.3597)  time: 0.1734  data: 0.0000  max mem: 15824
[15:19:54.239703] Test: Total time: 0:00:10 (0.1840 s / it)
[15:19:55.981104] Dice score of the network on the train images: 0.833183, val images: 0.782586
[15:19:55.984731] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:19:57.012574] Epoch: [29]  [  0/345]  eta: 0:05:54  lr: 0.000099  loss: 0.1613 (0.1613)  time: 1.0270  data: 0.4059  max mem: 15824
[15:20:09.315820] Epoch: [29]  [ 20/345]  eta: 0:03:26  lr: 0.000099  loss: 0.1628 (0.1673)  time: 0.6151  data: 0.0001  max mem: 15824
[15:20:21.649276] Epoch: [29]  [ 40/345]  eta: 0:03:10  lr: 0.000099  loss: 0.1666 (0.1688)  time: 0.6166  data: 0.0001  max mem: 15824
[15:20:33.995168] Epoch: [29]  [ 60/345]  eta: 0:02:57  lr: 0.000098  loss: 0.1663 (0.1693)  time: 0.6173  data: 0.0001  max mem: 15824
[15:20:46.357091] Epoch: [29]  [ 80/345]  eta: 0:02:44  lr: 0.000098  loss: 0.1606 (0.1677)  time: 0.6181  data: 0.0001  max mem: 15824
[15:20:58.728235] Epoch: [29]  [100/345]  eta: 0:02:32  lr: 0.000098  loss: 0.1659 (0.1694)  time: 0.6185  data: 0.0001  max mem: 15824
[15:21:11.163265] Epoch: [29]  [120/345]  eta: 0:02:19  lr: 0.000097  loss: 0.1686 (0.1698)  time: 0.6217  data: 0.0001  max mem: 15824
[15:21:23.586443] Epoch: [29]  [140/345]  eta: 0:02:07  lr: 0.000097  loss: 0.1589 (0.1688)  time: 0.6211  data: 0.0001  max mem: 15824
[15:21:35.993301] Epoch: [29]  [160/345]  eta: 0:01:54  lr: 0.000097  loss: 0.1719 (0.1694)  time: 0.6203  data: 0.0001  max mem: 15824
[15:21:48.408938] Epoch: [29]  [180/345]  eta: 0:01:42  lr: 0.000096  loss: 0.1624 (0.1695)  time: 0.6207  data: 0.0001  max mem: 15824
[15:22:00.824582] Epoch: [29]  [200/345]  eta: 0:01:30  lr: 0.000096  loss: 0.1562 (0.1685)  time: 0.6207  data: 0.0001  max mem: 15824
[15:22:13.249440] Epoch: [29]  [220/345]  eta: 0:01:17  lr: 0.000096  loss: 0.1596 (0.1684)  time: 0.6212  data: 0.0001  max mem: 15824
[15:22:25.672061] Epoch: [29]  [240/345]  eta: 0:01:05  lr: 0.000095  loss: 0.1648 (0.1680)  time: 0.6211  data: 0.0001  max mem: 15824
[15:22:38.070240] Epoch: [29]  [260/345]  eta: 0:00:52  lr: 0.000095  loss: 0.1817 (0.1697)  time: 0.6199  data: 0.0001  max mem: 15824
[15:22:50.454131] Epoch: [29]  [280/345]  eta: 0:00:40  lr: 0.000095  loss: 0.1672 (0.1702)  time: 0.6191  data: 0.0001  max mem: 15824
[15:23:02.864156] Epoch: [29]  [300/345]  eta: 0:00:27  lr: 0.000094  loss: 0.1697 (0.1702)  time: 0.6205  data: 0.0001  max mem: 15824
[15:23:15.244247] Epoch: [29]  [320/345]  eta: 0:00:15  lr: 0.000094  loss: 0.1755 (0.1705)  time: 0.6190  data: 0.0001  max mem: 15824
[15:23:27.617400] Epoch: [29]  [340/345]  eta: 0:00:03  lr: 0.000094  loss: 0.1758 (0.1709)  time: 0.6186  data: 0.0001  max mem: 15824
[15:23:30.091786] Epoch: [29]  [344/345]  eta: 0:00:00  lr: 0.000094  loss: 0.1796 (0.1710)  time: 0.6185  data: 0.0001  max mem: 15824
[15:23:30.154714] Epoch: [29] Total time: 0:03:34 (0.6208 s / it)
[15:23:30.154930] Averaged stats: lr: 0.000094  loss: 0.1796 (0.1710)
[15:23:30.733673] Test:  [  0/345]  eta: 0:03:17  loss: 0.1475 (0.1475)  time: 0.5733  data: 0.3904  max mem: 15824
[15:23:32.523027] Test:  [ 10/345]  eta: 0:01:11  loss: 0.1484 (0.1544)  time: 0.2147  data: 0.0356  max mem: 15824
[15:23:34.312933] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1553 (0.1559)  time: 0.1789  data: 0.0001  max mem: 15824
[15:23:36.107667] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1573 (0.1576)  time: 0.1792  data: 0.0001  max mem: 15824
[15:23:37.907287] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1675 (0.1618)  time: 0.1797  data: 0.0001  max mem: 15824
[15:23:39.708416] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1685 (0.1621)  time: 0.1800  data: 0.0001  max mem: 15824
[15:23:41.511700] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1677 (0.1626)  time: 0.1802  data: 0.0001  max mem: 15824
[15:23:43.319327] Test:  [ 70/345]  eta: 0:00:50  loss: 0.1735 (0.1636)  time: 0.1805  data: 0.0001  max mem: 15824
[15:23:45.131370] Test:  [ 80/345]  eta: 0:00:48  loss: 0.1702 (0.1642)  time: 0.1809  data: 0.0001  max mem: 15824
[15:23:46.947270] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1683 (0.1644)  time: 0.1813  data: 0.0001  max mem: 15824
[15:23:48.765292] Test:  [100/345]  eta: 0:00:45  loss: 0.1567 (0.1642)  time: 0.1816  data: 0.0001  max mem: 15824
[15:23:50.587137] Test:  [110/345]  eta: 0:00:43  loss: 0.1486 (0.1630)  time: 0.1819  data: 0.0001  max mem: 15824
[15:23:52.414192] Test:  [120/345]  eta: 0:00:41  loss: 0.1561 (0.1627)  time: 0.1824  data: 0.0001  max mem: 15824
[15:23:54.243093] Test:  [130/345]  eta: 0:00:39  loss: 0.1525 (0.1620)  time: 0.1827  data: 0.0001  max mem: 15824
[15:23:56.074204] Test:  [140/345]  eta: 0:00:37  loss: 0.1515 (0.1623)  time: 0.1829  data: 0.0001  max mem: 15824
[15:23:57.911129] Test:  [150/345]  eta: 0:00:35  loss: 0.1601 (0.1622)  time: 0.1833  data: 0.0001  max mem: 15824
[15:23:59.753973] Test:  [160/345]  eta: 0:00:33  loss: 0.1535 (0.1617)  time: 0.1839  data: 0.0001  max mem: 15824
[15:24:01.599381] Test:  [170/345]  eta: 0:00:32  loss: 0.1529 (0.1614)  time: 0.1843  data: 0.0001  max mem: 15824
[15:24:03.447974] Test:  [180/345]  eta: 0:00:30  loss: 0.1489 (0.1612)  time: 0.1846  data: 0.0001  max mem: 15824
[15:24:05.298934] Test:  [190/345]  eta: 0:00:28  loss: 0.1523 (0.1611)  time: 0.1849  data: 0.0001  max mem: 15824
[15:24:07.154442] Test:  [200/345]  eta: 0:00:26  loss: 0.1577 (0.1612)  time: 0.1853  data: 0.0001  max mem: 15824
[15:24:09.014273] Test:  [210/345]  eta: 0:00:24  loss: 0.1618 (0.1619)  time: 0.1857  data: 0.0001  max mem: 15824
[15:24:10.875018] Test:  [220/345]  eta: 0:00:23  loss: 0.1652 (0.1618)  time: 0.1860  data: 0.0001  max mem: 15824
[15:24:12.739093] Test:  [230/345]  eta: 0:00:21  loss: 0.1625 (0.1618)  time: 0.1862  data: 0.0001  max mem: 15824
[15:24:14.608704] Test:  [240/345]  eta: 0:00:19  loss: 0.1625 (0.1622)  time: 0.1866  data: 0.0001  max mem: 15824
[15:24:16.481277] Test:  [250/345]  eta: 0:00:17  loss: 0.1658 (0.1623)  time: 0.1870  data: 0.0001  max mem: 15824
[15:24:18.355733] Test:  [260/345]  eta: 0:00:15  loss: 0.1555 (0.1618)  time: 0.1873  data: 0.0001  max mem: 15824
[15:24:20.233665] Test:  [270/345]  eta: 0:00:13  loss: 0.1559 (0.1618)  time: 0.1876  data: 0.0001  max mem: 15824
[15:24:22.115898] Test:  [280/345]  eta: 0:00:12  loss: 0.1640 (0.1623)  time: 0.1879  data: 0.0001  max mem: 15824
[15:24:24.000767] Test:  [290/345]  eta: 0:00:10  loss: 0.1713 (0.1625)  time: 0.1883  data: 0.0001  max mem: 15824
[15:24:25.890528] Test:  [300/345]  eta: 0:00:08  loss: 0.1609 (0.1623)  time: 0.1887  data: 0.0001  max mem: 15824
[15:24:27.783975] Test:  [310/345]  eta: 0:00:06  loss: 0.1503 (0.1620)  time: 0.1891  data: 0.0001  max mem: 15824
[15:24:29.678248] Test:  [320/345]  eta: 0:00:04  loss: 0.1474 (0.1618)  time: 0.1893  data: 0.0001  max mem: 15824
[15:24:31.578376] Test:  [330/345]  eta: 0:00:02  loss: 0.1665 (0.1621)  time: 0.1897  data: 0.0001  max mem: 15824
[15:24:33.478047] Test:  [340/345]  eta: 0:00:00  loss: 0.1687 (0.1622)  time: 0.1899  data: 0.0001  max mem: 15824
[15:24:34.239844] Test:  [344/345]  eta: 0:00:00  loss: 0.1665 (0.1622)  time: 0.1901  data: 0.0001  max mem: 15824
[15:24:34.308192] Test: Total time: 0:01:04 (0.1859 s / it)
[15:24:44.708341] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4427 (0.4427)  time: 0.5363  data: 0.3553  max mem: 15824
[15:24:46.482333] Test:  [10/57]  eta: 0:00:09  loss: 0.4427 (0.4583)  time: 0.2099  data: 0.0324  max mem: 15824
[15:24:48.260826] Test:  [20/57]  eta: 0:00:07  loss: 0.4326 (0.4433)  time: 0.1775  data: 0.0001  max mem: 15824
[15:24:50.042853] Test:  [30/57]  eta: 0:00:05  loss: 0.2786 (0.3859)  time: 0.1780  data: 0.0001  max mem: 15824
[15:24:51.831985] Test:  [40/57]  eta: 0:00:03  loss: 0.2716 (0.3643)  time: 0.1785  data: 0.0001  max mem: 15824
[15:24:53.617229] Test:  [50/57]  eta: 0:00:01  loss: 0.3115 (0.3686)  time: 0.1787  data: 0.0001  max mem: 15824
[15:24:54.590190] Test:  [56/57]  eta: 0:00:00  loss: 0.3711 (0.3855)  time: 0.1736  data: 0.0001  max mem: 15824
[15:24:54.667085] Test: Total time: 0:00:10 (0.1841 s / it)
[15:24:56.470197] Dice score of the network on the train images: 0.849895, val images: 0.761612
[15:24:56.473861] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:24:57.486836] Epoch: [30]  [  0/345]  eta: 0:05:49  lr: 0.000094  loss: 0.1643 (0.1643)  time: 1.0121  data: 0.3899  max mem: 15824

[15:25:09.816020] Epoch: [30]  [ 20/345]  eta: 0:03:26  lr: 0.000093  loss: 0.1727 (0.1765)  time: 0.6164  data: 0.0001  max mem: 15824
[15:25:22.179941] Epoch: [30]  [ 40/345]  eta: 0:03:11  lr: 0.000093  loss: 0.1622 (0.1724)  time: 0.6181  data: 0.0001  max mem: 15824
[15:25:34.565405] Epoch: [30]  [ 60/345]  eta: 0:02:57  lr: 0.000093  loss: 0.1694 (0.1710)  time: 0.6192  data: 0.0001  max mem: 15824
[15:25:46.947251] Epoch: [30]  [ 80/345]  eta: 0:02:45  lr: 0.000092  loss: 0.1647 (0.1707)  time: 0.6190  data: 0.0001  max mem: 15824
[15:25:59.357976] Epoch: [30]  [100/345]  eta: 0:02:32  lr: 0.000092  loss: 0.1550 (0.1679)  time: 0.6205  data: 0.0001  max mem: 15824
[15:26:11.791888] Epoch: [30]  [120/345]  eta: 0:02:20  lr: 0.000092  loss: 0.1638 (0.1676)  time: 0.6216  data: 0.0001  max mem: 15824
[15:26:24.219136] Epoch: [30]  [140/345]  eta: 0:02:07  lr: 0.000091  loss: 0.1568 (0.1669)  time: 0.6213  data: 0.0001  max mem: 15824
[15:26:36.651481] Epoch: [30]  [160/345]  eta: 0:01:55  lr: 0.000091  loss: 0.1623 (0.1668)  time: 0.6216  data: 0.0001  max mem: 15824
[15:26:49.084870] Epoch: [30]  [180/345]  eta: 0:01:42  lr: 0.000091  loss: 0.1657 (0.1676)  time: 0.6216  data: 0.0001  max mem: 15824
[15:27:01.511164] Epoch: [30]  [200/345]  eta: 0:01:30  lr: 0.000090  loss: 0.1674 (0.1678)  time: 0.6213  data: 0.0001  max mem: 15824

[15:27:13.937494] Epoch: [30]  [220/345]  eta: 0:01:17  lr: 0.000090  loss: 0.1626 (0.1675)  time: 0.6213  data: 0.0001  max mem: 15824
[15:27:26.364913] Epoch: [30]  [240/345]  eta: 0:01:05  lr: 0.000090  loss: 0.1656 (0.1677)  time: 0.6213  data: 0.0001  max mem: 15824
[15:27:38.775204] Epoch: [30]  [260/345]  eta: 0:00:52  lr: 0.000089  loss: 0.1742 (0.1681)  time: 0.6205  data: 0.0001  max mem: 15824
[15:27:51.173727] Epoch: [30]  [280/345]  eta: 0:00:40  lr: 0.000089  loss: 0.1599 (0.1674)  time: 0.6199  data: 0.0001  max mem: 15824
[15:28:03.578942] Epoch: [30]  [300/345]  eta: 0:00:27  lr: 0.000089  loss: 0.1724 (0.1680)  time: 0.6202  data: 0.0001  max mem: 15824
[15:28:15.991954] Epoch: [30]  [320/345]  eta: 0:00:15  lr: 0.000088  loss: 0.1660 (0.1680)  time: 0.6206  data: 0.0001  max mem: 15824
[15:28:28.386239] Epoch: [30]  [340/345]  eta: 0:00:03  lr: 0.000088  loss: 0.1690 (0.1679)  time: 0.6197  data: 0.0001  max mem: 15824
[15:28:30.863309] Epoch: [30]  [344/345]  eta: 0:00:00  lr: 0.000088  loss: 0.1640 (0.1677)  time: 0.6198  data: 0.0001  max mem: 15824
[15:28:30.940808] Epoch: [30] Total time: 0:03:34 (0.6216 s / it)
[15:28:30.941063] Averaged stats: lr: 0.000088  loss: 0.1640 (0.1677)
[15:28:31.531214] Test:  [  0/345]  eta: 0:03:22  loss: 0.1381 (0.1381)  time: 0.5858  data: 0.4054  max mem: 15824
[15:28:33.321005] Test:  [ 10/345]  eta: 0:01:12  loss: 0.1400 (0.1443)  time: 0.2159  data: 0.0369  max mem: 15824
[15:28:35.110756] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1568 (0.1568)  time: 0.1789  data: 0.0001  max mem: 15824
[15:28:36.909697] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1701 (0.1585)  time: 0.1794  data: 0.0001  max mem: 15824
[15:28:38.709498] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1696 (0.1596)  time: 0.1799  data: 0.0001  max mem: 15824
[15:28:40.510946] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1456 (0.1574)  time: 0.1800  data: 0.0001  max mem: 15824
[15:28:42.313636] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1525 (0.1580)  time: 0.1801  data: 0.0001  max mem: 15824
[15:28:44.121770] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1649 (0.1583)  time: 0.1805  data: 0.0001  max mem: 15824
[15:28:45.934603] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1647 (0.1588)  time: 0.1810  data: 0.0001  max mem: 15824
[15:28:47.749549] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1645 (0.1593)  time: 0.1813  data: 0.0001  max mem: 15824
[15:28:49.567929] Test:  [100/345]  eta: 0:00:45  loss: 0.1464 (0.1588)  time: 0.1816  data: 0.0001  max mem: 15824
[15:28:51.392151] Test:  [110/345]  eta: 0:00:43  loss: 0.1542 (0.1587)  time: 0.1821  data: 0.0001  max mem: 15824
[15:28:53.216849] Test:  [120/345]  eta: 0:00:41  loss: 0.1642 (0.1597)  time: 0.1824  data: 0.0001  max mem: 15824
[15:28:55.043592] Test:  [130/345]  eta: 0:00:39  loss: 0.1579 (0.1589)  time: 0.1825  data: 0.0001  max mem: 15824
[15:28:56.876021] Test:  [140/345]  eta: 0:00:37  loss: 0.1551 (0.1592)  time: 0.1829  data: 0.0001  max mem: 15824
[15:28:58.710069] Test:  [150/345]  eta: 0:00:35  loss: 0.1542 (0.1589)  time: 0.1833  data: 0.0001  max mem: 15824
[15:29:00.548991] Test:  [160/345]  eta: 0:00:34  loss: 0.1510 (0.1589)  time: 0.1836  data: 0.0001  max mem: 15824
[15:29:02.392605] Test:  [170/345]  eta: 0:00:32  loss: 0.1564 (0.1588)  time: 0.1841  data: 0.0001  max mem: 15824
[15:29:04.236872] Test:  [180/345]  eta: 0:00:30  loss: 0.1600 (0.1591)  time: 0.1843  data: 0.0001  max mem: 15824
[15:29:06.084901] Test:  [190/345]  eta: 0:00:28  loss: 0.1517 (0.1584)  time: 0.1846  data: 0.0001  max mem: 15824
[15:29:07.936976] Test:  [200/345]  eta: 0:00:26  loss: 0.1429 (0.1583)  time: 0.1849  data: 0.0001  max mem: 15824
[15:29:09.793509] Test:  [210/345]  eta: 0:00:24  loss: 0.1507 (0.1583)  time: 0.1854  data: 0.0001  max mem: 15824
[15:29:11.653683] Test:  [220/345]  eta: 0:00:23  loss: 0.1491 (0.1580)  time: 0.1858  data: 0.0001  max mem: 15824
[15:29:13.517680] Test:  [230/345]  eta: 0:00:21  loss: 0.1491 (0.1581)  time: 0.1862  data: 0.0001  max mem: 15824
[15:29:15.384465] Test:  [240/345]  eta: 0:00:19  loss: 0.1543 (0.1581)  time: 0.1865  data: 0.0001  max mem: 15824
[15:29:17.255144] Test:  [250/345]  eta: 0:00:17  loss: 0.1465 (0.1580)  time: 0.1868  data: 0.0001  max mem: 15824
[15:29:19.127393] Test:  [260/345]  eta: 0:00:15  loss: 0.1465 (0.1580)  time: 0.1871  data: 0.0001  max mem: 15824
[15:29:21.005857] Test:  [270/345]  eta: 0:00:13  loss: 0.1507 (0.1576)  time: 0.1875  data: 0.0001  max mem: 15824
[15:29:22.888445] Test:  [280/345]  eta: 0:00:12  loss: 0.1499 (0.1576)  time: 0.1880  data: 0.0001  max mem: 15824
[15:29:24.774246] Test:  [290/345]  eta: 0:00:10  loss: 0.1502 (0.1575)  time: 0.1884  data: 0.0001  max mem: 15824
[15:29:26.663046] Test:  [300/345]  eta: 0:00:08  loss: 0.1476 (0.1573)  time: 0.1887  data: 0.0001  max mem: 15824
[15:29:28.554233] Test:  [310/345]  eta: 0:00:06  loss: 0.1489 (0.1575)  time: 0.1889  data: 0.0001  max mem: 15824
[15:29:30.449025] Test:  [320/345]  eta: 0:00:04  loss: 0.1557 (0.1574)  time: 0.1892  data: 0.0001  max mem: 15824
[15:29:32.345672] Test:  [330/345]  eta: 0:00:02  loss: 0.1574 (0.1576)  time: 0.1895  data: 0.0001  max mem: 15824
[15:29:34.243716] Test:  [340/345]  eta: 0:00:00  loss: 0.1574 (0.1575)  time: 0.1897  data: 0.0001  max mem: 15824
[15:29:35.003641] Test:  [344/345]  eta: 0:00:00  loss: 0.1577 (0.1578)  time: 0.1897  data: 0.0001  max mem: 15824
[15:29:35.078638] Test: Total time: 0:01:04 (0.1859 s / it)
[15:29:45.620953] Test:  [ 0/57]  eta: 0:00:31  loss: 0.5072 (0.5072)  time: 0.5545  data: 0.3736  max mem: 15824
[15:29:47.393068] Test:  [10/57]  eta: 0:00:09  loss: 0.4712 (0.4764)  time: 0.2114  data: 0.0341  max mem: 15824
[15:29:49.170681] Test:  [20/57]  eta: 0:00:07  loss: 0.4517 (0.4498)  time: 0.1774  data: 0.0001  max mem: 15824
[15:29:50.952511] Test:  [30/57]  eta: 0:00:05  loss: 0.3020 (0.3909)  time: 0.1779  data: 0.0001  max mem: 15824
[15:29:52.737332] Test:  [40/57]  eta: 0:00:03  loss: 0.2728 (0.3675)  time: 0.1783  data: 0.0001  max mem: 15824
[15:29:54.523398] Test:  [50/57]  eta: 0:00:01  loss: 0.3129 (0.3698)  time: 0.1785  data: 0.0001  max mem: 15824
[15:29:55.498329] Test:  [56/57]  eta: 0:00:00  loss: 0.3815 (0.3845)  time: 0.1737  data: 0.0001  max mem: 15824
[15:29:55.562518] Test: Total time: 0:00:10 (0.1842 s / it)
[15:29:57.352902] Dice score of the network on the train images: 0.847409, val images: 0.775792
[15:29:57.353141] saving best_prec_model_0 @ epoch 30
[15:29:58.537879] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:29:59.526655] Epoch: [31]  [  0/345]  eta: 0:05:40  lr: 0.000088  loss: 0.1557 (0.1557)  time: 0.9878  data: 0.3672  max mem: 15824
[15:30:11.826335] Epoch: [31]  [ 20/345]  eta: 0:03:25  lr: 0.000088  loss: 0.1593 (0.1625)  time: 0.6149  data: 0.0001  max mem: 15824
[15:30:24.162837] Epoch: [31]  [ 40/345]  eta: 0:03:10  lr: 0.000087  loss: 0.1621 (0.1622)  time: 0.6168  data: 0.0001  max mem: 15824
[15:30:36.525168] Epoch: [31]  [ 60/345]  eta: 0:02:57  lr: 0.000087  loss: 0.1608 (0.1622)  time: 0.6181  data: 0.0001  max mem: 15824
[15:30:48.918923] Epoch: [31]  [ 80/345]  eta: 0:02:44  lr: 0.000087  loss: 0.1566 (0.1632)  time: 0.6196  data: 0.0001  max mem: 15824
[15:31:01.321164] Epoch: [31]  [100/345]  eta: 0:02:32  lr: 0.000086  loss: 0.1555 (0.1625)  time: 0.6201  data: 0.0001  max mem: 15824
[15:31:13.741861] Epoch: [31]  [120/345]  eta: 0:02:19  lr: 0.000086  loss: 0.1531 (0.1621)  time: 0.6210  data: 0.0001  max mem: 15824
[15:31:26.176957] Epoch: [31]  [140/345]  eta: 0:02:07  lr: 0.000085  loss: 0.1596 (0.1612)  time: 0.6217  data: 0.0001  max mem: 15824
[15:31:38.614667] Epoch: [31]  [160/345]  eta: 0:01:54  lr: 0.000085  loss: 0.1613 (0.1620)  time: 0.6218  data: 0.0001  max mem: 15824
[15:31:51.045233] Epoch: [31]  [180/345]  eta: 0:01:42  lr: 0.000085  loss: 0.1434 (0.1609)  time: 0.6215  data: 0.0001  max mem: 15824
[15:32:03.470169] Epoch: [31]  [200/345]  eta: 0:01:30  lr: 0.000084  loss: 0.1684 (0.1614)  time: 0.6212  data: 0.0001  max mem: 15824
[15:32:15.888605] Epoch: [31]  [220/345]  eta: 0:01:17  lr: 0.000084  loss: 0.1619 (0.1617)  time: 0.6209  data: 0.0001  max mem: 15824
[15:32:28.311160] Epoch: [31]  [240/345]  eta: 0:01:05  lr: 0.000084  loss: 0.1820 (0.1633)  time: 0.6211  data: 0.0001  max mem: 15824
[15:32:40.707442] Epoch: [31]  [260/345]  eta: 0:00:52  lr: 0.000083  loss: 0.1591 (0.1633)  time: 0.6198  data: 0.0001  max mem: 15824
[15:32:53.119523] Epoch: [31]  [280/345]  eta: 0:00:40  lr: 0.000083  loss: 0.1714 (0.1641)  time: 0.6206  data: 0.0001  max mem: 15824
[15:33:05.534121] Epoch: [31]  [300/345]  eta: 0:00:27  lr: 0.000083  loss: 0.1668 (0.1645)  time: 0.6207  data: 0.0001  max mem: 15824
[15:33:17.940420] Epoch: [31]  [320/345]  eta: 0:00:15  lr: 0.000082  loss: 0.1662 (0.1650)  time: 0.6203  data: 0.0001  max mem: 15824
[15:33:30.319162] Epoch: [31]  [340/345]  eta: 0:00:03  lr: 0.000082  loss: 0.1563 (0.1647)  time: 0.6189  data: 0.0001  max mem: 15824
[15:33:32.797647] Epoch: [31]  [344/345]  eta: 0:00:00  lr: 0.000082  loss: 0.1537 (0.1647)  time: 0.6187  data: 0.0001  max mem: 15824
[15:33:32.870223] Epoch: [31] Total time: 0:03:34 (0.6213 s / it)
[15:33:32.870598] Averaged stats: lr: 0.000082  loss: 0.1537 (0.1647)
[15:33:33.449623] Test:  [  0/345]  eta: 0:03:17  loss: 0.1613 (0.1613)  time: 0.5717  data: 0.3888  max mem: 15824
[15:33:35.236581] Test:  [ 10/345]  eta: 0:01:11  loss: 0.1477 (0.1479)  time: 0.2143  data: 0.0354  max mem: 15824
[15:33:37.030141] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1477 (0.1529)  time: 0.1790  data: 0.0001  max mem: 15824
[15:33:38.827549] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1591 (0.1571)  time: 0.1795  data: 0.0001  max mem: 15824
[15:33:40.627550] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1635 (0.1582)  time: 0.1798  data: 0.0001  max mem: 15824
[15:33:42.434198] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1640 (0.1605)  time: 0.1803  data: 0.0001  max mem: 15824
[15:33:44.238304] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1519 (0.1573)  time: 0.1805  data: 0.0001  max mem: 15824
[15:33:46.046552] Test:  [ 70/345]  eta: 0:00:50  loss: 0.1519 (0.1593)  time: 0.1806  data: 0.0001  max mem: 15824
[15:33:47.858135] Test:  [ 80/345]  eta: 0:00:48  loss: 0.1599 (0.1588)  time: 0.1809  data: 0.0001  max mem: 15824
[15:33:49.675541] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1552 (0.1586)  time: 0.1814  data: 0.0001  max mem: 15824
[15:33:51.496418] Test:  [100/345]  eta: 0:00:45  loss: 0.1578 (0.1589)  time: 0.1819  data: 0.0001  max mem: 15824
[15:33:53.318632] Test:  [110/345]  eta: 0:00:43  loss: 0.1514 (0.1589)  time: 0.1821  data: 0.0001  max mem: 15824
[15:33:55.141644] Test:  [120/345]  eta: 0:00:41  loss: 0.1515 (0.1591)  time: 0.1822  data: 0.0001  max mem: 15824
[15:33:56.972065] Test:  [130/345]  eta: 0:00:39  loss: 0.1547 (0.1585)  time: 0.1826  data: 0.0001  max mem: 15824
[15:33:58.807810] Test:  [140/345]  eta: 0:00:37  loss: 0.1508 (0.1579)  time: 0.1832  data: 0.0001  max mem: 15824
[15:34:00.645981] Test:  [150/345]  eta: 0:00:35  loss: 0.1504 (0.1579)  time: 0.1836  data: 0.0001  max mem: 15824
[15:34:02.484766] Test:  [160/345]  eta: 0:00:34  loss: 0.1560 (0.1584)  time: 0.1838  data: 0.0001  max mem: 15824
[15:34:04.327683] Test:  [170/345]  eta: 0:00:32  loss: 0.1573 (0.1585)  time: 0.1840  data: 0.0001  max mem: 15824
[15:34:06.176293] Test:  [180/345]  eta: 0:00:30  loss: 0.1630 (0.1593)  time: 0.1845  data: 0.0001  max mem: 15824
[15:34:08.028116] Test:  [190/345]  eta: 0:00:28  loss: 0.1597 (0.1590)  time: 0.1850  data: 0.0001  max mem: 15824
[15:34:09.882388] Test:  [200/345]  eta: 0:00:26  loss: 0.1542 (0.1590)  time: 0.1852  data: 0.0001  max mem: 15824
[15:34:11.739491] Test:  [210/345]  eta: 0:00:24  loss: 0.1569 (0.1588)  time: 0.1855  data: 0.0001  max mem: 15824
[15:34:13.600512] Test:  [220/345]  eta: 0:00:23  loss: 0.1598 (0.1591)  time: 0.1858  data: 0.0001  max mem: 15824
[15:34:15.464956] Test:  [230/345]  eta: 0:00:21  loss: 0.1507 (0.1584)  time: 0.1862  data: 0.0001  max mem: 15824
[15:34:17.332131] Test:  [240/345]  eta: 0:00:19  loss: 0.1437 (0.1583)  time: 0.1865  data: 0.0001  max mem: 15824
[15:34:19.202479] Test:  [250/345]  eta: 0:00:17  loss: 0.1500 (0.1582)  time: 0.1868  data: 0.0001  max mem: 15824
[15:34:21.077096] Test:  [260/345]  eta: 0:00:15  loss: 0.1539 (0.1580)  time: 0.1872  data: 0.0001  max mem: 15824
[15:34:22.955953] Test:  [270/345]  eta: 0:00:13  loss: 0.1514 (0.1580)  time: 0.1876  data: 0.0001  max mem: 15824
[15:34:24.838429] Test:  [280/345]  eta: 0:00:12  loss: 0.1573 (0.1582)  time: 0.1880  data: 0.0001  max mem: 15824
[15:34:26.722595] Test:  [290/345]  eta: 0:00:10  loss: 0.1631 (0.1584)  time: 0.1883  data: 0.0001  max mem: 15824
[15:34:28.615275] Test:  [300/345]  eta: 0:00:08  loss: 0.1646 (0.1587)  time: 0.1888  data: 0.0001  max mem: 15824
[15:34:30.507413] Test:  [310/345]  eta: 0:00:06  loss: 0.1593 (0.1585)  time: 0.1892  data: 0.0001  max mem: 15824
[15:34:32.405361] Test:  [320/345]  eta: 0:00:04  loss: 0.1572 (0.1586)  time: 0.1894  data: 0.0001  max mem: 15824
[15:34:34.304279] Test:  [330/345]  eta: 0:00:02  loss: 0.1647 (0.1590)  time: 0.1898  data: 0.0001  max mem: 15824
[15:34:36.203294] Test:  [340/345]  eta: 0:00:00  loss: 0.1595 (0.1588)  time: 0.1898  data: 0.0001  max mem: 15824
[15:34:36.965225] Test:  [344/345]  eta: 0:00:00  loss: 0.1646 (0.1589)  time: 0.1900  data: 0.0001  max mem: 15824
[15:34:37.042597] Test: Total time: 0:01:04 (0.1860 s / it)
[15:34:47.466644] Test:  [ 0/57]  eta: 0:00:34  loss: 0.4870 (0.4870)  time: 0.6116  data: 0.4319  max mem: 15824
[15:34:49.238057] Test:  [10/57]  eta: 0:00:10  loss: 0.4870 (0.4870)  time: 0.2166  data: 0.0393  max mem: 15824
[15:34:51.016852] Test:  [20/57]  eta: 0:00:07  loss: 0.4583 (0.4657)  time: 0.1774  data: 0.0001  max mem: 15824
[15:34:52.797596] Test:  [30/57]  eta: 0:00:05  loss: 0.3294 (0.4130)  time: 0.1779  data: 0.0001  max mem: 15824
[15:34:54.584028] Test:  [40/57]  eta: 0:00:03  loss: 0.3235 (0.3958)  time: 0.1783  data: 0.0001  max mem: 15824
[15:34:56.368910] Test:  [50/57]  eta: 0:00:01  loss: 0.3532 (0.3999)  time: 0.1785  data: 0.0001  max mem: 15824
[15:34:57.344086] Test:  [56/57]  eta: 0:00:00  loss: 0.4064 (0.4157)  time: 0.1738  data: 0.0000  max mem: 15824
[15:34:57.421409] Test: Total time: 0:00:10 (0.1854 s / it)
[15:34:59.155592] Dice score of the network on the train images: 0.858502, val images: 0.741444
[15:34:59.155803] saving best_prec_model_0 @ epoch 31
[15:35:00.353232] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:35:01.353684] Epoch: [32]  [  0/345]  eta: 0:05:44  lr: 0.000082  loss: 0.1462 (0.1462)  time: 0.9995  data: 0.3705  max mem: 15824
[15:35:13.675051] Epoch: [32]  [ 20/345]  eta: 0:03:26  lr: 0.000081  loss: 0.1519 (0.1542)  time: 0.6160  data: 0.0001  max mem: 15824
[15:35:26.044345] Epoch: [32]  [ 40/345]  eta: 0:03:11  lr: 0.000081  loss: 0.1547 (0.1552)  time: 0.6184  data: 0.0001  max mem: 15824
[15:35:38.420636] Epoch: [32]  [ 60/345]  eta: 0:02:57  lr: 0.000081  loss: 0.1559 (0.1554)  time: 0.6188  data: 0.0001  max mem: 15824
[15:35:50.799519] Epoch: [32]  [ 80/345]  eta: 0:02:45  lr: 0.000080  loss: 0.1585 (0.1580)  time: 0.6189  data: 0.0001  max mem: 15824
[15:36:03.194822] Epoch: [32]  [100/345]  eta: 0:02:32  lr: 0.000080  loss: 0.1567 (0.1585)  time: 0.6197  data: 0.0001  max mem: 15824
[15:36:15.614288] Epoch: [32]  [120/345]  eta: 0:02:19  lr: 0.000080  loss: 0.1545 (0.1588)  time: 0.6209  data: 0.0001  max mem: 15824
[15:36:28.028712] Epoch: [32]  [140/345]  eta: 0:02:07  lr: 0.000079  loss: 0.1534 (0.1586)  time: 0.6207  data: 0.0001  max mem: 15824
[15:36:40.428861] Epoch: [32]  [160/345]  eta: 0:01:54  lr: 0.000079  loss: 0.1550 (0.1586)  time: 0.6200  data: 0.0001  max mem: 15824
[15:36:52.840137] Epoch: [32]  [180/345]  eta: 0:01:42  lr: 0.000079  loss: 0.1641 (0.1588)  time: 0.6205  data: 0.0001  max mem: 15824
[15:37:05.255532] Epoch: [32]  [200/345]  eta: 0:01:30  lr: 0.000078  loss: 0.1675 (0.1596)  time: 0.6207  data: 0.0001  max mem: 15824
[15:37:17.681922] Epoch: [32]  [220/345]  eta: 0:01:17  lr: 0.000078  loss: 0.1577 (0.1594)  time: 0.6213  data: 0.0001  max mem: 15824
[15:37:30.092631] Epoch: [32]  [240/345]  eta: 0:01:05  lr: 0.000077  loss: 0.1534 (0.1592)  time: 0.6205  data: 0.0001  max mem: 15824
[15:37:42.501659] Epoch: [32]  [260/345]  eta: 0:00:52  lr: 0.000077  loss: 0.1613 (0.1594)  time: 0.6204  data: 0.0001  max mem: 15824
[15:37:54.899615] Epoch: [32]  [280/345]  eta: 0:00:40  lr: 0.000077  loss: 0.1529 (0.1591)  time: 0.6198  data: 0.0001  max mem: 15824
[15:38:07.299757] Epoch: [32]  [300/345]  eta: 0:00:27  lr: 0.000076  loss: 0.1540 (0.1590)  time: 0.6200  data: 0.0001  max mem: 15824
[15:38:19.693454] Epoch: [32]  [320/345]  eta: 0:00:15  lr: 0.000076  loss: 0.1512 (0.1588)  time: 0.6196  data: 0.0001  max mem: 15824
[15:38:32.085445] Epoch: [32]  [340/345]  eta: 0:00:03  lr: 0.000076  loss: 0.1594 (0.1587)  time: 0.6196  data: 0.0001  max mem: 15824
[15:38:34.566623] Epoch: [32]  [344/345]  eta: 0:00:00  lr: 0.000076  loss: 0.1594 (0.1587)  time: 0.6195  data: 0.0001  max mem: 15824
[15:38:34.631566] Epoch: [32] Total time: 0:03:34 (0.6211 s / it)
[15:38:34.632160] Averaged stats: lr: 0.000076  loss: 0.1594 (0.1587)
[15:38:35.265996] Test:  [  0/345]  eta: 0:03:36  loss: 0.1503 (0.1503)  time: 0.6284  data: 0.4466  max mem: 15824
[15:38:37.055668] Test:  [ 10/345]  eta: 0:01:13  loss: 0.1500 (0.1487)  time: 0.2197  data: 0.0407  max mem: 15824
[15:38:38.851345] Test:  [ 20/345]  eta: 0:01:05  loss: 0.1394 (0.1462)  time: 0.1792  data: 0.0001  max mem: 15824
[15:38:40.651241] Test:  [ 30/345]  eta: 0:01:01  loss: 0.1351 (0.1429)  time: 0.1797  data: 0.0001  max mem: 15824
[15:38:42.454132] Test:  [ 40/345]  eta: 0:00:58  loss: 0.1434 (0.1453)  time: 0.1801  data: 0.0001  max mem: 15824
[15:38:44.256377] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1531 (0.1454)  time: 0.1802  data: 0.0001  max mem: 15824
[15:38:46.060938] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1500 (0.1458)  time: 0.1803  data: 0.0001  max mem: 15824
[15:38:47.867021] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1500 (0.1483)  time: 0.1805  data: 0.0001  max mem: 15824
[15:38:49.680042] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1583 (0.1488)  time: 0.1809  data: 0.0001  max mem: 15824
[15:38:51.496350] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1487 (0.1498)  time: 0.1814  data: 0.0001  max mem: 15824
[15:38:53.317125] Test:  [100/345]  eta: 0:00:45  loss: 0.1475 (0.1499)  time: 0.1818  data: 0.0001  max mem: 15824
[15:38:55.138544] Test:  [110/345]  eta: 0:00:43  loss: 0.1518 (0.1511)  time: 0.1820  data: 0.0001  max mem: 15824
[15:38:56.962750] Test:  [120/345]  eta: 0:00:41  loss: 0.1475 (0.1506)  time: 0.1822  data: 0.0001  max mem: 15824
[15:38:58.789450] Test:  [130/345]  eta: 0:00:39  loss: 0.1475 (0.1509)  time: 0.1825  data: 0.0001  max mem: 15824
[15:39:00.620359] Test:  [140/345]  eta: 0:00:37  loss: 0.1586 (0.1508)  time: 0.1828  data: 0.0001  max mem: 15824
[15:39:02.457179] Test:  [150/345]  eta: 0:00:35  loss: 0.1500 (0.1513)  time: 0.1833  data: 0.0001  max mem: 15824
[15:39:04.300182] Test:  [160/345]  eta: 0:00:34  loss: 0.1500 (0.1515)  time: 0.1839  data: 0.0001  max mem: 15824
[15:39:06.145149] Test:  [170/345]  eta: 0:00:32  loss: 0.1428 (0.1511)  time: 0.1843  data: 0.0001  max mem: 15824
[15:39:07.993787] Test:  [180/345]  eta: 0:00:30  loss: 0.1409 (0.1512)  time: 0.1846  data: 0.0001  max mem: 15824
[15:39:09.845170] Test:  [190/345]  eta: 0:00:28  loss: 0.1444 (0.1513)  time: 0.1849  data: 0.0001  max mem: 15824
[15:39:11.700580] Test:  [200/345]  eta: 0:00:26  loss: 0.1438 (0.1509)  time: 0.1853  data: 0.0001  max mem: 15824
[15:39:13.560004] Test:  [210/345]  eta: 0:00:24  loss: 0.1387 (0.1506)  time: 0.1857  data: 0.0001  max mem: 15824
[15:39:15.420951] Test:  [220/345]  eta: 0:00:23  loss: 0.1432 (0.1505)  time: 0.1860  data: 0.0001  max mem: 15824
[15:39:17.285729] Test:  [230/345]  eta: 0:00:21  loss: 0.1469 (0.1504)  time: 0.1862  data: 0.0001  max mem: 15824
[15:39:19.152642] Test:  [240/345]  eta: 0:00:19  loss: 0.1506 (0.1506)  time: 0.1865  data: 0.0001  max mem: 15824
[15:39:21.025978] Test:  [250/345]  eta: 0:00:17  loss: 0.1506 (0.1504)  time: 0.1869  data: 0.0001  max mem: 15824
[15:39:22.901819] Test:  [260/345]  eta: 0:00:15  loss: 0.1409 (0.1502)  time: 0.1874  data: 0.0001  max mem: 15824
[15:39:24.779530] Test:  [270/345]  eta: 0:00:13  loss: 0.1369 (0.1499)  time: 0.1876  data: 0.0001  max mem: 15824
[15:39:26.661633] Test:  [280/345]  eta: 0:00:12  loss: 0.1411 (0.1501)  time: 0.1879  data: 0.0001  max mem: 15824
[15:39:28.546585] Test:  [290/345]  eta: 0:00:10  loss: 0.1437 (0.1500)  time: 0.1883  data: 0.0001  max mem: 15824
[15:39:30.436562] Test:  [300/345]  eta: 0:00:08  loss: 0.1497 (0.1500)  time: 0.1887  data: 0.0001  max mem: 15824
[15:39:32.329839] Test:  [310/345]  eta: 0:00:06  loss: 0.1385 (0.1497)  time: 0.1891  data: 0.0001  max mem: 15824
[15:39:34.227341] Test:  [320/345]  eta: 0:00:04  loss: 0.1385 (0.1497)  time: 0.1895  data: 0.0001  max mem: 15824
[15:39:36.128915] Test:  [330/345]  eta: 0:00:02  loss: 0.1476 (0.1499)  time: 0.1899  data: 0.0001  max mem: 15824
[15:39:38.028095] Test:  [340/345]  eta: 0:00:00  loss: 0.1467 (0.1498)  time: 0.1900  data: 0.0001  max mem: 15824
[15:39:38.788451] Test:  [344/345]  eta: 0:00:00  loss: 0.1476 (0.1498)  time: 0.1899  data: 0.0001  max mem: 15824
[15:39:38.862358] Test: Total time: 0:01:04 (0.1862 s / it)
[15:39:49.309537] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4889 (0.4889)  time: 0.5368  data: 0.3539  max mem: 15824
[15:39:51.084312] Test:  [10/57]  eta: 0:00:09  loss: 0.4656 (0.4706)  time: 0.2100  data: 0.0323  max mem: 15824
[15:39:52.861136] Test:  [20/57]  eta: 0:00:07  loss: 0.4474 (0.4514)  time: 0.1775  data: 0.0001  max mem: 15824
[15:39:54.643404] Test:  [30/57]  eta: 0:00:05  loss: 0.2832 (0.3914)  time: 0.1779  data: 0.0001  max mem: 15824
[15:39:56.428639] Test:  [40/57]  eta: 0:00:03  loss: 0.2740 (0.3684)  time: 0.1783  data: 0.0001  max mem: 15824
[15:39:58.216983] Test:  [50/57]  eta: 0:00:01  loss: 0.3184 (0.3705)  time: 0.1786  data: 0.0001  max mem: 15824
[15:39:59.188397] Test:  [56/57]  eta: 0:00:00  loss: 0.3775 (0.3866)  time: 0.1736  data: 0.0001  max mem: 15824
[15:39:59.262311] Test: Total time: 0:00:10 (0.1840 s / it)
[15:40:00.984594] Dice score of the network on the train images: 0.854484, val images: 0.770019
[15:40:00.988197] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:40:01.972912] Epoch: [33]  [  0/345]  eta: 0:05:39  lr: 0.000075  loss: 0.1824 (0.1824)  time: 0.9838  data: 0.3589  max mem: 15824
[15:40:14.299818] Epoch: [33]  [ 20/345]  eta: 0:03:25  lr: 0.000075  loss: 0.1449 (0.1505)  time: 0.6163  data: 0.0001  max mem: 15824
[15:40:26.627075] Epoch: [33]  [ 40/345]  eta: 0:03:10  lr: 0.000075  loss: 0.1527 (0.1534)  time: 0.6163  data: 0.0001  max mem: 15824
[15:40:38.985371] Epoch: [33]  [ 60/345]  eta: 0:02:57  lr: 0.000074  loss: 0.1504 (0.1538)  time: 0.6179  data: 0.0001  max mem: 15824
[15:40:51.385892] Epoch: [33]  [ 80/345]  eta: 0:02:44  lr: 0.000074  loss: 0.1556 (0.1549)  time: 0.6200  data: 0.0001  max mem: 15824
[15:41:03.919622] Epoch: [33]  [100/345]  eta: 0:02:32  lr: 0.000074  loss: 0.1547 (0.1560)  time: 0.6266  data: 0.0001  max mem: 15824
[15:41:16.352430] Epoch: [33]  [120/345]  eta: 0:02:20  lr: 0.000073  loss: 0.1516 (0.1564)  time: 0.6216  data: 0.0001  max mem: 15824
[15:41:28.788374] Epoch: [33]  [140/345]  eta: 0:02:07  lr: 0.000073  loss: 0.1529 (0.1562)  time: 0.6217  data: 0.0001  max mem: 15824
[15:41:41.234980] Epoch: [33]  [160/345]  eta: 0:01:55  lr: 0.000073  loss: 0.1523 (0.1562)  time: 0.6223  data: 0.0001  max mem: 15824
[15:41:53.649193] Epoch: [33]  [180/345]  eta: 0:01:42  lr: 0.000072  loss: 0.1456 (0.1560)  time: 0.6207  data: 0.0001  max mem: 15824
[15:42:06.070321] Epoch: [33]  [200/345]  eta: 0:01:30  lr: 0.000072  loss: 0.1554 (0.1557)  time: 0.6210  data: 0.0001  max mem: 15824
[15:42:18.509494] Epoch: [33]  [220/345]  eta: 0:01:17  lr: 0.000071  loss: 0.1561 (0.1561)  time: 0.6219  data: 0.0001  max mem: 15824
[15:42:30.921410] Epoch: [33]  [240/345]  eta: 0:01:05  lr: 0.000071  loss: 0.1566 (0.1564)  time: 0.6205  data: 0.0001  max mem: 15824
[15:42:43.330505] Epoch: [33]  [260/345]  eta: 0:00:52  lr: 0.000071  loss: 0.1400 (0.1558)  time: 0.6204  data: 0.0001  max mem: 15824
[15:42:55.726966] Epoch: [33]  [280/345]  eta: 0:00:40  lr: 0.000070  loss: 0.1484 (0.1553)  time: 0.6198  data: 0.0001  max mem: 15824
[15:43:08.139538] Epoch: [33]  [300/345]  eta: 0:00:27  lr: 0.000070  loss: 0.1480 (0.1551)  time: 0.6206  data: 0.0001  max mem: 15824
[15:43:20.535005] Epoch: [33]  [320/345]  eta: 0:00:15  lr: 0.000070  loss: 0.1502 (0.1551)  time: 0.6197  data: 0.0001  max mem: 15824
[15:43:33.014104] Epoch: [33]  [340/345]  eta: 0:00:03  lr: 0.000069  loss: 0.1426 (0.1548)  time: 0.6239  data: 0.0001  max mem: 15824
[15:43:35.492139] Epoch: [33]  [344/345]  eta: 0:00:00  lr: 0.000069  loss: 0.1449 (0.1547)  time: 0.6238  data: 0.0001  max mem: 15824
[15:43:35.566404] Epoch: [33] Total time: 0:03:34 (0.6220 s / it)
[15:43:35.566777] Averaged stats: lr: 0.000069  loss: 0.1449 (0.1547)
[15:43:36.148991] Test:  [  0/345]  eta: 0:03:18  loss: 0.1338 (0.1338)  time: 0.5752  data: 0.3926  max mem: 15824
[15:43:37.936331] Test:  [ 10/345]  eta: 0:01:11  loss: 0.1401 (0.1474)  time: 0.2147  data: 0.0358  max mem: 15824
[15:43:39.730481] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1467 (0.1485)  time: 0.1790  data: 0.0001  max mem: 15824
[15:43:41.524595] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1434 (0.1504)  time: 0.1794  data: 0.0001  max mem: 15824
[15:43:43.319784] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1375 (0.1518)  time: 0.1794  data: 0.0001  max mem: 15824
[15:43:45.120624] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1369 (0.1513)  time: 0.1797  data: 0.0001  max mem: 15824
[15:43:46.923337] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1386 (0.1501)  time: 0.1801  data: 0.0001  max mem: 15824
[15:43:48.731567] Test:  [ 70/345]  eta: 0:00:50  loss: 0.1390 (0.1500)  time: 0.1805  data: 0.0001  max mem: 15824
[15:43:50.540583] Test:  [ 80/345]  eta: 0:00:48  loss: 0.1390 (0.1491)  time: 0.1808  data: 0.0001  max mem: 15824
[15:43:52.355881] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1470 (0.1493)  time: 0.1812  data: 0.0001  max mem: 15824
[15:43:54.172446] Test:  [100/345]  eta: 0:00:45  loss: 0.1435 (0.1489)  time: 0.1815  data: 0.0001  max mem: 15824
[15:43:55.993098] Test:  [110/345]  eta: 0:00:43  loss: 0.1433 (0.1487)  time: 0.1818  data: 0.0001  max mem: 15824
[15:43:57.817194] Test:  [120/345]  eta: 0:00:41  loss: 0.1413 (0.1480)  time: 0.1822  data: 0.0001  max mem: 15824
[15:43:59.645019] Test:  [130/345]  eta: 0:00:39  loss: 0.1379 (0.1479)  time: 0.1825  data: 0.0001  max mem: 15824
[15:44:01.477744] Test:  [140/345]  eta: 0:00:37  loss: 0.1432 (0.1485)  time: 0.1830  data: 0.0001  max mem: 15824
[15:44:03.316022] Test:  [150/345]  eta: 0:00:35  loss: 0.1474 (0.1481)  time: 0.1835  data: 0.0001  max mem: 15824
[15:44:05.157269] Test:  [160/345]  eta: 0:00:33  loss: 0.1410 (0.1476)  time: 0.1839  data: 0.0001  max mem: 15824
[15:44:07.001139] Test:  [170/345]  eta: 0:00:32  loss: 0.1425 (0.1477)  time: 0.1842  data: 0.0001  max mem: 15824
[15:44:08.847056] Test:  [180/345]  eta: 0:00:30  loss: 0.1444 (0.1483)  time: 0.1844  data: 0.0001  max mem: 15824
[15:44:10.696310] Test:  [190/345]  eta: 0:00:28  loss: 0.1492 (0.1483)  time: 0.1847  data: 0.0001  max mem: 15824
[15:44:12.551922] Test:  [200/345]  eta: 0:00:26  loss: 0.1461 (0.1483)  time: 0.1852  data: 0.0001  max mem: 15824
[15:44:14.409888] Test:  [210/345]  eta: 0:00:24  loss: 0.1416 (0.1483)  time: 0.1856  data: 0.0001  max mem: 15824
[15:44:16.270391] Test:  [220/345]  eta: 0:00:23  loss: 0.1442 (0.1482)  time: 0.1859  data: 0.0001  max mem: 15824
[15:44:18.133932] Test:  [230/345]  eta: 0:00:21  loss: 0.1405 (0.1480)  time: 0.1861  data: 0.0001  max mem: 15824
[15:44:20.002028] Test:  [240/345]  eta: 0:00:19  loss: 0.1388 (0.1479)  time: 0.1865  data: 0.0001  max mem: 15824
[15:44:21.873854] Test:  [250/345]  eta: 0:00:17  loss: 0.1454 (0.1480)  time: 0.1869  data: 0.0001  max mem: 15824
[15:44:23.747482] Test:  [260/345]  eta: 0:00:15  loss: 0.1416 (0.1474)  time: 0.1872  data: 0.0001  max mem: 15824
[15:44:25.626595] Test:  [270/345]  eta: 0:00:13  loss: 0.1405 (0.1475)  time: 0.1876  data: 0.0001  max mem: 15824
[15:44:27.508309] Test:  [280/345]  eta: 0:00:12  loss: 0.1429 (0.1475)  time: 0.1880  data: 0.0001  max mem: 15824
[15:44:29.391327] Test:  [290/345]  eta: 0:00:10  loss: 0.1508 (0.1476)  time: 0.1882  data: 0.0001  max mem: 15824
[15:44:31.278816] Test:  [300/345]  eta: 0:00:08  loss: 0.1508 (0.1476)  time: 0.1885  data: 0.0001  max mem: 15824
[15:44:33.170519] Test:  [310/345]  eta: 0:00:06  loss: 0.1417 (0.1473)  time: 0.1889  data: 0.0001  max mem: 15824
[15:44:35.066610] Test:  [320/345]  eta: 0:00:04  loss: 0.1418 (0.1474)  time: 0.1893  data: 0.0001  max mem: 15824
[15:44:36.964680] Test:  [330/345]  eta: 0:00:02  loss: 0.1451 (0.1474)  time: 0.1896  data: 0.0001  max mem: 15824
[15:44:38.861501] Test:  [340/345]  eta: 0:00:00  loss: 0.1428 (0.1476)  time: 0.1897  data: 0.0001  max mem: 15824
[15:44:39.621529] Test:  [344/345]  eta: 0:00:00  loss: 0.1451 (0.1476)  time: 0.1898  data: 0.0001  max mem: 15824
[15:44:39.687092] Test: Total time: 0:01:04 (0.1858 s / it)
[15:44:50.191871] Test:  [ 0/57]  eta: 0:00:32  loss: 0.4740 (0.4740)  time: 0.5731  data: 0.3920  max mem: 15824
[15:44:51.967179] Test:  [10/57]  eta: 0:00:10  loss: 0.4622 (0.4598)  time: 0.2134  data: 0.0357  max mem: 15824
[15:44:53.744510] Test:  [20/57]  eta: 0:00:07  loss: 0.4345 (0.4464)  time: 0.1776  data: 0.0001  max mem: 15824
[15:44:55.524424] Test:  [30/57]  eta: 0:00:05  loss: 0.2953 (0.3936)  time: 0.1778  data: 0.0001  max mem: 15824
[15:44:57.310125] Test:  [40/57]  eta: 0:00:03  loss: 0.2953 (0.3755)  time: 0.1782  data: 0.0001  max mem: 15824
[15:44:59.098855] Test:  [50/57]  eta: 0:00:01  loss: 0.3344 (0.3799)  time: 0.1787  data: 0.0001  max mem: 15824
[15:45:00.070724] Test:  [56/57]  eta: 0:00:00  loss: 0.3814 (0.3962)  time: 0.1738  data: 0.0000  max mem: 15824
[15:45:00.137002] Test: Total time: 0:00:10 (0.1845 s / it)
[15:45:01.867906] Dice score of the network on the train images: 0.861927, val images: 0.754832
[15:45:01.872007] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:45:02.877005] Epoch: [34]  [  0/345]  eta: 0:05:46  lr: 0.000069  loss: 0.1747 (0.1747)  time: 1.0038  data: 0.3800  max mem: 15824
[15:45:15.210587] Epoch: [34]  [ 20/345]  eta: 0:03:26  lr: 0.000069  loss: 0.1557 (0.1584)  time: 0.6166  data: 0.0001  max mem: 15824
[15:45:27.565460] Epoch: [34]  [ 40/345]  eta: 0:03:11  lr: 0.000068  loss: 0.1607 (0.1592)  time: 0.6177  data: 0.0001  max mem: 15824
[15:45:39.957155] Epoch: [34]  [ 60/345]  eta: 0:02:57  lr: 0.000068  loss: 0.1372 (0.1557)  time: 0.6195  data: 0.0001  max mem: 15824
[15:45:52.364296] Epoch: [34]  [ 80/345]  eta: 0:02:45  lr: 0.000068  loss: 0.1432 (0.1537)  time: 0.6203  data: 0.0001  max mem: 15824
[15:46:04.741590] Epoch: [34]  [100/345]  eta: 0:02:32  lr: 0.000067  loss: 0.1445 (0.1529)  time: 0.6188  data: 0.0001  max mem: 15824
[15:46:17.138626] Epoch: [34]  [120/345]  eta: 0:02:19  lr: 0.000067  loss: 0.1548 (0.1539)  time: 0.6198  data: 0.0001  max mem: 15824
[15:46:29.534863] Epoch: [34]  [140/345]  eta: 0:02:07  lr: 0.000066  loss: 0.1554 (0.1542)  time: 0.6198  data: 0.0001  max mem: 15824
[15:46:41.927276] Epoch: [34]  [160/345]  eta: 0:01:54  lr: 0.000066  loss: 0.1503 (0.1546)  time: 0.6196  data: 0.0001  max mem: 15824
[15:46:54.324846] Epoch: [34]  [180/345]  eta: 0:01:42  lr: 0.000066  loss: 0.1483 (0.1541)  time: 0.6198  data: 0.0001  max mem: 15824
[15:47:06.718962] Epoch: [34]  [200/345]  eta: 0:01:30  lr: 0.000065  loss: 0.1401 (0.1532)  time: 0.6197  data: 0.0001  max mem: 15824
[15:47:19.098517] Epoch: [34]  [220/345]  eta: 0:01:17  lr: 0.000065  loss: 0.1601 (0.1539)  time: 0.6189  data: 0.0001  max mem: 15824
[15:47:31.499110] Epoch: [34]  [240/345]  eta: 0:01:05  lr: 0.000064  loss: 0.1480 (0.1536)  time: 0.6200  data: 0.0001  max mem: 15824
[15:47:43.905140] Epoch: [34]  [260/345]  eta: 0:00:52  lr: 0.000064  loss: 0.1482 (0.1529)  time: 0.6203  data: 0.0001  max mem: 15824
[15:47:56.275950] Epoch: [34]  [280/345]  eta: 0:00:40  lr: 0.000064  loss: 0.1401 (0.1527)  time: 0.6185  data: 0.0001  max mem: 15824
[15:48:08.637120] Epoch: [34]  [300/345]  eta: 0:00:27  lr: 0.000063  loss: 0.1342 (0.1519)  time: 0.6180  data: 0.0001  max mem: 15824
[15:48:21.010456] Epoch: [34]  [320/345]  eta: 0:00:15  lr: 0.000063  loss: 0.1464 (0.1517)  time: 0.6186  data: 0.0001  max mem: 15824
[15:48:33.372184] Epoch: [34]  [340/345]  eta: 0:00:03  lr: 0.000063  loss: 0.1533 (0.1516)  time: 0.6180  data: 0.0001  max mem: 15824
[15:48:35.844013] Epoch: [34]  [344/345]  eta: 0:00:00  lr: 0.000063  loss: 0.1509 (0.1515)  time: 0.6179  data: 0.0001  max mem: 15824
[15:48:35.917032] Epoch: [34] Total time: 0:03:34 (0.6204 s / it)
[15:48:35.917269] Averaged stats: lr: 0.000063  loss: 0.1509 (0.1515)
[15:48:36.496376] Test:  [  0/345]  eta: 0:03:17  loss: 0.1839 (0.1839)  time: 0.5735  data: 0.3914  max mem: 15824
[15:48:38.285554] Test:  [ 10/345]  eta: 0:01:11  loss: 0.1347 (0.1419)  time: 0.2147  data: 0.0357  max mem: 15824
[15:48:40.077185] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1314 (0.1410)  time: 0.1790  data: 0.0001  max mem: 15824
[15:48:41.877539] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1325 (0.1412)  time: 0.1795  data: 0.0001  max mem: 15824
[15:48:43.678424] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1417 (0.1435)  time: 0.1800  data: 0.0001  max mem: 15824
[15:48:45.481284] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1378 (0.1423)  time: 0.1801  data: 0.0001  max mem: 15824
[15:48:47.284470] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1293 (0.1412)  time: 0.1802  data: 0.0001  max mem: 15824
[15:48:49.093581] Test:  [ 70/345]  eta: 0:00:50  loss: 0.1315 (0.1409)  time: 0.1806  data: 0.0001  max mem: 15824
[15:48:50.905055] Test:  [ 80/345]  eta: 0:00:48  loss: 0.1355 (0.1403)  time: 0.1810  data: 0.0001  max mem: 15824
[15:48:52.720739] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1404 (0.1418)  time: 0.1813  data: 0.0001  max mem: 15824
[15:48:54.539500] Test:  [100/345]  eta: 0:00:45  loss: 0.1442 (0.1426)  time: 0.1817  data: 0.0001  max mem: 15824
[15:48:56.362478] Test:  [110/345]  eta: 0:00:43  loss: 0.1436 (0.1427)  time: 0.1820  data: 0.0001  max mem: 15824
[15:48:58.186878] Test:  [120/345]  eta: 0:00:41  loss: 0.1397 (0.1435)  time: 0.1823  data: 0.0001  max mem: 15824
[15:49:00.017194] Test:  [130/345]  eta: 0:00:39  loss: 0.1363 (0.1430)  time: 0.1827  data: 0.0001  max mem: 15824
[15:49:01.850941] Test:  [140/345]  eta: 0:00:37  loss: 0.1292 (0.1421)  time: 0.1831  data: 0.0001  max mem: 15824
[15:49:03.687711] Test:  [150/345]  eta: 0:00:35  loss: 0.1362 (0.1425)  time: 0.1835  data: 0.0001  max mem: 15824
[15:49:05.526648] Test:  [160/345]  eta: 0:00:34  loss: 0.1416 (0.1425)  time: 0.1837  data: 0.0001  max mem: 15824
[15:49:07.369601] Test:  [170/345]  eta: 0:00:32  loss: 0.1402 (0.1426)  time: 0.1840  data: 0.0001  max mem: 15824
[15:49:09.216870] Test:  [180/345]  eta: 0:00:30  loss: 0.1425 (0.1430)  time: 0.1844  data: 0.0001  max mem: 15824
[15:49:11.066424] Test:  [190/345]  eta: 0:00:28  loss: 0.1442 (0.1429)  time: 0.1848  data: 0.0001  max mem: 15824
[15:49:12.919241] Test:  [200/345]  eta: 0:00:26  loss: 0.1396 (0.1431)  time: 0.1851  data: 0.0001  max mem: 15824
[15:49:14.777036] Test:  [210/345]  eta: 0:00:24  loss: 0.1389 (0.1431)  time: 0.1855  data: 0.0001  max mem: 15824
[15:49:16.637547] Test:  [220/345]  eta: 0:00:23  loss: 0.1388 (0.1432)  time: 0.1859  data: 0.0001  max mem: 15824
[15:49:18.499831] Test:  [230/345]  eta: 0:00:21  loss: 0.1420 (0.1432)  time: 0.1861  data: 0.0001  max mem: 15824
[15:49:20.366876] Test:  [240/345]  eta: 0:00:19  loss: 0.1431 (0.1434)  time: 0.1864  data: 0.0001  max mem: 15824
[15:49:22.238744] Test:  [250/345]  eta: 0:00:17  loss: 0.1411 (0.1433)  time: 0.1869  data: 0.0001  max mem: 15824
[15:49:24.113304] Test:  [260/345]  eta: 0:00:15  loss: 0.1430 (0.1436)  time: 0.1873  data: 0.0001  max mem: 15824
[15:49:25.992513] Test:  [270/345]  eta: 0:00:13  loss: 0.1517 (0.1439)  time: 0.1876  data: 0.0001  max mem: 15824
[15:49:27.874112] Test:  [280/345]  eta: 0:00:12  loss: 0.1398 (0.1435)  time: 0.1880  data: 0.0001  max mem: 15824
[15:49:29.757561] Test:  [290/345]  eta: 0:00:10  loss: 0.1332 (0.1435)  time: 0.1882  data: 0.0001  max mem: 15824
[15:49:31.645499] Test:  [300/345]  eta: 0:00:08  loss: 0.1331 (0.1432)  time: 0.1885  data: 0.0001  max mem: 15824
[15:49:33.537962] Test:  [310/345]  eta: 0:00:06  loss: 0.1370 (0.1432)  time: 0.1890  data: 0.0001  max mem: 15824
[15:49:35.431884] Test:  [320/345]  eta: 0:00:04  loss: 0.1399 (0.1432)  time: 0.1893  data: 0.0001  max mem: 15824
[15:49:37.331841] Test:  [330/345]  eta: 0:00:02  loss: 0.1380 (0.1434)  time: 0.1896  data: 0.0001  max mem: 15824
[15:49:39.231475] Test:  [340/345]  eta: 0:00:00  loss: 0.1501 (0.1437)  time: 0.1899  data: 0.0001  max mem: 15824
[15:49:39.992856] Test:  [344/345]  eta: 0:00:00  loss: 0.1427 (0.1436)  time: 0.1900  data: 0.0001  max mem: 15824
[15:49:40.061172] Test: Total time: 0:01:04 (0.1859 s / it)
[15:49:50.509721] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4604 (0.4604)  time: 0.5338  data: 0.3536  max mem: 15824
[15:49:52.281000] Test:  [10/57]  eta: 0:00:09  loss: 0.4357 (0.4576)  time: 0.2095  data: 0.0322  max mem: 15824
[15:49:54.056661] Test:  [20/57]  eta: 0:00:07  loss: 0.4323 (0.4374)  time: 0.1773  data: 0.0001  max mem: 15824
[15:49:55.836374] Test:  [30/57]  eta: 0:00:05  loss: 0.2653 (0.3793)  time: 0.1777  data: 0.0001  max mem: 15824
[15:49:57.621238] Test:  [40/57]  eta: 0:00:03  loss: 0.2639 (0.3558)  time: 0.1782  data: 0.0001  max mem: 15824
[15:49:59.407513] Test:  [50/57]  eta: 0:00:01  loss: 0.2991 (0.3583)  time: 0.1785  data: 0.0001  max mem: 15824
[15:50:00.378129] Test:  [56/57]  eta: 0:00:00  loss: 0.3609 (0.3755)  time: 0.1734  data: 0.0000  max mem: 15824
[15:50:00.453069] Test: Total time: 0:00:10 (0.1838 s / it)
[15:50:02.188000] Dice score of the network on the train images: 0.856474, val images: 0.774707
[15:50:02.191573] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:50:03.176802] Epoch: [35]  [  0/345]  eta: 0:05:39  lr: 0.000063  loss: 0.1490 (0.1490)  time: 0.9843  data: 0.3614  max mem: 15824
[15:50:15.507874] Epoch: [35]  [ 20/345]  eta: 0:03:26  lr: 0.000062  loss: 0.1413 (0.1442)  time: 0.6165  data: 0.0001  max mem: 15824
[15:50:27.864282] Epoch: [35]  [ 40/345]  eta: 0:03:10  lr: 0.000062  loss: 0.1417 (0.1442)  time: 0.6178  data: 0.0001  max mem: 15824
[15:50:40.255981] Epoch: [35]  [ 60/345]  eta: 0:02:57  lr: 0.000061  loss: 0.1446 (0.1465)  time: 0.6195  data: 0.0001  max mem: 15824
[15:50:52.653475] Epoch: [35]  [ 80/345]  eta: 0:02:45  lr: 0.000061  loss: 0.1511 (0.1489)  time: 0.6198  data: 0.0001  max mem: 15824
[15:51:05.071327] Epoch: [35]  [100/345]  eta: 0:02:32  lr: 0.000061  loss: 0.1397 (0.1478)  time: 0.6208  data: 0.0001  max mem: 15824
[15:51:17.493119] Epoch: [35]  [120/345]  eta: 0:02:20  lr: 0.000060  loss: 0.1320 (0.1460)  time: 0.6210  data: 0.0001  max mem: 15824
[15:51:29.922482] Epoch: [35]  [140/345]  eta: 0:02:07  lr: 0.000060  loss: 0.1424 (0.1460)  time: 0.6214  data: 0.0001  max mem: 15824
[15:51:42.318725] Epoch: [35]  [160/345]  eta: 0:01:55  lr: 0.000059  loss: 0.1518 (0.1472)  time: 0.6198  data: 0.0001  max mem: 15824
[15:51:54.748628] Epoch: [35]  [180/345]  eta: 0:01:42  lr: 0.000059  loss: 0.1448 (0.1470)  time: 0.6215  data: 0.0001  max mem: 15824
[15:52:07.168524] Epoch: [35]  [200/345]  eta: 0:01:30  lr: 0.000059  loss: 0.1524 (0.1475)  time: 0.6209  data: 0.0001  max mem: 15824
[15:52:19.587514] Epoch: [35]  [220/345]  eta: 0:01:17  lr: 0.000058  loss: 0.1479 (0.1478)  time: 0.6209  data: 0.0001  max mem: 15824
[15:52:32.009350] Epoch: [35]  [240/345]  eta: 0:01:05  lr: 0.000058  loss: 0.1417 (0.1473)  time: 0.6210  data: 0.0001  max mem: 15824
[15:52:44.413417] Epoch: [35]  [260/345]  eta: 0:00:52  lr: 0.000058  loss: 0.1414 (0.1474)  time: 0.6202  data: 0.0001  max mem: 15824
[15:52:56.822182] Epoch: [35]  [280/345]  eta: 0:00:40  lr: 0.000057  loss: 0.1405 (0.1476)  time: 0.6204  data: 0.0001  max mem: 15824
[15:53:09.240075] Epoch: [35]  [300/345]  eta: 0:00:27  lr: 0.000057  loss: 0.1488 (0.1477)  time: 0.6208  data: 0.0001  max mem: 15824
[15:53:21.655544] Epoch: [35]  [320/345]  eta: 0:00:15  lr: 0.000056  loss: 0.1413 (0.1476)  time: 0.6207  data: 0.0001  max mem: 15824
[15:53:34.053425] Epoch: [35]  [340/345]  eta: 0:00:03  lr: 0.000056  loss: 0.1528 (0.1478)  time: 0.6199  data: 0.0001  max mem: 15824
[15:53:36.534325] Epoch: [35]  [344/345]  eta: 0:00:00  lr: 0.000056  loss: 0.1528 (0.1477)  time: 0.6196  data: 0.0001  max mem: 15824
[15:53:36.611985] Epoch: [35] Total time: 0:03:34 (0.6215 s / it)
[15:53:36.612580] Averaged stats: lr: 0.000056  loss: 0.1528 (0.1477)
[15:53:37.229217] Test:  [  0/345]  eta: 0:03:31  loss: 0.1406 (0.1406)  time: 0.6116  data: 0.4287  max mem: 15824
[15:53:39.017668] Test:  [ 10/345]  eta: 0:01:13  loss: 0.1406 (0.1400)  time: 0.2181  data: 0.0391  max mem: 15824
[15:53:40.810139] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1434 (0.1436)  time: 0.1790  data: 0.0001  max mem: 15824
[15:53:42.603124] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1399 (0.1412)  time: 0.1792  data: 0.0001  max mem: 15824
[15:53:44.402938] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1339 (0.1411)  time: 0.1796  data: 0.0001  max mem: 15824
[15:53:46.203621] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1332 (0.1408)  time: 0.1800  data: 0.0001  max mem: 15824
[15:53:48.005706] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1332 (0.1405)  time: 0.1801  data: 0.0001  max mem: 15824
[15:53:49.812386] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1344 (0.1402)  time: 0.1804  data: 0.0001  max mem: 15824
[15:53:51.624240] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1274 (0.1387)  time: 0.1809  data: 0.0001  max mem: 15824
[15:53:53.440015] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1340 (0.1396)  time: 0.1813  data: 0.0001  max mem: 15824
[15:53:55.258199] Test:  [100/345]  eta: 0:00:45  loss: 0.1428 (0.1393)  time: 0.1816  data: 0.0001  max mem: 15824
[15:53:57.080815] Test:  [110/345]  eta: 0:00:43  loss: 0.1305 (0.1388)  time: 0.1820  data: 0.0001  max mem: 15824
[15:53:58.906650] Test:  [120/345]  eta: 0:00:41  loss: 0.1322 (0.1390)  time: 0.1824  data: 0.0001  max mem: 15824
[15:54:00.734942] Test:  [130/345]  eta: 0:00:39  loss: 0.1382 (0.1389)  time: 0.1826  data: 0.0001  max mem: 15824
[15:54:02.567103] Test:  [140/345]  eta: 0:00:37  loss: 0.1416 (0.1396)  time: 0.1830  data: 0.0001  max mem: 15824
[15:54:04.401951] Test:  [150/345]  eta: 0:00:35  loss: 0.1418 (0.1394)  time: 0.1833  data: 0.0001  max mem: 15824
[15:54:06.242744] Test:  [160/345]  eta: 0:00:34  loss: 0.1313 (0.1391)  time: 0.1837  data: 0.0001  max mem: 15824
[15:54:08.086573] Test:  [170/345]  eta: 0:00:32  loss: 0.1393 (0.1392)  time: 0.1842  data: 0.0001  max mem: 15824
[15:54:09.932110] Test:  [180/345]  eta: 0:00:30  loss: 0.1410 (0.1394)  time: 0.1844  data: 0.0001  max mem: 15824
[15:54:11.782752] Test:  [190/345]  eta: 0:00:28  loss: 0.1285 (0.1391)  time: 0.1848  data: 0.0001  max mem: 15824
[15:54:13.636270] Test:  [200/345]  eta: 0:00:26  loss: 0.1379 (0.1395)  time: 0.1851  data: 0.0001  max mem: 15824
[15:54:15.492404] Test:  [210/345]  eta: 0:00:24  loss: 0.1441 (0.1395)  time: 0.1854  data: 0.0001  max mem: 15824
[15:54:17.351953] Test:  [220/345]  eta: 0:00:23  loss: 0.1441 (0.1396)  time: 0.1857  data: 0.0001  max mem: 15824
[15:54:19.215943] Test:  [230/345]  eta: 0:00:21  loss: 0.1357 (0.1393)  time: 0.1861  data: 0.0001  max mem: 15824
[15:54:21.083485] Test:  [240/345]  eta: 0:00:19  loss: 0.1272 (0.1388)  time: 0.1865  data: 0.0001  max mem: 15824
[15:54:22.955648] Test:  [250/345]  eta: 0:00:17  loss: 0.1257 (0.1384)  time: 0.1869  data: 0.0001  max mem: 15824
[15:54:24.831821] Test:  [260/345]  eta: 0:00:15  loss: 0.1321 (0.1386)  time: 0.1874  data: 0.0001  max mem: 15824
[15:54:26.709016] Test:  [270/345]  eta: 0:00:13  loss: 0.1363 (0.1387)  time: 0.1876  data: 0.0001  max mem: 15824
[15:54:28.592083] Test:  [280/345]  eta: 0:00:12  loss: 0.1363 (0.1386)  time: 0.1880  data: 0.0001  max mem: 15824
[15:54:30.479896] Test:  [290/345]  eta: 0:00:10  loss: 0.1436 (0.1388)  time: 0.1885  data: 0.0001  max mem: 15824
[15:54:32.369248] Test:  [300/345]  eta: 0:00:08  loss: 0.1477 (0.1393)  time: 0.1888  data: 0.0001  max mem: 15824
[15:54:34.261602] Test:  [310/345]  eta: 0:00:06  loss: 0.1484 (0.1394)  time: 0.1890  data: 0.0001  max mem: 15824
[15:54:36.155497] Test:  [320/345]  eta: 0:00:04  loss: 0.1349 (0.1394)  time: 0.1893  data: 0.0001  max mem: 15824
[15:54:38.055910] Test:  [330/345]  eta: 0:00:02  loss: 0.1285 (0.1392)  time: 0.1897  data: 0.0001  max mem: 15824
[15:54:39.956575] Test:  [340/345]  eta: 0:00:00  loss: 0.1341 (0.1393)  time: 0.1900  data: 0.0001  max mem: 15824
[15:54:40.718124] Test:  [344/345]  eta: 0:00:00  loss: 0.1339 (0.1393)  time: 0.1901  data: 0.0001  max mem: 15824
[15:54:40.775639] Test: Total time: 0:01:04 (0.1860 s / it)
[15:54:51.189569] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4678 (0.4678)  time: 0.5343  data: 0.3538  max mem: 15824
[15:54:52.963326] Test:  [10/57]  eta: 0:00:09  loss: 0.4564 (0.4692)  time: 0.2097  data: 0.0322  max mem: 15824
[15:54:54.742392] Test:  [20/57]  eta: 0:00:07  loss: 0.4480 (0.4547)  time: 0.1776  data: 0.0001  max mem: 15824
[15:54:56.521980] Test:  [30/57]  eta: 0:00:05  loss: 0.2889 (0.3952)  time: 0.1779  data: 0.0001  max mem: 15824
[15:54:58.307119] Test:  [40/57]  eta: 0:00:03  loss: 0.2752 (0.3723)  time: 0.1782  data: 0.0001  max mem: 15824
[15:55:00.092360] Test:  [50/57]  eta: 0:00:01  loss: 0.3095 (0.3741)  time: 0.1785  data: 0.0001  max mem: 15824
[15:55:01.063746] Test:  [56/57]  eta: 0:00:00  loss: 0.3723 (0.3911)  time: 0.1735  data: 0.0000  max mem: 15824
[15:55:01.134014] Test: Total time: 0:00:10 (0.1838 s / it)
[15:55:02.844138] Dice score of the network on the train images: 0.863706, val images: 0.766523
[15:55:02.848276] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[15:55:03.872079] Epoch: [36]  [  0/345]  eta: 0:05:52  lr: 0.000056  loss: 0.1658 (0.1658)  time: 1.0227  data: 0.3999  max mem: 15824
[15:55:16.198788] Epoch: [36]  [ 20/345]  eta: 0:03:26  lr: 0.000056  loss: 0.1324 (0.1403)  time: 0.6163  data: 0.0001  max mem: 15824
[15:55:28.577635] Epoch: [36]  [ 40/345]  eta: 0:03:11  lr: 0.000055  loss: 0.1413 (0.1411)  time: 0.6189  data: 0.0001  max mem: 15824
[15:55:40.976394] Epoch: [36]  [ 60/345]  eta: 0:02:58  lr: 0.000055  loss: 0.1419 (0.1420)  time: 0.6199  data: 0.0001  max mem: 15824
[15:55:53.375864] Epoch: [36]  [ 80/345]  eta: 0:02:45  lr: 0.000054  loss: 0.1420 (0.1437)  time: 0.6199  data: 0.0001  max mem: 15824
[15:56:05.790617] Epoch: [36]  [100/345]  eta: 0:02:32  lr: 0.000054  loss: 0.1427 (0.1445)  time: 0.6207  data: 0.0001  max mem: 15824
[15:56:18.214712] Epoch: [36]  [120/345]  eta: 0:02:20  lr: 0.000054  loss: 0.1387 (0.1443)  time: 0.6212  data: 0.0001  max mem: 15824
[15:56:30.640419] Epoch: [36]  [140/345]  eta: 0:02:07  lr: 0.000053  loss: 0.1369 (0.1433)  time: 0.6212  data: 0.0001  max mem: 15824
[15:56:43.059053] Epoch: [36]  [160/345]  eta: 0:01:55  lr: 0.000053  loss: 0.1374 (0.1434)  time: 0.6209  data: 0.0001  max mem: 15824
[15:56:55.481371] Epoch: [36]  [180/345]  eta: 0:01:42  lr: 0.000053  loss: 0.1535 (0.1446)  time: 0.6211  data: 0.0001  max mem: 15824
[15:57:07.908490] Epoch: [36]  [200/345]  eta: 0:01:30  lr: 0.000052  loss: 0.1417 (0.1445)  time: 0.6213  data: 0.0001  max mem: 15824
[15:57:20.420930] Epoch: [36]  [220/345]  eta: 0:01:17  lr: 0.000052  loss: 0.1371 (0.1441)  time: 0.6256  data: 0.0001  max mem: 15824
[15:57:32.817530] Epoch: [36]  [240/345]  eta: 0:01:05  lr: 0.000051  loss: 0.1482 (0.1442)  time: 0.6198  data: 0.0001  max mem: 15824
[15:57:45.212334] Epoch: [36]  [260/345]  eta: 0:00:52  lr: 0.000051  loss: 0.1466 (0.1446)  time: 0.6197  data: 0.0001  max mem: 15824
[15:57:57.588198] Epoch: [36]  [280/345]  eta: 0:00:40  lr: 0.000051  loss: 0.1491 (0.1449)  time: 0.6188  data: 0.0001  max mem: 15824
[15:58:09.965225] Epoch: [36]  [300/345]  eta: 0:00:27  lr: 0.000050  loss: 0.1379 (0.1444)  time: 0.6188  data: 0.0001  max mem: 15824
[15:58:22.348577] Epoch: [36]  [320/345]  eta: 0:00:15  lr: 0.000050  loss: 0.1444 (0.1447)  time: 0.6191  data: 0.0001  max mem: 15824

[15:58:34.717089] Epoch: [36]  [340/345]  eta: 0:00:03  lr: 0.000050  loss: 0.1488 (0.1446)  time: 0.6184  data: 0.0001  max mem: 15824
[15:58:37.191257] Epoch: [36]  [344/345]  eta: 0:00:00  lr: 0.000050  loss: 0.1497 (0.1448)  time: 0.6184  data: 0.0001  max mem: 15824
[15:58:37.263815] Epoch: [36] Total time: 0:03:34 (0.6215 s / it)
[15:58:37.264175] Averaged stats: lr: 0.000050  loss: 0.1497 (0.1448)
[15:58:37.854340] Test:  [  0/345]  eta: 0:03:21  loss: 0.1286 (0.1286)  time: 0.5846  data: 0.4006  max mem: 15824
[15:58:39.641223] Test:  [ 10/345]  eta: 0:01:12  loss: 0.1455 (0.1496)  time: 0.2155  data: 0.0365  max mem: 15824
[15:58:41.432704] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1433 (0.1438)  time: 0.1788  data: 0.0001  max mem: 15824
[15:58:43.225520] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1285 (0.1393)  time: 0.1792  data: 0.0001  max mem: 15824
[15:58:45.024386] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1263 (0.1408)  time: 0.1795  data: 0.0001  max mem: 15824
[15:58:46.825826] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1338 (0.1403)  time: 0.1799  data: 0.0001  max mem: 15824
[15:58:48.626874] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1310 (0.1392)  time: 0.1801  data: 0.0001  max mem: 15824
[15:58:50.431013] Test:  [ 70/345]  eta: 0:00:50  loss: 0.1313 (0.1389)  time: 0.1802  data: 0.0001  max mem: 15824
[15:58:52.244613] Test:  [ 80/345]  eta: 0:00:48  loss: 0.1313 (0.1380)  time: 0.1808  data: 0.0001  max mem: 15824
[15:58:54.059279] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1330 (0.1381)  time: 0.1814  data: 0.0001  max mem: 15824
[15:58:55.877129] Test:  [100/345]  eta: 0:00:45  loss: 0.1406 (0.1386)  time: 0.1816  data: 0.0001  max mem: 15824
[15:58:57.699056] Test:  [110/345]  eta: 0:00:43  loss: 0.1372 (0.1384)  time: 0.1819  data: 0.0001  max mem: 15824
[15:58:59.523956] Test:  [120/345]  eta: 0:00:41  loss: 0.1342 (0.1385)  time: 0.1823  data: 0.0001  max mem: 15824
[15:59:01.352453] Test:  [130/345]  eta: 0:00:39  loss: 0.1350 (0.1381)  time: 0.1826  data: 0.0001  max mem: 15824
[15:59:03.185001] Test:  [140/345]  eta: 0:00:37  loss: 0.1310 (0.1381)  time: 0.1830  data: 0.0001  max mem: 15824
[15:59:05.018614] Test:  [150/345]  eta: 0:00:35  loss: 0.1418 (0.1384)  time: 0.1833  data: 0.0001  max mem: 15824
[15:59:06.857135] Test:  [160/345]  eta: 0:00:33  loss: 0.1418 (0.1383)  time: 0.1835  data: 0.0001  max mem: 15824
[15:59:08.699227] Test:  [170/345]  eta: 0:00:32  loss: 0.1371 (0.1383)  time: 0.1840  data: 0.0001  max mem: 15824
[15:59:10.546366] Test:  [180/345]  eta: 0:00:30  loss: 0.1314 (0.1378)  time: 0.1844  data: 0.0001  max mem: 15824
[15:59:12.395765] Test:  [190/345]  eta: 0:00:28  loss: 0.1280 (0.1374)  time: 0.1848  data: 0.0001  max mem: 15824
[15:59:14.248859] Test:  [200/345]  eta: 0:00:26  loss: 0.1251 (0.1371)  time: 0.1851  data: 0.0001  max mem: 15824
[15:59:16.104808] Test:  [210/345]  eta: 0:00:24  loss: 0.1280 (0.1372)  time: 0.1854  data: 0.0001  max mem: 15824
[15:59:17.964598] Test:  [220/345]  eta: 0:00:23  loss: 0.1307 (0.1371)  time: 0.1857  data: 0.0001  max mem: 15824
[15:59:19.827414] Test:  [230/345]  eta: 0:00:21  loss: 0.1291 (0.1367)  time: 0.1861  data: 0.0001  max mem: 15824
[15:59:21.693793] Test:  [240/345]  eta: 0:00:19  loss: 0.1289 (0.1368)  time: 0.1864  data: 0.0001  max mem: 15824
[15:59:23.565733] Test:  [250/345]  eta: 0:00:17  loss: 0.1294 (0.1365)  time: 0.1868  data: 0.0001  max mem: 15824
[15:59:25.441028] Test:  [260/345]  eta: 0:00:15  loss: 0.1278 (0.1363)  time: 0.1873  data: 0.0001  max mem: 15824
[15:59:27.318853] Test:  [270/345]  eta: 0:00:13  loss: 0.1203 (0.1361)  time: 0.1876  data: 0.0001  max mem: 15824
[15:59:29.202619] Test:  [280/345]  eta: 0:00:12  loss: 0.1297 (0.1361)  time: 0.1880  data: 0.0001  max mem: 15824
[15:59:31.086173] Test:  [290/345]  eta: 0:00:10  loss: 0.1334 (0.1362)  time: 0.1883  data: 0.0001  max mem: 15824
[15:59:32.979173] Test:  [300/345]  eta: 0:00:08  loss: 0.1335 (0.1361)  time: 0.1888  data: 0.0001  max mem: 15824
[15:59:34.872148] Test:  [310/345]  eta: 0:00:06  loss: 0.1359 (0.1363)  time: 0.1892  data: 0.0001  max mem: 15824
[15:59:36.767199] Test:  [320/345]  eta: 0:00:04  loss: 0.1367 (0.1364)  time: 0.1893  data: 0.0001  max mem: 15824
[15:59:38.665735] Test:  [330/345]  eta: 0:00:02  loss: 0.1370 (0.1364)  time: 0.1896  data: 0.0001  max mem: 15824
[15:59:40.565144] Test:  [340/345]  eta: 0:00:00  loss: 0.1368 (0.1363)  time: 0.1898  data: 0.0001  max mem: 15824
[15:59:41.326250] Test:  [344/345]  eta: 0:00:00  loss: 0.1370 (0.1363)  time: 0.1899  data: 0.0001  max mem: 15824
[15:59:41.384876] Test: Total time: 0:01:04 (0.1858 s / it)
[15:59:51.839855] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4713 (0.4713)  time: 0.5464  data: 0.3667  max mem: 15824
[15:59:53.612371] Test:  [10/57]  eta: 0:00:09  loss: 0.4510 (0.4729)  time: 0.2107  data: 0.0334  max mem: 15824
[15:59:55.388437] Test:  [20/57]  eta: 0:00:07  loss: 0.4442 (0.4537)  time: 0.1774  data: 0.0001  max mem: 15824
[15:59:57.172776] Test:  [30/57]  eta: 0:00:05  loss: 0.2798 (0.3903)  time: 0.1780  data: 0.0001  max mem: 15824
[15:59:58.960280] Test:  [40/57]  eta: 0:00:03  loss: 0.2605 (0.3643)  time: 0.1785  data: 0.0001  max mem: 15824
[16:00:00.747988] Test:  [50/57]  eta: 0:00:01  loss: 0.2954 (0.3649)  time: 0.1787  data: 0.0001  max mem: 15824
[16:00:01.720387] Test:  [56/57]  eta: 0:00:00  loss: 0.3667 (0.3813)  time: 0.1737  data: 0.0001  max mem: 15824
[16:00:01.798151] Test: Total time: 0:00:10 (0.1843 s / it)
[16:00:03.536510] Dice score of the network on the train images: 0.861591, val images: 0.781797
[16:00:03.540555] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:00:04.544310] Epoch: [37]  [  0/345]  eta: 0:05:46  lr: 0.000050  loss: 0.1423 (0.1423)  time: 1.0030  data: 0.3779  max mem: 15824

[16:00:16.887525] Epoch: [37]  [ 20/345]  eta: 0:03:26  lr: 0.000049  loss: 0.1390 (0.1425)  time: 0.6171  data: 0.0001  max mem: 15824
[16:00:29.235883] Epoch: [37]  [ 40/345]  eta: 0:03:11  lr: 0.000049  loss: 0.1371 (0.1420)  time: 0.6174  data: 0.0001  max mem: 15824
[16:00:41.612861] Epoch: [37]  [ 60/345]  eta: 0:02:57  lr: 0.000048  loss: 0.1311 (0.1401)  time: 0.6188  data: 0.0001  max mem: 15824
[16:00:53.993474] Epoch: [37]  [ 80/345]  eta: 0:02:45  lr: 0.000048  loss: 0.1321 (0.1396)  time: 0.6190  data: 0.0001  max mem: 15824
[16:01:06.413059] Epoch: [37]  [100/345]  eta: 0:02:32  lr: 0.000048  loss: 0.1405 (0.1400)  time: 0.6209  data: 0.0001  max mem: 15824
[16:01:18.820434] Epoch: [37]  [120/345]  eta: 0:02:19  lr: 0.000047  loss: 0.1283 (0.1384)  time: 0.6203  data: 0.0001  max mem: 15824
[16:01:31.223499] Epoch: [37]  [140/345]  eta: 0:02:07  lr: 0.000047  loss: 0.1375 (0.1392)  time: 0.6201  data: 0.0001  max mem: 15824
[16:01:43.619645] Epoch: [37]  [160/345]  eta: 0:01:54  lr: 0.000047  loss: 0.1374 (0.1396)  time: 0.6198  data: 0.0001  max mem: 15824
[16:01:56.011394] Epoch: [37]  [180/345]  eta: 0:01:42  lr: 0.000046  loss: 0.1328 (0.1394)  time: 0.6195  data: 0.0001  max mem: 15824
[16:02:08.413933] Epoch: [37]  [200/345]  eta: 0:01:30  lr: 0.000046  loss: 0.1311 (0.1391)  time: 0.6201  data: 0.0001  max mem: 15824
[16:02:20.834564] Epoch: [37]  [220/345]  eta: 0:01:17  lr: 0.000045  loss: 0.1542 (0.1405)  time: 0.6210  data: 0.0001  max mem: 15824
[16:02:33.251108] Epoch: [37]  [240/345]  eta: 0:01:05  lr: 0.000045  loss: 0.1424 (0.1413)  time: 0.6208  data: 0.0001  max mem: 15824
[16:02:45.672679] Epoch: [37]  [260/345]  eta: 0:00:52  lr: 0.000045  loss: 0.1391 (0.1415)  time: 0.6210  data: 0.0001  max mem: 15824
[16:02:58.072187] Epoch: [37]  [280/345]  eta: 0:00:40  lr: 0.000044  loss: 0.1382 (0.1414)  time: 0.6199  data: 0.0001  max mem: 15824
[16:03:10.494226] Epoch: [37]  [300/345]  eta: 0:00:27  lr: 0.000044  loss: 0.1430 (0.1416)  time: 0.6210  data: 0.0001  max mem: 15824
[16:03:22.902785] Epoch: [37]  [320/345]  eta: 0:00:15  lr: 0.000044  loss: 0.1336 (0.1414)  time: 0.6204  data: 0.0001  max mem: 15824
[16:03:35.291464] Epoch: [37]  [340/345]  eta: 0:00:03  lr: 0.000043  loss: 0.1337 (0.1411)  time: 0.6194  data: 0.0001  max mem: 15824
[16:03:37.763636] Epoch: [37]  [344/345]  eta: 0:00:00  lr: 0.000043  loss: 0.1332 (0.1410)  time: 0.6191  data: 0.0001  max mem: 15824
[16:03:37.836529] Epoch: [37] Total time: 0:03:34 (0.6211 s / it)
[16:03:37.836765] Averaged stats: lr: 0.000043  loss: 0.1332 (0.1410)
[16:03:38.421027] Test:  [  0/345]  eta: 0:03:19  loss: 0.1195 (0.1195)  time: 0.5787  data: 0.3956  max mem: 15824
[16:03:40.212668] Test:  [ 10/345]  eta: 0:01:12  loss: 0.1223 (0.1263)  time: 0.2154  data: 0.0361  max mem: 15824
[16:03:42.005167] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1295 (0.1330)  time: 0.1791  data: 0.0001  max mem: 15824
[16:03:43.804693] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1353 (0.1352)  time: 0.1795  data: 0.0001  max mem: 15824
[16:03:45.605626] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1297 (0.1324)  time: 0.1800  data: 0.0001  max mem: 15824
[16:03:47.408536] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1283 (0.1350)  time: 0.1801  data: 0.0001  max mem: 15824
[16:03:49.213658] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1388 (0.1352)  time: 0.1803  data: 0.0001  max mem: 15824
[16:03:51.026317] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1379 (0.1356)  time: 0.1808  data: 0.0001  max mem: 15824
[16:03:52.837261] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1313 (0.1350)  time: 0.1811  data: 0.0001  max mem: 15824
[16:03:54.652848] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1309 (0.1348)  time: 0.1813  data: 0.0001  max mem: 15824
[16:03:56.475103] Test:  [100/345]  eta: 0:00:45  loss: 0.1308 (0.1345)  time: 0.1818  data: 0.0001  max mem: 15824
[16:03:58.299062] Test:  [110/345]  eta: 0:00:43  loss: 0.1217 (0.1343)  time: 0.1822  data: 0.0001  max mem: 15824
[16:04:00.125659] Test:  [120/345]  eta: 0:00:41  loss: 0.1319 (0.1355)  time: 0.1825  data: 0.0001  max mem: 15824
[16:04:01.956231] Test:  [130/345]  eta: 0:00:39  loss: 0.1339 (0.1359)  time: 0.1828  data: 0.0001  max mem: 15824
[16:04:03.791739] Test:  [140/345]  eta: 0:00:37  loss: 0.1269 (0.1354)  time: 0.1832  data: 0.0001  max mem: 15824
[16:04:05.630190] Test:  [150/345]  eta: 0:00:35  loss: 0.1300 (0.1354)  time: 0.1836  data: 0.0001  max mem: 15824
[16:04:07.472371] Test:  [160/345]  eta: 0:00:34  loss: 0.1287 (0.1347)  time: 0.1840  data: 0.0001  max mem: 15824
[16:04:09.319853] Test:  [170/345]  eta: 0:00:32  loss: 0.1221 (0.1345)  time: 0.1844  data: 0.0001  max mem: 15824
[16:04:11.170072] Test:  [180/345]  eta: 0:00:30  loss: 0.1373 (0.1350)  time: 0.1848  data: 0.0001  max mem: 15824
[16:04:13.022445] Test:  [190/345]  eta: 0:00:28  loss: 0.1366 (0.1353)  time: 0.1851  data: 0.0001  max mem: 15824
[16:04:14.877368] Test:  [200/345]  eta: 0:00:26  loss: 0.1290 (0.1350)  time: 0.1853  data: 0.0001  max mem: 15824
[16:04:16.733759] Test:  [210/345]  eta: 0:00:24  loss: 0.1288 (0.1349)  time: 0.1855  data: 0.0001  max mem: 15824
[16:04:18.597998] Test:  [220/345]  eta: 0:00:23  loss: 0.1288 (0.1348)  time: 0.1860  data: 0.0001  max mem: 15824
[16:04:20.465684] Test:  [230/345]  eta: 0:00:21  loss: 0.1265 (0.1345)  time: 0.1865  data: 0.0001  max mem: 15824
[16:04:22.333137] Test:  [240/345]  eta: 0:00:19  loss: 0.1286 (0.1344)  time: 0.1867  data: 0.0001  max mem: 15824
[16:04:24.204456] Test:  [250/345]  eta: 0:00:17  loss: 0.1286 (0.1347)  time: 0.1869  data: 0.0001  max mem: 15824
[16:04:26.082087] Test:  [260/345]  eta: 0:00:15  loss: 0.1283 (0.1345)  time: 0.1874  data: 0.0001  max mem: 15824
[16:04:27.959887] Test:  [270/345]  eta: 0:00:13  loss: 0.1305 (0.1346)  time: 0.1877  data: 0.0001  max mem: 15824
[16:04:29.841174] Test:  [280/345]  eta: 0:00:12  loss: 0.1347 (0.1344)  time: 0.1879  data: 0.0001  max mem: 15824
[16:04:31.727160] Test:  [290/345]  eta: 0:00:10  loss: 0.1295 (0.1342)  time: 0.1883  data: 0.0001  max mem: 15824
[16:04:33.616112] Test:  [300/345]  eta: 0:00:08  loss: 0.1295 (0.1341)  time: 0.1887  data: 0.0001  max mem: 15824
[16:04:35.509545] Test:  [310/345]  eta: 0:00:06  loss: 0.1294 (0.1338)  time: 0.1891  data: 0.0001  max mem: 15824
[16:04:37.407159] Test:  [320/345]  eta: 0:00:04  loss: 0.1214 (0.1336)  time: 0.1895  data: 0.0001  max mem: 15824
[16:04:39.308472] Test:  [330/345]  eta: 0:00:02  loss: 0.1219 (0.1335)  time: 0.1899  data: 0.0001  max mem: 15824
[16:04:41.209571] Test:  [340/345]  eta: 0:00:00  loss: 0.1252 (0.1335)  time: 0.1900  data: 0.0001  max mem: 15824
[16:04:41.970074] Test:  [344/345]  eta: 0:00:00  loss: 0.1270 (0.1335)  time: 0.1900  data: 0.0001  max mem: 15824
[16:04:42.036608] Test: Total time: 0:01:04 (0.1861 s / it)
[16:04:52.537448] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4795 (0.4795)  time: 0.5568  data: 0.3745  max mem: 15824
[16:04:54.311011] Test:  [10/57]  eta: 0:00:09  loss: 0.4702 (0.4753)  time: 0.2118  data: 0.0341  max mem: 15824
[16:04:56.087809] Test:  [20/57]  eta: 0:00:07  loss: 0.4597 (0.4595)  time: 0.1774  data: 0.0001  max mem: 15824
[16:04:57.867811] Test:  [30/57]  eta: 0:00:05  loss: 0.2924 (0.3985)  time: 0.1778  data: 0.0001  max mem: 15824
[16:04:59.652426] Test:  [40/57]  eta: 0:00:03  loss: 0.2765 (0.3759)  time: 0.1782  data: 0.0001  max mem: 15824
[16:05:01.439099] Test:  [50/57]  eta: 0:00:01  loss: 0.3217 (0.3782)  time: 0.1785  data: 0.0001  max mem: 15824
[16:05:02.413032] Test:  [56/57]  eta: 0:00:00  loss: 0.3896 (0.3972)  time: 0.1737  data: 0.0000  max mem: 15824
[16:05:02.478293] Test: Total time: 0:00:10 (0.1842 s / it)
[16:05:04.217932] Dice score of the network on the train images: 0.870911, val images: 0.766690
[16:05:04.222124] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:05:05.276596] Epoch: [38]  [  0/345]  eta: 0:06:03  lr: 0.000043  loss: 0.1391 (0.1391)  time: 1.0534  data: 0.4278  max mem: 15824
[16:05:17.602648] Epoch: [38]  [ 20/345]  eta: 0:03:27  lr: 0.000043  loss: 0.1342 (0.1399)  time: 0.6163  data: 0.0001  max mem: 15824
[16:05:29.980837] Epoch: [38]  [ 40/345]  eta: 0:03:11  lr: 0.000042  loss: 0.1270 (0.1350)  time: 0.6189  data: 0.0001  max mem: 15824
[16:05:42.385622] Epoch: [38]  [ 60/345]  eta: 0:02:58  lr: 0.000042  loss: 0.1357 (0.1375)  time: 0.6202  data: 0.0001  max mem: 15824
[16:05:54.800391] Epoch: [38]  [ 80/345]  eta: 0:02:45  lr: 0.000042  loss: 0.1467 (0.1390)  time: 0.6207  data: 0.0001  max mem: 15824
[16:06:07.230895] Epoch: [38]  [100/345]  eta: 0:02:32  lr: 0.000041  loss: 0.1389 (0.1388)  time: 0.6215  data: 0.0001  max mem: 15824
[16:06:19.663001] Epoch: [38]  [120/345]  eta: 0:02:20  lr: 0.000041  loss: 0.1283 (0.1388)  time: 0.6216  data: 0.0001  max mem: 15824
[16:06:32.112207] Epoch: [38]  [140/345]  eta: 0:02:07  lr: 0.000041  loss: 0.1404 (0.1388)  time: 0.6224  data: 0.0001  max mem: 15824
[16:06:44.560204] Epoch: [38]  [160/345]  eta: 0:01:55  lr: 0.000040  loss: 0.1339 (0.1389)  time: 0.6223  data: 0.0001  max mem: 15824
[16:06:57.001790] Epoch: [38]  [180/345]  eta: 0:01:42  lr: 0.000040  loss: 0.1294 (0.1383)  time: 0.6220  data: 0.0001  max mem: 15824
[16:07:09.429944] Epoch: [38]  [200/345]  eta: 0:01:30  lr: 0.000040  loss: 0.1410 (0.1388)  time: 0.6214  data: 0.0001  max mem: 15824
[16:07:21.841686] Epoch: [38]  [220/345]  eta: 0:01:17  lr: 0.000039  loss: 0.1377 (0.1391)  time: 0.6205  data: 0.0001  max mem: 15824
[16:07:34.286060] Epoch: [38]  [240/345]  eta: 0:01:05  lr: 0.000039  loss: 0.1334 (0.1391)  time: 0.6222  data: 0.0001  max mem: 15824
[16:07:46.710662] Epoch: [38]  [260/345]  eta: 0:00:52  lr: 0.000039  loss: 0.1375 (0.1392)  time: 0.6212  data: 0.0001  max mem: 15824
[16:07:59.112968] Epoch: [38]  [280/345]  eta: 0:00:40  lr: 0.000038  loss: 0.1409 (0.1393)  time: 0.6201  data: 0.0001  max mem: 15824
[16:08:11.535102] Epoch: [38]  [300/345]  eta: 0:00:28  lr: 0.000038  loss: 0.1286 (0.1392)  time: 0.6211  data: 0.0001  max mem: 15824
[16:08:23.957242] Epoch: [38]  [320/345]  eta: 0:00:15  lr: 0.000038  loss: 0.1364 (0.1390)  time: 0.6211  data: 0.0001  max mem: 15824
[16:08:36.342105] Epoch: [38]  [340/345]  eta: 0:00:03  lr: 0.000037  loss: 0.1344 (0.1389)  time: 0.6192  data: 0.0001  max mem: 15824
[16:08:38.817487] Epoch: [38]  [344/345]  eta: 0:00:00  lr: 0.000037  loss: 0.1344 (0.1389)  time: 0.6188  data: 0.0001  max mem: 15824
[16:08:38.888351] Epoch: [38] Total time: 0:03:34 (0.6222 s / it)
[16:08:38.888674] Averaged stats: lr: 0.000037  loss: 0.1344 (0.1389)
[16:08:39.533298] Test:  [  0/345]  eta: 0:03:40  loss: 0.1360 (0.1360)  time: 0.6392  data: 0.4578  max mem: 15824
[16:08:41.325973] Test:  [ 10/345]  eta: 0:01:14  loss: 0.1447 (0.1417)  time: 0.2210  data: 0.0417  max mem: 15824
[16:08:43.121048] Test:  [ 20/345]  eta: 0:01:05  loss: 0.1428 (0.1443)  time: 0.1793  data: 0.0001  max mem: 15824
[16:08:44.916326] Test:  [ 30/345]  eta: 0:01:01  loss: 0.1289 (0.1371)  time: 0.1795  data: 0.0001  max mem: 15824
[16:08:46.716863] Test:  [ 40/345]  eta: 0:00:58  loss: 0.1279 (0.1361)  time: 0.1797  data: 0.0001  max mem: 15824
[16:08:48.519667] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1325 (0.1354)  time: 0.1801  data: 0.0001  max mem: 15824
[16:08:50.328964] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1300 (0.1344)  time: 0.1805  data: 0.0001  max mem: 15824
[16:08:52.136479] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1300 (0.1353)  time: 0.1808  data: 0.0001  max mem: 15824
[16:08:53.949491] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1378 (0.1349)  time: 0.1810  data: 0.0001  max mem: 15824
[16:08:55.766091] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1358 (0.1354)  time: 0.1814  data: 0.0001  max mem: 15824
[16:08:57.586988] Test:  [100/345]  eta: 0:00:45  loss: 0.1347 (0.1347)  time: 0.1818  data: 0.0001  max mem: 15824
[16:08:59.408247] Test:  [110/345]  eta: 0:00:43  loss: 0.1273 (0.1342)  time: 0.1820  data: 0.0001  max mem: 15824
[16:09:01.235142] Test:  [120/345]  eta: 0:00:41  loss: 0.1273 (0.1341)  time: 0.1823  data: 0.0001  max mem: 15824
[16:09:03.066375] Test:  [130/345]  eta: 0:00:39  loss: 0.1249 (0.1330)  time: 0.1828  data: 0.0001  max mem: 15824
[16:09:04.900937] Test:  [140/345]  eta: 0:00:37  loss: 0.1220 (0.1326)  time: 0.1832  data: 0.0001  max mem: 15824
[16:09:06.735348] Test:  [150/345]  eta: 0:00:35  loss: 0.1317 (0.1331)  time: 0.1834  data: 0.0001  max mem: 15824
[16:09:08.577091] Test:  [160/345]  eta: 0:00:34  loss: 0.1278 (0.1327)  time: 0.1837  data: 0.0001  max mem: 15824
[16:09:10.422760] Test:  [170/345]  eta: 0:00:32  loss: 0.1254 (0.1327)  time: 0.1843  data: 0.0001  max mem: 15824
[16:09:12.271314] Test:  [180/345]  eta: 0:00:30  loss: 0.1376 (0.1330)  time: 0.1846  data: 0.0001  max mem: 15824
[16:09:14.121721] Test:  [190/345]  eta: 0:00:28  loss: 0.1422 (0.1333)  time: 0.1849  data: 0.0001  max mem: 15824
[16:09:15.976085] Test:  [200/345]  eta: 0:00:26  loss: 0.1299 (0.1331)  time: 0.1852  data: 0.0001  max mem: 15824
[16:09:17.834496] Test:  [210/345]  eta: 0:00:24  loss: 0.1333 (0.1337)  time: 0.1856  data: 0.0001  max mem: 15824
[16:09:19.696519] Test:  [220/345]  eta: 0:00:23  loss: 0.1276 (0.1331)  time: 0.1860  data: 0.0001  max mem: 15824
[16:09:21.560864] Test:  [230/345]  eta: 0:00:21  loss: 0.1253 (0.1329)  time: 0.1863  data: 0.0001  max mem: 15824
[16:09:23.429639] Test:  [240/345]  eta: 0:00:19  loss: 0.1253 (0.1326)  time: 0.1866  data: 0.0001  max mem: 15824
[16:09:25.302691] Test:  [250/345]  eta: 0:00:17  loss: 0.1239 (0.1323)  time: 0.1870  data: 0.0001  max mem: 15824
[16:09:27.178012] Test:  [260/345]  eta: 0:00:15  loss: 0.1285 (0.1323)  time: 0.1874  data: 0.0001  max mem: 15824
[16:09:29.057226] Test:  [270/345]  eta: 0:00:13  loss: 0.1307 (0.1322)  time: 0.1877  data: 0.0001  max mem: 15824
[16:09:30.939631] Test:  [280/345]  eta: 0:00:12  loss: 0.1295 (0.1322)  time: 0.1880  data: 0.0001  max mem: 15824
[16:09:32.825184] Test:  [290/345]  eta: 0:00:10  loss: 0.1236 (0.1321)  time: 0.1883  data: 0.0001  max mem: 15824
[16:09:34.712631] Test:  [300/345]  eta: 0:00:08  loss: 0.1236 (0.1319)  time: 0.1886  data: 0.0001  max mem: 15824
[16:09:36.605093] Test:  [310/345]  eta: 0:00:06  loss: 0.1267 (0.1321)  time: 0.1889  data: 0.0001  max mem: 15824
[16:09:38.500908] Test:  [320/345]  eta: 0:00:04  loss: 0.1297 (0.1321)  time: 0.1893  data: 0.0001  max mem: 15824
[16:09:40.401148] Test:  [330/345]  eta: 0:00:02  loss: 0.1218 (0.1319)  time: 0.1897  data: 0.0001  max mem: 15824
[16:09:42.300139] Test:  [340/345]  eta: 0:00:00  loss: 0.1220 (0.1317)  time: 0.1899  data: 0.0001  max mem: 15824
[16:09:43.060775] Test:  [344/345]  eta: 0:00:00  loss: 0.1220 (0.1316)  time: 0.1900  data: 0.0001  max mem: 15824
[16:09:43.116710] Test: Total time: 0:01:04 (0.1862 s / it)
[16:09:53.507258] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4731 (0.4731)  time: 0.5497  data: 0.3697  max mem: 15824
[16:09:55.282374] Test:  [10/57]  eta: 0:00:09  loss: 0.4513 (0.4691)  time: 0.2113  data: 0.0337  max mem: 15824
[16:09:57.059926] Test:  [20/57]  eta: 0:00:07  loss: 0.4459 (0.4487)  time: 0.1776  data: 0.0001  max mem: 15824
[16:09:58.841882] Test:  [30/57]  eta: 0:00:05  loss: 0.2883 (0.3870)  time: 0.1779  data: 0.0001  max mem: 15824
[16:10:00.629999] Test:  [40/57]  eta: 0:00:03  loss: 0.2650 (0.3619)  time: 0.1784  data: 0.0001  max mem: 15824
[16:10:02.418570] Test:  [50/57]  eta: 0:00:01  loss: 0.2998 (0.3633)  time: 0.1788  data: 0.0001  max mem: 15824
[16:10:03.389715] Test:  [56/57]  eta: 0:00:00  loss: 0.3792 (0.3823)  time: 0.1736  data: 0.0000  max mem: 15824
[16:10:03.459069] Test: Total time: 0:00:10 (0.1842 s / it)
[16:10:05.203633] Dice score of the network on the train images: 0.862148, val images: 0.774808
[16:10:05.207219] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:10:06.189014] Epoch: [39]  [  0/345]  eta: 0:05:38  lr: 0.000037  loss: 0.1280 (0.1280)  time: 0.9809  data: 0.3571  max mem: 15824
[16:10:18.508206] Epoch: [39]  [ 20/345]  eta: 0:03:25  lr: 0.000037  loss: 0.1279 (0.1358)  time: 0.6159  data: 0.0001  max mem: 15824
[16:10:30.894675] Epoch: [39]  [ 40/345]  eta: 0:03:11  lr: 0.000036  loss: 0.1420 (0.1395)  time: 0.6193  data: 0.0001  max mem: 15824
[16:10:43.287803] Epoch: [39]  [ 60/345]  eta: 0:02:57  lr: 0.000036  loss: 0.1362 (0.1397)  time: 0.6196  data: 0.0001  max mem: 15824
[16:10:55.705356] Epoch: [39]  [ 80/345]  eta: 0:02:45  lr: 0.000036  loss: 0.1270 (0.1373)  time: 0.6208  data: 0.0001  max mem: 15824
[16:11:08.112932] Epoch: [39]  [100/345]  eta: 0:02:32  lr: 0.000035  loss: 0.1330 (0.1365)  time: 0.6203  data: 0.0001  max mem: 15824
[16:11:20.559717] Epoch: [39]  [120/345]  eta: 0:02:20  lr: 0.000035  loss: 0.1410 (0.1370)  time: 0.6223  data: 0.0001  max mem: 15824
[16:11:33.002223] Epoch: [39]  [140/345]  eta: 0:02:07  lr: 0.000035  loss: 0.1246 (0.1364)  time: 0.6221  data: 0.0001  max mem: 15824
[16:11:45.442573] Epoch: [39]  [160/345]  eta: 0:01:55  lr: 0.000034  loss: 0.1365 (0.1368)  time: 0.6220  data: 0.0001  max mem: 15824
[16:11:57.864604] Epoch: [39]  [180/345]  eta: 0:01:42  lr: 0.000034  loss: 0.1312 (0.1373)  time: 0.6211  data: 0.0001  max mem: 15824
[16:12:10.299985] Epoch: [39]  [200/345]  eta: 0:01:30  lr: 0.000034  loss: 0.1395 (0.1374)  time: 0.6217  data: 0.0001  max mem: 15824
[16:12:22.741416] Epoch: [39]  [220/345]  eta: 0:01:17  lr: 0.000033  loss: 0.1296 (0.1371)  time: 0.6220  data: 0.0001  max mem: 15824
[16:12:35.167018] Epoch: [39]  [240/345]  eta: 0:01:05  lr: 0.000033  loss: 0.1260 (0.1365)  time: 0.6212  data: 0.0001  max mem: 15824
[16:12:47.581385] Epoch: [39]  [260/345]  eta: 0:00:52  lr: 0.000033  loss: 0.1329 (0.1365)  time: 0.6207  data: 0.0001  max mem: 15824
[16:12:59.997643] Epoch: [39]  [280/345]  eta: 0:00:40  lr: 0.000032  loss: 0.1321 (0.1363)  time: 0.6208  data: 0.0001  max mem: 15824
[16:13:12.403912] Epoch: [39]  [300/345]  eta: 0:00:27  lr: 0.000032  loss: 0.1258 (0.1360)  time: 0.6203  data: 0.0001  max mem: 15824
[16:13:24.830280] Epoch: [39]  [320/345]  eta: 0:00:15  lr: 0.000032  loss: 0.1411 (0.1359)  time: 0.6213  data: 0.0001  max mem: 15824
[16:13:37.225431] Epoch: [39]  [340/345]  eta: 0:00:03  lr: 0.000031  loss: 0.1313 (0.1355)  time: 0.6197  data: 0.0001  max mem: 15824
[16:13:39.703737] Epoch: [39]  [344/345]  eta: 0:00:00  lr: 0.000031  loss: 0.1363 (0.1357)  time: 0.6196  data: 0.0001  max mem: 15824
[16:13:39.779701] Epoch: [39] Total time: 0:03:34 (0.6219 s / it)
[16:13:39.779910] Averaged stats: lr: 0.000031  loss: 0.1363 (0.1357)
[16:13:40.378328] Test:  [  0/345]  eta: 0:03:24  loss: 0.1247 (0.1247)  time: 0.5932  data: 0.4106  max mem: 15824
[16:13:42.168918] Test:  [ 10/345]  eta: 0:01:12  loss: 0.1229 (0.1277)  time: 0.2166  data: 0.0374  max mem: 15824
[16:13:43.961772] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1304 (0.1338)  time: 0.1791  data: 0.0001  max mem: 15824
[16:13:45.757023] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1304 (0.1306)  time: 0.1793  data: 0.0001  max mem: 15824
[16:13:47.554152] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1157 (0.1279)  time: 0.1796  data: 0.0001  max mem: 15824
[16:13:49.353734] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1311 (0.1309)  time: 0.1798  data: 0.0001  max mem: 15824
[16:13:51.158038] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1314 (0.1298)  time: 0.1801  data: 0.0001  max mem: 15824
[16:13:52.967055] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1259 (0.1295)  time: 0.1806  data: 0.0001  max mem: 15824
[16:13:54.778242] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1223 (0.1286)  time: 0.1810  data: 0.0001  max mem: 15824
[16:13:56.594449] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1223 (0.1287)  time: 0.1813  data: 0.0001  max mem: 15824
[16:13:58.415290] Test:  [100/345]  eta: 0:00:45  loss: 0.1224 (0.1291)  time: 0.1818  data: 0.0001  max mem: 15824
[16:14:00.239180] Test:  [110/345]  eta: 0:00:43  loss: 0.1225 (0.1293)  time: 0.1822  data: 0.0001  max mem: 15824
[16:14:02.064998] Test:  [120/345]  eta: 0:00:41  loss: 0.1270 (0.1294)  time: 0.1824  data: 0.0001  max mem: 15824
[16:14:03.894613] Test:  [130/345]  eta: 0:00:39  loss: 0.1270 (0.1291)  time: 0.1827  data: 0.0001  max mem: 15824
[16:14:05.728381] Test:  [140/345]  eta: 0:00:37  loss: 0.1220 (0.1285)  time: 0.1831  data: 0.0001  max mem: 15824
[16:14:07.563192] Test:  [150/345]  eta: 0:00:35  loss: 0.1219 (0.1284)  time: 0.1834  data: 0.0001  max mem: 15824
[16:14:09.406162] Test:  [160/345]  eta: 0:00:34  loss: 0.1300 (0.1289)  time: 0.1838  data: 0.0001  max mem: 15824
[16:14:11.250669] Test:  [170/345]  eta: 0:00:32  loss: 0.1306 (0.1291)  time: 0.1843  data: 0.0001  max mem: 15824
[16:14:13.097475] Test:  [180/345]  eta: 0:00:30  loss: 0.1306 (0.1291)  time: 0.1845  data: 0.0001  max mem: 15824
[16:14:14.947623] Test:  [190/345]  eta: 0:00:28  loss: 0.1216 (0.1287)  time: 0.1848  data: 0.0001  max mem: 15824
[16:14:16.803907] Test:  [200/345]  eta: 0:00:26  loss: 0.1211 (0.1286)  time: 0.1853  data: 0.0001  max mem: 15824
[16:14:18.661870] Test:  [210/345]  eta: 0:00:24  loss: 0.1191 (0.1282)  time: 0.1857  data: 0.0001  max mem: 15824
[16:14:20.522752] Test:  [220/345]  eta: 0:00:23  loss: 0.1185 (0.1283)  time: 0.1859  data: 0.0001  max mem: 15824
[16:14:22.387676] Test:  [230/345]  eta: 0:00:21  loss: 0.1182 (0.1278)  time: 0.1862  data: 0.0001  max mem: 15824
[16:14:24.256852] Test:  [240/345]  eta: 0:00:19  loss: 0.1219 (0.1277)  time: 0.1866  data: 0.0001  max mem: 15824
[16:14:26.130089] Test:  [250/345]  eta: 0:00:17  loss: 0.1166 (0.1274)  time: 0.1870  data: 0.0001  max mem: 15824
[16:14:28.003608] Test:  [260/345]  eta: 0:00:15  loss: 0.1227 (0.1278)  time: 0.1873  data: 0.0001  max mem: 15824
[16:14:29.881426] Test:  [270/345]  eta: 0:00:13  loss: 0.1305 (0.1279)  time: 0.1875  data: 0.0001  max mem: 15824
[16:14:31.763123] Test:  [280/345]  eta: 0:00:12  loss: 0.1262 (0.1278)  time: 0.1879  data: 0.0001  max mem: 15824
[16:14:33.648462] Test:  [290/345]  eta: 0:00:10  loss: 0.1266 (0.1280)  time: 0.1883  data: 0.0001  max mem: 15824
[16:14:35.538952] Test:  [300/345]  eta: 0:00:08  loss: 0.1265 (0.1280)  time: 0.1887  data: 0.0001  max mem: 15824
[16:14:37.433889] Test:  [310/345]  eta: 0:00:06  loss: 0.1229 (0.1280)  time: 0.1892  data: 0.0001  max mem: 15824
[16:14:39.331074] Test:  [320/345]  eta: 0:00:04  loss: 0.1229 (0.1280)  time: 0.1895  data: 0.0001  max mem: 15824
[16:14:41.230805] Test:  [330/345]  eta: 0:00:02  loss: 0.1364 (0.1284)  time: 0.1898  data: 0.0001  max mem: 15824
[16:14:43.131607] Test:  [340/345]  eta: 0:00:00  loss: 0.1346 (0.1284)  time: 0.1900  data: 0.0001  max mem: 15824
[16:14:43.892790] Test:  [344/345]  eta: 0:00:00  loss: 0.1346 (0.1285)  time: 0.1900  data: 0.0001  max mem: 15824
[16:14:43.978388] Test: Total time: 0:01:04 (0.1861 s / it)
[16:14:54.515761] Test:  [ 0/57]  eta: 0:00:33  loss: 0.4737 (0.4737)  time: 0.5801  data: 0.3987  max mem: 15824
[16:14:56.287028] Test:  [10/57]  eta: 0:00:10  loss: 0.4518 (0.4699)  time: 0.2137  data: 0.0363  max mem: 15824
[16:14:58.064353] Test:  [20/57]  eta: 0:00:07  loss: 0.4467 (0.4515)  time: 0.1774  data: 0.0001  max mem: 15824
[16:14:59.844704] Test:  [30/57]  eta: 0:00:05  loss: 0.2865 (0.3917)  time: 0.1778  data: 0.0001  max mem: 15824
[16:15:01.629084] Test:  [40/57]  eta: 0:00:03  loss: 0.2675 (0.3695)  time: 0.1782  data: 0.0001  max mem: 15824
[16:15:03.416011] Test:  [50/57]  eta: 0:00:01  loss: 0.3164 (0.3713)  time: 0.1785  data: 0.0001  max mem: 15824
[16:15:04.386103] Test:  [56/57]  eta: 0:00:00  loss: 0.3796 (0.3897)  time: 0.1734  data: 0.0000  max mem: 15824
[16:15:04.457988] Test: Total time: 0:00:10 (0.1846 s / it)
[16:15:06.182142] Dice score of the network on the train images: 0.866248, val images: 0.770575
[16:15:06.186258] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:15:07.199373] Epoch: [40]  [  0/345]  eta: 0:05:49  lr: 0.000031  loss: 0.1507 (0.1507)  time: 1.0120  data: 0.3863  max mem: 15824
[16:15:19.513363] Epoch: [40]  [ 20/345]  eta: 0:03:26  lr: 0.000031  loss: 0.1325 (0.1336)  time: 0.6157  data: 0.0001  max mem: 15824
[16:15:31.867406] Epoch: [40]  [ 40/345]  eta: 0:03:11  lr: 0.000031  loss: 0.1379 (0.1362)  time: 0.6177  data: 0.0001  max mem: 15824
[16:15:44.269761] Epoch: [40]  [ 60/345]  eta: 0:02:57  lr: 0.000030  loss: 0.1298 (0.1366)  time: 0.6201  data: 0.0001  max mem: 15824
[16:15:56.686712] Epoch: [40]  [ 80/345]  eta: 0:02:45  lr: 0.000030  loss: 0.1253 (0.1345)  time: 0.6208  data: 0.0001  max mem: 15824
[16:16:09.112267] Epoch: [40]  [100/345]  eta: 0:02:32  lr: 0.000030  loss: 0.1281 (0.1336)  time: 0.6212  data: 0.0001  max mem: 15824
[16:16:21.546806] Epoch: [40]  [120/345]  eta: 0:02:20  lr: 0.000029  loss: 0.1272 (0.1333)  time: 0.6217  data: 0.0001  max mem: 15824
[16:16:33.973392] Epoch: [40]  [140/345]  eta: 0:02:07  lr: 0.000029  loss: 0.1327 (0.1332)  time: 0.6213  data: 0.0001  max mem: 15824
[16:16:46.406333] Epoch: [40]  [160/345]  eta: 0:01:55  lr: 0.000029  loss: 0.1273 (0.1328)  time: 0.6216  data: 0.0001  max mem: 15824
[16:16:58.845597] Epoch: [40]  [180/345]  eta: 0:01:42  lr: 0.000028  loss: 0.1313 (0.1330)  time: 0.6219  data: 0.0001  max mem: 15824
[16:17:11.292025] Epoch: [40]  [200/345]  eta: 0:01:30  lr: 0.000028  loss: 0.1302 (0.1329)  time: 0.6223  data: 0.0001  max mem: 15824
[16:17:23.717701] Epoch: [40]  [220/345]  eta: 0:01:17  lr: 0.000028  loss: 0.1316 (0.1334)  time: 0.6212  data: 0.0001  max mem: 15824
[16:17:36.154298] Epoch: [40]  [240/345]  eta: 0:01:05  lr: 0.000027  loss: 0.1269 (0.1332)  time: 0.6218  data: 0.0001  max mem: 15824
[16:17:48.583722] Epoch: [40]  [260/345]  eta: 0:00:52  lr: 0.000027  loss: 0.1320 (0.1333)  time: 0.6214  data: 0.0001  max mem: 15824
[16:18:01.002724] Epoch: [40]  [280/345]  eta: 0:00:40  lr: 0.000027  loss: 0.1308 (0.1331)  time: 0.6209  data: 0.0001  max mem: 15824
[16:18:13.394727] Epoch: [40]  [300/345]  eta: 0:00:27  lr: 0.000026  loss: 0.1281 (0.1329)  time: 0.6196  data: 0.0001  max mem: 15824
[16:18:25.805370] Epoch: [40]  [320/345]  eta: 0:00:15  lr: 0.000026  loss: 0.1291 (0.1328)  time: 0.6205  data: 0.0001  max mem: 15824
[16:18:38.201337] Epoch: [40]  [340/345]  eta: 0:00:03  lr: 0.000026  loss: 0.1299 (0.1330)  time: 0.6198  data: 0.0001  max mem: 15824
[16:18:40.678273] Epoch: [40]  [344/345]  eta: 0:00:00  lr: 0.000026  loss: 0.1247 (0.1328)  time: 0.6195  data: 0.0001  max mem: 15824
[16:18:40.755931] Epoch: [40] Total time: 0:03:34 (0.6219 s / it)
[16:18:40.756419] Averaged stats: lr: 0.000026  loss: 0.1247 (0.1328)
[16:18:41.335277] Test:  [  0/345]  eta: 0:03:17  loss: 0.1213 (0.1213)  time: 0.5736  data: 0.3926  max mem: 15824
[16:18:43.125510] Test:  [ 10/345]  eta: 0:01:11  loss: 0.1213 (0.1247)  time: 0.2148  data: 0.0358  max mem: 15824
[16:18:44.918436] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1219 (0.1265)  time: 0.1791  data: 0.0001  max mem: 15824
[16:18:46.715989] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1251 (0.1253)  time: 0.1794  data: 0.0001  max mem: 15824
[16:18:48.515153] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1168 (0.1241)  time: 0.1798  data: 0.0001  max mem: 15824
[16:18:50.318971] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1237 (0.1240)  time: 0.1801  data: 0.0001  max mem: 15824
[16:18:52.128602] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1235 (0.1237)  time: 0.1806  data: 0.0001  max mem: 15824
[16:18:53.937385] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1204 (0.1230)  time: 0.1809  data: 0.0001  max mem: 15824
[16:18:55.751551] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1200 (0.1247)  time: 0.1811  data: 0.0001  max mem: 15824
[16:18:57.567784] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1240 (0.1250)  time: 0.1815  data: 0.0001  max mem: 15824
[16:18:59.390744] Test:  [100/345]  eta: 0:00:45  loss: 0.1216 (0.1253)  time: 0.1819  data: 0.0001  max mem: 15824
[16:19:01.214785] Test:  [110/345]  eta: 0:00:43  loss: 0.1203 (0.1252)  time: 0.1823  data: 0.0001  max mem: 15824
[16:19:03.042672] Test:  [120/345]  eta: 0:00:41  loss: 0.1221 (0.1261)  time: 0.1825  data: 0.0001  max mem: 15824
[16:19:04.874706] Test:  [130/345]  eta: 0:00:39  loss: 0.1317 (0.1265)  time: 0.1829  data: 0.0001  max mem: 15824
[16:19:06.713454] Test:  [140/345]  eta: 0:00:37  loss: 0.1284 (0.1270)  time: 0.1835  data: 0.0001  max mem: 15824
[16:19:08.549653] Test:  [150/345]  eta: 0:00:35  loss: 0.1232 (0.1272)  time: 0.1837  data: 0.0001  max mem: 15824
[16:19:10.391110] Test:  [160/345]  eta: 0:00:34  loss: 0.1232 (0.1270)  time: 0.1838  data: 0.0001  max mem: 15824
[16:19:12.235284] Test:  [170/345]  eta: 0:00:32  loss: 0.1257 (0.1269)  time: 0.1842  data: 0.0001  max mem: 15824
[16:19:14.085252] Test:  [180/345]  eta: 0:00:30  loss: 0.1209 (0.1268)  time: 0.1846  data: 0.0001  max mem: 15824
[16:19:15.937765] Test:  [190/345]  eta: 0:00:28  loss: 0.1197 (0.1264)  time: 0.1850  data: 0.0001  max mem: 15824
[16:19:17.792351] Test:  [200/345]  eta: 0:00:26  loss: 0.1194 (0.1263)  time: 0.1853  data: 0.0001  max mem: 15824
[16:19:19.651532] Test:  [210/345]  eta: 0:00:24  loss: 0.1194 (0.1263)  time: 0.1856  data: 0.0001  max mem: 15824
[16:19:21.515057] Test:  [220/345]  eta: 0:00:23  loss: 0.1202 (0.1263)  time: 0.1861  data: 0.0001  max mem: 15824
[16:19:23.378161] Test:  [230/345]  eta: 0:00:21  loss: 0.1259 (0.1263)  time: 0.1863  data: 0.0001  max mem: 15824
[16:19:25.249048] Test:  [240/345]  eta: 0:00:19  loss: 0.1254 (0.1266)  time: 0.1866  data: 0.0001  max mem: 15824
[16:19:27.123835] Test:  [250/345]  eta: 0:00:17  loss: 0.1222 (0.1262)  time: 0.1872  data: 0.0001  max mem: 15824
[16:19:29.000277] Test:  [260/345]  eta: 0:00:15  loss: 0.1148 (0.1260)  time: 0.1875  data: 0.0001  max mem: 15824
[16:19:30.884600] Test:  [270/345]  eta: 0:00:13  loss: 0.1136 (0.1256)  time: 0.1880  data: 0.0001  max mem: 15824
[16:19:32.769023] Test:  [280/345]  eta: 0:00:12  loss: 0.1150 (0.1255)  time: 0.1884  data: 0.0001  max mem: 15824
[16:19:34.655665] Test:  [290/345]  eta: 0:00:10  loss: 0.1269 (0.1259)  time: 0.1885  data: 0.0001  max mem: 15824
[16:19:36.547820] Test:  [300/345]  eta: 0:00:08  loss: 0.1296 (0.1264)  time: 0.1889  data: 0.0001  max mem: 15824
[16:19:38.443988] Test:  [310/345]  eta: 0:00:06  loss: 0.1160 (0.1261)  time: 0.1894  data: 0.0001  max mem: 15824
[16:19:40.343691] Test:  [320/345]  eta: 0:00:04  loss: 0.1196 (0.1261)  time: 0.1897  data: 0.0001  max mem: 15824
[16:19:42.245596] Test:  [330/345]  eta: 0:00:02  loss: 0.1196 (0.1257)  time: 0.1900  data: 0.0001  max mem: 15824
[16:19:44.145747] Test:  [340/345]  eta: 0:00:00  loss: 0.1107 (0.1255)  time: 0.1900  data: 0.0001  max mem: 15824
[16:19:44.906850] Test:  [344/345]  eta: 0:00:00  loss: 0.1130 (0.1254)  time: 0.1901  data: 0.0001  max mem: 15824
[16:19:44.971003] Test: Total time: 0:01:04 (0.1861 s / it)
[16:19:55.496468] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4880 (0.4880)  time: 0.5614  data: 0.3797  max mem: 15824
[16:19:57.269638] Test:  [10/57]  eta: 0:00:09  loss: 0.4576 (0.4786)  time: 0.2121  data: 0.0346  max mem: 15824
[16:19:59.045545] Test:  [20/57]  eta: 0:00:07  loss: 0.4566 (0.4591)  time: 0.1774  data: 0.0001  max mem: 15824
[16:20:00.824961] Test:  [30/57]  eta: 0:00:05  loss: 0.2858 (0.3985)  time: 0.1777  data: 0.0001  max mem: 15824
[16:20:02.609053] Test:  [40/57]  eta: 0:00:03  loss: 0.2833 (0.3754)  time: 0.1781  data: 0.0001  max mem: 15824
[16:20:04.397986] Test:  [50/57]  eta: 0:00:01  loss: 0.3175 (0.3773)  time: 0.1786  data: 0.0001  max mem: 15824
[16:20:05.368895] Test:  [56/57]  eta: 0:00:00  loss: 0.3885 (0.3936)  time: 0.1736  data: 0.0000  max mem: 15824
[16:20:05.450308] Test: Total time: 0:00:10 (0.1845 s / it)
[16:20:07.205241] Dice score of the network on the train images: 0.871354, val images: 0.769364
[16:20:07.209400] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:20:08.250501] Epoch: [41]  [  0/345]  eta: 0:05:58  lr: 0.000026  loss: 0.1387 (0.1387)  time: 1.0400  data: 0.4158  max mem: 15824
[16:20:20.583670] Epoch: [41]  [ 20/345]  eta: 0:03:26  lr: 0.000025  loss: 0.1291 (0.1350)  time: 0.6166  data: 0.0001  max mem: 15824
[16:20:32.961967] Epoch: [41]  [ 40/345]  eta: 0:03:11  lr: 0.000025  loss: 0.1287 (0.1298)  time: 0.6189  data: 0.0001  max mem: 15824
[16:20:45.351797] Epoch: [41]  [ 60/345]  eta: 0:02:58  lr: 0.000025  loss: 0.1278 (0.1289)  time: 0.6194  data: 0.0001  max mem: 15824
[16:20:57.764921] Epoch: [41]  [ 80/345]  eta: 0:02:45  lr: 0.000025  loss: 0.1246 (0.1301)  time: 0.6206  data: 0.0001  max mem: 15824
[16:21:10.186004] Epoch: [41]  [100/345]  eta: 0:02:32  lr: 0.000024  loss: 0.1272 (0.1308)  time: 0.6210  data: 0.0001  max mem: 15824
[16:21:22.617867] Epoch: [41]  [120/345]  eta: 0:02:20  lr: 0.000024  loss: 0.1257 (0.1308)  time: 0.6215  data: 0.0001  max mem: 15824
[16:21:35.055556] Epoch: [41]  [140/345]  eta: 0:02:07  lr: 0.000024  loss: 0.1234 (0.1303)  time: 0.6218  data: 0.0001  max mem: 15824
[16:21:47.487285] Epoch: [41]  [160/345]  eta: 0:01:55  lr: 0.000023  loss: 0.1263 (0.1300)  time: 0.6215  data: 0.0001  max mem: 15824
[16:21:59.918042] Epoch: [41]  [180/345]  eta: 0:01:42  lr: 0.000023  loss: 0.1278 (0.1300)  time: 0.6215  data: 0.0001  max mem: 15824
[16:22:12.339399] Epoch: [41]  [200/345]  eta: 0:01:30  lr: 0.000023  loss: 0.1227 (0.1296)  time: 0.6210  data: 0.0001  max mem: 15824
[16:22:24.761740] Epoch: [41]  [220/345]  eta: 0:01:17  lr: 0.000022  loss: 0.1286 (0.1297)  time: 0.6211  data: 0.0001  max mem: 15824
[16:22:37.186881] Epoch: [41]  [240/345]  eta: 0:01:05  lr: 0.000022  loss: 0.1206 (0.1292)  time: 0.6212  data: 0.0001  max mem: 15824
[16:22:49.603015] Epoch: [41]  [260/345]  eta: 0:00:52  lr: 0.000022  loss: 0.1288 (0.1296)  time: 0.6208  data: 0.0001  max mem: 15824
[16:23:02.001368] Epoch: [41]  [280/345]  eta: 0:00:40  lr: 0.000022  loss: 0.1323 (0.1302)  time: 0.6199  data: 0.0001  max mem: 15824
[16:23:14.399230] Epoch: [41]  [300/345]  eta: 0:00:27  lr: 0.000021  loss: 0.1233 (0.1301)  time: 0.6198  data: 0.0001  max mem: 15824
[16:23:26.798840] Epoch: [41]  [320/345]  eta: 0:00:15  lr: 0.000021  loss: 0.1260 (0.1301)  time: 0.6199  data: 0.0001  max mem: 15824
[16:23:39.213445] Epoch: [41]  [340/345]  eta: 0:00:03  lr: 0.000021  loss: 0.1295 (0.1302)  time: 0.6207  data: 0.0001  max mem: 15824
[16:23:41.691538] Epoch: [41]  [344/345]  eta: 0:00:00  lr: 0.000021  loss: 0.1295 (0.1304)  time: 0.6202  data: 0.0001  max mem: 15824
[16:23:41.761579] Epoch: [41] Total time: 0:03:34 (0.6219 s / it)
[16:23:41.761799] Averaged stats: lr: 0.000021  loss: 0.1295 (0.1304)
[16:23:42.338744] Test:  [  0/345]  eta: 0:03:17  loss: 0.1297 (0.1297)  time: 0.5718  data: 0.3900  max mem: 15824
[16:23:44.131397] Test:  [ 10/345]  eta: 0:01:11  loss: 0.1256 (0.1270)  time: 0.2149  data: 0.0356  max mem: 15824
[16:23:45.925918] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1224 (0.1275)  time: 0.1793  data: 0.0001  max mem: 15824
[16:23:47.720856] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1241 (0.1299)  time: 0.1794  data: 0.0001  max mem: 15824
[16:23:49.519802] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1216 (0.1263)  time: 0.1796  data: 0.0001  max mem: 15824
[16:23:51.321022] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1141 (0.1251)  time: 0.1799  data: 0.0001  max mem: 15824
[16:23:53.127125] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1094 (0.1235)  time: 0.1803  data: 0.0001  max mem: 15824
[16:23:54.938153] Test:  [ 70/345]  eta: 0:00:50  loss: 0.1153 (0.1233)  time: 0.1808  data: 0.0001  max mem: 15824
[16:23:56.754736] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1194 (0.1229)  time: 0.1813  data: 0.0001  max mem: 15824
[16:23:58.571006] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1223 (0.1233)  time: 0.1816  data: 0.0001  max mem: 15824
[16:24:00.391214] Test:  [100/345]  eta: 0:00:45  loss: 0.1143 (0.1220)  time: 0.1818  data: 0.0001  max mem: 15824
[16:24:02.215517] Test:  [110/345]  eta: 0:00:43  loss: 0.1102 (0.1213)  time: 0.1822  data: 0.0001  max mem: 15824
[16:24:04.040517] Test:  [120/345]  eta: 0:00:41  loss: 0.1174 (0.1220)  time: 0.1824  data: 0.0001  max mem: 15824
[16:24:05.875409] Test:  [130/345]  eta: 0:00:39  loss: 0.1232 (0.1220)  time: 0.1829  data: 0.0001  max mem: 15824
[16:24:07.708670] Test:  [140/345]  eta: 0:00:37  loss: 0.1189 (0.1219)  time: 0.1833  data: 0.0001  max mem: 15824
[16:24:09.548293] Test:  [150/345]  eta: 0:00:35  loss: 0.1162 (0.1216)  time: 0.1836  data: 0.0001  max mem: 15824
[16:24:11.391790] Test:  [160/345]  eta: 0:00:34  loss: 0.1133 (0.1214)  time: 0.1841  data: 0.0001  max mem: 15824
[16:24:13.236072] Test:  [170/345]  eta: 0:00:32  loss: 0.1187 (0.1220)  time: 0.1843  data: 0.0001  max mem: 15824
[16:24:15.081917] Test:  [180/345]  eta: 0:00:30  loss: 0.1187 (0.1222)  time: 0.1844  data: 0.0001  max mem: 15824
[16:24:16.933045] Test:  [190/345]  eta: 0:00:28  loss: 0.1208 (0.1222)  time: 0.1848  data: 0.0001  max mem: 15824
[16:24:18.789453] Test:  [200/345]  eta: 0:00:26  loss: 0.1200 (0.1222)  time: 0.1853  data: 0.0001  max mem: 15824
[16:24:20.647105] Test:  [210/345]  eta: 0:00:24  loss: 0.1163 (0.1221)  time: 0.1856  data: 0.0001  max mem: 15824
[16:24:22.512772] Test:  [220/345]  eta: 0:00:23  loss: 0.1252 (0.1222)  time: 0.1861  data: 0.0001  max mem: 15824
[16:24:24.376558] Test:  [230/345]  eta: 0:00:21  loss: 0.1259 (0.1226)  time: 0.1864  data: 0.0001  max mem: 15824
[16:24:26.243866] Test:  [240/345]  eta: 0:00:19  loss: 0.1232 (0.1230)  time: 0.1865  data: 0.0001  max mem: 15824
[16:24:28.115732] Test:  [250/345]  eta: 0:00:17  loss: 0.1169 (0.1228)  time: 0.1869  data: 0.0001  max mem: 15824
[16:24:29.990017] Test:  [260/345]  eta: 0:00:15  loss: 0.1144 (0.1228)  time: 0.1873  data: 0.0001  max mem: 15824
[16:24:31.869510] Test:  [270/345]  eta: 0:00:13  loss: 0.1272 (0.1232)  time: 0.1876  data: 0.0001  max mem: 15824
[16:24:33.755553] Test:  [280/345]  eta: 0:00:12  loss: 0.1224 (0.1230)  time: 0.1882  data: 0.0001  max mem: 15824
[16:24:35.764894] Test:  [290/345]  eta: 0:00:10  loss: 0.1160 (0.1230)  time: 0.1947  data: 0.0001  max mem: 15824
[16:24:37.655727] Test:  [300/345]  eta: 0:00:08  loss: 0.1241 (0.1231)  time: 0.1949  data: 0.0001  max mem: 15824
[16:24:39.547093] Test:  [310/345]  eta: 0:00:06  loss: 0.1269 (0.1233)  time: 0.1890  data: 0.0001  max mem: 15824
[16:24:41.443847] Test:  [320/345]  eta: 0:00:04  loss: 0.1185 (0.1232)  time: 0.1893  data: 0.0001  max mem: 15824
[16:24:43.343394] Test:  [330/345]  eta: 0:00:02  loss: 0.1185 (0.1234)  time: 0.1898  data: 0.0001  max mem: 15824
[16:24:45.242882] Test:  [340/345]  eta: 0:00:00  loss: 0.1202 (0.1235)  time: 0.1899  data: 0.0001  max mem: 15824
[16:24:46.003122] Test:  [344/345]  eta: 0:00:00  loss: 0.1202 (0.1234)  time: 0.1899  data: 0.0001  max mem: 15824
[16:24:46.078642] Test: Total time: 0:01:04 (0.1864 s / it)
[16:24:56.639520] Test:  [ 0/57]  eta: 0:00:33  loss: 0.4824 (0.4824)  time: 0.5820  data: 0.4013  max mem: 15824
[16:24:58.413075] Test:  [10/57]  eta: 0:00:10  loss: 0.4526 (0.4767)  time: 0.2141  data: 0.0366  max mem: 15824
[16:25:00.192153] Test:  [20/57]  eta: 0:00:07  loss: 0.4501 (0.4572)  time: 0.1776  data: 0.0001  max mem: 15824
[16:25:01.973888] Test:  [30/57]  eta: 0:00:05  loss: 0.2902 (0.3973)  time: 0.1780  data: 0.0001  max mem: 15824
[16:25:03.760499] Test:  [40/57]  eta: 0:00:03  loss: 0.2758 (0.3747)  time: 0.1784  data: 0.0001  max mem: 15824
[16:25:05.547781] Test:  [50/57]  eta: 0:00:01  loss: 0.3170 (0.3758)  time: 0.1786  data: 0.0001  max mem: 15824
[16:25:06.520160] Test:  [56/57]  eta: 0:00:00  loss: 0.3849 (0.3935)  time: 0.1736  data: 0.0000  max mem: 15824
[16:25:06.592088] Test: Total time: 0:00:10 (0.1848 s / it)
[16:25:08.378016] Dice score of the network on the train images: 0.872598, val images: 0.768348
[16:25:08.381664] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:25:09.412658] Epoch: [42]  [  0/345]  eta: 0:05:55  lr: 0.000021  loss: 0.1637 (0.1637)  time: 1.0301  data: 0.4041  max mem: 15824
[16:25:21.764116] Epoch: [42]  [ 20/345]  eta: 0:03:27  lr: 0.000020  loss: 0.1275 (0.1334)  time: 0.6175  data: 0.0001  max mem: 15824
[16:25:34.155180] Epoch: [42]  [ 40/345]  eta: 0:03:11  lr: 0.000020  loss: 0.1255 (0.1308)  time: 0.6195  data: 0.0001  max mem: 15824
[16:25:46.561989] Epoch: [42]  [ 60/345]  eta: 0:02:58  lr: 0.000020  loss: 0.1233 (0.1311)  time: 0.6203  data: 0.0001  max mem: 15824
[16:25:58.984336] Epoch: [42]  [ 80/345]  eta: 0:02:45  lr: 0.000020  loss: 0.1222 (0.1297)  time: 0.6211  data: 0.0001  max mem: 15824
[16:26:11.428018] Epoch: [42]  [100/345]  eta: 0:02:32  lr: 0.000019  loss: 0.1246 (0.1290)  time: 0.6221  data: 0.0001  max mem: 15824
[16:26:23.880342] Epoch: [42]  [120/345]  eta: 0:02:20  lr: 0.000019  loss: 0.1237 (0.1288)  time: 0.6226  data: 0.0001  max mem: 15824
[16:26:36.329044] Epoch: [42]  [140/345]  eta: 0:02:07  lr: 0.000019  loss: 0.1249 (0.1281)  time: 0.6224  data: 0.0001  max mem: 15824

[16:26:48.780669] Epoch: [42]  [160/345]  eta: 0:01:55  lr: 0.000018  loss: 0.1343 (0.1290)  time: 0.6225  data: 0.0001  max mem: 15824
[16:27:01.227762] Epoch: [42]  [180/345]  eta: 0:01:42  lr: 0.000018  loss: 0.1180 (0.1286)  time: 0.6223  data: 0.0001  max mem: 15824
[16:27:13.657177] Epoch: [42]  [200/345]  eta: 0:01:30  lr: 0.000018  loss: 0.1247 (0.1289)  time: 0.6214  data: 0.0001  max mem: 15824
[16:27:26.089353] Epoch: [42]  [220/345]  eta: 0:01:17  lr: 0.000018  loss: 0.1248 (0.1292)  time: 0.6216  data: 0.0001  max mem: 15824
[16:27:38.521103] Epoch: [42]  [240/345]  eta: 0:01:05  lr: 0.000017  loss: 0.1159 (0.1287)  time: 0.6215  data: 0.0001  max mem: 15824
[16:27:50.953798] Epoch: [42]  [260/345]  eta: 0:00:52  lr: 0.000017  loss: 0.1244 (0.1290)  time: 0.6216  data: 0.0001  max mem: 15824
[16:28:03.396305] Epoch: [42]  [280/345]  eta: 0:00:40  lr: 0.000017  loss: 0.1210 (0.1285)  time: 0.6221  data: 0.0001  max mem: 15824
[16:28:15.830324] Epoch: [42]  [300/345]  eta: 0:00:28  lr: 0.000017  loss: 0.1289 (0.1287)  time: 0.6217  data: 0.0001  max mem: 15824
[16:28:28.266357] Epoch: [42]  [320/345]  eta: 0:00:15  lr: 0.000016  loss: 0.1248 (0.1288)  time: 0.6218  data: 0.0001  max mem: 15824
[16:28:40.677346] Epoch: [42]  [340/345]  eta: 0:00:03  lr: 0.000016  loss: 0.1244 (0.1286)  time: 0.6205  data: 0.0001  max mem: 15824
[16:28:43.156086] Epoch: [42]  [344/345]  eta: 0:00:00  lr: 0.000016  loss: 0.1244 (0.1287)  time: 0.6201  data: 0.0001  max mem: 15824
[16:28:43.232372] Epoch: [42] Total time: 0:03:34 (0.6228 s / it)
[16:28:43.232695] Averaged stats: lr: 0.000016  loss: 0.1244 (0.1287)
[16:28:43.801754] Test:  [  0/345]  eta: 0:03:14  loss: 0.1102 (0.1102)  time: 0.5635  data: 0.3809  max mem: 15824
[16:28:45.592184] Test:  [ 10/345]  eta: 0:01:11  loss: 0.1185 (0.1234)  time: 0.2139  data: 0.0347  max mem: 15824
[16:28:47.387062] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1185 (0.1206)  time: 0.1792  data: 0.0001  max mem: 15824
[16:28:49.183547] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1174 (0.1221)  time: 0.1795  data: 0.0001  max mem: 15824
[16:28:50.984044] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1174 (0.1212)  time: 0.1798  data: 0.0001  max mem: 15824
[16:28:52.786807] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1179 (0.1217)  time: 0.1801  data: 0.0001  max mem: 15824
[16:28:54.595989] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1144 (0.1199)  time: 0.1805  data: 0.0001  max mem: 15824
[16:28:56.404419] Test:  [ 70/345]  eta: 0:00:50  loss: 0.1149 (0.1204)  time: 0.1808  data: 0.0001  max mem: 15824
[16:28:58.219648] Test:  [ 80/345]  eta: 0:00:48  loss: 0.1186 (0.1209)  time: 0.1811  data: 0.0001  max mem: 15824
[16:29:00.038332] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1230 (0.1213)  time: 0.1816  data: 0.0001  max mem: 15824
[16:29:01.859480] Test:  [100/345]  eta: 0:00:45  loss: 0.1157 (0.1203)  time: 0.1819  data: 0.0001  max mem: 15824
[16:29:03.683280] Test:  [110/345]  eta: 0:00:43  loss: 0.1139 (0.1217)  time: 0.1822  data: 0.0001  max mem: 15824
[16:29:05.511439] Test:  [120/345]  eta: 0:00:41  loss: 0.1151 (0.1216)  time: 0.1825  data: 0.0001  max mem: 15824
[16:29:07.340323] Test:  [130/345]  eta: 0:00:39  loss: 0.1154 (0.1222)  time: 0.1828  data: 0.0001  max mem: 15824
[16:29:09.174546] Test:  [140/345]  eta: 0:00:37  loss: 0.1210 (0.1223)  time: 0.1831  data: 0.0001  max mem: 15824
[16:29:11.012122] Test:  [150/345]  eta: 0:00:35  loss: 0.1208 (0.1223)  time: 0.1835  data: 0.0001  max mem: 15824
[16:29:12.852487] Test:  [160/345]  eta: 0:00:34  loss: 0.1207 (0.1222)  time: 0.1838  data: 0.0001  max mem: 15824
[16:29:14.697642] Test:  [170/345]  eta: 0:00:32  loss: 0.1197 (0.1222)  time: 0.1842  data: 0.0001  max mem: 15824
[16:29:16.545047] Test:  [180/345]  eta: 0:00:30  loss: 0.1203 (0.1224)  time: 0.1846  data: 0.0001  max mem: 15824
[16:29:18.398217] Test:  [190/345]  eta: 0:00:28  loss: 0.1165 (0.1220)  time: 0.1850  data: 0.0001  max mem: 15824
[16:29:20.251842] Test:  [200/345]  eta: 0:00:26  loss: 0.1192 (0.1223)  time: 0.1853  data: 0.0001  max mem: 15824
[16:29:22.109995] Test:  [210/345]  eta: 0:00:24  loss: 0.1254 (0.1225)  time: 0.1855  data: 0.0001  max mem: 15824
[16:29:23.976432] Test:  [220/345]  eta: 0:00:23  loss: 0.1168 (0.1226)  time: 0.1862  data: 0.0001  max mem: 15824
[16:29:25.843249] Test:  [230/345]  eta: 0:00:21  loss: 0.1168 (0.1226)  time: 0.1866  data: 0.0001  max mem: 15824
[16:29:27.714681] Test:  [240/345]  eta: 0:00:19  loss: 0.1148 (0.1225)  time: 0.1869  data: 0.0001  max mem: 15824
[16:29:29.590217] Test:  [250/345]  eta: 0:00:17  loss: 0.1122 (0.1226)  time: 0.1873  data: 0.0001  max mem: 15824
[16:29:31.466824] Test:  [260/345]  eta: 0:00:15  loss: 0.1194 (0.1224)  time: 0.1875  data: 0.0001  max mem: 15824
[16:29:33.346800] Test:  [270/345]  eta: 0:00:13  loss: 0.1159 (0.1222)  time: 0.1878  data: 0.0001  max mem: 15824
[16:29:35.229983] Test:  [280/345]  eta: 0:00:12  loss: 0.1152 (0.1219)  time: 0.1881  data: 0.0001  max mem: 15824
[16:29:37.115589] Test:  [290/345]  eta: 0:00:10  loss: 0.1249 (0.1220)  time: 0.1884  data: 0.0001  max mem: 15824
[16:29:39.008698] Test:  [300/345]  eta: 0:00:08  loss: 0.1122 (0.1217)  time: 0.1889  data: 0.0001  max mem: 15824
[16:29:40.901912] Test:  [310/345]  eta: 0:00:06  loss: 0.1122 (0.1216)  time: 0.1893  data: 0.0001  max mem: 15824
[16:29:42.798604] Test:  [320/345]  eta: 0:00:04  loss: 0.1190 (0.1216)  time: 0.1894  data: 0.0001  max mem: 15824
[16:29:44.699036] Test:  [330/345]  eta: 0:00:02  loss: 0.1230 (0.1218)  time: 0.1898  data: 0.0001  max mem: 15824
[16:29:46.599675] Test:  [340/345]  eta: 0:00:00  loss: 0.1229 (0.1220)  time: 0.1900  data: 0.0001  max mem: 15824
[16:29:47.360805] Test:  [344/345]  eta: 0:00:00  loss: 0.1231 (0.1221)  time: 0.1901  data: 0.0001  max mem: 15824
[16:29:47.429978] Test: Total time: 0:01:04 (0.1861 s / it)
[16:29:57.894356] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4882 (0.4882)  time: 0.5380  data: 0.3572  max mem: 15824
[16:29:59.669808] Test:  [10/57]  eta: 0:00:09  loss: 0.4524 (0.4792)  time: 0.2102  data: 0.0326  max mem: 15824
[16:30:01.446334] Test:  [20/57]  eta: 0:00:07  loss: 0.4524 (0.4599)  time: 0.1775  data: 0.0001  max mem: 15824
[16:30:03.227968] Test:  [30/57]  eta: 0:00:05  loss: 0.2741 (0.3985)  time: 0.1778  data: 0.0001  max mem: 15824
[16:30:05.014823] Test:  [40/57]  eta: 0:00:03  loss: 0.2720 (0.3748)  time: 0.1784  data: 0.0001  max mem: 15824
[16:30:06.803732] Test:  [50/57]  eta: 0:00:01  loss: 0.3119 (0.3759)  time: 0.1787  data: 0.0001  max mem: 15824
[16:30:07.776069] Test:  [56/57]  eta: 0:00:00  loss: 0.3886 (0.3938)  time: 0.1737  data: 0.0001  max mem: 15824
[16:30:07.852686] Test: Total time: 0:00:10 (0.1842 s / it)
[16:30:09.602235] Dice score of the network on the train images: 0.873494, val images: 0.767594
[16:30:09.607347] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:30:10.596416] Epoch: [43]  [  0/345]  eta: 0:05:40  lr: 0.000016  loss: 0.0984 (0.0984)  time: 0.9879  data: 0.3600  max mem: 15824
[16:30:22.931800] Epoch: [43]  [ 20/345]  eta: 0:03:26  lr: 0.000016  loss: 0.1259 (0.1269)  time: 0.6167  data: 0.0001  max mem: 15824
[16:30:35.271365] Epoch: [43]  [ 40/345]  eta: 0:03:10  lr: 0.000016  loss: 0.1230 (0.1271)  time: 0.6169  data: 0.0001  max mem: 15824
[16:30:47.675503] Epoch: [43]  [ 60/345]  eta: 0:02:57  lr: 0.000015  loss: 0.1210 (0.1264)  time: 0.6202  data: 0.0001  max mem: 15824
[16:31:00.099062] Epoch: [43]  [ 80/345]  eta: 0:02:45  lr: 0.000015  loss: 0.1275 (0.1268)  time: 0.6211  data: 0.0001  max mem: 15824
[16:31:12.524546] Epoch: [43]  [100/345]  eta: 0:02:32  lr: 0.000015  loss: 0.1263 (0.1273)  time: 0.6212  data: 0.0001  max mem: 15824
[16:31:24.965786] Epoch: [43]  [120/345]  eta: 0:02:20  lr: 0.000015  loss: 0.1244 (0.1277)  time: 0.6220  data: 0.0001  max mem: 15824
[16:31:37.401842] Epoch: [43]  [140/345]  eta: 0:02:07  lr: 0.000014  loss: 0.1233 (0.1280)  time: 0.6217  data: 0.0001  max mem: 15824
[16:31:49.853935] Epoch: [43]  [160/345]  eta: 0:01:55  lr: 0.000014  loss: 0.1252 (0.1283)  time: 0.6226  data: 0.0001  max mem: 15824
[16:32:02.304323] Epoch: [43]  [180/345]  eta: 0:01:42  lr: 0.000014  loss: 0.1157 (0.1275)  time: 0.6225  data: 0.0001  max mem: 15824
[16:32:14.745912] Epoch: [43]  [200/345]  eta: 0:01:30  lr: 0.000014  loss: 0.1210 (0.1271)  time: 0.6220  data: 0.0001  max mem: 15824
[16:32:27.135515] Epoch: [43]  [220/345]  eta: 0:01:17  lr: 0.000013  loss: 0.1227 (0.1268)  time: 0.6194  data: 0.0001  max mem: 15824
[16:32:39.532759] Epoch: [43]  [240/345]  eta: 0:01:05  lr: 0.000013  loss: 0.1236 (0.1273)  time: 0.6198  data: 0.0001  max mem: 15824
[16:32:51.929623] Epoch: [43]  [260/345]  eta: 0:00:52  lr: 0.000013  loss: 0.1205 (0.1275)  time: 0.6198  data: 0.0001  max mem: 15824
[16:33:04.358932] Epoch: [43]  [280/345]  eta: 0:00:40  lr: 0.000013  loss: 0.1171 (0.1271)  time: 0.6214  data: 0.0001  max mem: 15824
[16:33:16.780568] Epoch: [43]  [300/345]  eta: 0:00:27  lr: 0.000012  loss: 0.1303 (0.1275)  time: 0.6210  data: 0.0001  max mem: 15824
[16:33:29.204575] Epoch: [43]  [320/345]  eta: 0:00:15  lr: 0.000012  loss: 0.1215 (0.1273)  time: 0.6212  data: 0.0001  max mem: 15824
[16:33:41.606516] Epoch: [43]  [340/345]  eta: 0:00:03  lr: 0.000012  loss: 0.1172 (0.1270)  time: 0.6200  data: 0.0001  max mem: 15824
[16:33:44.079443] Epoch: [43]  [344/345]  eta: 0:00:00  lr: 0.000012  loss: 0.1168 (0.1269)  time: 0.6192  data: 0.0001  max mem: 15824
[16:33:44.151744] Epoch: [43] Total time: 0:03:34 (0.6219 s / it)
[16:33:44.152114] Averaged stats: lr: 0.000012  loss: 0.1168 (0.1269)
[16:33:44.741886] Test:  [  0/345]  eta: 0:03:21  loss: 0.1115 (0.1115)  time: 0.5841  data: 0.4028  max mem: 15824
[16:33:46.531696] Test:  [ 10/345]  eta: 0:01:12  loss: 0.1199 (0.1181)  time: 0.2157  data: 0.0367  max mem: 15824
[16:33:48.322506] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1147 (0.1193)  time: 0.1789  data: 0.0001  max mem: 15824
[16:33:50.116923] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1147 (0.1211)  time: 0.1792  data: 0.0001  max mem: 15824
[16:33:51.917640] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1204 (0.1221)  time: 0.1797  data: 0.0001  max mem: 15824
[16:33:53.719605] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1204 (0.1216)  time: 0.1801  data: 0.0001  max mem: 15824
[16:33:55.523763] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1140 (0.1202)  time: 0.1802  data: 0.0001  max mem: 15824
[16:33:57.329583] Test:  [ 70/345]  eta: 0:00:50  loss: 0.1121 (0.1192)  time: 0.1804  data: 0.0001  max mem: 15824
[16:33:59.141530] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1152 (0.1201)  time: 0.1808  data: 0.0001  max mem: 15824
[16:34:00.955359] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1192 (0.1194)  time: 0.1812  data: 0.0001  max mem: 15824
[16:34:02.773976] Test:  [100/345]  eta: 0:00:45  loss: 0.1086 (0.1189)  time: 0.1816  data: 0.0001  max mem: 15824
[16:34:04.596009] Test:  [110/345]  eta: 0:00:43  loss: 0.1074 (0.1186)  time: 0.1820  data: 0.0001  max mem: 15824
[16:34:06.422641] Test:  [120/345]  eta: 0:00:41  loss: 0.1155 (0.1184)  time: 0.1824  data: 0.0001  max mem: 15824
[16:34:08.254403] Test:  [130/345]  eta: 0:00:39  loss: 0.1118 (0.1179)  time: 0.1829  data: 0.0001  max mem: 15824
[16:34:10.090082] Test:  [140/345]  eta: 0:00:37  loss: 0.1118 (0.1186)  time: 0.1833  data: 0.0001  max mem: 15824
[16:34:11.930957] Test:  [150/345]  eta: 0:00:35  loss: 0.1164 (0.1185)  time: 0.1838  data: 0.0001  max mem: 15824
[16:34:13.770648] Test:  [160/345]  eta: 0:00:34  loss: 0.1149 (0.1190)  time: 0.1840  data: 0.0001  max mem: 15824
[16:34:15.615180] Test:  [170/345]  eta: 0:00:32  loss: 0.1199 (0.1196)  time: 0.1842  data: 0.0001  max mem: 15824
[16:34:17.464942] Test:  [180/345]  eta: 0:00:30  loss: 0.1211 (0.1197)  time: 0.1847  data: 0.0001  max mem: 15824
[16:34:19.318968] Test:  [190/345]  eta: 0:00:28  loss: 0.1226 (0.1198)  time: 0.1851  data: 0.0001  max mem: 15824
[16:34:21.175095] Test:  [200/345]  eta: 0:00:26  loss: 0.1226 (0.1201)  time: 0.1854  data: 0.0001  max mem: 15824
[16:34:23.033160] Test:  [210/345]  eta: 0:00:24  loss: 0.1243 (0.1212)  time: 0.1857  data: 0.0001  max mem: 15824
[16:34:24.897455] Test:  [220/345]  eta: 0:00:23  loss: 0.1280 (0.1213)  time: 0.1861  data: 0.0001  max mem: 15824
[16:34:26.763275] Test:  [230/345]  eta: 0:00:21  loss: 0.1167 (0.1209)  time: 0.1864  data: 0.0001  max mem: 15824
[16:34:28.631513] Test:  [240/345]  eta: 0:00:19  loss: 0.1120 (0.1208)  time: 0.1866  data: 0.0001  max mem: 15824
[16:34:30.502435] Test:  [250/345]  eta: 0:00:17  loss: 0.1158 (0.1210)  time: 0.1869  data: 0.0001  max mem: 15824
[16:34:32.379655] Test:  [260/345]  eta: 0:00:15  loss: 0.1262 (0.1211)  time: 0.1873  data: 0.0001  max mem: 15824
[16:34:34.256751] Test:  [270/345]  eta: 0:00:13  loss: 0.1217 (0.1210)  time: 0.1877  data: 0.0001  max mem: 15824
[16:34:36.137588] Test:  [280/345]  eta: 0:00:12  loss: 0.1217 (0.1210)  time: 0.1878  data: 0.0001  max mem: 15824
[16:34:38.023132] Test:  [290/345]  eta: 0:00:10  loss: 0.1181 (0.1210)  time: 0.1883  data: 0.0001  max mem: 15824
[16:34:39.911622] Test:  [300/345]  eta: 0:00:08  loss: 0.1145 (0.1206)  time: 0.1886  data: 0.0001  max mem: 15824
[16:34:41.807052] Test:  [310/345]  eta: 0:00:06  loss: 0.1079 (0.1205)  time: 0.1891  data: 0.0001  max mem: 15824
[16:34:43.703653] Test:  [320/345]  eta: 0:00:04  loss: 0.1167 (0.1206)  time: 0.1895  data: 0.0001  max mem: 15824
[16:34:45.605701] Test:  [330/345]  eta: 0:00:02  loss: 0.1121 (0.1203)  time: 0.1899  data: 0.0001  max mem: 15824
[16:34:47.505857] Test:  [340/345]  eta: 0:00:00  loss: 0.1153 (0.1206)  time: 0.1901  data: 0.0001  max mem: 15824
[16:34:48.268760] Test:  [344/345]  eta: 0:00:00  loss: 0.1154 (0.1206)  time: 0.1902  data: 0.0001  max mem: 15824
[16:34:48.326952] Test: Total time: 0:01:04 (0.1860 s / it)
[16:34:58.803785] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4845 (0.4845)  time: 0.5347  data: 0.3531  max mem: 15824
[16:35:00.577593] Test:  [10/57]  eta: 0:00:09  loss: 0.4549 (0.4826)  time: 0.2098  data: 0.0322  max mem: 15824
[16:35:02.355078] Test:  [20/57]  eta: 0:00:07  loss: 0.4549 (0.4616)  time: 0.1775  data: 0.0001  max mem: 15824
[16:35:04.136266] Test:  [30/57]  eta: 0:00:05  loss: 0.2745 (0.3980)  time: 0.1779  data: 0.0001  max mem: 15824
[16:35:05.922422] Test:  [40/57]  eta: 0:00:03  loss: 0.2640 (0.3727)  time: 0.1783  data: 0.0001  max mem: 15824
[16:35:07.709070] Test:  [50/57]  eta: 0:00:01  loss: 0.3090 (0.3727)  time: 0.1786  data: 0.0001  max mem: 15824
[16:35:08.681471] Test:  [56/57]  eta: 0:00:00  loss: 0.3851 (0.3911)  time: 0.1736  data: 0.0000  max mem: 15824
[16:35:08.762019] Test: Total time: 0:00:10 (0.1841 s / it)
[16:35:10.501862] Dice score of the network on the train images: 0.871930, val images: 0.773282
[16:35:10.505871] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:35:11.579453] Epoch: [44]  [  0/345]  eta: 0:06:10  lr: 0.000012  loss: 0.1153 (0.1153)  time: 1.0725  data: 0.4473  max mem: 15824
[16:35:23.877704] Epoch: [44]  [ 20/345]  eta: 0:03:26  lr: 0.000012  loss: 0.1189 (0.1228)  time: 0.6149  data: 0.0001  max mem: 15824
[16:35:36.249732] Epoch: [44]  [ 40/345]  eta: 0:03:11  lr: 0.000011  loss: 0.1258 (0.1238)  time: 0.6186  data: 0.0001  max mem: 15824
[16:35:48.649509] Epoch: [44]  [ 60/345]  eta: 0:02:58  lr: 0.000011  loss: 0.1251 (0.1256)  time: 0.6199  data: 0.0001  max mem: 15824
[16:36:01.050662] Epoch: [44]  [ 80/345]  eta: 0:02:45  lr: 0.000011  loss: 0.1247 (0.1251)  time: 0.6200  data: 0.0001  max mem: 15824
[16:36:13.470105] Epoch: [44]  [100/345]  eta: 0:02:32  lr: 0.000011  loss: 0.1198 (0.1248)  time: 0.6209  data: 0.0001  max mem: 15824
[16:36:25.908955] Epoch: [44]  [120/345]  eta: 0:02:20  lr: 0.000011  loss: 0.1167 (0.1240)  time: 0.6219  data: 0.0001  max mem: 15824
[16:36:38.349337] Epoch: [44]  [140/345]  eta: 0:02:07  lr: 0.000010  loss: 0.1250 (0.1245)  time: 0.6220  data: 0.0001  max mem: 15824
[16:36:50.777421] Epoch: [44]  [160/345]  eta: 0:01:55  lr: 0.000010  loss: 0.1312 (0.1251)  time: 0.6214  data: 0.0001  max mem: 15824
[16:37:03.207370] Epoch: [44]  [180/345]  eta: 0:01:42  lr: 0.000010  loss: 0.1229 (0.1253)  time: 0.6215  data: 0.0001  max mem: 15824
[16:37:15.632807] Epoch: [44]  [200/345]  eta: 0:01:30  lr: 0.000010  loss: 0.1113 (0.1249)  time: 0.6212  data: 0.0001  max mem: 15824
[16:37:28.062132] Epoch: [44]  [220/345]  eta: 0:01:17  lr: 0.000010  loss: 0.1166 (0.1243)  time: 0.6214  data: 0.0001  max mem: 15824
[16:37:40.493253] Epoch: [44]  [240/345]  eta: 0:01:05  lr: 0.000009  loss: 0.1191 (0.1243)  time: 0.6215  data: 0.0001  max mem: 15824
[16:37:52.890077] Epoch: [44]  [260/345]  eta: 0:00:52  lr: 0.000009  loss: 0.1263 (0.1245)  time: 0.6198  data: 0.0001  max mem: 15824
[16:38:05.282732] Epoch: [44]  [280/345]  eta: 0:00:40  lr: 0.000009  loss: 0.1295 (0.1250)  time: 0.6196  data: 0.0001  max mem: 15824
[16:38:17.694097] Epoch: [44]  [300/345]  eta: 0:00:27  lr: 0.000009  loss: 0.1298 (0.1256)  time: 0.6205  data: 0.0001  max mem: 15824
[16:38:30.095012] Epoch: [44]  [320/345]  eta: 0:00:15  lr: 0.000009  loss: 0.1147 (0.1254)  time: 0.6200  data: 0.0001  max mem: 15824
[16:38:42.495788] Epoch: [44]  [340/345]  eta: 0:00:03  lr: 0.000008  loss: 0.1171 (0.1251)  time: 0.6200  data: 0.0001  max mem: 15824
[16:38:44.974368] Epoch: [44]  [344/345]  eta: 0:00:00  lr: 0.000008  loss: 0.1236 (0.1253)  time: 0.6199  data: 0.0001  max mem: 15824
[16:38:45.046914] Epoch: [44] Total time: 0:03:34 (0.6219 s / it)
[16:38:45.047147] Averaged stats: lr: 0.000008  loss: 0.1236 (0.1253)
[16:38:45.623535] Test:  [  0/345]  eta: 0:03:16  loss: 0.1312 (0.1312)  time: 0.5707  data: 0.3884  max mem: 15824
[16:38:47.413759] Test:  [ 10/345]  eta: 0:01:11  loss: 0.1142 (0.1156)  time: 0.2145  data: 0.0354  max mem: 15824
[16:38:49.204122] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1102 (0.1136)  time: 0.1790  data: 0.0001  max mem: 15824
[16:38:51.000399] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1065 (0.1141)  time: 0.1793  data: 0.0001  max mem: 15824
[16:38:52.801116] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1065 (0.1147)  time: 0.1798  data: 0.0001  max mem: 15824
[16:38:54.602156] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1123 (0.1143)  time: 0.1800  data: 0.0001  max mem: 15824
[16:38:56.410748] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1100 (0.1150)  time: 0.1804  data: 0.0001  max mem: 15824
[16:38:58.220549] Test:  [ 70/345]  eta: 0:00:50  loss: 0.1149 (0.1153)  time: 0.1809  data: 0.0001  max mem: 15824
[16:39:00.031566] Test:  [ 80/345]  eta: 0:00:48  loss: 0.1149 (0.1147)  time: 0.1810  data: 0.0001  max mem: 15824
[16:39:01.851023] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1173 (0.1158)  time: 0.1815  data: 0.0001  max mem: 15824
[16:39:03.670463] Test:  [100/345]  eta: 0:00:45  loss: 0.1218 (0.1166)  time: 0.1819  data: 0.0001  max mem: 15824
[16:39:05.496997] Test:  [110/345]  eta: 0:00:43  loss: 0.1240 (0.1173)  time: 0.1822  data: 0.0001  max mem: 15824
[16:39:07.325735] Test:  [120/345]  eta: 0:00:41  loss: 0.1210 (0.1180)  time: 0.1827  data: 0.0001  max mem: 15824
[16:39:09.153393] Test:  [130/345]  eta: 0:00:39  loss: 0.1126 (0.1179)  time: 0.1828  data: 0.0001  max mem: 15824
[16:39:10.989589] Test:  [140/345]  eta: 0:00:37  loss: 0.1140 (0.1181)  time: 0.1831  data: 0.0001  max mem: 15824
[16:39:12.828442] Test:  [150/345]  eta: 0:00:35  loss: 0.1242 (0.1187)  time: 0.1837  data: 0.0001  max mem: 15824
[16:39:14.671411] Test:  [160/345]  eta: 0:00:34  loss: 0.1232 (0.1192)  time: 0.1840  data: 0.0001  max mem: 15824
[16:39:16.515888] Test:  [170/345]  eta: 0:00:32  loss: 0.1192 (0.1197)  time: 0.1843  data: 0.0001  max mem: 15824
[16:39:18.362940] Test:  [180/345]  eta: 0:00:30  loss: 0.1165 (0.1194)  time: 0.1845  data: 0.0001  max mem: 15824
[16:39:20.215876] Test:  [190/345]  eta: 0:00:28  loss: 0.1132 (0.1197)  time: 0.1849  data: 0.0001  max mem: 15824
[16:39:22.070653] Test:  [200/345]  eta: 0:00:26  loss: 0.1133 (0.1196)  time: 0.1853  data: 0.0001  max mem: 15824
[16:39:23.927843] Test:  [210/345]  eta: 0:00:24  loss: 0.1124 (0.1193)  time: 0.1855  data: 0.0001  max mem: 15824
[16:39:25.794374] Test:  [220/345]  eta: 0:00:23  loss: 0.1077 (0.1191)  time: 0.1861  data: 0.0001  max mem: 15824
[16:39:27.659945] Test:  [230/345]  eta: 0:00:21  loss: 0.1117 (0.1189)  time: 0.1865  data: 0.0001  max mem: 15824
[16:39:29.527584] Test:  [240/345]  eta: 0:00:19  loss: 0.1128 (0.1193)  time: 0.1866  data: 0.0001  max mem: 15824
[16:39:31.401248] Test:  [250/345]  eta: 0:00:17  loss: 0.1192 (0.1193)  time: 0.1870  data: 0.0001  max mem: 15824
[16:39:33.277359] Test:  [260/345]  eta: 0:00:15  loss: 0.1192 (0.1197)  time: 0.1874  data: 0.0001  max mem: 15824
[16:39:35.158543] Test:  [270/345]  eta: 0:00:13  loss: 0.1135 (0.1194)  time: 0.1878  data: 0.0001  max mem: 15824
[16:39:37.042989] Test:  [280/345]  eta: 0:00:12  loss: 0.1108 (0.1193)  time: 0.1882  data: 0.0001  max mem: 15824
[16:39:38.929779] Test:  [290/345]  eta: 0:00:10  loss: 0.1102 (0.1192)  time: 0.1885  data: 0.0001  max mem: 15824
[16:39:40.819796] Test:  [300/345]  eta: 0:00:08  loss: 0.1101 (0.1189)  time: 0.1888  data: 0.0001  max mem: 15824
[16:39:42.714720] Test:  [310/345]  eta: 0:00:06  loss: 0.1117 (0.1189)  time: 0.1892  data: 0.0001  max mem: 15824
[16:39:44.612475] Test:  [320/345]  eta: 0:00:04  loss: 0.1117 (0.1186)  time: 0.1896  data: 0.0001  max mem: 15824
[16:39:46.511803] Test:  [330/345]  eta: 0:00:02  loss: 0.1121 (0.1186)  time: 0.1898  data: 0.0001  max mem: 15824
[16:39:48.412740] Test:  [340/345]  eta: 0:00:00  loss: 0.1214 (0.1188)  time: 0.1900  data: 0.0001  max mem: 15824
[16:39:49.174176] Test:  [344/345]  eta: 0:00:00  loss: 0.1214 (0.1188)  time: 0.1901  data: 0.0001  max mem: 15824
[16:39:49.246921] Test: Total time: 0:01:04 (0.1861 s / it)
[16:39:59.726691] Test:  [ 0/57]  eta: 0:00:33  loss: 0.4722 (0.4722)  time: 0.5964  data: 0.4158  max mem: 15824
[16:40:01.500453] Test:  [10/57]  eta: 0:00:10  loss: 0.4502 (0.4809)  time: 0.2154  data: 0.0379  max mem: 15824
[16:40:03.275301] Test:  [20/57]  eta: 0:00:07  loss: 0.4502 (0.4603)  time: 0.1774  data: 0.0001  max mem: 15824
[16:40:05.055289] Test:  [30/57]  eta: 0:00:05  loss: 0.2727 (0.3978)  time: 0.1777  data: 0.0001  max mem: 15824
[16:40:06.843907] Test:  [40/57]  eta: 0:00:03  loss: 0.2683 (0.3737)  time: 0.1784  data: 0.0001  max mem: 15824
[16:40:08.631304] Test:  [50/57]  eta: 0:00:01  loss: 0.3100 (0.3735)  time: 0.1787  data: 0.0001  max mem: 15824
[16:40:09.603297] Test:  [56/57]  eta: 0:00:00  loss: 0.3873 (0.3919)  time: 0.1736  data: 0.0000  max mem: 15824
[16:40:09.672463] Test: Total time: 0:00:10 (0.1850 s / it)
[16:40:11.425304] Dice score of the network on the train images: 0.874416, val images: 0.772040
[16:40:11.429609] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:40:12.420981] Epoch: [45]  [  0/345]  eta: 0:05:41  lr: 0.000008  loss: 0.1216 (0.1216)  time: 0.9904  data: 0.3656  max mem: 15824
[16:40:24.773671] Epoch: [45]  [ 20/345]  eta: 0:03:26  lr: 0.000008  loss: 0.1265 (0.1286)  time: 0.6176  data: 0.0001  max mem: 15824
[16:40:37.270275] Epoch: [45]  [ 40/345]  eta: 0:03:12  lr: 0.000008  loss: 0.1211 (0.1250)  time: 0.6248  data: 0.0001  max mem: 15824
[16:40:49.673335] Epoch: [45]  [ 60/345]  eta: 0:02:58  lr: 0.000008  loss: 0.1212 (0.1240)  time: 0.6201  data: 0.0001  max mem: 15824
[16:41:02.079123] Epoch: [45]  [ 80/345]  eta: 0:02:45  lr: 0.000008  loss: 0.1218 (0.1238)  time: 0.6202  data: 0.0001  max mem: 15824
[16:41:14.498623] Epoch: [45]  [100/345]  eta: 0:02:32  lr: 0.000007  loss: 0.1212 (0.1240)  time: 0.6209  data: 0.0001  max mem: 15824
[16:41:26.933785] Epoch: [45]  [120/345]  eta: 0:02:20  lr: 0.000007  loss: 0.1252 (0.1250)  time: 0.6217  data: 0.0001  max mem: 15824
[16:41:39.369559] Epoch: [45]  [140/345]  eta: 0:02:07  lr: 0.000007  loss: 0.1205 (0.1244)  time: 0.6217  data: 0.0001  max mem: 15824
[16:41:51.813770] Epoch: [45]  [160/345]  eta: 0:01:55  lr: 0.000007  loss: 0.1184 (0.1242)  time: 0.6222  data: 0.0001  max mem: 15824
[16:42:04.250501] Epoch: [45]  [180/345]  eta: 0:01:42  lr: 0.000007  loss: 0.1233 (0.1240)  time: 0.6218  data: 0.0001  max mem: 15824
[16:42:16.665299] Epoch: [45]  [200/345]  eta: 0:01:30  lr: 0.000007  loss: 0.1271 (0.1243)  time: 0.6207  data: 0.0001  max mem: 15824
[16:42:29.063765] Epoch: [45]  [220/345]  eta: 0:01:17  lr: 0.000006  loss: 0.1105 (0.1237)  time: 0.6199  data: 0.0001  max mem: 15824
[16:42:41.457715] Epoch: [45]  [240/345]  eta: 0:01:05  lr: 0.000006  loss: 0.1206 (0.1236)  time: 0.6196  data: 0.0001  max mem: 15824
[16:42:53.853558] Epoch: [45]  [260/345]  eta: 0:00:52  lr: 0.000006  loss: 0.1249 (0.1236)  time: 0.6197  data: 0.0001  max mem: 15824
[16:43:06.330991] Epoch: [45]  [280/345]  eta: 0:00:40  lr: 0.000006  loss: 0.1251 (0.1239)  time: 0.6238  data: 0.0001  max mem: 15824
[16:43:18.733426] Epoch: [45]  [300/345]  eta: 0:00:27  lr: 0.000006  loss: 0.1182 (0.1239)  time: 0.6201  data: 0.0001  max mem: 15824
[16:43:31.157145] Epoch: [45]  [320/345]  eta: 0:00:15  lr: 0.000006  loss: 0.1131 (0.1235)  time: 0.6211  data: 0.0001  max mem: 15824
[16:43:43.573293] Epoch: [45]  [340/345]  eta: 0:00:03  lr: 0.000005  loss: 0.1232 (0.1237)  time: 0.6208  data: 0.0001  max mem: 15824
[16:43:46.057117] Epoch: [45]  [344/345]  eta: 0:00:00  lr: 0.000005  loss: 0.1232 (0.1237)  time: 0.6206  data: 0.0001  max mem: 15824
[16:43:46.132096] Epoch: [45] Total time: 0:03:34 (0.6223 s / it)
[16:43:46.132231] Averaged stats: lr: 0.000005  loss: 0.1232 (0.1237)
[16:43:46.721476] Test:  [  0/345]  eta: 0:03:21  loss: 0.1328 (0.1328)  time: 0.5847  data: 0.4036  max mem: 15824
[16:43:48.513640] Test:  [ 10/345]  eta: 0:01:12  loss: 0.1152 (0.1171)  time: 0.2160  data: 0.0368  max mem: 15824
[16:43:50.304655] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1107 (0.1166)  time: 0.1791  data: 0.0001  max mem: 15824
[16:43:52.101095] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1107 (0.1150)  time: 0.1793  data: 0.0001  max mem: 15824
[16:43:53.901841] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1170 (0.1170)  time: 0.1798  data: 0.0001  max mem: 15824
[16:43:55.704016] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1178 (0.1181)  time: 0.1801  data: 0.0001  max mem: 15824
[16:43:57.507531] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1215 (0.1202)  time: 0.1802  data: 0.0001  max mem: 15824
[16:43:59.314635] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1145 (0.1194)  time: 0.1805  data: 0.0001  max mem: 15824
[16:44:01.127165] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1145 (0.1202)  time: 0.1809  data: 0.0001  max mem: 15824
[16:44:02.943786] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1180 (0.1201)  time: 0.1814  data: 0.0001  max mem: 15824
[16:44:04.762763] Test:  [100/345]  eta: 0:00:45  loss: 0.1195 (0.1198)  time: 0.1817  data: 0.0001  max mem: 15824
[16:44:06.584815] Test:  [110/345]  eta: 0:00:43  loss: 0.1211 (0.1197)  time: 0.1820  data: 0.0001  max mem: 15824
[16:44:08.411127] Test:  [120/345]  eta: 0:00:41  loss: 0.1141 (0.1197)  time: 0.1824  data: 0.0001  max mem: 15824
[16:44:10.241856] Test:  [130/345]  eta: 0:00:39  loss: 0.1141 (0.1191)  time: 0.1828  data: 0.0001  max mem: 15824
[16:44:12.074876] Test:  [140/345]  eta: 0:00:37  loss: 0.1053 (0.1192)  time: 0.1831  data: 0.0001  max mem: 15824
[16:44:13.913736] Test:  [150/345]  eta: 0:00:35  loss: 0.1140 (0.1187)  time: 0.1835  data: 0.0001  max mem: 15824
[16:44:15.754608] Test:  [160/345]  eta: 0:00:34  loss: 0.1165 (0.1186)  time: 0.1839  data: 0.0001  max mem: 15824
[16:44:17.599025] Test:  [170/345]  eta: 0:00:32  loss: 0.1171 (0.1185)  time: 0.1842  data: 0.0001  max mem: 15824
[16:44:19.447569] Test:  [180/345]  eta: 0:00:30  loss: 0.1139 (0.1186)  time: 0.1846  data: 0.0001  max mem: 15824
[16:44:21.301183] Test:  [190/345]  eta: 0:00:28  loss: 0.1141 (0.1183)  time: 0.1850  data: 0.0001  max mem: 15824
[16:44:23.157370] Test:  [200/345]  eta: 0:00:26  loss: 0.1129 (0.1180)  time: 0.1854  data: 0.0001  max mem: 15824
[16:44:25.016456] Test:  [210/345]  eta: 0:00:24  loss: 0.1129 (0.1181)  time: 0.1857  data: 0.0001  max mem: 15824
[16:44:26.878624] Test:  [220/345]  eta: 0:00:23  loss: 0.1168 (0.1179)  time: 0.1860  data: 0.0001  max mem: 15824
[16:44:28.745605] Test:  [230/345]  eta: 0:00:21  loss: 0.1182 (0.1181)  time: 0.1864  data: 0.0001  max mem: 15824
[16:44:30.615614] Test:  [240/345]  eta: 0:00:19  loss: 0.1182 (0.1182)  time: 0.1868  data: 0.0001  max mem: 15824
[16:44:32.487016] Test:  [250/345]  eta: 0:00:17  loss: 0.1192 (0.1183)  time: 0.1870  data: 0.0001  max mem: 15824
[16:44:34.365742] Test:  [260/345]  eta: 0:00:15  loss: 0.1129 (0.1182)  time: 0.1874  data: 0.0001  max mem: 15824
[16:44:36.243910] Test:  [270/345]  eta: 0:00:13  loss: 0.1112 (0.1181)  time: 0.1878  data: 0.0001  max mem: 15824
[16:44:38.125477] Test:  [280/345]  eta: 0:00:12  loss: 0.1142 (0.1183)  time: 0.1879  data: 0.0001  max mem: 15824
[16:44:40.013126] Test:  [290/345]  eta: 0:00:10  loss: 0.1142 (0.1181)  time: 0.1884  data: 0.0001  max mem: 15824
[16:44:41.903298] Test:  [300/345]  eta: 0:00:08  loss: 0.1130 (0.1182)  time: 0.1888  data: 0.0001  max mem: 15824
[16:44:43.796445] Test:  [310/345]  eta: 0:00:06  loss: 0.1189 (0.1183)  time: 0.1891  data: 0.0001  max mem: 15824
[16:44:45.693982] Test:  [320/345]  eta: 0:00:04  loss: 0.1189 (0.1181)  time: 0.1895  data: 0.0001  max mem: 15824
[16:44:47.598914] Test:  [330/345]  eta: 0:00:02  loss: 0.1159 (0.1180)  time: 0.1901  data: 0.0001  max mem: 15824
[16:44:49.498570] Test:  [340/345]  eta: 0:00:00  loss: 0.1159 (0.1179)  time: 0.1902  data: 0.0001  max mem: 15824
[16:44:50.260025] Test:  [344/345]  eta: 0:00:00  loss: 0.1159 (0.1179)  time: 0.1901  data: 0.0001  max mem: 15824
[16:44:50.328235] Test: Total time: 0:01:04 (0.1861 s / it)
[16:45:00.747258] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4768 (0.4768)  time: 0.5446  data: 0.3636  max mem: 15824
[16:45:02.521200] Test:  [10/57]  eta: 0:00:09  loss: 0.4517 (0.4791)  time: 0.2107  data: 0.0331  max mem: 15824
[16:45:04.299717] Test:  [20/57]  eta: 0:00:07  loss: 0.4517 (0.4598)  time: 0.1775  data: 0.0001  max mem: 15824
[16:45:06.082942] Test:  [30/57]  eta: 0:00:05  loss: 0.2792 (0.3977)  time: 0.1780  data: 0.0001  max mem: 15824
[16:45:07.871998] Test:  [40/57]  eta: 0:00:03  loss: 0.2657 (0.3735)  time: 0.1786  data: 0.0001  max mem: 15824
[16:45:09.658840] Test:  [50/57]  eta: 0:00:01  loss: 0.3111 (0.3733)  time: 0.1787  data: 0.0001  max mem: 15824
[16:45:10.632540] Test:  [56/57]  eta: 0:00:00  loss: 0.3862 (0.3913)  time: 0.1738  data: 0.0000  max mem: 15824
[16:45:10.701582] Test: Total time: 0:00:10 (0.1842 s / it)
[16:45:12.423907] Dice score of the network on the train images: 0.874220, val images: 0.773074
[16:45:12.427863] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:45:13.426143] Epoch: [46]  [  0/345]  eta: 0:05:44  lr: 0.000005  loss: 0.1188 (0.1188)  time: 0.9971  data: 0.3737  max mem: 15824
[16:45:25.770916] Epoch: [46]  [ 20/345]  eta: 0:03:26  lr: 0.000005  loss: 0.1221 (0.1269)  time: 0.6172  data: 0.0001  max mem: 15824
[16:45:38.147161] Epoch: [46]  [ 40/345]  eta: 0:03:11  lr: 0.000005  loss: 0.1239 (0.1249)  time: 0.6188  data: 0.0001  max mem: 15824
[16:45:50.513826] Epoch: [46]  [ 60/345]  eta: 0:02:57  lr: 0.000005  loss: 0.1139 (0.1230)  time: 0.6183  data: 0.0001  max mem: 15824
[16:46:02.889152] Epoch: [46]  [ 80/345]  eta: 0:02:45  lr: 0.000005  loss: 0.1310 (0.1244)  time: 0.6187  data: 0.0001  max mem: 15824
[16:46:15.289793] Epoch: [46]  [100/345]  eta: 0:02:32  lr: 0.000005  loss: 0.1184 (0.1243)  time: 0.6200  data: 0.0001  max mem: 15824
[16:46:27.687085] Epoch: [46]  [120/345]  eta: 0:02:19  lr: 0.000005  loss: 0.1177 (0.1237)  time: 0.6198  data: 0.0001  max mem: 15824
[16:46:40.087547] Epoch: [46]  [140/345]  eta: 0:02:07  lr: 0.000004  loss: 0.1104 (0.1229)  time: 0.6200  data: 0.0001  max mem: 15824
[16:46:52.477765] Epoch: [46]  [160/345]  eta: 0:01:54  lr: 0.000004  loss: 0.1170 (0.1228)  time: 0.6195  data: 0.0001  max mem: 15824
[16:47:04.873259] Epoch: [46]  [180/345]  eta: 0:01:42  lr: 0.000004  loss: 0.1193 (0.1225)  time: 0.6197  data: 0.0001  max mem: 15824
[16:47:17.266663] Epoch: [46]  [200/345]  eta: 0:01:30  lr: 0.000004  loss: 0.1154 (0.1225)  time: 0.6196  data: 0.0001  max mem: 15824
[16:47:29.664624] Epoch: [46]  [220/345]  eta: 0:01:17  lr: 0.000004  loss: 0.1179 (0.1223)  time: 0.6199  data: 0.0001  max mem: 15824
[16:47:42.058312] Epoch: [46]  [240/345]  eta: 0:01:05  lr: 0.000004  loss: 0.1200 (0.1224)  time: 0.6196  data: 0.0001  max mem: 15824
[16:47:54.454373] Epoch: [46]  [260/345]  eta: 0:00:52  lr: 0.000004  loss: 0.1184 (0.1223)  time: 0.6198  data: 0.0001  max mem: 15824
[16:48:06.850631] Epoch: [46]  [280/345]  eta: 0:00:40  lr: 0.000003  loss: 0.1131 (0.1222)  time: 0.6198  data: 0.0001  max mem: 15824
[16:48:19.247522] Epoch: [46]  [300/345]  eta: 0:00:27  lr: 0.000003  loss: 0.1246 (0.1228)  time: 0.6198  data: 0.0001  max mem: 15824
[16:48:31.640216] Epoch: [46]  [320/345]  eta: 0:00:15  lr: 0.000003  loss: 0.1238 (0.1229)  time: 0.6196  data: 0.0001  max mem: 15824
[16:48:44.019204] Epoch: [46]  [340/345]  eta: 0:00:03  lr: 0.000003  loss: 0.1215 (0.1230)  time: 0.6189  data: 0.0001  max mem: 15824
[16:48:46.495727] Epoch: [46]  [344/345]  eta: 0:00:00  lr: 0.000003  loss: 0.1231 (0.1230)  time: 0.6187  data: 0.0001  max mem: 15824
[16:48:46.564118] Epoch: [46] Total time: 0:03:34 (0.6207 s / it)
[16:48:46.564599] Averaged stats: lr: 0.000003  loss: 0.1231 (0.1230)
[16:48:47.136630] Test:  [  0/345]  eta: 0:03:15  loss: 0.1079 (0.1079)  time: 0.5667  data: 0.3848  max mem: 15824
[16:48:48.925454] Test:  [ 10/345]  eta: 0:01:11  loss: 0.1146 (0.1171)  time: 0.2140  data: 0.0351  max mem: 15824
[16:48:50.722194] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1155 (0.1168)  time: 0.1792  data: 0.0001  max mem: 15824
[16:48:52.521330] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1171 (0.1182)  time: 0.1797  data: 0.0001  max mem: 15824
[16:48:54.326400] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1171 (0.1175)  time: 0.1801  data: 0.0001  max mem: 15824
[16:48:56.127264] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1155 (0.1171)  time: 0.1802  data: 0.0001  max mem: 15824
[16:48:57.931831] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1104 (0.1160)  time: 0.1802  data: 0.0001  max mem: 15824
[16:48:59.745945] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1082 (0.1163)  time: 0.1809  data: 0.0001  max mem: 15824
[16:49:01.559725] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1082 (0.1153)  time: 0.1813  data: 0.0001  max mem: 15824
[16:49:03.376906] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1059 (0.1144)  time: 0.1815  data: 0.0001  max mem: 15824
[16:49:05.197064] Test:  [100/345]  eta: 0:00:45  loss: 0.1096 (0.1146)  time: 0.1818  data: 0.0001  max mem: 15824
[16:49:07.023827] Test:  [110/345]  eta: 0:00:43  loss: 0.1141 (0.1148)  time: 0.1823  data: 0.0001  max mem: 15824
[16:49:08.850749] Test:  [120/345]  eta: 0:00:41  loss: 0.1138 (0.1153)  time: 0.1826  data: 0.0001  max mem: 15824
[16:49:10.680759] Test:  [130/345]  eta: 0:00:39  loss: 0.1155 (0.1152)  time: 0.1828  data: 0.0001  max mem: 15824
[16:49:12.517025] Test:  [140/345]  eta: 0:00:37  loss: 0.1127 (0.1154)  time: 0.1833  data: 0.0001  max mem: 15824
[16:49:14.355071] Test:  [150/345]  eta: 0:00:35  loss: 0.1102 (0.1154)  time: 0.1836  data: 0.0001  max mem: 15824
[16:49:16.198352] Test:  [160/345]  eta: 0:00:34  loss: 0.1087 (0.1152)  time: 0.1840  data: 0.0001  max mem: 15824
[16:49:18.043584] Test:  [170/345]  eta: 0:00:32  loss: 0.1061 (0.1153)  time: 0.1844  data: 0.0001  max mem: 15824
[16:49:19.892743] Test:  [180/345]  eta: 0:00:30  loss: 0.1071 (0.1151)  time: 0.1847  data: 0.0001  max mem: 15824
[16:49:21.743274] Test:  [190/345]  eta: 0:00:28  loss: 0.1081 (0.1154)  time: 0.1849  data: 0.0001  max mem: 15824
[16:49:23.603125] Test:  [200/345]  eta: 0:00:26  loss: 0.1175 (0.1156)  time: 0.1855  data: 0.0001  max mem: 15824
[16:49:25.461562] Test:  [210/345]  eta: 0:00:24  loss: 0.1171 (0.1155)  time: 0.1859  data: 0.0001  max mem: 15824
[16:49:27.327302] Test:  [220/345]  eta: 0:00:23  loss: 0.1164 (0.1156)  time: 0.1861  data: 0.0001  max mem: 15824
[16:49:29.191906] Test:  [230/345]  eta: 0:00:21  loss: 0.1109 (0.1154)  time: 0.1865  data: 0.0001  max mem: 15824
[16:49:31.064534] Test:  [240/345]  eta: 0:00:19  loss: 0.1078 (0.1154)  time: 0.1868  data: 0.0001  max mem: 15824
[16:49:32.936974] Test:  [250/345]  eta: 0:00:17  loss: 0.1135 (0.1154)  time: 0.1872  data: 0.0001  max mem: 15824
[16:49:34.813256] Test:  [260/345]  eta: 0:00:15  loss: 0.1148 (0.1154)  time: 0.1874  data: 0.0001  max mem: 15824
[16:49:36.692703] Test:  [270/345]  eta: 0:00:13  loss: 0.1148 (0.1158)  time: 0.1877  data: 0.0001  max mem: 15824
[16:49:38.575616] Test:  [280/345]  eta: 0:00:12  loss: 0.1242 (0.1161)  time: 0.1881  data: 0.0001  max mem: 15824
[16:49:40.461032] Test:  [290/345]  eta: 0:00:10  loss: 0.1193 (0.1162)  time: 0.1884  data: 0.0001  max mem: 15824
[16:49:42.354714] Test:  [300/345]  eta: 0:00:08  loss: 0.1177 (0.1164)  time: 0.1889  data: 0.0001  max mem: 15824
[16:49:44.247154] Test:  [310/345]  eta: 0:00:06  loss: 0.1146 (0.1164)  time: 0.1892  data: 0.0001  max mem: 15824
[16:49:46.146642] Test:  [320/345]  eta: 0:00:04  loss: 0.1146 (0.1164)  time: 0.1895  data: 0.0001  max mem: 15824
[16:49:48.047784] Test:  [330/345]  eta: 0:00:02  loss: 0.1192 (0.1166)  time: 0.1900  data: 0.0001  max mem: 15824
[16:49:49.948643] Test:  [340/345]  eta: 0:00:00  loss: 0.1187 (0.1166)  time: 0.1900  data: 0.0001  max mem: 15824
[16:49:50.709038] Test:  [344/345]  eta: 0:00:00  loss: 0.1272 (0.1168)  time: 0.1900  data: 0.0001  max mem: 15824
[16:49:50.782598] Test: Total time: 0:01:04 (0.1861 s / it)
[16:50:01.428658] Test:  [ 0/57]  eta: 0:00:32  loss: 0.4772 (0.4772)  time: 0.5686  data: 0.3878  max mem: 15824
[16:50:03.200814] Test:  [10/57]  eta: 0:00:09  loss: 0.4531 (0.4821)  time: 0.2127  data: 0.0353  max mem: 15824
[16:50:04.978217] Test:  [20/57]  eta: 0:00:07  loss: 0.4531 (0.4633)  time: 0.1774  data: 0.0001  max mem: 15824
[16:50:06.760053] Test:  [30/57]  eta: 0:00:05  loss: 0.2821 (0.4007)  time: 0.1779  data: 0.0001  max mem: 15824
[16:50:08.546937] Test:  [40/57]  eta: 0:00:03  loss: 0.2713 (0.3768)  time: 0.1784  data: 0.0001  max mem: 15824
[16:50:10.335864] Test:  [50/57]  eta: 0:00:01  loss: 0.3108 (0.3770)  time: 0.1787  data: 0.0001  max mem: 15824
[16:50:11.309663] Test:  [56/57]  eta: 0:00:00  loss: 0.3890 (0.3955)  time: 0.1738  data: 0.0000  max mem: 15824
[16:50:11.386831] Test: Total time: 0:00:10 (0.1847 s / it)
[16:50:13.150154] Dice score of the network on the train images: 0.876216, val images: 0.769957
[16:50:13.154155] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[16:50:14.160030] Epoch: [47]  [  0/345]  eta: 0:05:46  lr: 0.000003  loss: 0.1198 (0.1198)  time: 1.0048  data: 0.3789  max mem: 15824
[16:50:26.492702] Epoch: [47]  [ 20/345]  eta: 0:03:26  lr: 0.000003  loss: 0.1177 (0.1195)  time: 0.6166  data: 0.0001  max mem: 15824
[16:50:38.878022] Epoch: [47]  [ 40/345]  eta: 0:03:11  lr: 0.000003  loss: 0.1199 (0.1233)  time: 0.6192  data: 0.0001  max mem: 15824
[16:50:51.282276] Epoch: [47]  [ 60/345]  eta: 0:02:58  lr: 0.000003  loss: 0.1242 (0.1223)  time: 0.6202  data: 0.0001  max mem: 15824
[16:51:03.700521] Epoch: [47]  [ 80/345]  eta: 0:02:45  lr: 0.000003  loss: 0.1193 (0.1223)  time: 0.6209  data: 0.0001  max mem: 15824
[16:51:16.133485] Epoch: [47]  [100/345]  eta: 0:02:32  lr: 0.000003  loss: 0.1142 (0.1222)  time: 0.6216  data: 0.0001  max mem: 15824
[16:51:28.582440] Epoch: [47]  [120/345]  eta: 0:02:20  lr: 0.000002  loss: 0.1178 (0.1213)  time: 0.6224  data: 0.0001  max mem: 15824

[16:51:41.032758] Epoch: [47]  [140/345]  eta: 0:02:07  lr: 0.000002  loss: 0.1124 (0.1211)  time: 0.6225  data: 0.0001  max mem: 15824
[16:51:53.442217] Epoch: [47]  [160/345]  eta: 0:01:55  lr: 0.000002  loss: 0.1240 (0.1211)  time: 0.6204  data: 0.0001  max mem: 15824
[16:52:05.873735] Epoch: [47]  [180/345]  eta: 0:01:42  lr: 0.000002  loss: 0.1177 (0.1213)  time: 0.6215  data: 0.0001  max mem: 15824
[16:52:18.298816] Epoch: [47]  [200/345]  eta: 0:01:30  lr: 0.000002  loss: 0.1215 (0.1213)  time: 0.6212  data: 0.0001  max mem: 15824
[16:52:30.732134] Epoch: [47]  [220/345]  eta: 0:01:17  lr: 0.000002  loss: 0.1147 (0.1213)  time: 0.6216  data: 0.0001  max mem: 15824
[16:52:43.172493] Epoch: [47]  [240/345]  eta: 0:01:05  lr: 0.000002  loss: 0.1156 (0.1212)  time: 0.6220  data: 0.0001  max mem: 15824
[16:52:55.596955] Epoch: [47]  [260/345]  eta: 0:00:52  lr: 0.000002  loss: 0.1198 (0.1216)  time: 0.6212  data: 0.0001  max mem: 15824
[16:53:08.031232] Epoch: [47]  [280/345]  eta: 0:00:40  lr: 0.000002  loss: 0.1158 (0.1218)  time: 0.6217  data: 0.0001  max mem: 15824
[16:53:20.463648] Epoch: [47]  [300/345]  eta: 0:00:28  lr: 0.000002  loss: 0.1293 (0.1224)  time: 0.6216  data: 0.0001  max mem: 15824
[16:53:32.874555] Epoch: [47]  [320/345]  eta: 0:00:15  lr: 0.000001  loss: 0.1228 (0.1224)  time: 0.6205  data: 0.0001  max mem: 15824
[16:53:45.253877] Epoch: [47]  [340/345]  eta: 0:00:03  lr: 0.000001  loss: 0.1229 (0.1225)  time: 0.6189  data: 0.0001  max mem: 15824
[16:53:47.734980] Epoch: [47]  [344/345]  eta: 0:00:00  lr: 0.000001  loss: 0.1199 (0.1225)  time: 0.6192  data: 0.0001  max mem: 15824
[16:53:47.812540] Epoch: [47] Total time: 0:03:34 (0.6222 s / it)
[16:53:47.812888] Averaged stats: lr: 0.000001  loss: 0.1199 (0.1225)
[16:53:48.400244] Test:  [  0/345]  eta: 0:03:20  loss: 0.1102 (0.1102)  time: 0.5819  data: 0.3975  max mem: 15824
[16:53:50.189530] Test:  [ 10/345]  eta: 0:01:12  loss: 0.1126 (0.1232)  time: 0.2155  data: 0.0362  max mem: 15824
[16:53:51.983669] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1126 (0.1180)  time: 0.1791  data: 0.0001  max mem: 15824
[16:53:53.786282] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1101 (0.1166)  time: 0.1798  data: 0.0001  max mem: 15824
[16:53:55.588983] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1133 (0.1162)  time: 0.1802  data: 0.0001  max mem: 15824
[16:53:57.391237] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1161 (0.1171)  time: 0.1802  data: 0.0001  max mem: 15824
[16:53:59.199460] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1159 (0.1164)  time: 0.1805  data: 0.0001  max mem: 15824
[16:54:01.011629] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1115 (0.1155)  time: 0.1810  data: 0.0001  max mem: 15824
[16:54:02.827157] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1144 (0.1155)  time: 0.1813  data: 0.0001  max mem: 15824
[16:54:04.644346] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1154 (0.1160)  time: 0.1816  data: 0.0001  max mem: 15824
[16:54:06.467644] Test:  [100/345]  eta: 0:00:45  loss: 0.1123 (0.1159)  time: 0.1820  data: 0.0001  max mem: 15824
[16:54:08.293418] Test:  [110/345]  eta: 0:00:43  loss: 0.1123 (0.1158)  time: 0.1824  data: 0.0001  max mem: 15824
[16:54:10.122981] Test:  [120/345]  eta: 0:00:41  loss: 0.1157 (0.1159)  time: 0.1827  data: 0.0001  max mem: 15824
[16:54:11.954189] Test:  [130/345]  eta: 0:00:39  loss: 0.1129 (0.1156)  time: 0.1830  data: 0.0001  max mem: 15824
[16:54:13.791872] Test:  [140/345]  eta: 0:00:37  loss: 0.1117 (0.1159)  time: 0.1834  data: 0.0001  max mem: 15824
[16:54:15.632359] Test:  [150/345]  eta: 0:00:35  loss: 0.1090 (0.1157)  time: 0.1838  data: 0.0001  max mem: 15824
[16:54:17.473665] Test:  [160/345]  eta: 0:00:34  loss: 0.1054 (0.1155)  time: 0.1840  data: 0.0001  max mem: 15824
[16:54:19.319076] Test:  [170/345]  eta: 0:00:32  loss: 0.1107 (0.1159)  time: 0.1843  data: 0.0001  max mem: 15824
[16:54:21.169635] Test:  [180/345]  eta: 0:00:30  loss: 0.1125 (0.1158)  time: 0.1847  data: 0.0001  max mem: 15824
[16:54:23.023091] Test:  [190/345]  eta: 0:00:28  loss: 0.1116 (0.1157)  time: 0.1851  data: 0.0001  max mem: 15824
[16:54:24.879435] Test:  [200/345]  eta: 0:00:26  loss: 0.1179 (0.1158)  time: 0.1854  data: 0.0001  max mem: 15824
[16:54:26.739396] Test:  [210/345]  eta: 0:00:24  loss: 0.1080 (0.1153)  time: 0.1858  data: 0.0001  max mem: 15824
[16:54:28.605082] Test:  [220/345]  eta: 0:00:23  loss: 0.1102 (0.1154)  time: 0.1862  data: 0.0001  max mem: 15824
[16:54:30.473194] Test:  [230/345]  eta: 0:00:21  loss: 0.1187 (0.1157)  time: 0.1866  data: 0.0001  max mem: 15824
[16:54:32.342057] Test:  [240/345]  eta: 0:00:19  loss: 0.1215 (0.1161)  time: 0.1868  data: 0.0001  max mem: 15824
[16:54:34.214806] Test:  [250/345]  eta: 0:00:17  loss: 0.1153 (0.1160)  time: 0.1870  data: 0.0001  max mem: 15824
[16:54:36.091278] Test:  [260/345]  eta: 0:00:15  loss: 0.1070 (0.1156)  time: 0.1874  data: 0.0001  max mem: 15824
[16:54:37.971474] Test:  [270/345]  eta: 0:00:13  loss: 0.1081 (0.1159)  time: 0.1878  data: 0.0001  max mem: 15824
[16:54:39.856318] Test:  [280/345]  eta: 0:00:12  loss: 0.1076 (0.1157)  time: 0.1882  data: 0.0001  max mem: 15824
[16:54:41.741381] Test:  [290/345]  eta: 0:00:10  loss: 0.1094 (0.1157)  time: 0.1884  data: 0.0001  max mem: 15824
[16:54:43.630381] Test:  [300/345]  eta: 0:00:08  loss: 0.1130 (0.1158)  time: 0.1886  data: 0.0001  max mem: 15824
[16:54:45.525846] Test:  [310/345]  eta: 0:00:06  loss: 0.1184 (0.1160)  time: 0.1892  data: 0.0001  max mem: 15824
[16:54:47.423589] Test:  [320/345]  eta: 0:00:04  loss: 0.1212 (0.1161)  time: 0.1896  data: 0.0001  max mem: 15824
[16:54:49.324864] Test:  [330/345]  eta: 0:00:02  loss: 0.1113 (0.1161)  time: 0.1899  data: 0.0001  max mem: 15824
[16:54:51.226079] Test:  [340/345]  eta: 0:00:00  loss: 0.1132 (0.1164)  time: 0.1901  data: 0.0001  max mem: 15824
[16:54:51.988177] Test:  [344/345]  eta: 0:00:00  loss: 0.1081 (0.1163)  time: 0.1901  data: 0.0001  max mem: 15824
[16:54:52.059436] Test: Total time: 0:01:04 (0.1862 s / it)
[16:55:02.559278] Test:  [ 0/57]  eta: 0:00:32  loss: 0.4805 (0.4805)  time: 0.5658  data: 0.3855  max mem: 15824
[16:55:04.334230] Test:  [10/57]  eta: 0:00:09  loss: 0.4522 (0.4818)  time: 0.2127  data: 0.0351  max mem: 15824
[16:55:06.113121] Test:  [20/57]  eta: 0:00:07  loss: 0.4522 (0.4632)  time: 0.1776  data: 0.0001  max mem: 15824
[16:55:07.895307] Test:  [30/57]  eta: 0:00:05  loss: 0.2836 (0.4008)  time: 0.1780  data: 0.0001  max mem: 15824
[16:55:09.680740] Test:  [40/57]  eta: 0:00:03  loss: 0.2706 (0.3769)  time: 0.1783  data: 0.0001  max mem: 15824
[16:55:11.469422] Test:  [50/57]  eta: 0:00:01  loss: 0.3122 (0.3773)  time: 0.1786  data: 0.0001  max mem: 15824
[16:55:12.440633] Test:  [56/57]  eta: 0:00:00  loss: 0.3872 (0.3957)  time: 0.1737  data: 0.0000  max mem: 15824
[16:55:12.500394] Test: Total time: 0:00:10 (0.1843 s / it)
[16:55:14.218922] Dice score of the network on the train images: 0.876580, val images: 0.769897
[16:55:14.223179] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft

[16:55:15.294102] Epoch: [48]  [  0/345]  eta: 0:06:09  lr: 0.000001  loss: 0.1030 (0.1030)  time: 1.0697  data: 0.4488  max mem: 15824
[16:55:27.599387] Epoch: [48]  [ 20/345]  eta: 0:03:26  lr: 0.000001  loss: 0.1158 (0.1176)  time: 0.6152  data: 0.0001  max mem: 15824
[16:55:39.983282] Epoch: [48]  [ 40/345]  eta: 0:03:11  lr: 0.000001  loss: 0.1250 (0.1204)  time: 0.6191  data: 0.0001  max mem: 15824
[16:55:52.371666] Epoch: [48]  [ 60/345]  eta: 0:02:58  lr: 0.000001  loss: 0.1115 (0.1188)  time: 0.6194  data: 0.0001  max mem: 15824
[16:56:04.788855] Epoch: [48]  [ 80/345]  eta: 0:02:45  lr: 0.000001  loss: 0.1167 (0.1190)  time: 0.6208  data: 0.0001  max mem: 15824
[16:56:17.210185] Epoch: [48]  [100/345]  eta: 0:02:32  lr: 0.000001  loss: 0.1215 (0.1197)  time: 0.6210  data: 0.0001  max mem: 15824
[16:56:29.645707] Epoch: [48]  [120/345]  eta: 0:02:20  lr: 0.000001  loss: 0.1190 (0.1200)  time: 0.6217  data: 0.0001  max mem: 15824
[16:56:42.102373] Epoch: [48]  [140/345]  eta: 0:02:07  lr: 0.000001  loss: 0.1243 (0.1209)  time: 0.6228  data: 0.0001  max mem: 15824
[16:56:54.543330] Epoch: [48]  [160/345]  eta: 0:01:55  lr: 0.000001  loss: 0.1130 (0.1201)  time: 0.6220  data: 0.0001  max mem: 15824
[16:57:06.963963] Epoch: [48]  [180/345]  eta: 0:01:42  lr: 0.000001  loss: 0.1201 (0.1204)  time: 0.6210  data: 0.0001  max mem: 15824
[16:57:19.400986] Epoch: [48]  [200/345]  eta: 0:01:30  lr: 0.000001  loss: 0.1115 (0.1202)  time: 0.6218  data: 0.0001  max mem: 15824
[16:57:31.838263] Epoch: [48]  [220/345]  eta: 0:01:17  lr: 0.000001  loss: 0.1179 (0.1201)  time: 0.6218  data: 0.0001  max mem: 15824
[16:57:44.282967] Epoch: [48]  [240/345]  eta: 0:01:05  lr: 0.000001  loss: 0.1146 (0.1197)  time: 0.6222  data: 0.0001  max mem: 15824
[16:57:56.702456] Epoch: [48]  [260/345]  eta: 0:00:52  lr: 0.000001  loss: 0.1259 (0.1205)  time: 0.6209  data: 0.0001  max mem: 15824
[16:58:09.118591] Epoch: [48]  [280/345]  eta: 0:00:40  lr: 0.000000  loss: 0.1176 (0.1206)  time: 0.6208  data: 0.0001  max mem: 15824

[16:58:21.516032] Epoch: [48]  [300/345]  eta: 0:00:27  lr: 0.000000  loss: 0.1190 (0.1209)  time: 0.6198  data: 0.0001  max mem: 15824
[16:58:33.918769] Epoch: [48]  [320/345]  eta: 0:00:15  lr: 0.000000  loss: 0.1178 (0.1211)  time: 0.6201  data: 0.0001  max mem: 15824
[16:58:46.336160] Epoch: [48]  [340/345]  eta: 0:00:03  lr: 0.000000  loss: 0.1367 (0.1219)  time: 0.6208  data: 0.0001  max mem: 15824
[16:58:48.822722] Epoch: [48]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.1369 (0.1220)  time: 0.6206  data: 0.0001  max mem: 15824
[16:58:48.905143] Epoch: [48] Total time: 0:03:34 (0.6223 s / it)
[16:58:48.905396] Averaged stats: lr: 0.000000  loss: 0.1369 (0.1220)
[16:58:49.489751] Test:  [  0/345]  eta: 0:03:19  loss: 0.1181 (0.1181)  time: 0.5787  data: 0.3954  max mem: 15824
[16:58:51.283323] Test:  [ 10/345]  eta: 0:01:12  loss: 0.1125 (0.1113)  time: 0.2156  data: 0.0360  max mem: 15824
[16:58:53.078384] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1125 (0.1134)  time: 0.1794  data: 0.0001  max mem: 15824
[16:58:54.876686] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1126 (0.1143)  time: 0.1796  data: 0.0001  max mem: 15824
[16:58:56.677247] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1095 (0.1136)  time: 0.1799  data: 0.0001  max mem: 15824
[16:58:58.480454] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1149 (0.1150)  time: 0.1801  data: 0.0001  max mem: 15824
[16:59:00.294419] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1293 (0.1170)  time: 0.1808  data: 0.0001  max mem: 15824
[16:59:02.106979] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1274 (0.1179)  time: 0.1813  data: 0.0001  max mem: 15824
[16:59:03.923038] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1155 (0.1173)  time: 0.1814  data: 0.0001  max mem: 15824
[16:59:05.741490] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1080 (0.1167)  time: 0.1817  data: 0.0001  max mem: 15824
[16:59:07.565324] Test:  [100/345]  eta: 0:00:45  loss: 0.1110 (0.1162)  time: 0.1821  data: 0.0001  max mem: 15824
[16:59:09.392281] Test:  [110/345]  eta: 0:00:43  loss: 0.1098 (0.1153)  time: 0.1825  data: 0.0001  max mem: 15824
[16:59:11.219886] Test:  [120/345]  eta: 0:00:41  loss: 0.1094 (0.1149)  time: 0.1827  data: 0.0001  max mem: 15824
[16:59:13.057038] Test:  [130/345]  eta: 0:00:39  loss: 0.1091 (0.1148)  time: 0.1832  data: 0.0001  max mem: 15824
[16:59:14.893218] Test:  [140/345]  eta: 0:00:37  loss: 0.1091 (0.1149)  time: 0.1836  data: 0.0001  max mem: 15824
[16:59:16.732304] Test:  [150/345]  eta: 0:00:35  loss: 0.1148 (0.1151)  time: 0.1837  data: 0.0001  max mem: 15824
[16:59:18.576111] Test:  [160/345]  eta: 0:00:34  loss: 0.1112 (0.1148)  time: 0.1841  data: 0.0001  max mem: 15824
[16:59:20.422864] Test:  [170/345]  eta: 0:00:32  loss: 0.1160 (0.1150)  time: 0.1845  data: 0.0001  max mem: 15824
[16:59:22.275674] Test:  [180/345]  eta: 0:00:30  loss: 0.1180 (0.1155)  time: 0.1849  data: 0.0001  max mem: 15824
[16:59:24.128956] Test:  [190/345]  eta: 0:00:28  loss: 0.1102 (0.1150)  time: 0.1852  data: 0.0001  max mem: 15824
[16:59:25.985463] Test:  [200/345]  eta: 0:00:26  loss: 0.1059 (0.1149)  time: 0.1854  data: 0.0001  max mem: 15824
[16:59:27.845789] Test:  [210/345]  eta: 0:00:24  loss: 0.1095 (0.1147)  time: 0.1858  data: 0.0001  max mem: 15824
[16:59:29.710673] Test:  [220/345]  eta: 0:00:23  loss: 0.1137 (0.1148)  time: 0.1862  data: 0.0001  max mem: 15824
[16:59:31.578495] Test:  [230/345]  eta: 0:00:21  loss: 0.1168 (0.1155)  time: 0.1866  data: 0.0001  max mem: 15824
[16:59:33.450236] Test:  [240/345]  eta: 0:00:19  loss: 0.1189 (0.1157)  time: 0.1869  data: 0.0001  max mem: 15824
[16:59:35.325186] Test:  [250/345]  eta: 0:00:17  loss: 0.1162 (0.1155)  time: 0.1873  data: 0.0001  max mem: 15824
[16:59:37.202368] Test:  [260/345]  eta: 0:00:15  loss: 0.1101 (0.1157)  time: 0.1875  data: 0.0001  max mem: 15824
[16:59:39.083310] Test:  [270/345]  eta: 0:00:13  loss: 0.1170 (0.1159)  time: 0.1878  data: 0.0001  max mem: 15824
[16:59:40.967596] Test:  [280/345]  eta: 0:00:12  loss: 0.1122 (0.1158)  time: 0.1882  data: 0.0001  max mem: 15824
[16:59:42.855356] Test:  [290/345]  eta: 0:00:10  loss: 0.1073 (0.1158)  time: 0.1885  data: 0.0001  max mem: 15824
[16:59:44.747811] Test:  [300/345]  eta: 0:00:08  loss: 0.1150 (0.1158)  time: 0.1889  data: 0.0001  max mem: 15824
[16:59:46.642608] Test:  [310/345]  eta: 0:00:06  loss: 0.1150 (0.1161)  time: 0.1893  data: 0.0001  max mem: 15824
[16:59:48.541227] Test:  [320/345]  eta: 0:00:04  loss: 0.1129 (0.1160)  time: 0.1896  data: 0.0001  max mem: 15824
[16:59:50.441930] Test:  [330/345]  eta: 0:00:02  loss: 0.1139 (0.1160)  time: 0.1899  data: 0.0001  max mem: 15824
[16:59:52.343189] Test:  [340/345]  eta: 0:00:00  loss: 0.1095 (0.1160)  time: 0.1900  data: 0.0001  max mem: 15824
[16:59:53.104983] Test:  [344/345]  eta: 0:00:00  loss: 0.1150 (0.1161)  time: 0.1901  data: 0.0001  max mem: 15824
[16:59:53.174347] Test: Total time: 0:01:04 (0.1863 s / it)
[17:00:03.702362] Test:  [ 0/57]  eta: 0:00:31  loss: 0.4807 (0.4807)  time: 0.5507  data: 0.3705  max mem: 15824
[17:00:05.480803] Test:  [10/57]  eta: 0:00:09  loss: 0.4533 (0.4828)  time: 0.2117  data: 0.0338  max mem: 15824
[17:00:07.259506] Test:  [20/57]  eta: 0:00:07  loss: 0.4533 (0.4643)  time: 0.1778  data: 0.0001  max mem: 15824
[17:00:09.042697] Test:  [30/57]  eta: 0:00:05  loss: 0.2837 (0.4019)  time: 0.1780  data: 0.0001  max mem: 15824
[17:00:10.830592] Test:  [40/57]  eta: 0:00:03  loss: 0.2715 (0.3781)  time: 0.1785  data: 0.0001  max mem: 15824
[17:00:12.619023] Test:  [50/57]  eta: 0:00:01  loss: 0.3139 (0.3785)  time: 0.1788  data: 0.0001  max mem: 15824
[17:00:13.592283] Test:  [56/57]  eta: 0:00:00  loss: 0.3885 (0.3969)  time: 0.1737  data: 0.0001  max mem: 15824
[17:00:13.655887] Test: Total time: 0:00:10 (0.1843 s / it)
[17:00:15.412179] Dice score of the network on the train images: 0.876999, val images: 0.769386
[17:00:15.416453] log_dir: /root/seg_framework/MS-Mamba/output_dir/mslesseg/train_ft
[17:00:16.414111] Epoch: [49]  [  0/345]  eta: 0:05:43  lr: 0.000000  loss: 0.1349 (0.1349)  time: 0.9966  data: 0.3702  max mem: 15824
[17:00:28.745440] Epoch: [49]  [ 20/345]  eta: 0:03:26  lr: 0.000000  loss: 0.1189 (0.1230)  time: 0.6165  data: 0.0001  max mem: 15824
[17:00:41.123763] Epoch: [49]  [ 40/345]  eta: 0:03:11  lr: 0.000000  loss: 0.1169 (0.1211)  time: 0.6189  data: 0.0001  max mem: 15824
[17:00:53.521977] Epoch: [49]  [ 60/345]  eta: 0:02:58  lr: 0.000000  loss: 0.1194 (0.1204)  time: 0.6199  data: 0.0001  max mem: 15824
[17:01:05.943489] Epoch: [49]  [ 80/345]  eta: 0:02:45  lr: 0.000000  loss: 0.1137 (0.1200)  time: 0.6210  data: 0.0001  max mem: 15824
[17:01:18.375803] Epoch: [49]  [100/345]  eta: 0:02:32  lr: 0.000000  loss: 0.1250 (0.1213)  time: 0.6216  data: 0.0001  max mem: 15824
[17:01:30.827375] Epoch: [49]  [120/345]  eta: 0:02:20  lr: 0.000000  loss: 0.1200 (0.1219)  time: 0.6225  data: 0.0001  max mem: 15824
[17:01:43.274265] Epoch: [49]  [140/345]  eta: 0:02:07  lr: 0.000000  loss: 0.1205 (0.1225)  time: 0.6223  data: 0.0001  max mem: 15824
[17:01:55.722776] Epoch: [49]  [160/345]  eta: 0:01:55  lr: 0.000000  loss: 0.1248 (0.1227)  time: 0.6224  data: 0.0001  max mem: 15824
[17:02:08.159876] Epoch: [49]  [180/345]  eta: 0:01:42  lr: 0.000000  loss: 0.1188 (0.1228)  time: 0.6218  data: 0.0001  max mem: 15824
[17:02:20.601394] Epoch: [49]  [200/345]  eta: 0:01:30  lr: 0.000000  loss: 0.1149 (0.1226)  time: 0.6220  data: 0.0001  max mem: 15824
[17:02:33.050659] Epoch: [49]  [220/345]  eta: 0:01:17  lr: 0.000000  loss: 0.1192 (0.1224)  time: 0.6224  data: 0.0001  max mem: 15824
[17:02:45.485491] Epoch: [49]  [240/345]  eta: 0:01:05  lr: 0.000000  loss: 0.1202 (0.1228)  time: 0.6217  data: 0.0001  max mem: 15824
[17:02:57.913772] Epoch: [49]  [260/345]  eta: 0:00:52  lr: 0.000000  loss: 0.1154 (0.1227)  time: 0.6214  data: 0.0001  max mem: 15824
[17:03:10.355640] Epoch: [49]  [280/345]  eta: 0:00:40  lr: 0.000000  loss: 0.1203 (0.1228)  time: 0.6220  data: 0.0001  max mem: 15824
[17:03:22.795954] Epoch: [49]  [300/345]  eta: 0:00:28  lr: 0.000000  loss: 0.1129 (0.1224)  time: 0.6220  data: 0.0001  max mem: 15824
[17:03:35.227924] Epoch: [49]  [320/345]  eta: 0:00:15  lr: 0.000000  loss: 0.1139 (0.1223)  time: 0.6216  data: 0.0001  max mem: 15824
[17:03:47.636103] Epoch: [49]  [340/345]  eta: 0:00:03  lr: 0.000000  loss: 0.1112 (0.1219)  time: 0.6204  data: 0.0001  max mem: 15824
[17:03:50.118572] Epoch: [49]  [344/345]  eta: 0:00:00  lr: 0.000000  loss: 0.1112 (0.1218)  time: 0.6203  data: 0.0001  max mem: 15824
[17:03:50.180476] Epoch: [49] Total time: 0:03:34 (0.6225 s / it)
[17:03:50.180702] Averaged stats: lr: 0.000000  loss: 0.1112 (0.1218)
[17:03:50.756147] Test:  [  0/345]  eta: 0:03:16  loss: 0.1064 (0.1064)  time: 0.5695  data: 0.3857  max mem: 15824
[17:03:52.552274] Test:  [ 10/345]  eta: 0:01:12  loss: 0.1133 (0.1226)  time: 0.2150  data: 0.0352  max mem: 15824
[17:03:54.351418] Test:  [ 20/345]  eta: 0:01:04  loss: 0.1141 (0.1205)  time: 0.1797  data: 0.0001  max mem: 15824
[17:03:56.153617] Test:  [ 30/345]  eta: 0:01:00  loss: 0.1141 (0.1198)  time: 0.1800  data: 0.0001  max mem: 15824
[17:03:57.955256] Test:  [ 40/345]  eta: 0:00:57  loss: 0.1125 (0.1176)  time: 0.1801  data: 0.0001  max mem: 15824
[17:03:59.759207] Test:  [ 50/345]  eta: 0:00:55  loss: 0.1129 (0.1173)  time: 0.1802  data: 0.0001  max mem: 15824
[17:04:01.568742] Test:  [ 60/345]  eta: 0:00:53  loss: 0.1129 (0.1173)  time: 0.1806  data: 0.0001  max mem: 15824
[17:04:03.381729] Test:  [ 70/345]  eta: 0:00:51  loss: 0.1131 (0.1170)  time: 0.1811  data: 0.0001  max mem: 15824
[17:04:05.196176] Test:  [ 80/345]  eta: 0:00:49  loss: 0.1126 (0.1168)  time: 0.1813  data: 0.0001  max mem: 15824
[17:04:07.015196] Test:  [ 90/345]  eta: 0:00:47  loss: 0.1126 (0.1177)  time: 0.1816  data: 0.0001  max mem: 15824
[17:04:08.837333] Test:  [100/345]  eta: 0:00:45  loss: 0.1099 (0.1166)  time: 0.1820  data: 0.0001  max mem: 15824
[17:04:10.662589] Test:  [110/345]  eta: 0:00:43  loss: 0.1096 (0.1163)  time: 0.1823  data: 0.0001  max mem: 15824
[17:04:12.491543] Test:  [120/345]  eta: 0:00:41  loss: 0.1117 (0.1161)  time: 0.1827  data: 0.0001  max mem: 15824
[17:04:14.323279] Test:  [130/345]  eta: 0:00:39  loss: 0.1117 (0.1158)  time: 0.1830  data: 0.0001  max mem: 15824
[17:04:16.158993] Test:  [140/345]  eta: 0:00:37  loss: 0.1113 (0.1158)  time: 0.1833  data: 0.0001  max mem: 15824
[17:04:18.002360] Test:  [150/345]  eta: 0:00:35  loss: 0.1082 (0.1152)  time: 0.1839  data: 0.0001  max mem: 15824
[17:04:19.844982] Test:  [160/345]  eta: 0:00:34  loss: 0.1063 (0.1148)  time: 0.1842  data: 0.0001  max mem: 15824
[17:04:21.691713] Test:  [170/345]  eta: 0:00:32  loss: 0.1087 (0.1154)  time: 0.1844  data: 0.0001  max mem: 15824
[17:04:23.540911] Test:  [180/345]  eta: 0:00:30  loss: 0.1158 (0.1154)  time: 0.1847  data: 0.0001  max mem: 15824
[17:04:25.394366] Test:  [190/345]  eta: 0:00:28  loss: 0.1163 (0.1158)  time: 0.1851  data: 0.0001  max mem: 15824
[17:04:27.252610] Test:  [200/345]  eta: 0:00:26  loss: 0.1178 (0.1158)  time: 0.1855  data: 0.0001  max mem: 15824
[17:04:29.112851] Test:  [210/345]  eta: 0:00:24  loss: 0.1178 (0.1160)  time: 0.1859  data: 0.0001  max mem: 15824
[17:04:30.977697] Test:  [220/345]  eta: 0:00:23  loss: 0.1209 (0.1161)  time: 0.1862  data: 0.0001  max mem: 15824
[17:04:32.844337] Test:  [230/345]  eta: 0:00:21  loss: 0.1198 (0.1161)  time: 0.1865  data: 0.0001  max mem: 15824
[17:04:34.713975] Test:  [240/345]  eta: 0:00:19  loss: 0.1143 (0.1160)  time: 0.1868  data: 0.0001  max mem: 15824
[17:04:36.592679] Test:  [250/345]  eta: 0:00:17  loss: 0.1152 (0.1162)  time: 0.1874  data: 0.0001  max mem: 15824
[17:04:38.471622] Test:  [260/345]  eta: 0:00:15  loss: 0.1227 (0.1161)  time: 0.1878  data: 0.0001  max mem: 15824
[17:04:40.353174] Test:  [270/345]  eta: 0:00:13  loss: 0.1108 (0.1159)  time: 0.1880  data: 0.0001  max mem: 15824
[17:04:42.237922] Test:  [280/345]  eta: 0:00:12  loss: 0.1139 (0.1165)  time: 0.1883  data: 0.0001  max mem: 15824
[17:04:44.125536] Test:  [290/345]  eta: 0:00:10  loss: 0.1101 (0.1161)  time: 0.1886  data: 0.0001  max mem: 15824
[17:04:46.019242] Test:  [300/345]  eta: 0:00:08  loss: 0.1087 (0.1161)  time: 0.1890  data: 0.0001  max mem: 15824
[17:04:47.913542] Test:  [310/345]  eta: 0:00:06  loss: 0.1139 (0.1163)  time: 0.1893  data: 0.0001  max mem: 15824
[17:04:49.812967] Test:  [320/345]  eta: 0:00:04  loss: 0.1177 (0.1164)  time: 0.1896  data: 0.0001  max mem: 15824
[17:04:51.714073] Test:  [330/345]  eta: 0:00:02  loss: 0.1107 (0.1162)  time: 0.1900  data: 0.0001  max mem: 15824
[17:04:53.617141] Test:  [340/345]  eta: 0:00:00  loss: 0.1108 (0.1163)  time: 0.1902  data: 0.0001  max mem: 15824
[17:04:54.378957] Test:  [344/345]  eta: 0:00:00  loss: 0.1108 (0.1162)  time: 0.1903  data: 0.0001  max mem: 15824
[17:04:54.445742] Test: Total time: 0:01:04 (0.1863 s / it)
[17:05:05.031002] Test:  [ 0/57]  eta: 0:00:30  loss: 0.4802 (0.4802)  time: 0.5358  data: 0.3553  max mem: 15824
[17:05:06.805904] Test:  [10/57]  eta: 0:00:09  loss: 0.4530 (0.4824)  time: 0.2100  data: 0.0324  max mem: 15824
[17:05:08.584641] Test:  [20/57]  eta: 0:00:07  loss: 0.4530 (0.4639)  time: 0.1776  data: 0.0001  max mem: 15824
[17:05:10.367201] Test:  [30/57]  eta: 0:00:05  loss: 0.2837 (0.4015)  time: 0.1780  data: 0.0001  max mem: 15824
[17:05:12.155428] Test:  [40/57]  eta: 0:00:03  loss: 0.2708 (0.3776)  time: 0.1785  data: 0.0001  max mem: 15824
[17:05:13.943069] Test:  [50/57]  eta: 0:00:01  loss: 0.3125 (0.3779)  time: 0.1787  data: 0.0001  max mem: 15824
[17:05:14.917233] Test:  [56/57]  eta: 0:00:00  loss: 0.3882 (0.3963)  time: 0.1737  data: 0.0000  max mem: 15824
[17:05:14.991792] Test: Total time: 0:00:10 (0.1842 s / it)
[17:05:16.732437] Dice score of the network on the train images: 0.876694, val images: 0.769835
[17:05:16.733968] Training time 4:11:18
[17:05:18.686606] Load pre-trained checkpoint from: /root/seg_framework/MS-Mamba/output_dir/mslesseg/checkpoints_0/checkpoint-best_dice_model_0.pth
[17:05:18.708079] <All keys matched successfully>
[17:05:21.843452] Test:  [  0/246]  eta: 0:12:32    time: 3.0607  data: 0.5164  max mem: 15824
[17:05:24.690684] Test:  [ 10/246]  eta: 0:02:06    time: 0.5370  data: 0.0470  max mem: 15824
[17:05:30.686324] ---------------------------------
[17:05:30.686548] Patient 1:
[17:05:30.686629]       precision: 0.41095298528671265
[17:05:30.686696]       recall: 0.6273864507675171
[17:05:30.686757]       dice_score: 0.4966128170490265
[17:05:30.689788] Test:  [ 20/246]  eta: 0:02:08    time: 0.4423  data: 0.0001  max mem: 15824
[17:05:33.529581] Test:  [ 30/246]  eta: 0:01:42    time: 0.4419  data: 0.0001  max mem: 15824
[17:05:39.492437] ---------------------------------
[17:05:39.492657] Patient 2:
[17:05:39.492735]       precision: 0.48098024725914
[17:05:39.492799]       recall: 0.663806140422821
[17:05:39.492858]       dice_score: 0.5577942728996277
[17:05:39.493381] Test:  [ 40/246]  eta: 0:01:44    time: 0.4401  data: 0.0001  max mem: 15824
[17:05:42.335230] Test:  [ 50/246]  eta: 0:01:30    time: 0.4402  data: 0.0001  max mem: 15824
[17:05:45.183931] Test:  [ 60/246]  eta: 0:01:20    time: 0.2845  data: 0.0001  max mem: 15824
[17:05:48.537058] ---------------------------------
[17:05:48.537279] Patient 3:
[17:05:48.537352]       precision: 0.2886338233947754
[17:05:48.537417]       recall: 0.5655512809753418
[17:05:48.537476]       dice_score: 0.3822057545185089
[17:05:51.095437] Test:  [ 70/246]  eta: 0:01:20    time: 0.4380  data: 0.0001  max mem: 15824
[17:05:53.945453] Test:  [ 80/246]  eta: 0:01:12    time: 0.4380  data: 0.0001  max mem: 15824
[17:05:57.336529] ---------------------------------
[17:05:57.336746] Patient 4:
[17:05:57.336822]       precision: 0.5307692289352417
[17:05:57.336883]       recall: 0.5572943091392517
[17:05:57.336943]       dice_score: 0.5437084436416626
[17:05:59.887662] Test:  [ 90/246]  eta: 0:01:10    time: 0.4396  data: 0.0001  max mem: 15824
[17:06:02.732404] Test:  [100/246]  eta: 0:01:03    time: 0.4393  data: 0.0001  max mem: 15824
[17:06:06.384550] ---------------------------------
[17:06:06.384764] Patient 5:
[17:06:06.384842]       precision: 0.3288567364215851
[17:06:06.384904]       recall: 0.5238617658615112
[17:06:06.384962]       dice_score: 0.40406176447868347
[17:06:08.658193] Test:  [110/246]  eta: 0:01:01    time: 0.4385  data: 0.0001  max mem: 15824
[17:06:11.506436] Test:  [120/246]  eta: 0:00:54    time: 0.4386  data: 0.0001  max mem: 15824
[17:06:15.130153] ---------------------------------
[17:06:15.130391] Patient 6:
[17:06:15.130465]       precision: 0.3209953308105469
[17:06:15.130528]       recall: 0.5660998225212097
[17:06:15.130587]       dice_score: 0.4096863865852356
[17:06:17.397549] Test:  [130/246]  eta: 0:00:51    time: 0.4369  data: 0.0001  max mem: 15824
[17:06:20.241694] Test:  [140/246]  eta: 0:00:46    time: 0.4367  data: 0.0001  max mem: 15824
[17:06:24.176224] ---------------------------------
[17:06:24.176444] Patient 7:
[17:06:24.176520]       precision: 0.7481896281242371
[17:06:24.176584]       recall: 0.8229543566703796
[17:06:24.176641]       dice_score: 0.7837930917739868
[17:06:26.164225] Test:  [150/246]  eta: 0:00:42    time: 0.4383  data: 0.0001  max mem: 15824
[17:06:29.010389] Test:  [160/246]  eta: 0:00:37    time: 0.4384  data: 0.0001  max mem: 15824
[17:06:32.915369] ---------------------------------
[17:06:32.915597] Patient 8:
[17:06:32.915670]       precision: 0.82578444480896
[17:06:32.915732]       recall: 0.5880436897277832
[17:06:32.915790]       dice_score: 0.6869255304336548
[17:06:34.901752] Test:  [170/246]  eta: 0:00:33    time: 0.4368  data: 0.0001  max mem: 15824
[17:06:37.747098] Test:  [180/246]  eta: 0:00:28    time: 0.4368  data: 0.0001  max mem: 15824
[17:06:41.683187] ---------------------------------
[17:06:41.683411] Patient 9:
[17:06:41.683484]       precision: 0.6977662444114685
[17:06:41.683546]       recall: 0.8154938817024231
[17:06:41.683606]       dice_score: 0.7520506381988525
[17:06:43.669522] Test:  [190/246]  eta: 0:00:24    time: 0.4383  data: 0.0001  max mem: 15824
[17:06:46.516721] Test:  [200/246]  eta: 0:00:20    time: 0.4384  data: 0.0001  max mem: 15824
[17:06:50.708376] ---------------------------------
[17:06:50.708599] Patient 10:
[17:06:50.708675]       precision: 0.6241858005523682
[17:06:50.708739]       recall: 0.8843421936035156
[17:06:50.708798]       dice_score: 0.7318310737609863
[17:06:52.418117] Test:  [210/246]  eta: 0:00:15    time: 0.4374  data: 0.0001  max mem: 15824
[17:06:55.264837] Test:  [220/246]  eta: 0:00:11    time: 0.4374  data: 0.0001  max mem: 15824
[17:06:59.460270] ---------------------------------
[17:06:59.460473] Patient 11:
[17:06:59.460546]       precision: 0.8791062235832214
[17:06:59.460611]       recall: 0.7406575083732605
[17:06:59.460672]       dice_score: 0.8039649128913879
[17:07:01.164078] Test:  [230/246]  eta: 0:00:07    time: 0.4372  data: 0.0001  max mem: 15824
[17:07:04.008196] Test:  [240/246]  eta: 0:00:02    time: 0.4371  data: 0.0001  max mem: 15824
[17:07:09.118951] ---------------------------------
[17:07:09.119174] Patient 12:
[17:07:09.119255]       precision: 0.5707134008407593
[17:07:09.119332]       recall: 0.82236248254776
[17:07:09.119430]       dice_score: 0.6738086342811584
[17:07:09.119883] Test:  [245/246]  eta: 0:00:00    time: 0.4689  data: 0.0000  max mem: 15824
[17:07:09.210437] Test: Total time: 0:01:50 (0.4489 s / it)
[17:07:09.210772] ================================
[17:07:09.210877] Averaged over all patients:
[17:07:09.211176]       precision: 0.5589 ± 0.1925
[17:07:09.211366]       recall: 0.6815 ± 0.1230
[17:07:09.211587]       dice_score: 0.6022 ± 0.1490